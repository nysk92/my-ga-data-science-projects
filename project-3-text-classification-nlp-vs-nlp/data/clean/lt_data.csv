level_0,index,title,selftext,url,subreddit,name,content,len
0,0,"Facebook AI Open-Source ‘The FLORES-101 Data Set’, For Better Translation Systems Around The World (Paper included)","[FLORES-101](https://l.facebook.com/l.php?u=https%3A%2F%2Fgithub.com%2Ffacebookresearch%2Fflores%3Ffbclid%3DIwAR18XHNF2irnZUwv6ZwTrfX9LTX7NFQW-GHaVPTMffhKWPQcgBjgMD1A8mo&amp;h=AT03MSblPXA3bufCYi2Xy_GR-fxCQFim0iX2w2ZkT5fiiJLjE-Zltua9obJXi4oRaOaqVHEEZ3QNRN8SXrC8lt5lLw3P4Hnlvw6L3ldX5I_z35thn6992Ve6b8H5wYE_JiYd_A), a first-of-its-kind, many-to-many evaluation data set that covers 101 languages from around the world, is now open-sourced. FLORES-101 is a tool that allows researchers to test and refine multilingual translation models such as M2M-100 quickly. To speed work on many-to-many translation systems worldwide, Facebook AI makes [the complete FLORES-101 data set](https://github.com/facebookresearch/flores?fbclid=IwAR1pjSZbSRQhxv9QccaCCApZLS0zltZy0uji24rWt9QxTR0HgWkNCGu_F2M), and associated technical report, and various models freely available for anybody to use.

Full Article: [https://www.marktechpost.com/2021/06/12/facebook-ai-open-source-the-flores-101-data-set-for-better-translation-systems-around-the-world/](https://www.marktechpost.com/2021/06/12/facebook-ai-open-source-the-flores-101-data-set-for-better-translation-systems-around-the-world/) 

Paper: https://arxiv.org/abs/2106.03193",https://www.reddit.com/r/LanguageTechnology/comments/nypgu0/facebook_ai_opensource_the_flores101_data_set_for/,LanguageTechnology,t3_nypgu0,"Facebook AI Open-Source ‘The FLORES-101 Data Set’, For Better Translation Systems Around The World (Paper included) [FLORES-101](https://l.facebook.com/l.php?u=https%3A%2F%2Fgithub.com%2Ffacebookresearch%2Fflores%3Ffbclid%3DIwAR18XHNF2irnZUwv6ZwTrfX9LTX7NFQW-GHaVPTMffhKWPQcgBjgMD1A8mo&amp;h=AT03MSblPXA3bufCYi2Xy_GR-fxCQFim0iX2w2ZkT5fiiJLjE-Zltua9obJXi4oRaOaqVHEEZ3QNRN8SXrC8lt5lLw3P4Hnlvw6L3ldX5I_z35thn6992Ve6b8H5wYE_JiYd_A), a first-of-its-kind, many-to-many evaluation data set that covers 101 languages from around the world, is now open-sourced. FLORES-101 is a tool that allows researchers to test and refine multilingual translation models such as M2M-100 quickly. To speed work on many-to-many translation systems worldwide, Facebook AI makes [the complete FLORES-101 data set](https://github.com/facebookresearch/flores?fbclid=IwAR1pjSZbSRQhxv9QccaCCApZLS0zltZy0uji24rWt9QxTR0HgWkNCGu_F2M), and associated technical report, and various models freely available for anybody to use.

Full Article: [https://www.marktechpost.com/2021/06/12/facebook-ai-open-source-the-flores-101-data-set-for-better-translation-systems-around-the-world/](https://www.marktechpost.com/2021/06/12/facebook-ai-open-source-the-flores-101-data-set-for-better-translation-systems-around-the-world/) 

Paper: https://arxiv.org/abs/2106.03193",1324
1,1,Can anyone please guide me to a video based Automatic speech recognition (ASR) course ?,,https://www.reddit.com/r/LanguageTechnology/comments/nyw4qu/can_anyone_please_guide_me_to_a_video_based/,LanguageTechnology,t3_nyw4qu,Can anyone please guide me to a video based Automatic speech recognition (ASR) course ? ,88
2,2,How to pass BERT output to dense layer,"I am confused about which out of BERT transformer should be fed to dense layer. BERT transformer output is \`batch,sequence length, 768 \`. So I am confused about how to pass it to the dense layer",https://www.reddit.com/r/LanguageTechnology/comments/nyx09y/how_to_pass_bert_output_to_dense_layer/,LanguageTechnology,t3_nyx09y,"How to pass BERT output to dense layer I am confused about which out of BERT transformer should be fed to dense layer. BERT transformer output is \`batch,sequence length, 768 \`. So I am confused about how to pass it to the dense layer",235
3,3,Detecting Hallucinated Content in Conditional Neural Sequence Generation (NLP Paper Walkthrough),,https://youtu.be/fD2g9s1Isi4,LanguageTechnology,t3_nyvm5d,Detecting Hallucinated Content in Conditional Neural Sequence Generation (NLP Paper Walkthrough) ,97
4,4,Text Classification using spaCy v3.0 transformers in Python | Natural Language Processing Tutorial,,https://youtu.be/NkuqNItEbsc,LanguageTechnology,t3_nyv1pp,Text Classification using spaCy v3.0 transformers in Python | Natural Language Processing Tutorial ,99
5,5,Towards Emotional Support Dialog Systems,"Hello everyone,

Really excited to share with you that our paper ""Towards Emotional Support Dialog Systems"" got accepted to the main conference of the Association for Computational Linguistics this year (ACL2021). We strongly believe that dialogue systems have the potential to become powerful emotional supporters that can help many individuals with their daily struggles. Towards this goal, we created a high-quality dataset of emotional conversations between trained crowdsourcing workers and will be making this dataset publicly available.

Feel free to read our [paper](https://arxiv.org/abs/2106.01144) for more details.

Thank you and wish you a great day!",https://www.reddit.com/r/LanguageTechnology/comments/nyndog/towards_emotional_support_dialog_systems/,LanguageTechnology,t3_nyndog,"Towards Emotional Support Dialog Systems Hello everyone,

Really excited to share with you that our paper ""Towards Emotional Support Dialog Systems"" got accepted to the main conference of the Association for Computational Linguistics this year (ACL2021). We strongly believe that dialogue systems have the potential to become powerful emotional supporters that can help many individuals with their daily struggles. Towards this goal, we created a high-quality dataset of emotional conversations between trained crowdsourcing workers and will be making this dataset publicly available.

Feel free to read our [paper](https://arxiv.org/abs/2106.01144) for more details.

Thank you and wish you a great day!",704
6,6,Using gpt neo checkpoints,"Hi,
I downloaded gpt neo from theeye.eye on my pc.
It downloaded a various checkpoints.
How do i use them? ... Because in order too load and use model I'd need encoder. Json, pytorch. Bin, etc..",https://www.reddit.com/r/LanguageTechnology/comments/nys2gg/using_gpt_neo_checkpoints/,LanguageTechnology,t3_nys2gg,"Using gpt neo checkpoints Hi,
I downloaded gpt neo from theeye.eye on my pc.
It downloaded a various checkpoints.
How do i use them? ... Because in order too load and use model I'd need encoder. Json, pytorch. Bin, etc..",220
7,7,A Search Engine with a normalized scoring function,"Hey!  
I am involved in a project where I am trying to create a programming language that uses machine learning to compile text as computer code, some info here ([https://github.com/quantleaf/quantleaf-language-documentation](https://github.com/quantleaf/quantleaf-language-documentation)). This is not yet open source as a whole, but I am currently in the process of doing so. The first subproject to be released is a search engine library that enables you to score documents with a value between 0 and 1 (I call it “zero-to-one” score). In short, this is done by evaluating the product of how close we are to a perfect match regarding document length and query length, but also in terms of the amount of tokens, in the document and in the query.

I have created a small recipe search demo for this to showcase it benefits (and potential drawbacks)

[https://quantleaf.github.io/probly-search-demo/](https://quantleaf.github.io/probly-search-demo/)

When searching “Garlic Chicken”, the first two results are:

For the “zero-to-one” scoring
“Garlic Chicken” score 1.
“Garlic-Sherry Chicken” score: 0.7307692307692308

For BM25 (standard parameters)
“Garlic Oven Fried Chicken” score 8.564332563809089
“Garlic Chicken“ score 8.455662889754347

For the BM25 algorithm the perfect match is not the top score. You could circumvent this behaviour by adjusting the parameters of the BM25 algorithm. Or is it in conjunction with a term matching algorithm. But for my programming language project, this was not good enough. I needed a score to be 1, to know when we are 100% matching, 0.5 if we are matching with a 50% relevance, hence I created this.

The search engine is written in Rust, but you could use it in any Node project if you write a little bit of WASM bindgen code (see the demo source code).

Library source code: [https://github.com/quantleaf/probly-search](https://github.com/quantleaf/probly-search)Demo source code: [https://github.com/quantleaf/probly-search-demo](https://github.com/quantleaf/probly-search-demo)

I am curious with what your take is on this scoring function, would you find it useful in comparison to the solution that you currently are using? (Especially for title/label matching)",https://www.reddit.com/r/LanguageTechnology/comments/nybd9c/a_search_engine_with_a_normalized_scoring_function/,LanguageTechnology,t3_nybd9c,"A Search Engine with a normalized scoring function Hey!  
I am involved in a project where I am trying to create a programming language that uses machine learning to compile text as computer code, some info here ([https://github.com/quantleaf/quantleaf-language-documentation](https://github.com/quantleaf/quantleaf-language-documentation)). This is not yet open source as a whole, but I am currently in the process of doing so. The first subproject to be released is a search engine library that enables you to score documents with a value between 0 and 1 (I call it “zero-to-one” score). In short, this is done by evaluating the product of how close we are to a perfect match regarding document length and query length, but also in terms of the amount of tokens, in the document and in the query.

I have created a small recipe search demo for this to showcase it benefits (and potential drawbacks)

[https://quantleaf.github.io/probly-search-demo/](https://quantleaf.github.io/probly-search-demo/)

When searching “Garlic Chicken”, the first two results are:

For the “zero-to-one” scoring
“Garlic Chicken” score 1.
“Garlic-Sherry Chicken” score: 0.7307692307692308

For BM25 (standard parameters)
“Garlic Oven Fried Chicken” score 8.564332563809089
“Garlic Chicken“ score 8.455662889754347

For the BM25 algorithm the perfect match is not the top score. You could circumvent this behaviour by adjusting the parameters of the BM25 algorithm. Or is it in conjunction with a term matching algorithm. But for my programming language project, this was not good enough. I needed a score to be 1, to know when we are 100% matching, 0.5 if we are matching with a 50% relevance, hence I created this.

The search engine is written in Rust, but you could use it in any Node project if you write a little bit of WASM bindgen code (see the demo source code).

Library source code: [https://github.com/quantleaf/probly-search](https://github.com/quantleaf/probly-search)Demo source code: [https://github.com/quantleaf/probly-search-demo](https://github.com/quantleaf/probly-search-demo)

I am curious with what your take is on this scoring function, would you find it useful in comparison to the solution that you currently are using? (Especially for title/label matching)",2263
8,8,Best approach to find (similar) matches for a string in a corpus of documents?,"Context: I'm a hobbyist that got into NLP superficially, so I don't expect a definitive answer. I'd be grateful if you could just point me in the right direction, because I was overwhelmed with all the different approaches after googling it.

Here's what I want to do:

I have laws and legislation split into its smallest pieces. Each piece is a specific string. So one or two lines, maybe a paragraph, with a specific rule saying what you can and cannot do, who is responsible for what, how many days you have to do something, what is the punishment for breaking it etc. I also have a corpus of written tests (about 70k total), with questions that are often about said rules. For each small string, I want to see how many times it was mentioned in tests, so I can rank them in regards to which subjects are more likely to be asked about in tests.

How would you go about doing something like that?",https://www.reddit.com/r/LanguageTechnology/comments/nyctxd/best_approach_to_find_similar_matches_for_a/,LanguageTechnology,t3_nyctxd,"Best approach to find (similar) matches for a string in a corpus of documents? Context: I'm a hobbyist that got into NLP superficially, so I don't expect a definitive answer. I'd be grateful if you could just point me in the right direction, because I was overwhelmed with all the different approaches after googling it.

Here's what I want to do:

I have laws and legislation split into its smallest pieces. Each piece is a specific string. So one or two lines, maybe a paragraph, with a specific rule saying what you can and cannot do, who is responsible for what, how many days you have to do something, what is the punishment for breaking it etc. I also have a corpus of written tests (about 70k total), with questions that are often about said rules. For each small string, I want to see how many times it was mentioned in tests, so I can rank them in regards to which subjects are more likely to be asked about in tests.

How would you go about doing something like that?",977
9,9,Extract text from image which is printed columnwise,"Hi, I want to extract text from image where text is printed columnwise (like research papers) does anybody know any libraries that will help me with it? Or advice how to approach with such use case? 

Thanks in advance!",https://www.reddit.com/r/LanguageTechnology/comments/nyfn5w/extract_text_from_image_which_is_printed/,LanguageTechnology,t3_nyfn5w,"Extract text from image which is printed columnwise Hi, I want to extract text from image where text is printed columnwise (like research papers) does anybody know any libraries that will help me with it? Or advice how to approach with such use case? 

Thanks in advance!",271
10,10,Can't run gpt3 xl,"Hi All,
I downloaded the model from
https://the-eye.eu/public/AI/gptneo-release/GPT3_XL/

after which i changed model_path in config.json to:
""model_path"" : ""C:\Users\GPT_NEO_2\GPT3_XL""

Whenever i run the following code:
model = GPTNeoForCausalLM.from_pretrained(""C:\Users\GPT_NEO_2\GPT3_XL"")

i get an error:
f""Error no file named {[WEIGHTS_NAME, TF2_WEIGHTS_NAME, TF_WEIGHTS_NAME + '.index', FLAX_WEIGHTS_NAME]} found in ""
OSError: Error no file named ['pytorch_model.bin', 'tf_model.h5', 'model.ckpt.index', 'flax_model.msgpack'] found in directory C:\Users\GPT_NEO_2\GPT3_XL or from_tf and from_flax set to False.

and while running :
generator = pipeline('text-generation', model=""C:\Users\GPT_NEO_2\GPT3_XL"")

i get following error:
f""Unrecognized model in {pretrained_model_name_or_path}. ""

I have the latest TF and torch (both cpu).

Thanks",https://www.reddit.com/r/LanguageTechnology/comments/ny88wd/cant_run_gpt3_xl/,LanguageTechnology,t3_ny88wd,"Can't run gpt3 xl Hi All,
I downloaded the model from
https://the-eye.eu/public/AI/gptneo-release/GPT3_XL/

after which i changed model_path in config.json to:
""model_path"" : ""C:\Users\GPT_NEO_2\GPT3_XL""

Whenever i run the following code:
model = GPTNeoForCausalLM.from_pretrained(""C:\Users\GPT_NEO_2\GPT3_XL"")

i get an error:
f""Error no file named {[WEIGHTS_NAME, TF2_WEIGHTS_NAME, TF_WEIGHTS_NAME + '.index', FLAX_WEIGHTS_NAME]} found in ""
OSError: Error no file named ['pytorch_model.bin', 'tf_model.h5', 'model.ckpt.index', 'flax_model.msgpack'] found in directory C:\Users\GPT_NEO_2\GPT3_XL or from_tf and from_flax set to False.

and while running :
generator = pipeline('text-generation', model=""C:\Users\GPT_NEO_2\GPT3_XL"")

i get following error:
f""Unrecognized model in {pretrained_model_name_or_path}. ""

I have the latest TF and torch (both cpu).

Thanks",868
11,11,Detecting all words/entities with a certain attribute,"Hi folks. I wanted to find all words that indicated a certain attribute. For example, consider finding all words that are 'hot'. That could include 'fire', 'flame', 'lava', 'heat' or a 'stove'.

The approach I came up with is to use word embeddings and the resulting word graph. If I start with 'hot', I could add all words within a certain distance, and then perform this process for all subsequent nodes to find paths of a certain max total distance. All vertices in this subgraph would be my answer. But I would still have to account for colloquialism.

Are there any existing frameworks or datasets that already do it like this or with any other methods?

Thanks in advance!",https://www.reddit.com/r/LanguageTechnology/comments/nxlmi0/detecting_all_wordsentities_with_a_certain/,LanguageTechnology,t3_nxlmi0,"Detecting all words/entities with a certain attribute Hi folks. I wanted to find all words that indicated a certain attribute. For example, consider finding all words that are 'hot'. That could include 'fire', 'flame', 'lava', 'heat' or a 'stove'.

The approach I came up with is to use word embeddings and the resulting word graph. If I start with 'hot', I could add all words within a certain distance, and then perform this process for all subsequent nodes to find paths of a certain max total distance. All vertices in this subgraph would be my answer. But I would still have to account for colloquialism.

Are there any existing frameworks or datasets that already do it like this or with any other methods?

Thanks in advance!",732
12,12,At OpenDialog we make NLU more useful by making it work less. Combining context and pro-active conversation management to reduce reliance on NLU understanding state.,,https://opendialog.ai/2021/06/08/how-opendialog-approaches-natural-language-understanding/,LanguageTechnology,t3_nxb3ar,At OpenDialog we make NLU more useful by making it work less. Combining context and pro-active conversation management to reduce reliance on NLU understanding state. ,166
13,13,Custom Named Entity (Disease) Recognition in clinical text with spaCy v3 Transformers in Python,,https://youtu.be/Nv3TqzT2RLI,LanguageTechnology,t3_nxie9m,Custom Named Entity (Disease) Recognition in clinical text with spaCy v3 Transformers in Python ,96
14,14,How to use gensim topic modeling to predict sentences in a document?,"Im able to predict document topics (such as document A is 60% Topic 1, and 40% topic 2). But cant find a way to classify what sentences are Topic 1 and which ones are Topic 2. One way of doing this could be to use sentence boundaries to extract sentences and then use gensim to predict each sentence but im looking for a formal way to do it.",https://www.reddit.com/r/LanguageTechnology/comments/nxj9dj/how_to_use_gensim_topic_modeling_to_predict/,LanguageTechnology,t3_nxj9dj,"How to use gensim topic modeling to predict sentences in a document? Im able to predict document topics (such as document A is 60% Topic 1, and 40% topic 2). But cant find a way to classify what sentences are Topic 1 and which ones are Topic 2. One way of doing this could be to use sentence boundaries to extract sentences and then use gensim to predict each sentence but im looking for a formal way to do it.",410
15,15,"How to understand the ""valence"" of DMV in unsupervised dependency parsing?","I have read the paper "" Corpus-Based Induction of Syntactic Structure: Models of Dependency and Constituency "", which proposed a classical model DMV( Dependency Model with Valence ) for unsupervised dependency parsing.

As far as I know, the conception ""valence"" is used to describe the number of  “action element” which is dependenct by a verb.

But I can't find more details about how the DMV used ""valence"" in aforementioned paper excepted the model's name.

Can anyone solve my doubts? Thank you very much!",https://www.reddit.com/r/LanguageTechnology/comments/nxh2t8/how_to_understand_the_valence_of_dmv_in/,LanguageTechnology,t3_nxh2t8,"How to understand the ""valence"" of DMV in unsupervised dependency parsing? I have read the paper "" Corpus-Based Induction of Syntactic Structure: Models of Dependency and Constituency "", which proposed a classical model DMV( Dependency Model with Valence ) for unsupervised dependency parsing.

As far as I know, the conception ""valence"" is used to describe the number of  “action element” which is dependenct by a verb.

But I can't find more details about how the DMV used ""valence"" in aforementioned paper excepted the model's name.

Can anyone solve my doubts? Thank you very much!",585
16,16,Problem while doing daily topic modeling,"I've been trying for weeks to do daily topic modeling in this [methodology](https://github.com/Stveshawn/contextual_topic_identification). What I did was divide my dataset into groups by day and loop through the architecture by mini dataset. The first ""problem"" is that I'm getting a warning that I can't loop in an autoencoder and the second is that my metric values don't change much despite the dataset I use (I'm using average coherence at the end, but if I run the code with another dataset with other texts, the average coherence remains similar). Anyone could tell me what I'm doing wrong and how do I model the daily topics correctly, as I'm doing this without any examples (because I couldn't find any).

Code:

    for i, group in enumerate(data_groups.groups):
        #LDA
        
        #BERT
        
        #Concatenation 
        
        #Autoencoder
        AE = Autoencoder()
        AE.fit(ldabert)
        vec = AE.encoder.predict(ldabert)
        
        #Kmeans
    
        #Metrics

Warning:

    WARNING:tensorflow:5 out of the last 5 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000161989E3AF0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.

Metric values I'm having: +- 0.55 in coherence, doesn't change much beyond that",https://www.reddit.com/r/LanguageTechnology/comments/nxgveu/problem_while_doing_daily_topic_modeling/,LanguageTechnology,t3_nxgveu,"Problem while doing daily topic modeling I've been trying for weeks to do daily topic modeling in this [methodology](https://github.com/Stveshawn/contextual_topic_identification). What I did was divide my dataset into groups by day and loop through the architecture by mini dataset. The first ""problem"" is that I'm getting a warning that I can't loop in an autoencoder and the second is that my metric values don't change much despite the dataset I use (I'm using average coherence at the end, but if I run the code with another dataset with other texts, the average coherence remains similar). Anyone could tell me what I'm doing wrong and how do I model the daily topics correctly, as I'm doing this without any examples (because I couldn't find any).

Code:

    for i, group in enumerate(data_groups.groups):
        #LDA
        
        #BERT
        
        #Concatenation 
        
        #Autoencoder
        AE = Autoencoder()
        AE.fit(ldabert)
        vec = AE.encoder.predict(ldabert)
        
        #Kmeans
    
        #Metrics

Warning:

    WARNING:tensorflow:5 out of the last 5 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000161989E3AF0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.

Metric values I'm having: +- 0.55 in coherence, doesn't change much beyond that",1920
17,17,How often is NER (named entity recognition) a process in your model building process?,"I recently started, kaggle notebooks don't suggest it's that important.


 But I recently got access to Prodigy, and it took me an embarassngly long time to install it in Pycharm. But the concept and ease of use is  convenient but i am not sure how often business/ orgs require this. 

If you're working in a real world project/Enterprise, what is your exp. with NER. 

Also if you happen to know a repo or list of public projects lemmino.",https://www.reddit.com/r/LanguageTechnology/comments/nwwsuc/how_often_is_ner_named_entity_recognition_a/,LanguageTechnology,t3_nwwsuc,"How often is NER (named entity recognition) a process in your model building process? I recently started, kaggle notebooks don't suggest it's that important.


 But I recently got access to Prodigy, and it took me an embarassngly long time to install it in Pycharm. But the concept and ease of use is  convenient but i am not sure how often business/ orgs require this. 

If you're working in a real world project/Enterprise, what is your exp. with NER. 

Also if you happen to know a repo or list of public projects lemmino.",525
18,18,How to apply Mutual Information for feature selection in Text Classification where features are words?,"I am writing a text classifier and want to use MI for feature selection but not sure how to compute when the features are words. If I compute scores for features, say using TFIDF, and then apply MI on it, then I get the same top features as with just TFIDF and there is no improvement in results.

Is there any resource I can refer for the same?",https://www.reddit.com/r/LanguageTechnology/comments/nxa329/how_to_apply_mutual_information_for_feature/,LanguageTechnology,t3_nxa329,"How to apply Mutual Information for feature selection in Text Classification where features are words? I am writing a text classifier and want to use MI for feature selection but not sure how to compute when the features are words. If I compute scores for features, say using TFIDF, and then apply MI on it, then I get the same top features as with just TFIDF and there is no improvement in results.

Is there any resource I can refer for the same?",448
19,19,Tutorial on how to replace missing values in a data frame by the column mean (i.e. mean imputation) using R,"Hey, I've created a tutorial on how to replace missing values in a data frame by the column mean (i.e. mean imputation) using the R programming language: [https://statisticsglobe.com/replace-missing-values-by-column-mean-in-r](https://statisticsglobe.com/replace-missing-values-by-column-mean-in-r)",https://www.reddit.com/r/LanguageTechnology/comments/nxb4wm/tutorial_on_how_to_replace_missing_values_in_a/,LanguageTechnology,t3_nxb4wm,"Tutorial on how to replace missing values in a data frame by the column mean (i.e. mean imputation) using R Hey, I've created a tutorial on how to replace missing values in a data frame by the column mean (i.e. mean imputation) using the R programming language: [https://statisticsglobe.com/replace-missing-values-by-column-mean-in-r](https://statisticsglobe.com/replace-missing-values-by-column-mean-in-r)",406
20,20,Clustering word vectors for topic discovery without the actual documents (overlapping &amp; hierarchical),"Hi everyone,

For my project I have a set of word vectors which I have to classify in an unsupervised manner to identify topics, similar concepts, etc. The requirement is to allow each word to belong to multiple topics (overlapping), and allow the topics to include other subtopics (hierarchical).

The problem is that because I don't have documents it's not straightforward to apply topic modeling ideas here.

I know one can look at the problem from pure clustering perspective and use kmeans/GMMs/HDBSCAN/deep learning based clustering, but the problem is that most of such methods assume non-overlapping or non-hierarchical clusters, and there's little research on hierarchical overlapping clustering.

I've been also thinking to leverage community detection methods on graphs, as it's possible to treat each word as a node, however, such methods could be computationally expensive, and I just want to make sure there's no a more natural choice before pursuing this.

Would appreciate any ideas, thank you!",https://www.reddit.com/r/LanguageTechnology/comments/nwk09n/clustering_word_vectors_for_topic_discovery/,LanguageTechnology,t3_nwk09n,"Clustering word vectors for topic discovery without the actual documents (overlapping &amp; hierarchical) Hi everyone,

For my project I have a set of word vectors which I have to classify in an unsupervised manner to identify topics, similar concepts, etc. The requirement is to allow each word to belong to multiple topics (overlapping), and allow the topics to include other subtopics (hierarchical).

The problem is that because I don't have documents it's not straightforward to apply topic modeling ideas here.

I know one can look at the problem from pure clustering perspective and use kmeans/GMMs/HDBSCAN/deep learning based clustering, but the problem is that most of such methods assume non-overlapping or non-hierarchical clusters, and there's little research on hierarchical overlapping clustering.

I've been also thinking to leverage community detection methods on graphs, as it's possible to treat each word as a node, however, such methods could be computationally expensive, and I just want to make sure there's no a more natural choice before pursuing this.

Would appreciate any ideas, thank you!",1116
21,21,Question answering with Wikipedia API,"I'm working on a question answering system based on the Wikipedia API. A problem is that ""wikipedia.search"" yields a couple of articles, the first one not always being the best one. Any ideas how to chose the most appropriate article from the results?",https://www.reddit.com/r/LanguageTechnology/comments/nwk5sp/question_answering_with_wikipedia_api/,LanguageTechnology,t3_nwk5sp,"Question answering with Wikipedia API I'm working on a question answering system based on the Wikipedia API. A problem is that ""wikipedia.search"" yields a couple of articles, the first one not always being the best one. Any ideas how to chose the most appropriate article from the results?",289
22,22,Speech summarization datasets,"Hi everyone,

I'm currently learning about text summarization and I'd really like to fine-tune a transformer model for summarizing speeches (i.e. texts of speeches by political leaders or parliament debates, NOT voice recordings).

Does anyone know about an English dataset containing both the speeches and the respective summaries? It would also be great if someone had an idea as to where one could source such a dataset (e.g. websites from parliaments). I already checked the websites of the US senate, UK government etc., but no luck so far.

Thank you!",https://www.reddit.com/r/LanguageTechnology/comments/nwmezs/speech_summarization_datasets/,LanguageTechnology,t3_nwmezs,"Speech summarization datasets Hi everyone,

I'm currently learning about text summarization and I'd really like to fine-tune a transformer model for summarizing speeches (i.e. texts of speeches by political leaders or parliament debates, NOT voice recordings).

Does anyone know about an English dataset containing both the speeches and the respective summaries? It would also be great if someone had an idea as to where one could source such a dataset (e.g. websites from parliaments). I already checked the websites of the US senate, UK government etc., but no luck so far.

Thank you!",587
23,23,The creators of GPT-Neo just released a 6B parameter open-source version of GPT-3 called GPT-J-6B,,https://www.youtube.com/watch?v=6w5sgWo68E0,LanguageTechnology,t3_nw6yx3,The creators of GPT-Neo just released a 6B parameter open-source version of GPT-3 called GPT-J-6B ,98
24,24,Google AI Introduces ByT5: Pre-Trained Byte-to-Byte Models for NLP Tasks,"Google researcher’s new study suggests modifying the conventional transformer architecture to process byte sequences in natural language processing (NLP). The new competitive byte-level models can effectively balance computational cost trade-offs of contemporary large language models.

Tokenization splits the sentences into a sequence of tokens. Most NLP tasks follow a tokenization procedure to preprocess the data. However, tokenization can struggle with typos, irregularities in spelling and capitalization, morphological changes, and out-of-vocabulary tokenization problems.

Summary: [https://www.marktechpost.com/2021/06/08/google-ai-introduces-byt5-pre-trained-byte-to-byte-models-for-nlp-tasks/](https://www.marktechpost.com/2021/06/08/google-ai-introduces-byt5-pre-trained-byte-to-byte-models-for-nlp-tasks/) 

GitHub: https://github.com/google-research/byt5

Paper: https://arxiv.org/abs/2105.13626",https://www.reddit.com/r/LanguageTechnology/comments/nvot6o/google_ai_introduces_byt5_pretrained_bytetobyte/,LanguageTechnology,t3_nvot6o,"Google AI Introduces ByT5: Pre-Trained Byte-to-Byte Models for NLP Tasks Google researcher’s new study suggests modifying the conventional transformer architecture to process byte sequences in natural language processing (NLP). The new competitive byte-level models can effectively balance computational cost trade-offs of contemporary large language models.

Tokenization splits the sentences into a sequence of tokens. Most NLP tasks follow a tokenization procedure to preprocess the data. However, tokenization can struggle with typos, irregularities in spelling and capitalization, morphological changes, and out-of-vocabulary tokenization problems.

Summary: [https://www.marktechpost.com/2021/06/08/google-ai-introduces-byt5-pre-trained-byte-to-byte-models-for-nlp-tasks/](https://www.marktechpost.com/2021/06/08/google-ai-introduces-byt5-pre-trained-byte-to-byte-models-for-nlp-tasks/) 

GitHub: https://github.com/google-research/byt5

Paper: https://arxiv.org/abs/2105.13626",983
25,25,Language Model for Summarization,"Hi all,

What is the best word embedding to use for automatic text summarization? I want to make extractive summaries of documents.",https://www.reddit.com/r/LanguageTechnology/comments/nvxizn/language_model_for_summarization/,LanguageTechnology,t3_nvxizn,"Language Model for Summarization Hi all,

What is the best word embedding to use for automatic text summarization? I want to make extractive summaries of documents.",164
26,26,Unsupervised Relation Extraction using BERT attention scores,"Hey, 

Given that I have a Named Entity extractor trained over a BERT pre-trained model, is it possible to utilize the already computed attention scores for extracting Relations between these entities?  

Obviously, categorizing the active relations is still a challenge, but is it possible to detect if a relation is active only by using the attention scores? Specifically if the BERT model is only trained for NER.",https://www.reddit.com/r/LanguageTechnology/comments/nvvvzs/unsupervised_relation_extraction_using_bert/,LanguageTechnology,t3_nvvvzs,"Unsupervised Relation Extraction using BERT attention scores Hey, 

Given that I have a Named Entity extractor trained over a BERT pre-trained model, is it possible to utilize the already computed attention scores for extracting Relations between these entities?  

Obviously, categorizing the active relations is still a challenge, but is it possible to detect if a relation is active only by using the attention scores? Specifically if the BERT model is only trained for NER.",477
27,27,Relationship extraction,"I would like to extract relationships in plain text between two named entities.  

I first wanted to try with Machine Learning but it's complicated to find an annotated corpus for training ... Then I wanted to create patterns (for example: PERSON live LOCATION) but it is not not very precise because I'm trying to find relationships between each pair of named entities (and honestly it takes a long time to write a good dictionary).

Do you have any suggestions for doing this more efficiently please? Maybe a corpus that exists, an algorithm next to which I pass ? 

Thaaaanks :)",https://www.reddit.com/r/LanguageTechnology/comments/nvuwiw/relationship_extraction/,LanguageTechnology,t3_nvuwiw,"Relationship extraction I would like to extract relationships in plain text between two named entities.  

I first wanted to try with Machine Learning but it's complicated to find an annotated corpus for training ... Then I wanted to create patterns (for example: PERSON live LOCATION) but it is not not very precise because I'm trying to find relationships between each pair of named entities (and honestly it takes a long time to write a good dictionary).

Do you have any suggestions for doing this more efficiently please? Maybe a corpus that exists, an algorithm next to which I pass ? 

Thaaaanks :)",605
28,28,How to build a model for german paraphrase generation?,"I need to generate german paraphrases and I was already looking at some huggingface models which work really well for english sentences. For example tuner007/pegasus\_paraphrase or Vamsi/T5\_Paraphrase\_Paws.

    tokenizer = PegasusTokenizer.from_pretrained(model_name)
    model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device) 

I can't find any german models for paraphrasing on Huggingface. How do I build a model on my own? Is this the best way to generate german paraphrases with transformers or should I use other methods? Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/nvr3zl/how_to_build_a_model_for_german_paraphrase/,LanguageTechnology,t3_nvr3zl,"How to build a model for german paraphrase generation? I need to generate german paraphrases and I was already looking at some huggingface models which work really well for english sentences. For example tuner007/pegasus\_paraphrase or Vamsi/T5\_Paraphrase\_Paws.

    tokenizer = PegasusTokenizer.from_pretrained(model_name)
    model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device) 

I can't find any german models for paraphrasing on Huggingface. How do I build a model on my own? Is this the best way to generate german paraphrases with transformers or should I use other methods? Thanks!",623
29,29,[d] Inspecting Neural Networks with Canonical Correlation Analysis (CKA/SVCCA Video),,/r/MachineLearning/comments/nvr0v0/d_inspecting_neural_networks_with_canonical/,LanguageTechnology,t3_nvr1cf,[d] Inspecting Neural Networks with Canonical Correlation Analysis (CKA/SVCCA Video) ,85
30,30,"I am experimenting with using NLP to measure market sentiment with custom classifiers for neutrality, FUD, hype etc. stuff typical for crypto world. I trained my classifiers in natural.js with data I pulled from social media. This is my attempt number one",,https://comint.ai/coins/btc,LanguageTechnology,t3_nvycft,"I am experimenting with using NLP to measure market sentiment with custom classifiers for neutrality, FUD, hype etc. stuff typical for crypto world. I trained my classifiers in natural.js with data I pulled from social media. This is my attempt number one ",256
31,31,Is there a text list of words and their variations?,"For example:

exist exists existed existing 

run ran running 

And so forth?",https://www.reddit.com/r/LanguageTechnology/comments/nv89vk/is_there_a_text_list_of_words_and_their_variations/,LanguageTechnology,t3_nv89vk,"Is there a text list of words and their variations? For example:

exist exists existed existing 

run ran running 

And so forth?",129
32,32,Job opportunity: Assistant Professor in Speech Technology at the University of Groningen (the Netherlands),"Very interesting job to teach at a new [MSc. in Voice technology](https://www.rug.nl/masters/voice-technology/)!

Key points:

* English language program
* 80-100% full-time position (depending on how many classes you want to teach)
* Balance between teaching and research is 60/40 (really!)

In addition to supervising theses within your area of expertise, you will support the teaching and/or curriculum development of courses in speech synthesis, speech recognition, Python, and machine learning for voice tech (all courses already have detailed week-by-week descriptions but lack student-ready syllabi, giving you some creative freedom -- more information about the courses, including learning outcomes, is available upon request):

● Speech Synthesis I and II  
● Speech Recognition I and II  
● Python for Voice Technology (and Intro to Python at the undergraduate level)  
● Machine Learning for Voice Technology

[More details](https://www.rug.nl/about-ug/work-with-us/job-opportunities/?details=00347-02S0008E4P)  (qualifications, application procedure, etc.)

Deadline: 13 June 11:59pm (CEST - European time)",https://www.reddit.com/r/LanguageTechnology/comments/nuzw46/job_opportunity_assistant_professor_in_speech/,LanguageTechnology,t3_nuzw46,"Job opportunity: Assistant Professor in Speech Technology at the University of Groningen (the Netherlands) Very interesting job to teach at a new [MSc. in Voice technology](https://www.rug.nl/masters/voice-technology/)!

Key points:

* English language program
* 80-100% full-time position (depending on how many classes you want to teach)
* Balance between teaching and research is 60/40 (really!)

In addition to supervising theses within your area of expertise, you will support the teaching and/or curriculum development of courses in speech synthesis, speech recognition, Python, and machine learning for voice tech (all courses already have detailed week-by-week descriptions but lack student-ready syllabi, giving you some creative freedom -- more information about the courses, including learning outcomes, is available upon request):

● Speech Synthesis I and II  
● Speech Recognition I and II  
● Python for Voice Technology (and Intro to Python at the undergraduate level)  
● Machine Learning for Voice Technology

[More details](https://www.rug.nl/about-ug/work-with-us/job-opportunities/?details=00347-02S0008E4P)  (qualifications, application procedure, etc.)

Deadline: 13 June 11:59pm (CEST - European time)",1225
33,33,GAN-BioBERT: A Methodology For Assessing Reporting Trends In Clinical Trials (Paper Summary),"I saw this paper and thought it was an interesting application of sentiment analysis. 

[https://arxiv.org/abs/2106.00665](https://arxiv.org/abs/2106.00665)

The paper proposes using GAN-BERT with BioBERT for 3 class sentiment classification in clinical trial abstracts as a way to assess reporting trends in literature. 

They also found that the accuracy of the algorithm was far better than using an expert rater (which is the standard right now in clinical literature for these types of studies).

I'm curious what the r/LanguageTechnology world thinks; This seems like a really cool application but I'm a total novice when it comes to NLP (coming from a signal processing background)",https://www.reddit.com/r/LanguageTechnology/comments/nv5yb8/ganbiobert_a_methodology_for_assessing_reporting/,LanguageTechnology,t3_nv5yb8,"GAN-BioBERT: A Methodology For Assessing Reporting Trends In Clinical Trials (Paper Summary) I saw this paper and thought it was an interesting application of sentiment analysis. 

[https://arxiv.org/abs/2106.00665](https://arxiv.org/abs/2106.00665)

The paper proposes using GAN-BERT with BioBERT for 3 class sentiment classification in clinical trial abstracts as a way to assess reporting trends in literature. 

They also found that the accuracy of the algorithm was far better than using an expert rater (which is the standard right now in clinical literature for these types of studies).

I'm curious what the r/LanguageTechnology world thinks; This seems like a really cool application but I'm a total novice when it comes to NLP (coming from a signal processing background)",781
34,34,"Need direction related a project, like what topics(study material) should I look into.",I want to do a contextual analysis on two topics and learn the in what  context some common keywords has been used in both of the topics. Thank  you.,https://www.reddit.com/r/LanguageTechnology/comments/nvaccr/need_direction_related_a_project_like_what/,LanguageTechnology,t3_nvaccr,"Need direction related a project, like what topics(study material) should I look into. I want to do a contextual analysis on two topics and learn the in what  context some common keywords has been used in both of the topics. Thank  you.",236
35,35,Benefits of Using PHP for Web Development,,https://coresumo.com/benefits-of-using-php-for-web-development-2021/,LanguageTechnology,t3_nvqkl1,Benefits of Using PHP for Web Development ,42
36,36,Advice - Choosing a Master's in NLP (France),"Hello,
I am planning on studying NLP in the fall and have been accepted to two programs that really interest me.
They are the University of Strasbourg's Master in Language Technology and the PluriTAL program in Paris that is organized by Paris 3, Paris Nanterre, and Inalco.
I was wondering if anyone here has studied in one of these programs or knows anyone that has and would have any pros and cons between them.

Thank you for your help!",https://www.reddit.com/r/LanguageTechnology/comments/nuylqi/advice_choosing_a_masters_in_nlp_france/,LanguageTechnology,t3_nuylqi,"Advice - Choosing a Master's in NLP (France) Hello,
I am planning on studying NLP in the fall and have been accepted to two programs that really interest me.
They are the University of Strasbourg's Master in Language Technology and the PluriTAL program in Paris that is organized by Paris 3, Paris Nanterre, and Inalco.
I was wondering if anyone here has studied in one of these programs or knows anyone that has and would have any pros and cons between them.

Thank you for your help!",485
37,37,Clustering latent representation vectors with a size less than the number of clusters," 

I'm doing topic modeling for the first time in my life and I have a problem. My intention is to model daily topics, but my number of daily samples varies a lot, from 5 samples in one day to 100 in another, for example. The desired number of topics is 7, so I have problems from the first day of the dataset.

The methodology I'm following is [this](https://blog.insightdatascience.com/contextual-topic-identification-4291d256a032).

Then the vector resulting from the LDA+BERT concatenation is passed in an Autoencoder and then used in a clustering model. This is where I have the problem at hand. My number of clusters is 7, but the representation vectors are 5.

With this I have the error:

ValueError: n\_samples=5 should be &gt;= n\_clusters=7.

Does anyone know how I could fix this?",https://www.reddit.com/r/LanguageTechnology/comments/nv1y5k/clustering_latent_representation_vectors_with_a/,LanguageTechnology,t3_nv1y5k,"Clustering latent representation vectors with a size less than the number of clusters  

I'm doing topic modeling for the first time in my life and I have a problem. My intention is to model daily topics, but my number of daily samples varies a lot, from 5 samples in one day to 100 in another, for example. The desired number of topics is 7, so I have problems from the first day of the dataset.

The methodology I'm following is [this](https://blog.insightdatascience.com/contextual-topic-identification-4291d256a032).

Then the vector resulting from the LDA+BERT concatenation is passed in an Autoencoder and then used in a clustering model. This is where I have the problem at hand. My number of clusters is 7, but the representation vectors are 5.

With this I have the error:

ValueError: n\_samples=5 should be &gt;= n\_clusters=7.

Does anyone know how I could fix this?",878
38,38,FREE WEBINAR - Automating Data Annotation with MicroModels - Automating processes within the workflow to improve efficiency &amp; guarantee high quality,,https://www.re-work.co/events/webinar:automating-data-annotation-with-micromodels?utm_source=Promo&amp;utm_medium=Promo&amp;utm_campaign=LK_Promo_Sama_Webinar,LanguageTechnology,t3_nv0z0r,FREE WEBINAR - Automating Data Annotation with MicroModels - Automating processes within the workflow to improve efficiency &amp; guarantee high quality ,153
39,39,How to identify sentences from a stream of characters?,"Hi all. I have a little problem I am facing and I'm not quite sure where I should start looking. I have an application where I want to identify sentences inline as the user types. The goal is to operate on the sentences and provide feedback to the user without them needing to indicate the sentence as completed.

Does anyone have any ideas on how to effectively identify complete sentences as they are being typed? The quick solutions I've thought of seem a little too simple and error prone. 

Please let me know.",https://www.reddit.com/r/LanguageTechnology/comments/nuvgii/how_to_identify_sentences_from_a_stream_of/,LanguageTechnology,t3_nuvgii,"How to identify sentences from a stream of characters? Hi all. I have a little problem I am facing and I'm not quite sure where I should start looking. I have an application where I want to identify sentences inline as the user types. The goal is to operate on the sentences and provide feedback to the user without them needing to indicate the sentence as completed.

Does anyone have any ideas on how to effectively identify complete sentences as they are being typed? The quick solutions I've thought of seem a little too simple and error prone. 

Please let me know.",570
40,40,"John Snow Labs Spark-NLP 3.1.0: Over 2600+ new models and pipelines in 200+ languages, new DistilBERT, RoBERTa, and XLM-RoBERTa transformers, support for external Transformers, and lots more!",,https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.1.0,LanguageTechnology,t3_nufyy8,"John Snow Labs Spark-NLP 3.1.0: Over 2600+ new models and pipelines in 200+ languages, new DistilBERT, RoBERTa, and XLM-RoBERTa transformers, support for external Transformers, and lots more! ",192
41,41,"What's the algorithm pipeline for Google's ""People Also Ask""?","I tried to find some well-summarized answers, but there really isn't any.

I can only guess some combination of:

* Query Expansion
* Query Embedding and Finding Semantically Similar Queries
* Query-Answer scores(from the field data) for raking PAA suggestions
* Text Summarization(for the snippet of answers)
* Natural Language Generation(for the ""general"" form of questions)

Anyone can give a bit more detailed version of what is actually going on behind?

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/nuo2xl/whats_the_algorithm_pipeline_for_googles_people/,LanguageTechnology,t3_nuo2xl,"What's the algorithm pipeline for Google's ""People Also Ask""? I tried to find some well-summarized answers, but there really isn't any.

I can only guess some combination of:

* Query Expansion
* Query Embedding and Finding Semantically Similar Queries
* Query-Answer scores(from the field data) for raking PAA suggestions
* Text Summarization(for the snippet of answers)
* Natural Language Generation(for the ""general"" form of questions)

Anyone can give a bit more detailed version of what is actually going on behind?

Thanks!",529
42,42,"google-research/mozolm - A language model serving library, with middleware functionality including mixing of probabilities from disparate base language model types and tokenizations along with RPC client/server interactions.",,https://github.com/google-research/mozolm,LanguageTechnology,t3_nunqg8,"google-research/mozolm - A language model serving library, with middleware functionality including mixing of probabilities from disparate base language model types and tokenizations along with RPC client/server interactions. ",225
43,43,"Building a corpus of AAC users speech/writing: ""Know of any AAC users who want a faster system? This research study aims to build a large open database for researchers and developers to make far better systems. End users can now help this effort directly""",,https://spark.adobe.com/video/F8MNMohwepvrG,LanguageTechnology,t3_nunmmp,"Building a corpus of AAC users speech/writing: ""Know of any AAC users who want a faster system? This research study aims to build a large open database for researchers and developers to make far better systems. End users can now help this effort directly"" ",256
44,44,Preventing ‘Hallucination’ In GPT-3 And Other Complex Language Models,,https://www.unite.ai/preventing-hallucination-in-gpt-3-and-other-complex-language-models/,LanguageTechnology,t3_nu8qyy,Preventing ‘Hallucination’ In GPT-3 And Other Complex Language Models ,70
45,45,ByT5: Towards a token-free future with pre-trained byte-to-byte models (Research Paper Summary),"Most of the pre-trained language models operate on sequences of tokens corresponding to word or subword units. 

This paper proposes Token-free models that instead operate directly on raw bytes. 

https://link.medium.com/qKwrXYXqTgb

P.S. Most of this blog was written from my mobile device. Please excuse brevity and typos.


Actual Paper: https://arxiv.org/pdf/2105.13626v1.pdf",https://www.reddit.com/r/LanguageTechnology/comments/nu9ty9/byt5_towards_a_tokenfree_future_with_pretrained/,LanguageTechnology,t3_nu9ty9,"ByT5: Towards a token-free future with pre-trained byte-to-byte models (Research Paper Summary) Most of the pre-trained language models operate on sequences of tokens corresponding to word or subword units. 

This paper proposes Token-free models that instead operate directly on raw bytes. 

https://link.medium.com/qKwrXYXqTgb

P.S. Most of this blog was written from my mobile device. Please excuse brevity and typos.


Actual Paper: https://arxiv.org/pdf/2105.13626v1.pdf",475
46,46,Hugging Face: Unable to use emojis for masked language modelling?,"I am new to Hugging Face and masked language modelling (MLM), and I was wondering how to include emojis when doing such a task.

I have a dataset with tweets, with each tweet containing an emoji at the end - here is a sample of my data:

| ID |        Tweet |
| -------- | -------------- |
| 1    | Looking good today 😎         |
| 2   | Weather is so hot, lol ☀️          |
| 3  | I hate you!!! 🤬        |

At the moment, I have fully trained my masked language model using my dataset, but when I predict something, it does **NOT** output or predict the emojis. It just predicts words.

This is my desired input from using my dataset for MLM:

```
""You look great [MASK]""
```

This is my desired output from using my dataset for MLM:

```
[{'score': 0.26041436195373535,
  'sequence': 'You look great 😎""',
  'token': 72,
  'token_str': '.""'},
 {'score': 0.1813151091337204,
  'sequence': 'you look great 💯""',
  'token': 2901,
  'token_str': '!""'},
 {'score': 0.14516998827457428,
  'sequence': 'you look great 👌',
  'token': 328,
  'token_str': '!'},]
```

However, this is what I am actually getting from my output:

```
[{'score': 0.26041436195373535,
  'sequence': 'You look great?""',
  'token': 72,
  'token_str': '.""'},
 {'score': 0.1813151091337204,
  'sequence': 'You look great.""',
  'token': 2901,
  'token_str': '!""'},
 {'score': 0.14516998827457428,
  'sequence': 'You look great!',
  'token': 328,
  'token_str': '!'},]
```

I know it is possible to do this, but how do I do it? I am close, but not very.

Likewise, I have my model fully trained on my dataset, but it just does not seem to output emojis, even though I have included them in the training. 

Does something need to be included to accept emoji? If so, what?

Thanks - I would really appreciate the help!",https://www.reddit.com/r/LanguageTechnology/comments/nu90dm/hugging_face_unable_to_use_emojis_for_masked/,LanguageTechnology,t3_nu90dm,"Hugging Face: Unable to use emojis for masked language modelling? I am new to Hugging Face and masked language modelling (MLM), and I was wondering how to include emojis when doing such a task.

I have a dataset with tweets, with each tweet containing an emoji at the end - here is a sample of my data:

| ID |        Tweet |
| -------- | -------------- |
| 1    | Looking good today 😎         |
| 2   | Weather is so hot, lol ☀️          |
| 3  | I hate you!!! 🤬        |

At the moment, I have fully trained my masked language model using my dataset, but when I predict something, it does **NOT** output or predict the emojis. It just predicts words.

This is my desired input from using my dataset for MLM:

```
""You look great [MASK]""
```

This is my desired output from using my dataset for MLM:

```
[{'score': 0.26041436195373535,
  'sequence': 'You look great 😎""',
  'token': 72,
  'token_str': '.""'},
 {'score': 0.1813151091337204,
  'sequence': 'you look great 💯""',
  'token': 2901,
  'token_str': '!""'},
 {'score': 0.14516998827457428,
  'sequence': 'you look great 👌',
  'token': 328,
  'token_str': '!'},]
```

However, this is what I am actually getting from my output:

```
[{'score': 0.26041436195373535,
  'sequence': 'You look great?""',
  'token': 72,
  'token_str': '.""'},
 {'score': 0.1813151091337204,
  'sequence': 'You look great.""',
  'token': 2901,
  'token_str': '!""'},
 {'score': 0.14516998827457428,
  'sequence': 'You look great!',
  'token': 328,
  'token_str': '!'},]
```

I know it is possible to do this, but how do I do it? I am close, but not very.

Likewise, I have my model fully trained on my dataset, but it just does not seem to output emojis, even though I have included them in the training. 

Does something need to be included to accept emoji? If so, what?

Thanks - I would really appreciate the help!",1846
47,47,Master's degree in Computational Linguistics (Stuttgart),"Hello everyone!

I'm an Italian uni student, and I'm going to graduate in foreign languages and literature in October (English and German).

I'm interested in studying CL after my Bachelor (Stuttgart seems to be a good choice, and spending some time in a German-speaking country would enable me to improve my German), but I don't know whether I stand any chance of getting accepted into this programme.

I took a couple of linguistics exams, but since in Italy Bachelors of linguistics don't exist at all, all I could do was enrol in the languages programme. Stuttgart university accepts Bachelors related to linguistics, but I'm still afraid that my degree won't be enough to satisfy their admission requirements.

I know the basics of programming (Python), but I actually don't know what I could do so as to stand a better chance of getting accepted. 

Is there anything else I could do?",https://www.reddit.com/r/LanguageTechnology/comments/ntw7yu/masters_degree_in_computational_linguistics/,LanguageTechnology,t3_ntw7yu,"Master's degree in Computational Linguistics (Stuttgart) Hello everyone!

I'm an Italian uni student, and I'm going to graduate in foreign languages and literature in October (English and German).

I'm interested in studying CL after my Bachelor (Stuttgart seems to be a good choice, and spending some time in a German-speaking country would enable me to improve my German), but I don't know whether I stand any chance of getting accepted into this programme.

I took a couple of linguistics exams, but since in Italy Bachelors of linguistics don't exist at all, all I could do was enrol in the languages programme. Stuttgart university accepts Bachelors related to linguistics, but I'm still afraid that my degree won't be enough to satisfy their admission requirements.

I know the basics of programming (Python), but I actually don't know what I could do so as to stand a better chance of getting accepted. 

Is there anything else I could do?",946
48,48,More than 10K of you downloaded the free NLP transformers course... Wow!,"Three days ago I made a video explaining how my NLP transformers course would be entirely free as part of a limited-time promo. I shared that video here and in a couple of other subreddits too, r/learnmachinglearning and r/Python being two.

Three days and 10823 downloads later, here we are! I thought we'd be lucky to hit 1K!

Incredible response, and very happy to be able to have been able to give so many of you an opportunity to access the course where some of you may not have been able to otherwise. I'm looking forward to working with all the students and helping you guys out, just please don't all ask me questions at once! 😬

Thanks all, truly humbled by the response - it's really *really* cool, it has blown my mind.

For any of you that are still interested, I will leave a final discount link [here](https://www.udemy.com/course/nlp-with-transformers/?couponCode=MEDIUM), thanks all!",https://www.reddit.com/r/LanguageTechnology/comments/nti8vm/more_than_10k_of_you_downloaded_the_free_nlp/,LanguageTechnology,t3_nti8vm,"More than 10K of you downloaded the free NLP transformers course... Wow! Three days ago I made a video explaining how my NLP transformers course would be entirely free as part of a limited-time promo. I shared that video here and in a couple of other subreddits too, r/learnmachinglearning and r/Python being two.

Three days and 10823 downloads later, here we are! I thought we'd be lucky to hit 1K!

Incredible response, and very happy to be able to have been able to give so many of you an opportunity to access the course where some of you may not have been able to otherwise. I'm looking forward to working with all the students and helping you guys out, just please don't all ask me questions at once! 😬

Thanks all, truly humbled by the response - it's really *really* cool, it has blown my mind.

For any of you that are still interested, I will leave a final discount link [here](https://www.udemy.com/course/nlp-with-transformers/?couponCode=MEDIUM), thanks all!",972
49,49,Debiasing large pretrained language models using distributional control,,https://europe.naverlabs.com/blog/debiasing-large-pretrained-language-models-using-distributional-control/,LanguageTechnology,t3_ntqm8h,Debiasing large pretrained language models using distributional control ,72
50,50,Does anyone know of coreference resolution tools where you can specify the entity?,,/r/MachineLearning/comments/nta7gu/d_does_anyone_know_of_coreference_resolution/,LanguageTechnology,t3_ntb3m6,Does anyone know of coreference resolution tools where you can specify the entity? ,83
51,51,ConvoKit corpus research,"Hello! I am a PhD researcher. I am looking urgently for someone having used ConvoKit and knowing how to extract coded variables through it. Please reply here or email me at:

[ax23@kent.ac.uk](mailto:ax23@kent.ac.uk)",https://www.reddit.com/r/LanguageTechnology/comments/ntia70/convokit_corpus_research/,LanguageTechnology,t3_ntia70,"ConvoKit corpus research Hello! I am a PhD researcher. I am looking urgently for someone having used ConvoKit and knowing how to extract coded variables through it. Please reply here or email me at:

[ax23@kent.ac.uk](mailto:ax23@kent.ac.uk)",241
52,52,Hugging Face: How to test masked language model after training it?,"I have followed this tutorial for masked language modelling from Hugging Face using BERT, but I am unsure how to actually deploy the model.

Tutorial: [https://github.com/huggingface/notebooks/blob/master/examples/language\_modeling.ipynb](https://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb)

I have trained the model using my own dataset, which has worked fine, but I don't know how to actually use the model, as the notebook does not include an example on how to do this, sadly.

&amp;#x200B;

On the Hugging Face website, this is the code used in the example; hence, I want to do this exact thing but with my model:

    &gt;&gt;&gt; from transformers import pipeline
    &gt;&gt;&gt; unmasker = pipeline('fill-mask', model='bert-base-uncased')
    &gt;&gt;&gt; unmasker(""Hello I'm a [MASK] model."")
    
    [{'sequence': ""[CLS] hello i'm a fashion model. [SEP]"",
      'score': 0.1073106899857521,
      'token': 4827,
      'token_str': 'fashion'},
     {'sequence': ""[CLS] hello i'm a role model. [SEP]"",
      'score': 0.08774490654468536,
      'token': 2535,
      'token_str': 'role'},
     {'sequence': ""[CLS] hello i'm a new model. [SEP]"",
      'score': 0.05338378623127937,
      'token': 2047,
      'token_str': 'new'},
     {'sequence': ""[CLS] hello i'm a super model. [SEP]"",
      'score': 0.04667217284440994,
      'token': 3565,
      'token_str': 'super'},
     {'sequence': ""[CLS] hello i'm a fine model. [SEP]"",
      'score': 0.027095865458250046,
      'token': 2986,
      'token_str': 'fine'}

Any help on how to do this would be great.",https://www.reddit.com/r/LanguageTechnology/comments/nt04tj/hugging_face_how_to_test_masked_language_model/,LanguageTechnology,t3_nt04tj,"Hugging Face: How to test masked language model after training it? I have followed this tutorial for masked language modelling from Hugging Face using BERT, but I am unsure how to actually deploy the model.

Tutorial: [https://github.com/huggingface/notebooks/blob/master/examples/language\_modeling.ipynb](https://github.com/huggingface/notebooks/blob/master/examples/language_modeling.ipynb)

I have trained the model using my own dataset, which has worked fine, but I don't know how to actually use the model, as the notebook does not include an example on how to do this, sadly.

&amp;#x200B;

On the Hugging Face website, this is the code used in the example; hence, I want to do this exact thing but with my model:

    &gt;&gt;&gt; from transformers import pipeline
    &gt;&gt;&gt; unmasker = pipeline('fill-mask', model='bert-base-uncased')
    &gt;&gt;&gt; unmasker(""Hello I'm a [MASK] model."")
    
    [{'sequence': ""[CLS] hello i'm a fashion model. [SEP]"",
      'score': 0.1073106899857521,
      'token': 4827,
      'token_str': 'fashion'},
     {'sequence': ""[CLS] hello i'm a role model. [SEP]"",
      'score': 0.08774490654468536,
      'token': 2535,
      'token_str': 'role'},
     {'sequence': ""[CLS] hello i'm a new model. [SEP]"",
      'score': 0.05338378623127937,
      'token': 2047,
      'token_str': 'new'},
     {'sequence': ""[CLS] hello i'm a super model. [SEP]"",
      'score': 0.04667217284440994,
      'token': 3565,
      'token_str': 'super'},
     {'sequence': ""[CLS] hello i'm a fine model. [SEP]"",
      'score': 0.027095865458250046,
      'token': 2986,
      'token_str': 'fine'}

Any help on how to do this would be great.",1668
53,53,How to use BERT multilingual embedding,"I have a task where i want to use multilingual embeddings for 2 different languages(one of them being english). 
I first checked fasttext but its aligned vectors does have one pf my language. So i check a basic vector aligning algo and it was using common words between two languages to align them. But one of my language does not have english characters so cant use that algo.

Then i read about BERT embeddings and found multilingual model on their git repo. But i dont know how to get word embeddings using using that model.
So, does anybody know how to use the embeddings from bert multilingual model.",https://www.reddit.com/r/LanguageTechnology/comments/nt6wsx/how_to_use_bert_multilingual_embedding/,LanguageTechnology,t3_nt6wsx,"How to use BERT multilingual embedding I have a task where i want to use multilingual embeddings for 2 different languages(one of them being english). 
I first checked fasttext but its aligned vectors does have one pf my language. So i check a basic vector aligning algo and it was using common words between two languages to align them. But one of my language does not have english characters so cant use that algo.

Then i read about BERT embeddings and found multilingual model on their git repo. But i dont know how to get word embeddings using using that model.
So, does anybody know how to use the embeddings from bert multilingual model.",644
54,54,"How do I find similar words to certain words (NLP, other techniques)?","Hi, I'd like to write a program that does the following: you put in a word (or words) and as an output you get a similar word (words) to it. So if I give the words 'investment banker' as an input, it should give back the words 'investment analyst' or 'private equity manager'.

The language wouldn't be English, but French, German and Dutch. Which frameworks, libraries and techniques should I look at to implement this and how do I make it work as accurate as possible? Does anyone have any experience with this that you'd like or good guides on it? Is it hard to implement this program? Thanks in advance.",https://www.reddit.com/r/LanguageTechnology/comments/nt3kgx/how_do_i_find_similar_words_to_certain_words_nlp/,LanguageTechnology,t3_nt3kgx,"How do I find similar words to certain words (NLP, other techniques)? Hi, I'd like to write a program that does the following: you put in a word (or words) and as an output you get a similar word (words) to it. So if I give the words 'investment banker' as an input, it should give back the words 'investment analyst' or 'private equity manager'.

The language wouldn't be English, but French, German and Dutch. Which frameworks, libraries and techniques should I look at to implement this and how do I make it work as accurate as possible? Does anyone have any experience with this that you'd like or good guides on it? Is it hard to implement this program? Thanks in advance.",677
55,55,Incorrect tags when parsing test case,"I’m interested in parsing manual test cases into classified/formatted data so I can extract the intent of the tester and then generate automated test cases (e.g. Selenium). I’ve been playing around with Python’s spaCy library and noticed that when I process the following string, I get incorrect tags:

“User enters Password and press tab key”

“press” is incorrectly tagged as a noun when it should really be a verb. I realize that the word should have been “pressED” and may be the reason why tags are coming out wrong, but is there anything that can be done to work around typo issues like these?",https://www.reddit.com/r/LanguageTechnology/comments/nt6aqr/incorrect_tags_when_parsing_test_case/,LanguageTechnology,t3_nt6aqr,"Incorrect tags when parsing test case I’m interested in parsing manual test cases into classified/formatted data so I can extract the intent of the tester and then generate automated test cases (e.g. Selenium). I’ve been playing around with Python’s spaCy library and noticed that when I process the following string, I get incorrect tags:

“User enters Password and press tab key”

“press” is incorrectly tagged as a noun when it should really be a verb. I realize that the word should have been “pressED” and may be the reason why tags are coming out wrong, but is there anything that can be done to work around typo issues like these?",637
56,56,How to implement ALBERT for sarcasm detection,Hi everyone I search for good resource to implement ALBERT for sarcasm detection on Reddit dataset...can u help me?,https://www.reddit.com/r/LanguageTechnology/comments/nsr07m/how_to_implement_albert_for_sarcasm_detection/,LanguageTechnology,t3_nsr07m,How to implement ALBERT for sarcasm detection Hi everyone I search for good resource to implement ALBERT for sarcasm detection on Reddit dataset...can u help me?,161
57,57,Building Grammar Correction API in Python with Gramformer and FastApI,,https://youtu.be/yH36NQGp4NQ,LanguageTechnology,t3_nsdki0,Building Grammar Correction API in Python with Gramformer and FastApI ,70
58,58,Does a truly comprehensive rule-based grammar for the English language exist? Or is there any (recent) study that discusses their limitations?,"Hey,

I'm working with rule-based language models and I'm wondering if there is anything that could be called a ""comprehensive set of rules""  for the English grammar. My gut feeling tells me that it is close to impossible to catch all possible grammatical variations of the English language, but I'd love to be proven wrong!

I'm know of Lambeks Pregroup grammar and Montague grammar but I'm not sure if any of those formalism captures the English language without major flaws.

I appreciate any references!",https://www.reddit.com/r/LanguageTechnology/comments/ns27v5/does_a_truly_comprehensive_rulebased_grammar_for/,LanguageTechnology,t3_ns27v5,"Does a truly comprehensive rule-based grammar for the English language exist? Or is there any (recent) study that discusses their limitations? Hey,

I'm working with rule-based language models and I'm wondering if there is anything that could be called a ""comprehensive set of rules""  for the English grammar. My gut feeling tells me that it is close to impossible to catch all possible grammatical variations of the English language, but I'd love to be proven wrong!

I'm know of Lambeks Pregroup grammar and Montague grammar but I'm not sure if any of those formalism captures the English language without major flaws.

I appreciate any references!",650
59,59,Trouble with gImageReader (Tesseract) - Exporting to PDF (Linux Mint),"I've been using gImageReader for a few years and I've always used it to export the OCR'ed text as an invisible text layer over the existing pdf scan, resulting in a searchable pdf file, which is useful for research, working with the text etc.

I was doing this on Windows 10, and recently installed a dual boot with Linux Mint and reinstalled Windows due to slow-down. Now I reinstalled gImageReader and I can no longer find the option to export to PDF with text layer. In fact I'm having trouble even finding much mention of said function online. I don't know if I originally installed some fork or beta or what, but the way the (probably) official version of the program looks is not what I'd been using so far.

I was always able to set certain post-production parameters, such as size of the invisible text etc.

Any ideas where I could find that version again? I'd prefer a Linux Mint compatible version, but Windows would also be fine, if that's the only one.  
Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/nsd4bj/trouble_with_gimagereader_tesseract_exporting_to/,LanguageTechnology,t3_nsd4bj,"Trouble with gImageReader (Tesseract) - Exporting to PDF (Linux Mint) I've been using gImageReader for a few years and I've always used it to export the OCR'ed text as an invisible text layer over the existing pdf scan, resulting in a searchable pdf file, which is useful for research, working with the text etc.

I was doing this on Windows 10, and recently installed a dual boot with Linux Mint and reinstalled Windows due to slow-down. Now I reinstalled gImageReader and I can no longer find the option to export to PDF with text layer. In fact I'm having trouble even finding much mention of said function online. I don't know if I originally installed some fork or beta or what, but the way the (probably) official version of the program looks is not what I'd been using so far.

I was always able to set certain post-production parameters, such as size of the invisible text etc.

Any ideas where I could find that version again? I'd prefer a Linux Mint compatible version, but Windows would also be fine, if that's the only one.  
Thanks!",1045
60,60,Best weekly digest to keep up with NLP research?,I would like to subscribe to some weekly news about NLP in order to be up-to-date with latest research in NLP. Could somebody please recommend me one?,https://www.reddit.com/r/LanguageTechnology/comments/ns2x5i/best_weekly_digest_to_keep_up_with_nlp_research/,LanguageTechnology,t3_ns2x5i,Best weekly digest to keep up with NLP research? I would like to subscribe to some weekly news about NLP in order to be up-to-date with latest research in NLP. Could somebody please recommend me one?,199
61,61,Advice for fake news classifier research paper,I am playing to write a paper in the NLP field on fake news classifier. Any suggestions about what I could try out and write on? ,https://www.reddit.com/r/LanguageTechnology/comments/nscnd2/advice_for_fake_news_classifier_research_paper/,LanguageTechnology,t3_nscnd2,Advice for fake news classifier research paper I am playing to write a paper in the NLP field on fake news classifier. Any suggestions about what I could try out and write on? ,176
62,62,Can you guys help me understand how word embeddings is not a symbolic representation of language?,I understand that models like GPT 3 are auto regressive models which uses word statistics but what I am struggling to understand is why the discernable semantic information that you can get from a word2vec model is not symbolic representation in at least in some way?,https://www.reddit.com/r/LanguageTechnology/comments/ns23bt/can_you_guys_help_me_understand_how_word/,LanguageTechnology,t3_ns23bt,Can you guys help me understand how word embeddings is not a symbolic representation of language? I understand that models like GPT 3 are auto regressive models which uses word statistics but what I am struggling to understand is why the discernable semantic information that you can get from a word2vec model is not symbolic representation in at least in some way?,365
63,63,Training T5 model in just 3 lines of code with ONNX Inference,,https://link.medium.com/KYA6WERvOgb,LanguageTechnology,t3_ns3hip,Training T5 model in just 3 lines of code with ONNX Inference ,62
64,64,Answer matching using sentence similarity,"Hi, I am relatively new to NLP. I am trying to write a code that allows me to grade elementary student's  Science questions. For keyword-based answers, I am able to easily match student's answer to the model answer using lemmatization and such.

**Question: Why did you classify Animal A as a mammal?**

**Answer: fur/ produces milk/ give birth/ warm-blooded**

matching the keywords in the answer is relatively straightforward.

&amp;#x200B;

However, the issue comes when we need to match answers that are more complex.

**Question: what is the relationship between the amount of water given and the height of the seedling?**

**Answer: As the amount of water given increases, the height of the seedling increases.**

&amp;#x200B;

A student may phrase the above answer differently and get a correct answer. (e.g. more water given, taller the plant grows). Take note that students are not graded on language skills ( i.e. grammar and spelling to a reasonable extent.)

I have tried using a pre-trained corpus to calculate the cosine similarity and use that to determine whether an answer matches the model answer or not. However, the resulting cosine values are rather indistinguishable. As a result, I am not able to pick a suitable threshold to ""differentiate"" right from wrong.

I have considered breaking down the answers into clauses and perform a similar analysis on them individually before adding up the scores for each clause. I could possibly use the dependency matcher of spacy to fix the correct subject-verb-object relation in an attempt to extract semantic meaning using algorithms. I guess the next step forward would be to apply machine learning. Thank you for taking the time to read this. I would greatly appreciate any inputs from anyone here. Thanks again!",https://www.reddit.com/r/LanguageTechnology/comments/ns4nw3/answer_matching_using_sentence_similarity/,LanguageTechnology,t3_ns4nw3,"Answer matching using sentence similarity Hi, I am relatively new to NLP. I am trying to write a code that allows me to grade elementary student's  Science questions. For keyword-based answers, I am able to easily match student's answer to the model answer using lemmatization and such.

**Question: Why did you classify Animal A as a mammal?**

**Answer: fur/ produces milk/ give birth/ warm-blooded**

matching the keywords in the answer is relatively straightforward.

&amp;#x200B;

However, the issue comes when we need to match answers that are more complex.

**Question: what is the relationship between the amount of water given and the height of the seedling?**

**Answer: As the amount of water given increases, the height of the seedling increases.**

&amp;#x200B;

A student may phrase the above answer differently and get a correct answer. (e.g. more water given, taller the plant grows). Take note that students are not graded on language skills ( i.e. grammar and spelling to a reasonable extent.)

I have tried using a pre-trained corpus to calculate the cosine similarity and use that to determine whether an answer matches the model answer or not. However, the resulting cosine values are rather indistinguishable. As a result, I am not able to pick a suitable threshold to ""differentiate"" right from wrong.

I have considered breaking down the answers into clauses and perform a similar analysis on them individually before adding up the scores for each clause. I could possibly use the dependency matcher of spacy to fix the correct subject-verb-object relation in an attempt to extract semantic meaning using algorithms. I guess the next step forward would be to apply machine learning. Thank you for taking the time to read this. I would greatly appreciate any inputs from anyone here. Thanks again!",1820
65,65,"Text classification for item matching, best setup?","Hi there, I am building a text classification model to match the name and description of a customer's item (e.g. name: ""suction press nip"", category: ""paper machine parts"") to a list of 10k basic items (name: ""steel, unalloyed"", category: ""metals""). I have some initial matched data to test and I will get more and more, hopefully.

I've build a sentiment analysis program in the past, this is a good example of what I used: [https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/) (Spacy, Scikitlearn).

This current problem is more complex though, it's 1 to 10k+ match and not binary (or max 5, 6 values), the string for the item is short and absolutely at the discretion of the source (client item log).

Which reads/tutorials/examples would you suggest to take a look at? (in Python please)",https://www.reddit.com/r/LanguageTechnology/comments/ns1dt0/text_classification_for_item_matching_best_setup/,LanguageTechnology,t3_ns1dt0,"Text classification for item matching, best setup? Hi there, I am building a text classification model to match the name and description of a customer's item (e.g. name: ""suction press nip"", category: ""paper machine parts"") to a list of 10k basic items (name: ""steel, unalloyed"", category: ""metals""). I have some initial matched data to test and I will get more and more, hopefully.

I've build a sentiment analysis program in the past, this is a good example of what I used: [https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/) (Spacy, Scikitlearn).

This current problem is more complex though, it's 1 to 10k+ match and not binary (or max 5, 6 values), the string for the item is short and absolutely at the discretion of the source (client item log).

Which reads/tutorials/examples would you suggest to take a look at? (in Python please)",955
66,66,[Discussion] What should be the data driven chatbot architecture using NLP2SQL?," Given a table, I am able to convert natural language questions into appropriate SQL query with transformers.

The architecture of a chatbot should be:

1. Natural language question to SQL query translation using transformers (this part is completed)
2. Fed SQL query to SQL engine and collect response (this part is completed)
3. Convert SQL engine response to Natural Language Response

How can I accomplish the last part? What kind of architecture or model should I use?",https://www.reddit.com/r/LanguageTechnology/comments/nrxxpr/discussion_what_should_be_the_data_driven_chatbot/,LanguageTechnology,t3_nrxxpr,"[Discussion] What should be the data driven chatbot architecture using NLP2SQL?  Given a table, I am able to convert natural language questions into appropriate SQL query with transformers.

The architecture of a chatbot should be:

1. Natural language question to SQL query translation using transformers (this part is completed)
2. Fed SQL query to SQL engine and collect response (this part is completed)
3. Convert SQL engine response to Natural Language Response

How can I accomplish the last part? What kind of architecture or model should I use?",553
67,67,To Negate a word,Any method to negate a Verb or Noun word in the sentence using NLP,https://www.reddit.com/r/LanguageTechnology/comments/nrwarv/to_negate_a_word/,LanguageTechnology,t3_nrwarv,To Negate a word Any method to negate a Verb or Noun word in the sentence using NLP,83
68,68,"What is happening when you say ""play me butter"" to your Alexa/Google/Siri?","Hi,

It might be a novice question, but could be a deeper one as well.

Anyone out there please guide me with what is actually happening when you say,

**Play me Butter**

to your Alexa/Google/Siri?

What I know is that, the ML/NLP engine under the hood will

1. Classify the intent -&gt; Music Play
2. Recognize what ""Butter"" means -&gt; It is a song by BTS
3. Tell ""here's Butter by BTS"" to the user
4. And actually play it.

But this is just the high-level sketch. For example, the word ""Butter"" was meaning the food ingredient before BTS launched the single.

**How will the engine behind update their Knowledge Base according to new releases? In a timely manner?** 

I can't imagine it's being done manually. And,

What will be the pipeline of classifiers for finally recognizing Butter as a BTS song? I doubt it'll be done with a single classifier.

Thanks a ton in advance!",https://www.reddit.com/r/LanguageTechnology/comments/nrmv0a/what_is_happening_when_you_say_play_me_butter_to/,LanguageTechnology,t3_nrmv0a,"What is happening when you say ""play me butter"" to your Alexa/Google/Siri? Hi,

It might be a novice question, but could be a deeper one as well.

Anyone out there please guide me with what is actually happening when you say,

**Play me Butter**

to your Alexa/Google/Siri?

What I know is that, the ML/NLP engine under the hood will

1. Classify the intent -&gt; Music Play
2. Recognize what ""Butter"" means -&gt; It is a song by BTS
3. Tell ""here's Butter by BTS"" to the user
4. And actually play it.

But this is just the high-level sketch. For example, the word ""Butter"" was meaning the food ingredient before BTS launched the single.

**How will the engine behind update their Knowledge Base according to new releases? In a timely manner?** 

I can't imagine it's being done manually. And,

What will be the pipeline of classifiers for finally recognizing Butter as a BTS song? I doubt it'll be done with a single classifier.

Thanks a ton in advance!",955
69,69,Is there a cloud service where I can run my LDA code at a good speed?,"I have a deadline tonight and I wont make it because the code takes several days to finish making the corpus and then passing them it through LDA.

&amp;#x200B;

Edit: I use gensim in python",https://www.reddit.com/r/LanguageTechnology/comments/ns09fc/is_there_a_cloud_service_where_i_can_run_my_lda/,LanguageTechnology,t3_ns09fc,"Is there a cloud service where I can run my LDA code at a good speed? I have a deadline tonight and I wont make it because the code takes several days to finish making the corpus and then passing them it through LDA.

&amp;#x200B;

Edit: I use gensim in python",260
70,70,Build and query a book similarity index,"&amp;#x200B;

https://reddit.com/link/nrp6bw/video/dzi6hndkh4371/player

This application builds a local txtai index using book data from [openlibrary.org](https://openlibrary.org). It supports natural language queries to find the best matching books.

Applications that support natural language queries open up exciting possibilities. Take conversational AI as an example, you wouldn't expect users to speak in an abrupt way that is typical with traditional token-based search systems.

GitHub: [https://github.com/neuml/txtai](https://github.com/neuml/txtai)  
Application: [https://github.com/neuml/txtai/blob/master/examples/books.py](https://github.com/neuml/txtai/blob/master/examples/books.py)",https://www.reddit.com/r/LanguageTechnology/comments/nrp6bw/build_and_query_a_book_similarity_index/,LanguageTechnology,t3_nrp6bw,"Build and query a book similarity index &amp;#x200B;

https://reddit.com/link/nrp6bw/video/dzi6hndkh4371/player

This application builds a local txtai index using book data from [openlibrary.org](https://openlibrary.org). It supports natural language queries to find the best matching books.

Applications that support natural language queries open up exciting possibilities. Take conversational AI as an example, you wouldn't expect users to speak in an abrupt way that is typical with traditional token-based search systems.

GitHub: [https://github.com/neuml/txtai](https://github.com/neuml/txtai)  
Application: [https://github.com/neuml/txtai/blob/master/examples/books.py](https://github.com/neuml/txtai/blob/master/examples/books.py)",740
71,71,Text classification: When to use sequence models over bag-of-words model?,"In the recent update on his upcoming book ""Deep Learning with Python. 2nd edition"" F. Chollet refers to research done in 2017: He and his team did a systematic analysis of text classification using different data sets. He claims that they discovered a simple rule of thumb: If the (number of samples / mean sample length)  &gt; 1500 one should use a sequence model, if  it is &lt; 1500, then one should use a bag-of-bigrams. 

It seems they didn't publish this finding in a research paper but only in a [Google guide to text classification](https://developers.google.com/machine-learning/guides/text-classification) (without any names except 'Google'). I am gathering this from the fact that Chollet only refers to the guide. The guide gives a little bit more information: they ran 450k experiments "" across problems of different types (especially sentiment analysis and topic classification problems), using 12 datasets, alternating for each dataset between different data preprocessing techniques and different model architectures"" ([source](https://developers.google.com/machine-learning/guides/text-classification/step-2-5)). 

As this was done 2017, it would be very interesting to see whether this rule is still valid with the context-sensitive language models like Bert. Does anyone know about research checking this claim in recent years?",https://www.reddit.com/r/LanguageTechnology/comments/nrcaqj/text_classification_when_to_use_sequence_models/,LanguageTechnology,t3_nrcaqj,"Text classification: When to use sequence models over bag-of-words model? In the recent update on his upcoming book ""Deep Learning with Python. 2nd edition"" F. Chollet refers to research done in 2017: He and his team did a systematic analysis of text classification using different data sets. He claims that they discovered a simple rule of thumb: If the (number of samples / mean sample length)  &gt; 1500 one should use a sequence model, if  it is &lt; 1500, then one should use a bag-of-bigrams. 

It seems they didn't publish this finding in a research paper but only in a [Google guide to text classification](https://developers.google.com/machine-learning/guides/text-classification) (without any names except 'Google'). I am gathering this from the fact that Chollet only refers to the guide. The guide gives a little bit more information: they ran 450k experiments "" across problems of different types (especially sentiment analysis and topic classification problems), using 12 datasets, alternating for each dataset between different data preprocessing techniques and different model architectures"" ([source](https://developers.google.com/machine-learning/guides/text-classification/step-2-5)). 

As this was done 2017, it would be very interesting to see whether this rule is still valid with the context-sensitive language models like Bert. Does anyone know about research checking this claim in recent years?",1420
72,72,Advice for how to approach classifying apartment posts on facebook?,"I want to develop software that helps streamline connecting people with roomates/apartments. Right now I'm using a few facebook groups where people post about either looking for someone to rent a room in their apartment or they post about needing a room. I'd like to write something that automatically parses the data out of these that people commonly need. Like: Is this apartment pet friendly? How much is the room? What neighborhood is it in? How many bedrooms? etc.

My background is in computer vision for robotics with CNNs, so this is a totally different domain I'm not familiar with. From the research I've done so far, it sounds like I should look into entity recognition and relationship extraction. But I'm not sure what models are good for that, how much labeled data I need to get started.

I'd be willing to put a few thousand dollars into data annotation I think if that could get me something I could use for my own apartment search.

What models should I look into? What data labeling services/tools? How should I approach this?",https://www.reddit.com/r/LanguageTechnology/comments/nrv8xt/advice_for_how_to_approach_classifying_apartment/,LanguageTechnology,t3_nrv8xt,"Advice for how to approach classifying apartment posts on facebook? I want to develop software that helps streamline connecting people with roomates/apartments. Right now I'm using a few facebook groups where people post about either looking for someone to rent a room in their apartment or they post about needing a room. I'd like to write something that automatically parses the data out of these that people commonly need. Like: Is this apartment pet friendly? How much is the room? What neighborhood is it in? How many bedrooms? etc.

My background is in computer vision for robotics with CNNs, so this is a totally different domain I'm not familiar with. From the research I've done so far, it sounds like I should look into entity recognition and relationship extraction. But I'm not sure what models are good for that, how much labeled data I need to get started.

I'd be willing to put a few thousand dollars into data annotation I think if that could get me something I could use for my own apartment search.

What models should I look into? What data labeling services/tools? How should I approach this?",1113
73,73,What are state-of-the-art methods for abstractive text summarization ?,,https://www.reddit.com/r/LanguageTechnology/comments/nr6xx7/what_are_stateoftheart_methods_for_abstractive/,LanguageTechnology,t3_nr6xx7,What are state-of-the-art methods for abstractive text summarization ? ,71
74,74,Assessing the “Value” of a question.,"Hi, All. I am new to NLP but have a problem I'd like to solve. I host a podcast of sorts at work and I am always on the lookout for great questions. Since I also enjoy python and data science I decided to see if I could uncover anything using those tools.

Did a bit of research and found a corpus of transcribed npr interviews. That seemed like a good place to start so I wrote the code to tokenize all the sentences and find those ending in '?'. So, that's all the questions.

In 3M+ utterances, there are a bunch of questions. Many are...not good questions.

'Beth, are you out there?'

'What do you say, Bob?'

'Is that right?'

Fewer are actually good or more meaningful questions.

'Clinton and Obama are pretty similar on policy issues, so why would a Democrat switch loyalties like that?'

""The issue in the Hollywood writer's strike is, do writers get paid for work that winds up online?""

In general, these questions tend to be longer and have larger words in them but, I am curious if there are any established methods for determining the meaning or value of a question? I am not really certain even what the right word is to use (meaning, value, etc).

Anyways, I always open to learn something new. If anyone can point me in the right direction, i'd appreciate it. Thanks!

&amp;#x200B;

Code thus far for anyone interested:

`import nltk`

`from nltk.corpus import stopwords`

`from nltk import word_tokenize`

`from nltk import sent_tokenize`

`import numpy as np`

`import pandas as pd`

[`nltk.download`](https://nltk.download)`('nps_chat')`

&amp;#x200B;

`npr = pd.read_csv('C:\Users\...\Desktop\Python Scripts\Data\utterances.csv')`

`npr = npr[npr['utterance'].notna()]`

&amp;#x200B;

`tokens = npr['utterance'].apply(lambda x: sent_tokenize(x))`

`#put tokens into the DF`

`npr['utterance_tokenized'] = tokens`

`#build lists of question sentences`

`is_question = npr['utterance_tokenized'].apply(lambda x:`

`[q for q in x if '?' in q])`

`#put questions into the DF`

`npr['questions'] = is_question`

`#identify non-empty lists of questions`

`has_question = npr['questions'].apply(lambda x: True if (len(x) &gt; 0) else False)`

`#put boolean results into data frame`

`npr['has_questions'] = has_question`",https://www.reddit.com/r/LanguageTechnology/comments/nqzvav/assessing_the_value_of_a_question/,LanguageTechnology,t3_nqzvav,"Assessing the “Value” of a question. Hi, All. I am new to NLP but have a problem I'd like to solve. I host a podcast of sorts at work and I am always on the lookout for great questions. Since I also enjoy python and data science I decided to see if I could uncover anything using those tools.

Did a bit of research and found a corpus of transcribed npr interviews. That seemed like a good place to start so I wrote the code to tokenize all the sentences and find those ending in '?'. So, that's all the questions.

In 3M+ utterances, there are a bunch of questions. Many are...not good questions.

'Beth, are you out there?'

'What do you say, Bob?'

'Is that right?'

Fewer are actually good or more meaningful questions.

'Clinton and Obama are pretty similar on policy issues, so why would a Democrat switch loyalties like that?'

""The issue in the Hollywood writer's strike is, do writers get paid for work that winds up online?""

In general, these questions tend to be longer and have larger words in them but, I am curious if there are any established methods for determining the meaning or value of a question? I am not really certain even what the right word is to use (meaning, value, etc).

Anyways, I always open to learn something new. If anyone can point me in the right direction, i'd appreciate it. Thanks!

&amp;#x200B;

Code thus far for anyone interested:

`import nltk`

`from nltk.corpus import stopwords`

`from nltk import word_tokenize`

`from nltk import sent_tokenize`

`import numpy as np`

`import pandas as pd`

[`nltk.download`](https://nltk.download)`('nps_chat')`

&amp;#x200B;

`npr = pd.read_csv('C:\Users\...\Desktop\Python Scripts\Data\utterances.csv')`

`npr = npr[npr['utterance'].notna()]`

&amp;#x200B;

`tokens = npr['utterance'].apply(lambda x: sent_tokenize(x))`

`#put tokens into the DF`

`npr['utterance_tokenized'] = tokens`

`#build lists of question sentences`

`is_question = npr['utterance_tokenized'].apply(lambda x:`

`[q for q in x if '?' in q])`

`#put questions into the DF`

`npr['questions'] = is_question`

`#identify non-empty lists of questions`

`has_question = npr['questions'].apply(lambda x: True if (len(x) &gt; 0) else False)`

`#put boolean results into data frame`

`npr['has_questions'] = has_question`",2272
75,75,What have you read recently?,"I work in the field of NLP and realized I wasn't reading enough papers on what's going around in the field. What is the latest paper you read and that leaves you mindblown (or at least excited)?

It can be any fields of NLP, I'm just curious.",https://www.reddit.com/r/LanguageTechnology/comments/nqvvka/what_have_you_read_recently/,LanguageTechnology,t3_nqvvka,"What have you read recently? I work in the field of NLP and realized I wasn't reading enough papers on what's going around in the field. What is the latest paper you read and that leaves you mindblown (or at least excited)?

It can be any fields of NLP, I'm just curious.",271
76,76,Few Shot Learning in BERT,"Hi, I'm interested to know whether the few-shot learning can be done on BERT for sentence similarity.  


Update: Found the pipeline in hugging face for zero-shot learning.  
[https://huggingface.co/facebook/bart-large-mnli](https://huggingface.co/facebook/bart-large-mnli)  
But still, I'm not sure about the few-shot though.  
",https://www.reddit.com/r/LanguageTechnology/comments/nqh6jw/few_shot_learning_in_bert/,LanguageTechnology,t3_nqh6jw,"Few Shot Learning in BERT Hi, I'm interested to know whether the few-shot learning can be done on BERT for sentence similarity.  


Update: Found the pipeline in hugging face for zero-shot learning.  
[https://huggingface.co/facebook/bart-large-mnli](https://huggingface.co/facebook/bart-large-mnli)  
But still, I'm not sure about the few-shot though.  
",355
77,77,Sentiment Analysis with flair on poetry - model evaluation,"Hi! I am a digital humanities student and a newbie in NLP and for my dissertation I tried sentiment analysis with flair library on around 517 poems. My problem is: I used a pre-trained model and it labeled my poems as Negative/Positive, but I do not know how to evaluate how accurate this was. My data was unlabeled before applying the pre-trained model.  

If someone could please help me, that would be great. Thank you!",https://www.reddit.com/r/LanguageTechnology/comments/nqhf6g/sentiment_analysis_with_flair_on_poetry_model/,LanguageTechnology,t3_nqhf6g,"Sentiment Analysis with flair on poetry - model evaluation Hi! I am a digital humanities student and a newbie in NLP and for my dissertation I tried sentiment analysis with flair library on around 517 poems. My problem is: I used a pre-trained model and it labeled my poems as Negative/Positive, but I do not know how to evaluate how accurate this was. My data was unlabeled before applying the pre-trained model.  

If someone could please help me, that would be great. Thank you!",481
78,78,"If you are looking to automatically extract information from PDFs or scanned images, check out this article on how to leverage OCR to create training data.","[https://towardsdatascience.com/how-to-annotate-pdfs-and-scanned-images-for-nlp-applications-f7b7b1db5c4a](https://towardsdatascience.com/how-to-annotate-pdfs-and-scanned-images-for-nlp-applications-f7b7b1db5c4a)

Disclaimer: The OCR feature mentioned in the article is only available for paid subscriptions, if you are interested by a demo send us an email at [admin@ubiai.tools](mailto:admin@ubiai.tools).",https://www.reddit.com/r/LanguageTechnology/comments/nq8ahy/if_you_are_looking_to_automatically_extract/,LanguageTechnology,t3_nq8ahy,"If you are looking to automatically extract information from PDFs or scanned images, check out this article on how to leverage OCR to create training data. [https://towardsdatascience.com/how-to-annotate-pdfs-and-scanned-images-for-nlp-applications-f7b7b1db5c4a](https://towardsdatascience.com/how-to-annotate-pdfs-and-scanned-images-for-nlp-applications-f7b7b1db5c4a)

Disclaimer: The OCR feature mentioned in the article is only available for paid subscriptions, if you are interested by a demo send us an email at [admin@ubiai.tools](mailto:admin@ubiai.tools).",563
79,79,Assigning a category to a word,"Hey there,
I am waiting currently waiting my master's thesis and I had an idea for an analysis. 
I have a list of domain names and I was wondering whether I could automatically categorize them. I already tried the word embedding methods GloVe methods as presented by Stanford in 2013, googleNews negative 300 and Facebooks fasttext. My best results were with fasttext but they are still somewhat unreliable and when I look at the vectorization of words I find the their neighbours but I don't really get ""super-categories"" of these words. 
I would love to have something like:
f(""cars-for-sale.com"")=  ""car sales website"".
Am I overlooking some super obvious method for this? I am new to the field of NLP so please forgive me my ignorance.",https://www.reddit.com/r/LanguageTechnology/comments/nq0nl5/assigning_a_category_to_a_word/,LanguageTechnology,t3_nq0nl5,"Assigning a category to a word Hey there,
I am waiting currently waiting my master's thesis and I had an idea for an analysis. 
I have a list of domain names and I was wondering whether I could automatically categorize them. I already tried the word embedding methods GloVe methods as presented by Stanford in 2013, googleNews negative 300 and Facebooks fasttext. My best results were with fasttext but they are still somewhat unreliable and when I look at the vectorization of words I find the their neighbours but I don't really get ""super-categories"" of these words. 
I would love to have something like:
f(""cars-for-sale.com"")=  ""car sales website"".
Am I overlooking some super obvious method for this? I am new to the field of NLP so please forgive me my ignorance.",770
80,80,What advantage is there to treating sentiment analysis as a classification problem vs a regression problem?," Many of the papers and tutorials I'm reading on sentiment analysis seem to treat the problem as classification problem where the goal is to classify some text as ""positive"", ""negative"", or ""neutral"". However, sentiment is discrete concept, so why would you treat is as such? Wouldn't you need to model sentiment as a float value between say -1 and 1, and then preform a regression? Is there are problem with the latter solution that the former method fixes?",https://www.reddit.com/r/LanguageTechnology/comments/nq5zz8/what_advantage_is_there_to_treating_sentiment/,LanguageTechnology,t3_nq5zz8,"What advantage is there to treating sentiment analysis as a classification problem vs a regression problem?  Many of the papers and tutorials I'm reading on sentiment analysis seem to treat the problem as classification problem where the goal is to classify some text as ""positive"", ""negative"", or ""neutral"". However, sentiment is discrete concept, so why would you treat is as such? Wouldn't you need to model sentiment as a float value between say -1 and 1, and then preform a regression? Is there are problem with the latter solution that the former method fixes?",566
81,81,Minimum text length in diary entries for detecting emotions/sentiment and classifying levels of mental health issues,"Hi, 

I am designing a study where I will collect daily diary entries and try to predict emotions/sentiment as well as levels of mental health issues (the ground truth scores will be acquired through daily questionnaires). Since I am new to NLP, what would be a good minimum text length of these diary entries for using machine learning/NLP methods and why? I would be grateful for any relevant sources as well.

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/npw3c1/minimum_text_length_in_diary_entries_for/,LanguageTechnology,t3_npw3c1,"Minimum text length in diary entries for detecting emotions/sentiment and classifying levels of mental health issues Hi, 

I am designing a study where I will collect daily diary entries and try to predict emotions/sentiment as well as levels of mental health issues (the ground truth scores will be acquired through daily questionnaires). Since I am new to NLP, what would be a good minimum text length of these diary entries for using machine learning/NLP methods and why? I would be grateful for any relevant sources as well.

Thanks!",537
82,82,Facebook AI Demonstrates How The Power Of Transfer Learning Can Boost Code Autocompletion Accuracy By Over 50%,"Autocompletion has become a handy and widely used tool in contemporary messaging and other writing tasks. It is also an essential feature of an integrated development environment (IDE) for computer programming. Recently, research has shown that autocompletion can be powered by deep learning, thus allowing software language models to achieve significant accuracy improvements by training on real-world datasets collected from programmers’ IDE activity. However, a common issue with less popular programming languages is that the available IDE datasets may be insufficient for training.

In a [paper](https://arxiv.org/pdf/2105.05991.pdf), a research team from Facebook demonstrates how transfer learning can enable pre-training on non-IDE, non-autocompletion, and different-language example code sequences before fine-tuning on the autocompletion prediction task. The proposed method improves model accuracy by more than 50 percent on small fine-tuning datasets and over 10 percent on 50k labeled examples.

Summary: [https://www.marktechpost.com/2021/05/31/facebook-demonstrates-how-the-power-of-transfer-learning-can-boost-code-autocompletion-accuracy-by-over-50/](https://www.marktechpost.com/2021/05/31/facebook-demonstrates-how-the-power-of-transfer-learning-can-boost-code-autocompletion-accuracy-by-over-50/?_ga=2.133350797.2041055336.1622397040-488125022.1618729090)

Paper: https://arxiv.org/pdf/2105.05991.pdf",https://www.reddit.com/r/LanguageTechnology/comments/nplea7/facebook_ai_demonstrates_how_the_power_of/,LanguageTechnology,t3_nplea7,"Facebook AI Demonstrates How The Power Of Transfer Learning Can Boost Code Autocompletion Accuracy By Over 50% Autocompletion has become a handy and widely used tool in contemporary messaging and other writing tasks. It is also an essential feature of an integrated development environment (IDE) for computer programming. Recently, research has shown that autocompletion can be powered by deep learning, thus allowing software language models to achieve significant accuracy improvements by training on real-world datasets collected from programmers’ IDE activity. However, a common issue with less popular programming languages is that the available IDE datasets may be insufficient for training.

In a [paper](https://arxiv.org/pdf/2105.05991.pdf), a research team from Facebook demonstrates how transfer learning can enable pre-training on non-IDE, non-autocompletion, and different-language example code sequences before fine-tuning on the autocompletion prediction task. The proposed method improves model accuracy by more than 50 percent on small fine-tuning datasets and over 10 percent on 50k labeled examples.

Summary: [https://www.marktechpost.com/2021/05/31/facebook-demonstrates-how-the-power-of-transfer-learning-can-boost-code-autocompletion-accuracy-by-over-50/](https://www.marktechpost.com/2021/05/31/facebook-demonstrates-how-the-power-of-transfer-learning-can-boost-code-autocompletion-accuracy-by-over-50/?_ga=2.133350797.2041055336.1622397040-488125022.1618729090)

Paper: https://arxiv.org/pdf/2105.05991.pdf",1531
83,83,[D] Probing Classifiers: A Gentle Intro (Explainable AI for Deep Learning) [Video],,/r/MachineLearning/comments/npraw7/d_probing_classifiers_a_gentle_intro_explainable/,LanguageTechnology,t3_nprdjx,[D] Probing Classifiers: A Gentle Intro (Explainable AI for Deep Learning) [Video] ,83
84,84,Your opinions: Where are conversational interfaces actually useful?,"Hi. I'm working in a company that has recently started accepting projects on conversational and vocal interfaces but I am personaly at a point in my path where I often doubt that these kind of applications with the current level of performance are actually useful outside very specific cases (like for disabled people).

So, in the spirit of the ""are chatbots just a fad?"" I would like to know your opinions on the following subjects:

# Are the current tecnologies for conversational and vocal interfaces really useful? Are we just offering on the market something that is ""cool"" but useless? What are examples of conversational and vocal interfaces the general public is using in their lifes right now? Where might we use these technologies in the very near future that we still don't?",https://www.reddit.com/r/LanguageTechnology/comments/np4mqr/your_opinions_where_are_conversational_interfaces/,LanguageTechnology,t3_np4mqr,"Your opinions: Where are conversational interfaces actually useful? Hi. I'm working in a company that has recently started accepting projects on conversational and vocal interfaces but I am personaly at a point in my path where I often doubt that these kind of applications with the current level of performance are actually useful outside very specific cases (like for disabled people).

So, in the spirit of the ""are chatbots just a fad?"" I would like to know your opinions on the following subjects:

# Are the current tecnologies for conversational and vocal interfaces really useful? Are we just offering on the market something that is ""cool"" but useless? What are examples of conversational and vocal interfaces the general public is using in their lifes right now? Where might we use these technologies in the very near future that we still don't?",855
85,85,Into NLP - Part-of-speech tagging,,https://www.qualicen.de/into-nlp-5-numerous-language-parts-pos-tagging/,LanguageTechnology,t3_np15gv,Into NLP - Part-of-speech tagging ,34
86,86,[2105.13626] ByT5: Towards a token-free future with pre-trained byte-to-byte models,,https://arxiv.org/abs/2105.13626,LanguageTechnology,t3_np39fr,[2105.13626] ByT5: Towards a token-free future with pre-trained byte-to-byte models ,84
87,87,Entity-level Factual Consistency of Abstractive Text Summarization (Research Paper Walkthrough),,https://youtu.be/P9wr8IBfDQs,LanguageTechnology,t3_noyvf4,Entity-level Factual Consistency of Abstractive Text Summarization (Research Paper Walkthrough) ,96
88,88,Noob question - What are the better tools/programs that general code using instructions in natural language/plain English?,Generate code*,https://www.reddit.com/r/LanguageTechnology/comments/noxvs0/noob_question_what_are_the_better_toolsprograms/,LanguageTechnology,t3_noxvs0,Noob question - What are the better tools/programs that general code using instructions in natural language/plain English? Generate code*,137
89,89,BERT - Annotated Paper + Paper Summary,"Everyone who is interested in NLP or even DL and ML for that matter, has definitely heard about the BERT family of models. BERT, RoBERTa, DistilBERT and many many more. This paper ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"" first introduced this and it has now completely changed the way AI practitioners are solving and looking at NLP problems these days.

As a part of my Paper Notes series, I have gone through the paper and created an informative summary of the paper. This time it goes a bit longer than the previous paper summaries, but it had to be done. The paper contained many tiny interesting nuggets that I had to include. Check out the links below and happy reading!

Paper Summary -  [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://shreyansh26.github.io/post/2021-05-09_pretraining_deep_bidirectional_transformers_bert/)

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf)",https://www.reddit.com/r/LanguageTechnology/comments/np03n3/bert_annotated_paper_paper_summary/,LanguageTechnology,t3_np03n3,"BERT - Annotated Paper + Paper Summary Everyone who is interested in NLP or even DL and ML for that matter, has definitely heard about the BERT family of models. BERT, RoBERTa, DistilBERT and many many more. This paper ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"" first introduced this and it has now completely changed the way AI practitioners are solving and looking at NLP problems these days.

As a part of my Paper Notes series, I have gone through the paper and created an informative summary of the paper. This time it goes a bit longer than the previous paper summaries, but it had to be done. The paper contained many tiny interesting nuggets that I had to include. Check out the links below and happy reading!

Paper Summary -  [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://shreyansh26.github.io/post/2021-05-09_pretraining_deep_bidirectional_transformers_bert/)

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf)",1118
90,90,Google’s Multitask Unified Model (MUM) Transforms How Google AI Understands Complex Queries,,https://www.marktechpost.com/2021/05/31/googles-multitask-unified-model-mum-transforms-how-google-ai-understands-complex-queries/,LanguageTechnology,t3_np2pfo,Google’s Multitask Unified Model (MUM) Transforms How Google AI Understands Complex Queries ,92
91,91,Facebook AI releases Dynaboard: A New Evaluation platform for NLP Models,"Last year, Facebook AI released [Dynabench](https://dynabench.org/?fbclid=IwAR1ScAjtZoAb_PwA0-rPlCQYxWS-9-iGJpcYKQ5eyFUvLnQVVbSZtV8j3as), a platform that radically rethinks benchmarking in AI, starting with natural language processing (NLP) models. Going forward, they have now announced a new evaluation-as-a-service platform for comprehensive, standardized evaluations of NLP models called [Dynaboard](https://dynabench.org/dynaboard.pdf?fbclid=IwAR3rTJa8jRQtaJp8FFp5wf-eyWZ2QmXHTapxHjmpqw-j1t0Sw9n1xD31ASs). Dynaboard can perform apples-to-apples comparisons dynamically without common issues from bugs in evaluation code, inconsistencies in filtering test data, backward compatibility, accessibility, and several other reproducibility issues.

Dynaboard enables AI researchers to customize a new Dynascore metric based on multiple axes of evaluation, including compute, accuracy, robustness, memory, and fairness.

Full Summary: [https://www.marktechpost.com/2021/05/30/facebook-ai-releases-dynaboard-a-new-evaluation-platform-for-nlp-models/](https://www.marktechpost.com/2021/05/30/facebook-ai-releases-dynaboard-a-new-evaluation-platform-for-nlp-models/?_ga=2.190349480.2041055336.1622397040-488125022.1618729090)

Github: https://github.com/facebookresearch/dynalab

Paper: https://dynabench.org/dynaboard.pdf",https://www.reddit.com/r/LanguageTechnology/comments/nogmtg/facebook_ai_releases_dynaboard_a_new_evaluation/,LanguageTechnology,t3_nogmtg,"Facebook AI releases Dynaboard: A New Evaluation platform for NLP Models Last year, Facebook AI released [Dynabench](https://dynabench.org/?fbclid=IwAR1ScAjtZoAb_PwA0-rPlCQYxWS-9-iGJpcYKQ5eyFUvLnQVVbSZtV8j3as), a platform that radically rethinks benchmarking in AI, starting with natural language processing (NLP) models. Going forward, they have now announced a new evaluation-as-a-service platform for comprehensive, standardized evaluations of NLP models called [Dynaboard](https://dynabench.org/dynaboard.pdf?fbclid=IwAR3rTJa8jRQtaJp8FFp5wf-eyWZ2QmXHTapxHjmpqw-j1t0Sw9n1xD31ASs). Dynaboard can perform apples-to-apples comparisons dynamically without common issues from bugs in evaluation code, inconsistencies in filtering test data, backward compatibility, accessibility, and several other reproducibility issues.

Dynaboard enables AI researchers to customize a new Dynascore metric based on multiple axes of evaluation, including compute, accuracy, robustness, memory, and fairness.

Full Summary: [https://www.marktechpost.com/2021/05/30/facebook-ai-releases-dynaboard-a-new-evaluation-platform-for-nlp-models/](https://www.marktechpost.com/2021/05/30/facebook-ai-releases-dynaboard-a-new-evaluation-platform-for-nlp-models/?_ga=2.190349480.2041055336.1622397040-488125022.1618729090)

Github: https://github.com/facebookresearch/dynalab

Paper: https://dynabench.org/dynaboard.pdf",1390
92,92,"Structuring free text, then performing analysis vs. Performing analysis on unstructured free text","Hi reddit, NLP newbie here

I am trying to understand if there is any value in creating a table out of free text, versus predictive analysis on the free text itself. 

For context, I am working with 2 million clinical notes from the MIMIC-III dataset, and I would like to tabluate all this unstructured data. Would this yield much value, considering I could design a bespoke predicitve model directly on to the free text? Would there be much difference in results from the free text compared to its structured counterpart?",https://www.reddit.com/r/LanguageTechnology/comments/not78h/structuring_free_text_then_performing_analysis_vs/,LanguageTechnology,t3_not78h,"Structuring free text, then performing analysis vs. Performing analysis on unstructured free text Hi reddit, NLP newbie here

I am trying to understand if there is any value in creating a table out of free text, versus predictive analysis on the free text itself. 

For context, I am working with 2 million clinical notes from the MIMIC-III dataset, and I would like to tabluate all this unstructured data. Would this yield much value, considering I could design a bespoke predicitve model directly on to the free text? Would there be much difference in results from the free text compared to its structured counterpart?",620
93,93,Python bindings for LibreTranslate,,https://github.com/argosopentech/LibreTranslate-py,LanguageTechnology,t3_nooqsl,Python bindings for LibreTranslate ,35
94,94,Comparing between Cosine Similarity and Word Mover's Distance,"So basically what i'm attempting is to benchmark Cosine and WMD for a very generic use-case of textual similarity (This is probably quite the noob question).

My dataset is a parallel corpus made of pairs of paraphrased sentences. My issue is mainly in how I can compare the two metrics since they are of different order of magnitude:

* Cosine is \[-1, 1\] (or \[1, 0\]).
* WMD is not bound by an upper limit and goes from 0 to \~3.83 for my small dataset, and I can't think of a way to normalise it without introducing a bias.

My use case does not involve some form of classification, in which case I could just compare normally by how good the classification is. As for setting a threshold, (for example if WMD(S1, S2) &lt; 0.5 then consider the pair to be similar) and I really don't know how I can set a threshold based on this benchmarking alone because all pairs are actually paraphrases, so the expected output is always a distance of 0, while my results are quite sparse.

What would you guys suggest (a metric to compare with or a way to determine a threshold for the two of them, or anything else) to pick which of the 2 is performing better?",https://www.reddit.com/r/LanguageTechnology/comments/noobre/comparing_between_cosine_similarity_and_word/,LanguageTechnology,t3_noobre,"Comparing between Cosine Similarity and Word Mover's Distance So basically what i'm attempting is to benchmark Cosine and WMD for a very generic use-case of textual similarity (This is probably quite the noob question).

My dataset is a parallel corpus made of pairs of paraphrased sentences. My issue is mainly in how I can compare the two metrics since they are of different order of magnitude:

* Cosine is \[-1, 1\] (or \[1, 0\]).
* WMD is not bound by an upper limit and goes from 0 to \~3.83 for my small dataset, and I can't think of a way to normalise it without introducing a bias.

My use case does not involve some form of classification, in which case I could just compare normally by how good the classification is. As for setting a threshold, (for example if WMD(S1, S2) &lt; 0.5 then consider the pair to be similar) and I really don't know how I can set a threshold based on this benchmarking alone because all pairs are actually paraphrases, so the expected output is always a distance of 0, while my results are quite sparse.

What would you guys suggest (a metric to compare with or a way to determine a threshold for the two of them, or anything else) to pick which of the 2 is performing better?",1216
95,95,"Spacy Matcher, POS Tagging and Grammatical Errors","Hi everyone, 

I'm a language learning/teaching researcher who has been trying to develop little tools to help other researchers recently. As you might guess, low-proficiency learner texts are quite a pain in the neck in this context due to frequent grammatical errors. 

So I'm actually looking for suggestions regarding a particular POS tagging problem as seen below:

""I think very good idea."" 

There, the learner obviously means ""I think -it is a- very good idea"" but since the function words are not there, POS taggers cannot accurately identify the parts of speech in the sentence. 

How could one deal with such sentences from a matching/POS tagging perspective? 

I have been considering ""next word generation"" but so far I haven't tested it properly. So any suggestion is welcome. 

Thanks in advance big time.",https://www.reddit.com/r/LanguageTechnology/comments/no7wrt/spacy_matcher_pos_tagging_and_grammatical_errors/,LanguageTechnology,t3_no7wrt,"Spacy Matcher, POS Tagging and Grammatical Errors Hi everyone, 

I'm a language learning/teaching researcher who has been trying to develop little tools to help other researchers recently. As you might guess, low-proficiency learner texts are quite a pain in the neck in this context due to frequent grammatical errors. 

So I'm actually looking for suggestions regarding a particular POS tagging problem as seen below:

""I think very good idea."" 

There, the learner obviously means ""I think -it is a- very good idea"" but since the function words are not there, POS taggers cannot accurately identify the parts of speech in the sentence. 

How could one deal with such sentences from a matching/POS tagging perspective? 

I have been considering ""next word generation"" but so far I haven't tested it properly. So any suggestion is welcome. 

Thanks in advance big time.",870
96,96,Loading mbart-large-50-one-to-many-mmt is very slow,"Whenever i try to run :
model = MBartForConditionalGeneration.from_pretrained("" [local path]/mbart-large-50-one-to-many-mmt"")
My computer ether freezes or it takes 15-20 minutes to load the model.

I am using it for translation
Code: https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt

Any solution fo this?

-Thanks",https://www.reddit.com/r/LanguageTechnology/comments/no6idv/loading_mbartlarge50onetomanymmt_is_very_slow/,LanguageTechnology,t3_no6idv,"Loading mbart-large-50-one-to-many-mmt is very slow Whenever i try to run :
model = MBartForConditionalGeneration.from_pretrained("" [local path]/mbart-large-50-one-to-many-mmt"")
My computer ether freezes or it takes 15-20 minutes to load the model.

I am using it for translation
Code: https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt

Any solution fo this?

-Thanks",380
97,97,The competition that involves linguistics and logic,,https://youtu.be/9tyG71ogKlE,LanguageTechnology,t3_nniznw,The competition that involves linguistics and logic ,52
98,98,How to dramatically improve the reasoning ability of GPT-3,,https://blog.andrewcantino.com/blog/2021/05/28/how-to-dramatically-improve-the-reasoning-ability-of-GPT-3/,LanguageTechnology,t3_nn75r9,How to dramatically improve the reasoning ability of GPT-3 ,59
99,99,Any free open-access NLP annotation tools?,"I am looking for a web based tool for an NLP annotation task (similar to docanno for example). 

The catch is that I have to create a project and make it easily accessed with a link without the need to create an account per each annotator.

Any tool that comes close to this criteria?",https://www.reddit.com/r/LanguageTechnology/comments/nn0lyf/any_free_openaccess_nlp_annotation_tools/,LanguageTechnology,t3_nn0lyf,"Any free open-access NLP annotation tools? I am looking for a web based tool for an NLP annotation task (similar to docanno for example). 

The catch is that I have to create a project and make it easily accessed with a link without the need to create an account per each annotator.

Any tool that comes close to this criteria?",327
100,100,Trying T5 11B,"Aside from self-hosting, where can I try non-fine-tuned T5 11B? 

If that’s not possible, are there any publicly available examples of its output?",https://www.reddit.com/r/LanguageTechnology/comments/nnggrj/trying_t5_11b/,LanguageTechnology,t3_nnggrj,"Trying T5 11B Aside from self-hosting, where can I try non-fine-tuned T5 11B? 

If that’s not possible, are there any publicly available examples of its output?",160
101,101,Benchmarking An NLP Tool,"Just as the title says, I'm looking for a way to benchmark the sentiment analysis component of two or more NLP tools like retextjs and Stanford Core NLP. Are there any tools or techniques out for doing this?",https://www.reddit.com/r/LanguageTechnology/comments/nnas13/benchmarking_an_nlp_tool/,LanguageTechnology,t3_nnas13,"Benchmarking An NLP Tool Just as the title says, I'm looking for a way to benchmark the sentiment analysis component of two or more NLP tools like retextjs and Stanford Core NLP. Are there any tools or techniques out for doing this?",232
102,102,NLP Certifications,Which are some coveted NLP Certifications available in the market having good industry recognition?,https://www.reddit.com/r/LanguageTechnology/comments/nmxhny/nlp_certifications/,LanguageTechnology,t3_nmxhny,NLP Certifications Which are some coveted NLP Certifications available in the market having good industry recognition?,118
103,103,Semantic similarity between programming languages and math terminology,"I've wondered how good neural nets can get at predicting semantic similarity at a more abstract level between different topics. For example, finding context between math terminology like 'vector' and 'matrix' and programming terminology like 'list/array' and '2d array'. Also, finding context between common data types, functions, concepts between different languages and frameworks/libraries. Ideally, I'd want a binary output that takes two strings as input to compare.

Question is what would be the approach to a problem like this, would it need carefully labelled data ('translating' the terminology between the two topics) or is a self-supervised method at all possible? I've only recently got into data so I could be way off here on what is possible and what is not.",https://www.reddit.com/r/LanguageTechnology/comments/nmuy6b/semantic_similarity_between_programming_languages/,LanguageTechnology,t3_nmuy6b,"Semantic similarity between programming languages and math terminology I've wondered how good neural nets can get at predicting semantic similarity at a more abstract level between different topics. For example, finding context between math terminology like 'vector' and 'matrix' and programming terminology like 'list/array' and '2d array'. Also, finding context between common data types, functions, concepts between different languages and frameworks/libraries. Ideally, I'd want a binary output that takes two strings as input to compare.

Question is what would be the approach to a problem like this, would it need carefully labelled data ('translating' the terminology between the two topics) or is a self-supervised method at all possible? I've only recently got into data so I could be way off here on what is possible and what is not.",844
104,104,"FastSpeech2 DTW computing, and other TTS evaluation methods","Hi all, at the moment im working on a TTS system and i want to evaluate it. Unfortunately i can not do the usual Mean opinion score, so i'm looking at more numeric evaluations to compare my generated speech to gt.

While looking for some i found the fastspeech2 paper where they use Dynamic Time Warping (DTW) to evaluate the pitch in the generated speech. Here they explain it as: ""average DTW distances (DTW) of pitch in ground-truth and synthesized audio"".

Now, when i try to calculate the DTW with [this](https://dynamictimewarping.github.io/python/) python package i seem to get strange results. In the fast speech 2 paper their DTW distances are between 24-26. Mine are all between 9000-10000 when i try to do this.

the way i try to do this is as followed(in a short pseudo code):

    for all gt and prediction:
        distance = DTW(gt,pred)
        total += distance
    result = total/number_of_samples

I've tried several distances from the [scipy page](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html) but none of them seem to get close to the range of 24-26 (when i use the seuclidean distance i get a total of 96, but this still seems too high)

the only way i can come close to the 24-26 range is by also averaging the dtw (with normal euclidean distance) by the time series length as followed:

    for all gt and prediction:
        distance = DTW(gt,pred)/length_of_prediction
        total += distance
    result = total/number_of_samples

can someone tell me if this is correct or how i should calculate the average DTW distance instead? Maybe any links (i tried to read the refrence from the paper to Meinard Muller's chapter on this, but i couldnt figure out which distance to use from there).

Any other metrics to evaluate speech is also always welcome :)

Thank you and kind regards!

(i'm tagging u/rayeren since he posted the FS1/FS2 papers on r/MachineLearning and i think he's one of the authors. if so, can you comment on this please? :) )",https://www.reddit.com/r/LanguageTechnology/comments/nn272c/fastspeech2_dtw_computing_and_other_tts/,LanguageTechnology,t3_nn272c,"FastSpeech2 DTW computing, and other TTS evaluation methods Hi all, at the moment im working on a TTS system and i want to evaluate it. Unfortunately i can not do the usual Mean opinion score, so i'm looking at more numeric evaluations to compare my generated speech to gt.

While looking for some i found the fastspeech2 paper where they use Dynamic Time Warping (DTW) to evaluate the pitch in the generated speech. Here they explain it as: ""average DTW distances (DTW) of pitch in ground-truth and synthesized audio"".

Now, when i try to calculate the DTW with [this](https://dynamictimewarping.github.io/python/) python package i seem to get strange results. In the fast speech 2 paper their DTW distances are between 24-26. Mine are all between 9000-10000 when i try to do this.

the way i try to do this is as followed(in a short pseudo code):

    for all gt and prediction:
        distance = DTW(gt,pred)
        total += distance
    result = total/number_of_samples

I've tried several distances from the [scipy page](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html) but none of them seem to get close to the range of 24-26 (when i use the seuclidean distance i get a total of 96, but this still seems too high)

the only way i can come close to the 24-26 range is by also averaging the dtw (with normal euclidean distance) by the time series length as followed:

    for all gt and prediction:
        distance = DTW(gt,pred)/length_of_prediction
        total += distance
    result = total/number_of_samples

can someone tell me if this is correct or how i should calculate the average DTW distance instead? Maybe any links (i tried to read the refrence from the paper to Meinard Muller's chapter on this, but i couldnt figure out which distance to use from there).

Any other metrics to evaluate speech is also always welcome :)

Thank you and kind regards!

(i'm tagging u/rayeren since he posted the FS1/FS2 papers on r/MachineLearning and i think he's one of the authors. if so, can you comment on this please? :) )",2071
105,105,[P] Do Context-Aware Translation Models Pay the Right Attention?,,/r/DeepLearningPapers/comments/nmhyfr/p_do_contextaware_translation_models_pay_the/,LanguageTechnology,t3_nmuhni,[P] Do Context-Aware Translation Models Pay the Right Attention? ,65
106,106,What is considered as a small learning rate?,"I using the BERT transformer to solve the classification problem.

I am confused with the size of the learning rate of the BERT

The author suggests of using one of the following parameters

    learning rates: 3e-4, 1e-4, 5e-5, 3e-5
    
     

I know that a small learning rate makes our model learn very slow, however it also helps prevent overfitting, in contrast to big learning which learns faster but it can lead to overfitting.

&amp;#x200B;

When  I use a learning rate of 1e-5 I get the following result

    {""train"": {""eval_examples_count"": 8548, ""metrics"": {""f1_weighted"": 0.721, ""f1_macro"": 0.7201, ""accuracy"": 0.7255, ""roc_auc"": 0.8883}, ""time_spent"": ""0:02:06""}}
    {""valid"": {""eval_examples_count"": 2849, ""metrics"": {""f1_weighted"": 0.6766, ""f1_macro"": 0.6784, ""accuracy"": 0.6816, ""roc_auc"": 0.8545}, ""time_spent"": ""0:00:42""}}
    {""test"": {""eval_examples_count"": 2850, ""metrics"": {""f1_weighted"": 0.7003, ""f1_macro"": 0.7008, ""accuracy"": 0.7046, ""roc_auc"": 0.8685}, ""time_spent"": ""0:00:42""}}

However when I use 5e-5:

    {""train"": {""eval_examples_count"": 8548, ""metrics"": {""f1_weighted"": 0.1617, ""f1_macro"": 0.1647, ""accuracy"": 0.3269, ""roc_auc"": 0.5159}, ""time_spent"": ""0:02:07""}}
    {""valid"": {""eval_examples_count"": 2849, ""metrics"": {""f1_weighted"": 0.1743, ""f1_macro"": 0.1704, ""accuracy"": 0.3412, ""roc_auc"": 0.5321}, ""time_spent"": ""0:00:42""}}
    {""test"": {""eval_examples_count"": 2850, ""metrics"": {""f1_weighted"": 0.1758, ""f1_macro"": 0.1705, ""accuracy"": 0.3435, ""roc_auc"": 0.5208}, ""time_spent"": ""0:00:42""}}

IT DOES NOT LEARN ANYTHING

&amp;#x200B;

So I thought 1e-5 is small and 5e-5 is the big learning rate, am I right? 

What is the ascending order of these learning rates?

Which one considered as big and which is considered as small?",https://www.reddit.com/r/LanguageTechnology/comments/nmljji/what_is_considered_as_a_small_learning_rate/,LanguageTechnology,t3_nmljji,"What is considered as a small learning rate? I using the BERT transformer to solve the classification problem.

I am confused with the size of the learning rate of the BERT

The author suggests of using one of the following parameters

    learning rates: 3e-4, 1e-4, 5e-5, 3e-5
    
     

I know that a small learning rate makes our model learn very slow, however it also helps prevent overfitting, in contrast to big learning which learns faster but it can lead to overfitting.

&amp;#x200B;

When  I use a learning rate of 1e-5 I get the following result

    {""train"": {""eval_examples_count"": 8548, ""metrics"": {""f1_weighted"": 0.721, ""f1_macro"": 0.7201, ""accuracy"": 0.7255, ""roc_auc"": 0.8883}, ""time_spent"": ""0:02:06""}}
    {""valid"": {""eval_examples_count"": 2849, ""metrics"": {""f1_weighted"": 0.6766, ""f1_macro"": 0.6784, ""accuracy"": 0.6816, ""roc_auc"": 0.8545}, ""time_spent"": ""0:00:42""}}
    {""test"": {""eval_examples_count"": 2850, ""metrics"": {""f1_weighted"": 0.7003, ""f1_macro"": 0.7008, ""accuracy"": 0.7046, ""roc_auc"": 0.8685}, ""time_spent"": ""0:00:42""}}

However when I use 5e-5:

    {""train"": {""eval_examples_count"": 8548, ""metrics"": {""f1_weighted"": 0.1617, ""f1_macro"": 0.1647, ""accuracy"": 0.3269, ""roc_auc"": 0.5159}, ""time_spent"": ""0:02:07""}}
    {""valid"": {""eval_examples_count"": 2849, ""metrics"": {""f1_weighted"": 0.1743, ""f1_macro"": 0.1704, ""accuracy"": 0.3412, ""roc_auc"": 0.5321}, ""time_spent"": ""0:00:42""}}
    {""test"": {""eval_examples_count"": 2850, ""metrics"": {""f1_weighted"": 0.1758, ""f1_macro"": 0.1705, ""accuracy"": 0.3435, ""roc_auc"": 0.5208}, ""time_spent"": ""0:00:42""}}

IT DOES NOT LEARN ANYTHING

&amp;#x200B;

So I thought 1e-5 is small and 5e-5 is the big learning rate, am I right? 

What is the ascending order of these learning rates?

Which one considered as big and which is considered as small?",1808
107,107,XLNet - Annotated Paper + Paper Summary,"Although BERT became really popular after its release, it did have some limitations. And there were certain limitations associated with autoregressive methods like ELMo and GPT as well. XLNet was introduced to get the best of both worlds while at the same time not include their weaknesses.

In continuation of my Paper Notes series, I have written an informative summary of the paper. Personally, reading the XLNet paper was a very fun experience. I was amazed at every step, how they were including stuff to make the whole model work so well. The paper contained many interesting concepts that I had to give time to understand. So don't worry if you don't get it on the first go. Check out the links below and happy reading!

Paper Summary - [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://shreyansh26.github.io/post/2021-05-16_generalized_autoregressive_pretraining_xlnet/)

Annotated Paper - [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf)",https://www.reddit.com/r/LanguageTechnology/comments/nmr2qi/xlnet_annotated_paper_paper_summary/,LanguageTechnology,t3_nmr2qi,"XLNet - Annotated Paper + Paper Summary Although BERT became really popular after its release, it did have some limitations. And there were certain limitations associated with autoregressive methods like ELMo and GPT as well. XLNet was introduced to get the best of both worlds while at the same time not include their weaknesses.

In continuation of my Paper Notes series, I have written an informative summary of the paper. Personally, reading the XLNet paper was a very fun experience. I was amazed at every step, how they were including stuff to make the whole model work so well. The paper contained many interesting concepts that I had to give time to understand. So don't worry if you don't get it on the first go. Check out the links below and happy reading!

Paper Summary - [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://shreyansh26.github.io/post/2021-05-16_generalized_autoregressive_pretraining_xlnet/)

Annotated Paper - [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf)",1115
108,108,Paraphrase Generation given Input Sentences,"I need a good way to generate paraphrases from given input sentences. The input sentences already have the same meaning/are paraphrases. But I want more paraphrases (for example with different syntactic structures, with synonyms etc.). Ideally, I want to combine lexical and syntactic paraphrasing. What could be the state of the art solution for this problem? I read in some paper about phrase based translation methods but I don't think this suits my task. I am open for paper suggestions!",https://www.reddit.com/r/LanguageTechnology/comments/nmcowu/paraphrase_generation_given_input_sentences/,LanguageTechnology,t3_nmcowu,"Paraphrase Generation given Input Sentences I need a good way to generate paraphrases from given input sentences. The input sentences already have the same meaning/are paraphrases. But I want more paraphrases (for example with different syntactic structures, with synonyms etc.). Ideally, I want to combine lexical and syntactic paraphrasing. What could be the state of the art solution for this problem? I read in some paper about phrase based translation methods but I don't think this suits my task. I am open for paper suggestions!",535
109,109,English Paraphrasing in Python with Parrot,,https://youtu.be/FFjpQiVFPZo,LanguageTechnology,t3_nmizd0,English Paraphrasing in Python with Parrot ,43
110,110,Summarizing NLP Research Papers,,https://link.medium.com/82UC06vuBgb,LanguageTechnology,t3_nmacyt,Summarizing NLP Research Papers ,32
111,111,GPT-2 - Annotated Paper + Paper Summary,"The GPT-2 model was a major breakthrough in the path of creating a general multitask NLP system that was totally unsupervised. It demonstrated that given a large training corpus and a large model size, the language model was capable of learning the knowledge required for solving these tasks. It was not perfect, however, and performed poorly on some tasks as well.

I went through the paper and have written an informative summary of the paper. The paper was quite easy to follow and the experimentation section had interesting observations. Check out the links below and happy reading!

Paper Summary -  [Language Models are Unsupervised Multitask Learners](https://shreyansh26.github.io/post/2021-05-23_language_models_unsupervised_multitask_learners_gpt2/)

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT2.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT2.pdf)",https://www.reddit.com/r/LanguageTechnology/comments/nm39gt/gpt2_annotated_paper_paper_summary/,LanguageTechnology,t3_nm39gt,"GPT-2 - Annotated Paper + Paper Summary The GPT-2 model was a major breakthrough in the path of creating a general multitask NLP system that was totally unsupervised. It demonstrated that given a large training corpus and a large model size, the language model was capable of learning the knowledge required for solving these tasks. It was not perfect, however, and performed poorly on some tasks as well.

I went through the paper and have written an informative summary of the paper. The paper was quite easy to follow and the experimentation section had interesting observations. Check out the links below and happy reading!

Paper Summary -  [Language Models are Unsupervised Multitask Learners](https://shreyansh26.github.io/post/2021-05-23_language_models_unsupervised_multitask_learners_gpt2/)

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT2.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT2.pdf)",963
112,112,For GPT3 users - What's the longest output you've had it write?,How long was it and what was it about?,https://www.reddit.com/r/LanguageTechnology/comments/nm53h3/for_gpt3_users_whats_the_longest_output_youve_had/,LanguageTechnology,t3_nm53h3,For GPT3 users - What's the longest output you've had it write? How long was it and what was it about?,102
113,113,Transformer-XL: Attentive Language Models Beyond a Fixed Length Context,"My first youtube video discussing a research paper -

**Transformer-XL: Attentive Language Models Beyond a Fixed Length Context** [https://youtu.be/2cmVnQNWQt8](https://youtu.be/2cmVnQNWQt8) 

Check it out!",https://www.reddit.com/r/LanguageTechnology/comments/nlqr66/transformerxl_attentive_language_models_beyond_a/,LanguageTechnology,t3_nlqr66,"Transformer-XL: Attentive Language Models Beyond a Fixed Length Context My first youtube video discussing a research paper -

**Transformer-XL: Attentive Language Models Beyond a Fixed Length Context** [https://youtu.be/2cmVnQNWQt8](https://youtu.be/2cmVnQNWQt8) 

Check it out!",278
114,114,Zero-Shot Knowledge Distillation From GPT-3,"Hi there,

I recently wrote a blog post about zero-shot knowledge distillation from big language models with a method called DINO (Datasets from Instructions 🦕) that does not require any (labeled or unlabeled) data or access to model internals. The key idea is to prompt the LM to generate an entire dataset from scratch on which much smaller models can then be trained.

 I'd be very happy to hear your thoughts (both on the blog post and on the method) 😊

📝 Link: http://timoschick.com/research/2021/05/19/dino.html",https://www.reddit.com/r/LanguageTechnology/comments/nlcx98/zeroshot_knowledge_distillation_from_gpt3/,LanguageTechnology,t3_nlcx98,"Zero-Shot Knowledge Distillation From GPT-3 Hi there,

I recently wrote a blog post about zero-shot knowledge distillation from big language models with a method called DINO (Datasets from Instructions 🦕) that does not require any (labeled or unlabeled) data or access to model internals. The key idea is to prompt the LM to generate an entire dataset from scratch on which much smaller models can then be trained.

 I'd be very happy to hear your thoughts (both on the blog post and on the method) 😊

📝 Link: http://timoschick.com/research/2021/05/19/dino.html",561
115,115,Extracting topics from 250k facebook posts,"Hi there!

I'm working on a project in which I need to extract the topics from a collection of 250K facebook posts. 

Can someone recommend (in high level) what's the best approach to do something like that? Ways that will generate the best results.

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/nlfysm/extracting_topics_from_250k_facebook_posts/,LanguageTechnology,t3_nlfysm,"Extracting topics from 250k facebook posts Hi there!

I'm working on a project in which I need to extract the topics from a collection of 250K facebook posts. 

Can someone recommend (in high level) what's the best approach to do something like that? Ways that will generate the best results.

Thanks!",301
116,116,Efficient System for Grammar Error Correction on Mobile Devices (Research Paper Summary),,https://link.medium.com/tVSykpafzgb,LanguageTechnology,t3_nlau0l,Efficient System for Grammar Error Correction on Mobile Devices (Research Paper Summary) ,89
117,117,Can you classify texts without any labeled examples? Putting zero-shot classification to the test.,,https://nlp.town/blog/zero-shot-classification/,LanguageTechnology,t3_nkr5gr,Can you classify texts without any labeled examples? Putting zero-shot classification to the test. ,99
118,118,EleutherAI Develops GPT-3’s Free Alternative: GPT-Neo,"In today’s era, all top benchmarks in natural language processing are dominated by Transformer-based models. In a machine learning model, the most critical elements of the training process are the model code, training data, and available computing resources.

With the Transformer family of models, researchers have now finally come up with a way to increase the performance of a model infinitely by increasing the amount of training data and compute power.

OpenAI did this with GPT-2 and with GPT-3. They used a private corpus of 500 billion tokens for training the model and spent $50 million in computing costs.

Full Article: [https://www.marktechpost.com/2021/05/24/eleutherai-develops-gpt-3s-free-alternative-gpt-neo/](https://www.marktechpost.com/2021/05/24/eleutherai-develops-gpt-3s-free-alternative-gpt-neo/?_ga=2.62220524.1924646600.1621739878-488125022.1618729090)

Github: [https://github.com/EleutherAI/gpt-neo](https://github.com/EleutherAI/gpt-neo)",https://www.reddit.com/r/LanguageTechnology/comments/njzmmr/eleutherai_develops_gpt3s_free_alternative_gptneo/,LanguageTechnology,t3_njzmmr,"EleutherAI Develops GPT-3’s Free Alternative: GPT-Neo In today’s era, all top benchmarks in natural language processing are dominated by Transformer-based models. In a machine learning model, the most critical elements of the training process are the model code, training data, and available computing resources.

With the Transformer family of models, researchers have now finally come up with a way to increase the performance of a model infinitely by increasing the amount of training data and compute power.

OpenAI did this with GPT-2 and with GPT-3. They used a private corpus of 500 billion tokens for training the model and spent $50 million in computing costs.

Full Article: [https://www.marktechpost.com/2021/05/24/eleutherai-develops-gpt-3s-free-alternative-gpt-neo/](https://www.marktechpost.com/2021/05/24/eleutherai-develops-gpt-3s-free-alternative-gpt-neo/?_ga=2.62220524.1924646600.1621739878-488125022.1618729090)

Github: [https://github.com/EleutherAI/gpt-neo](https://github.com/EleutherAI/gpt-neo)",1019
119,119,Is there a way to score the structure of a sentence against a corpus of other sentences?,"Using Python.

Having trouble putting this question into words.

Is there a way to score the structure of a sentence against a corpus of other sentences?

So if a sentence if badly written in terms of grammar/word order, the score would be low.

I guess one would need to know the most common sentence structure within the corpus and work back from there?

Any ideas much appreciated and apologies for the vagueness of the question.",https://www.reddit.com/r/LanguageTechnology/comments/njvtsw/is_there_a_way_to_score_the_structure_of_a/,LanguageTechnology,t3_njvtsw,"Is there a way to score the structure of a sentence against a corpus of other sentences? Using Python.

Having trouble putting this question into words.

Is there a way to score the structure of a sentence against a corpus of other sentences?

So if a sentence if badly written in terms of grammar/word order, the score would be low.

I guess one would need to know the most common sentence structure within the corpus and work back from there?

Any ideas much appreciated and apologies for the vagueness of the question.",521
120,120,Tokenising SpaCy constituency parse output,"Hi all, so I'm doing some constituency parsing with SpaCy and benepar, and i'd ideally like to be able to tag the words in a sentence with their corresponding constituents. 

Currently however, Spacy allows you to print the parse string, but I'd like to be able to attach the actual syntactic structure to each word, as a POS tagger would do. So for the following code; 

    import spacy
    import benepar
    
    nlp = spacy.load('en_core_web_md')
    
    if spacy.__version__.startswith('2'):
      nlp.add_pipe('benepar', config={'model': 'benepar_en3'})
    else:
      nlp.add_pipe(""benepar"", config={""model"": ""benepar_en3""})
    
    doc = nlp(""Last Tuesday, I thought to myself that I saw a cat."")
    sent = list(doc.sents)[0]
    
    constituents = sent._.parse_string
    print(constituents)
    
    &gt;&gt;&gt; (S (NP (JJ Last) (NNP Tuesday)) (, ,) (NP (PRP I)) (VP (VBD thought) (PP (IN to) (NP (PRP myself))) (SBAR (IN that) (S (NP (PRP I)) (VP (VBD saw) (NP (DT a) (NN cat)))))) (. .))
    

I'd like for each word to be tagged with it's corresponding grammatical structure, but currently this is just one string. Any ideas on how to achieve this?",https://www.reddit.com/r/LanguageTechnology/comments/njudn4/tokenising_spacy_constituency_parse_output/,LanguageTechnology,t3_njudn4,"Tokenising SpaCy constituency parse output Hi all, so I'm doing some constituency parsing with SpaCy and benepar, and i'd ideally like to be able to tag the words in a sentence with their corresponding constituents. 

Currently however, Spacy allows you to print the parse string, but I'd like to be able to attach the actual syntactic structure to each word, as a POS tagger would do. So for the following code; 

    import spacy
    import benepar
    
    nlp = spacy.load('en_core_web_md')
    
    if spacy.__version__.startswith('2'):
      nlp.add_pipe('benepar', config={'model': 'benepar_en3'})
    else:
      nlp.add_pipe(""benepar"", config={""model"": ""benepar_en3""})
    
    doc = nlp(""Last Tuesday, I thought to myself that I saw a cat."")
    sent = list(doc.sents)[0]
    
    constituents = sent._.parse_string
    print(constituents)
    
    &gt;&gt;&gt; (S (NP (JJ Last) (NNP Tuesday)) (, ,) (NP (PRP I)) (VP (VBD thought) (PP (IN to) (NP (PRP myself))) (SBAR (IN that) (S (NP (PRP I)) (VP (VBD saw) (NP (DT a) (NN cat)))))) (. .))
    

I'd like for each word to be tagged with it's corresponding grammatical structure, but currently this is just one string. Any ideas on how to achieve this?",1211
121,121,Get POS tags for multiple spacy documents,"EDIT - solved 

I have a list of strings, which I have turned into SpaCy documents in order to be able to POS tag each string as such; 

    example_sents = [nlp(sent) for sent in example_sents[0:2]]
    print(example_sents)
    
    &gt;&gt;&gt; [well as long as you accept that it is  testing uhyou know  alleviate, she cant accept that we want to be the care givers]

However, when I try and POS tag multiple strings, I get the error 'AttributeError: 'spacy.tokens.doc.Doc' object has no attribute 'pos\_''

Does anyone know why this is happening when I try to iterate over each spacy document as such; 

    for token in example_sents[1:2]:
      print(token.text, token.pos_)

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/njzz7v/get_pos_tags_for_multiple_spacy_documents/,LanguageTechnology,t3_njzz7v,"Get POS tags for multiple spacy documents EDIT - solved 

I have a list of strings, which I have turned into SpaCy documents in order to be able to POS tag each string as such; 

    example_sents = [nlp(sent) for sent in example_sents[0:2]]
    print(example_sents)
    
    &gt;&gt;&gt; [well as long as you accept that it is  testing uhyou know  alleviate, she cant accept that we want to be the care givers]

However, when I try and POS tag multiple strings, I get the error 'AttributeError: 'spacy.tokens.doc.Doc' object has no attribute 'pos\_''

Does anyone know why this is happening when I try to iterate over each spacy document as such; 

    for token in example_sents[1:2]:
      print(token.text, token.pos_)

Thanks!",731
122,122,Analyzing the vast coronavirus literature with CoronaCentral,,https://www.pnas.org/content/118/23/e2100766118,LanguageTechnology,t3_nju4az,Analyzing the vast coronavirus literature with CoronaCentral ,61
123,123,Controllable Text Summarization in Python based on CtrlSum,,https://www.youtube.com/watch?v=P8CqGqR1Zr4,LanguageTechnology,t3_nk1w7q,Controllable Text Summarization in Python based on CtrlSum ,59
124,124,One sentence highlight for every NAACL-2021 Paper,"Here is the list of all NAACL-2021 (Annual Conference of the North American Chapter of the Association for Computational Linguistics) papers, and a one sentence highlight for each of them. The proceeding was released today.

[https://www.paperdigest.org/2021/05/naacl-2021-highlights/](https://www.paperdigest.org/2021/05/naacl-2021-highlights/)",https://www.reddit.com/r/LanguageTechnology/comments/njkuau/one_sentence_highlight_for_every_naacl2021_paper/,LanguageTechnology,t3_njkuau,"One sentence highlight for every NAACL-2021 Paper Here is the list of all NAACL-2021 (Annual Conference of the North American Chapter of the Association for Computational Linguistics) papers, and a one sentence highlight for each of them. The proceeding was released today.

[https://www.paperdigest.org/2021/05/naacl-2021-highlights/](https://www.paperdigest.org/2021/05/naacl-2021-highlights/)",395
125,125,Advanced Math for NLP,"I am in my last year of undergraduate studies and want to use my electives on math. Other than basic math like Probability theory, Statistics, Linear Algebra, or Multivariate Calculus, are there any other important math classes that would be beneficial for a career or research in NLP in 2021-2022?

I assume ODEs can help with Neural Nets and higher statistics are always beneficial but there must be more.",https://www.reddit.com/r/LanguageTechnology/comments/njibcy/advanced_math_for_nlp/,LanguageTechnology,t3_njibcy,"Advanced Math for NLP I am in my last year of undergraduate studies and want to use my electives on math. Other than basic math like Probability theory, Statistics, Linear Algebra, or Multivariate Calculus, are there any other important math classes that would be beneficial for a career or research in NLP in 2021-2022?

I assume ODEs can help with Neural Nets and higher statistics are always beneficial but there must be more.",429
126,126,Search on vector embeddings,"What would be the way to go for a search engine to search on similar words. When I check txtai or similar implementations they use pooling (averaging) on words. What I am looking for is that if i search on a query of 3 words for example that it searches for the 100 closest words (cosine similarity) for each word and creates some rank. But this rank should not be compromised by matching words of only one semantic meaning. 
Example if I search for:  “great iphone tutorials” this ranking should not be compromised by documents with a lot of matching similarities for “great” with no mentioning for iphone and tutorials.",https://www.reddit.com/r/LanguageTechnology/comments/njc3wk/search_on_vector_embeddings/,LanguageTechnology,t3_njc3wk,"Search on vector embeddings What would be the way to go for a search engine to search on similar words. When I check txtai or similar implementations they use pooling (averaging) on words. What I am looking for is that if i search on a query of 3 words for example that it searches for the 100 closest words (cosine similarity) for each word and creates some rank. But this rank should not be compromised by matching words of only one semantic meaning. 
Example if I search for:  “great iphone tutorials” this ranking should not be compromised by documents with a lot of matching similarities for “great” with no mentioning for iphone and tutorials.",649
127,127,NLP : Access feature vector from Pipeline object,"I am new to machine learning.  I am trying to build a text classifier.

I have the following code:

    title_tfidf = TfidfVectorizer(use_idf=True, max_df=0.12, stop_words='english', preprocessor=custom_preprocessor) 
    text_tfidf = TfidfVectorizer(use_idf=True, max_df=0.12, stop_words='english', preprocessor=custom_preprocessor)  
    
    preprocess = ColumnTransformer([('title_tfidf', title_tfidf, 'Title'), ('text_tfidf', text_tfidf, 'Text')])  
    
    model = make_pipeline(preprocess, LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000))  
    
    model.fit(x_train, y_train)

I access the feature-names list and coefficients in the following way:

    regressor = model.named_steps['logisticregression'] 
    print (""Coefficients: "", regressor.coef_) 
    feature_names = preprocess.get_feature_names()

how can one retrieve the feature vector?

Would be grateful for any inputs!",https://www.reddit.com/r/LanguageTechnology/comments/njs41v/nlp_access_feature_vector_from_pipeline_object/,LanguageTechnology,t3_njs41v,"NLP : Access feature vector from Pipeline object I am new to machine learning.  I am trying to build a text classifier.

I have the following code:

    title_tfidf = TfidfVectorizer(use_idf=True, max_df=0.12, stop_words='english', preprocessor=custom_preprocessor) 
    text_tfidf = TfidfVectorizer(use_idf=True, max_df=0.12, stop_words='english', preprocessor=custom_preprocessor)  
    
    preprocess = ColumnTransformer([('title_tfidf', title_tfidf, 'Title'), ('text_tfidf', text_tfidf, 'Text')])  
    
    model = make_pipeline(preprocess, LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000))  
    
    model.fit(x_train, y_train)

I access the feature-names list and coefficients in the following way:

    regressor = model.named_steps['logisticregression'] 
    print (""Coefficients: "", regressor.coef_) 
    feature_names = preprocess.get_feature_names()

how can one retrieve the feature vector?

Would be grateful for any inputs!",989
128,128,Interesting seminars and talks?,"I have to attend a quota of seminars as part of my degree, but the offerings at my university are a bit limited. Is there an equivalent to [http://researchseminars.org/](http://researchseminars.org/) for language technology / computation linguistics / that sort of space?

Or, if you don't know of a large universal one, does your research group have a website where you publish your upcoming seminars?",https://www.reddit.com/r/LanguageTechnology/comments/njoaqt/interesting_seminars_and_talks/,LanguageTechnology,t3_njoaqt,"Interesting seminars and talks? I have to attend a quota of seminars as part of my degree, but the offerings at my university are a bit limited. Is there an equivalent to [http://researchseminars.org/](http://researchseminars.org/) for language technology / computation linguistics / that sort of space?

Or, if you don't know of a large universal one, does your research group have a website where you publish your upcoming seminars?",434
129,129,A Graph-based Text Similarity Method with Named Entity Information in NLP,,https://medium.com/p/abc7f1201d96?source=linkShare-bcb8dddfcc90-1621765097,LanguageTechnology,t3_nj4xc6,A Graph-based Text Similarity Method with Named Entity Information in NLP ,74
130,130,Spanish keyword extraction [D],"Hey guys am creating a keyword extraction model to get keywords from text, for Spanish language. Any and all resources or ideas are welcome. Thanks 😊",https://www.reddit.com/r/LanguageTechnology/comments/njgmwd/spanish_keyword_extraction_d/,LanguageTechnology,t3_njgmwd,"Spanish keyword extraction [D] Hey guys am creating a keyword extraction model to get keywords from text, for Spanish language. Any and all resources or ideas are welcome. Thanks 😊",180
131,131,Laptop for deep learning,"Hello,

What is the best laptops for deep learning under 1000$?

Thank you",https://www.reddit.com/r/LanguageTechnology/comments/nj4xvz/laptop_for_deep_learning/,LanguageTechnology,t3_nj4xvz,"Laptop for deep learning Hello,

What is the best laptops for deep learning under 1000$?

Thank you",99
132,132,Classification of bank statement transactions,"Hello everybody, I am a student working on his bachelor thesis.. I have a some ML background but I am quite new to NLP.

Shortly, the goal of my thesis is to extract text from CSV bank transactions files and EBICS exports and categorize them into about 20 categories.. So far I have tried with a basic Naive-Bayes classificator getting +- 65% accuracy but nothing more.. do you have any tips on some specific models or papers that could help me achieve a higher precision?

To add some more details, the bank statements that I have so far are not that big in terms of transactions, I have about 400 rows of data right now.. this is probably impacting the accuracy but it's kinda a long process to gather those kind of files.

Additionally, the data from the CVS and EBIC files are quite short sentences.. around 60/80 characters per line.

Thanks in advance for any suggestion! have a nice day :)",https://www.reddit.com/r/LanguageTechnology/comments/nje9nc/classification_of_bank_statement_transactions/,LanguageTechnology,t3_nje9nc,"Classification of bank statement transactions Hello everybody, I am a student working on his bachelor thesis.. I have a some ML background but I am quite new to NLP.

Shortly, the goal of my thesis is to extract text from CSV bank transactions files and EBICS exports and categorize them into about 20 categories.. So far I have tried with a basic Naive-Bayes classificator getting +- 65% accuracy but nothing more.. do you have any tips on some specific models or papers that could help me achieve a higher precision?

To add some more details, the bank statements that I have so far are not that big in terms of transactions, I have about 400 rows of data right now.. this is probably impacting the accuracy but it's kinda a long process to gather those kind of files.

Additionally, the data from the CVS and EBIC files are quite short sentences.. around 60/80 characters per line.

Thanks in advance for any suggestion! have a nice day :)",942
133,133,How to write a code/mini program that collects articles?,"To clarify, is it difficult for a non-programmer to write a code or mini program that would collect articles based on several simple criteria or maybe there are some other solutions for this purpose?

Example: I want to collect and gather all articles published on BBC website between January 2021 and April 2021 that contain the word ""doggo"" for the purposes of corpus linguistics. 

I am aware of BootCat but I never managed to get it work properly, though",https://www.reddit.com/r/LanguageTechnology/comments/nimrip/how_to_write_a_codemini_program_that_collects/,LanguageTechnology,t3_nimrip,"How to write a code/mini program that collects articles? To clarify, is it difficult for a non-programmer to write a code or mini program that would collect articles based on several simple criteria or maybe there are some other solutions for this purpose?

Example: I want to collect and gather all articles published on BBC website between January 2021 and April 2021 that contain the word ""doggo"" for the purposes of corpus linguistics. 

I am aware of BootCat but I never managed to get it work properly, though",515
134,134,An Efficient System for Grammatical Error Correction on Mobile Devices (Research Paper Walkthrough),,https://youtu.be/3rVn14m8zaM,LanguageTechnology,t3_nidynd,An Efficient System for Grammatical Error Correction on Mobile Devices (Research Paper Walkthrough) ,100
135,135,gImageReader/Tesseract: Having trouble with old texts and spaces between words,"I'm working with some older texts, were the letters are sometimes a little smudgy.

The letters and words get recognized near-perfectly, and when I look at the hOCR or html file, the text looks perfect.

But when I **export to PDF** with an invisible text layer the spaces between words frequently go missing, for paragraphs at a time. This is annoying when trying to highlight parts of the text and then copy-paste those excerpts.

Any advice?

Other than these old texts, gImageReader is absolutely amazing and does exactly what I want.",https://www.reddit.com/r/LanguageTechnology/comments/nidwks/gimagereadertesseract_having_trouble_with_old/,LanguageTechnology,t3_nidwks,"gImageReader/Tesseract: Having trouble with old texts and spaces between words I'm working with some older texts, were the letters are sometimes a little smudgy.

The letters and words get recognized near-perfectly, and when I look at the hOCR or html file, the text looks perfect.

But when I **export to PDF** with an invisible text layer the spaces between words frequently go missing, for paragraphs at a time. This is annoying when trying to highlight parts of the text and then copy-paste those excerpts.

Any advice?

Other than these old texts, gImageReader is absolutely amazing and does exactly what I want.",617
136,136,Automating a Web Scraper,"I'm trying to automate the process of web scraping. I have a dataset of real-estate data with fields like Title, Price, Street, Postcode, etc. I want to make a model that takes the content of a webpage and returns words/phrases that are similar to/match those in the dataset. This way I won't have to write a custom web scraper for every website. I think this is similar to keyword extraction except that I want the model to learn a dataset of keywords and then extract those keywords from a webpage.

Can anyone guide me on how to approach this problem?",https://www.reddit.com/r/LanguageTechnology/comments/nie7t0/automating_a_web_scraper/,LanguageTechnology,t3_nie7t0,"Automating a Web Scraper I'm trying to automate the process of web scraping. I have a dataset of real-estate data with fields like Title, Price, Street, Postcode, etc. I want to make a model that takes the content of a webpage and returns words/phrases that are similar to/match those in the dataset. This way I won't have to write a custom web scraper for every website. I think this is similar to keyword extraction except that I want the model to learn a dataset of keywords and then extract those keywords from a webpage.

Can anyone guide me on how to approach this problem?",579
137,137,Using document formatting for NLU,"Can anyone recommend any NLU services, libraries, or methods that can perform NLU tasks using both language tokens and simple document formatting such as indentation level. For example, in lecture notes, indentations could help refine coreference resolution by understanding that there’s a good chance indented text is highly related to less indented text on an earlier document line or paragraph.",https://www.reddit.com/r/LanguageTechnology/comments/ni48rc/using_document_formatting_for_nlu/,LanguageTechnology,t3_ni48rc,"Using document formatting for NLU Can anyone recommend any NLU services, libraries, or methods that can perform NLU tasks using both language tokens and simple document formatting such as indentation level. For example, in lecture notes, indentations could help refine coreference resolution by understanding that there’s a good chance indented text is highly related to less indented text on an earlier document line or paragraph.",431
138,138,Is Word Sense Disambiguation outdated?,"I recently published a blog post about how the original WSD task formulation is not suitable for modern domain-specific and enterprise disambiguation settings and how Target Sense Verification can improve this situation. Here is the link: [https://annabreit.medium.com/is-word-sense-disambiguation-outdated-ef05a139576](https://annabreit.medium.com/is-word-sense-disambiguation-outdated-ef05a139576)  


Would be glad for any feedback and am happy to discuss!",https://www.reddit.com/r/LanguageTechnology/comments/nhohkx/is_word_sense_disambiguation_outdated/,LanguageTechnology,t3_nhohkx,"Is Word Sense Disambiguation outdated? I recently published a blog post about how the original WSD task formulation is not suitable for modern domain-specific and enterprise disambiguation settings and how Target Sense Verification can improve this situation. Here is the link: [https://annabreit.medium.com/is-word-sense-disambiguation-outdated-ef05a139576](https://annabreit.medium.com/is-word-sense-disambiguation-outdated-ef05a139576)  


Would be glad for any feedback and am happy to discuss!",498
139,139,Text Extraction,New to NLP. Can anyone suggest me how I can use NLP to extract important details from large documents? Thanks in advance.,https://www.reddit.com/r/LanguageTechnology/comments/nhnpyv/text_extraction/,LanguageTechnology,t3_nhnpyv,Text Extraction New to NLP. Can anyone suggest me how I can use NLP to extract important details from large documents? Thanks in advance.,137
140,140,Automatic Extraction of Hypernym Relations from Text,,https://link.medium.com/r22yL4WTqgb,LanguageTechnology,t3_nhlyzg,Automatic Extraction of Hypernym Relations from Text ,53
141,141,"1 line to visualizations for dependency trees, entity relationships, resolution, assertion, NER and new models for Afrikaans, Welsh, Maltese, Tamil, and Vietnamese - John Snow Labs NLU 3.0.1 for Python","# NLU 3.0.1 Release Notes
We are very excited to announce NLU 3.0.1 has been released!
This is one of the most visually appealing releases, with the integration of the [Spark-NLP-Display](https://nlp.johnsnowlabs.com/docs/en/display) library and visualizations for `dependency trees`, `entity resolution`, `entity assertion`, `relationship between entities` and `named
entity recognition`. In addition to this, the schema of how columns are named by NLU has been reworked and all 140+ tutorial notebooks have been updated to reflect the latest changes in NLU 3.0.0+
Finally, new multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese` are now available.




# New Features and Enhancements
- 1 line to visualization for `NER`, `Dependency`, `Resolution`, `Assertion` and `Relation` via [Spark-NLP-Display](https://nlp.johnsnowlabs.com/docs/en/display) integration
- Improved column naming schema
- [Over 140 + NLU tutorial Notebooks updated](https://github.com/JohnSnowLabs/nlu/tree/master/examples) and improved to reflect latest changes in NLU 3.0.0 +
- New multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese`
- Enhanced offline loading


## NLU visualization
The latest NLU release integrated the beautiful Spark-NLP-Display package visualizations. You do not need to worry about installing it, when you try to visualize something, NLU will check if
Spark-NLP-Display is installed, if it is missing it will be dynamically installed into your python executable environment, so you don't need to worry about anything!

See the [visualization tutorial notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/visualization/NLU_visualizations_tutorial.ipynb)  and [visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples) for more info.

![Cheat Sheet visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/cheat_sheet.png)

## NER visualization
Applicable to any of the [100+ NER models! See here for an overview](https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition)
```python
nlu.load('ner').viz(""Donald Trump from America and Angela Merkel from Germany don't share many oppinions."")
```
![NER visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/NER.png)

## Dependency tree visualization
Visualizes the structure of the labeled dependency tree and part of speech tags
```python
nlu.load('dep.typed').viz(""Billy went to the mall"")
```

![Dependency Tree visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP.png)

```python
#Bigger Example
nlu.load('dep.typed').viz(""Donald Trump from America and Angela Merkel from Germany don't share many oppinions but they both love John Snow Labs software"")
```
![Dependency Tree visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP_big.png)

## Assertion status visualization
Visualizes asserted statuses and entities.        
Applicable to any of the [10 + Assertion models! See here for an overview](https://nlp.johnsnowlabs.com/models?task=Assertion+Status)
```python
nlu.load('med_ner.clinical assert').viz(""The MRI scan showed no signs of cancer in the left lung"")
```


![Assert visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion.png)

```python
#bigger example
data ='This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed.'
nlu.load('med_ner.clinical assert').viz(data)
```
![Assert visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion_big.png)


## Relationship between entities visualization
Visualizes the extracted entities between relationship.    
Applicable to any of the [20 + Relation Extractor models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Relation+Extraction)
```python
nlu.load('med_ner.jsl.wip.clinical relation.temporal_events').viz('The patient developed cancer after a mercury poisoning in 1999 ')
```
![Entity Relation visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation.png)

```python
# bigger example
data = 'This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed'
pipe = nlu.load('med_ner.jsl.wip.clinical relation.clinical').viz(data)
```
![Entity Relation visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation_big.png)


## Entity Resolution visualization for chunks
Visualizes resolutions of entities
Applicable to any of the [100+ Resolver models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Entity+Resolution)
```python
nlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(""He took Prevacid 30 mg  daily"")
```
![Chunk Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk.png)

```python
# bigger example
data = ""This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret\'s Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .""
nlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(data)
```

![Chunk Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk_big.png)


## Entity Resolution visualization for sentences
Visualizes resolutions of entities in sentences
Applicable to any of the [100+ Resolver models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Entity+Resolution)
```python
nlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz('She was diagnosed with a respiratory congestion')
```
![Sentence Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence.png)

```python
# bigger example
data = 'The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion'
nlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz(data)
```
![Sentence Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence_big.png)

## Configure visualizations
### Define custom colors for labels
Some entity and relation labels will be highlighted with a pre-defined color, which you [can find here](https://github.com/JohnSnowLabs/spark-nlp-display/tree/main/sparknlp_display/label_colors).    
For labels that have no color defined, a random color will be generated.     
You can define colors for labels manually, by specifying via the `viz_colors` parameter
and defining `hex color codes` in a dictionary that maps `labels` to `colors` .
```python
data = 'Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough'
# Define custom colors for labels
viz_colors={'STRENGTH':'#800080', 'DRUG_BRANDNAME':'#77b5fe', 'GENDER':'#77ffe'}
nlu.load('med_ner.jsl.wip.clinical').viz(data,viz_colors =viz_colors)
```
![define colors labels](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/define_colors.png)


### Filter entities that get highlighted
By default every entity class will be visualized.    
The `labels_to_viz` can be used to define a set of labels to highlight.       
Applicable for ner, resolution and assert.
```python
data = 'Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough'
# Filter wich NER label to viz
labels_to_viz=['SYMPTOM']
nlu.load('med_ner.jsl.wip.clinical').viz(data,labels_to_viz=labels_to_viz)
```
![filter labels](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/filter_labels.png)


## New models
New multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese`

| nlu.load() Refrence                                          | Spark NLP Refrence                                           |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [vi.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) |
| [mt.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) |
| [ta.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) |
| [af.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) |
| [af.pos](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) | [pos_afribooms](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) |
| [cy.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) |

## Reworked and updated NLU tutorial notebooks

All of the [140+ NLU tutorial Notebooks](https://github.com/JohnSnowLabs/nlu/tree/master/examples) have been updated and reworked to reflect the latest changes in NLU 3.0.0+


## Improved Column Name generation
- NLU categorized each internal component now with boolean labels for `name_deductable` and `always_name_deductable` .
- Before generating column names, NLU checks wether each component is of unique in the pipeline or not. If a component is not unique in the
  pipe and there are multiple components of same type, i.e. multiple `NER` models, NLU will deduct a base name for the final output columns from the
  NLU reference each NER model is pointing to.
- If on the other hand, there is only one `NER` model in the pipeline, only the default `ner` column prefixed will be generated.
- For some components, like `embeddings` and `classifiers` are now defined as `always_name_deductable`, for those NLU will always try to infer a meaningful base name for the output columns.
- Newly trained component output columns will now be prefixed with `trained_&lt;type&gt;` , for types `pos` , `ner`, `cLassifier`, `sentiment` and `multi_classifier`

## Enhanced offline mode
- You can still load a model from a path as usual with `nlu.load(path=model_path)` and output columns will be suffixed with `from_disk`
- You can now optionally also specify `request` parameter during  load a model from HDD, it will be used to deduct more meaningful column name suffixes, instead of `from_disk`, i.e. by calling `nlu.load(request ='en.embed_sentence.biobert.pubmed_pmc_base_cased', path=model_path)`


### Bugfixes
- Fixed a bug that caused  resolution algorithms output level to be inferred incorrectly
- Fixed a bug that caused stranger cols got dropped
- Fixed a bug that caused endings to miss when  .predict(position=True) was specified
- Fixed a bug that caused pd.Series to be converted incorrectly internally
- Fixed a bug that caused output level transformations to crash
- Fixed a bug that caused verbose mode not to turn of properly after turning it on.
- fixed a bug that caused some models to crash when loaded for HDD

# Additional NLU resources
* [140+ updates tutorials](https://github.com/JohnSnowLabs/nlu/tree/master/examples)
* [Updated visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples)
* [Models Hub](https://nlp.johnsnowlabs.com/models) with new models
* [Spark NLP publications](https://medium.com/spark-nlp)
* [NLU in Action](https://nlp.johnsnowlabs.com/demo)
* [NLU documentation](https://nlu.johnsnowlabs.com/docs/en/install)
* [Discussions](https://github.com/JohnSnowLabs/spark-nlp/discussions) Engage with other community members, share ideas, and show off how you use Spark NLP and NLU!

# 1 line Install NLU on Google Colab
```!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash```
# 1 line Install NLU on Kaggle
```!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash```
# Install via PIP
```! pip install nlu pyspark==3.0.1```",https://www.reddit.com/r/LanguageTechnology/comments/nh4qzh/1_line_to_visualizations_for_dependency_trees/,LanguageTechnology,t3_nh4qzh,"1 line to visualizations for dependency trees, entity relationships, resolution, assertion, NER and new models for Afrikaans, Welsh, Maltese, Tamil, and Vietnamese - John Snow Labs NLU 3.0.1 for Python # NLU 3.0.1 Release Notes
We are very excited to announce NLU 3.0.1 has been released!
This is one of the most visually appealing releases, with the integration of the [Spark-NLP-Display](https://nlp.johnsnowlabs.com/docs/en/display) library and visualizations for `dependency trees`, `entity resolution`, `entity assertion`, `relationship between entities` and `named
entity recognition`. In addition to this, the schema of how columns are named by NLU has been reworked and all 140+ tutorial notebooks have been updated to reflect the latest changes in NLU 3.0.0+
Finally, new multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese` are now available.




# New Features and Enhancements
- 1 line to visualization for `NER`, `Dependency`, `Resolution`, `Assertion` and `Relation` via [Spark-NLP-Display](https://nlp.johnsnowlabs.com/docs/en/display) integration
- Improved column naming schema
- [Over 140 + NLU tutorial Notebooks updated](https://github.com/JohnSnowLabs/nlu/tree/master/examples) and improved to reflect latest changes in NLU 3.0.0 +
- New multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese`
- Enhanced offline loading


## NLU visualization
The latest NLU release integrated the beautiful Spark-NLP-Display package visualizations. You do not need to worry about installing it, when you try to visualize something, NLU will check if
Spark-NLP-Display is installed, if it is missing it will be dynamically installed into your python executable environment, so you don't need to worry about anything!

See the [visualization tutorial notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/visualization/NLU_visualizations_tutorial.ipynb)  and [visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples) for more info.

![Cheat Sheet visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/cheat_sheet.png)

## NER visualization
Applicable to any of the [100+ NER models! See here for an overview](https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition)
```python
nlu.load('ner').viz(""Donald Trump from America and Angela Merkel from Germany don't share many oppinions."")
```
![NER visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/NER.png)

## Dependency tree visualization
Visualizes the structure of the labeled dependency tree and part of speech tags
```python
nlu.load('dep.typed').viz(""Billy went to the mall"")
```

![Dependency Tree visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP.png)

```python
#Bigger Example
nlu.load('dep.typed').viz(""Donald Trump from America and Angela Merkel from Germany don't share many oppinions but they both love John Snow Labs software"")
```
![Dependency Tree visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP_big.png)

## Assertion status visualization
Visualizes asserted statuses and entities.        
Applicable to any of the [10 + Assertion models! See here for an overview](https://nlp.johnsnowlabs.com/models?task=Assertion+Status)
```python
nlu.load('med_ner.clinical assert').viz(""The MRI scan showed no signs of cancer in the left lung"")
```


![Assert visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion.png)

```python
#bigger example
data ='This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed.'
nlu.load('med_ner.clinical assert').viz(data)
```
![Assert visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion_big.png)


## Relationship between entities visualization
Visualizes the extracted entities between relationship.    
Applicable to any of the [20 + Relation Extractor models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Relation+Extraction)
```python
nlu.load('med_ner.jsl.wip.clinical relation.temporal_events').viz('The patient developed cancer after a mercury poisoning in 1999 ')
```
![Entity Relation visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation.png)

```python
# bigger example
data = 'This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed'
pipe = nlu.load('med_ner.jsl.wip.clinical relation.clinical').viz(data)
```
![Entity Relation visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation_big.png)


## Entity Resolution visualization for chunks
Visualizes resolutions of entities
Applicable to any of the [100+ Resolver models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Entity+Resolution)
```python
nlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(""He took Prevacid 30 mg  daily"")
```
![Chunk Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk.png)

```python
# bigger example
data = ""This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret\'s Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .""
nlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(data)
```

![Chunk Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk_big.png)


## Entity Resolution visualization for sentences
Visualizes resolutions of entities in sentences
Applicable to any of the [100+ Resolver models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Entity+Resolution)
```python
nlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz('She was diagnosed with a respiratory congestion')
```
![Sentence Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence.png)

```python
# bigger example
data = 'The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion'
nlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz(data)
```
![Sentence Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence_big.png)

## Configure visualizations
### Define custom colors for labels
Some entity and relation labels will be highlighted with a pre-defined color, which you [can find here](https://github.com/JohnSnowLabs/spark-nlp-display/tree/main/sparknlp_display/label_colors).    
For labels that have no color defined, a random color will be generated.     
You can define colors for labels manually, by specifying via the `viz_colors` parameter
and defining `hex color codes` in a dictionary that maps `labels` to `colors` .
```python
data = 'Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough'
# Define custom colors for labels
viz_colors={'STRENGTH':'#800080', 'DRUG_BRANDNAME':'#77b5fe', 'GENDER':'#77ffe'}
nlu.load('med_ner.jsl.wip.clinical').viz(data,viz_colors =viz_colors)
```
![define colors labels](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/define_colors.png)


### Filter entities that get highlighted
By default every entity class will be visualized.    
The `labels_to_viz` can be used to define a set of labels to highlight.       
Applicable for ner, resolution and assert.
```python
data = 'Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough'
# Filter wich NER label to viz
labels_to_viz=['SYMPTOM']
nlu.load('med_ner.jsl.wip.clinical').viz(data,labels_to_viz=labels_to_viz)
```
![filter labels](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/filter_labels.png)


## New models
New multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese`

| nlu.load() Refrence                                          | Spark NLP Refrence                                           |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [vi.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) |
| [mt.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) |
| [ta.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) |
| [af.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) |
| [af.pos](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) | [pos_afribooms](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) |
| [cy.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) |

## Reworked and updated NLU tutorial notebooks

All of the [140+ NLU tutorial Notebooks](https://github.com/JohnSnowLabs/nlu/tree/master/examples) have been updated and reworked to reflect the latest changes in NLU 3.0.0+


## Improved Column Name generation
- NLU categorized each internal component now with boolean labels for `name_deductable` and `always_name_deductable` .
- Before generating column names, NLU checks wether each component is of unique in the pipeline or not. If a component is not unique in the
  pipe and there are multiple components of same type, i.e. multiple `NER` models, NLU will deduct a base name for the final output columns from the
  NLU reference each NER model is pointing to.
- If on the other hand, there is only one `NER` model in the pipeline, only the default `ner` column prefixed will be generated.
- For some components, like `embeddings` and `classifiers` are now defined as `always_name_deductable`, for those NLU will always try to infer a meaningful base name for the output columns.
- Newly trained component output columns will now be prefixed with `trained_&lt;type&gt;` , for types `pos` , `ner`, `cLassifier`, `sentiment` and `multi_classifier`

## Enhanced offline mode
- You can still load a model from a path as usual with `nlu.load(path=model_path)` and output columns will be suffixed with `from_disk`
- You can now optionally also specify `request` parameter during  load a model from HDD, it will be used to deduct more meaningful column name suffixes, instead of `from_disk`, i.e. by calling `nlu.load(request ='en.embed_sentence.biobert.pubmed_pmc_base_cased', path=model_path)`


### Bugfixes
- Fixed a bug that caused  resolution algorithms output level to be inferred incorrectly
- Fixed a bug that caused stranger cols got dropped
- Fixed a bug that caused endings to miss when  .predict(position=True) was specified
- Fixed a bug that caused pd.Series to be converted incorrectly internally
- Fixed a bug that caused output level transformations to crash
- Fixed a bug that caused verbose mode not to turn of properly after turning it on.
- fixed a bug that caused some models to crash when loaded for HDD

# Additional NLU resources
* [140+ updates tutorials](https://github.com/JohnSnowLabs/nlu/tree/master/examples)
* [Updated visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples)
* [Models Hub](https://nlp.johnsnowlabs.com/models) with new models
* [Spark NLP publications](https://medium.com/spark-nlp)
* [NLU in Action](https://nlp.johnsnowlabs.com/demo)
* [NLU documentation](https://nlu.johnsnowlabs.com/docs/en/install)
* [Discussions](https://github.com/JohnSnowLabs/spark-nlp/discussions) Engage with other community members, share ideas, and show off how you use Spark NLP and NLU!

# 1 line Install NLU on Google Colab
```!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash```
# 1 line Install NLU on Kaggle
```!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash```
# Install via PIP
```! pip install nlu pyspark==3.0.1```",16577
142,142,Dataset to study structure of comparison questions," I have to study the structure of questions comparing electronic products, e.g., Computers, Laptops, Tablets, etc.

Example questions:

1. What are the disadvantages of a Chromebook as opposed to a regular laptop computer?
2. what are the pros and cons of buying a dell laptop?
3. what can a $1000 apple laptop do which $500 Lenovo laptop not? is an expensive one worth it?
4. are hp laptops good for students?

I would be grateful If anyone can provide a lead to such a dataset. Currently, I am looking at questions on Quora, Reddit, and other forums manually.",https://www.reddit.com/r/LanguageTechnology/comments/nh2flv/dataset_to_study_structure_of_comparison_questions/,LanguageTechnology,t3_nh2flv,"Dataset to study structure of comparison questions  I have to study the structure of questions comparing electronic products, e.g., Computers, Laptops, Tablets, etc.

Example questions:

1. What are the disadvantages of a Chromebook as opposed to a regular laptop computer?
2. what are the pros and cons of buying a dell laptop?
3. what can a $1000 apple laptop do which $500 Lenovo laptop not? is an expensive one worth it?
4. are hp laptops good for students?

I would be grateful If anyone can provide a lead to such a dataset. Currently, I am looking at questions on Quora, Reddit, and other forums manually.",612
143,143,Looking to extract insights from your unstructured text? Check out this article on how to combine NLP and knowledge graphs to uncover new information.,"If you have a specific use case that can benefit from knowledge graphs, please share below, we would love to learn about the different applications of NLP. If you have any question, please reply below or send an email at [admin@ubiai.tools](mailto:admin@ubiai.tools)

&amp;#x200B;

[https://walidamamou.medium.com/building-a-knowledge-graph-for-job-search-using-bert-transformer-8677c8b3a2e7](https://walidamamou.medium.com/building-a-knowledge-graph-for-job-search-using-bert-transformer-8677c8b3a2e7)",https://www.reddit.com/r/LanguageTechnology/comments/nhhp3y/looking_to_extract_insights_from_your/,LanguageTechnology,t3_nhhp3y,"Looking to extract insights from your unstructured text? Check out this article on how to combine NLP and knowledge graphs to uncover new information. If you have a specific use case that can benefit from knowledge graphs, please share below, we would love to learn about the different applications of NLP. If you have any question, please reply below or send an email at [admin@ubiai.tools](mailto:admin@ubiai.tools)

&amp;#x200B;

[https://walidamamou.medium.com/building-a-knowledge-graph-for-job-search-using-bert-transformer-8677c8b3a2e7](https://walidamamou.medium.com/building-a-knowledge-graph-for-job-search-using-bert-transformer-8677c8b3a2e7)",653
144,144,How does Google Translate's add-on translates a web page so perfectly?,"I'm talking about the little translate button at the top left (can't put images).

&amp;#x200B;

As I understood it takes the html and translates the text in it. What I can't comprehend is it fits the correct words perfectly, for example in the &lt;strong&gt; tag.

For example &lt;p&gt;there is &lt;strong&gt;some text here&lt;/strong&gt; google will translate it&lt;/p&gt;

After the translation google finds the exact match to put inside the &lt;strong&gt; tag. They can't translate it separately it would distort the meaning. Even sentence is complex and inside the tag does not make a sentence on its own they handle it somehow.

I tried to make it as clear as possible. I've been searching but I couldn't come up with a solution. Do you have any ideas? Please share.

&amp;#x200B;

Edit (Clarification)

&amp;#x200B;

We have a sentence: ""It’s recommended that you do that in a [virtual environment using virtualenv](https://pythonbasics.org/virtualenv/).""

&amp;#x200B;

as you can see ""virtual environment using virtualenv"" is let's say tagged. After translating this sentence google is able to tag the same piece in the target language. For example

&amp;#x200B;

Es wird empfohlen, dies in einer [virtuellen Umgebung mit virtualenv zu tun](https://pythonbasics.org/virtualenv/) .

&amp;#x200B;

How they can match the meaning and ""tag"" the correct positions? Obviously translation of the tagged part won't be same if it's done independently from the original sentence. So how they match it?",https://www.reddit.com/r/LanguageTechnology/comments/nhbztd/how_does_google_translates_addon_translates_a_web/,LanguageTechnology,t3_nhbztd,"How does Google Translate's add-on translates a web page so perfectly? I'm talking about the little translate button at the top left (can't put images).

&amp;#x200B;

As I understood it takes the html and translates the text in it. What I can't comprehend is it fits the correct words perfectly, for example in the &lt;strong&gt; tag.

For example &lt;p&gt;there is &lt;strong&gt;some text here&lt;/strong&gt; google will translate it&lt;/p&gt;

After the translation google finds the exact match to put inside the &lt;strong&gt; tag. They can't translate it separately it would distort the meaning. Even sentence is complex and inside the tag does not make a sentence on its own they handle it somehow.

I tried to make it as clear as possible. I've been searching but I couldn't come up with a solution. Do you have any ideas? Please share.

&amp;#x200B;

Edit (Clarification)

&amp;#x200B;

We have a sentence: ""It’s recommended that you do that in a [virtual environment using virtualenv](https://pythonbasics.org/virtualenv/).""

&amp;#x200B;

as you can see ""virtual environment using virtualenv"" is let's say tagged. After translating this sentence google is able to tag the same piece in the target language. For example

&amp;#x200B;

Es wird empfohlen, dies in einer [virtuellen Umgebung mit virtualenv zu tun](https://pythonbasics.org/virtualenv/) .

&amp;#x200B;

How they can match the meaning and ""tag"" the correct positions? Obviously translation of the tagged part won't be same if it's done independently from the original sentence. So how they match it?",1571
145,145,M.Sc. Computer linguistics in Germany,"Hi, hi!

Basically, my case is the opposite as the one archived here:

https://www.reddit.com/r/LanguageTechnology/comments/8w06zn/msc_computational_linguistics_in_germany/

I come from a theoretical/computational physics background and would like to properly educate myself in computational linguistics. Linguistics has been much of a hobby for me, while math and programming were part of my curriculum. 

Now I am finishing my master's on physics of complex systems and had one introduction to speech and text analysis, as well as a deep learning course.

This last information is also relevant, since I wouldn't like paying the tution fees for a second master (Zweitstudiengebühren) which would be applied in BaWü (Heidelberg, Tübingen, Stuttgart)

Any recommendations here?",https://www.reddit.com/r/LanguageTechnology/comments/ngyzvo/msc_computer_linguistics_in_germany/,LanguageTechnology,t3_ngyzvo,"M.Sc. Computer linguistics in Germany Hi, hi!

Basically, my case is the opposite as the one archived here:

https://www.reddit.com/r/LanguageTechnology/comments/8w06zn/msc_computational_linguistics_in_germany/

I come from a theoretical/computational physics background and would like to properly educate myself in computational linguistics. Linguistics has been much of a hobby for me, while math and programming were part of my curriculum. 

Now I am finishing my master's on physics of complex systems and had one introduction to speech and text analysis, as well as a deep learning course.

This last information is also relevant, since I wouldn't like paying the tution fees for a second master (Zweitstudiengebühren) which would be applied in BaWü (Heidelberg, Tübingen, Stuttgart)

Any recommendations here?",815
146,146,A New Google Research Introduces FNet By Replacing Self-Attention Sublayers With Simple Linear Transformations Achieving 92% Accuracy and Runs Up To Seven Times Faster On GPUs And Twice As Fast On TPUs (Paper link in comments),,https://www.marktechpost.com/2021/05/19/a-new-google-research-introduces-fnet-by-replacing-self-attention-sublayers-with-simple-linear-transformations-achieving-92-accuracy-and-runs-up-to-seven-times-faster-on-gpus-and-twice-as-fast-on-tpus/,LanguageTechnology,t3_ngsmcs,A New Google Research Introduces FNet By Replacing Self-Attention Sublayers With Simple Linear Transformations Achieving 92% Accuracy and Runs Up To Seven Times Faster On GPUs And Twice As Fast On TPUs (Paper link in comments) ,227
147,147,Is this approach to summary production novel?,"Hello! Been playing around with summary generators, and I'm pretty sure I came up with a novel approach, which should produce a summary that has the most resemblance to an author's typical writing style. Basically I'm just trying to find out if there's a word for this algo yet or not. Project is called Bite, and can be found [here](https://github.com/cyberrumor/bite). 

&amp;#x200B;

Say we have the following corpus:  


""Mary had a little lamb.""  


Bite will tokenize the sentence like so:  


* mary had
* mary had a 
* mary had a little
* mary had a little lamb
* had a
* had a little
* had a little lamb
* a little
* a little lamb
* a lamb

Next, it creates a frequency map to count all occurrences of each token, assigning scores to sentences by adding up the sum of token scores. 

&amp;#x200B;

Is there a word for this type of categorization?",https://www.reddit.com/r/LanguageTechnology/comments/nggaag/is_this_approach_to_summary_production_novel/,LanguageTechnology,t3_nggaag,"Is this approach to summary production novel? Hello! Been playing around with summary generators, and I'm pretty sure I came up with a novel approach, which should produce a summary that has the most resemblance to an author's typical writing style. Basically I'm just trying to find out if there's a word for this algo yet or not. Project is called Bite, and can be found [here](https://github.com/cyberrumor/bite). 

&amp;#x200B;

Say we have the following corpus:  


""Mary had a little lamb.""  


Bite will tokenize the sentence like so:  


* mary had
* mary had a 
* mary had a little
* mary had a little lamb
* had a
* had a little
* had a little lamb
* a little
* a little lamb
* a lamb

Next, it creates a frequency map to count all occurrences of each token, assigning scores to sentences by adding up the sum of token scores. 

&amp;#x200B;

Is there a word for this type of categorization?",901
148,148,Data Augmentation Techniques in NLP,,https://youtube.com/playlist?list=PLsAqq9lZFOtUg63g_95OuV-R2GhV1UiIZ,LanguageTechnology,t3_nfzwl5,Data Augmentation Techniques in NLP ,36
149,149,What are some resources to learn about incorporating images into word vectorization model?,,https://www.reddit.com/r/LanguageTechnology/comments/ngcis0/what_are_some_resources_to_learn_about/,LanguageTechnology,t3_ngcis0,What are some resources to learn about incorporating images into word vectorization model? ,91
150,150,Neural nets for word sense disambiguation?,,/r/learnmachinelearning/comments/ng6dfp/neural_nets_for_word_sense_disambiguation/,LanguageTechnology,t3_ng6e8v,Neural nets for word sense disambiguation? ,43
151,151,Automatically label syntactic structures in text,"I'm curious as to the best way to tag the syntactic structures of some text. So not just POS tags, but things like complement and relative clauses? Are there taggers specifically for this?",https://www.reddit.com/r/LanguageTechnology/comments/ng3bic/automatically_label_syntactic_structures_in_text/,LanguageTechnology,t3_ng3bic,"Automatically label syntactic structures in text I'm curious as to the best way to tag the syntactic structures of some text. So not just POS tags, but things like complement and relative clauses? Are there taggers specifically for this?",237
152,152,MUM: a new AI milestone for understanding information,,https://blog.google/products/search/introducing-mum/,LanguageTechnology,t3_nfjtj1,MUM: a new AI milestone for understanding information ,54
153,153,Māori are trying to save their language from Big Tech,,https://www.wired.co.uk/article/maori-language-tech,LanguageTechnology,t3_nfkiao,Māori are trying to save their language from Big Tech ,54
154,154,Debugging a NN model,"Hi all,

I have trained a simple multi-input NN. I have 4 inputs ( one text field &amp; other 3 categorical variables : cat1, cat2 , cat3).

It is a classification model.

For the text field, I use Glove embeddings in the Embedding layer, followed by LSTM layer.

For the other 3 categorical fields, I just encode them in a dense layer. Finally, I concatenate these 2 layers followed by softmax for classification. Below is the main block of code :

&amp;#x200B;

    embeddings_dictionary = dict()
    glove_file = open('glove.6B.100d.txt', encoding=""utf8"")
    for line in glove_file:
        records = line.split()
        word = records[0]
        vector_dimensions = asarray(records[1:], dtype='float32')
        embeddings_dictionary[word] = vector_dimensions
    glove_file.close()
    embedding_matrix = zeros((vocab_size, 100))
    for word, index in tokenizer.word_index.items():
        embedding_vector = embeddings_dictionary.get(word)
        if embedding_vector is not None:
            embedding_matrix[index] = embedding_vector
    
    # Text input handling
    text_input_1 = Input(shape=(maxlen,))
    embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(text_input_1)
    LSTM_Layer_1 = LSTM(128)(embedding_layer)
    
    
    # categorical variables handling
    layout_input_2 = Input(shape=(3,))
    dense_layer_1 = Dense(10, activation='relu')(layout_input_2)
    dense_layer_2 = Dense(10, activation='relu')(dense_layer_1)
    
    # Concatenating the above 2
    concat_layer = Concatenate()([LSTM_Layer_1, dense_layer_2])
    dense_layer_3 = Dense(10, activation='relu')(concat_layer)
    output = Dense(3, activation='softmax')(dense_layer_3)
    model = Model(inputs=[text_input_1, layout_input_2], outputs=output)
    
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])
    print(model.summary())

The problem is , when I infer/predict using the above model weights, the respose is like all the weightage is being given to the categorical variables only , irrespective of the text input.

e.g. predict (text1, cat1, cat2, cat3)  &amp;  predict (text2, cat1, cat2, cat3)  is exactly same.

Even if I provide blank text as input, the output remains same if I don't change the categorical variable values.

Can anybody help troubleshooting this ?",https://www.reddit.com/r/LanguageTechnology/comments/nfxmqa/debugging_a_nn_model/,LanguageTechnology,t3_nfxmqa,"Debugging a NN model Hi all,

I have trained a simple multi-input NN. I have 4 inputs ( one text field &amp; other 3 categorical variables : cat1, cat2 , cat3).

It is a classification model.

For the text field, I use Glove embeddings in the Embedding layer, followed by LSTM layer.

For the other 3 categorical fields, I just encode them in a dense layer. Finally, I concatenate these 2 layers followed by softmax for classification. Below is the main block of code :

&amp;#x200B;

    embeddings_dictionary = dict()
    glove_file = open('glove.6B.100d.txt', encoding=""utf8"")
    for line in glove_file:
        records = line.split()
        word = records[0]
        vector_dimensions = asarray(records[1:], dtype='float32')
        embeddings_dictionary[word] = vector_dimensions
    glove_file.close()
    embedding_matrix = zeros((vocab_size, 100))
    for word, index in tokenizer.word_index.items():
        embedding_vector = embeddings_dictionary.get(word)
        if embedding_vector is not None:
            embedding_matrix[index] = embedding_vector
    
    # Text input handling
    text_input_1 = Input(shape=(maxlen,))
    embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(text_input_1)
    LSTM_Layer_1 = LSTM(128)(embedding_layer)
    
    
    # categorical variables handling
    layout_input_2 = Input(shape=(3,))
    dense_layer_1 = Dense(10, activation='relu')(layout_input_2)
    dense_layer_2 = Dense(10, activation='relu')(dense_layer_1)
    
    # Concatenating the above 2
    concat_layer = Concatenate()([LSTM_Layer_1, dense_layer_2])
    dense_layer_3 = Dense(10, activation='relu')(concat_layer)
    output = Dense(3, activation='softmax')(dense_layer_3)
    model = Model(inputs=[text_input_1, layout_input_2], outputs=output)
    
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])
    print(model.summary())

The problem is , when I infer/predict using the above model weights, the respose is like all the weightage is being given to the categorical variables only , irrespective of the text input.

e.g. predict (text1, cat1, cat2, cat3)  &amp;  predict (text2, cat1, cat2, cat3)  is exactly same.

Even if I provide blank text as input, the output remains same if I don't change the categorical variable values.

Can anybody help troubleshooting this ?",2368
155,155,Deploying a transformer-based text classification NLP model with FastAPI,"Hello all,

Recently I wrote an article about deploying spaCy with FastAPI for NER. As many people told me it was helpful, I did a new article about deploying transformer-based models with FastAPI for text classification (using Facebook's Bart Large MNLI model).

FastAPI  is a great is great framework for API development in Python in my opinion. It helped me save a lot of troubles when developing the [NLPCloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=d13c16ae-b7d8-11eb-8529-0242ac130003) API.

Here's the article:

[https://nlpcloud.io/nlp-machine-learning-classification-api-production-fastapi-transformers-nlpcloud.html](https://nlpcloud.io/nlp-machine-learning-classification-api-production-fastapi-transformers-nlpcloud.html?utm_source=reddit&amp;utm_campaign=d13c16ae-b7d8-11eb-8529-0242ac130003)

I'd love to have your feedback on this! Have you ever deployed transformer-based models to production? If so, which tools did you use?

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/nfa5ek/deploying_a_transformerbased_text_classification/,LanguageTechnology,t3_nfa5ek,"Deploying a transformer-based text classification NLP model with FastAPI Hello all,

Recently I wrote an article about deploying spaCy with FastAPI for NER. As many people told me it was helpful, I did a new article about deploying transformer-based models with FastAPI for text classification (using Facebook's Bart Large MNLI model).

FastAPI  is a great is great framework for API development in Python in my opinion. It helped me save a lot of troubles when developing the [NLPCloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=d13c16ae-b7d8-11eb-8529-0242ac130003) API.

Here's the article:

[https://nlpcloud.io/nlp-machine-learning-classification-api-production-fastapi-transformers-nlpcloud.html](https://nlpcloud.io/nlp-machine-learning-classification-api-production-fastapi-transformers-nlpcloud.html?utm_source=reddit&amp;utm_campaign=d13c16ae-b7d8-11eb-8529-0242ac130003)

I'd love to have your feedback on this! Have you ever deployed transformer-based models to production? If so, which tools did you use?

Thanks!",1043
156,156,Explanability for Transformers with Transformers-Interpret — A Model Explainability Tool,,https://link.medium.com/cNDQwZ84lgb,LanguageTechnology,t3_nf5o8o,Explanability for Transformers with Transformers-Interpret — A Model Explainability Tool ,89
157,157,Long Form Automatic Transcription from Audio (Transcribe Movie Dialogue to Text) - How Do I Do It?,"So I'm looking to create a subtitle file from a film that is only in Portuguese. 

I can do it by hand but that would take sooo long. 

I figure that I can probably extract the audio and use Google's transcription API to do a majority of the work for me, but I'm not sure how to go about doing that with a long length file.

Any tips?",https://www.reddit.com/r/LanguageTechnology/comments/nf3vmz/long_form_automatic_transcription_from_audio/,LanguageTechnology,t3_nf3vmz,"Long Form Automatic Transcription from Audio (Transcribe Movie Dialogue to Text) - How Do I Do It? So I'm looking to create a subtitle file from a film that is only in Portuguese. 

I can do it by hand but that would take sooo long. 

I figure that I can probably extract the audio and use Google's transcription API to do a majority of the work for me, but I'm not sure how to go about doing that with a long length file.

Any tips?",433
158,158,Text Summarisation Techniques in NLP,,https://youtube.com/playlist?list=PLsAqq9lZFOtV8jYq3JlkqPQUN5QxcWq0f,LanguageTechnology,t3_neo5lz,Text Summarisation Techniques in NLP ,37
159,159,The importance of language technologies for the future of the public health system (in Spanish),,https://theconversation.com/el-desarrollo-de-las-tecnologias-del-lenguaje-para-el-futuro-de-la-sanidad-159013,LanguageTechnology,t3_nf73gw,The importance of language technologies for the future of the public health system (in Spanish) ,96
160,160,Spacy 3.0 multi class Textcat,"If anyone has any experience with this I would love to pick your brain / ask you a little assistance. 

Been struggling to correctly initialize my model.",https://www.reddit.com/r/LanguageTechnology/comments/nerxde/spacy_30_multi_class_textcat/,LanguageTechnology,t3_nerxde,"Spacy 3.0 multi class Textcat If anyone has any experience with this I would love to pick your brain / ask you a little assistance. 

Been struggling to correctly initialize my model.",183
161,161,Spacy NER Model 2 Entities versus 6,"Hello all! Currently have a Spacy NER model that looks for 6 custom entities, while only two (Person and Organization) are truly important.

Would it be beneficial to cut out the other four entities in the model? My boss added them because he thought they would help with accuracy essentially through lessening the chance of false positives for person and organization. 

I personally believe the model would perform fine with only Person and organization, but am new to data science so just wanted to verify my hunch.",https://www.reddit.com/r/LanguageTechnology/comments/nerh99/spacy_ner_model_2_entities_versus_6/,LanguageTechnology,t3_nerh99,"Spacy NER Model 2 Entities versus 6 Hello all! Currently have a Spacy NER model that looks for 6 custom entities, while only two (Person and Organization) are truly important.

Would it be beneficial to cut out the other four entities in the model? My boss added them because he thought they would help with accuracy essentially through lessening the chance of false positives for person and organization. 

I personally believe the model would perform fine with only Person and organization, but am new to data science so just wanted to verify my hunch.",554
162,162,Is it conference paper worthy?,"My final year project is on Multi-class text classification and simply explores existing techniques (TF-IDF and Word2Vec) on a new and different dataset. Pipeline is standard: Data Pre-processing and Cleaning, Vectorization and Dimensionality Reduction, Model splitting and Training, Hyperparameter tuning, model re-training and finally model evaluation.

Is it worthy of sending it as a paper to conferences even though it is nothing novel technique-wise but is on a different dataset?

Any guidance would be appreciated!",https://www.reddit.com/r/LanguageTechnology/comments/nehdv5/is_it_conference_paper_worthy/,LanguageTechnology,t3_nehdv5,"Is it conference paper worthy? My final year project is on Multi-class text classification and simply explores existing techniques (TF-IDF and Word2Vec) on a new and different dataset. Pipeline is standard: Data Pre-processing and Cleaning, Vectorization and Dimensionality Reduction, Model splitting and Training, Hyperparameter tuning, model re-training and finally model evaluation.

Is it worthy of sending it as a paper to conferences even though it is nothing novel technique-wise but is on a different dataset?

Any guidance would be appreciated!",553
163,163,Automatic question generation from input paragraph,"I am doing my individual research on automatic question generation from the paragraphs which will be input in to the system. I have divided this idea into three steps,

1. sentence selection
2. complex sentence simplification
3. sentence classification based on POS and NE tagged information

I would be grateful to hear your opinions based on the methodology which i am going to use. Please be kind enough to mention if i need to upgrade the methodology or any other changes that i should consider.",https://www.reddit.com/r/LanguageTechnology/comments/neav37/automatic_question_generation_from_input_paragraph/,LanguageTechnology,t3_neav37,"Automatic question generation from input paragraph I am doing my individual research on automatic question generation from the paragraphs which will be input in to the system. I have divided this idea into three steps,

1. sentence selection
2. complex sentence simplification
3. sentence classification based on POS and NE tagged information

I would be grateful to hear your opinions based on the methodology which i am going to use. Please be kind enough to mention if i need to upgrade the methodology or any other changes that i should consider.",550
164,164,IBM's Project Codenet will teach AI to code in dozens of programming languages. Extremely vast dataset,,https://artificialintelligence-news.com/2021/05/11/ibm-project-codenet-wants-teach-ai-how-code/,LanguageTechnology,t3_nep2tj,IBM's Project Codenet will teach AI to code in dozens of programming languages. Extremely vast dataset ,103
165,165,Are there tools that tell a word's difficulty?,"Are there any tools that determine a word's difficulty? GPT3 has this thing where it can simplify things so that a 2nd grader would understand, how would it distinguish a word's level of complexity?",https://www.reddit.com/r/LanguageTechnology/comments/nehs9k/are_there_tools_that_tell_a_words_difficulty/,LanguageTechnology,t3_nehs9k,"Are there tools that tell a word's difficulty? Are there any tools that determine a word's difficulty? GPT3 has this thing where it can simplify things so that a 2nd grader would understand, how would it distinguish a word's level of complexity?",245
166,166,New to NLP. Looking for library recommendations.,"Hello. I recently decided to start exploring the use of NLP for solving language and machine translation problems.

I'm familiar with Python but don't really know my way around what NLP libraries are out there as of 2021. **Does anyone have a list of must-know Python-based NLP libraries (I assume Python is the best tool for NLP) and NLP libraries specific to machine translation?**

Thank you in advance.",https://www.reddit.com/r/LanguageTechnology/comments/ndz50q/new_to_nlp_looking_for_library_recommendations/,LanguageTechnology,t3_ndz50q,"New to NLP. Looking for library recommendations. Hello. I recently decided to start exploring the use of NLP for solving language and machine translation problems.

I'm familiar with Python but don't really know my way around what NLP libraries are out there as of 2021. **Does anyone have a list of must-know Python-based NLP libraries (I assume Python is the best tool for NLP) and NLP libraries specific to machine translation?**

Thank you in advance.",455
167,167,How to create a model like BERT or GPT?,"I am a sophomore and have studied ML and DL for last 6 months. Recently I started working on NLP. I was wondering how these models (BERT, GPT) are created. Following are some questions

1. Is it possible to create my own model? I was thinking of making a hybrid of encoders and decoders of transformers. 

2. Is it even feasible to create a model at my stage? 

3. How much time would it take to create it?",https://www.reddit.com/r/LanguageTechnology/comments/ne5mkc/how_to_create_a_model_like_bert_or_gpt/,LanguageTechnology,t3_ne5mkc,"How to create a model like BERT or GPT? I am a sophomore and have studied ML and DL for last 6 months. Recently I started working on NLP. I was wondering how these models (BERT, GPT) are created. Following are some questions

1. Is it possible to create my own model? I was thinking of making a hybrid of encoders and decoders of transformers. 

2. Is it even feasible to create a model at my stage? 

3. How much time would it take to create it?",446
168,168,Techniques to handle over-fitting with text classifier,"Hi, I'm currently using a dataset, that has 6 different target labels. The number of instance of target 1-6 is 20k, 16k, 3k, 2k, 1.5k, 1.2k.

I'm making use of fastText to classify. The model gets over-fitted and for most of times gives the targets that have 20k (target 1) or 16k (target 2) instances.

The accuracy given by fastText is 90% but that is because of over fitting.
In another try, I provided (almost) equal amount of all instances ( &lt;= 2k ) for each target label and the accuracy had become 78%.

Is there any better way of handling this problem without neglecting thousands of instances?

Any suggestions would be helpful!",https://www.reddit.com/r/LanguageTechnology/comments/ndw6ys/techniques_to_handle_overfitting_with_text/,LanguageTechnology,t3_ndw6ys,"Techniques to handle over-fitting with text classifier Hi, I'm currently using a dataset, that has 6 different target labels. The number of instance of target 1-6 is 20k, 16k, 3k, 2k, 1.5k, 1.2k.

I'm making use of fastText to classify. The model gets over-fitted and for most of times gives the targets that have 20k (target 1) or 16k (target 2) instances.

The accuracy given by fastText is 90% but that is because of over fitting.
In another try, I provided (almost) equal amount of all instances ( &lt;= 2k ) for each target label and the accuracy had become 78%.

Is there any better way of handling this problem without neglecting thousands of instances?

Any suggestions would be helpful!",695
169,169,Is a primitive method using NLTK and counters viable?,"This question might be inappropriate here, but IDK where else to ask it. I have trouble getting a hugging face model to work, but I do have sufficient data and not enough time. I want to 'predict' a sentence from a previous one, or a sentence fragment. What is the simplest thing that I can do with NLTK and counters that is still useful?",https://www.reddit.com/r/LanguageTechnology/comments/ndq9fq/is_a_primitive_method_using_nltk_and_counters/,LanguageTechnology,t3_ndq9fq,"Is a primitive method using NLTK and counters viable? This question might be inappropriate here, but IDK where else to ask it. I have trouble getting a hugging face model to work, but I do have sufficient data and not enough time. I want to 'predict' a sentence from a previous one, or a sentence fragment. What is the simplest thing that I can do with NLTK and counters that is still useful?",392
170,170,10 popular Keyword Extraction Techniques in NLP,"This blog lists out (All?) popular Unsupervised Keyword Extraction Algorithms in NLP. 

Here, I summarize almost 10 papers w.r.t all these techniques. Enjoy the read! 🎉 


https://link.medium.com/4ah0jdgXhgb",https://www.reddit.com/r/LanguageTechnology/comments/nd8q5a/10_popular_keyword_extraction_techniques_in_nlp/,LanguageTechnology,t3_nd8q5a,"10 popular Keyword Extraction Techniques in NLP This blog lists out (All?) popular Unsupervised Keyword Extraction Algorithms in NLP. 

Here, I summarize almost 10 papers w.r.t all these techniques. Enjoy the read! 🎉 


https://link.medium.com/4ah0jdgXhgb",255
171,171,CQP vs LexiDB,"Has anyone here gotten LexiDB to work? I recently found LexiDB as a potenialy corpus querying alternative to CWB's CQP.

These tools allow you to query large corpora (my current largest corpus has 800 million tokens in it) for patterns. For example, you could search for ""the &lt;adjective&gt; *"" and the tool will quickly return a list of matches.

I have CQP working already but LexiDB sounds a little better for my needs. Unfortunately so far I can't get it to work.",https://www.reddit.com/r/LanguageTechnology/comments/nd8ra2/cqp_vs_lexidb/,LanguageTechnology,t3_nd8ra2,"CQP vs LexiDB Has anyone here gotten LexiDB to work? I recently found LexiDB as a potenialy corpus querying alternative to CWB's CQP.

These tools allow you to query large corpora (my current largest corpus has 800 million tokens in it) for patterns. For example, you could search for ""the &lt;adjective&gt; *"" and the tool will quickly return a list of matches.

I have CQP working already but LexiDB sounds a little better for my needs. Unfortunately so far I can't get it to work.",483
172,172,Ides for making a podcast summarizer?,"In short: I listen to lots of interesting podcasts, but with my limited human memory, I tend to forget some of the juicier details that I would like to remember.. My solution to this would be to summarize podcast episodes that I find memorable so that a quick glimpse at the highlights would bring the topics back to memory. However, instead of spending time doing manual summations, I would like to practice some ML/NLP applications by making my own podcast summarizer.

My thought is to divide the problem into two main steps:

1. Audio to transcript
2. Transcript summation/extraction of main topics

What ideas and thoughts do you all having regarding which models/libraries to use for the two steps? Or any other inputs on how to approach it?

Super excited to hear your thoughts!",https://www.reddit.com/r/LanguageTechnology/comments/nd3pff/ides_for_making_a_podcast_summarizer/,LanguageTechnology,t3_nd3pff,"Ides for making a podcast summarizer? In short: I listen to lots of interesting podcasts, but with my limited human memory, I tend to forget some of the juicier details that I would like to remember.. My solution to this would be to summarize podcast episodes that I find memorable so that a quick glimpse at the highlights would bring the topics back to memory. However, instead of spending time doing manual summations, I would like to practice some ML/NLP applications by making my own podcast summarizer.

My thought is to divide the problem into two main steps:

1. Audio to transcript
2. Transcript summation/extraction of main topics

What ideas and thoughts do you all having regarding which models/libraries to use for the two steps? Or any other inputs on how to approach it?

Super excited to hear your thoughts!",823
173,173,NLP job opportunities for Master graduates(no PhD),"Hello,

I am a Computer science Master graduate from a top EU university.  During my Masters I focused mainly on NLP and I did 2 internships as an NLP engineer. I am currently looking(not actively looking) for opportunities in NLP in Europe(mainly London, Switzerland, and maybe Germany). 

But I am having trouble finding opportunities that match my profile and that I like. The main issue that I have is that a lot of big companies(not start ups) say that they do NLP but in reality most of the time you end up working on software engineering tasks. The other problem is that all the posts that I like require a PhD.  I also applied in FAANG companies but they only accepted me to interview for a Software engineering roles. 

1. Do any of you work at a FAANG company as a Software engineer and work on NLP projects ? What exactly is your job, do you come up with architecture of the model or do you just build the infrastructure around the model ... ? 
2. For those who work in NLP but don't have a PhD can you give me an example of NLP projects that you do at work and if possible tell me for which company you work. 

Any recommendations of companies that do NLP and hire people without a PhD are welcomed.",https://www.reddit.com/r/LanguageTechnology/comments/ncue0g/nlp_job_opportunities_for_master_graduatesno_phd/,LanguageTechnology,t3_ncue0g,"NLP job opportunities for Master graduates(no PhD) Hello,

I am a Computer science Master graduate from a top EU university.  During my Masters I focused mainly on NLP and I did 2 internships as an NLP engineer. I am currently looking(not actively looking) for opportunities in NLP in Europe(mainly London, Switzerland, and maybe Germany). 

But I am having trouble finding opportunities that match my profile and that I like. The main issue that I have is that a lot of big companies(not start ups) say that they do NLP but in reality most of the time you end up working on software engineering tasks. The other problem is that all the posts that I like require a PhD.  I also applied in FAANG companies but they only accepted me to interview for a Software engineering roles. 

1. Do any of you work at a FAANG company as a Software engineer and work on NLP projects ? What exactly is your job, do you come up with architecture of the model or do you just build the infrastructure around the model ... ? 
2. For those who work in NLP but don't have a PhD can you give me an example of NLP projects that you do at work and if possible tell me for which company you work. 

Any recommendations of companies that do NLP and hire people without a PhD are welcomed.",1262
174,174,Is it just me or is mobileBERT is much slower than DistilBERT on Huggingface,"When I train mobileBERT on GTX 1070, I get 3.8 it/sec. However, when I train DistilBERT on the same GPU, I get 15 it/sec. Am I missing something? The paper on MobileBERT states that MobileBERT should be faster.",https://www.reddit.com/r/LanguageTechnology/comments/nczb5s/is_it_just_me_or_is_mobilebert_is_much_slower/,LanguageTechnology,t3_nczb5s,"Is it just me or is mobileBERT is much slower than DistilBERT on Huggingface When I train mobileBERT on GTX 1070, I get 3.8 it/sec. However, when I train DistilBERT on the same GPU, I get 15 it/sec. Am I missing something? The paper on MobileBERT states that MobileBERT should be faster.",287
175,175,"Is there a network available for download that has a very long attention span? Something that could summarize a book, for instance.","Title, basically sums up my question.",https://www.reddit.com/r/LanguageTechnology/comments/ncb54r/is_there_a_network_available_for_download_that/,LanguageTechnology,t3_ncb54r,"Is there a network available for download that has a very long attention span? Something that could summarize a book, for instance. Title, basically sums up my question.",169
176,176,Regex to detect age in a sting literal on Python,"Hi everyone! I'm wrapping my head around regular expressions and I managed to write a simple line of code that detects age. I tried my best, unfortunately that doesn't work every time because there are several ways people can express their age.

1) ""I'm 25""
2) ""I'm 25yo""
3) ""I'm 25 years old""
4) ""I'm 25M""

My regex is very simple re.search(r'\d+\w+', text) and it works fine with 2 and 4 since there's no space between them. Do you have any idea to improve this regex so that it works with all of them?

Thanks for your time!",https://www.reddit.com/r/LanguageTechnology/comments/ncczd0/regex_to_detect_age_in_a_sting_literal_on_python/,LanguageTechnology,t3_ncczd0,"Regex to detect age in a sting literal on Python Hi everyone! I'm wrapping my head around regular expressions and I managed to write a simple line of code that detects age. I tried my best, unfortunately that doesn't work every time because there are several ways people can express their age.

1) ""I'm 25""
2) ""I'm 25yo""
3) ""I'm 25 years old""
4) ""I'm 25M""

My regex is very simple re.search(r'\d+\w+', text) and it works fine with 2 and 4 since there's no space between them. Do you have any idea to improve this regex so that it works with all of them?

Thanks for your time!",576
177,177,EmbedRank: Simple Unsupervised Keyphrase Extraction using Sentence Embeddings,,https://link.medium.com/zaWf1MfUfgb,LanguageTechnology,t3_ncbjs8,EmbedRank: Simple Unsupervised Keyphrase Extraction using Sentence Embeddings ,78
178,178,Large summarization dataset in Portuguese,"I'm looking for a large (more than 100K records) corpus dataset for a summarization task in Portuguese. Something like the CNN/DailyMail dataset ([https://huggingface.co/datasets/cnn\_dailymail](https://huggingface.co/datasets/cnn_dailymail)) but in Portuguese.

Does anyone know of such a dataset?",https://www.reddit.com/r/LanguageTechnology/comments/nc6mku/large_summarization_dataset_in_portuguese/,LanguageTechnology,t3_nc6mku,"Large summarization dataset in Portuguese I'm looking for a large (more than 100K records) corpus dataset for a summarization task in Portuguese. Something like the CNN/DailyMail dataset ([https://huggingface.co/datasets/cnn\_dailymail](https://huggingface.co/datasets/cnn_dailymail)) but in Portuguese.

Does anyone know of such a dataset?",340
179,179,Evolution of NLP search methods and the latest method - Neural Search. What is it and how to get started with it,,https://medium.com/nerd-for-tech/what-is-neural-search-537853f3d628,LanguageTechnology,t3_nbzarl,Evolution of NLP search methods and the latest method - Neural Search. What is it and how to get started with it ,113
180,180,After-the-fact conversational topic analysis?,"I've developed a conversational architecture for my robots that works fairly well in an unsupervised setting.  The robots recognize the folks they talk to (if they've been introduced) and save the interactions and the full text of the dialog between them by date.  

I am looking for something that can summarize the primary subjects of the conversations after the fact, so that I can sort of ""categorize"" the subjects that interest various folks that the robots talk with.  

I've found things like this:  https://convokit.cornell.edu/documentation/tutorial.html

These seem to offer some useful direction - just wondering if anyone else has any suggestions to summarize a given interaction?  Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/nbsuph/afterthefact_conversational_topic_analysis/,LanguageTechnology,t3_nbsuph,"After-the-fact conversational topic analysis? I've developed a conversational architecture for my robots that works fairly well in an unsupervised setting.  The robots recognize the folks they talk to (if they've been introduced) and save the interactions and the full text of the dialog between them by date.  

I am looking for something that can summarize the primary subjects of the conversations after the fact, so that I can sort of ""categorize"" the subjects that interest various folks that the robots talk with.  

I've found things like this:  https://convokit.cornell.edu/documentation/tutorial.html

These seem to offer some useful direction - just wondering if anyone else has any suggestions to summarize a given interaction?  Thanks.",747
181,181,I have a list of names of publicly listed companies (around 1000) and want to do textual analysis of information on their websites. Where do I start?,"I mean is there already a database that I can use. If not, how do I get their website address without looking each one up on google and how to automate the process of collecting information. I use python if you need to know. Any suggestion helps. Thankyou",https://www.reddit.com/r/LanguageTechnology/comments/nbyu2x/i_have_a_list_of_names_of_publicly_listed/,LanguageTechnology,t3_nbyu2x,"I have a list of names of publicly listed companies (around 1000) and want to do textual analysis of information on their websites. Where do I start? I mean is there already a database that I can use. If not, how do I get their website address without looking each one up on google and how to automate the process of collecting information. I use python if you need to know. Any suggestion helps. Thankyou",405
182,182,SpaCy 3.0 Text Classifier,Anyone have experience using Spacy 3.0 Text classifier for multi class classification? I have 6 classes but after running the model get all 0s for the accuracy score. Code is at work but I can provide it tomorrow if anyone has had a similar use case! I have a feeling I’m making a mistake regarding the multiple classes,https://www.reddit.com/r/LanguageTechnology/comments/nbvv0h/spacy_30_text_classifier/,LanguageTechnology,t3_nbvv0h,SpaCy 3.0 Text Classifier Anyone have experience using Spacy 3.0 Text classifier for multi class classification? I have 6 classes but after running the model get all 0s for the accuracy score. Code is at work but I can provide it tomorrow if anyone has had a similar use case! I have a feeling I’m making a mistake regarding the multiple classes,345
183,183,Best approach for preprocessing in 2021,"Hi everyone!

What would you recommend for an efficient preprocessing pipeline these days? I was checking spaCy but they don't offer bi-gramization out of the box right?

So to include bi-grams I was thinking on gensim.

But there things get hairy. Gensim needs tokens per sentence per doc to learn the phrase model, then I need to tokenize/segment first.

I don't like this since I wanted to use spaCy for the tokenization and lemmatization as a final and single step.

Also, I guess spaCy's lemmatization is much better than NLTK's

All seems like a mess and perhaps can shade some light on this.

Finally, will bi-grams affect lemmatization? Which is the correct order?

Thanks for your insights!!



Edit 1: And how about frequency filtering and min/max length filtering?

Edit 2: Is it better to TF-IDF or just stop words removal?

Edit 3: This preprocessing if for topic modelling",https://www.reddit.com/r/LanguageTechnology/comments/nbn0rw/best_approach_for_preprocessing_in_2021/,LanguageTechnology,t3_nbn0rw,"Best approach for preprocessing in 2021 Hi everyone!

What would you recommend for an efficient preprocessing pipeline these days? I was checking spaCy but they don't offer bi-gramization out of the box right?

So to include bi-grams I was thinking on gensim.

But there things get hairy. Gensim needs tokens per sentence per doc to learn the phrase model, then I need to tokenize/segment first.

I don't like this since I wanted to use spaCy for the tokenization and lemmatization as a final and single step.

Also, I guess spaCy's lemmatization is much better than NLTK's

All seems like a mess and perhaps can shade some light on this.

Finally, will bi-grams affect lemmatization? Which is the correct order?

Thanks for your insights!!



Edit 1: And how about frequency filtering and min/max length filtering?

Edit 2: Is it better to TF-IDF or just stop words removal?

Edit 3: This preprocessing if for topic modelling",926
184,184,Anonymous Walk Embeddings (Graph ML Research Paper Walkthrough),"This research talks about using Random Walk inspired Anonymous Walks as graph units to derive feature-based and data-driven Graph Embeddings in an unsupervised fashion. 🔥 

https://youtu.be/VVml3nDiM3E",https://www.reddit.com/r/LanguageTechnology/comments/nbk2ja/anonymous_walk_embeddings_graph_ml_research_paper/,LanguageTechnology,t3_nbk2ja,"Anonymous Walk Embeddings (Graph ML Research Paper Walkthrough) This research talks about using Random Walk inspired Anonymous Walks as graph units to derive feature-based and data-driven Graph Embeddings in an unsupervised fashion. 🔥 

https://youtu.be/VVml3nDiM3E",265
185,185,Looking for a Claim Extraction/Sentence Segmentation Framework,"Hi All, I’m looking for a framework that allows for the extraction of knowledge claims/factual statements from a given text. For example…

Input: “Joe Biden won the election, making him the 46th President of the United States”

Output: “Joe Biden won the election”, “Joe Biden is the 46th President of the United States”

I know this has some overlap with sentence entailment, but that’s not exactly what I’m looking for.

Does anyone know of anything like this? Thanks! :)",https://www.reddit.com/r/LanguageTechnology/comments/nbp2ec/looking_for_a_claim_extractionsentence/,LanguageTechnology,t3_nbp2ec,"Looking for a Claim Extraction/Sentence Segmentation Framework Hi All, I’m looking for a framework that allows for the extraction of knowledge claims/factual statements from a given text. For example…

Input: “Joe Biden won the election, making him the 46th President of the United States”

Output: “Joe Biden won the election”, “Joe Biden is the 46th President of the United States”

I know this has some overlap with sentence entailment, but that’s not exactly what I’m looking for.

Does anyone know of anything like this? Thanks! :)",536
186,186,Beyond Accuracy: Behavioral Testing of NLP Models with CheckList (BEST PAPER ACL),,https://link.medium.com/XUG13JXHdgb,LanguageTechnology,t3_nbbbiy,Beyond Accuracy: Behavioral Testing of NLP Models with CheckList (BEST PAPER ACL) ,82
187,187,Parrot: Paraphrase based utterance augmentation framework | Python #NLP,,https://youtu.be/7rgvS1qMePo,LanguageTechnology,t3_nbhb5l,Parrot: Paraphrase based utterance augmentation framework | Python #NLP ,72
188,188,Sentiment Analysis Recommendations on Review data,,/r/datascience/comments/nbj29s/sentiment_analysis_recommendations_on_review_data/,LanguageTechnology,t3_nbj7u6,Sentiment Analysis Recommendations on Review data ,50
189,189,What are some good Poster Submission venues for NLP,"I am an undergraduate in my third year, I've been working in NLP research for over a year now. My university however, is not very research inclined and there is very little good guidance on good poster submission/publication venues. While I've researched and found places to submit complete research papers, there's very little information on poster submission venues. Any information would be helpful!",https://www.reddit.com/r/LanguageTechnology/comments/nbpox4/what_are_some_good_poster_submission_venues_for/,LanguageTechnology,t3_nbpox4,"What are some good Poster Submission venues for NLP I am an undergraduate in my third year, I've been working in NLP research for over a year now. My university however, is not very research inclined and there is very little good guidance on good poster submission/publication venues. While I've researched and found places to submit complete research papers, there's very little information on poster submission venues. Any information would be helpful!",454
190,190,"Webpage summarization: Given the URL of a company webpage, what does the company do?","I'm faced with a task: Given the URL of webpage, that links to the homepage of a company, can you describe to me, in 1 to 10 sentences, what the company does?

Are there any pre-made solutions for this? I already have a massive amounts of supervised training data for the problem.",https://www.reddit.com/r/LanguageTechnology/comments/nbcwma/webpage_summarization_given_the_url_of_a_company/,LanguageTechnology,t3_nbcwma,"Webpage summarization: Given the URL of a company webpage, what does the company do? I'm faced with a task: Given the URL of webpage, that links to the homepage of a company, can you describe to me, in 1 to 10 sentences, what the company does?

Are there any pre-made solutions for this? I already have a massive amounts of supervised training data for the problem.",365
191,191,"Graph-Based Framework for Structured Prediction Tasks in Sanskrit by Dr. Pawan Goyal. This is a search-based structured prediction framework, which expects a graph as input, where relevant linguistic info is encoded in the nodes, &amp; the edges are then used to indicate the association b/w these nodes.",,https://www.asiainnovationsummit.com/pawan-goyal,LanguageTechnology,t3_nb4hty,"Graph-Based Framework for Structured Prediction Tasks in Sanskrit by Dr. Pawan Goyal. This is a search-based structured prediction framework, which expects a graph as input, where relevant linguistic info is encoded in the nodes, &amp; the edges are then used to indicate the association b/w these nodes. ",305
192,192,Linguistics student looking for advice to advance in NLP/Computational Linguistics,"Hello! I am currently a second-year (third) linguistics major student, and I am looking for an academic advice. I am looking forward intro declaring a minor in computer science or math. The problem is that I do not know what to commit to (and I can only choose one). I am aiming to apply to grad school in data science / natural language processing / computational linguistics. I have already developed some Data Science projects and I have developed pretty good coding skills by myself (Python, C++, Swift), and I am pretty much equally good at math. However, I am not entirely sure which minor would help me more career-wise. Can you guys help me out?",https://www.reddit.com/r/LanguageTechnology/comments/nbcb2p/linguistics_student_looking_for_advice_to_advance/,LanguageTechnology,t3_nbcb2p,"Linguistics student looking for advice to advance in NLP/Computational Linguistics Hello! I am currently a second-year (third) linguistics major student, and I am looking for an academic advice. I am looking forward intro declaring a minor in computer science or math. The problem is that I do not know what to commit to (and I can only choose one). I am aiming to apply to grad school in data science / natural language processing / computational linguistics. I have already developed some Data Science projects and I have developed pretty good coding skills by myself (Python, C++, Swift), and I am pretty much equally good at math. However, I am not entirely sure which minor would help me more career-wise. Can you guys help me out?",736
193,193,Cognitive Scientist Terrence Deacon Says Current AI Lacks Symbolic Representations &amp; True Language Comprehension Abilities,,https://www.youtube.com/watch?v=gbWX--cpbYU&amp;t=10s,LanguageTechnology,t3_nas06j,Cognitive Scientist Terrence Deacon Says Current AI Lacks Symbolic Representations &amp; True Language Comprehension Abilities ,127
194,194,Flashcard Generator - using a multi-transformer pipeline to self-correct,,http://www.revision.ai/quiz?cdf,LanguageTechnology,t3_nb6nem,Flashcard Generator - using a multi-transformer pipeline to self-correct ,73
195,195,Importance of end symbol in N gram,"I'm reading a book 'Speech and Language Processing'. Here it is mentioned that without an end-symbol, the sentence probabilities for all sentences of a given length would sum to one.
I searched google to understand this statement but couldn't get satisfactory answers. Could anyone help me understand this.",https://www.reddit.com/r/LanguageTechnology/comments/nav6mc/importance_of_end_symbol_in_n_gram/,LanguageTechnology,t3_nav6mc,"Importance of end symbol in N gram I'm reading a book 'Speech and Language Processing'. Here it is mentioned that without an end-symbol, the sentence probabilities for all sentences of a given length would sum to one.
I searched google to understand this statement but couldn't get satisfactory answers. Could anyone help me understand this.",341
196,196,Leveraging BERT for Extractive Text Summarization on Lectures,,https://link.medium.com/hvJSmr6dcgb,LanguageTechnology,t3_nalfmp,Leveraging BERT for Extractive Text Summarization on Lectures ,62
197,197,Descriptions of Named Humans,"Does anyone know where to find a dataset of adjectives used to describe humans in a text? I know named entity recognition exists, but I don't know how I would extend this to only extract human entities and then select adjectives which describe them.",https://www.reddit.com/r/LanguageTechnology/comments/naz8vi/descriptions_of_named_humans/,LanguageTechnology,t3_naz8vi,"Descriptions of Named Humans Does anyone know where to find a dataset of adjectives used to describe humans in a text? I know named entity recognition exists, but I don't know how I would extend this to only extract human entities and then select adjectives which describe them.",278
198,198,Topic modelling for single document?,The common techniques to do topic modelling (eg. SVD) depend on multiple documents. What's a good method for extracting topics for a single document?,https://www.reddit.com/r/LanguageTechnology/comments/nat8fr/topic_modelling_for_single_document/,LanguageTechnology,t3_nat8fr,Topic modelling for single document? The common techniques to do topic modelling (eg. SVD) depend on multiple documents. What's a good method for extracting topics for a single document?,186
199,199,FactSumm: Factual Consistency Scorer for Abstractive Summarization,,https://github.com/Huffon/factsumm,LanguageTechnology,t3_nakqet,FactSumm: Factual Consistency Scorer for Abstractive Summarization ,67
200,200,"Machine learning workflows to summarize, translate, transcribe and more","&amp;#x200B;

https://reddit.com/link/nacy0z/video/enf2j74sbly61/player

What if we want to extract and summarize text from documents, also handle translation, combine the  outputs and load it into an Embeddings index. Enter workflows! The demo above takes a list of GitHub project pages, extracts text from HTML, summarizes the text and builds a similarity search index. This same concept could be applied towards a list of company pages, wikipedia  pages and more. This is just one example of what txtai workflows can do.

txtai workflows are a simple yet powerful construct that takes a callable and returns elements. Workflows are streaming by nature and work on data in batches, allowing large volumes of data to be processed efficiently. The amount of functionality provided by machine learning models continues to grow rapidly. txtai provides an easy way to interface with these models. The following is a non-comprehensive list.

\- Questions - Extractive question-answering using a text context  
\- Labels - Apply labels to text using a zero-shot classification model  
\- Summary - Abstractive text summarization  
\- Text Extraction - Extract text from documents  
\- Transcription - Transcribe audio to text  
\- Translation - Machine translation

Workflows allows joining these models together to create powerful data transformations. Workflows can also be constructed in JavaScript, Go, Rust and Java via the API.

See the following links for more information.

[GitHub](https://github.com/neuml/txtai) | [Workflow builder](https://github.com/neuml/txtai/blob/master/examples/workflows.py) | [Documentation](https://neuml.github.io/txtai) | [Article](https://towardsdatascience.com/run-machine-learning-workflows-to-transform-data-and-build-ai-powered-text-indices-with-txtai-43d769b566a7)",https://www.reddit.com/r/LanguageTechnology/comments/nacy0z/machine_learning_workflows_to_summarize_translate/,LanguageTechnology,t3_nacy0z,"Machine learning workflows to summarize, translate, transcribe and more &amp;#x200B;

https://reddit.com/link/nacy0z/video/enf2j74sbly61/player

What if we want to extract and summarize text from documents, also handle translation, combine the  outputs and load it into an Embeddings index. Enter workflows! The demo above takes a list of GitHub project pages, extracts text from HTML, summarizes the text and builds a similarity search index. This same concept could be applied towards a list of company pages, wikipedia  pages and more. This is just one example of what txtai workflows can do.

txtai workflows are a simple yet powerful construct that takes a callable and returns elements. Workflows are streaming by nature and work on data in batches, allowing large volumes of data to be processed efficiently. The amount of functionality provided by machine learning models continues to grow rapidly. txtai provides an easy way to interface with these models. The following is a non-comprehensive list.

\- Questions - Extractive question-answering using a text context  
\- Labels - Apply labels to text using a zero-shot classification model  
\- Summary - Abstractive text summarization  
\- Text Extraction - Extract text from documents  
\- Transcription - Transcribe audio to text  
\- Translation - Machine translation

Workflows allows joining these models together to create powerful data transformations. Workflows can also be constructed in JavaScript, Go, Rust and Java via the API.

See the following links for more information.

[GitHub](https://github.com/neuml/txtai) | [Workflow builder](https://github.com/neuml/txtai/blob/master/examples/workflows.py) | [Documentation](https://neuml.github.io/txtai) | [Article](https://towardsdatascience.com/run-machine-learning-workflows-to-transform-data-and-build-ai-powered-text-indices-with-txtai-43d769b566a7)",1876
201,201,Are AAAI and IAAI tier I conferences?,Are [IAAI](https://aaai.org/Conferences/IAAI/iaai.php) INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE and AAAI Conference on Artificial Intelligence considered as tier I conferences in AI? Both of these seem to be quite popular but I am not sure if these could be called tier I. How can I find out if a particular conference is a tier I conference?,https://www.reddit.com/r/LanguageTechnology/comments/napn21/are_aaai_and_iaai_tier_i_conferences/,LanguageTechnology,t3_napn21,Are AAAI and IAAI tier I conferences? Are [IAAI](https://aaai.org/Conferences/IAAI/iaai.php) INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE and AAAI Conference on Artificial Intelligence considered as tier I conferences in AI? Both of these seem to be quite popular but I am not sure if these could be called tier I. How can I find out if a particular conference is a tier I conference?,401
202,202,BERT-QE: Contextualized Query Expansion for Document Re-ranking,,https://link.medium.com/LxXy8cjvagb,LanguageTechnology,t3_n9t3ii,BERT-QE: Contextualized Query Expansion for Document Re-ranking ,64
203,203,¿Master in Digital text Analysis (UAntwerp-Belgium) vs Master in Computational linguistics (UStuttgart-Germany)?,"Hello! I'd like to know your opinions about these two programs. I am applying to both, but I'm not sure which one is better. I have a background in Applied linguistics and I would like to move towards Computational linguistics.
I have many argumentd for each program, in fact, so far I have a tie. But what I haven't been able to consider are arguments about the quality and prestige of the programs, so I turn to you. Please, I want to read your opinions!

Thank you in advance!",https://www.reddit.com/r/LanguageTechnology/comments/na5jav/master_in_digital_text_analysis_uantwerpbelgium/,LanguageTechnology,t3_na5jav,"¿Master in Digital text Analysis (UAntwerp-Belgium) vs Master in Computational linguistics (UStuttgart-Germany)? Hello! I'd like to know your opinions about these two programs. I am applying to both, but I'm not sure which one is better. I have a background in Applied linguistics and I would like to move towards Computational linguistics.
I have many argumentd for each program, in fact, so far I have a tie. But what I haven't been able to consider are arguments about the quality and prestige of the programs, so I turn to you. Please, I want to read your opinions!

Thank you in advance!",592
204,204,NLP Keywords to Sentences Text Generation with {keytotext},,https://youtu.be/I0iBzP-SxFY,LanguageTechnology,t3_na71dg,NLP Keywords to Sentences Text Generation with {keytotext} ,59
205,205,Generating Sentences from Keywords using Transformers,"“keytotext” introduces the idea of building a model that would translate keywords into sentences using amazingly powerful T5 model. 

For example- 
Input: India, Capital, New Delhi
Output: The capital of India is New Delhi.

Interesting? Then read this walkthrough, 
Blog: https://lnkd.in/dS9_AH7
GitHub: https://github.com/gagan3012/keytotext",https://www.reddit.com/r/LanguageTechnology/comments/n92sfi/generating_sentences_from_keywords_using/,LanguageTechnology,t3_n92sfi,"Generating Sentences from Keywords using Transformers “keytotext” introduces the idea of building a model that would translate keywords into sentences using amazingly powerful T5 model. 

For example- 
Input: India, Capital, New Delhi
Output: The capital of India is New Delhi.

Interesting? Then read this walkthrough, 
Blog: https://lnkd.in/dS9_AH7
GitHub: https://github.com/gagan3012/keytotext",397
206,206,How to pass in two count vectorizers as separate features into MLP?,"I have two text columns. 

The objective is to vectorize each column separately. And then pass them into a MLP, so that the model can also understand which column a word is coming from.

But I am confused as to how to actually implement this.

Any help or resources would be appreciated.",https://www.reddit.com/r/LanguageTechnology/comments/n9cnxk/how_to_pass_in_two_count_vectorizers_as_separate/,LanguageTechnology,t3_n9cnxk,"How to pass in two count vectorizers as separate features into MLP? I have two text columns. 

The objective is to vectorize each column separately. And then pass them into a MLP, so that the model can also understand which column a word is coming from.

But I am confused as to how to actually implement this.

Any help or resources would be appreciated.",355
207,207,Anyone know of any papers that look at latent NER? Entities which are not exactly mentioned in the text.,"So far I could only find this one

https://www.aclweb.org/anthology/K18-1020/",https://www.reddit.com/r/LanguageTechnology/comments/n9asbs/anyone_know_of_any_papers_that_look_at_latent_ner/,LanguageTechnology,t3_n9asbs,"Anyone know of any papers that look at latent NER? Entities which are not exactly mentioned in the text. So far I could only find this one

https://www.aclweb.org/anthology/K18-1020/",182
208,208,Any known applications/developments between decentralised ledger (crypto) systems and MT/CAT?,"I have been searching around online weekly for any news or interesting developments in the cryptosphere/LSP world.

Keywords like decentralization, verification, remote, payment, trustless, exchange, control ... to me sound like there is much room for overlap, but there seems to be very little out there besides conjectures of NMT going to the ""cloud"" then the cryptosphere, which doesn't mean anything... 

Crtain coins/platforms like to market themselves as being a translation-crypto coin/platform but it is merely replacing QC and payment with crypto-incentives (that are not very motivating for a career translator).

I would to hear any thoughts on this from fellow LSPs and interested parties who are into augmenting their capabilities with what technology has to offer.

I have cross-posted this across some relevant subreddits.
Thanks in advance!",https://www.reddit.com/r/LanguageTechnology/comments/n90h0s/any_known_applicationsdevelopments_between/,LanguageTechnology,t3_n90h0s,"Any known applications/developments between decentralised ledger (crypto) systems and MT/CAT? I have been searching around online weekly for any news or interesting developments in the cryptosphere/LSP world.

Keywords like decentralization, verification, remote, payment, trustless, exchange, control ... to me sound like there is much room for overlap, but there seems to be very little out there besides conjectures of NMT going to the ""cloud"" then the cryptosphere, which doesn't mean anything... 

Crtain coins/platforms like to market themselves as being a translation-crypto coin/platform but it is merely replacing QC and payment with crypto-incentives (that are not very motivating for a career translator).

I would to hear any thoughts on this from fellow LSPs and interested parties who are into augmenting their capabilities with what technology has to offer.

I have cross-posted this across some relevant subreddits.
Thanks in advance!",950
209,209,NER for Resume parsing,"Hello,

I need to do resume parsing with French resumes. I will use Prodigy ([prodi.gy](https://prodi.gy)) to annotate my dataset and make my model.

My question is : is it better to annotate with the full resume or annotate line by line  ,

for me, the position of the text in the full document is an information but maybe spacy don't care.

Thanks !",https://www.reddit.com/r/LanguageTechnology/comments/n8yidr/ner_for_resume_parsing/,LanguageTechnology,t3_n8yidr,"NER for Resume parsing Hello,

I need to do resume parsing with French resumes. I will use Prodigy ([prodi.gy](https://prodi.gy)) to annotate my dataset and make my model.

My question is : is it better to annotate with the full resume or annotate line by line  ,

for me, the position of the text in the full document is an information but maybe spacy don't care.

Thanks !",374
210,210,Best way of integrating a NLP model in Python with a .NET Core API?,"I've recently started working as a .NET web developer building services, but as a side project I'm working on a text summarization API.

I would like to serve [this model](https://huggingface.co/facebook/bart-large-cnn/tree/main) through the API. How should I go about it? I haven't found much after searching, is there any tutorials out there that I'm missing? Do I need to create the API in Python instead of C#?

I would really appreciate any help. Thank you very much and sorry about my English.",https://www.reddit.com/r/LanguageTechnology/comments/n8nokg/best_way_of_integrating_a_nlp_model_in_python/,LanguageTechnology,t3_n8nokg,"Best way of integrating a NLP model in Python with a .NET Core API? I've recently started working as a .NET web developer building services, but as a side project I'm working on a text summarization API.

I would like to serve [this model](https://huggingface.co/facebook/bart-large-cnn/tree/main) through the API. How should I go about it? I haven't found much after searching, is there any tutorials out there that I'm missing? Do I need to create the API in Python instead of C#?

I would really appreciate any help. Thank you very much and sorry about my English.",567
211,211,Pooled Contextualised Embeddings for NER | Research Papers Summary 017,,https://youtu.be/HJtapl3zWC0,LanguageTechnology,t3_n8jz4r,Pooled Contextualised Embeddings for NER | Research Papers Summary 017 ,71
212,212,Is there a python library or API that is able to check the grammar of a sentence?,,https://www.reddit.com/r/LanguageTechnology/comments/n8qpvb/is_there_a_python_library_or_api_that_is_able_to/,LanguageTechnology,t3_n8qpvb,Is there a python library or API that is able to check the grammar of a sentence? ,82
213,213,Text Generation using GPT-Neo,,https://link.medium.com/84WG7KXa7fb,LanguageTechnology,t3_n8ao75,Text Generation using GPT-Neo ,30
214,214,How to increase the performance?,"I am trying to solve a multi-class emotion classification problem using BERT (NLP). It is my first ever BERT model and my model ended up overfitting.

    {""train"": {""eval_examples_count"": 10481, ""metrics"": {""f1_weighted"": 0.8869, ""f1_macro"": 0.8401, ""accuracy"": 0.8884, ""roc_auc"": 0.9686}, ""time_spent"": ""1:27:10""}} 
    {""valid"": {""eval_examples_count"": 3493, ""metrics"": {""f1_weighted"": 0.6112, ""f1_macro"": 0.5257, ""accuracy"": 0.6184, ""roc_auc"": 0.8177}, ""time_spent"": ""0:28:37""}} 
    {""test"": {""eval_examples_count"": 3494, ""metrics"": {""f1_weighted"": 0.6191, ""f1_macro"": 0.5282, ""accuracy"": 0.6259, ""roc_auc"": 0.8271}, ""time_spent"": ""0:28:26”}} 

Classes were pretty unbalanced, that's probably why it is overfitting i thought, and then I used the undersampling technique to come over this issue.

    Train:
    sad          756
    angry        756
    surprised    756
    smile        756
    kind         756
    
    Test:
    sad          235
    surprised    235
    angry        235
    kind         235
    smile        235
    
    Val:
    sad          235
    surprised    235
    angry        235
    kind         235
    smile        235

I know the dataset became too small, but it is just for training my model faster and quickly experiment with different approaches. In fact, using my entire dataset and this testing dataset both have been giving pretty similar results.

After balancing my dataset result looks like this:

    {""train"": {""eval_examples_count"": 3780, ""metrics"": {""f1_weighted"": 0.8719, ""f1_macro"": 0.8719, ""accuracy"": 0.8725, ""roc_auc"": 0.9744}, ""time_spent"": ""0:38:33""}} 
    {""valid"": {""eval_examples_count"": 1215, ""metrics"": {""f1_weighted"": 0.5165, ""f1_macro"": 0.5165, ""accuracy"": 0.5185, ""roc_auc"": 0.7993}, ""time_spent"": ""0:12:16""}} 
    {""test"": {""eval_examples_count"": 1215, ""metrics"": {""f1_weighted"": 0.5264, ""f1_macro"": 0.5264, ""accuracy"": 0.5276, ""roc_auc"": 0.8051}, ""time_spent"": ""0:12:28""}} 

So, dropping instances and balancing the dataset DIT NOT really solve the overfitting problem.

Then I decided to use the Drop Out technique and made it equal to 0.5

            ""keep_prob"": 0.5,
            ""learning_rate"": 1e-05,
            ""learning_rate_drop_patience"": 2,
            ""learning_rate_drop_div"": 2.0,
            ""load_before_drop"": True, 
            ""attention_probs_keep_prob"": 0.5,
            ""hidden_keep_prob"": 0.5,

that really solved the overfitting issue, however, badly affected on the performance of the training/model:

    {""train"": {""eval_examples_count"": 32, ""metrics"": {""f1_weighted"": 0.4099, ""f1_macro"": 0.3828, ""accuracy"": 0.4688, ""roc_auc"": 0.6969}, ""time_spent"": ""3:57:36"", ""epochs_done"": 3, ""batches_seen"": 357, ""train_examples_seen"": 11340, ""learning_rate"": 1e-05, ""loss"": 1.4732106072562081} 
    {""valid"": {""eval_examples_count"": 1215, ""metrics"": {""f1_weighted"": 0.3798, ""f1_macro"": 0.3798, ""accuracy"": 0.4272, ""roc_auc"": 0.7127}, ""time_spent"": ""4:06:33"", ""epochs_done"": 3, ""batches_seen"": 357, ""train_examples_seen"": 11340, ""impatience"": 0, ""patience_limit"": 2}} 

Now, I think I solved the overfitting problem, however, How can I improve the overall performance/accuracy? Maybe increasing the learning rate? I can really try all possible approaches but it is really taking too much time of mine, each training is roughly about 4-5 hours (On the small dataset) on the big one it goes to 15-17 hours. It is really hit or miss right now. I am really new in this field but i need to solve this problem. Any idea how to increase the performance would be appreciated. Thank you",https://www.reddit.com/r/LanguageTechnology/comments/n85h06/how_to_increase_the_performance/,LanguageTechnology,t3_n85h06,"How to increase the performance? I am trying to solve a multi-class emotion classification problem using BERT (NLP). It is my first ever BERT model and my model ended up overfitting.

    {""train"": {""eval_examples_count"": 10481, ""metrics"": {""f1_weighted"": 0.8869, ""f1_macro"": 0.8401, ""accuracy"": 0.8884, ""roc_auc"": 0.9686}, ""time_spent"": ""1:27:10""}} 
    {""valid"": {""eval_examples_count"": 3493, ""metrics"": {""f1_weighted"": 0.6112, ""f1_macro"": 0.5257, ""accuracy"": 0.6184, ""roc_auc"": 0.8177}, ""time_spent"": ""0:28:37""}} 
    {""test"": {""eval_examples_count"": 3494, ""metrics"": {""f1_weighted"": 0.6191, ""f1_macro"": 0.5282, ""accuracy"": 0.6259, ""roc_auc"": 0.8271}, ""time_spent"": ""0:28:26”}} 

Classes were pretty unbalanced, that's probably why it is overfitting i thought, and then I used the undersampling technique to come over this issue.

    Train:
    sad          756
    angry        756
    surprised    756
    smile        756
    kind         756
    
    Test:
    sad          235
    surprised    235
    angry        235
    kind         235
    smile        235
    
    Val:
    sad          235
    surprised    235
    angry        235
    kind         235
    smile        235

I know the dataset became too small, but it is just for training my model faster and quickly experiment with different approaches. In fact, using my entire dataset and this testing dataset both have been giving pretty similar results.

After balancing my dataset result looks like this:

    {""train"": {""eval_examples_count"": 3780, ""metrics"": {""f1_weighted"": 0.8719, ""f1_macro"": 0.8719, ""accuracy"": 0.8725, ""roc_auc"": 0.9744}, ""time_spent"": ""0:38:33""}} 
    {""valid"": {""eval_examples_count"": 1215, ""metrics"": {""f1_weighted"": 0.5165, ""f1_macro"": 0.5165, ""accuracy"": 0.5185, ""roc_auc"": 0.7993}, ""time_spent"": ""0:12:16""}} 
    {""test"": {""eval_examples_count"": 1215, ""metrics"": {""f1_weighted"": 0.5264, ""f1_macro"": 0.5264, ""accuracy"": 0.5276, ""roc_auc"": 0.8051}, ""time_spent"": ""0:12:28""}} 

So, dropping instances and balancing the dataset DIT NOT really solve the overfitting problem.

Then I decided to use the Drop Out technique and made it equal to 0.5

            ""keep_prob"": 0.5,
            ""learning_rate"": 1e-05,
            ""learning_rate_drop_patience"": 2,
            ""learning_rate_drop_div"": 2.0,
            ""load_before_drop"": True, 
            ""attention_probs_keep_prob"": 0.5,
            ""hidden_keep_prob"": 0.5,

that really solved the overfitting issue, however, badly affected on the performance of the training/model:

    {""train"": {""eval_examples_count"": 32, ""metrics"": {""f1_weighted"": 0.4099, ""f1_macro"": 0.3828, ""accuracy"": 0.4688, ""roc_auc"": 0.6969}, ""time_spent"": ""3:57:36"", ""epochs_done"": 3, ""batches_seen"": 357, ""train_examples_seen"": 11340, ""learning_rate"": 1e-05, ""loss"": 1.4732106072562081} 
    {""valid"": {""eval_examples_count"": 1215, ""metrics"": {""f1_weighted"": 0.3798, ""f1_macro"": 0.3798, ""accuracy"": 0.4272, ""roc_auc"": 0.7127}, ""time_spent"": ""4:06:33"", ""epochs_done"": 3, ""batches_seen"": 357, ""train_examples_seen"": 11340, ""impatience"": 0, ""patience_limit"": 2}} 

Now, I think I solved the overfitting problem, however, How can I improve the overall performance/accuracy? Maybe increasing the learning rate? I can really try all possible approaches but it is really taking too much time of mine, each training is roughly about 4-5 hours (On the small dataset) on the big one it goes to 15-17 hours. It is really hit or miss right now. I am really new in this field but i need to solve this problem. Any idea how to increase the performance would be appreciated. Thank you",3595
215,215,How to deal with the processed sentences whose length are equal to 0 and not greater than the minimal length of sentences of model,"After doing data cleaning and preprocesses for sentences like converting words to their lemma or lowercase, some sentences are equal to 0 and not greater than the minimal length of sentences of the model.

So I think the best way to deal with these sentences is to delete those sentences whose length is 0. 

But I am wondering if there is a more suitable way in this situation?

Thanks in advance.",https://www.reddit.com/r/LanguageTechnology/comments/n8bimb/how_to_deal_with_the_processed_sentences_whose/,LanguageTechnology,t3_n8bimb,"How to deal with the processed sentences whose length are equal to 0 and not greater than the minimal length of sentences of model After doing data cleaning and preprocesses for sentences like converting words to their lemma or lowercase, some sentences are equal to 0 and not greater than the minimal length of sentences of the model.

So I think the best way to deal with these sentences is to delete those sentences whose length is 0. 

But I am wondering if there is a more suitable way in this situation?

Thanks in advance.",529
216,216,"[Q] Why is interpretability important in natural language processing? This is easier to answer for models that make high stakes decisions (e.g., surgical risk assessment; self-driving car slamming brakes; etc.,), but I would like to understand why we care about interpretability in NLP.",,https://www.reddit.com/r/LanguageTechnology/comments/n7udhn/q_why_is_interpretability_important_in_natural/,LanguageTechnology,t3_n7udhn,"[Q] Why is interpretability important in natural language processing? This is easier to answer for models that make high stakes decisions (e.g., surgical risk assessment; self-driving car slamming brakes; etc.,), but I would like to understand why we care about interpretability in NLP. ",287
218,218,How come we haven't seen the Albert architecture trained by the Electra pretraining method?,It seems like a low hanging fruit that the architecture that usually have the top results be trained by the pre-training regimen that usually have the top results.,https://www.reddit.com/r/LanguageTechnology/comments/n7lmg8/how_come_we_havent_seen_the_albert_architecture/,LanguageTechnology,t3_n7lmg8,How come we haven't seen the Albert architecture trained by the Electra pretraining method? It seems like a low hanging fruit that the architecture that usually have the top results be trained by the pre-training regimen that usually have the top results.,255
219,219,MLE/NLP Engineer Positions at Big Tech,"Hi,

I'm currently a rising senior majoring in CS at a top 10 university in the US. I'm debating between graduating just with bachelor's or pursuing a master's in NLP/Human Language Technology (would only take me extra two semesters). I'm mainly interested in NLP, Text Mining and recommendation systems (haven't taken speech processing yet). My school is huge (top 3-5) in the NLP realm, and this is important not because of the rankings but because of the support and opportunities I'll have access to during my masters. If I graduate just with a bachelor's, then I'm considering an SWE role at big techs. If I end up doing a master's, then an applied ML position (MLE, NLP engineer, etc) at big techs.

I have taken some courses related to NLP/DL; I enjoyed them, but at the moment I'm not sure if I liked it enough to do a master's in it and potentially commit my career path to it. Job prospects and competitiveness of getting such positions at big techs would factor a lot in my decision.

I'm wondering how competitive it is to get an MLE/NLP engineer positions at big tech firms like FAANg, Linkedin, etc. What would the expectations/requirements be for MLE/NLP positions (ML- and NLP-related knowledge, research/internship experience, personal projects, publication, Leetcode, etc)? Also, what would an engineer at such positions work on on a regular day? In your opinion, what are the pros and cons of each role (MLE/NLP engineer vs. general SWE)? What would be the kinds of advantages an MLE/NLP engineer would have over general SWEs?

Thank you!",https://www.reddit.com/r/LanguageTechnology/comments/n7s7j8/mlenlp_engineer_positions_at_big_tech/,LanguageTechnology,t3_n7s7j8,"MLE/NLP Engineer Positions at Big Tech Hi,

I'm currently a rising senior majoring in CS at a top 10 university in the US. I'm debating between graduating just with bachelor's or pursuing a master's in NLP/Human Language Technology (would only take me extra two semesters). I'm mainly interested in NLP, Text Mining and recommendation systems (haven't taken speech processing yet). My school is huge (top 3-5) in the NLP realm, and this is important not because of the rankings but because of the support and opportunities I'll have access to during my masters. If I graduate just with a bachelor's, then I'm considering an SWE role at big techs. If I end up doing a master's, then an applied ML position (MLE, NLP engineer, etc) at big techs.

I have taken some courses related to NLP/DL; I enjoyed them, but at the moment I'm not sure if I liked it enough to do a master's in it and potentially commit my career path to it. Job prospects and competitiveness of getting such positions at big techs would factor a lot in my decision.

I'm wondering how competitive it is to get an MLE/NLP engineer positions at big tech firms like FAANg, Linkedin, etc. What would the expectations/requirements be for MLE/NLP positions (ML- and NLP-related knowledge, research/internship experience, personal projects, publication, Leetcode, etc)? Also, what would an engineer at such positions work on on a regular day? In your opinion, what are the pros and cons of each role (MLE/NLP engineer vs. general SWE)? What would be the kinds of advantages an MLE/NLP engineer would have over general SWEs?

Thank you!",1596
220,220,[Tutorial] Implementing different question-answering models with Hugging Face,"This tutorial covers how to implement 5 different question-answering models with Hugging Face, along with the theory behind each model and the different datasets used to pre-train them. We'll also look at the varying baselines for each of the models in terms of F1 and EM scores.  

Topics covered include:

* The Transformer Architecture
* Popular Datasets and Evaluation Metrics
* BERT (Bidirectional Encoder Representations from Transformers)
* ALBERT: A Lite BERT
* ELECTRA
* BART
* Issues with Long Document Question-Answering Using Standard Models
* LONGFORMER: the Long-Document Transformer

Tutorial link: [https://blog.paperspace.com/question-answering-models-a-comparison/](https://blog.paperspace.com/question-answering-models-a-comparison/)

Run the full code on a free GPU: [https://ml-showcase.paperspace.com/projects/question-answering-models](https://ml-showcase.paperspace.com/projects/question-answering-models)

Questions and comments encouraged!",https://www.reddit.com/r/LanguageTechnology/comments/n72vuk/tutorial_implementing_different_questionanswering/,LanguageTechnology,t3_n72vuk,"[Tutorial] Implementing different question-answering models with Hugging Face This tutorial covers how to implement 5 different question-answering models with Hugging Face, along with the theory behind each model and the different datasets used to pre-train them. We'll also look at the varying baselines for each of the models in terms of F1 and EM scores.  

Topics covered include:

* The Transformer Architecture
* Popular Datasets and Evaluation Metrics
* BERT (Bidirectional Encoder Representations from Transformers)
* ALBERT: A Lite BERT
* ELECTRA
* BART
* Issues with Long Document Question-Answering Using Standard Models
* LONGFORMER: the Long-Document Transformer

Tutorial link: [https://blog.paperspace.com/question-answering-models-a-comparison/](https://blog.paperspace.com/question-answering-models-a-comparison/)

Run the full code on a free GPU: [https://ml-showcase.paperspace.com/projects/question-answering-models](https://ml-showcase.paperspace.com/projects/question-answering-models)

Questions and comments encouraged!",1043
221,221,Computer-Aided Design as Language,,https://arxiv.org/abs/2105.02769,LanguageTechnology,t3_n7ct8t,Computer-Aided Design as Language ,34
222,222,NLPCloud.io for transformer-based models in production (PyTorch and TensorFlow),"Some of you might already know the [NLPCloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=23caa648-af1d-11eb-8529-0242ac130003) project I recently launched. The idea was to help developers and data scientists deploy spaCy models to production in a minute. It came from the fact that, as a developer, I spent much more time than I wanted on this DevOps part in my NLP projects. I was also seeing quite a lot of ML projects failing because teams didn't have the skills to deploy their new models to production... 

I had a lot of user requests asking me to support Hugging Face transformer-based models too, in addition to spaCy models. So I'm happy to announce that, after weeks of hard work, **it is now possible to deploy your own transformer-based models** to [https://nlpcloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=23caa648-af1d-11eb-8529-0242ac130003) , whether they are running on PyTorch or TensorFlow!

It can be useful in 2 situations:

* You developed your own models from scratch but you are having a hard time using them in production (because it takes an API, because resource consumption is very high, because you need high-availability, because server costs are too high, because you don't have advanced DevOps skills, etc.)
* You already use one of the Hugging Face pre-trained models on [NLPCloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=23caa648-af1d-11eb-8529-0242ac130003). It's not working so bad but you want to fine-tune them in order to adapt them to your own needs.

You can choose to either have your models run on CPU or GPU, depending on your requirements, and you can upload as many models as you want. Each new model has its own API endpoint, so you can use some of them in production while others are for testing only. It also makes it easy to urgently rollback to a previous model if needed.

Internally, everything is based on FastAPI and tons of Docker containers (if you are curious about our infra please don't hesitate to ask, I will be glad to comment).

For more details here is the API documentation: [https://docs.nlpcloud.io/#upload-your-transformers-based-model](https://docs.nlpcloud.io/#upload-your-transformers-based-model)

I really hope you will like it and find it useful!

I would love to have your opinion on this new feature. Please don't hesitate to answer this post!",https://www.reddit.com/r/LanguageTechnology/comments/n6vki5/nlpcloudio_for_transformerbased_models_in/,LanguageTechnology,t3_n6vki5,"NLPCloud.io for transformer-based models in production (PyTorch and TensorFlow) Some of you might already know the [NLPCloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=23caa648-af1d-11eb-8529-0242ac130003) project I recently launched. The idea was to help developers and data scientists deploy spaCy models to production in a minute. It came from the fact that, as a developer, I spent much more time than I wanted on this DevOps part in my NLP projects. I was also seeing quite a lot of ML projects failing because teams didn't have the skills to deploy their new models to production... 

I had a lot of user requests asking me to support Hugging Face transformer-based models too, in addition to spaCy models. So I'm happy to announce that, after weeks of hard work, **it is now possible to deploy your own transformer-based models** to [https://nlpcloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=23caa648-af1d-11eb-8529-0242ac130003) , whether they are running on PyTorch or TensorFlow!

It can be useful in 2 situations:

* You developed your own models from scratch but you are having a hard time using them in production (because it takes an API, because resource consumption is very high, because you need high-availability, because server costs are too high, because you don't have advanced DevOps skills, etc.)
* You already use one of the Hugging Face pre-trained models on [NLPCloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=23caa648-af1d-11eb-8529-0242ac130003). It's not working so bad but you want to fine-tune them in order to adapt them to your own needs.

You can choose to either have your models run on CPU or GPU, depending on your requirements, and you can upload as many models as you want. Each new model has its own API endpoint, so you can use some of them in production while others are for testing only. It also makes it easy to urgently rollback to a previous model if needed.

Internally, everything is based on FastAPI and tons of Docker containers (if you are curious about our infra please don't hesitate to ask, I will be glad to comment).

For more details here is the API documentation: [https://docs.nlpcloud.io/#upload-your-transformers-based-model](https://docs.nlpcloud.io/#upload-your-transformers-based-model)

I really hope you will like it and find it useful!

I would love to have your opinion on this new feature. Please don't hesitate to answer this post!",2455
223,223,Does a sequential fine-tuning process for BERT make sense?,"Hello everyone,

Quick question: I am working on a low resource language that even large multilingual models such as [mBERT](https://huggingface.co/bert-base-multilingual-cased) fail to represent properly. So, can I fine-tune these models on MLM just like they were originally trained and then fine-tune it again on a specific task? In other words:

1. Fine-tune mBERT on the masked language modeling task (using a domain-specific corpus)
2. Fine-tune the resulting model on a different task (say semantic analysis)
3. Test the model

Does this make sense? Is this equivalent to training a BERT model from scratch using the same multilingual corpus in mBERT, with my corpus added to it, or is it different? If so, how's it different?

Thank you for your time. I really appreciate any knowledge on the matter.",https://www.reddit.com/r/LanguageTechnology/comments/n709v8/does_a_sequential_finetuning_process_for_bert/,LanguageTechnology,t3_n709v8,"Does a sequential fine-tuning process for BERT make sense? Hello everyone,

Quick question: I am working on a low resource language that even large multilingual models such as [mBERT](https://huggingface.co/bert-base-multilingual-cased) fail to represent properly. So, can I fine-tune these models on MLM just like they were originally trained and then fine-tune it again on a specific task? In other words:

1. Fine-tune mBERT on the masked language modeling task (using a domain-specific corpus)
2. Fine-tune the resulting model on a different task (say semantic analysis)
3. Test the model

Does this make sense? Is this equivalent to training a BERT model from scratch using the same multilingual corpus in mBERT, with my corpus added to it, or is it different? If so, how's it different?

Thank you for your time. I really appreciate any knowledge on the matter.",867
224,224,Comparing individual predictions of two models,"Is it okay to use Matthews Correlation Coefficient (phi coefficient) to compare the predictions of two different models?

&amp;#x200B;

Is this code correct:?

&amp;#x200B;

from sklearn.metrics import matthews\_corrcoef  

&amp;#x200B;

model4 = MultinomialNB() 

model4.fit(X\_train, y\_train) 

y\_pred4 = model4.predict(X\_test)  

&amp;#x200B;

model5 = BernoulliNB() 

model5.fit(X\_train, y\_train) 

y\_pred5 = model5.predict(X\_test)  

&amp;#x200B;

matthews\_corrcoef(y\_pred4, y\_pred5)",https://www.reddit.com/r/LanguageTechnology/comments/n6zncc/comparing_individual_predictions_of_two_models/,LanguageTechnology,t3_n6zncc,"Comparing individual predictions of two models Is it okay to use Matthews Correlation Coefficient (phi coefficient) to compare the predictions of two different models?

&amp;#x200B;

Is this code correct:?

&amp;#x200B;

from sklearn.metrics import matthews\_corrcoef  

&amp;#x200B;

model4 = MultinomialNB() 

model4.fit(X\_train, y\_train) 

y\_pred4 = model4.predict(X\_test)  

&amp;#x200B;

model5 = BernoulliNB() 

model5.fit(X\_train, y\_train) 

y\_pred5 = model5.predict(X\_test)  

&amp;#x200B;

matthews\_corrcoef(y\_pred4, y\_pred5)",545
225,225,Are there any open-source aspect-oriented sentiment analysis APIs out there?,"Hey guys, I need some help. I need to find an open-source API for doing aspect-oriented sentiment analysis within this week. My brother is doing his first software project right now and I'd like to help him with his research. I was wondering if there are any sentiment analysis APIs or tools that can scan for the sentiment value of a specific topic word. Or maybe a sentiment analysis tool or trick that can be combined with a TF-IDF algorithm in order to do the same job.

Thanks in advance.",https://www.reddit.com/r/LanguageTechnology/comments/n6xx98/are_there_any_opensource_aspectoriented_sentiment/,LanguageTechnology,t3_n6xx98,"Are there any open-source aspect-oriented sentiment analysis APIs out there? Hey guys, I need some help. I need to find an open-source API for doing aspect-oriented sentiment analysis within this week. My brother is doing his first software project right now and I'd like to help him with his research. I was wondering if there are any sentiment analysis APIs or tools that can scan for the sentiment value of a specific topic word. Or maybe a sentiment analysis tool or trick that can be combined with a TF-IDF algorithm in order to do the same job.

Thanks in advance.",570
226,226,Recursive neural networks,"Normally, a recursive neural network is trained by back-propagating through every level of a tree (from the top to the bottom).

Did anybody encounter an example where a recursive neural network is trained by back-propagating on each level separately, calculating loss and updating weights on each level of the tree?

I am trying to do that on a ""pyramid"" binary tree, where the whole pyramid has the same consistent structure. I am looking for other similar examples so I can see how to improve my implementation.",https://www.reddit.com/r/LanguageTechnology/comments/n6wsn0/recursive_neural_networks/,LanguageTechnology,t3_n6wsn0,"Recursive neural networks Normally, a recursive neural network is trained by back-propagating through every level of a tree (from the top to the bottom).

Did anybody encounter an example where a recursive neural network is trained by back-propagating on each level separately, calculating loss and updating weights on each level of the tree?

I am trying to do that on a ""pyramid"" binary tree, where the whole pyramid has the same consistent structure. I am looking for other similar examples so I can see how to improve my implementation.",540
227,227,SpaCy NER Scorer/Example Question,"Created a custom NER model, which takes a blob of text as input. 

I’m trying to get the f1-score, recall, etc by using the Scorer.score method. This method requires a list of Example objects. 

Does anyone have or know of any code examples of how to accomplish this task? I looked for hours on the internet today without any luck, could definitely just be a silly mistake on my part as I’m still relatively new to the field !",https://www.reddit.com/r/LanguageTechnology/comments/n6i00e/spacy_ner_scorerexample_question/,LanguageTechnology,t3_n6i00e,"SpaCy NER Scorer/Example Question Created a custom NER model, which takes a blob of text as input. 

I’m trying to get the f1-score, recall, etc by using the Scorer.score method. This method requires a list of Example objects. 

Does anyone have or know of any code examples of how to accomplish this task? I looked for hours on the internet today without any luck, could definitely just be a silly mistake on my part as I’m still relatively new to the field !",460
228,228,Help on Relation Extraction,"Hello everyone, I need some help, or can I say, a second opinion on what I'm doing.

In the last few months I've been using spacy and nltk. Currently I'm working on a project in which I have to link multiple entities across multiple sentences. The main goal is to develop a knowledge graph. Now I'm using  mainly the dependency parser and other vanilla nlp techniques to filter out the relations between entities.

Now I'm seeking a second opinion,  after searching a few papers I'm finding a lot of work using machine learning, but I'm a total noob in that area. I'm feeling that I'm using the wrong approach.

Can someone help me out in the sense of, what I'm doing is actually not that bad or should I follow other approach, but again, I'm a total noob in the ML world.",https://www.reddit.com/r/LanguageTechnology/comments/n6ljt0/help_on_relation_extraction/,LanguageTechnology,t3_n6ljt0,"Help on Relation Extraction Hello everyone, I need some help, or can I say, a second opinion on what I'm doing.

In the last few months I've been using spacy and nltk. Currently I'm working on a project in which I have to link multiple entities across multiple sentences. The main goal is to develop a knowledge graph. Now I'm using  mainly the dependency parser and other vanilla nlp techniques to filter out the relations between entities.

Now I'm seeking a second opinion,  after searching a few papers I'm finding a lot of work using machine learning, but I'm a total noob in that area. I'm feeling that I'm using the wrong approach.

Can someone help me out in the sense of, what I'm doing is actually not that bad or should I follow other approach, but again, I'm a total noob in the ML world.",800
229,229,German Question Answering and Dense Passage Retrieval Datasets,[https://deepset.ai/germanquad](https://deepset.ai/germanquad),https://www.reddit.com/r/LanguageTechnology/comments/n6a94i/german_question_answering_and_dense_passage/,LanguageTechnology,t3_n6a94i,German Question Answering and Dense Passage Retrieval Datasets [https://deepset.ai/germanquad](https://deepset.ai/germanquad),125
230,230,KNN performs better on Word2Vec pretrained embedding than on TF-IDF vector representation,"Hi All.

I am doing a project on multi-class text classification and could do with some advice.

I have a dataset of reviews which are classified into 7 product categories.

Firstly, I create a term document matrix using TF-IDF (tfidfvectorizer from sklearn). This generates a matrix of n x m where n in the number of reviews in my dataset and m is the number of features.

Then after splitting term document matrix into 80:20 train:test, I pass it through the K-Nearest Neighbours (KNN) algorithm and achieve an accuracy of 53%.

&amp;#x200B;

In another experiment, I used the Google News Word2Vec pretrained embedding (300 dimensional) and averaged all the word vectors for each review. So, each review consists of x words and each of the words has a 300 dimensional vector. Each of the vectors are averaged to produce one 300 dimensional vector per review.

&amp;#x200B;

Then I pass this matrix through KNN. I get an accuracy of 72%.

&amp;#x200B;

As for other classifiers that I tested on the same dataset, all of them performed better on the TF-IDF method of vectorization. However, KNN performed better on word2vec.

Can anyone help me understand why there is a jump in accuracy for KNN in using the word2vec method as compared to when using the tfidf method?",https://www.reddit.com/r/LanguageTechnology/comments/n65ktg/knn_performs_better_on_word2vec_pretrained/,LanguageTechnology,t3_n65ktg,"KNN performs better on Word2Vec pretrained embedding than on TF-IDF vector representation Hi All.

I am doing a project on multi-class text classification and could do with some advice.

I have a dataset of reviews which are classified into 7 product categories.

Firstly, I create a term document matrix using TF-IDF (tfidfvectorizer from sklearn). This generates a matrix of n x m where n in the number of reviews in my dataset and m is the number of features.

Then after splitting term document matrix into 80:20 train:test, I pass it through the K-Nearest Neighbours (KNN) algorithm and achieve an accuracy of 53%.

&amp;#x200B;

In another experiment, I used the Google News Word2Vec pretrained embedding (300 dimensional) and averaged all the word vectors for each review. So, each review consists of x words and each of the words has a 300 dimensional vector. Each of the vectors are averaged to produce one 300 dimensional vector per review.

&amp;#x200B;

Then I pass this matrix through KNN. I get an accuracy of 72%.

&amp;#x200B;

As for other classifiers that I tested on the same dataset, all of them performed better on the TF-IDF method of vectorization. However, KNN performed better on word2vec.

Can anyone help me understand why there is a jump in accuracy for KNN in using the word2vec method as compared to when using the tfidf method?",1358
231,231,"Is there a reason text autoencoders mostly employ RNNs for encoder and decoder, instead of Transformers?","Hi. 

A trend I noticed in many papers that employ Autoencoders in text is that they use RNNs for encoding/decoding.

This might have something to do with data insufficiencies in fields that call for text autoencoders. (Since transformers are known to require a lot of training data). I am not sure.

I’d appreciate any insight into this!

Edit:

Some examples:
- [A Probabilistic Formulation of Unsupervised Text Style Transfer](https://arxiv.org/pdf/2002.03912.pdf)
- [Plug and Play Autoencoders for Conditional Text Generation](https://www.aclweb.org/anthology/2020.emnlp-main.491.pdf)
- [DialogWAE](https://arxiv.org/pdf/1805.12352.pdf)",https://www.reddit.com/r/LanguageTechnology/comments/n62d5p/is_there_a_reason_text_autoencoders_mostly_employ/,LanguageTechnology,t3_n62d5p,"Is there a reason text autoencoders mostly employ RNNs for encoder and decoder, instead of Transformers? Hi. 

A trend I noticed in many papers that employ Autoencoders in text is that they use RNNs for encoding/decoding.

This might have something to do with data insufficiencies in fields that call for text autoencoders. (Since transformers are known to require a lot of training data). I am not sure.

I’d appreciate any insight into this!

Edit:

Some examples:
- [A Probabilistic Formulation of Unsupervised Text Style Transfer](https://arxiv.org/pdf/2002.03912.pdf)
- [Plug and Play Autoencoders for Conditional Text Generation](https://www.aclweb.org/anthology/2020.emnlp-main.491.pdf)
- [DialogWAE](https://arxiv.org/pdf/1805.12352.pdf)",745
232,232,I need help to find a NLP topic for my thesis,"Hi everyone,

I am a second year Master's student and want to write my thesis about an application of NLP model, however, I am struggling to find an original idea. It would be great if you can give me some ideas/advices, because I am really nervous at this point.",https://www.reddit.com/r/LanguageTechnology/comments/n65oq8/i_need_help_to_find_a_nlp_topic_for_my_thesis/,LanguageTechnology,t3_n65oq8,"I need help to find a NLP topic for my thesis Hi everyone,

I am a second year Master's student and want to write my thesis about an application of NLP model, however, I am struggling to find an original idea. It would be great if you can give me some ideas/advices, because I am really nervous at this point.",309
233,233,Something like style transfer for language processing?,"This may be a silly question that is an existing topic already heavily explored by others more involved in NLP than me, but are there tools for taking a paragraph of text and transforming it into a machine-generated paragraph written in another person's style, but having similar content?  Essentially, I am looking for the NLP equivalent of what has already been done to death with GANs on image data (e.g. StyleGAN2).  Thanks in advance for any help!",https://www.reddit.com/r/LanguageTechnology/comments/n5y6an/something_like_style_transfer_for_language/,LanguageTechnology,t3_n5y6an,"Something like style transfer for language processing? This may be a silly question that is an existing topic already heavily explored by others more involved in NLP than me, but are there tools for taking a paragraph of text and transforming it into a machine-generated paragraph written in another person's style, but having similar content?  Essentially, I am looking for the NLP equivalent of what has already been done to death with GANs on image data (e.g. StyleGAN2).  Thanks in advance for any help!",507
234,234,Emotion and Empathy in NLP,"Hey everyone!

I'm a master's student currently doing my research in the field of NLP and I've recently become heavily invested in the idea of implementing concepts such as emotion and empathy in dialogue systems. I was wondering if there was anybody else who was also interested in this topic and wanted to share our resources together? I've made a simple [list of papers](https://github.com/Sahandfer/Empathetic-COAI-Papers) I've read so far (not complete yet). Feel free to let me know if you're interested or if you have any opinions or suggestions. Thanks and wish you have a great day.",https://www.reddit.com/r/LanguageTechnology/comments/n5dbnc/emotion_and_empathy_in_nlp/,LanguageTechnology,t3_n5dbnc,"Emotion and Empathy in NLP Hey everyone!

I'm a master's student currently doing my research in the field of NLP and I've recently become heavily invested in the idea of implementing concepts such as emotion and empathy in dialogue systems. I was wondering if there was anybody else who was also interested in this topic and wanted to share our resources together? I've made a simple [list of papers](https://github.com/Sahandfer/Empathetic-COAI-Papers) I've read so far (not complete yet). Feel free to let me know if you're interested or if you have any opinions or suggestions. Thanks and wish you have a great day.",618
235,235,"200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support - John Snow Labs NLU 3.0.0","
## 200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support in  NLU 3.0 Release and much more
We are incredibly excited to announce the release of `NLU 3.0.0` which makes most of John Snow Labs medical healthcare model available in just 1 line of code in NLU.
These models are the most accurate in their domains and highly scalable in Spark clusters.  
In addition, `Spark 3.0.X`  and `Spark 3.1.X ` is now supported, together with Python3.8

This is enabled by the amazing [Spark NLP3.0.1](https://nlp.johnsnowlabs.com/docs/en/release_notes#300) and [Spark NLP for Healthcare 3.0.1](https://nlp.johnsnowlabs.com/docs/en/licensed_release_notes#301) releases.

# New Features
- Over 200 new models for the `healthcare` domain
- 6 new classes of models, Assertion, Sentence/Chunk Resolvers, Relation Extractors, Medical NER models, De-Identificator Models
- Spark 3.0.X and 3.1.X support
- Python 3.8 Support
- New Output level `relation`
- 1 Line to install NLU  just run `!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash`
- [Various new EMR and Databricks versions supported](https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.0.0)
- GPU Mode, more then 600% speedup by enabling GPU mode.
- Authorized mode for licensed features

## New Documentation
- [NLU for Healthcare Examples](https://nlu.johnsnowlabs.com/docs/en/examples_hc#usage-examples-of-nluload)
- [Instrunctions to authorize your environment to use Licensed features](https://nlu.johnsnowlabs.com/docs/en/examples_hc#authorize-access-to-licensed-features-and-install-healthcare-dependencies)


## New Notebooks
- [Medical Named Entity Extraction (NER) notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/medical_named_entity_recognition/overview_medical_entity_recognizers.ipynb)
- [Relation extraction notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/relation_extraction/overview_relation.ipynb)
- [Entity Resolution overview notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/entity_resolution/entity_resolvers_overview.ipynb)
- [Assertion overview notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/assertion/assertion_overview.ipynb)
- [De-Identification overview notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/de_identification/DeIdentification_model_overview.ipynb)
- [Graph NLU tutorial](https://github.com/JohnSnowLabs/nlu/blob/3.0rc1/examples/webinars_conferences_etc/graph_ai_summit/Healthcare_Graph_NLU_COVID_Tigergraph.ipynb)


## AssertionDLModels

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [assert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html) | [assertion_dl](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html)                   |
| English  | [assert.biobert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html) | [assertion_dl_biobert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html)                   |
| English  | [assert.healthcare](https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html) | [assertion_dl_healthcare](https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html)                   |
| English  | [assert.large](https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html) | [assertion_dl_large](https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html)                   |

##  New Word Embeddings

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [embed.glove.clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html) | [embeddings_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html)                   |
| English  | [embed.glove.biovec](https://nlp.johnsnowlabs.com/2020/06/02/embeddings_biovec_en.html) | [embeddings_biovec](https://nlp.johnsnowlabs.com/2020/06/02/embeddings_biovec_en.html)                   |
| English  | [embed.glove.healthcare](https://nlp.johnsnowlabs.com/2020/03/26/embeddings_healthcare_en.html) | [embeddings_healthcare](https://nlp.johnsnowlabs.com/2020/03/26/embeddings_healthcare_en.html)                   |
| English  | [embed.glove.healthcare_100d](https://nlp.johnsnowlabs.com/2020/05/29/embeddings_healthcare_100d_en.html) | [embeddings_healthcare_100d](https://nlp.johnsnowlabs.com/2020/05/29/embeddings_healthcare_100d_en.html)                   |
| English  | en.embed.glove.icdoem | embeddings_icdoem          |
| English  | en.embed.glove.icdoem_2ng | embeddings_icdoem_2ng          |

## Sentence Entity resolvers

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | embed_sentence.biobert.mli | sbiobert_base_cased_mli          |
| English  | resolve | sbiobertresolve_cpt          |
| English  | resolve.cpt | sbiobertresolve_cpt          |
| English  | resolve.cpt.augmented | sbiobertresolve_cpt_augmented          |
| English  | resolve.cpt.procedures_augmented | sbiobertresolve_cpt_procedures_augmented          |
| English  | resolve.hcc.augmented | sbiobertresolve_hcc_augmented          |
| English  | [resolve.icd10cm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html) | [sbiobertresolve_icd10cm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html)                   |
| English  | [resolve.icd10cm.augmented](https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html) | [sbiobertresolve_icd10cm_augmented](https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html)                   |
| English  | [resolve.icd10cm.augmented_billable](https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html) | [sbiobertresolve_icd10cm_augmented_billable_hcc](https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html)                   |
| English  | [resolve.icd10pcs](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html) | [sbiobertresolve_icd10pcs](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html)                   |
| English  | [resolve.icdo](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html) | [sbiobertresolve_icdo](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html)                   |
| English  | [resolve.rxcui](https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html) | [sbiobertresolve_rxcui](https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html)                   |
| English  | [resolve.rxnorm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html) | [sbiobertresolve_rxnorm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html)                   |
| English  | [resolve.snomed](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html) | [sbiobertresolve_snomed_auxConcepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html)                   |
| English  | [resolve.snomed.aux_concepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html) | [sbiobertresolve_snomed_auxConcepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html)                   |
| English  | [resolve.snomed.aux_concepts_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html) | [sbiobertresolve_snomed_auxConcepts_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html)                   |
| English  | [resolve.snomed.findings](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html) | [sbiobertresolve_snomed_findings](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html)                   |
| English  | [resolve.snomed.findings_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html) | [sbiobertresolve_snomed_findings_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html)                   |

## RelationExtractionModel

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | relation.posology | posology_re          |
| English  | [relation](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html) | [redl_bodypart_direction_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html)                   |
| English  | [relation.bodypart.direction](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html) | [redl_bodypart_direction_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html)                   |
| English  | [relation.bodypart.problem](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_problem_biobert_en.html) | [redl_bodypart_problem_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_problem_biobert_en.html)                   |
| English  | [relation.bodypart.procedure](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_procedure_test_biobert_en.html) | [redl_bodypart_procedure_test_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_procedure_test_biobert_en.html)                   |
| English  | [relation.chemprot](https://nlp.johnsnowlabs.com/2021/02/04/redl_chemprot_biobert_en.html) | [redl_chemprot_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_chemprot_biobert_en.html)                   |
| English  | [relation.clinical](https://nlp.johnsnowlabs.com/2021/02/04/redl_clinical_biobert_en.html) | [redl_clinical_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_clinical_biobert_en.html)                   |
| English  | [relation.date](https://nlp.johnsnowlabs.com/2021/02/04/redl_date_clinical_biobert_en.htmls) | [redl_date_clinical_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_date_clinical_biobert_en.htmls)                   |
| English  | [relation.drug_drug_interaction](https://nlp.johnsnowlabs.com/2021/02/04/redl_drug_drug_interaction_biobert_en.html) | [redl_drug_drug_interaction_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_drug_drug_interaction_biobert_en.html)                   |
| English  | [relation.humen_phenotype_gene](https://nlp.johnsnowlabs.com/2021/02/04/redl_human_phenotype_gene_biobert_en.html) | [redl_human_phenotype_gene_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_human_phenotype_gene_biobert_en.html)                   |
| English  | [relation.temporal_events](https://nlp.johnsnowlabs.com/2021/02/04/redl_temporal_events_biobert_en.html) | [redl_temporal_events_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_temporal_events_biobert_en.html)                   |



## NERDLModels

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
|English  | [med_ner.ade.clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinical_en.html) | [ner_ade_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinical_en.html)                   |
| English  | [med_ner.ade.clinical_bert](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinicalbert_en.html) | [ner_ade_clinicalbert](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinicalbert_en.html)                   |
| English  | [med_ner.ade.ade_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_healthcare_en.html) | [ner_ade_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_healthcare_en.html)                   |
| English  | [med_ner.anatomy](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_en.html) | [ner_anatomy](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_en.html)                   |
| English  | [med_ner.anatomy.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_anatomy_biobert_en.html) | [ner_anatomy_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_anatomy_biobert_en.html)                   |
| English  | [med_ner.anatomy.coarse](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html) | [ner_anatomy_coarse](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html)                   |
| English  | [med_ner.anatomy.coarse_biobert](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_biobert_en.html) | [ner_anatomy_coarse_biobert](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_biobert_en.html)                   |
| English  | [med_ner.aspect_sentiment](https://nlp.johnsnowlabs.com/2021/03/31/ner_aspect_based_sentiment_en.html) | [ner_aspect_based_sentiment](https://nlp.johnsnowlabs.com/2021/03/31/ner_aspect_based_sentiment_en.html)                   |
| English  | [med_ner.bacterial_species](https://nlp.johnsnowlabs.com/2021/04/01/ner_bacterial_species_en.html) | [ner_bacterial_species](https://nlp.johnsnowlabs.com/2021/04/01/ner_bacterial_species_en.html)                   |
| English  | [med_ner.bionlp](https://nlp.johnsnowlabs.com/2021/03/31/ner_bionlp_en.html) | [ner_bionlp](https://nlp.johnsnowlabs.com/2021/03/31/ner_bionlp_en.html)                   |
| English  | [med_ner.bionlp.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_bionlp_biobert_en.html) | [ner_bionlp_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_bionlp_biobert_en.html)                   |
| English  | [med_ner.cancer](https://nlp.johnsnowlabs.com/2021/03/31/ner_cancer_genetics_en.html) | [ner_cancer_genetics](https://nlp.johnsnowlabs.com/2021/03/31/ner_cancer_genetics_en.html)                   |
| Englishs | [med_ner.cellular](https://nlp.johnsnowlabs.com/2021/03/31/ner_cellular_en.html) | [ner_cellular](https://nlp.johnsnowlabs.com/2021/03/31/ner_cellular_en.html)                   |
| English  | [med_ner.cellular.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_cellular_biobert_en.html) | [ner_cellular_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_cellular_biobert_en.html)                   |
| English  | [med_ner.chemicals](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemicals_en.html) | [ner_chemicals](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemicals_en.html)                   |
| English  | [med_ner.chemprot](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemprot_biobert_en.html) | [ner_chemprot_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemprot_biobert_en.html)           |
| English  | [med_ner.chemprot.clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_chemprot_clinical_en.html) | [ner_chemprot_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_chemprot_clinical_en.html)           |
| English  | [med_ner.clinical](https://nlp.johnsnowlabs.com/2020/01/30/ner_clinical_en.html) | [ner_clinical](https://nlp.johnsnowlabs.com/2020/01/30/ner_clinical_en.html)           |
| English  | [med_ner.clinical.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_clinical_biobert_en.html) | [ner_clinical_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_clinical_biobert_en.html)           |
| English  | med_ner.clinical.noncontrib | ner_clinical_noncontrib          |
| English  | [med_ner.diseases](https://nlp.johnsnowlabs.com/2021/03/31/ner_diseases_en.html) | [ner_diseases](https://nlp.johnsnowlabs.com/2021/03/31/ner_diseases_en.html)           |
| English  | [med_ner.diseases.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_biobert_en.html) | [ner_diseases_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_biobert_en.html)           |
| English  | [med_ner.diseases.large](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_large_en.html) | [ner_diseases_large](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_large_en.html)           |
| English  | [med_ner.drugs](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_en.html) | [ner_drugs](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_en.html)           |
| English  | [med_ner.drugsgreedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_greedy_en.html) | [ner_drugs_greedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_greedy_en.html)           |
| English  | [med_ner.drugs.large](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_large_en.html) | [ner_drugs_large](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_large_en.html)           |
| English  | [med_ner.events_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_biobert_en.html) | [ner_events_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_biobert_en.html)           |
| English  | [med_ner.events_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_events_clinical_en.html) | [ner_events_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_events_clinical_en.html)           |
| English  | [med_ner.events_healthcre](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_healthcare_en.html) | [ner_events_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_healthcare_en.html)           |
| English  | [med_ner.financial_contract](https://nlp.johnsnowlabs.com/2021/04/01/ner_financial_contract_en.html) | [ner_financial_contract](https://nlp.johnsnowlabs.com/2021/04/01/ner_financial_contract_en.html)           |
| English  | [med_ner.healthcare](https://nlp.johnsnowlabs.com/2021/03/31/ner_healthcare_de.html) | [ner_healthcare](https://nlp.johnsnowlabs.com/2021/03/31/ner_healthcare_de.html)           |
| English  | [med_ner.human_phenotype.gene_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_gene_biobert_en.html) | [ner_human_phenotype_gene_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_gene_biobert_en.html)           |
| English  | [med_ner.human_phenotype.gene_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html) | [ner_human_phenotype_gene_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html)           |
| English  | [med_ner.human_phenotype.go_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_go_biobert_en.html) | [ner_human_phenotype_go_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_go_biobert_en.html)           |
| English  | [med_ner.human_phenotype.go_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html) | [ner_human_phenotype_go_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html)           |
| English  | [med_ner.jsl](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_en.html) | [ner_jsl](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_en.html)           |
| English  | [med_ner.jsl.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_biobert_en.html) | [ner_jsl_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_biobert_en.html)           |
| English  | [med_ner.jsl.enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_enriched_en.html) | [ner_jsl_enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_enriched_en.html)           |
| English  | [med_ner.jsl.enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_enriched_biobert_en.html) | [ner_jsl_enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_enriched_biobert_en.html)           |
| English  | [med_ner.measurements](https://nlp.johnsnowlabs.com/2021/04/01/ner_measurements_clinical_en.html) | [ner_measurements_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_measurements_clinical_en.html)           |
| English  | [med_ner.medmentions](https://nlp.johnsnowlabs.com/2021/04/01/ner_medmentions_coarse_en.html) | [ner_medmentions_coarse](https://nlp.johnsnowlabs.com/2021/04/01/ner_medmentions_coarse_en.html)           |
| English  | [med_ner.posology](https://nlp.johnsnowlabs.com/2020/04/15/ner_posology_en.html) | [ner_posology](https://nlp.johnsnowlabs.com/2020/04/15/ner_posology_en.html)           |
| English  | [med_ner.posology.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_biobert_en.html) | [ner_posology_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_biobert_en.html)           |
| English  | [med_ner.posology.greedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_greedy_en.html) | [ner_posology_greedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_greedy_en.html)           |
| English  | [med_ner.posology.healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_healthcare_en.html) | [ner_posology_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_healthcare_en.html)           |
| English  | [med_ner.posology.large](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_large_en.html) | [ner_posology_large](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_large_en.html)           |
| English  | [med_ner.posology.large_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_large_biobert_en.html) | [ner_posology_large_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_large_biobert_en.html)           |
| English  | [med_ner.posology.small](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_small_en.html) | [ner_posology_small](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_small_en.html)           |
| English  | [med_ner.radiology](https://nlp.johnsnowlabs.com/2021/03/31/ner_radiology_en.html) | [ner_radiology](https://nlp.johnsnowlabs.com/2021/03/31/ner_radiology_en.html)           |
| English  | [med_ner.radiology.wip_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_radiology_wip_clinical_en.html) | [ner_radiology_wip_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_radiology_wip_clinical_en.html)           |
| English  | [med_ner.risk_factors](https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html) | [ner_risk_factors](https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html)           |
| English  | [med_ner.risk_factors.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_risk_factors_biobert_en.html) | [ner_risk_factors_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_risk_factors_biobert_en.html)           |
| English  | med_ner.i2b2 | nerdl_i2b2          |
| English  | [med_ner.tumour](https://nlp.johnsnowlabs.com/2021/04/01/nerdl_tumour_demo_en.html) | [nerdl_tumour_demo](https://nlp.johnsnowlabs.com/2021/04/01/nerdl_tumour_demo_en.html)           |
| English  | med_ner.jsl.wip.clinical | jsl_ner_wip_clinical          |
| English  | [med_ner.jsl.wip.clinical.greedy](https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html) | [jsl_ner_wip_greedy_clinical](https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html)           |
| English  | [med_ner.jsl.wip.clinical.modifier](https://nlp.johnsnowlabs.com/2021/04/01/jsl_ner_wip_modifier_clinical_en.html) | [jsl_ner_wip_modifier_clinical](https://nlp.johnsnowlabs.com/2021/04/01/jsl_ner_wip_modifier_clinical_en.html)           |
| English  | [med_ner.jsl.wip.clinical.rd](https://nlp.johnsnowlabs.com/2021/04/01/jsl_rd_ner_wip_greedy_clinical_en.html) | [jsl_rd_ner_wip_greedy_clinical](https://nlp.johnsnowlabs.com/2021/04/01/jsl_rd_ner_wip_greedy_clinical_en.html)           |


## De-Identification Models

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [med_ner.deid.augmented](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_augmented_en.html) | [ner_deid_augmented](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_augmented_en.html)           |
| English  | [med_ner.deid.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_biobert_en.html) | [ner_deid_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_biobert_en.html)           |
| English  | [med_ner.deid.enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_enriched_en.html) | [ner_deid_enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_enriched_en.html)           |
| English  | [med_ner.deid.enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_enriched_biobert_en.html) | [ner_deid_enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_enriched_biobert_en.html)           |
| English  | [med_ner.deid.large](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_large_en.html) | [ner_deid_large](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_large_en.html)           |
| English  | [med_ner.deid.sd](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_en.html) | [ner_deid_sd](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_en.html)           |
| English  | [med_ner.deid.sd_large](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_large_en.html) | [ner_deid_sd_large](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_large_en.html)           |
| English  | med_ner.deid | nerdl_deid          |
| English  | med_ner.deid.synthetic | ner_deid_synthetic          |
| English  | [med_ner.deid.dl](https://nlp.johnsnowlabs.com/2021/03/31/ner_deidentify_dl_en.html) | [ner_deidentify_dl](https://nlp.johnsnowlabs.com/2021/03/31/ner_deidentify_dl_en.html)           |
| English  | [en.de_identify](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html) | [deidentify_rb](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html)           |
| English  | de_identify.rules | deid_rules          |
| English  | [de_identify.clinical](https://nlp.johnsnowlabs.com/2021/01/29/deidentify_enriched_clinical_en.html) | [deidentify_enriched_clinical](https://nlp.johnsnowlabs.com/2021/01/29/deidentify_enriched_clinical_en.html)           |
| English  | [de_identify.large](https://nlp.johnsnowlabs.com/2020/08/04/deidentify_large_en.html) | [deidentify_large](https://nlp.johnsnowlabs.com/2020/08/04/deidentify_large_en.html)           |
| English  | [de_identify.rb](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html) | [deidentify_rb](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html)           |
| English  | de_identify.rb_no_regex | deidentify_rb_no_regex          |



# Chunk resolvers

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [resolve_chunk.athena_conditions](https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html) | [chunkresolve_athena_conditions_healthcare](https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html)           |
| English  | [resolve_chunk.cpt_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_cpt_clinical_en.html) | [chunkresolve_cpt_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_cpt_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_clinical_en.html) | [chunkresolve_icd10cm_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.diseases_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_diseases_clinical_en.html) | [chunkresolve_icd10cm_diseases_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_diseases_clinical_en.html)           |
| English  | resolve_chunk.icd10cm.hcc_clinical | chunkresolve_icd10cm_hcc_clinical          |
| English  | resolve_chunk.icd10cm.hcc_healthcare | chunkresolve_icd10cm_hcc_healthcare          |
| English  | [resolve_chunk.icd10cm.injuries](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_injuries_clinical_en.html) | [chunkresolve_icd10cm_injuries_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_injuries_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.musculoskeletal](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_musculoskeletal_clinical_en.html) | [chunkresolve_icd10cm_musculoskeletal_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_musculoskeletal_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.neoplasms](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_neoplasms_clinical_en.html) | [chunkresolve_icd10cm_neoplasms_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_neoplasms_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.poison](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_poison_ext_clinical_en.html) | [chunkresolve_icd10cm_poison_ext_clinical](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_poison_ext_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.puerile](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_puerile_clinical_en.html) | [chunkresolve_icd10cm_puerile_clinical](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_puerile_clinical_en.html)           |
| English  | resolve_chunk.icd10pcs.clinical | chunkresolve_icd10pcs_clinical          |
| English  | [resolve_chunk.icdo.clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10pcs_clinical_en.html) | [chunkresolve_icdo_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10pcs_clinical_en.html)           |
| English  | [resolve_chunk.loinc](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_loinc_clinical_en.html) | [chunkresolve_loinc_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_loinc_clinical_en.html)           |
| English  | [resolve_chunk.rxnorm.cd](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_cd_clinical_en.html) | [chunkresolve_rxnorm_cd_clinical](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_cd_clinical_en.html)           |
| English  | resolve_chunk.rxnorm.in | chunkresolve_rxnorm_in_clinical          |
| English  | resolve_chunk.rxnorm.in_healthcare | chunkresolve_rxnorm_in_healthcare          |
| English  | [resolve_chunk.rxnorm.sbd](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_sbd_clinical_en.html) | [chunkresolve_rxnorm_sbd_clinical](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_sbd_clinical_en.html)           |
| English  | [resolve_chunk.rxnorm.scd](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_scd_clinical_en.html) | [chunkresolve_rxnorm_scd_clinical](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_scd_clinical_en.html)           |
| English  | resolve_chunk.rxnorm.scdc | chunkresolve_rxnorm_scdc_clinical          |
| English  | resolve_chunk.rxnorm.scdc_healthcare | chunkresolve_rxnorm_scdc_healthcare          |
| English  | [resolve_chunk.rxnorm.xsmall.clinical](https://nlp.johnsnowlabs.com/2020/06/24/chunkresolve_rxnorm_xsmall_clinical_en.html) | [chunkresolve_rxnorm_xsmall_clinical](https://nlp.johnsnowlabs.com/2020/06/24/chunkresolve_rxnorm_xsmall_clinical_en.html)           |
| English  | [resolve_chunk.snomed.findings](https://nlp.johnsnowlabs.com/2020/06/20/chunkresolve_snomed_findings_clinical_en.html) | [chunkresolve_snomed_findings_clinical](https://nlp.johnsnowlabs.com/2020/06/20/chunkresolve_snomed_findings_clinical_en.html)           |


# New Classifiers

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | classify.icd10.clinical | classifier_icd10cm_hcc_clinical          |
| English  | classify.icd10.healthcare | classifier_icd10cm_hcc_healthcare          |
| English  | [classify.ade.biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_biobert_en.html) | [classifierdl_ade_biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_biobert_en.html)           |
| English  | [classify.ade.clinical](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_clinicalbert_en.html) | [classifierdl_ade_clinicalbert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_clinicalbert_en.html)           |
| English  | [classify.ade.conversational](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_conversational_biobert_en.html) | [classifierdl_ade_conversational_biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_conversational_biobert_en.html)           |
| English  | [classify.gender.biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_biobert_en.html) | [classifierdl_gender_biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_biobert_en.html)           |
| English  | [classify.gender.sbert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_sbert_en.html) | [classifierdl_gender_sbert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_sbert_en.html)           |
| English  | classify.pico | classifierdl_pico_biobert          |


# German Medical models

| nlu.load() reference                                         | Spark NLP Model reference          |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [embed]    | w2v_cc_300d|
| [embed.w2v]    | w2v_cc_300d|
| [resolve_chunk]    | chunkresolve_ICD10GM|
| [resolve_chunk.icd10gm]    | chunkresolve_ICD10GM|
| resolve_chunk.icd10gm.2021    | chunkresolve_ICD10GM_2021|
| med_ner.legal   | ner_legal|
| med_ner    | ner_healthcare|
| med_ner.healthcare    | ner_healthcare|
| med_ner.healthcare_slim    | ner_healthcare_slim|
| med_ner.traffic    | ner_traffic|

# Spanish Medical models
| nlu.load() reference                                         | Spark NLP Model reference          |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [embed.scielo.150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_150d_es.html) | [embeddings_scielo_150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_150d_es.html)| 
| [embed.scielo.300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_300d_es.html)   | [embeddings_scielo_300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_300d_es.html)| 
| [embed.scielo.50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_50d_es.html)  | [embeddings_scielo_50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_50d_es.html)| 
| [embed.scielowiki.150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_150d_es.html)   | [embeddings_scielowiki_150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_150d_es.html)| 
| [embed.scielowiki.300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_300d_es.html)   | [embeddings_scielowiki_300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_300d_es.html)| 
| [embed.scielowiki.50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_50d_es.html)   | [embeddings_scielowiki_50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_50d_es.html)| 
| [embed.sciwiki.150d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_150d_es.html)   | [embeddings_sciwiki_150d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_150d_es.html)| 
| [embed.sciwiki.300d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_300d_es.html)   | [embeddings_sciwiki_300d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_300d_es.html)| 
| [embed.sciwiki.50d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_50d_es.html)   | [embeddings_sciwiki_50d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_50d_es.html)| 
| [med_ner](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)   |  [ner_diag_proc](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)| 
| [med_ner.neoplasm](https://nlp.johnsnowlabs.com/2021/03/31/ner_neoplasms_es.html)  | [ner_neoplasms](https://nlp.johnsnowlabs.com/2021/03/31/ner_neoplasms_es.html)| 
| [med_ner.diag_proc](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)  | [ner_diag_proc](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)| 

# GPU Mode
You can now enable NLU GPU mode by setting `gpu=true` while loading a model. I.e. `nlu.load('train.sentiment' gpu=True)` . If must resart you kernel, if you already loaded a nlu pipeline withouth GPU mode.

# Output Level Relation
This new output level is used for relation extractors and will give you 1 row per relation extracted.


# Bug fixes
- Fixed a bug that caused loading NLU models in offline mode not to work in some occasions


# 1 line Install NLU
```!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash```

# Install via PIP 
```! pip install nlu pyspark==3.0.1```


## Additional NLU ressources

- [NLU Website](https://nlu.johnsnowlabs.com/)
- [All NLU Tutorial Notebooks](https://nlu.johnsnowlabs.com/docs/en/notebooks)
- [NLU Videos and Blogposts on NLU](https://nlp.johnsnowlabs.com/learn#pythons-nlu-library)
- [NLU on Github](https://github.com/JohnSnowLabs/nlu)
- [Suggestions or Questions? Contact us in Slack!](https://join.slack.com/t/spark-nlp/shared_invite/zt-lutct9gm-kuUazcyFKhuGY3_0AMkxqA)",https://www.reddit.com/r/LanguageTechnology/comments/n5gvel/200_state_of_the_art_medical_models_for_ner/,LanguageTechnology,t3_n5gvel,"200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support - John Snow Labs NLU 3.0.0 
## 200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support in  NLU 3.0 Release and much more
We are incredibly excited to announce the release of `NLU 3.0.0` which makes most of John Snow Labs medical healthcare model available in just 1 line of code in NLU.
These models are the most accurate in their domains and highly scalable in Spark clusters.  
In addition, `Spark 3.0.X`  and `Spark 3.1.X ` is now supported, together with Python3.8

This is enabled by the amazing [Spark NLP3.0.1](https://nlp.johnsnowlabs.com/docs/en/release_notes#300) and [Spark NLP for Healthcare 3.0.1](https://nlp.johnsnowlabs.com/docs/en/licensed_release_notes#301) releases.

# New Features
- Over 200 new models for the `healthcare` domain
- 6 new classes of models, Assertion, Sentence/Chunk Resolvers, Relation Extractors, Medical NER models, De-Identificator Models
- Spark 3.0.X and 3.1.X support
- Python 3.8 Support
- New Output level `relation`
- 1 Line to install NLU  just run `!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash`
- [Various new EMR and Databricks versions supported](https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.0.0)
- GPU Mode, more then 600% speedup by enabling GPU mode.
- Authorized mode for licensed features

## New Documentation
- [NLU for Healthcare Examples](https://nlu.johnsnowlabs.com/docs/en/examples_hc#usage-examples-of-nluload)
- [Instrunctions to authorize your environment to use Licensed features](https://nlu.johnsnowlabs.com/docs/en/examples_hc#authorize-access-to-licensed-features-and-install-healthcare-dependencies)


## New Notebooks
- [Medical Named Entity Extraction (NER) notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/medical_named_entity_recognition/overview_medical_entity_recognizers.ipynb)
- [Relation extraction notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/relation_extraction/overview_relation.ipynb)
- [Entity Resolution overview notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/entity_resolution/entity_resolvers_overview.ipynb)
- [Assertion overview notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/assertion/assertion_overview.ipynb)
- [De-Identification overview notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/de_identification/DeIdentification_model_overview.ipynb)
- [Graph NLU tutorial](https://github.com/JohnSnowLabs/nlu/blob/3.0rc1/examples/webinars_conferences_etc/graph_ai_summit/Healthcare_Graph_NLU_COVID_Tigergraph.ipynb)


## AssertionDLModels

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [assert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html) | [assertion_dl](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html)                   |
| English  | [assert.biobert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html) | [assertion_dl_biobert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html)                   |
| English  | [assert.healthcare](https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html) | [assertion_dl_healthcare](https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html)                   |
| English  | [assert.large](https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html) | [assertion_dl_large](https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html)                   |

##  New Word Embeddings

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [embed.glove.clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html) | [embeddings_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html)                   |
| English  | [embed.glove.biovec](https://nlp.johnsnowlabs.com/2020/06/02/embeddings_biovec_en.html) | [embeddings_biovec](https://nlp.johnsnowlabs.com/2020/06/02/embeddings_biovec_en.html)                   |
| English  | [embed.glove.healthcare](https://nlp.johnsnowlabs.com/2020/03/26/embeddings_healthcare_en.html) | [embeddings_healthcare](https://nlp.johnsnowlabs.com/2020/03/26/embeddings_healthcare_en.html)                   |
| English  | [embed.glove.healthcare_100d](https://nlp.johnsnowlabs.com/2020/05/29/embeddings_healthcare_100d_en.html) | [embeddings_healthcare_100d](https://nlp.johnsnowlabs.com/2020/05/29/embeddings_healthcare_100d_en.html)                   |
| English  | en.embed.glove.icdoem | embeddings_icdoem          |
| English  | en.embed.glove.icdoem_2ng | embeddings_icdoem_2ng          |

## Sentence Entity resolvers

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | embed_sentence.biobert.mli | sbiobert_base_cased_mli          |
| English  | resolve | sbiobertresolve_cpt          |
| English  | resolve.cpt | sbiobertresolve_cpt          |
| English  | resolve.cpt.augmented | sbiobertresolve_cpt_augmented          |
| English  | resolve.cpt.procedures_augmented | sbiobertresolve_cpt_procedures_augmented          |
| English  | resolve.hcc.augmented | sbiobertresolve_hcc_augmented          |
| English  | [resolve.icd10cm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html) | [sbiobertresolve_icd10cm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html)                   |
| English  | [resolve.icd10cm.augmented](https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html) | [sbiobertresolve_icd10cm_augmented](https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html)                   |
| English  | [resolve.icd10cm.augmented_billable](https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html) | [sbiobertresolve_icd10cm_augmented_billable_hcc](https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html)                   |
| English  | [resolve.icd10pcs](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html) | [sbiobertresolve_icd10pcs](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html)                   |
| English  | [resolve.icdo](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html) | [sbiobertresolve_icdo](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html)                   |
| English  | [resolve.rxcui](https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html) | [sbiobertresolve_rxcui](https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html)                   |
| English  | [resolve.rxnorm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html) | [sbiobertresolve_rxnorm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html)                   |
| English  | [resolve.snomed](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html) | [sbiobertresolve_snomed_auxConcepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html)                   |
| English  | [resolve.snomed.aux_concepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html) | [sbiobertresolve_snomed_auxConcepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html)                   |
| English  | [resolve.snomed.aux_concepts_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html) | [sbiobertresolve_snomed_auxConcepts_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html)                   |
| English  | [resolve.snomed.findings](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html) | [sbiobertresolve_snomed_findings](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html)                   |
| English  | [resolve.snomed.findings_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html) | [sbiobertresolve_snomed_findings_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html)                   |

## RelationExtractionModel

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | relation.posology | posology_re          |
| English  | [relation](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html) | [redl_bodypart_direction_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html)                   |
| English  | [relation.bodypart.direction](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html) | [redl_bodypart_direction_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html)                   |
| English  | [relation.bodypart.problem](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_problem_biobert_en.html) | [redl_bodypart_problem_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_problem_biobert_en.html)                   |
| English  | [relation.bodypart.procedure](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_procedure_test_biobert_en.html) | [redl_bodypart_procedure_test_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_procedure_test_biobert_en.html)                   |
| English  | [relation.chemprot](https://nlp.johnsnowlabs.com/2021/02/04/redl_chemprot_biobert_en.html) | [redl_chemprot_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_chemprot_biobert_en.html)                   |
| English  | [relation.clinical](https://nlp.johnsnowlabs.com/2021/02/04/redl_clinical_biobert_en.html) | [redl_clinical_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_clinical_biobert_en.html)                   |
| English  | [relation.date](https://nlp.johnsnowlabs.com/2021/02/04/redl_date_clinical_biobert_en.htmls) | [redl_date_clinical_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_date_clinical_biobert_en.htmls)                   |
| English  | [relation.drug_drug_interaction](https://nlp.johnsnowlabs.com/2021/02/04/redl_drug_drug_interaction_biobert_en.html) | [redl_drug_drug_interaction_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_drug_drug_interaction_biobert_en.html)                   |
| English  | [relation.humen_phenotype_gene](https://nlp.johnsnowlabs.com/2021/02/04/redl_human_phenotype_gene_biobert_en.html) | [redl_human_phenotype_gene_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_human_phenotype_gene_biobert_en.html)                   |
| English  | [relation.temporal_events](https://nlp.johnsnowlabs.com/2021/02/04/redl_temporal_events_biobert_en.html) | [redl_temporal_events_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_temporal_events_biobert_en.html)                   |



## NERDLModels

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
|English  | [med_ner.ade.clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinical_en.html) | [ner_ade_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinical_en.html)                   |
| English  | [med_ner.ade.clinical_bert](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinicalbert_en.html) | [ner_ade_clinicalbert](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinicalbert_en.html)                   |
| English  | [med_ner.ade.ade_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_healthcare_en.html) | [ner_ade_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_healthcare_en.html)                   |
| English  | [med_ner.anatomy](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_en.html) | [ner_anatomy](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_en.html)                   |
| English  | [med_ner.anatomy.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_anatomy_biobert_en.html) | [ner_anatomy_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_anatomy_biobert_en.html)                   |
| English  | [med_ner.anatomy.coarse](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html) | [ner_anatomy_coarse](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html)                   |
| English  | [med_ner.anatomy.coarse_biobert](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_biobert_en.html) | [ner_anatomy_coarse_biobert](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_biobert_en.html)                   |
| English  | [med_ner.aspect_sentiment](https://nlp.johnsnowlabs.com/2021/03/31/ner_aspect_based_sentiment_en.html) | [ner_aspect_based_sentiment](https://nlp.johnsnowlabs.com/2021/03/31/ner_aspect_based_sentiment_en.html)                   |
| English  | [med_ner.bacterial_species](https://nlp.johnsnowlabs.com/2021/04/01/ner_bacterial_species_en.html) | [ner_bacterial_species](https://nlp.johnsnowlabs.com/2021/04/01/ner_bacterial_species_en.html)                   |
| English  | [med_ner.bionlp](https://nlp.johnsnowlabs.com/2021/03/31/ner_bionlp_en.html) | [ner_bionlp](https://nlp.johnsnowlabs.com/2021/03/31/ner_bionlp_en.html)                   |
| English  | [med_ner.bionlp.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_bionlp_biobert_en.html) | [ner_bionlp_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_bionlp_biobert_en.html)                   |
| English  | [med_ner.cancer](https://nlp.johnsnowlabs.com/2021/03/31/ner_cancer_genetics_en.html) | [ner_cancer_genetics](https://nlp.johnsnowlabs.com/2021/03/31/ner_cancer_genetics_en.html)                   |
| Englishs | [med_ner.cellular](https://nlp.johnsnowlabs.com/2021/03/31/ner_cellular_en.html) | [ner_cellular](https://nlp.johnsnowlabs.com/2021/03/31/ner_cellular_en.html)                   |
| English  | [med_ner.cellular.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_cellular_biobert_en.html) | [ner_cellular_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_cellular_biobert_en.html)                   |
| English  | [med_ner.chemicals](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemicals_en.html) | [ner_chemicals](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemicals_en.html)                   |
| English  | [med_ner.chemprot](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemprot_biobert_en.html) | [ner_chemprot_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemprot_biobert_en.html)           |
| English  | [med_ner.chemprot.clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_chemprot_clinical_en.html) | [ner_chemprot_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_chemprot_clinical_en.html)           |
| English  | [med_ner.clinical](https://nlp.johnsnowlabs.com/2020/01/30/ner_clinical_en.html) | [ner_clinical](https://nlp.johnsnowlabs.com/2020/01/30/ner_clinical_en.html)           |
| English  | [med_ner.clinical.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_clinical_biobert_en.html) | [ner_clinical_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_clinical_biobert_en.html)           |
| English  | med_ner.clinical.noncontrib | ner_clinical_noncontrib          |
| English  | [med_ner.diseases](https://nlp.johnsnowlabs.com/2021/03/31/ner_diseases_en.html) | [ner_diseases](https://nlp.johnsnowlabs.com/2021/03/31/ner_diseases_en.html)           |
| English  | [med_ner.diseases.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_biobert_en.html) | [ner_diseases_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_biobert_en.html)           |
| English  | [med_ner.diseases.large](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_large_en.html) | [ner_diseases_large](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_large_en.html)           |
| English  | [med_ner.drugs](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_en.html) | [ner_drugs](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_en.html)           |
| English  | [med_ner.drugsgreedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_greedy_en.html) | [ner_drugs_greedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_greedy_en.html)           |
| English  | [med_ner.drugs.large](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_large_en.html) | [ner_drugs_large](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_large_en.html)           |
| English  | [med_ner.events_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_biobert_en.html) | [ner_events_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_biobert_en.html)           |
| English  | [med_ner.events_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_events_clinical_en.html) | [ner_events_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_events_clinical_en.html)           |
| English  | [med_ner.events_healthcre](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_healthcare_en.html) | [ner_events_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_healthcare_en.html)           |
| English  | [med_ner.financial_contract](https://nlp.johnsnowlabs.com/2021/04/01/ner_financial_contract_en.html) | [ner_financial_contract](https://nlp.johnsnowlabs.com/2021/04/01/ner_financial_contract_en.html)           |
| English  | [med_ner.healthcare](https://nlp.johnsnowlabs.com/2021/03/31/ner_healthcare_de.html) | [ner_healthcare](https://nlp.johnsnowlabs.com/2021/03/31/ner_healthcare_de.html)           |
| English  | [med_ner.human_phenotype.gene_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_gene_biobert_en.html) | [ner_human_phenotype_gene_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_gene_biobert_en.html)           |
| English  | [med_ner.human_phenotype.gene_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html) | [ner_human_phenotype_gene_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html)           |
| English  | [med_ner.human_phenotype.go_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_go_biobert_en.html) | [ner_human_phenotype_go_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_go_biobert_en.html)           |
| English  | [med_ner.human_phenotype.go_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html) | [ner_human_phenotype_go_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html)           |
| English  | [med_ner.jsl](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_en.html) | [ner_jsl](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_en.html)           |
| English  | [med_ner.jsl.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_biobert_en.html) | [ner_jsl_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_biobert_en.html)           |
| English  | [med_ner.jsl.enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_enriched_en.html) | [ner_jsl_enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_enriched_en.html)           |
| English  | [med_ner.jsl.enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_enriched_biobert_en.html) | [ner_jsl_enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_enriched_biobert_en.html)           |
| English  | [med_ner.measurements](https://nlp.johnsnowlabs.com/2021/04/01/ner_measurements_clinical_en.html) | [ner_measurements_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_measurements_clinical_en.html)           |
| English  | [med_ner.medmentions](https://nlp.johnsnowlabs.com/2021/04/01/ner_medmentions_coarse_en.html) | [ner_medmentions_coarse](https://nlp.johnsnowlabs.com/2021/04/01/ner_medmentions_coarse_en.html)           |
| English  | [med_ner.posology](https://nlp.johnsnowlabs.com/2020/04/15/ner_posology_en.html) | [ner_posology](https://nlp.johnsnowlabs.com/2020/04/15/ner_posology_en.html)           |
| English  | [med_ner.posology.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_biobert_en.html) | [ner_posology_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_biobert_en.html)           |
| English  | [med_ner.posology.greedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_greedy_en.html) | [ner_posology_greedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_greedy_en.html)           |
| English  | [med_ner.posology.healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_healthcare_en.html) | [ner_posology_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_healthcare_en.html)           |
| English  | [med_ner.posology.large](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_large_en.html) | [ner_posology_large](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_large_en.html)           |
| English  | [med_ner.posology.large_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_large_biobert_en.html) | [ner_posology_large_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_large_biobert_en.html)           |
| English  | [med_ner.posology.small](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_small_en.html) | [ner_posology_small](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_small_en.html)           |
| English  | [med_ner.radiology](https://nlp.johnsnowlabs.com/2021/03/31/ner_radiology_en.html) | [ner_radiology](https://nlp.johnsnowlabs.com/2021/03/31/ner_radiology_en.html)           |
| English  | [med_ner.radiology.wip_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_radiology_wip_clinical_en.html) | [ner_radiology_wip_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_radiology_wip_clinical_en.html)           |
| English  | [med_ner.risk_factors](https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html) | [ner_risk_factors](https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html)           |
| English  | [med_ner.risk_factors.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_risk_factors_biobert_en.html) | [ner_risk_factors_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_risk_factors_biobert_en.html)           |
| English  | med_ner.i2b2 | nerdl_i2b2          |
| English  | [med_ner.tumour](https://nlp.johnsnowlabs.com/2021/04/01/nerdl_tumour_demo_en.html) | [nerdl_tumour_demo](https://nlp.johnsnowlabs.com/2021/04/01/nerdl_tumour_demo_en.html)           |
| English  | med_ner.jsl.wip.clinical | jsl_ner_wip_clinical          |
| English  | [med_ner.jsl.wip.clinical.greedy](https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html) | [jsl_ner_wip_greedy_clinical](https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html)           |
| English  | [med_ner.jsl.wip.clinical.modifier](https://nlp.johnsnowlabs.com/2021/04/01/jsl_ner_wip_modifier_clinical_en.html) | [jsl_ner_wip_modifier_clinical](https://nlp.johnsnowlabs.com/2021/04/01/jsl_ner_wip_modifier_clinical_en.html)           |
| English  | [med_ner.jsl.wip.clinical.rd](https://nlp.johnsnowlabs.com/2021/04/01/jsl_rd_ner_wip_greedy_clinical_en.html) | [jsl_rd_ner_wip_greedy_clinical](https://nlp.johnsnowlabs.com/2021/04/01/jsl_rd_ner_wip_greedy_clinical_en.html)           |


## De-Identification Models

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [med_ner.deid.augmented](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_augmented_en.html) | [ner_deid_augmented](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_augmented_en.html)           |
| English  | [med_ner.deid.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_biobert_en.html) | [ner_deid_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_biobert_en.html)           |
| English  | [med_ner.deid.enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_enriched_en.html) | [ner_deid_enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_enriched_en.html)           |
| English  | [med_ner.deid.enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_enriched_biobert_en.html) | [ner_deid_enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_enriched_biobert_en.html)           |
| English  | [med_ner.deid.large](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_large_en.html) | [ner_deid_large](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_large_en.html)           |
| English  | [med_ner.deid.sd](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_en.html) | [ner_deid_sd](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_en.html)           |
| English  | [med_ner.deid.sd_large](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_large_en.html) | [ner_deid_sd_large](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_large_en.html)           |
| English  | med_ner.deid | nerdl_deid          |
| English  | med_ner.deid.synthetic | ner_deid_synthetic          |
| English  | [med_ner.deid.dl](https://nlp.johnsnowlabs.com/2021/03/31/ner_deidentify_dl_en.html) | [ner_deidentify_dl](https://nlp.johnsnowlabs.com/2021/03/31/ner_deidentify_dl_en.html)           |
| English  | [en.de_identify](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html) | [deidentify_rb](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html)           |
| English  | de_identify.rules | deid_rules          |
| English  | [de_identify.clinical](https://nlp.johnsnowlabs.com/2021/01/29/deidentify_enriched_clinical_en.html) | [deidentify_enriched_clinical](https://nlp.johnsnowlabs.com/2021/01/29/deidentify_enriched_clinical_en.html)           |
| English  | [de_identify.large](https://nlp.johnsnowlabs.com/2020/08/04/deidentify_large_en.html) | [deidentify_large](https://nlp.johnsnowlabs.com/2020/08/04/deidentify_large_en.html)           |
| English  | [de_identify.rb](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html) | [deidentify_rb](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html)           |
| English  | de_identify.rb_no_regex | deidentify_rb_no_regex          |



# Chunk resolvers

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [resolve_chunk.athena_conditions](https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html) | [chunkresolve_athena_conditions_healthcare](https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html)           |
| English  | [resolve_chunk.cpt_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_cpt_clinical_en.html) | [chunkresolve_cpt_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_cpt_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_clinical_en.html) | [chunkresolve_icd10cm_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.diseases_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_diseases_clinical_en.html) | [chunkresolve_icd10cm_diseases_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_diseases_clinical_en.html)           |
| English  | resolve_chunk.icd10cm.hcc_clinical | chunkresolve_icd10cm_hcc_clinical          |
| English  | resolve_chunk.icd10cm.hcc_healthcare | chunkresolve_icd10cm_hcc_healthcare          |
| English  | [resolve_chunk.icd10cm.injuries](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_injuries_clinical_en.html) | [chunkresolve_icd10cm_injuries_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_injuries_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.musculoskeletal](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_musculoskeletal_clinical_en.html) | [chunkresolve_icd10cm_musculoskeletal_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_musculoskeletal_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.neoplasms](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_neoplasms_clinical_en.html) | [chunkresolve_icd10cm_neoplasms_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_neoplasms_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.poison](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_poison_ext_clinical_en.html) | [chunkresolve_icd10cm_poison_ext_clinical](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_poison_ext_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.puerile](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_puerile_clinical_en.html) | [chunkresolve_icd10cm_puerile_clinical](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_puerile_clinical_en.html)           |
| English  | resolve_chunk.icd10pcs.clinical | chunkresolve_icd10pcs_clinical          |
| English  | [resolve_chunk.icdo.clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10pcs_clinical_en.html) | [chunkresolve_icdo_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10pcs_clinical_en.html)           |
| English  | [resolve_chunk.loinc](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_loinc_clinical_en.html) | [chunkresolve_loinc_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_loinc_clinical_en.html)           |
| English  | [resolve_chunk.rxnorm.cd](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_cd_clinical_en.html) | [chunkresolve_rxnorm_cd_clinical](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_cd_clinical_en.html)           |
| English  | resolve_chunk.rxnorm.in | chunkresolve_rxnorm_in_clinical          |
| English  | resolve_chunk.rxnorm.in_healthcare | chunkresolve_rxnorm_in_healthcare          |
| English  | [resolve_chunk.rxnorm.sbd](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_sbd_clinical_en.html) | [chunkresolve_rxnorm_sbd_clinical](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_sbd_clinical_en.html)           |
| English  | [resolve_chunk.rxnorm.scd](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_scd_clinical_en.html) | [chunkresolve_rxnorm_scd_clinical](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_scd_clinical_en.html)           |
| English  | resolve_chunk.rxnorm.scdc | chunkresolve_rxnorm_scdc_clinical          |
| English  | resolve_chunk.rxnorm.scdc_healthcare | chunkresolve_rxnorm_scdc_healthcare          |
| English  | [resolve_chunk.rxnorm.xsmall.clinical](https://nlp.johnsnowlabs.com/2020/06/24/chunkresolve_rxnorm_xsmall_clinical_en.html) | [chunkresolve_rxnorm_xsmall_clinical](https://nlp.johnsnowlabs.com/2020/06/24/chunkresolve_rxnorm_xsmall_clinical_en.html)           |
| English  | [resolve_chunk.snomed.findings](https://nlp.johnsnowlabs.com/2020/06/20/chunkresolve_snomed_findings_clinical_en.html) | [chunkresolve_snomed_findings_clinical](https://nlp.johnsnowlabs.com/2020/06/20/chunkresolve_snomed_findings_clinical_en.html)           |


# New Classifiers

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | classify.icd10.clinical | classifier_icd10cm_hcc_clinical          |
| English  | classify.icd10.healthcare | classifier_icd10cm_hcc_healthcare          |
| English  | [classify.ade.biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_biobert_en.html) | [classifierdl_ade_biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_biobert_en.html)           |
| English  | [classify.ade.clinical](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_clinicalbert_en.html) | [classifierdl_ade_clinicalbert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_clinicalbert_en.html)           |
| English  | [classify.ade.conversational](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_conversational_biobert_en.html) | [classifierdl_ade_conversational_biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_conversational_biobert_en.html)           |
| English  | [classify.gender.biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_biobert_en.html) | [classifierdl_gender_biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_biobert_en.html)           |
| English  | [classify.gender.sbert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_sbert_en.html) | [classifierdl_gender_sbert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_sbert_en.html)           |
| English  | classify.pico | classifierdl_pico_biobert          |


# German Medical models

| nlu.load() reference                                         | Spark NLP Model reference          |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [embed]    | w2v_cc_300d|
| [embed.w2v]    | w2v_cc_300d|
| [resolve_chunk]    | chunkresolve_ICD10GM|
| [resolve_chunk.icd10gm]    | chunkresolve_ICD10GM|
| resolve_chunk.icd10gm.2021    | chunkresolve_ICD10GM_2021|
| med_ner.legal   | ner_legal|
| med_ner    | ner_healthcare|
| med_ner.healthcare    | ner_healthcare|
| med_ner.healthcare_slim    | ner_healthcare_slim|
| med_ner.traffic    | ner_traffic|

# Spanish Medical models
| nlu.load() reference                                         | Spark NLP Model reference          |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [embed.scielo.150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_150d_es.html) | [embeddings_scielo_150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_150d_es.html)| 
| [embed.scielo.300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_300d_es.html)   | [embeddings_scielo_300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_300d_es.html)| 
| [embed.scielo.50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_50d_es.html)  | [embeddings_scielo_50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_50d_es.html)| 
| [embed.scielowiki.150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_150d_es.html)   | [embeddings_scielowiki_150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_150d_es.html)| 
| [embed.scielowiki.300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_300d_es.html)   | [embeddings_scielowiki_300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_300d_es.html)| 
| [embed.scielowiki.50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_50d_es.html)   | [embeddings_scielowiki_50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_50d_es.html)| 
| [embed.sciwiki.150d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_150d_es.html)   | [embeddings_sciwiki_150d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_150d_es.html)| 
| [embed.sciwiki.300d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_300d_es.html)   | [embeddings_sciwiki_300d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_300d_es.html)| 
| [embed.sciwiki.50d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_50d_es.html)   | [embeddings_sciwiki_50d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_50d_es.html)| 
| [med_ner](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)   |  [ner_diag_proc](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)| 
| [med_ner.neoplasm](https://nlp.johnsnowlabs.com/2021/03/31/ner_neoplasms_es.html)  | [ner_neoplasms](https://nlp.johnsnowlabs.com/2021/03/31/ner_neoplasms_es.html)| 
| [med_ner.diag_proc](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)  | [ner_diag_proc](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)| 

# GPU Mode
You can now enable NLU GPU mode by setting `gpu=true` while loading a model. I.e. `nlu.load('train.sentiment' gpu=True)` . If must resart you kernel, if you already loaded a nlu pipeline withouth GPU mode.

# Output Level Relation
This new output level is used for relation extractors and will give you 1 row per relation extracted.


# Bug fixes
- Fixed a bug that caused loading NLU models in offline mode not to work in some occasions


# 1 line Install NLU
```!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash```

# Install via PIP 
```! pip install nlu pyspark==3.0.1```


## Additional NLU ressources

- [NLU Website](https://nlu.johnsnowlabs.com/)
- [All NLU Tutorial Notebooks](https://nlu.johnsnowlabs.com/docs/en/notebooks)
- [NLU Videos and Blogposts on NLU](https://nlp.johnsnowlabs.com/learn#pythons-nlu-library)
- [NLU on Github](https://github.com/JohnSnowLabs/nlu)
- [Suggestions or Questions? Contact us in Slack!](https://join.slack.com/t/spark-nlp/shared_invite/zt-lutct9gm-kuUazcyFKhuGY3_0AMkxqA)",38411
236,236,Call for Participation in a Shared Task about occupations detection in clinical texts,"Hi, everyone!

I posted this earlier to r/MachineLearning, but I just found out about this subreddit and thought people here might be more interested. Sorry if it's not allowed!

I'm a researcher from the Text Mining Unit at the Barcelona Supercomputing  Center, and I wanted to share with you some information about MEDDOPROF,  a Shared Task that we are currently organizing focused on the detection  and normalization of professions and employment status in clinical  texts in Spanish.

Even if these types of entities might seem really niche, every day we learn more and more about their importance. Just think about how someone's occupation  can have a radical impact in their physical and mental health, habits,  lifestyle choices, ... There is even an entire medical specialty,  occupational medicine, that is centered around this topic. In the context of the current pandemic, many people with specific occupations  have been specially affected (for instance, health professionals and  other essential workers). The detection of these terms will help  researchers to better characterize health risks of specific occupations.

Outside  medicine, we foresee that the systems resulting from MEDDOPROF may be  used in fields such as social care, human resources, legal NLP and even gender studies. Personally, I think one of the main contributions of the  task is the inclusion of employment status in a broad sense. We have  annotated unemployed and retired people, family caregivers, people who  are homeless, people who depend on government subsidies, etc, which strengthens the social side of this project.

Additionally,  each mention in the corpus (which includes 2000 documents from over 20  different medical specialties) has been normalized to either the  European Skills, Competences, Qualifications and Occupations  classification (ESCO) or SNOMED-CT. These are multilingual vocabularies,  which we hope might inspire similar tasks in other languages (to the  best of our knowledge, there haven't been any similar tasks yet).

We  released the training set some weeks ago, and on June 1st we will  release the test set. If you are interested in the task, want to see  some annotated examples, the data or the annotation guidelines, ...  please check out the task's website:[ https://temu.bsc.es/meddoprof/](https://temu.bsc.es/meddoprof/)

Thank you if you have read up to here, I hope to see at least some of you at the task!",https://www.reddit.com/r/LanguageTechnology/comments/n5kw8w/call_for_participation_in_a_shared_task_about/,LanguageTechnology,t3_n5kw8w,"Call for Participation in a Shared Task about occupations detection in clinical texts Hi, everyone!

I posted this earlier to r/MachineLearning, but I just found out about this subreddit and thought people here might be more interested. Sorry if it's not allowed!

I'm a researcher from the Text Mining Unit at the Barcelona Supercomputing  Center, and I wanted to share with you some information about MEDDOPROF,  a Shared Task that we are currently organizing focused on the detection  and normalization of professions and employment status in clinical  texts in Spanish.

Even if these types of entities might seem really niche, every day we learn more and more about their importance. Just think about how someone's occupation  can have a radical impact in their physical and mental health, habits,  lifestyle choices, ... There is even an entire medical specialty,  occupational medicine, that is centered around this topic. In the context of the current pandemic, many people with specific occupations  have been specially affected (for instance, health professionals and  other essential workers). The detection of these terms will help  researchers to better characterize health risks of specific occupations.

Outside  medicine, we foresee that the systems resulting from MEDDOPROF may be  used in fields such as social care, human resources, legal NLP and even gender studies. Personally, I think one of the main contributions of the  task is the inclusion of employment status in a broad sense. We have  annotated unemployed and retired people, family caregivers, people who  are homeless, people who depend on government subsidies, etc, which strengthens the social side of this project.

Additionally,  each mention in the corpus (which includes 2000 documents from over 20  different medical specialties) has been normalized to either the  European Skills, Competences, Qualifications and Occupations  classification (ESCO) or SNOMED-CT. These are multilingual vocabularies,  which we hope might inspire similar tasks in other languages (to the  best of our knowledge, there haven't been any similar tasks yet).

We  released the training set some weeks ago, and on June 1st we will  release the test set. If you are interested in the task, want to see  some annotated examples, the data or the annotation guidelines, ...  please check out the task's website:[ https://temu.bsc.es/meddoprof/](https://temu.bsc.es/meddoprof/)

Thank you if you have read up to here, I hope to see at least some of you at the task!",2526
237,237,I am working on a topic modelling paper and I need your help,"Hello everyone,

I'm currently working on a topic modelling paper and I in order to evaluate it, I need your help. Topic models are unsupervised clustering methods used to group related words together and extract topics. To evaluate such topic I will in part use the word intrusion task ([source](https://papers.nips.cc/paper/2009/hash/f92586a25bb3145facd64ab20fd554ff-Abstract.html)). The task consist in polluting a topic (group of words) with an intruder. The assumption is that better the topic the easier it is to find the intruder. If you want to help, follow the link to a small 2min survey. No personal information is needed.

Link to the survey : [https://forms.gle/svWu4XmR2PAMeiCD9](https://forms.gle/svWu4XmR2PAMeiCD9)

Thank you to all who will find the time to help :)

&amp;#x200B;

PS: don't hesitate if you have any questions",https://www.reddit.com/r/LanguageTechnology/comments/n5h677/i_am_working_on_a_topic_modelling_paper_and_i/,LanguageTechnology,t3_n5h677,"I am working on a topic modelling paper and I need your help Hello everyone,

I'm currently working on a topic modelling paper and I in order to evaluate it, I need your help. Topic models are unsupervised clustering methods used to group related words together and extract topics. To evaluate such topic I will in part use the word intrusion task ([source](https://papers.nips.cc/paper/2009/hash/f92586a25bb3145facd64ab20fd554ff-Abstract.html)). The task consist in polluting a topic (group of words) with an intruder. The assumption is that better the topic the easier it is to find the intruder. If you want to help, follow the link to a small 2min survey. No personal information is needed.

Link to the survey : [https://forms.gle/svWu4XmR2PAMeiCD9](https://forms.gle/svWu4XmR2PAMeiCD9)

Thank you to all who will find the time to help :)

&amp;#x200B;

PS: don't hesitate if you have any questions",903
238,238,[Request] Curated Advanced NLP Resources,"Is there a curated list of Advanced Natural Language Processing (NLP) Resources (Model Zoo, GitHub Repositories, Datasets, etc.)  
I think Advanced NLP is progress in the last 3 years since BERT and GPT which are SOTA versatile models and also great for Transfer Learning (Zero-Shot and Few-Shot Learning) like Hugging Face models. Essentially, they've changed the way we approach NLP problems today.

I could not find it on the internet (including on GitHub, Kaggle, Medium, or Reddit.) And, I know about [NLP Progress](http://nlpprogress.com/) and [The Super Duper NLP Repo](https://notebooks.quantumstat.com/).

I need it for a project, and any help is greatly appreciated.",https://www.reddit.com/r/LanguageTechnology/comments/n5h4hy/request_curated_advanced_nlp_resources/,LanguageTechnology,t3_n5h4hy,"[Request] Curated Advanced NLP Resources Is there a curated list of Advanced Natural Language Processing (NLP) Resources (Model Zoo, GitHub Repositories, Datasets, etc.)  
I think Advanced NLP is progress in the last 3 years since BERT and GPT which are SOTA versatile models and also great for Transfer Learning (Zero-Shot and Few-Shot Learning) like Hugging Face models. Essentially, they've changed the way we approach NLP problems today.

I could not find it on the internet (including on GitHub, Kaggle, Medium, or Reddit.) And, I know about [NLP Progress](http://nlpprogress.com/) and [The Super Duper NLP Repo](https://notebooks.quantumstat.com/).

I need it for a project, and any help is greatly appreciated.",717
239,239,Tagalog: a text labeling platform for teams,,https://www.tagalog.ai/tagalog/,LanguageTechnology,t3_n5h2jx,Tagalog: a text labeling platform for teams ,44
240,240,EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks,,https://link.medium.com/YkCBPe5n0fb,LanguageTechnology,t3_n59z8e,EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks ,93
242,242,Q: Multi-Document Keyword Extraction,"Hello there,

im currently doing my research for my bachelor thesis.  
What is a nice technique to extract keywords from one or multiple documents. Currently i've tried TF-IDF, RAKE and YAKE. The hard part somehow is to find the Least Common Multiple of the documents.

Could someone help me out?

&amp;#x200B;

appreciate it",https://www.reddit.com/r/LanguageTechnology/comments/n5e67a/q_multidocument_keyword_extraction/,LanguageTechnology,t3_n5e67a,"Q: Multi-Document Keyword Extraction Hello there,

im currently doing my research for my bachelor thesis.  
What is a nice technique to extract keywords from one or multiple documents. Currently i've tried TF-IDF, RAKE and YAKE. The hard part somehow is to find the Least Common Multiple of the documents.

Could someone help me out?

&amp;#x200B;

appreciate it",362
243,243,Help with aligned word embeddings,"Hello NLP redditors.

I'm currently working on a project where I need to find the similarity between sentences. At the moment I'm using cosine similarity with [fastText word embeddings](https://fasttext.cc/docs/en/pretrained-vectors.html) and TF-IDF weights. On single languages results are pretty good so far, my boss is happy.

The next step is to solve the same problem with multiple languages. My idea is to use the same technology but with [aligned fastText word embeddings](https://fasttext.cc/docs/en/aligned-vectors.html). In theory, using vocabularies with aligned word vectors should mean that words with similar meanings (in different languages) have a similar vector. Thus, comparing ""the car runs fast"" and ""l'auto corre veloce"" (Italian) should bring a high cosine similarity.

In practice, results are disappointing. Even a comparison between simple particles such as ""yes"" and ""sì"", or even ""no"" and ""no"", bring a cosine similarity well below any acceptable threshold.

Is there anyone here that had some experience with aligned word vectors and can tell me if it's a lost war or there is something I can do to improve the results?

We currently train our own vocabularies on Wikipedia and other sources, and we align the vocabularies using [MUSE](https://github.com/facebookresearch/MUSE) with default settings (0-5000 dictionary for training, 5000-6500 dictionary for evaluation and 5 refinements).

Any help will be appreciated. Thanks in advance.

**Edit: Thanks all for the answers! Will take a look at each suggestion.**",https://www.reddit.com/r/LanguageTechnology/comments/n4wx6v/help_with_aligned_word_embeddings/,LanguageTechnology,t3_n4wx6v,"Help with aligned word embeddings Hello NLP redditors.

I'm currently working on a project where I need to find the similarity between sentences. At the moment I'm using cosine similarity with [fastText word embeddings](https://fasttext.cc/docs/en/pretrained-vectors.html) and TF-IDF weights. On single languages results are pretty good so far, my boss is happy.

The next step is to solve the same problem with multiple languages. My idea is to use the same technology but with [aligned fastText word embeddings](https://fasttext.cc/docs/en/aligned-vectors.html). In theory, using vocabularies with aligned word vectors should mean that words with similar meanings (in different languages) have a similar vector. Thus, comparing ""the car runs fast"" and ""l'auto corre veloce"" (Italian) should bring a high cosine similarity.

In practice, results are disappointing. Even a comparison between simple particles such as ""yes"" and ""sì"", or even ""no"" and ""no"", bring a cosine similarity well below any acceptable threshold.

Is there anyone here that had some experience with aligned word vectors and can tell me if it's a lost war or there is something I can do to improve the results?

We currently train our own vocabularies on Wikipedia and other sources, and we align the vocabularies using [MUSE](https://github.com/facebookresearch/MUSE) with default settings (0-5000 dictionary for training, 5000-6500 dictionary for evaluation and 5 refinements).

Any help will be appreciated. Thanks in advance.

**Edit: Thanks all for the answers! Will take a look at each suggestion.**",1576
244,244,Blog for papers in NLP/CompLing,"Hi everyone! I have started here a blog for discussing various papers in the field of NLP/CompLing: https://selfassuredpaperreads.medium.com/
Do give it a read and let me know what you think!",https://www.reddit.com/r/LanguageTechnology/comments/n4nt8n/blog_for_papers_in_nlpcompling/,LanguageTechnology,t3_n4nt8n,"Blog for papers in NLP/CompLing Hi everyone! I have started here a blog for discussing various papers in the field of NLP/CompLing: https://selfassuredpaperreads.medium.com/
Do give it a read and let me know what you think!",223
246,246,Text classification: words to numbers,In most standard applications of text classification - using algorithms like word2vec/glove/bert ... is text data automatically converted into vectors of numbers? Can you then use regression models right away once the text has been converted into numbers?,https://www.reddit.com/r/LanguageTechnology/comments/n4v4bu/text_classification_words_to_numbers/,LanguageTechnology,t3_n4v4bu,Text classification: words to numbers In most standard applications of text classification - using algorithms like word2vec/glove/bert ... is text data automatically converted into vectors of numbers? Can you then use regression models right away once the text has been converted into numbers?,293
247,247,Chatbot with R,"Hi everyone!  


I need to create a Bot that uses NLP with R!  


has anyone ever done this?  


Thank you so much!",https://www.reddit.com/r/LanguageTechnology/comments/n4p8ur/chatbot_with_r/,LanguageTechnology,t3_n4p8ur,"Chatbot with R Hi everyone!  


I need to create a Bot that uses NLP with R!  


has anyone ever done this?  


Thank you so much!",130
248,248,How is it possible to extract a single word (may be in textgrid) from the textgrid file of a sentence through a code in praat?,"1. How is it possible to extract a single word (may be in textgrid) from the textgrid file of a sentence through a code in praat?

&amp;#x200B;

Suppose, from a long file I have put boundary and created one textgrid containing 4 tokens sentences containing the same key word life. The sentence is ""He loves life and laughter."" The tokens are:

&amp;#x200B;

S1\_life1-life, S1\_life2-life, S1\_life3-life, S1\_life4-life. I need to write a praat code that will separate the ""life"" from the sentence text grid.

&amp;#x200B;

2. Will the same code be applicable for the same function in a different sentence where the positioning of the keyword is different. For instance, ""Life has a different meaning in the mountains."" In here, they keyword is at the beginning of the sentence.",https://www.reddit.com/r/LanguageTechnology/comments/n4og06/how_is_it_possible_to_extract_a_single_word_may/,LanguageTechnology,t3_n4og06,"How is it possible to extract a single word (may be in textgrid) from the textgrid file of a sentence through a code in praat? 1. How is it possible to extract a single word (may be in textgrid) from the textgrid file of a sentence through a code in praat?

&amp;#x200B;

Suppose, from a long file I have put boundary and created one textgrid containing 4 tokens sentences containing the same key word life. The sentence is ""He loves life and laughter."" The tokens are:

&amp;#x200B;

S1\_life1-life, S1\_life2-life, S1\_life3-life, S1\_life4-life. I need to write a praat code that will separate the ""life"" from the sentence text grid.

&amp;#x200B;

2. Will the same code be applicable for the same function in a different sentence where the positioning of the keyword is different. For instance, ""Life has a different meaning in the mountains."" In here, they keyword is at the beginning of the sentence.",906
249,249,Inevitable Manual Work involved in NLP,"I have feeling that not many people are willing to admit - but ultimately, is a significant part of many data mining projects (e.g. checking data quality, parsing through data, etc.) still done manually? 

For example here is an example I just made up relating to Supervised NLP (Natural Language Processing) Classification : Suppose I have 1000 medical reports of patients, containing unstructured text made by a doctor during a hospital visit. For a given patient, each report contains all the text notes that the doctor made for that patient, for visits between 2010 and 2020. These reports make mention of the patients bio data (e.g. age, gender, medical history, etc.) and the details of the symptoms that the patient is experiencing over a long period of time (e.g. let's say that these reports are 2000 words on average). The problem is, different doctors have different styles of writing - each of these 1000 reports is different from another. If a human were to read the report, the human could figure out what happened to the patient - did the patient have a serious condition (let's call this ""class 1"") or a non-serious condition (let's call this ""class 0""). This is what we are interested in predicting for future patients based on the limited medical notes made by doctors for these future patients. 

The problem is - there is no clear and fast way (not that I know of) to take the 1000 medical reports that are available, and label each report as ""class 1"" or ""class 0"". For example, for ""class 0"" : one of the doctors could clearly write at the end of a report ""all medical tests were conducted and the results and were all negative"", and another doctor could end the report by saying ""the patient should seriously consider changing their lifestyle and eat healthier food. benign."" . 

In this example, how would someone assign labels to all these 1000 cases, without manually reading them and deciding if the information in the report corresponds to a ""serious condition"" or a ""non-serious condition""? I was thinking of using something like ""sentiment analysis"" to capture the ""mood"" of these reports, and use sentiment analysis a method to informally gauge if the tone of the report is ""dark"" (serious condition) or ""light"" (non serious condition). But I am not sure if this is the best way to approach this problem. Is there a way to do this without reading all the reports and manually deciding labels?

In the end - this is what I am interested in doing : suppose a new patient comes in and on the first visit, the doctor makes some quick notes (e.g. patient is male, 30 years old, 180 cm, 100 kg, non-smoker, frequently complains of chest pains, no high blood pressure, works a construction worker and takes daily medicine for acid reflex). Just based on these quick notes and the 1000 reports available (NOTE: I am trying to illustrate a point here, that the medical notes for the new patient and the 1000 reports DO NOT have the same format), can a researcher predict (supervised classification, e.g. decision tree) if this patient will have a ""serious"" or a ""non-serious"" condition?

PS: suppose the doctors have a very detailed medical encyclopedia on their computers - can this medical encyclopedia be used alongside the 1000 medical reports to improve the prediction results?",https://www.reddit.com/r/LanguageTechnology/comments/n4i0le/inevitable_manual_work_involved_in_nlp/,LanguageTechnology,t3_n4i0le,"Inevitable Manual Work involved in NLP I have feeling that not many people are willing to admit - but ultimately, is a significant part of many data mining projects (e.g. checking data quality, parsing through data, etc.) still done manually? 

For example here is an example I just made up relating to Supervised NLP (Natural Language Processing) Classification : Suppose I have 1000 medical reports of patients, containing unstructured text made by a doctor during a hospital visit. For a given patient, each report contains all the text notes that the doctor made for that patient, for visits between 2010 and 2020. These reports make mention of the patients bio data (e.g. age, gender, medical history, etc.) and the details of the symptoms that the patient is experiencing over a long period of time (e.g. let's say that these reports are 2000 words on average). The problem is, different doctors have different styles of writing - each of these 1000 reports is different from another. If a human were to read the report, the human could figure out what happened to the patient - did the patient have a serious condition (let's call this ""class 1"") or a non-serious condition (let's call this ""class 0""). This is what we are interested in predicting for future patients based on the limited medical notes made by doctors for these future patients. 

The problem is - there is no clear and fast way (not that I know of) to take the 1000 medical reports that are available, and label each report as ""class 1"" or ""class 0"". For example, for ""class 0"" : one of the doctors could clearly write at the end of a report ""all medical tests were conducted and the results and were all negative"", and another doctor could end the report by saying ""the patient should seriously consider changing their lifestyle and eat healthier food. benign."" . 

In this example, how would someone assign labels to all these 1000 cases, without manually reading them and deciding if the information in the report corresponds to a ""serious condition"" or a ""non-serious condition""? I was thinking of using something like ""sentiment analysis"" to capture the ""mood"" of these reports, and use sentiment analysis a method to informally gauge if the tone of the report is ""dark"" (serious condition) or ""light"" (non serious condition). But I am not sure if this is the best way to approach this problem. Is there a way to do this without reading all the reports and manually deciding labels?

In the end - this is what I am interested in doing : suppose a new patient comes in and on the first visit, the doctor makes some quick notes (e.g. patient is male, 30 years old, 180 cm, 100 kg, non-smoker, frequently complains of chest pains, no high blood pressure, works a construction worker and takes daily medicine for acid reflex). Just based on these quick notes and the 1000 reports available (NOTE: I am trying to illustrate a point here, that the medical notes for the new patient and the 1000 reports DO NOT have the same format), can a researcher predict (supervised classification, e.g. decision tree) if this patient will have a ""serious"" or a ""non-serious"" condition?

PS: suppose the doctors have a very detailed medical encyclopedia on their computers - can this medical encyclopedia be used alongside the 1000 medical reports to improve the prediction results?",3343
250,250,Overfitting,"I am trying to solve multi-class classification problem using BERT.

My training accuracy is way higher than the validation and test sets so I assume that is clearly overfitting.

&amp;#x200B;

This is the configuration for my BERT Classifier

    ""class_name"": ""bert_classifier"",
            ""n_classes"": 5,
            ""return_probas"": True,
            ""one_hot_labels"": True,
            ""bert_config_file"": ""/content/ru_conversational_cased_L-12_H-768_A-12/bert_config.json"",
            ""pretrained_bert"": ""/content/ru_conversational_cased_L-12_H-768_A-12/bert_model.ckpt"",
            ""save_path"": ""sst_bert_model/model"",
            ""load_path"": ""sst_bert_model/model"",
            ""keep_prob"": 0.5,
            ""learning_rate"": 1e-05,
            ""weight_decay_rate"": 0.001, #this line added after the overfitting
            ""learning_rate_drop_patience"": 5,
            ""learning_rate_drop_div"": 2.0,
            ""in"": [
              ""bert_features""
                ],
            ""in_y"": [
              ""y_onehot""
            ],
            ""out"": [
              ""y_pred_probas""
            ]

Here is my plan to overcome the issue of overfitting.

1. I added a little `more data` to the current one, (just a bit, at least something that I could find)
2. I added `""weight_decay_rate"": 0.001`, to basically regularize the weight of the model
3. I increased the `batch size to 32`. It was 16 before ( I don't know if that helps)
4. I set a `""learning_rate_drop_patience"": 2,` so it stops training after 2 epochs if there no is an improvement.

&amp;#x200B;

The last thing I wanna do is to increase my dropout

    DropOut = 0.5

&amp;#x200B;

**QUESTIONS:** 

1. However, I can't figure out which parameter is actually ""dropout"" as there is no parameter called directly dropout.  Mainly because the language I am targeting is Russian and I need to use Deep Pavlov [http://docs.deeppavlov.ai/en/master/apiref/models/bert.html](http://docs.deeppavlov.ai/en/master/apiref/models/bert.html) not the hugging face directly so Deep Pavlov Bert Classifier has only these 3 things that are kinda close to what I am looking for (`dropout function`)

&amp;#8203;

    keep_prob             -     dropout keep_prob for non-Bert layers
    attention_probs_keep_prob – keep_prob for Bert self-attention layers
    hidden_keep_prob –           keep_prob for Bert hidden layers

which one is the `Dropout`? which function I need to make 0.5 out of these three?

   2.    I have 3 `epochs` in total, is it correct that I am making `patience rate` (it stops training after 2 epochs if there is no improvement) ==  2, instead of 1? 

   3.    I am thinking to minimize the `learning rate` as well. Now it is currently `1e-05.`  Should I make it maybe 1e-3? 

   4. And overall, what else can you suggest to me to overcome the issue of overfitting? is the plan good enough to tackle this problem?",https://www.reddit.com/r/LanguageTechnology/comments/n4ei50/overfitting/,LanguageTechnology,t3_n4ei50,"Overfitting I am trying to solve multi-class classification problem using BERT.

My training accuracy is way higher than the validation and test sets so I assume that is clearly overfitting.

&amp;#x200B;

This is the configuration for my BERT Classifier

    ""class_name"": ""bert_classifier"",
            ""n_classes"": 5,
            ""return_probas"": True,
            ""one_hot_labels"": True,
            ""bert_config_file"": ""/content/ru_conversational_cased_L-12_H-768_A-12/bert_config.json"",
            ""pretrained_bert"": ""/content/ru_conversational_cased_L-12_H-768_A-12/bert_model.ckpt"",
            ""save_path"": ""sst_bert_model/model"",
            ""load_path"": ""sst_bert_model/model"",
            ""keep_prob"": 0.5,
            ""learning_rate"": 1e-05,
            ""weight_decay_rate"": 0.001, #this line added after the overfitting
            ""learning_rate_drop_patience"": 5,
            ""learning_rate_drop_div"": 2.0,
            ""in"": [
              ""bert_features""
                ],
            ""in_y"": [
              ""y_onehot""
            ],
            ""out"": [
              ""y_pred_probas""
            ]

Here is my plan to overcome the issue of overfitting.

1. I added a little `more data` to the current one, (just a bit, at least something that I could find)
2. I added `""weight_decay_rate"": 0.001`, to basically regularize the weight of the model
3. I increased the `batch size to 32`. It was 16 before ( I don't know if that helps)
4. I set a `""learning_rate_drop_patience"": 2,` so it stops training after 2 epochs if there no is an improvement.

&amp;#x200B;

The last thing I wanna do is to increase my dropout

    DropOut = 0.5

&amp;#x200B;

**QUESTIONS:** 

1. However, I can't figure out which parameter is actually ""dropout"" as there is no parameter called directly dropout.  Mainly because the language I am targeting is Russian and I need to use Deep Pavlov [http://docs.deeppavlov.ai/en/master/apiref/models/bert.html](http://docs.deeppavlov.ai/en/master/apiref/models/bert.html) not the hugging face directly so Deep Pavlov Bert Classifier has only these 3 things that are kinda close to what I am looking for (`dropout function`)

&amp;#8203;

    keep_prob             -     dropout keep_prob for non-Bert layers
    attention_probs_keep_prob – keep_prob for Bert self-attention layers
    hidden_keep_prob –           keep_prob for Bert hidden layers

which one is the `Dropout`? which function I need to make 0.5 out of these three?

   2.    I have 3 `epochs` in total, is it correct that I am making `patience rate` (it stops training after 2 epochs if there is no improvement) ==  2, instead of 1? 

   3.    I am thinking to minimize the `learning rate` as well. Now it is currently `1e-05.`  Should I make it maybe 1e-3? 

   4. And overall, what else can you suggest to me to overcome the issue of overfitting? is the plan good enough to tackle this problem?",2902
251,251,How to quickly test my model?,"In my last post [https://www.reddit.com/r/learnmachinelearning/comments/n4ejdp/text\_classification\_problem\_overfitting/](https://www.reddit.com/r/learnmachinelearning/comments/n4ejdp/text_classification_problem_overfitting/)  I already said that I am trying to solve the multiclass text classification problem using BERT.

&amp;#x200B;

After the first training which took 13 hours, I noticed that my model is overfitting. I did some changes to my model, and now I wanna test it out. I can't afford training the whole model everytime because each time it takes huge amount of time, so how can i quickly test it to see how my changes affected my model? Maybe I can test it on a smaller dataset? I heard this is a way of doing so, however, i am not sure if I should use my test set to do so? if yes, should I break my test into 3 pieces (train,test,val ?) again? My test set is not that big (around 3000 rows of data) and I am wondering if such a small data can do the job? 

&amp;#x200B;

I am new in this field, and this is the first me doing this, so it would be highly appreciated if anyone could guide me through it. What are the best practices that allow me to quickly test my model?",https://www.reddit.com/r/LanguageTechnology/comments/n4eocz/how_to_quickly_test_my_model/,LanguageTechnology,t3_n4eocz,"How to quickly test my model? In my last post [https://www.reddit.com/r/learnmachinelearning/comments/n4ejdp/text\_classification\_problem\_overfitting/](https://www.reddit.com/r/learnmachinelearning/comments/n4ejdp/text_classification_problem_overfitting/)  I already said that I am trying to solve the multiclass text classification problem using BERT.

&amp;#x200B;

After the first training which took 13 hours, I noticed that my model is overfitting. I did some changes to my model, and now I wanna test it out. I can't afford training the whole model everytime because each time it takes huge amount of time, so how can i quickly test it to see how my changes affected my model? Maybe I can test it on a smaller dataset? I heard this is a way of doing so, however, i am not sure if I should use my test set to do so? if yes, should I break my test into 3 pieces (train,test,val ?) again? My test set is not that big (around 3000 rows of data) and I am wondering if such a small data can do the job? 

&amp;#x200B;

I am new in this field, and this is the first me doing this, so it would be highly appreciated if anyone could guide me through it. What are the best practices that allow me to quickly test my model?",1220
252,252,Jargon Detection and Normalization,"Hello,

I am a undergraduate student writing my final thesis right now. I am exploring links between different social media platforms in regards to sentiment. How does Sentiment „flow“ from thematically and temporally near posts. 

One of the platforms that I explore is 4chan and I am having a lot of problems with the special vocabulary there. Most resources I can find solve twitter specific problems where a character limit is involved. The lack of such a limit presents me a plethora of variations of the same token. Elongated words and written out laughter with typos really messes up my work. 

Additionally I can‘t correct typos easily because there are many special words that aren‘t written in any dictionary. Some of these I could identify through urban dictionary, but many others are falsely corrected by a spellchecker. 

With the FastText-Algorithm I could identify a couple hundred tokens and normalize them, but I suspect there is a bunch more. Right now I am reading Dr. Farrell‘s work on jargon detection: http://oro.open.ac.uk/70529/

I wonder if you guys could give me some pointers. Thank you very much!",https://www.reddit.com/r/LanguageTechnology/comments/n3u6uh/jargon_detection_and_normalization/,LanguageTechnology,t3_n3u6uh,"Jargon Detection and Normalization Hello,

I am a undergraduate student writing my final thesis right now. I am exploring links between different social media platforms in regards to sentiment. How does Sentiment „flow“ from thematically and temporally near posts. 

One of the platforms that I explore is 4chan and I am having a lot of problems with the special vocabulary there. Most resources I can find solve twitter specific problems where a character limit is involved. The lack of such a limit presents me a plethora of variations of the same token. Elongated words and written out laughter with typos really messes up my work. 

Additionally I can‘t correct typos easily because there are many special words that aren‘t written in any dictionary. Some of these I could identify through urban dictionary, but many others are falsely corrected by a spellchecker. 

With the FastText-Algorithm I could identify a couple hundred tokens and normalize them, but I suspect there is a bunch more. Right now I am reading Dr. Farrell‘s work on jargon detection: http://oro.open.ac.uk/70529/

I wonder if you guys could give me some pointers. Thank you very much!",1160
253,253,Any software that can annotate (grapheme/phonogram) in a word with the matching phoneme?,"I  am trying to find a software that could tell   
\-if the letter ""y"" in a word is a vowel or a consonant.  
\-Or if ""ti"" should be read as ""sh""

I found multiple tool that return a list of phoneme but none that tell me which letter in the original word match each phoneme (an alignment).  
I assume this is doable because this is essentially what speech-to-text tool are doing.  


But I would like a tool that give me a list of matching pair (grapheme/phoneme) so I display the annotation on the the correct range of letter in the original word.",https://www.reddit.com/r/LanguageTechnology/comments/n458pt/any_software_that_can_annotate_graphemephonogram/,LanguageTechnology,t3_n458pt,"Any software that can annotate (grapheme/phonogram) in a word with the matching phoneme? I  am trying to find a software that could tell   
\-if the letter ""y"" in a word is a vowel or a consonant.  
\-Or if ""ti"" should be read as ""sh""

I found multiple tool that return a list of phoneme but none that tell me which letter in the original word match each phoneme (an alignment).  
I assume this is doable because this is essentially what speech-to-text tool are doing.  


But I would like a tool that give me a list of matching pair (grapheme/phoneme) so I display the annotation on the the correct range of letter in the original word.",637
254,254,Stop Word and Tokenization (with R),"I am learning about NLP and trying to understand how to tokenize text and remove stop words.

I tried the following line of code (from ""quanteada) and got the following error:

first_method &lt;- tokens(tdm) %&gt;% tokens_remove(stopwords(""en""), pad = TRUE)

Error: tokens() only works on character, corpus, list, tokens objects.

Has anyone ever gotten this error before?

I posted the full details to my question over here: https://stackoverflow.com/questions/67376045/r-error-only-works-with-character-objects

Thanks",https://www.reddit.com/r/LanguageTechnology/comments/n494bh/stop_word_and_tokenization_with_r/,LanguageTechnology,t3_n494bh,"Stop Word and Tokenization (with R) I am learning about NLP and trying to understand how to tokenize text and remove stop words.

I tried the following line of code (from ""quanteada) and got the following error:

first_method &lt;- tokens(tdm) %&gt;% tokens_remove(stopwords(""en""), pad = TRUE)

Error: tokens() only works on character, corpus, list, tokens objects.

Has anyone ever gotten this error before?

I posted the full details to my question over here: https://stackoverflow.com/questions/67376045/r-error-only-works-with-character-objects

Thanks",556
255,255,The giant leaps in language technology -- and who's left behind,,https://www.ted.com/talks/kalika_bali_the_giant_leaps_in_language_technology_and_who_s_left_behind?utm_campaign=tedspread&amp;utm_medium=referral&amp;utm_source=tedcomshare,LanguageTechnology,t3_n3e5en,The giant leaps in language technology -- and who's left behind ,64
256,256,LINE: Large-scale Information Network Embedding (Machine Learning with Graphs),,https://youtu.be/VuqvD3qp76M,LanguageTechnology,t3_n31jh9,LINE: Large-scale Information Network Embedding (Machine Learning with Graphs) ,79
257,257,CrossWeigh: Training NER with Imperfect Annotations | Research Papers Summary 016,,https://youtu.be/IXrwYWgnijQ,LanguageTechnology,t3_n3d0kn,CrossWeigh: Training NER with Imperfect Annotations | Research Papers Summary 016 ,82
258,258,What model to create a sentence generator?,"Hello,
I'm new to this field.
What model would you recommend for creating single sentences? I'm looking for something a bit more advanced than a markov chain. I would like to have it choose a random word using a word probability distribution, and then give probability distributions for generating the next and previous words, repeating this until the start and end of a sentence.",https://www.reddit.com/r/LanguageTechnology/comments/n2quai/what_model_to_create_a_sentence_generator/,LanguageTechnology,t3_n2quai,"What model to create a sentence generator? Hello,
I'm new to this field.
What model would you recommend for creating single sentences? I'm looking for something a bit more advanced than a markov chain. I would like to have it choose a random word using a word probability distribution, and then give probability distributions for generating the next and previous words, repeating this until the start and end of a sentence.",423
259,259,"Clinical Natural Language Processing – Challenges, Tasks and Datasets #NLProc",,https://youtu.be/yrN8VqkCWWc,LanguageTechnology,t3_n2dl4b,"Clinical Natural Language Processing – Challenges, Tasks and Datasets #NLProc ",78
260,260,Advice on a clustering algorithm for a corpus of order forms that will sort documents into 'document' types without knowing how many different kinds there are.,"I have a collection of order forms from different manufacturers. Each manufacturer will generally use the same standardized order form but there is some variance where for whatever reason, a manufacturer might have 5-6 different order forms that they use.

Since each document contains a ton of legal language, I need to create a specific pipeline for each order form type, but I don't know how many different types there are in my corpus to begin with.

Can someone recommend a clustering algorithm to that I can use to figure out all the different document ""types"" that are in the corpus?

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/n26mty/advice_on_a_clustering_algorithm_for_a_corpus_of/,LanguageTechnology,t3_n26mty,"Advice on a clustering algorithm for a corpus of order forms that will sort documents into 'document' types without knowing how many different kinds there are. I have a collection of order forms from different manufacturers. Each manufacturer will generally use the same standardized order form but there is some variance where for whatever reason, a manufacturer might have 5-6 different order forms that they use.

Since each document contains a ton of legal language, I need to create a specific pipeline for each order form type, but I don't know how many different types there are in my corpus to begin with.

Can someone recommend a clustering algorithm to that I can use to figure out all the different document ""types"" that are in the corpus?

Thanks!",759
261,261,topic modeling over many subreddits,"Hello everyone,

As part of my dissertation, I want to examine the general question of ""What do people talk about on stock market-related subreddits?"" To this end, I have identified around 200 subreddits that I would like to examine, and I plan to examine both the posts and comments to these subreddits. I am trying to decide the best and most efficient way of extracting the content of thesis subreddit discussions.

Some features of the data that I think are relevant to my decision:

1. Some subreddits are naturally focused around a certain topic or set of topics (e.g., r/technicalanalysis or r/thcinvesting) while others are more general (e.g., r/StockMarket).
2. The size of the subreddits (i.e., # of posts and comments) varies dramatically (e.g., r/wallstreetbets with millions of members vs r/stockanalysis with a couple of hundred members).
3. The size of my dataset is going to be extremely large (unsure of exact size yet, but just r/wallstreetbets is a large amount of data).

&amp;#x200B;

A couple of options that I am considering include LDA, author-topic LDA (with ""author"" being the subreddit) ([https://radimrehurek.com/gensim/models/atmodel.html](https://radimrehurek.com/gensim/models/atmodel.html)), and BERTopic ([https://github.com/MaartenGr/BERTopic](https://github.com/MaartenGr/BERTopic)).

I am also wondering whether I should manually group subreddits by category (e.g., technical analysis subreddits, fundamental analysis subreddits, penny stock subreddits, general subreddits, etc.) first and then run topic analysis separately for each group?

Any and all thoughts are greatly appreciated, and I am definitely open to hearing about alternative approaches or concerns that I haven't discussed. I am trying to weigh the pros and cons of each approach to make sure that my methodology is not obviously sub-optimal to some alternative.

Thanks in advance!",https://www.reddit.com/r/LanguageTechnology/comments/n1x8vo/topic_modeling_over_many_subreddits/,LanguageTechnology,t3_n1x8vo,"topic modeling over many subreddits Hello everyone,

As part of my dissertation, I want to examine the general question of ""What do people talk about on stock market-related subreddits?"" To this end, I have identified around 200 subreddits that I would like to examine, and I plan to examine both the posts and comments to these subreddits. I am trying to decide the best and most efficient way of extracting the content of thesis subreddit discussions.

Some features of the data that I think are relevant to my decision:

1. Some subreddits are naturally focused around a certain topic or set of topics (e.g., r/technicalanalysis or r/thcinvesting) while others are more general (e.g., r/StockMarket).
2. The size of the subreddits (i.e., # of posts and comments) varies dramatically (e.g., r/wallstreetbets with millions of members vs r/stockanalysis with a couple of hundred members).
3. The size of my dataset is going to be extremely large (unsure of exact size yet, but just r/wallstreetbets is a large amount of data).

&amp;#x200B;

A couple of options that I am considering include LDA, author-topic LDA (with ""author"" being the subreddit) ([https://radimrehurek.com/gensim/models/atmodel.html](https://radimrehurek.com/gensim/models/atmodel.html)), and BERTopic ([https://github.com/MaartenGr/BERTopic](https://github.com/MaartenGr/BERTopic)).

I am also wondering whether I should manually group subreddits by category (e.g., technical analysis subreddits, fundamental analysis subreddits, penny stock subreddits, general subreddits, etc.) first and then run topic analysis separately for each group?

Any and all thoughts are greatly appreciated, and I am definitely open to hearing about alternative approaches or concerns that I haven't discussed. I am trying to weigh the pros and cons of each approach to make sure that my methodology is not obviously sub-optimal to some alternative.

Thanks in advance!",1921
262,262,Stanford's Chirpy Cardinal,"Hi Everybody, 

Wondering if anyone has experience with Stanford's NLP project Chirpy Cardinal. Looking to find a freelance consultant that has experience with Chirpy architecture. Any suggestions on where I might find some good leads?

Thank you.",https://www.reddit.com/r/LanguageTechnology/comments/n1yt21/stanfords_chirpy_cardinal/,LanguageTechnology,t3_n1yt21,"Stanford's Chirpy Cardinal Hi Everybody, 

Wondering if anyone has experience with Stanford's NLP project Chirpy Cardinal. Looking to find a freelance consultant that has experience with Chirpy architecture. Any suggestions on where I might find some good leads?

Thank you.",274
263,263,Concerns about studying NLP,"I asked you guys about the opinion of choosing which domain to 

choose between NLP and CV few weeks ago.

&amp;#x200B;

I finally decided to study NLP area more deeply.

&amp;#x200B;

But I have concerns. It is really difficult to get accepted in 

NLP Labs and artificial intelligence graduate school.

&amp;#x200B;

So I made two plans if I failed to have master degree in graduate school.

&amp;#x200B;

Plan A

Studying NLP in data science graduate school

This plan have risk; there are no lab in this graduate school 

so I have to study NLP by myself.

&amp;#x200B;

Plan B

Studying CL(Computational Linguistics) in language graduate school

Also this plan have risk; the same reason with Plan A

&amp;#x200B;

There are not that many NLP labs in Korea, so I wonder if I go to

plan A and B, I can work in NLP field.

&amp;#x200B;

The best way is to read articles published by data and language graduate school, 

and NLP lab in AI graduate school and compare it, but the sad thing is

I don't have enough time left to contact labs and graduate schools above.

&amp;#x200B;

I guess that there are some people who graduated those graduate school 

that I mentioned, or at least worked with the people who went to Plan A and Plan B.

&amp;#x200B;

I am looking forward to have any advice from you guys.

I appreciate to the people who gave me advice last time when I asked about

the prospective domain to choose.

&amp;#x200B;

Thank you for reading my post and wish you guys all have good days today !",https://www.reddit.com/r/LanguageTechnology/comments/n1x2c6/concerns_about_studying_nlp/,LanguageTechnology,t3_n1x2c6,"Concerns about studying NLP I asked you guys about the opinion of choosing which domain to 

choose between NLP and CV few weeks ago.

&amp;#x200B;

I finally decided to study NLP area more deeply.

&amp;#x200B;

But I have concerns. It is really difficult to get accepted in 

NLP Labs and artificial intelligence graduate school.

&amp;#x200B;

So I made two plans if I failed to have master degree in graduate school.

&amp;#x200B;

Plan A

Studying NLP in data science graduate school

This plan have risk; there are no lab in this graduate school 

so I have to study NLP by myself.

&amp;#x200B;

Plan B

Studying CL(Computational Linguistics) in language graduate school

Also this plan have risk; the same reason with Plan A

&amp;#x200B;

There are not that many NLP labs in Korea, so I wonder if I go to

plan A and B, I can work in NLP field.

&amp;#x200B;

The best way is to read articles published by data and language graduate school, 

and NLP lab in AI graduate school and compare it, but the sad thing is

I don't have enough time left to contact labs and graduate schools above.

&amp;#x200B;

I guess that there are some people who graduated those graduate school 

that I mentioned, or at least worked with the people who went to Plan A and Plan B.

&amp;#x200B;

I am looking forward to have any advice from you guys.

I appreciate to the people who gave me advice last time when I asked about

the prospective domain to choose.

&amp;#x200B;

Thank you for reading my post and wish you guys all have good days today !",1540
264,264,Master’s Thesis in Computational Phonology,"Hey NLPeople,

&amp;#x200B;

at the end of the year, I’m planning on writing my Master’s Thesis. My Master’s program is a combination of Computational Linguistics and Cognitive Science. I already know that I want to focus on the broad area of computational phonology.

Because we live in a productivity-driven dystopia apparently I’m already thinking about what would look good on my CV which I will embroider with the topic I will have spent a lot of time working on.

&amp;#x200B;

Do you guys have any general ideas for open research topics in phonologically driven speech recognition for example? Or would you nudge me towards literature in that field that comes to mind?

&amp;#x200B;

I’m really only looking for general inspiration right now.

&amp;#x200B;

Thanks a lot!",https://www.reddit.com/r/LanguageTechnology/comments/n1yw5t/masters_thesis_in_computational_phonology/,LanguageTechnology,t3_n1yw5t,"Master’s Thesis in Computational Phonology Hey NLPeople,

&amp;#x200B;

at the end of the year, I’m planning on writing my Master’s Thesis. My Master’s program is a combination of Computational Linguistics and Cognitive Science. I already know that I want to focus on the broad area of computational phonology.

Because we live in a productivity-driven dystopia apparently I’m already thinking about what would look good on my CV which I will embroider with the topic I will have spent a lot of time working on.

&amp;#x200B;

Do you guys have any general ideas for open research topics in phonologically driven speech recognition for example? Or would you nudge me towards literature in that field that comes to mind?

&amp;#x200B;

I’m really only looking for general inspiration right now.

&amp;#x200B;

Thanks a lot!",821
265,265,Extracting term definitions from research papers,"Say I have a research paper (or papers) and I want to see how they  define a common term. For example, the papers might be on the topic of ""engagement"" and have definitions for the term they use in the paper. I was wondering if it would be possible to extract those definitions given the tools of NLP.

From some light research this seems to be a ""Terminology extraction"" problem. There are some papers on the topic, but my problem seems easier than that. I already know what to look for (e.g., the term ""engagement""), I just want to capture a definition of that from a text.

An idea I had was to search the text for the term I'm looking for (e.g., engagement) and then capture the text around it for further processing; For example, a sentence or two near the ""engagement"" term. But it's the additional processing I'm not sure about.

Any ideas? Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/n1h5px/extracting_term_definitions_from_research_papers/,LanguageTechnology,t3_n1h5px,"Extracting term definitions from research papers Say I have a research paper (or papers) and I want to see how they  define a common term. For example, the papers might be on the topic of ""engagement"" and have definitions for the term they use in the paper. I was wondering if it would be possible to extract those definitions given the tools of NLP.

From some light research this seems to be a ""Terminology extraction"" problem. There are some papers on the topic, but my problem seems easier than that. I already know what to look for (e.g., the term ""engagement""), I just want to capture a definition of that from a text.

An idea I had was to search the text for the term I'm looking for (e.g., engagement) and then capture the text around it for further processing; For example, a sentence or two near the ""engagement"" term. But it's the additional processing I'm not sure about.

Any ideas? Thanks.",904
266,266,Sentiment analysis of long text,"How do you deal with large text when using sentiment analysis? Even if SA is often used to analyze small pieces of text like tweets and reviews, it's often complex to encode a sentence because negative and positive phrases modify each other and end up to modify the overall sentiment of the review. This is even more true when dealing with texts made out of multiple sentences. A reasonable way to handle that would be to analyze the sentiment of each sentence and then get the average score for that text. Are there better ways to improve the accuracy of our analysis with large texts?
I found an article of Shocher and colleagues where they classify sentiment phrase-by-phrase  rather than on the sentence level. 

This is the paper
https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf",https://www.reddit.com/r/LanguageTechnology/comments/n1gkh4/sentiment_analysis_of_long_text/,LanguageTechnology,t3_n1gkh4,"Sentiment analysis of long text How do you deal with large text when using sentiment analysis? Even if SA is often used to analyze small pieces of text like tweets and reviews, it's often complex to encode a sentence because negative and positive phrases modify each other and end up to modify the overall sentiment of the review. This is even more true when dealing with texts made out of multiple sentences. A reasonable way to handle that would be to analyze the sentiment of each sentence and then get the average score for that text. Are there better ways to improve the accuracy of our analysis with large texts?
I found an article of Shocher and colleagues where they classify sentiment phrase-by-phrase  rather than on the sentence level. 

This is the paper
https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf",819
267,267,Parallelization for Author-topic models (atmodel) in Gensim,"While LDA in Gensim supports both multiprocessing and distributed computation, the author-topic model implementation does not at the moment. Much of the infrastructure that allows both multiprocessing and distributed computation should however already be in place (class models.ldamulticore), as the model inherits it from LDA. Therefore, I was asking myself if these functionalities could be enabled also for atmodel without major issues",https://www.reddit.com/r/LanguageTechnology/comments/n17myt/parallelization_for_authortopic_models_atmodel_in/,LanguageTechnology,t3_n17myt,"Parallelization for Author-topic models (atmodel) in Gensim While LDA in Gensim supports both multiprocessing and distributed computation, the author-topic model implementation does not at the moment. Much of the infrastructure that allows both multiprocessing and distributed computation should however already be in place (class models.ldamulticore), as the model inherits it from LDA. Therefore, I was asking myself if these functionalities could be enabled also for atmodel without major issues",498
268,268,Best evaluation metrics for the BERT model,"My dataset is a little unbalanced:

    smile        4852 
    kind         2027 
    angry        1926 
    surprised     979 
    sad           698 

pretty same for the validation and test sets. My goal was to predict the emotion of user tweets, which I already did, however now I am wondering what are the best evaluation metrics for this type of problem?

My initial metrics score is as following

    {""train"": {""eval_examples_count"": 10481, ""metrics"": {""f1_weighted"": 0.8869, ""f1_macro"": 0.8401, ""accuracy"": 0.8884, ""roc_auc"": 0.9686}, ""time_spent"": ""1:27:10""}} {""valid"": {""eval_examples_count"": 3493, ""metrics"": {""f1_weighted"": 0.6112, ""f1_macro"": 0.5257, ""accuracy"": 0.6184, ""roc_auc"": 0.8177}, ""time_spent"": ""0:28:37""}} {""test"": {""eval_examples_count"": 3494, ""metrics"": {""f1_weighted"": 0.6191, ""f1_macro"": 0.5282, ""accuracy"": 0.6259, ""roc_auc"": 0.8271}, ""time_spent"": ""0:28:26""}} 

I am pretty new to ML and NLP in general so I am kinda confused. I have several questions here:

1. Why train f1\_macro is so high but valid and test sets are not that high? How to interpret it?
2. How to interpret the above result in general?
3. I've seen someone using Matthews Correlation Coefficient for the kinda similar task, but I heard that is only for the binary class problem, How can i use it for the multiclass problem?
4. How valuable roc\_auc information in a multi-class classification problem?

In general, even though metrics above are kinda giving me not really result, but i ve been testing the model manually and it just work pretty good.",https://www.reddit.com/r/LanguageTechnology/comments/n0yido/best_evaluation_metrics_for_the_bert_model/,LanguageTechnology,t3_n0yido,"Best evaluation metrics for the BERT model My dataset is a little unbalanced:

    smile        4852 
    kind         2027 
    angry        1926 
    surprised     979 
    sad           698 

pretty same for the validation and test sets. My goal was to predict the emotion of user tweets, which I already did, however now I am wondering what are the best evaluation metrics for this type of problem?

My initial metrics score is as following

    {""train"": {""eval_examples_count"": 10481, ""metrics"": {""f1_weighted"": 0.8869, ""f1_macro"": 0.8401, ""accuracy"": 0.8884, ""roc_auc"": 0.9686}, ""time_spent"": ""1:27:10""}} {""valid"": {""eval_examples_count"": 3493, ""metrics"": {""f1_weighted"": 0.6112, ""f1_macro"": 0.5257, ""accuracy"": 0.6184, ""roc_auc"": 0.8177}, ""time_spent"": ""0:28:37""}} {""test"": {""eval_examples_count"": 3494, ""metrics"": {""f1_weighted"": 0.6191, ""f1_macro"": 0.5282, ""accuracy"": 0.6259, ""roc_auc"": 0.8271}, ""time_spent"": ""0:28:26""}} 

I am pretty new to ML and NLP in general so I am kinda confused. I have several questions here:

1. Why train f1\_macro is so high but valid and test sets are not that high? How to interpret it?
2. How to interpret the above result in general?
3. I've seen someone using Matthews Correlation Coefficient for the kinda similar task, but I heard that is only for the binary class problem, How can i use it for the multiclass problem?
4. How valuable roc\_auc information in a multi-class classification problem?

In general, even though metrics above are kinda giving me not really result, but i ve been testing the model manually and it just work pretty good.",1593
269,269,What are some easy research topics for beginners related to nlp?,I am supposed to be doing a research paper(my first time) and thought nlp related topics would be good. Can you suggest some easy to understand research papers that I can refer to understand how this research paper thing actually works?,https://www.reddit.com/r/LanguageTechnology/comments/n1103z/what_are_some_easy_research_topics_for_beginners/,LanguageTechnology,t3_n1103z,What are some easy research topics for beginners related to nlp? I am supposed to be doing a research paper(my first time) and thought nlp related topics would be good. Can you suggest some easy to understand research papers that I can refer to understand how this research paper thing actually works?,301
270,270,Training a model on an entire dataset by dividing the dataset into chunks &amp; loading the model back again untill all chunks of the dataset are trained,"I am working on the **CUAD**(Contract Understanding Atticus Dataset) which is a Q&amp;A based dataset. But training 80% of the dataset in one go is impossible due to resource constraints. I am using the boilerplate code provided by HuggingFace Transformer docs for Q&amp;A task [here](https://huggingface.co/transformers/examples.html). My hands are tied with Google Colab Pro. So, it's not possible for me to use multiple GPU's in training the dataset. Inspite of using the hyperparameters below, I'm unable to avoid errors due to memory constraints like ""CUDA out of Memory"" etc.

```
args = TrainingArguments(
    'cuad-roberta',
    evaluation_strategy = ""epoch"",
    learning_rate=3e-5,
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    num_train_epochs=2,
    weight_decay=0.01,
    save_steps=5000,
    logging_steps=5000,
    save_total_limit=100,
    gradient_accumulation_steps = 12,
    eval_accumulation_steps = 4,
)
```
Under these circumstances, I have divided my training set(80%) into 4 parts with each part holding 25% data. So, using any Q&amp;A supported pretrained model from Transformers, I've trained the first 25% of the training data and then saved the model in a directory of my drive. Then, I have loaded that tokenizer and model from the saved directory and trained the next 25% of my training data on the same model as shown below. 

```
tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/models/cuad-25%-roberta-base')
model = AutoModelForQuestionAnswering.from_pretrained('/content/drive/MyDrive/models/cuad-25%-roberta-base')
```

I repeated the step two more times to complete training the model on the entire training data.

Now, my question is that, **Is this approach correct in terms of training a model when I have resource constraints? If it is correct, will this approach hurt the performance of my model?** I'm relatively new to ML and NLP so please kindly consider any silly mistakes.

Also, any sources for understanding, visualising or implementing the Q&amp;A task through HuggingFace Transformers would be really helpful.",https://www.reddit.com/r/LanguageTechnology/comments/n0xasz/training_a_model_on_an_entire_dataset_by_dividing/,LanguageTechnology,t3_n0xasz,"Training a model on an entire dataset by dividing the dataset into chunks &amp; loading the model back again untill all chunks of the dataset are trained I am working on the **CUAD**(Contract Understanding Atticus Dataset) which is a Q&amp;A based dataset. But training 80% of the dataset in one go is impossible due to resource constraints. I am using the boilerplate code provided by HuggingFace Transformer docs for Q&amp;A task [here](https://huggingface.co/transformers/examples.html). My hands are tied with Google Colab Pro. So, it's not possible for me to use multiple GPU's in training the dataset. Inspite of using the hyperparameters below, I'm unable to avoid errors due to memory constraints like ""CUDA out of Memory"" etc.

```
args = TrainingArguments(
    'cuad-roberta',
    evaluation_strategy = ""epoch"",
    learning_rate=3e-5,
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    num_train_epochs=2,
    weight_decay=0.01,
    save_steps=5000,
    logging_steps=5000,
    save_total_limit=100,
    gradient_accumulation_steps = 12,
    eval_accumulation_steps = 4,
)
```
Under these circumstances, I have divided my training set(80%) into 4 parts with each part holding 25% data. So, using any Q&amp;A supported pretrained model from Transformers, I've trained the first 25% of the training data and then saved the model in a directory of my drive. Then, I have loaded that tokenizer and model from the saved directory and trained the next 25% of my training data on the same model as shown below. 

```
tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/models/cuad-25%-roberta-base')
model = AutoModelForQuestionAnswering.from_pretrained('/content/drive/MyDrive/models/cuad-25%-roberta-base')
```

I repeated the step two more times to complete training the model on the entire training data.

Now, my question is that, **Is this approach correct in terms of training a model when I have resource constraints? If it is correct, will this approach hurt the performance of my model?** I'm relatively new to ML and NLP so please kindly consider any silly mistakes.

Also, any sources for understanding, visualising or implementing the Q&amp;A task through HuggingFace Transformers would be really helpful.",2258
271,271,A model to evaluate audio clips similarly,"Dear all, I'm relatively new to NLP and ML. Currently I'm working on projects in which I have to compare and score two audio clips. Original clip (single sentence) will be from movie character (animated or real) and in second clip human will try to mimic it. I have to come up with my model to determine similarly and score human clip out of 5.
Factors which I have considered to be used are:
1. Getting sentence from speech and comparing with original
2. Evaluating similarly from audio spectrogram (spectral centroid and zero crossing rate)
3. Identification of emotion from speech and using emotions embedding (assuming it's available on internet) to measure similarly (will probably use cosine similarly)
I couldn't come up with more factors. Can you please help me come up with new comparison factors or suggest how can I approach this problem in better way?
Thanking you in anticipation...",https://www.reddit.com/r/LanguageTechnology/comments/n0x12t/a_model_to_evaluate_audio_clips_similarly/,LanguageTechnology,t3_n0x12t,"A model to evaluate audio clips similarly Dear all, I'm relatively new to NLP and ML. Currently I'm working on projects in which I have to compare and score two audio clips. Original clip (single sentence) will be from movie character (animated or real) and in second clip human will try to mimic it. I have to come up with my model to determine similarly and score human clip out of 5.
Factors which I have considered to be used are:
1. Getting sentence from speech and comparing with original
2. Evaluating similarly from audio spectrogram (spectral centroid and zero crossing rate)
3. Identification of emotion from speech and using emotions embedding (assuming it's available on internet) to measure similarly (will probably use cosine similarly)
I couldn't come up with more factors. Can you please help me come up with new comparison factors or suggest how can I approach this problem in better way?
Thanking you in anticipation...",937
272,272,Looking for Datasets on Meronyms and Hypernyms - Full sentences,"Hi everyone, 

I am in the hunt for open-domain datasets on Meronyms and Hypernyms. There are a few available online, but so far I've found only sets of entity pairs and **my research requires full sentences.** 

Any suggestion on where to search for datasets like this will be very much appreciated. Also if you happen to have one, please Dm me!

Thanks",https://www.reddit.com/r/LanguageTechnology/comments/n0ntyi/looking_for_datasets_on_meronyms_and_hypernyms/,LanguageTechnology,t3_n0ntyi,"Looking for Datasets on Meronyms and Hypernyms - Full sentences Hi everyone, 

I am in the hunt for open-domain datasets on Meronyms and Hypernyms. There are a few available online, but so far I've found only sets of entity pairs and **my research requires full sentences.** 

Any suggestion on where to search for datasets like this will be very much appreciated. Also if you happen to have one, please Dm me!

Thanks",418
273,273,Call for Teachable NLP Challenge,"Hi NLP lovers,

I found this exciting Teachable NLP Challenge! Is there anyone who wants to participate with me?

Teachable NLP Challenge is free and open to everyone interested in training their own AI without coding! All you need to be prepared for is good ideas and datasets.

* When: 05/05/2021 - 05/18/2021 11:59 EDT
* How: You just need to submit your AI model link and explanations on your AI (Good example: [https://forum.ainetwork.ai/c/ai-showcase/11](https://forum.ainetwork.ai/c/ai-showcase/11))
* Prizes: Apple Store gift cards, Winners' interviews will be broadcasted through AI Network Youtube Channel(1.48K subscribers)

To participate, submit your info via [https://forms.gle/XfUuNSS2heAn7JtH7](https://forms.gle/XfUuNSS2heAn7JtH7). You will receive an invitation email!

Check how Teachable NLP works: [https://forum.ainetwork.ai/t/teachable-nlp-how-to-use-teachable-nlp/65](https://forum.ainetwork.ai/t/teachable-nlp-how-to-use-teachable-nlp/65)Or watch a 1-minute tutorial video: [https://youtu.be/hzujZOT1qz8](https://youtu.be/hzujZOT1qz8)",https://www.reddit.com/r/LanguageTechnology/comments/n0fzcb/call_for_teachable_nlp_challenge/,LanguageTechnology,t3_n0fzcb,"Call for Teachable NLP Challenge Hi NLP lovers,

I found this exciting Teachable NLP Challenge! Is there anyone who wants to participate with me?

Teachable NLP Challenge is free and open to everyone interested in training their own AI without coding! All you need to be prepared for is good ideas and datasets.

* When: 05/05/2021 - 05/18/2021 11:59 EDT
* How: You just need to submit your AI model link and explanations on your AI (Good example: [https://forum.ainetwork.ai/c/ai-showcase/11](https://forum.ainetwork.ai/c/ai-showcase/11))
* Prizes: Apple Store gift cards, Winners' interviews will be broadcasted through AI Network Youtube Channel(1.48K subscribers)

To participate, submit your info via [https://forms.gle/XfUuNSS2heAn7JtH7](https://forms.gle/XfUuNSS2heAn7JtH7). You will receive an invitation email!

Check how Teachable NLP works: [https://forum.ainetwork.ai/t/teachable-nlp-how-to-use-teachable-nlp/65](https://forum.ainetwork.ai/t/teachable-nlp-how-to-use-teachable-nlp/65)Or watch a 1-minute tutorial video: [https://youtu.be/hzujZOT1qz8](https://youtu.be/hzujZOT1qz8)",1092
274,274,Classification dimension mismatch,"I’m building a classifier to predict whether or not a mechanical part is or is not automotive based on its description using a training dataset of approx. 13k labeled data points. After preprocessing, vectorizing, and TF-IDF the array is (12,918, 16,230). 

After training, I tried predicting on a new dataset of 173 descriptions. After preprocessing, vectorizing, and TF-IDF the new data array is (173, 492) and I’m getting a “dimension mismatch” error when passing it through my models’ predict function. 

Can anyone help with how to get the new unlabeled test data shaped to fit the training data?",https://www.reddit.com/r/LanguageTechnology/comments/n0lrrl/classification_dimension_mismatch/,LanguageTechnology,t3_n0lrrl,"Classification dimension mismatch I’m building a classifier to predict whether or not a mechanical part is or is not automotive based on its description using a training dataset of approx. 13k labeled data points. After preprocessing, vectorizing, and TF-IDF the array is (12,918, 16,230). 

After training, I tried predicting on a new dataset of 173 descriptions. After preprocessing, vectorizing, and TF-IDF the new data array is (173, 492) and I’m getting a “dimension mismatch” error when passing it through my models’ predict function. 

Can anyone help with how to get the new unlabeled test data shaped to fit the training data?",635
275,275,3 Things I Learned About SPACs Using Knowledge Graphs,,https://medium.com/kgbase-blog/3-things-i-learned-about-spacs-using-knowledge-graphs-2ad0a7c12cf9,LanguageTechnology,t3_n0fx7y,3 Things I Learned About SPACs Using Knowledge Graphs ,54
276,276,[D] metrics for measuring similarity of word vectors between different models,"Hi!

I have 2 separately trained word2vec models. I want to be able to compare the same word in both models and see how they relate to each other and their surroundings through a metric. Now of course, I can't use the cosine similarity as the word vectors are completely different. I also want to avoid using the `wv.most_similar()` method as I would like to effectively capture the similarity of the same word in both models through some kind of metric if it were possible (as if i were using the cosine similarity between 2 words in the same model), but i am not sure of any that may exist! 

Does anybody know of any such metrics or ways of comparing two word vectors like this?

thank you!",https://www.reddit.com/r/LanguageTechnology/comments/n0h695/d_metrics_for_measuring_similarity_of_word/,LanguageTechnology,t3_n0h695,"[D] metrics for measuring similarity of word vectors between different models Hi!

I have 2 separately trained word2vec models. I want to be able to compare the same word in both models and see how they relate to each other and their surroundings through a metric. Now of course, I can't use the cosine similarity as the word vectors are completely different. I also want to avoid using the `wv.most_similar()` method as I would like to effectively capture the similarity of the same word in both models through some kind of metric if it were possible (as if i were using the cosine similarity between 2 words in the same model), but i am not sure of any that may exist! 

Does anybody know of any such metrics or ways of comparing two word vectors like this?

thank you!",771
277,277,Chai - Build your own chat AI in 10 minutes,"Wanted to introduce [chai](https://chai.ml) to y'all - it's a free, open-source platform for developers to build and deploy their own chat AIs. Currently over 100 AIs are hosted on the platform, which has over 12,000 conversations 😱

Following the tutorials at [https://chai.ml/docs](https://chai.ml/docs) you can deploy your own in under 10 minutes. I think this is such a cool way to learn NLP and it's really fun seeing your score go up on the [developer platform](https://chai.ml/dev).",https://www.reddit.com/r/LanguageTechnology/comments/n08m10/chai_build_your_own_chat_ai_in_10_minutes/,LanguageTechnology,t3_n08m10,"Chai - Build your own chat AI in 10 minutes Wanted to introduce [chai](https://chai.ml) to y'all - it's a free, open-source platform for developers to build and deploy their own chat AIs. Currently over 100 AIs are hosted on the platform, which has over 12,000 conversations 😱

Following the tutorials at [https://chai.ml/docs](https://chai.ml/docs) you can deploy your own in under 10 minutes. I think this is such a cool way to learn NLP and it's really fun seeing your score go up on the [developer platform](https://chai.ml/dev).",533
278,278,Does anyone have any suggestions for determining sentiment associated with key words in online reviews? Pls help,"Hi guys, 

I’m working on a student assignment that essentially involves determining whether the sentiment is good/bad for certain keywords.

For example if a review is: 

‘I love the facilities and staff here, however the bathrooms were dirty.’

I need to be able to determine that the facilities and staff were positive and the cleanliness was negative. 

Does anyone have any suggestions for how to go about this? 

Relatively new to NLP!!!",https://www.reddit.com/r/LanguageTechnology/comments/n0e2wq/does_anyone_have_any_suggestions_for_determining/,LanguageTechnology,t3_n0e2wq,"Does anyone have any suggestions for determining sentiment associated with key words in online reviews? Pls help Hi guys, 

I’m working on a student assignment that essentially involves determining whether the sentiment is good/bad for certain keywords.

For example if a review is: 

‘I love the facilities and staff here, however the bathrooms were dirty.’

I need to be able to determine that the facilities and staff were positive and the cleanliness was negative. 

Does anyone have any suggestions for how to go about this? 

Relatively new to NLP!!!",556
279,279,"The NLP Index: 3,000+ code repos for hackers and researchers. [self-promotion]","Want to introduce “The NLP Index”, a new asset in NLP code discovery. It's free and open to the public.

It houses over 3,000 code repositories that one can search including a side bar with some of the most important topics in NLP today. The engine is search as you type and typo tolerant (it’s crazy fast). The index includes the arxiv research paper PDF, ConnectedPapers link, and its GitHub repo.

[https://index.quantumstat.com/](https://index.quantumstat.com/)",https://www.reddit.com/r/LanguageTechnology/comments/mzosly/the_nlp_index_3000_code_repos_for_hackers_and/,LanguageTechnology,t3_mzosly,"The NLP Index: 3,000+ code repos for hackers and researchers. [self-promotion] Want to introduce “The NLP Index”, a new asset in NLP code discovery. It's free and open to the public.

It houses over 3,000 code repositories that one can search including a side bar with some of the most important topics in NLP today. The engine is search as you type and typo tolerant (it’s crazy fast). The index includes the arxiv research paper PDF, ConnectedPapers link, and its GitHub repo.

[https://index.quantumstat.com/](https://index.quantumstat.com/)",544
280,280,Facebook's Internal Report About Its Role In The Capitol Insurrection -- Interested in Thoughts about the analysts' approach to text analytics as an adjunct to their social network and time analytics,,https://www.buzzfeednews.com/article/ryanmac/full-facebook-stop-the-steal-internal-report,LanguageTechnology,t3_mzn432,Facebook's Internal Report About Its Role In The Capitol Insurrection -- Interested in Thoughts about the analysts' approach to text analytics as an adjunct to their social network and time analytics ,200
281,281,Reading material for Topic Modelling,As the title suggests I'm looking for some reading material (or videos) on Topic Modelling (esp. Hierarchical Topic Modelling). My aim is to understand the concept.,https://www.reddit.com/r/LanguageTechnology/comments/mzk8y4/reading_material_for_topic_modelling/,LanguageTechnology,t3_mzk8y4,Reading material for Topic Modelling As the title suggests I'm looking for some reading material (or videos) on Topic Modelling (esp. Hierarchical Topic Modelling). My aim is to understand the concept.,201
282,282,"I added translation models to the NLPCloud.io API, based on Helsinki NLP's Opus MT","Hello!

Many users were asking me to add transformer-based translation models to the [NLPCloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=f80a8332-aaaf-11eb-bcbc-0242ac130002)'s API. So I added the 12 following NLP models based on Hugging Face transformers and Helsinki NLP's Opus MT:

* English to French
* French to English
* English to Spanish
* Spanish to English
* English to German
* German to English
* English to Dutch
* Dutch to English
* English to Chinese
* Chinese to English
* English to Russian
* Russian to English

I personally find the accuracy of these translation models very good, and the latency is pretty good too. Here's the link to the docs: [https://docs.nlpcloud.io/#translation](https://docs.nlpcloud.io/#translation)

**I would LOVE to have your opinion on this guys!**  Do you think that quality is good enough for  production use? Are there other languages you would like to see?

If you want to have a try, the API is free for up to 3 requests per minute, but if it's not enough please don't hesitate to ping me so I can grant you more requests.

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/mzqdgi/i_added_translation_models_to_the_nlpcloudio_api/,LanguageTechnology,t3_mzqdgi,"I added translation models to the NLPCloud.io API, based on Helsinki NLP's Opus MT Hello!

Many users were asking me to add transformer-based translation models to the [NLPCloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=f80a8332-aaaf-11eb-bcbc-0242ac130002)'s API. So I added the 12 following NLP models based on Hugging Face transformers and Helsinki NLP's Opus MT:

* English to French
* French to English
* English to Spanish
* Spanish to English
* English to German
* German to English
* English to Dutch
* Dutch to English
* English to Chinese
* Chinese to English
* English to Russian
* Russian to English

I personally find the accuracy of these translation models very good, and the latency is pretty good too. Here's the link to the docs: [https://docs.nlpcloud.io/#translation](https://docs.nlpcloud.io/#translation)

**I would LOVE to have your opinion on this guys!**  Do you think that quality is good enough for  production use? Are there other languages you would like to see?

If you want to have a try, the API is free for up to 3 requests per minute, but if it's not enough please don't hesitate to ping me so I can grant you more requests.

Thanks!",1185
283,283,"I often help companies do branding, and I'm wanting to find words that are simple to hear, are there words that are unique and easy to hear?","I imagine in voice recognition training data there are simple nouns which you can hear clearly, and with no similar words?",https://www.reddit.com/r/LanguageTechnology/comments/mzybpa/i_often_help_companies_do_branding_and_im_wanting/,LanguageTechnology,t3_mzybpa,"I often help companies do branding, and I'm wanting to find words that are simple to hear, are there words that are unique and easy to hear? I imagine in voice recognition training data there are simple nouns which you can hear clearly, and with no similar words?",263
284,284,"If you can build AI chatbots, what kinds of chatbots do you want to build?","Hi everyone, I'm really interested in building chatbots. I'm wondering what kinds of chatbot people need. 

If you can build your own AI chatbots, what kinds of chatbots do you want to build? (e.g., BTS chatbot, the chatbot that brings your loved one back from the dead, and business chatbot, etc.) Why you need those chatbots?",https://www.reddit.com/r/LanguageTechnology/comments/mzoos1/if_you_can_build_ai_chatbots_what_kinds_of/,LanguageTechnology,t3_mzoos1,"If you can build AI chatbots, what kinds of chatbots do you want to build? Hi everyone, I'm really interested in building chatbots. I'm wondering what kinds of chatbot people need. 

If you can build your own AI chatbots, what kinds of chatbots do you want to build? (e.g., BTS chatbot, the chatbot that brings your loved one back from the dead, and business chatbot, etc.) Why you need those chatbots?",402
285,285,Gan-Bert for Topic modelling,Need suggestions to fine tune Gan-Bert model on mechanical design dataset. Any leads would be appreciated. I can share the detailed problem if you can suggest some insights.,https://www.reddit.com/r/LanguageTechnology/comments/mzm7kp/ganbert_for_topic_modelling/,LanguageTechnology,t3_mzm7kp,Gan-Bert for Topic modelling Need suggestions to fine tune Gan-Bert model on mechanical design dataset. Any leads would be appreciated. I can share the detailed problem if you can suggest some insights.,202
286,286,Speech Recognition Training Data Tools?,"I have an upcoming project that has a speech recognition component, but I'm pretty unfamiliar with the basics of this branch of NLP.

I suspect that I will need to create my own training dataset because the speech will involve a lot of niche terminology. From [what little I've seen on the tooling side](https://prodi.gy/docs/audio-video#transcribe), it looks like people segment audio into rough sentence equivalents, and then just type in a transcript to an input field. 

Is this best practice for creating speech recognition models? I would think you would need to provide word-level alignments to the audio, and that the models would be word level sequence models. But the training data tools seem mostly to facilitate capture of whole sentence transcripts.

Any help is appreciated",https://www.reddit.com/r/LanguageTechnology/comments/mzf2ee/speech_recognition_training_data_tools/,LanguageTechnology,t3_mzf2ee,"Speech Recognition Training Data Tools? I have an upcoming project that has a speech recognition component, but I'm pretty unfamiliar with the basics of this branch of NLP.

I suspect that I will need to create my own training dataset because the speech will involve a lot of niche terminology. From [what little I've seen on the tooling side](https://prodi.gy/docs/audio-video#transcribe), it looks like people segment audio into rough sentence equivalents, and then just type in a transcript to an input field. 

Is this best practice for creating speech recognition models? I would think you would need to provide word-level alignments to the audio, and that the models would be word level sequence models. But the training data tools seem mostly to facilitate capture of whole sentence transcripts.

Any help is appreciated",827
287,287,Into NLP - Text Normalization,,https://www.qualicen.de/into-nlp-4-normal-language-perfection-text-normalization/,LanguageTechnology,t3_myv82r,Into NLP - Text Normalization ,30
288,288,Biomedical datasets suggestions for fine tuning Bert variant models on three tasks,"As part of an internship, I have to build a biomedical knowledge graph from textual data, to do this I have to go through the tasks of named entity extraction and relation extraction as well as coreference resolution using BERT variant models. My problem is the availability of fine tune data for the three tasks.

Is there any open access datasets that I can use to fine tune my models in the three previous tasks in the biomedical domain?",https://www.reddit.com/r/LanguageTechnology/comments/mywo9c/biomedical_datasets_suggestions_for_fine_tuning/,LanguageTechnology,t3_mywo9c,"Biomedical datasets suggestions for fine tuning Bert variant models on three tasks As part of an internship, I have to build a biomedical knowledge graph from textual data, to do this I have to go through the tasks of named entity extraction and relation extraction as well as coreference resolution using BERT variant models. My problem is the availability of fine tune data for the three tasks.

Is there any open access datasets that I can use to fine tune my models in the three previous tasks in the biomedical domain?",523
289,289,What specific math subjects do I need to fully understand every NLP/Computational Linguistics journal article (espeically the most important ones)?,"Please state specific math subjects in the format used below (these are simply examples).

* Calculus 1

* Calculus 2

* Calculus 3

* Calculus 4

* Discrete Math

* Introduction to Probability

* Introduction to Statistics

* Statistical Inference

* Linear Algebra

Thank You",https://www.reddit.com/r/LanguageTechnology/comments/myqlea/what_specific_math_subjects_do_i_need_to_fully/,LanguageTechnology,t3_myqlea,"What specific math subjects do I need to fully understand every NLP/Computational Linguistics journal article (espeically the most important ones)? Please state specific math subjects in the format used below (these are simply examples).

* Calculus 1

* Calculus 2

* Calculus 3

* Calculus 4

* Discrete Math

* Introduction to Probability

* Introduction to Statistics

* Statistical Inference

* Linear Algebra

Thank You",425
290,290,Incorporating Text Data for a Sales Forecasting Model,"There's a dataset which has conversational data with customer &amp; sales persons &amp; I have to incorporate that data into a sales forecasting model. 

The conversational data is mainly in sentiment - related topics (For reference)

What NLP technique can be applied here to maybe get a feature out that can act as a dependent variable when I am predicting my final sales output?

PS. I have other variables that can help to predict sales, but I need to use the text data as well. How am  I supposed to move forward with this?",https://www.reddit.com/r/LanguageTechnology/comments/myqvhj/incorporating_text_data_for_a_sales_forecasting/,LanguageTechnology,t3_myqvhj,"Incorporating Text Data for a Sales Forecasting Model There's a dataset which has conversational data with customer &amp; sales persons &amp; I have to incorporate that data into a sales forecasting model. 

The conversational data is mainly in sentiment - related topics (For reference)

What NLP technique can be applied here to maybe get a feature out that can act as a dependent variable when I am predicting my final sales output?

PS. I have other variables that can help to predict sales, but I need to use the text data as well. How am  I supposed to move forward with this?",582
291,291,Any good tutorials for creating a semantic search engine?,I'm pretty new to NLP so I hope you can help me out. I have a file with \~700 paragraphs on a similar topic and I want to make a semantic search engine so that the user can input a query and it will return the paragraphs that match the closest. Thanks!,https://www.reddit.com/r/LanguageTechnology/comments/myk81n/any_good_tutorials_for_creating_a_semantic_search/,LanguageTechnology,t3_myk81n,Any good tutorials for creating a semantic search engine? I'm pretty new to NLP so I hope you can help me out. I have a file with \~700 paragraphs on a similar topic and I want to make a semantic search engine so that the user can input a query and it will return the paragraphs that match the closest. Thanks!,310
292,292,BERTweet (SOTA) for Named Entity Recognition in Social Media | Research Papers Summary 015,,https://youtu.be/npxjcPhFLKE,LanguageTechnology,t3_myf69x,BERTweet (SOTA) for Named Entity Recognition in Social Media | Research Papers Summary 015 ,91
293,293,Handling Multi-lingual text,"I was wondering whether there are models that can handle text input with two or more languages.

For instance, a multilingualBert can probably understand both English and Spanish:

`(en) This is a test for language model`

`(es)Esta es una prueba para el modelo de lenguaje`

But it fails in understanding the following :

`(en-es) This is a prueba for language modelo`

`(en-jp) This is a テスト for language モデル`

A text that has both English and Spanish or Japanese(where even the script is different than Latin).",https://www.reddit.com/r/LanguageTechnology/comments/my6w2t/handling_multilingual_text/,LanguageTechnology,t3_my6w2t,"Handling Multi-lingual text I was wondering whether there are models that can handle text input with two or more languages.

For instance, a multilingualBert can probably understand both English and Spanish:

`(en) This is a test for language model`

`(es)Esta es una prueba para el modelo de lenguaje`

But it fails in understanding the following :

`(en-es) This is a prueba for language modelo`

`(en-jp) This is a テスト for language モデル`

A text that has both English and Spanish or Japanese(where even the script is different than Latin).",541
294,294,Aspect-based Document Similarity for Research Papers (Research Paper Walkthrough),,https://youtu.be/ZO6QWG7-Ye0,LanguageTechnology,t3_my6c2k,Aspect-based Document Similarity for Research Papers (Research Paper Walkthrough) ,82
295,295,Government complaint dataset,"I'm building a open source government complaint redressal system. For the purpose of complaint classification (for routing the complaints to a department), I need a existing government complaint dataset. If anyone has come across any such datasets, please help by commenting.

It basically needs to have a complaint column and a column with department name to which the complaints belong",https://www.reddit.com/r/LanguageTechnology/comments/myc2ee/government_complaint_dataset/,LanguageTechnology,t3_myc2ee,"Government complaint dataset I'm building a open source government complaint redressal system. For the purpose of complaint classification (for routing the complaints to a department), I need a existing government complaint dataset. If anyone has come across any such datasets, please help by commenting.

It basically needs to have a complaint column and a column with department name to which the complaints belong",416
296,296,Feedback for NLP project," Hi all,

My  name is Kushel Ramanayake, and I am a current 4th undergraduate at  Informatics Institute of Technology affiliated with University of  Westminster UK. As part of my Final Year Thesis, I am required to gather some feedback on my project, from experts within the domain. The project I am working on is similar to an automatic question generation system, and main technology is NLP.

Ideally we'll get on a 1 on 1 zoom call (\~15 minutes), where I'd go over my project and you'd give me feedback on;

* The Scope
* The Architecture of the Solution
* The Implementation of the Solution

The data collected will only be used for my thesis and will be discarded with afterwards. No personal information other than maybe name and occupation will be collected. 

Thank you in advance,

Kushel Ramanayake",https://www.reddit.com/r/LanguageTechnology/comments/my41vc/feedback_for_nlp_project/,LanguageTechnology,t3_my41vc,"Feedback for NLP project  Hi all,

My  name is Kushel Ramanayake, and I am a current 4th undergraduate at  Informatics Institute of Technology affiliated with University of  Westminster UK. As part of my Final Year Thesis, I am required to gather some feedback on my project, from experts within the domain. The project I am working on is similar to an automatic question generation system, and main technology is NLP.

Ideally we'll get on a 1 on 1 zoom call (\~15 minutes), where I'd go over my project and you'd give me feedback on;

* The Scope
* The Architecture of the Solution
* The Implementation of the Solution

The data collected will only be used for my thesis and will be discarded with afterwards. No personal information other than maybe name and occupation will be collected. 

Thank you in advance,

Kushel Ramanayake",834
297,297,I fine-tuned a language model on left and right leaning political commentary on Reddit,"[https://preview.redd.it/t60n4t6z08v61.gif?format=mp4&amp;s=b3e2748ba96ec723266ee5c8e14bd49081cb6c57](https://preview.redd.it/t60n4t6z08v61.gif?format=mp4&amp;s=b3e2748ba96ec723266ee5c8e14bd49081cb6c57)

Information:  
For my dissertation project I fine-tuned a pre-trained language model on a self-mined dataset of ""left"" and ""right"" leaning subreddits to classify comments and subreddit's.

I mined the data over a few months using praw, I used a list of around 20-25 different subreddits taking between 10-20,000 comments from each from within the past year, so the model is quite American election biased but the model was fine tuned a few weeks ago so the comments you are seeing the gif it has not seen before.

I used DistilBert to fine-tune the model on pre-processed text, I spent a few months fine-tuning different models on different versions of the data set until I minimised overfitting and got a decent validation to training trade-off.

I also made a fun venn diagram tool to help find similar subreddits, I used this tool with a much larger sample size to help find similar leaning subreddits to help remove my personal bias although I am certain the left-wing subreddits tend to the far left more than the right which is why you may see a fair bit of negative biden commentary leading more left than right.

Disclaimer:  
The venn diagram tool and the subreddit classifier tool utilise praw which has a decent rate limit so may take 10-20 seconds before it returns a result, I have moved to psaw although loading times have not improved much.

View this project: [https://reddit-political-analysis.com/](https://reddit-political-analysis.com/)",https://www.reddit.com/r/LanguageTechnology/comments/mxxwlc/i_finetuned_a_language_model_on_left_and_right/,LanguageTechnology,t3_mxxwlc,"I fine-tuned a language model on left and right leaning political commentary on Reddit [https://preview.redd.it/t60n4t6z08v61.gif?format=mp4&amp;s=b3e2748ba96ec723266ee5c8e14bd49081cb6c57](https://preview.redd.it/t60n4t6z08v61.gif?format=mp4&amp;s=b3e2748ba96ec723266ee5c8e14bd49081cb6c57)

Information:  
For my dissertation project I fine-tuned a pre-trained language model on a self-mined dataset of ""left"" and ""right"" leaning subreddits to classify comments and subreddit's.

I mined the data over a few months using praw, I used a list of around 20-25 different subreddits taking between 10-20,000 comments from each from within the past year, so the model is quite American election biased but the model was fine tuned a few weeks ago so the comments you are seeing the gif it has not seen before.

I used DistilBert to fine-tune the model on pre-processed text, I spent a few months fine-tuning different models on different versions of the data set until I minimised overfitting and got a decent validation to training trade-off.

I also made a fun venn diagram tool to help find similar subreddits, I used this tool with a much larger sample size to help find similar leaning subreddits to help remove my personal bias although I am certain the left-wing subreddits tend to the far left more than the right which is why you may see a fair bit of negative biden commentary leading more left than right.

Disclaimer:  
The venn diagram tool and the subreddit classifier tool utilise praw which has a decent rate limit so may take 10-20 seconds before it returns a result, I have moved to psaw although loading times have not improved much.

View this project: [https://reddit-political-analysis.com/](https://reddit-political-analysis.com/)",1747
298,298,Corpus overlap and inflection,"I'm researching language mixing and English borrowings and I need to compare two txt corpora (one in English, one in Polish) to find words that overlap between them, excluding stop words, and preferably the frequency of overlap as well. I'm using Python. One difficulty is that Polish is an inflectional language, so e.g. ""to ghost"" is ""ghostOWAĆ"" in Polish. How can I account for that in my code so the program to find the instances of these inflected words as well?

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/my4vju/corpus_overlap_and_inflection/,LanguageTechnology,t3_my4vju,"Corpus overlap and inflection I'm researching language mixing and English borrowings and I need to compare two txt corpora (one in English, one in Polish) to find words that overlap between them, excluding stop words, and preferably the frequency of overlap as well. I'm using Python. One difficulty is that Polish is an inflectional language, so e.g. ""to ghost"" is ""ghostOWAĆ"" in Polish. How can I account for that in my code so the program to find the instances of these inflected words as well?

Thanks!",506
299,299,Anyone know of any papers about training with a traditional pretraining task (MLM) simultaneously with a finetuning task; as opposed to first doing pretraining then finetuning ?,,https://www.reddit.com/r/LanguageTechnology/comments/my1ruz/anyone_know_of_any_papers_about_training_with_a/,LanguageTechnology,t3_my1ruz,Anyone know of any papers about training with a traditional pretraining task (MLM) simultaneously with a finetuning task; as opposed to first doing pretraining then finetuning ? ,178
300,300,How to approach finding Similar wording in paragraph,"I have data which is basically a group of paragraphs that I know could be related.

Inside a group of paragraphs (let’s say 100 paragraphs). There could be a sentence of two that are almost/exactly the same text across 60% of the paragraphs. Another completely different similar text across 20% of the paragraphs while the other 20% might be unrelated. 

I have billions of these groups of 100 paragraphs and have no idea where to start! Thanks for any pointers",https://www.reddit.com/r/LanguageTechnology/comments/mxm06o/how_to_approach_finding_similar_wording_in/,LanguageTechnology,t3_mxm06o,"How to approach finding Similar wording in paragraph I have data which is basically a group of paragraphs that I know could be related.

Inside a group of paragraphs (let’s say 100 paragraphs). There could be a sentence of two that are almost/exactly the same text across 60% of the paragraphs. Another completely different similar text across 20% of the paragraphs while the other 20% might be unrelated. 

I have billions of these groups of 100 paragraphs and have no idea where to start! Thanks for any pointers",514
301,301,Best way to find the (best) solution to any task?,"What would be a good method to find, for example, the best method to compare two sentences for having the same or a similar meaning? I mean something like a overview or a search engine, based on a problem/solution pattern. Finding the best ways to solve a problem, without asking around a lot or looking into abstracts for papers.",https://www.reddit.com/r/LanguageTechnology/comments/mxodes/best_way_to_find_the_best_solution_to_any_task/,LanguageTechnology,t3_mxodes,"Best way to find the (best) solution to any task? What would be a good method to find, for example, the best method to compare two sentences for having the same or a similar meaning? I mean something like a overview or a search engine, based on a problem/solution pattern. Finding the best ways to solve a problem, without asking around a lot or looking into abstracts for papers.",380
302,302,Latest trends in topic modelling?,"Any expert in the domain here?

I had learnt about LDA/ LSA, and it seems that BERT artchitecture is not a fit if there's no pretagged labels on the topics. What are some of the latst trends? Are there any good teams/ companies working on this sector?",https://www.reddit.com/r/LanguageTechnology/comments/mxcvxk/latest_trends_in_topic_modelling/,LanguageTechnology,t3_mxcvxk,"Latest trends in topic modelling? Any expert in the domain here?

I had learnt about LDA/ LSA, and it seems that BERT artchitecture is not a fit if there's no pretagged labels on the topics. What are some of the latst trends? Are there any good teams/ companies working on this sector?",285
303,303,Transformers Pegasus - how do I fine tune another language?,How do I fine tune another language? Who will tell you?,https://www.reddit.com/r/LanguageTechnology/comments/mxj2j1/transformers_pegasus_how_do_i_fine_tune_another/,LanguageTechnology,t3_mxj2j1,Transformers Pegasus - how do I fine tune another language? How do I fine tune another language? Who will tell you?,115
304,304,How to get Training data for NER?,"Hello,

I'm currently working on a NER that extracts products and capabilities of company based on texts from their website. At the moment I don't have any training data that I could use to train my NLP Model. I need German training data.

I found this farmework: [https://github.com/NorskRegnesentral/skweak](https://github.com/NorskRegnesentral/skweak) and it looks great to automatically label data, but I would still need some kind of structured data in form of gazetters or another ML model to automatically annotate words.

One thing I tried is using Masked Language Model to predict missing words. I found this approach here: [https://towardsdatascience.com/unsupervised-ner-using-bert-2d7af5f90b8a](https://towardsdatascience.com/unsupervised-ner-using-bert-2d7af5f90b8a)  
If one of the predicted words is in my target dictionary then I tag this word with the corresponding entity. This approach works in some cases, but it is not very accurate and I'm not sure how to deal with products that consist of multiple words.

Do any of you have an idea where I could find training data in German with labeled products or how i could generate the training data myself?

Thanks",https://www.reddit.com/r/LanguageTechnology/comments/mxg8pj/how_to_get_training_data_for_ner/,LanguageTechnology,t3_mxg8pj,"How to get Training data for NER? Hello,

I'm currently working on a NER that extracts products and capabilities of company based on texts from their website. At the moment I don't have any training data that I could use to train my NLP Model. I need German training data.

I found this farmework: [https://github.com/NorskRegnesentral/skweak](https://github.com/NorskRegnesentral/skweak) and it looks great to automatically label data, but I would still need some kind of structured data in form of gazetters or another ML model to automatically annotate words.

One thing I tried is using Masked Language Model to predict missing words. I found this approach here: [https://towardsdatascience.com/unsupervised-ner-using-bert-2d7af5f90b8a](https://towardsdatascience.com/unsupervised-ner-using-bert-2d7af5f90b8a)  
If one of the predicted words is in my target dictionary then I tag this word with the corresponding entity. This approach works in some cases, but it is not very accurate and I'm not sure how to deal with products that consist of multiple words.

Do any of you have an idea where I could find training data in German with labeled products or how i could generate the training data myself?

Thanks",1213
305,305,YOLOv5 equivalent for NLP classification?,"I'm coming from the world of computer vision and was wondering whether there's the YOLOv5 model equivalent for NLP? I'm looking to train a classification model to categorize short strings (ex: classifying area-related words - Acreage, Land Area, acres, estimated size, lot size, deeded acres, and land area - all as ""area""). I'm thinking of using transfer learning on a custom dataset.

Are there industry-standard models that you'd recommend looking into? Or, put differently, models that offer a good tradeoff between performance and ease-of-use?

Edit: Looking for deep learning approaches to NLP. Perhaps with a [fast.ai](https://fast.ai) flavour",https://www.reddit.com/r/LanguageTechnology/comments/mxae9h/yolov5_equivalent_for_nlp_classification/,LanguageTechnology,t3_mxae9h,"YOLOv5 equivalent for NLP classification? I'm coming from the world of computer vision and was wondering whether there's the YOLOv5 model equivalent for NLP? I'm looking to train a classification model to categorize short strings (ex: classifying area-related words - Acreage, Land Area, acres, estimated size, lot size, deeded acres, and land area - all as ""area""). I'm thinking of using transfer learning on a custom dataset.

Are there industry-standard models that you'd recommend looking into? Or, put differently, models that offer a good tradeoff between performance and ease-of-use?

Edit: Looking for deep learning approaches to NLP. Perhaps with a [fast.ai](https://fast.ai) flavour",692
306,306,Text Classification using Convolutional Neural Network with TensorFlow 2.1 in Python | #NLProc,,https://youtu.be/MsL79ZIqWpg,LanguageTechnology,t3_mxdj43,Text Classification using Convolutional Neural Network with TensorFlow 2.1 in Python | #NLProc ,95
307,307,"Introducing mlconjug3. A Python library to conjugate verbs in French, English, Spanish, Italian, Portuguese and Romanian (with more in beta version) using Machine Learning techniques.","Hi everybody!

&amp;#x200B;

A couple of years ago, I made a [post to announce the release of mlconjug](https://www.reddit.com/r/Python/comments/bb8400/mlconjug_a_python_library_to_conjugate_verbs_in/),  a Python package/library to conjugate verbs (even made-up verbs, or verbs coming from slang and not covered in traditional conjugation tables) in French, English, Spanish, Italian, Portuguese and Romanian using Machine Learning techniques.

Since then, mlconjug has had a lot of success with thousands of students of foreign languages using it as a standalone application to improve their conjugation skills, but it has also been incorporated as a library dependency in more than a dozen different python software projects ranging from traditional NLP tasks using Machine Learning, to twitter bots, Voice Assistants, and even games.

It has also been used in several Academic publications, for example: [""Generative Grading: Near Human-level Accuracy for Automated Feedback on Richly Structured Problems""](https://arxiv.org/abs/1905.09916) where it is used for automatically grading students essays, and  United States citizenship exam questions.

I released a new and improved version of the software, called [mlconjug3](https://github.com/SekouDiaoNlp/mlconjug3) as it is only compatible with Python 3.x, and had many enhancements and bug fixes. The accuracy of the conjugations models has improved a lot and I am in the process of implementing regional European languages (in beta version for now), like Catalan,  Valencian , Basque language, etc... as well as slavic languages (Czech and Polish for now).

Those new languages should be available in the beginning of summer and I am looking for native speakers of the languages that are in beta status to test the software and check that the conjugated forms are correct.

You can install mlconjug3 from [PyPi](https://pypi.python.org/pypi/mlconjug3) or [Anaconda](https://anaconda.org/conda-forge/mlconjug3).

Some of the features of mlconjug3 are the following:

* Easy to use API.
* Includes pre-trained language models with 99% + accuracy in predicting conjugation class of unknown verbs.
* Easily train new models or add new languages.
* Easily integrate MLConjug in your own projects.
* Can be used as a command line tool.

I invite everyone to try it out and if you are a native speaker of Catalan,  Valencian , Basque, Czech or Polish and are willing to beta-test the software, please pm me, you are would be greatly appreciated, and it will make mlconjug3 more versatile and therefore more useful.

Thanks Everyone,

Peace,

SekouDiaoNlp",https://www.reddit.com/r/LanguageTechnology/comments/mwsymt/introducing_mlconjug3_a_python_library_to/,LanguageTechnology,t3_mwsymt,"Introducing mlconjug3. A Python library to conjugate verbs in French, English, Spanish, Italian, Portuguese and Romanian (with more in beta version) using Machine Learning techniques. Hi everybody!

&amp;#x200B;

A couple of years ago, I made a [post to announce the release of mlconjug](https://www.reddit.com/r/Python/comments/bb8400/mlconjug_a_python_library_to_conjugate_verbs_in/),  a Python package/library to conjugate verbs (even made-up verbs, or verbs coming from slang and not covered in traditional conjugation tables) in French, English, Spanish, Italian, Portuguese and Romanian using Machine Learning techniques.

Since then, mlconjug has had a lot of success with thousands of students of foreign languages using it as a standalone application to improve their conjugation skills, but it has also been incorporated as a library dependency in more than a dozen different python software projects ranging from traditional NLP tasks using Machine Learning, to twitter bots, Voice Assistants, and even games.

It has also been used in several Academic publications, for example: [""Generative Grading: Near Human-level Accuracy for Automated Feedback on Richly Structured Problems""](https://arxiv.org/abs/1905.09916) where it is used for automatically grading students essays, and  United States citizenship exam questions.

I released a new and improved version of the software, called [mlconjug3](https://github.com/SekouDiaoNlp/mlconjug3) as it is only compatible with Python 3.x, and had many enhancements and bug fixes. The accuracy of the conjugations models has improved a lot and I am in the process of implementing regional European languages (in beta version for now), like Catalan,  Valencian , Basque language, etc... as well as slavic languages (Czech and Polish for now).

Those new languages should be available in the beginning of summer and I am looking for native speakers of the languages that are in beta status to test the software and check that the conjugated forms are correct.

You can install mlconjug3 from [PyPi](https://pypi.python.org/pypi/mlconjug3) or [Anaconda](https://anaconda.org/conda-forge/mlconjug3).

Some of the features of mlconjug3 are the following:

* Easy to use API.
* Includes pre-trained language models with 99% + accuracy in predicting conjugation class of unknown verbs.
* Easily train new models or add new languages.
* Easily integrate MLConjug in your own projects.
* Can be used as a command line tool.

I invite everyone to try it out and if you are a native speaker of Catalan,  Valencian , Basque, Czech or Polish and are willing to beta-test the software, please pm me, you are would be greatly appreciated, and it will make mlconjug3 more versatile and therefore more useful.

Thanks Everyone,

Peace,

SekouDiaoNlp",2787
308,308,Which domain in master degree to choose,"Hello guys, I am living in korea and majored arabic in HUFS(Hankook university of foreign studies).

I got interest on singularity concept since 2013, and I got into this field

from learning machine learning and big data in the academy funded by government.

&amp;#x200B;

Now I am preparing to go artificial intelligence in graduate school, which is master degree

but there are not that many information in korea that which part; computer vision, natural language processing, have more good prospect.

&amp;#x200B;

I was actually thinking about studying nlp, because I majored language in university; english and arabic, and korean speaker, so I applied to the program that only teach nlp for 6 months.

&amp;#x200B;

But I saw one opinion in the forum that nlp have no future after gpt3, and if gpt4 comes out,

there will be no future for nlp.

&amp;#x200B;

So I felt that I have to consider which part will survive for long.

&amp;#x200B;

One of the member in A.I group recommended me that Medical image analysis is hot trend now,

so it is better to study computer vision for the future.

&amp;#x200B;

From now, I have to decide which part I should study more deeply in order to appeal graduate school that I had interest on specific field.

&amp;#x200B;

Briefly, the question is two.

&amp;#x200B;

1.Which part of A.I will survive long? CV or NLP? And which part is more prospective regarding

job opportunity and studying ph.D?

&amp;#x200B;

2.I applied to two kind of government program, first one is teaching general artificial intelligence

including brief lesson of CV and NLP. Second one is the program that only teaches NLP. I am 

wondering which program is better for me entering A.I field.

My second question will be depend on the first question, because if the future of NLP is dark,

I will apply to general A.I program and then study medical image analysis and contact the graduate school in CV lab.

&amp;#x200B;

thank you for reading all of my stories and questions.",https://www.reddit.com/r/LanguageTechnology/comments/mwwkk0/which_domain_in_master_degree_to_choose/,LanguageTechnology,t3_mwwkk0,"Which domain in master degree to choose Hello guys, I am living in korea and majored arabic in HUFS(Hankook university of foreign studies).

I got interest on singularity concept since 2013, and I got into this field

from learning machine learning and big data in the academy funded by government.

&amp;#x200B;

Now I am preparing to go artificial intelligence in graduate school, which is master degree

but there are not that many information in korea that which part; computer vision, natural language processing, have more good prospect.

&amp;#x200B;

I was actually thinking about studying nlp, because I majored language in university; english and arabic, and korean speaker, so I applied to the program that only teach nlp for 6 months.

&amp;#x200B;

But I saw one opinion in the forum that nlp have no future after gpt3, and if gpt4 comes out,

there will be no future for nlp.

&amp;#x200B;

So I felt that I have to consider which part will survive for long.

&amp;#x200B;

One of the member in A.I group recommended me that Medical image analysis is hot trend now,

so it is better to study computer vision for the future.

&amp;#x200B;

From now, I have to decide which part I should study more deeply in order to appeal graduate school that I had interest on specific field.

&amp;#x200B;

Briefly, the question is two.

&amp;#x200B;

1.Which part of A.I will survive long? CV or NLP? And which part is more prospective regarding

job opportunity and studying ph.D?

&amp;#x200B;

2.I applied to two kind of government program, first one is teaching general artificial intelligence

including brief lesson of CV and NLP. Second one is the program that only teaches NLP. I am 

wondering which program is better for me entering A.I field.

My second question will be depend on the first question, because if the future of NLP is dark,

I will apply to general A.I program and then study medical image analysis and contact the graduate school in CV lab.

&amp;#x200B;

thank you for reading all of my stories and questions.",2038
309,309,Best way to choose topic keyword for text?,"Hi everyone, been a lurker here for a while. I'd like some advice on an NLP task I'm working on.
 I have a list of paragraphs, and a list of possible key words/phrases to choose from. I would like to assign the most probable keyword from the list for each paragraph, based on semantic meaning. 
Currently I am just computing an embedding for the keyword and the paragraph and comparing the two, but the results aren't great. What would be the best way to do this? Is there some preprocessing that would improve results? Thanks in advance",https://www.reddit.com/r/LanguageTechnology/comments/mx1um3/best_way_to_choose_topic_keyword_for_text/,LanguageTechnology,t3_mx1um3,"Best way to choose topic keyword for text? Hi everyone, been a lurker here for a while. I'd like some advice on an NLP task I'm working on.
 I have a list of paragraphs, and a list of possible key words/phrases to choose from. I would like to assign the most probable keyword from the list for each paragraph, based on semantic meaning. 
Currently I am just computing an embedding for the keyword and the paragraph and comparing the two, but the results aren't great. What would be the best way to do this? Is there some preprocessing that would improve results? Thanks in advance",580
310,310,"[Call For Participants] MESINESP2 (BioASQ / CLEF2021 shared task) on semantic indexing of heterogenous health content: literature, clinical trials and patents","**\*\*\* CFP2  MESINESP2 track: Medical Semantic Indexing (BioASQ – CLEF 2021) \*\*\***

[https://temu.bsc.es/mesinesp2/](https://temu.bsc.es/mesinesp2/) 

**MESINESP2 Awards by BSC-Plan TL \[2,700€\]**

**Test sets and additional data are now available**

There is a pressing need for advanced multilingual semantic search strategies for health related content like literature, patents and clinical trials (cross-genre). The use of semantic search techniques in combination with structured vocabularies is critical for sophisticated searches or content analysis as needed by healthcare professionals, researchers, the pharmaceutical industry, patient groups and private citizens.

Following the impact of past BioASQ tracks for benchmarking studies (e.g. BioBERT) and organization of other initiatives like BioCreative or IberLEF, we propose three semantic labelling subtracks using the widely used DeCS vocabulary (similar to MeSH terms):

**MESINESP-L – Scientific Literature**: for automatic labelling of medical literature abstracts in Spanish (including recent COVID-19 literature).

**MESINESP-T – Clinical trials**: for automatic labelling of clinical trials summaries.

**MESINESP-P – Patents:** for automatic labelling of health-related patents in Spanish to improve patent intelligence.

**Key information**

**Web**:[ https://temu.bsc.es/mesinesp2](https://temu.bsc.es/mesinesp2) 

**Registration**:[ http://clef2021-labs-registration.dei.unipd.it/](http://clef2021-labs-registration.dei.unipd.it/) (BioASQ **Task 3 - MESINESP**)

**Data**: [https://doi.org/10.5281/zenodo.4707104](https://doi.org/10.5281/zenodo.4707104)

MESINESP2 is organized in close collaboration with widely used multilingual medical literature databases (BIREME/WHO, ISCIII/Spain), which expressed a direct need for advanced technologies to accelerate manual indexing efforts for the contents in Spanish (spoken globally by over 572 million people). They do face a challenge to keep up with the increasing number of published medical papers when using purely manual indexing.

A large manually indexed collection of training documents will be provided. These documents have already been automatically annotated (&gt; 1.5 million entity mentions) with  medical entities such as diseases, medical procedures, drugs and symptoms to facilitate the use of complementary strategies like *multi-label classification*, *multilingual transformers*, *graph matching*, *text similarity,* *advanced term matching* or *named entity recognition components*. 

Participating systems will be directly useful for ongoing medical literature indexing efforts, and thus improve competitive intelligence/prior art searches, enable complex search queries needed for evidence-based medicine, clinical decision making, or elaboration of clinical practice guidelines and serve as base for future tasks on semantic indexing of medical records or content in other languages. 

**Important dates**

* April 19: Updated Train, Validation and Test sets release
* April 19: Additional datasets release (Medical entities present in documents)
* April , 30: BioASQ9 Lab u/CLEF 2021 Registration Deadline
* May, 7: Start of the evaluation period
* May, 17: End of the evaluation period
* May,28 :Submission of Participant Papers at CLEF2021
* July, 2: Camera ready paper submission.
* Sep 21-24: CLEF 2021 Conference

**Publications and BioASQ/CLEF2021 workshop**

Teams participating in MESINESP2 will be invited to contribute a systems description paper for the BioASQ (CLEF 2021) Working Notes proceedings, and a short presentation of their approach at the BioASQ 2021 workshop.

**Main Track organizers**

* **Martin Krallinger**, Barcelona Supercomputing Center (BSC), Spain.
* **Luis Gascó**, Barcelona Supercomputing Center (BSC), Spain.
* **Anastasios Nentidis**, National Center for Scientific Research Demokritos, Greece.
* **Elena Primo-Peña,** Biblioteca Nacional de Ciencias de Salud. Instituto de Salud Carlos III, Spain.
* **Cristina Bojo Canales,** Biblioteca Nacional de Ciencias de la Salud. Instituto de Salud Carlos III, Spain.
* **George Paliouras**, National Center for Scientific Research Demokritos, Greece.
* **Anastasia Krithara**, National Center for Scientific Research Demokritos, Greece.
* **Renato Murasaki,** BIREME – Organización Panamericana de la Salud (WHO), Brasil.

**Scientific Committee**

* **Tristan Naumann,** Microsoft Research (USA)
* **Prof. Xavier Tannier,** Sorbonne Université and LIMICS (France)
* **Lucy Lu Wang,** Allen Institute for AI (AI2) (USA)
* **Prof. David Camacho,** Applied Intelligence and Data Analysis Research Group, Universidad Politécnica de Madrid (Spain)
* **Prof. Oscar Corcho,** Ontology Engineering Group, Universidad Politécnica de Madrid (Spain)
* **Parminder Batia,** Amazon Health AI (USA)
* **Prof. Irena Spasic,** School of Computer Science &amp; Informatics, co-Director of the Data Innovation Research Institute, Cardiff University (UK)
* **Jose Luis Redondo García,** Amazon Alexa, Amazon (UK)
* **Carlos Badenes-Olmedo,** Ontology Engineering Group, Universidad Politécnica de Madrid (Spain)
* **Prof. Allan Hanbury,**  E-Commerce Research Unit in the Faculty of Informatics, TU Wien (Austria)
* **Prof. Alfonso Valencia,** Barcelona Supercomputing Center (Spain)
* **Prof. Stefan J. Darmoni,** Department of Biomedical Informatics, Rouen University Hospital (France) and LIMICS (France)
* **Rezarta Islamaj,** National Center for Biotechnology Information (USA)
* **Prof. Rafael Berlanga Llavori,** Universidad Jaume I (Spain)
* **Prof. Henning Müller,** University of Applied Sciences Western Switzerland – Valais (Switzerland)
* **Prof. Gareth J.F. Jones,** School of Computing at Dublin City University (Ireland)
* **Georg Rehm,** Deutsches Forschungszentrum für Künstliche Intelligenz (Germany)
* **Petr Knoth,** Research Studios Austria Forschungsgesellschaft mbH (Austria)
* **Natalia Manola,** CEO at OpenAIRE AMKE (Greece)
* **Prof. Jesús Tramullas,** Departamento de Ciencias de la Documentación e Historia de la Ciencia, Universidad de Zaragoza (Spain)",https://www.reddit.com/r/LanguageTechnology/comments/mwqxru/call_for_participants_mesinesp2_bioasq_clef2021/,LanguageTechnology,t3_mwqxru,"[Call For Participants] MESINESP2 (BioASQ / CLEF2021 shared task) on semantic indexing of heterogenous health content: literature, clinical trials and patents **\*\*\* CFP2  MESINESP2 track: Medical Semantic Indexing (BioASQ – CLEF 2021) \*\*\***

[https://temu.bsc.es/mesinesp2/](https://temu.bsc.es/mesinesp2/) 

**MESINESP2 Awards by BSC-Plan TL \[2,700€\]**

**Test sets and additional data are now available**

There is a pressing need for advanced multilingual semantic search strategies for health related content like literature, patents and clinical trials (cross-genre). The use of semantic search techniques in combination with structured vocabularies is critical for sophisticated searches or content analysis as needed by healthcare professionals, researchers, the pharmaceutical industry, patient groups and private citizens.

Following the impact of past BioASQ tracks for benchmarking studies (e.g. BioBERT) and organization of other initiatives like BioCreative or IberLEF, we propose three semantic labelling subtracks using the widely used DeCS vocabulary (similar to MeSH terms):

**MESINESP-L – Scientific Literature**: for automatic labelling of medical literature abstracts in Spanish (including recent COVID-19 literature).

**MESINESP-T – Clinical trials**: for automatic labelling of clinical trials summaries.

**MESINESP-P – Patents:** for automatic labelling of health-related patents in Spanish to improve patent intelligence.

**Key information**

**Web**:[ https://temu.bsc.es/mesinesp2](https://temu.bsc.es/mesinesp2) 

**Registration**:[ http://clef2021-labs-registration.dei.unipd.it/](http://clef2021-labs-registration.dei.unipd.it/) (BioASQ **Task 3 - MESINESP**)

**Data**: [https://doi.org/10.5281/zenodo.4707104](https://doi.org/10.5281/zenodo.4707104)

MESINESP2 is organized in close collaboration with widely used multilingual medical literature databases (BIREME/WHO, ISCIII/Spain), which expressed a direct need for advanced technologies to accelerate manual indexing efforts for the contents in Spanish (spoken globally by over 572 million people). They do face a challenge to keep up with the increasing number of published medical papers when using purely manual indexing.

A large manually indexed collection of training documents will be provided. These documents have already been automatically annotated (&gt; 1.5 million entity mentions) with  medical entities such as diseases, medical procedures, drugs and symptoms to facilitate the use of complementary strategies like *multi-label classification*, *multilingual transformers*, *graph matching*, *text similarity,* *advanced term matching* or *named entity recognition components*. 

Participating systems will be directly useful for ongoing medical literature indexing efforts, and thus improve competitive intelligence/prior art searches, enable complex search queries needed for evidence-based medicine, clinical decision making, or elaboration of clinical practice guidelines and serve as base for future tasks on semantic indexing of medical records or content in other languages. 

**Important dates**

* April 19: Updated Train, Validation and Test sets release
* April 19: Additional datasets release (Medical entities present in documents)
* April , 30: BioASQ9 Lab u/CLEF 2021 Registration Deadline
* May, 7: Start of the evaluation period
* May, 17: End of the evaluation period
* May,28 :Submission of Participant Papers at CLEF2021
* July, 2: Camera ready paper submission.
* Sep 21-24: CLEF 2021 Conference

**Publications and BioASQ/CLEF2021 workshop**

Teams participating in MESINESP2 will be invited to contribute a systems description paper for the BioASQ (CLEF 2021) Working Notes proceedings, and a short presentation of their approach at the BioASQ 2021 workshop.

**Main Track organizers**

* **Martin Krallinger**, Barcelona Supercomputing Center (BSC), Spain.
* **Luis Gascó**, Barcelona Supercomputing Center (BSC), Spain.
* **Anastasios Nentidis**, National Center for Scientific Research Demokritos, Greece.
* **Elena Primo-Peña,** Biblioteca Nacional de Ciencias de Salud. Instituto de Salud Carlos III, Spain.
* **Cristina Bojo Canales,** Biblioteca Nacional de Ciencias de la Salud. Instituto de Salud Carlos III, Spain.
* **George Paliouras**, National Center for Scientific Research Demokritos, Greece.
* **Anastasia Krithara**, National Center for Scientific Research Demokritos, Greece.
* **Renato Murasaki,** BIREME – Organización Panamericana de la Salud (WHO), Brasil.

**Scientific Committee**

* **Tristan Naumann,** Microsoft Research (USA)
* **Prof. Xavier Tannier,** Sorbonne Université and LIMICS (France)
* **Lucy Lu Wang,** Allen Institute for AI (AI2) (USA)
* **Prof. David Camacho,** Applied Intelligence and Data Analysis Research Group, Universidad Politécnica de Madrid (Spain)
* **Prof. Oscar Corcho,** Ontology Engineering Group, Universidad Politécnica de Madrid (Spain)
* **Parminder Batia,** Amazon Health AI (USA)
* **Prof. Irena Spasic,** School of Computer Science &amp; Informatics, co-Director of the Data Innovation Research Institute, Cardiff University (UK)
* **Jose Luis Redondo García,** Amazon Alexa, Amazon (UK)
* **Carlos Badenes-Olmedo,** Ontology Engineering Group, Universidad Politécnica de Madrid (Spain)
* **Prof. Allan Hanbury,**  E-Commerce Research Unit in the Faculty of Informatics, TU Wien (Austria)
* **Prof. Alfonso Valencia,** Barcelona Supercomputing Center (Spain)
* **Prof. Stefan J. Darmoni,** Department of Biomedical Informatics, Rouen University Hospital (France) and LIMICS (France)
* **Rezarta Islamaj,** National Center for Biotechnology Information (USA)
* **Prof. Rafael Berlanga Llavori,** Universidad Jaume I (Spain)
* **Prof. Henning Müller,** University of Applied Sciences Western Switzerland – Valais (Switzerland)
* **Prof. Gareth J.F. Jones,** School of Computing at Dublin City University (Ireland)
* **Georg Rehm,** Deutsches Forschungszentrum für Künstliche Intelligenz (Germany)
* **Petr Knoth,** Research Studios Austria Forschungsgesellschaft mbH (Austria)
* **Natalia Manola,** CEO at OpenAIRE AMKE (Greece)
* **Prof. Jesús Tramullas,** Departamento de Ciencias de la Documentación e Historia de la Ciencia, Universidad de Zaragoza (Spain)",6257
311,311,AI Tutor: A Computer Science Domain Knowledge Graph-Based QA System,"I didn't build it. But I found it interesting. What could be other alternative approach to solve this problem?

[Research Paper](https://publications.waset.org/10011676/ai-tutor-a-computer-science-domain-knowledge-graph-based-qa-system-on-jade-platform)",https://www.reddit.com/r/LanguageTechnology/comments/mwakja/ai_tutor_a_computer_science_domain_knowledge/,LanguageTechnology,t3_mwakja,"AI Tutor: A Computer Science Domain Knowledge Graph-Based QA System I didn't build it. But I found it interesting. What could be other alternative approach to solve this problem?

[Research Paper](https://publications.waset.org/10011676/ai-tutor-a-computer-science-domain-knowledge-graph-based-qa-system-on-jade-platform)",321
312,312,Any idea what technology google map uses to tag reviews into categories,"I was reading reviews for a food outlet and saw tags like ""wrap"" ""hummus"" ""chicken"" ""lady"" ""platter"" ""sauce""",https://www.reddit.com/r/LanguageTechnology/comments/mw41p3/any_idea_what_technology_google_map_uses_to_tag/,LanguageTechnology,t3_mw41p3,"Any idea what technology google map uses to tag reviews into categories I was reading reviews for a food outlet and saw tags like ""wrap"" ""hummus"" ""chicken"" ""lady"" ""platter"" ""sauce""",180
313,313,Recommendation about regression + language,"I am not sure if this question fit here, but I am working with a regression task on a songs dataset,  one of the variables is the name, I am trying to use it to get a better prediction.

What I did:
I use the python library langdetec to get the language of the name, transform this categorical variable to numerical, and it work good, but I want to improve it.

- Langdetec is not too good, I saw Spanish songs catalogued as italian, but others better libraries takes a lot of time to evaluate all the dataset (this dataset has 130000 rows).
- My transformation from categorical to numerical is basic (number=1, other=2, af=3, ..., en=13, etc).
- I think using a word embedded would be too much for this kind of problem, there is other 17 variables in the data set and the results are good, I just want to take advantage of the name too.

Does anybody recommend me something?
It would be great if anybody recommend me a paper to base on because this task is for an assignment.

Also, I am thinking in a future research about best way to have language categorical variable or language prediction based on frequency.

Thanks in advance for any comments.",https://www.reddit.com/r/LanguageTechnology/comments/mwdzeq/recommendation_about_regression_language/,LanguageTechnology,t3_mwdzeq,"Recommendation about regression + language I am not sure if this question fit here, but I am working with a regression task on a songs dataset,  one of the variables is the name, I am trying to use it to get a better prediction.

What I did:
I use the python library langdetec to get the language of the name, transform this categorical variable to numerical, and it work good, but I want to improve it.

- Langdetec is not too good, I saw Spanish songs catalogued as italian, but others better libraries takes a lot of time to evaluate all the dataset (this dataset has 130000 rows).
- My transformation from categorical to numerical is basic (number=1, other=2, af=3, ..., en=13, etc).
- I think using a word embedded would be too much for this kind of problem, there is other 17 variables in the data set and the results are good, I just want to take advantage of the name too.

Does anybody recommend me something?
It would be great if anybody recommend me a paper to base on because this task is for an assignment.

Also, I am thinking in a future research about best way to have language categorical variable or language prediction based on frequency.

Thanks in advance for any comments.",1194
314,314,Free NLP assignments,"If anyone is teaching NLP this summer, feel free to use any of these free assignments from OpenClass: [https://openclass.ai/catalog/nlp](https://openclass.ai/catalog/nlp)

These assignments leverage learning principles proven to optimize knowledge retention, and identify &amp; bridge knowledge gaps to personalize the experience for learners. The idea is to provide a low-stakes environment for learners to master fundamental concepts at their own pace.

Our mission with this project is to improve &amp; democratize education. We're looking to grow our community of NLP educators, so if you're interested in contributing, feel free to join on. (Note: you can also keep your assignments private.)",https://www.reddit.com/r/LanguageTechnology/comments/mvjzhp/free_nlp_assignments/,LanguageTechnology,t3_mvjzhp,"Free NLP assignments If anyone is teaching NLP this summer, feel free to use any of these free assignments from OpenClass: [https://openclass.ai/catalog/nlp](https://openclass.ai/catalog/nlp)

These assignments leverage learning principles proven to optimize knowledge retention, and identify &amp; bridge knowledge gaps to personalize the experience for learners. The idea is to provide a low-stakes environment for learners to master fundamental concepts at their own pace.

Our mission with this project is to improve &amp; democratize education. We're looking to grow our community of NLP educators, so if you're interested in contributing, feel free to join on. (Note: you can also keep your assignments private.)",718
315,315,Measuring accuracy of my clusters,"I am trying to do multi classification for sentences.

What are the best ways to make sure my clusters are homogenous?

(I am having a coverage of aprox 80%))

Edit; More context as requested;

I am working on clustering methods for textual data (sentences). Implemented an unsupervised clustering method . When I go through the output, it makes sense. I went through literatures to see what metrics would to tell us ""how good the clusters are"" and got confused. This will help me compare my methods to other methods out there and maybe tweak my method to perform better. I would like to know from the fellow researchers if there are methods which worked best for you which :  
 1. gives a score on homogeneity of clusters  
 2. gives a score on what's the optimal inter-cluster distance.  
 3. gives significance of a cluster  
 4. gives a number on ""optimal number of clusters""",https://www.reddit.com/r/LanguageTechnology/comments/mw4a6p/measuring_accuracy_of_my_clusters/,LanguageTechnology,t3_mw4a6p,"Measuring accuracy of my clusters I am trying to do multi classification for sentences.

What are the best ways to make sure my clusters are homogenous?

(I am having a coverage of aprox 80%))

Edit; More context as requested;

I am working on clustering methods for textual data (sentences). Implemented an unsupervised clustering method . When I go through the output, it makes sense. I went through literatures to see what metrics would to tell us ""how good the clusters are"" and got confused. This will help me compare my methods to other methods out there and maybe tweak my method to perform better. I would like to know from the fellow researchers if there are methods which worked best for you which :  
 1. gives a score on homogeneity of clusters  
 2. gives a score on what's the optimal inter-cluster distance.  
 3. gives significance of a cluster  
 4. gives a number on ""optimal number of clusters""",913
316,316,How to make a multilingual translator like Google Translate,,https://www.youtube.com/watch?v=HuZq5KkLx8Q&amp;list=PL_49VD9KwQ_ObGMW5g9hMOLnDY01NHv91&amp;index=2&amp;t=1s,LanguageTechnology,t3_mvlh37,How to make a multilingual translator like Google Translate ,60
317,317,Do we need to balance a dataset when using BERT,"My dataset looks like following:

    smile        7957
    kind         3399
    angry        3288
    surprised    1702
    sad          1124

My goal is to classify an emotion using BERT.

and I decided to use SMOTE to balance it back

    train['numeric'] = train['emotions'].replace(to_replace=['smile', 'kind','angry','surprised','sad'], value=[0,1,2,3,4])
    
    smote = SMOTE()
    tv = TfidfVectorizer(stop_words=None, max_features=100000)
    tfidf = tv.fit_transform(train['content'].values.astype('U'))
    X_SMOTE, y_SMOTE = smote.fit_resample(tfidf, train['numeric'])
    

Should I even worry about balancing this dataset when using the BERT? or it is handled by BERT already?",https://www.reddit.com/r/LanguageTechnology/comments/mvmujf/do_we_need_to_balance_a_dataset_when_using_bert/,LanguageTechnology,t3_mvmujf,"Do we need to balance a dataset when using BERT My dataset looks like following:

    smile        7957
    kind         3399
    angry        3288
    surprised    1702
    sad          1124

My goal is to classify an emotion using BERT.

and I decided to use SMOTE to balance it back

    train['numeric'] = train['emotions'].replace(to_replace=['smile', 'kind','angry','surprised','sad'], value=[0,1,2,3,4])
    
    smote = SMOTE()
    tv = TfidfVectorizer(stop_words=None, max_features=100000)
    tfidf = tv.fit_transform(train['content'].values.astype('U'))
    X_SMOTE, y_SMOTE = smote.fit_resample(tfidf, train['numeric'])
    

Should I even worry about balancing this dataset when using the BERT? or it is handled by BERT already?",741
318,318,How do you guys find/ keep up to date with the latest NLP papers?,,https://www.reddit.com/r/LanguageTechnology/comments/mv8vn3/how_do_you_guys_find_keep_up_to_date_with_the/,LanguageTechnology,t3_mv8vn3,How do you guys find/ keep up to date with the latest NLP papers? ,66
319,319,"The Conversational AI &amp; NLP Summit is hosting speakers from DeepMind, Facebook, Nestle, McDonald's and more next week. See the full list of talks, networking opps and speakers below!",,https://www.re-work.co/events/conversational-ai-nlp-summit-2021?utm_source=LK&amp;utm_medium=Promo&amp;utm_campaign=LK_Conv_NLP_LC,LanguageTechnology,t3_mvdqql,"The Conversational AI &amp; NLP Summit is hosting speakers from DeepMind, Facebook, Nestle, McDonald's and more next week. See the full list of talks, networking opps and speakers below! ",187
320,320,Using Deep Learning Based On Semantic Features for Emotion Classification in Tweets,"Hello

I am a student and I am working on emotion analysis with deep learning. My supervisor asked me to extract semantic features from the text ( convert raw data into useful semantic features ) before using deep learning. But I am confused when I read research about text classification with deep learning. DL does not need feature extraction only using different types of word embedding to convert data, I need to clarify this. Is it possible to extract features before applying Deep Learning.? Is there any research that can help me with that? Any suggestions tools or techniques to extract semantic features from the text.",https://www.reddit.com/r/LanguageTechnology/comments/mvlr8c/using_deep_learning_based_on_semantic_features/,LanguageTechnology,t3_mvlr8c,"Using Deep Learning Based On Semantic Features for Emotion Classification in Tweets Hello

I am a student and I am working on emotion analysis with deep learning. My supervisor asked me to extract semantic features from the text ( convert raw data into useful semantic features ) before using deep learning. But I am confused when I read research about text classification with deep learning. DL does not need feature extraction only using different types of word embedding to convert data, I need to clarify this. Is it possible to extract features before applying Deep Learning.? Is there any research that can help me with that? Any suggestions tools or techniques to extract semantic features from the text.",711
321,321,Is causal language modeling (CLM) vs masked language modeling (MLM) a common distinction in NLP research?,"The [huggingface documentation](https://huggingface.co/transformers/v2.5.0/examples.html) states:

&gt;GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned using a masked language modeling (MLM) loss.

Is this a common distinction you'd find in the NLP literature? Is it a sensible distinction in your opinion? While I totally agree with the first category, I don't understand why you would call BERT &amp; co. ""masked language models"", since causal language models do the actual masking in next token prediction.",https://www.reddit.com/r/LanguageTechnology/comments/mvepoi/is_causal_language_modeling_clm_vs_masked/,LanguageTechnology,t3_mvepoi,"Is causal language modeling (CLM) vs masked language modeling (MLM) a common distinction in NLP research? The [huggingface documentation](https://huggingface.co/transformers/v2.5.0/examples.html) states:

&gt;GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned using a masked language modeling (MLM) loss.

Is this a common distinction you'd find in the NLP literature? Is it a sensible distinction in your opinion? While I totally agree with the first category, I don't understand why you would call BERT &amp; co. ""masked language models"", since causal language models do the actual masking in next token prediction.",677
322,322,Natural Language Generation Systems - are there any communities or open source projects around here?,"Hey everyone! Made a post and started delving into this space a few months ago when i decided to take this on for my Final Year Project. Find my post here: [https://www.reddit.com/r/LanguageTechnology/comments/jvo6ec/what\_is\_the\_technology\_behind\_automated\_insights/?utm\_source=share&amp;utm\_medium=web2x&amp;context=3](https://www.reddit.com/r/LanguageTechnology/comments/jvo6ec/what_is_the_technology_behind_automated_insights/?utm_source=share&amp;utm_medium=web2x&amp;context=3)

&amp;#x200B;

I've been building and simultaneously reading papers and enhancing my designs. Wanted to ask if anyone else is or has been working on this type of projects. Would love to know if there is a community in this space or any open source projects happening because from what i see, people working on this would be mainly also working in the companies that are building these systems :/ Would love to hear what challenges have been faced while building these systems. Coding is hard enough, creating a system that generates text that makes grammatical sense and fluent is SUPER difficult.",https://www.reddit.com/r/LanguageTechnology/comments/mv94ps/natural_language_generation_systems_are_there_any/,LanguageTechnology,t3_mv94ps,"Natural Language Generation Systems - are there any communities or open source projects around here? Hey everyone! Made a post and started delving into this space a few months ago when i decided to take this on for my Final Year Project. Find my post here: [https://www.reddit.com/r/LanguageTechnology/comments/jvo6ec/what\_is\_the\_technology\_behind\_automated\_insights/?utm\_source=share&amp;utm\_medium=web2x&amp;context=3](https://www.reddit.com/r/LanguageTechnology/comments/jvo6ec/what_is_the_technology_behind_automated_insights/?utm_source=share&amp;utm_medium=web2x&amp;context=3)

&amp;#x200B;

I've been building and simultaneously reading papers and enhancing my designs. Wanted to ask if anyone else is or has been working on this type of projects. Would love to know if there is a community in this space or any open source projects happening because from what i see, people working on this would be mainly also working in the companies that are building these systems :/ Would love to hear what challenges have been faced while building these systems. Coding is hard enough, creating a system that generates text that makes grammatical sense and fluent is SUPER difficult.",1189
323,323,AI-Generated Blog Content with GPT-Neo (GPT-3 Alternative) - Python Web App,,https://youtu.be/d_xRYyy2LFM,LanguageTechnology,t3_muzgu1,AI-Generated Blog Content with GPT-Neo (GPT-3 Alternative) - Python Web App ,76
324,324,How to add the Gradient Accumulation to my model?,"I am following this tutorial  [dp\_tutorials/Tutorial\_3\_RU\_Fine\_tuning\_BERT\_classifier.ipynb at master · deepmipt/dp\_tutorials · GitHub](https://github.com/deepmipt/dp_tutorials/blob/master/russian_tutorials/Tutorial_3_RU_Fine_tuning_BERT_classifier.ipynb)

However, I am constantly running out of memory so I decided to use Gradient Accumulation to reduce the memory size as it was suggested in my previous post. How can I add it to my model? I can’t find any tutorial that explains it well.

&amp;#x200B;

I already reduced the batch size however it did not helped that much

Thank you.",https://www.reddit.com/r/LanguageTechnology/comments/mv2tzf/how_to_add_the_gradient_accumulation_to_my_model/,LanguageTechnology,t3_mv2tzf,"How to add the Gradient Accumulation to my model? I am following this tutorial  [dp\_tutorials/Tutorial\_3\_RU\_Fine\_tuning\_BERT\_classifier.ipynb at master · deepmipt/dp\_tutorials · GitHub](https://github.com/deepmipt/dp_tutorials/blob/master/russian_tutorials/Tutorial_3_RU_Fine_tuning_BERT_classifier.ipynb)

However, I am constantly running out of memory so I decided to use Gradient Accumulation to reduce the memory size as it was suggested in my previous post. How can I add it to my model? I can’t find any tutorial that explains it well.

&amp;#x200B;

I already reduced the batch size however it did not helped that much

Thank you.",645
325,325,Use NLP to detect and classify emotion in text,"Hi everyone! I'm currently trying to develop a text classification program that detects emotions and social instances from written text of individuals diagnosed with depression. I thought it'd be a good idea to use lists of words for specific categories in order to build a vocabulary, like for social words I used ""family, friends, girlfriend"" and so on. This classification task is still simple though because it doesn't take into account context and negation (""not happy"" = unhappy). For example, the program can detect a word like ""bad"" but that word could be unrelated, like ""bad driver"". That doesn't give me any hint about the emotional state of that person but ""bad"" still gets detected as part of ""bad driver"". The downside of making a vocabulary using a list is that it can't contain complex words such as ""pissed off"" because they're two words and the text is tokenized at the beginning of the process, so they are passed in as two different words, ""piss"" and ""off"".  I'm trying to implement bigrams to add a little bit of context. I'm open to any suggestion and ready to hear from you.",https://www.reddit.com/r/LanguageTechnology/comments/mv2f32/use_nlp_to_detect_and_classify_emotion_in_text/,LanguageTechnology,t3_mv2f32,"Use NLP to detect and classify emotion in text Hi everyone! I'm currently trying to develop a text classification program that detects emotions and social instances from written text of individuals diagnosed with depression. I thought it'd be a good idea to use lists of words for specific categories in order to build a vocabulary, like for social words I used ""family, friends, girlfriend"" and so on. This classification task is still simple though because it doesn't take into account context and negation (""not happy"" = unhappy). For example, the program can detect a word like ""bad"" but that word could be unrelated, like ""bad driver"". That doesn't give me any hint about the emotional state of that person but ""bad"" still gets detected as part of ""bad driver"". The downside of making a vocabulary using a list is that it can't contain complex words such as ""pissed off"" because they're two words and the text is tokenized at the beginning of the process, so they are passed in as two different words, ""piss"" and ""off"".  I'm trying to implement bigrams to add a little bit of context. I'm open to any suggestion and ready to hear from you.",1144
326,326,Bitextor: a tool for generating translation memories from multilingual websites,,https://github.com/bitextor/bitextor,LanguageTechnology,t3_mur9ki,Bitextor: a tool for generating translation memories from multilingual websites ,80
327,327,"For binary classification, is it better to train with more focused examples?","I'm in the process of labeling data that I'll be using for an NLP binary classification project.  Some of my text is longer and some of it is shorter.  

If I have some text (call it two paragraphs), that exhibits traits of both classifications (label A and label not-A), is it better to break the text apart and apply the specific labels to each?  

Or is it better to keep the text together and apply just one of the labels (label A, since it does include some text that is ""A"")?  

If I keep the paragraphs together, I don't want the model to just learn that long text = A.  But if I break it apart, will the model struggle with longer text when it was only trained on single paragraphs?",https://www.reddit.com/r/LanguageTechnology/comments/muzfp7/for_binary_classification_is_it_better_to_train/,LanguageTechnology,t3_muzfp7,"For binary classification, is it better to train with more focused examples? I'm in the process of labeling data that I'll be using for an NLP binary classification project.  Some of my text is longer and some of it is shorter.  

If I have some text (call it two paragraphs), that exhibits traits of both classifications (label A and label not-A), is it better to break the text apart and apply the specific labels to each?  

Or is it better to keep the text together and apply just one of the labels (label A, since it does include some text that is ""A"")?  

If I keep the paragraphs together, I don't want the model to just learn that long text = A.  But if I break it apart, will the model struggle with longer text when it was only trained on single paragraphs?",767
328,328,"Researchers From NVIDIA, Stanford University and Microsoft Research Propose Efficient Trillion-Parameter Language Model Training on GPU Clusters (Paper and Github link included)","Large-scale transformer-based language models have produced significant gains in natural language processing (NLP) in recent years. However, training such models is difficult because no single GPU has enough memory to accommodate parameter totals that have grown exponentially in recent years. Even if these parameters could be trained on a single GPU, limited computing power would result in longer training times without model parallelism. 

In a [paper](https://arxiv.org/pdf/2104.04473.pdf) by NVIDIA, Stanford University, and Microsoft Research, a research team has proposed a new parallelization schedule that improves throughput by more than 10 percent with a comparable memory footprint. The paper demonstrated that such strategies could be composed to achieve high aggregate throughput when training large models with nearly a trillion parameters. 

Summary: [https://www.marktechpost.com/2021/04/19/researchers-from-nvidia-stanford-university-and-microsoft-research-propose-efficient-trillion-parameter-language-model-training-on-gpu-clusters/](https://www.marktechpost.com/2021/04/19/researchers-from-nvidia-stanford-university-and-microsoft-research-propose-efficient-trillion-parameter-language-model-training-on-gpu-clusters/) 

Paper: https://arxiv.org/pdf/2104.04473.pdf

Github: https://github.com/nvidia/megatron-lm",https://www.reddit.com/r/LanguageTechnology/comments/mufmdd/researchers_from_nvidia_stanford_university_and/,LanguageTechnology,t3_mufmdd,"Researchers From NVIDIA, Stanford University and Microsoft Research Propose Efficient Trillion-Parameter Language Model Training on GPU Clusters (Paper and Github link included) Large-scale transformer-based language models have produced significant gains in natural language processing (NLP) in recent years. However, training such models is difficult because no single GPU has enough memory to accommodate parameter totals that have grown exponentially in recent years. Even if these parameters could be trained on a single GPU, limited computing power would result in longer training times without model parallelism. 

In a [paper](https://arxiv.org/pdf/2104.04473.pdf) by NVIDIA, Stanford University, and Microsoft Research, a research team has proposed a new parallelization schedule that improves throughput by more than 10 percent with a comparable memory footprint. The paper demonstrated that such strategies could be composed to achieve high aggregate throughput when training large models with nearly a trillion parameters. 

Summary: [https://www.marktechpost.com/2021/04/19/researchers-from-nvidia-stanford-university-and-microsoft-research-propose-efficient-trillion-parameter-language-model-training-on-gpu-clusters/](https://www.marktechpost.com/2021/04/19/researchers-from-nvidia-stanford-university-and-microsoft-research-propose-efficient-trillion-parameter-language-model-training-on-gpu-clusters/) 

Paper: https://arxiv.org/pdf/2104.04473.pdf

Github: https://github.com/nvidia/megatron-lm",1511
329,329,Automatic Title Generation for Text with Transformer Language Model (Research Paper Walkthrough),,https://youtu.be/KhxHo_OQGtI,LanguageTechnology,t3_muo3fn,Automatic Title Generation for Text with Transformer Language Model (Research Paper Walkthrough) ,97
330,330,nlp project with biobert,"Hi everyone, 

I am currently doing a project where I am supposed to be using named entity recognition with models such as biobert to process clinical data and possibly link them to ICD (International Classification of Diseases) codes however I am currently extremely lost. 

I am planning on using spacy to do the pre-processing on the data however, I am unsure as to what format biobert needs the dataset in.

Would anyone be able to point me in the right direction?",https://www.reddit.com/r/LanguageTechnology/comments/muc80y/nlp_project_with_biobert/,LanguageTechnology,t3_muc80y,"nlp project with biobert Hi everyone, 

I am currently doing a project where I am supposed to be using named entity recognition with models such as biobert to process clinical data and possibly link them to ICD (International Classification of Diseases) codes however I am currently extremely lost. 

I am planning on using spacy to do the pre-processing on the data however, I am unsure as to what format biobert needs the dataset in.

Would anyone be able to point me in the right direction?",493
331,331,Named Entity Recognition and possible extensions such as Non-noun phrases,"Hey, people! Hope you are all well!

I've been reading some papers on NER and started to notice a development towards a more general and less strict definition of the task. Firstly, at MUC, only named mentions (proper nouns) would be considered. Then, at ACE, both nominal (common nouns) and pronominal phrases were added and also recursive mentions were considered. Further, other datasets kept exploring broader settings, like LitBank accepting personifications and recursive mentions in literary texts, HAREM enforcing ambiguity, etc.

As a part of this extension of the NER definition, do you believe that non-noun phrases can also be considered as mentions? Do you see other constructions being considered as mentions in the future?  

Also, if there are other interesting extensions you might know or believe may occur, please share!",https://www.reddit.com/r/LanguageTechnology/comments/mud88u/named_entity_recognition_and_possible_extensions/,LanguageTechnology,t3_mud88u,"Named Entity Recognition and possible extensions such as Non-noun phrases Hey, people! Hope you are all well!

I've been reading some papers on NER and started to notice a development towards a more general and less strict definition of the task. Firstly, at MUC, only named mentions (proper nouns) would be considered. Then, at ACE, both nominal (common nouns) and pronominal phrases were added and also recursive mentions were considered. Further, other datasets kept exploring broader settings, like LitBank accepting personifications and recursive mentions in literary texts, HAREM enforcing ambiguity, etc.

As a part of this extension of the NER definition, do you believe that non-noun phrases can also be considered as mentions? Do you see other constructions being considered as mentions in the future?  

Also, if there are other interesting extensions you might know or believe may occur, please share!",913
332,332,NLP and Mathematical Generation?,"Hello everyone,

I am currently developing a system (for one of my thesis components) which analyses the mathematical relationships between numbers extracted from a given text and generates alternatives, unfortunately there are requirements such that the numbers can't be negative of a majority of 0.

I am currently making improvements on my current system however I think it would be wise to look at more feasible alternatives as this is for my thesis however I have not found any previous work in this niche. Does anyone have any ideas on this front please?",https://www.reddit.com/r/LanguageTechnology/comments/mu5x5k/nlp_and_mathematical_generation/,LanguageTechnology,t3_mu5x5k,"NLP and Mathematical Generation? Hello everyone,

I am currently developing a system (for one of my thesis components) which analyses the mathematical relationships between numbers extracted from a given text and generates alternatives, unfortunately there are requirements such that the numbers can't be negative of a majority of 0.

I am currently making improvements on my current system however I think it would be wise to look at more feasible alternatives as this is for my thesis however I have not found any previous work in this niche. Does anyone have any ideas on this front please?",593
333,333,NLP Help | Scraping Question,"Hello, 

I have a few hundred txt documents, each containing a few sentences about someone's history with substance abuse. 

Based on 2 types of substances, I am trying to go through each file and collect the frequencies of 4 entities: **status** (e.g., past, current, none), **method** (e.g., inhale, chew), **amount** (e.g., 2 packs, 3-4 glasses), and **frequency** (e.g., a day). 

Example txt file: ""He does not use tobacco. He sometimes drinks wine. He does not use drugs ever."" 

**My dilemma:** again, I need to scrape the frequencies of these entities (essentially attributes of some type of substance abuse), ***but the wording/sentence structure varies a lot*** \--&gt; the **status** entity, for example, could see 'past', 'currently', 'still', 'sometimes', 'on weekends', 'back in 1984', etc... just a whole lot of things. I think I need to employ some NLP technique to classify/annotate this stuff but I am not sure how. **Any ideas?**

Thank you so much for your consideration.",https://www.reddit.com/r/LanguageTechnology/comments/mtvquw/nlp_help_scraping_question/,LanguageTechnology,t3_mtvquw,"NLP Help | Scraping Question Hello, 

I have a few hundred txt documents, each containing a few sentences about someone's history with substance abuse. 

Based on 2 types of substances, I am trying to go through each file and collect the frequencies of 4 entities: **status** (e.g., past, current, none), **method** (e.g., inhale, chew), **amount** (e.g., 2 packs, 3-4 glasses), and **frequency** (e.g., a day). 

Example txt file: ""He does not use tobacco. He sometimes drinks wine. He does not use drugs ever."" 

**My dilemma:** again, I need to scrape the frequencies of these entities (essentially attributes of some type of substance abuse), ***but the wording/sentence structure varies a lot*** \--&gt; the **status** entity, for example, could see 'past', 'currently', 'still', 'sometimes', 'on weekends', 'back in 1984', etc... just a whole lot of things. I think I need to employ some NLP technique to classify/annotate this stuff but I am not sure how. **Any ideas?**

Thank you so much for your consideration.",1020
334,334,NLP and Skill Transfer,"I would like to start a career in NLP. Before investing my time in NLP, I would like to know if the skills needed in NLP can be transferred to another fields or not. For example, if in the future I want to work in DSP( digital signal processing), or Image processing, can NLP skills applied in these fields? 


Thank you very much! 

Note: I am asking because tomorrow I have an interview for  NLP job in a startup company. My background is CS, networking and a limited knowledge in Genetic algorithms  .

Edit: language mistakes",https://www.reddit.com/r/LanguageTechnology/comments/mu3v2m/nlp_and_skill_transfer/,LanguageTechnology,t3_mu3v2m,"NLP and Skill Transfer I would like to start a career in NLP. Before investing my time in NLP, I would like to know if the skills needed in NLP can be transferred to another fields or not. For example, if in the future I want to work in DSP( digital signal processing), or Image processing, can NLP skills applied in these fields? 


Thank you very much! 

Note: I am asking because tomorrow I have an interview for  NLP job in a startup company. My background is CS, networking and a limited knowledge in Genetic algorithms  .

Edit: language mistakes",552
335,335,WHY DO I KEEP RUNNING OUT OF MEMORY (RAM),"Guys I am trying to develop a BERT model that basically predicts an emotion. (Emotion classifier)

I never got a chance to eventually finish my training because I every time run out of Memory Ram

I tried Google Colab (ran out of memory) then tried Kaggle Kernel (ran out of space as well), both 12 and 16 GB RAM.

I do not know what is wrong with it? how people even train this type of model?

&amp;#x200B;

    ......DATA LOADING AND PREPROCESSING...
    
    !pip install deeppavlov
    from deeppavlov.dataset_readers.basic_classification_reader import BasicClassificationDatasetReader
    data = BasicClassificationDatasetReader().read(
        data_path='./',
        train='../input/pikabucsva/train_pikabu_a.csv',
        valid=""../input/pikabucsva/validation_pikabu_a.csv"", 
        test=""../input/pikabucsva/test_pikabu_a.csv"",
        x = 'content',
        y = 'emotions'
    )
    
    #ITERATOR
    from deeppavlov.dataset_iterators.basic_classification_iterator import BasicClassificationDatasetIterator
    # initializing an iterator
    iterator = BasicClassificationDatasetIterator(data, seed=42, shuffle=True)
    
    #BERT PREPROCESSOR
    !python -m deeppavlov install squad_bert
    from deeppavlov.models.preprocessors.bert_preprocessor import BertPreprocessor
    bert_preprocessor = BertPreprocessor(vocab_file=""../input/bertmodel/vocab.txt"",
                                         do_lower_case=False,
                                         max_seq_length=64)
    
    #SIMPLE VOCABULARY
    from deeppavlov.core.data.simple_vocab import SimpleVocabulary
    vocab = SimpleVocabulary(save_path=""./binary_classes.dict"")
    
    
    #ONEHOTTER
    from deeppavlov.models.preprocessors.one_hotter import OneHotter
    one_hotter = OneHotter(depth=vocab.len, 
                           single_vector=True  # means we want to have one vector per sample
                          )
    #PROB TO LABELS
    from deeppavlov.models.classifiers.proba2labels import Proba2Labels
    prob2labels = Proba2Labels(max_proba=True)
    vocab(prob2labels([[0.6, 0.4], 
                       [0.2, 0.8],
                       [0.1, 0.9]]))
    
    
    #BERT CLASSIFIER
    from deeppavlov.models.bert.bert_classifier import BertClassifierModel
    from deeppavlov.metrics.accuracy import sets_accuracy
    
    bert_classifier = BertClassifierModel(
        n_classes=vocab.len,
        return_probas=True,
        one_hot_labels=True,
        bert_config_file=""../input/bertmodel/bert_config.json"",
        pretrained_bert=""../input/bertmodel/bert_model.ckpt"",
        save_path=""sst_bert_model/model"",
        load_path=""sst_bert_model/model"",
        keep_prob=0.5,
        learning_rate=1e-05,
        learning_rate_drop_patience=5,
        learning_rate_drop_div=2.0
        )
    
    #TRAINING
    # Method `get_instances` returns all the samples of particular data field
    x_valid, y_valid = iterator.get_instances(data_type=""valid"")
    # You need to save model only when validation score is higher than previous one.
    # This variable will contain the highest accuracy score
    best_score = 0.
    patience = 2
    impatience = 0
    
    # let's train for 3 epochs
    for ep in range(3):
      
        nbatches = 0
        for x, y in iterator.gen_batches(batch_size=256, 
                                         data_type=""train"", shuffle=True):
            x_feat = bert_preprocessor(x)
            y_onehot = one_hotter(vocab(y))
            bert_classifier.train_on_batch(x_feat, y_onehot)
            print(""Batch done\n"")
            nbatches += 1
            
            if nbatches % 1 == 0:
                # валидируемся каждые 100 батчей
                y_valid_pred = bert_classifier(bert_preprocessor(x_valid))
                score = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))
                print(""Batches done: {}. Valid Accuracy: {}"".format(nbatches, score))
                
        y_valid_pred = bert_classifier(bert_preprocessor(x_valid))
        score = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))
        print(""Epochs done: {}. Valid Accuracy: {}"".format(ep + 1, score))
        if score &gt; best_score:
            bert_classifier.save()
            print(""New best score. Saving model."")
            best_score = score    
            impatience = 0
        else:
            impatience += 1
            if impatience == patience:
                print(""Out of patience. Stop training."")
                break",https://www.reddit.com/r/LanguageTechnology/comments/muf1be/why_do_i_keep_running_out_of_memory_ram/,LanguageTechnology,t3_muf1be,"WHY DO I KEEP RUNNING OUT OF MEMORY (RAM) Guys I am trying to develop a BERT model that basically predicts an emotion. (Emotion classifier)

I never got a chance to eventually finish my training because I every time run out of Memory Ram

I tried Google Colab (ran out of memory) then tried Kaggle Kernel (ran out of space as well), both 12 and 16 GB RAM.

I do not know what is wrong with it? how people even train this type of model?

&amp;#x200B;

    ......DATA LOADING AND PREPROCESSING...
    
    !pip install deeppavlov
    from deeppavlov.dataset_readers.basic_classification_reader import BasicClassificationDatasetReader
    data = BasicClassificationDatasetReader().read(
        data_path='./',
        train='../input/pikabucsva/train_pikabu_a.csv',
        valid=""../input/pikabucsva/validation_pikabu_a.csv"", 
        test=""../input/pikabucsva/test_pikabu_a.csv"",
        x = 'content',
        y = 'emotions'
    )
    
    #ITERATOR
    from deeppavlov.dataset_iterators.basic_classification_iterator import BasicClassificationDatasetIterator
    # initializing an iterator
    iterator = BasicClassificationDatasetIterator(data, seed=42, shuffle=True)
    
    #BERT PREPROCESSOR
    !python -m deeppavlov install squad_bert
    from deeppavlov.models.preprocessors.bert_preprocessor import BertPreprocessor
    bert_preprocessor = BertPreprocessor(vocab_file=""../input/bertmodel/vocab.txt"",
                                         do_lower_case=False,
                                         max_seq_length=64)
    
    #SIMPLE VOCABULARY
    from deeppavlov.core.data.simple_vocab import SimpleVocabulary
    vocab = SimpleVocabulary(save_path=""./binary_classes.dict"")
    
    
    #ONEHOTTER
    from deeppavlov.models.preprocessors.one_hotter import OneHotter
    one_hotter = OneHotter(depth=vocab.len, 
                           single_vector=True  # means we want to have one vector per sample
                          )
    #PROB TO LABELS
    from deeppavlov.models.classifiers.proba2labels import Proba2Labels
    prob2labels = Proba2Labels(max_proba=True)
    vocab(prob2labels([[0.6, 0.4], 
                       [0.2, 0.8],
                       [0.1, 0.9]]))
    
    
    #BERT CLASSIFIER
    from deeppavlov.models.bert.bert_classifier import BertClassifierModel
    from deeppavlov.metrics.accuracy import sets_accuracy
    
    bert_classifier = BertClassifierModel(
        n_classes=vocab.len,
        return_probas=True,
        one_hot_labels=True,
        bert_config_file=""../input/bertmodel/bert_config.json"",
        pretrained_bert=""../input/bertmodel/bert_model.ckpt"",
        save_path=""sst_bert_model/model"",
        load_path=""sst_bert_model/model"",
        keep_prob=0.5,
        learning_rate=1e-05,
        learning_rate_drop_patience=5,
        learning_rate_drop_div=2.0
        )
    
    #TRAINING
    # Method `get_instances` returns all the samples of particular data field
    x_valid, y_valid = iterator.get_instances(data_type=""valid"")
    # You need to save model only when validation score is higher than previous one.
    # This variable will contain the highest accuracy score
    best_score = 0.
    patience = 2
    impatience = 0
    
    # let's train for 3 epochs
    for ep in range(3):
      
        nbatches = 0
        for x, y in iterator.gen_batches(batch_size=256, 
                                         data_type=""train"", shuffle=True):
            x_feat = bert_preprocessor(x)
            y_onehot = one_hotter(vocab(y))
            bert_classifier.train_on_batch(x_feat, y_onehot)
            print(""Batch done\n"")
            nbatches += 1
            
            if nbatches % 1 == 0:
                # валидируемся каждые 100 батчей
                y_valid_pred = bert_classifier(bert_preprocessor(x_valid))
                score = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))
                print(""Batches done: {}. Valid Accuracy: {}"".format(nbatches, score))
                
        y_valid_pred = bert_classifier(bert_preprocessor(x_valid))
        score = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))
        print(""Epochs done: {}. Valid Accuracy: {}"".format(ep + 1, score))
        if score &gt; best_score:
            bert_classifier.save()
            print(""New best score. Saving model."")
            best_score = score    
            impatience = 0
        else:
            impatience += 1
            if impatience == patience:
                print(""Out of patience. Stop training."")
                break",4545
336,336,production-ready NLP/NLU for restaurants?,"Hi

about 3 years ago Google showed a demo in which a human-sounding ""AI assistant"" made a phone call to a shop (a hairdresser, if I remember well). Is anybody using this technology in production, for example to accept restaurant/takeaway orders? Is DialogFlow production-ready? What's the SOTA in this field?

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/mu0rxw/productionready_nlpnlu_for_restaurants/,LanguageTechnology,t3_mu0rxw,"production-ready NLP/NLU for restaurants? Hi

about 3 years ago Google showed a demo in which a human-sounding ""AI assistant"" made a phone call to a shop (a hairdresser, if I remember well). Is anybody using this technology in production, for example to accept restaurant/takeaway orders? Is DialogFlow production-ready? What's the SOTA in this field?

Thanks!",360
337,337,A Rigorous Study on Pretrained Model for NER | Research Papers Summary 014,,https://youtu.be/rL6FvknTdKw,LanguageTechnology,t3_mtixvt,A Rigorous Study on Pretrained Model for NER | Research Papers Summary 014 ,75
338,338,Tutorial on how to specify a large formula for a regression model,"Hey, I've created a tutorial on how to specify a large formula for a regression model using the R programming language. The tutorial shows different tips and tricks to make your code more efficient: [https://statisticsglobe.com/write-model-formula-with-many-variables-in-r](https://statisticsglobe.com/write-model-formula-with-many-variables-in-r)",https://www.reddit.com/r/LanguageTechnology/comments/mtvm0d/tutorial_on_how_to_specify_a_large_formula_for_a/,LanguageTechnology,t3_mtvm0d,"Tutorial on how to specify a large formula for a regression model Hey, I've created a tutorial on how to specify a large formula for a regression model using the R programming language. The tutorial shows different tips and tricks to make your code more efficient: [https://statisticsglobe.com/write-model-formula-with-many-variables-in-r](https://statisticsglobe.com/write-model-formula-with-many-variables-in-r)",413
339,339,Generating Datasets with Pretrained Language Models,"In our most recent paper, we introduce ""Datasets from Instructions"" (DINO 🦕) and show how LMs can create entire datasets from scratch if provided with instructions. These datasets can be used to train much smaller models.

This is an early draft, so I'd be very happy to hear your thoughts 😊

📄 Paper: https://arxiv.org/abs/2104.07540

🖥️ Code: https://github.com/timoschick/dino",https://www.reddit.com/r/LanguageTechnology/comments/mtacs2/generating_datasets_with_pretrained_language/,LanguageTechnology,t3_mtacs2,"Generating Datasets with Pretrained Language Models In our most recent paper, we introduce ""Datasets from Instructions"" (DINO 🦕) and show how LMs can create entire datasets from scratch if provided with instructions. These datasets can be used to train much smaller models.

This is an early draft, so I'd be very happy to hear your thoughts 😊

📄 Paper: https://arxiv.org/abs/2104.07540

🖥️ Code: https://github.com/timoschick/dino",431
340,340,BART: Denoising Sequence-to-Sequence Pre-training for NLG (Research Paper Walkthrough),,https://youtu.be/BGWpNQHIcs4,LanguageTechnology,t3_mt7zun,BART: Denoising Sequence-to-Sequence Pre-training for NLG (Research Paper Walkthrough) ,87
341,341,Does anyone know of any biomedical entity search engines out there?,"I'm doing some research on biomedical language models and would like to use search engines as a baseline. What I have in mind is something like the [Biomedical Entity Search Tool (BEST)](http://best.korea.ac.kr/). Polysearch is also a candidate, but for some reason it's not working anymore.

I'd appreciate it if someone who knows of other search engines like these ones would be able to provide some tips on where I could find more. Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/mta54d/does_anyone_know_of_any_biomedical_entity_search/,LanguageTechnology,t3_mta54d,"Does anyone know of any biomedical entity search engines out there? I'm doing some research on biomedical language models and would like to use search engines as a baseline. What I have in mind is something like the [Biomedical Entity Search Tool (BEST)](http://best.korea.ac.kr/). Polysearch is also a candidate, but for some reason it's not working anymore.

I'd appreciate it if someone who knows of other search engines like these ones would be able to provide some tips on where I could find more. Thanks!",510
342,342,Deciding between Saarland and Gothenburg,"Hello everyone!

Over the last few months I've been knee deep in the process for applying to grad school in compling/language technology, and now that decisions have come back I'm left with the choice between programs at Saarland University and the University of Gothenburg.

My research so far has favored Saarland: it's often mentioned in online forums and lists of the best compling universities, it ranks highly in the CSRankings for NLP in Europe (number 6 is you only consider English language master programs), and appears to be well regarded on this subreddit. Gothenburg, on the other hand, is rarely if ever mentioned, and ranks in the 50s in CSRankings for NLP in Europe. Indeed, I only applied for Gothenburg at the suggestion of a friend who goes there, when I was panicking after getting rejected from Edinburgh (which came as a surprise, given that it was my alma mater).

While this may appear to be an open and shut case, given the above, as far as I can tell Gothenburg does appear to have one major advantage over Saarland: job placement. According to my friend, Gothenburg works closely with Swedish tech firms to place its students, and indeed it actively encourages and facilitates collaborating with local firms on your dissertation. Saarland, on the other hand, does not appear to provide this level of support: according to the Saarland program's study coordinator, Saarland does not offer individual support for placement, and it appears that the university's relationship with local companies is not a strong as Gothenburg's appears to be.

My question is, does anyone here have experience with Saarland in terms of career placement? And is Saarland truly a better overall choice than Gothenburg?

Thank you in advance!",https://www.reddit.com/r/LanguageTechnology/comments/mtestc/deciding_between_saarland_and_gothenburg/,LanguageTechnology,t3_mtestc,"Deciding between Saarland and Gothenburg Hello everyone!

Over the last few months I've been knee deep in the process for applying to grad school in compling/language technology, and now that decisions have come back I'm left with the choice between programs at Saarland University and the University of Gothenburg.

My research so far has favored Saarland: it's often mentioned in online forums and lists of the best compling universities, it ranks highly in the CSRankings for NLP in Europe (number 6 is you only consider English language master programs), and appears to be well regarded on this subreddit. Gothenburg, on the other hand, is rarely if ever mentioned, and ranks in the 50s in CSRankings for NLP in Europe. Indeed, I only applied for Gothenburg at the suggestion of a friend who goes there, when I was panicking after getting rejected from Edinburgh (which came as a surprise, given that it was my alma mater).

While this may appear to be an open and shut case, given the above, as far as I can tell Gothenburg does appear to have one major advantage over Saarland: job placement. According to my friend, Gothenburg works closely with Swedish tech firms to place its students, and indeed it actively encourages and facilitates collaborating with local firms on your dissertation. Saarland, on the other hand, does not appear to provide this level of support: according to the Saarland program's study coordinator, Saarland does not offer individual support for placement, and it appears that the university's relationship with local companies is not a strong as Gothenburg's appears to be.

My question is, does anyone here have experience with Saarland in terms of career placement? And is Saarland truly a better overall choice than Gothenburg?

Thank you in advance!",1787
343,343,Word embeddings and neural machine translation,"Can someone help me understand what is the purpose of word embeddings in neural machine translation models? 

I understand (mostly) he word embeddings in the context of sentiment analysis and other tasks, but what purpose does it have in the context of neural machine translation? Doesn't the neural model learn everything itself without needing any embedding space?",https://www.reddit.com/r/LanguageTechnology/comments/mtb0c7/word_embeddings_and_neural_machine_translation/,LanguageTechnology,t3_mtb0c7,"Word embeddings and neural machine translation Can someone help me understand what is the purpose of word embeddings in neural machine translation models? 

I understand (mostly) he word embeddings in the context of sentiment analysis and other tasks, but what purpose does it have in the context of neural machine translation? Doesn't the neural model learn everything itself without needing any embedding space?",413
344,344,DUC 2004 Dataset,"Many of you were asking for the DUC 2004 dataset. Although it is available through their website, I have also uploaded it to GitHub and Kaggle for a better workflow. You can download it from here. 

&amp;#x200B;

 [UsmanNiazi/DUC-2004-Dataset: This Repo Contains the DUC 2004 Dataset (github.com)](https://github.com/UsmanNiazi/DUC-2004-Dataset)   


 [DUC 2004 Dataset | Kaggle](https://www.kaggle.com/usmanniazi/duc-2004-dataset)",https://www.reddit.com/r/LanguageTechnology/comments/mt3228/duc_2004_dataset/,LanguageTechnology,t3_mt3228,"DUC 2004 Dataset Many of you were asking for the DUC 2004 dataset. Although it is available through their website, I have also uploaded it to GitHub and Kaggle for a better workflow. You can download it from here. 

&amp;#x200B;

 [UsmanNiazi/DUC-2004-Dataset: This Repo Contains the DUC 2004 Dataset (github.com)](https://github.com/UsmanNiazi/DUC-2004-Dataset)   


 [DUC 2004 Dataset | Kaggle](https://www.kaggle.com/usmanniazi/duc-2004-dataset)",448
345,345,Why is batch size a relevant hyperparameter for BERT?,"BERT is made up of Transformer encoders, and therefore uses layer normalization instead of batch normalization. Layer normalization normalizes each datapoint independently from other datapoints in the batch. So why would batch size matter for BERT's performance? Where else does it factor in?",https://www.reddit.com/r/LanguageTechnology/comments/mt9ex7/why_is_batch_size_a_relevant_hyperparameter_for/,LanguageTechnology,t3_mt9ex7,"Why is batch size a relevant hyperparameter for BERT? BERT is made up of Transformer encoders, and therefore uses layer normalization instead of batch normalization. Layer normalization normalizes each datapoint independently from other datapoints in the batch. So why would batch size matter for BERT's performance? Where else does it factor in?",346
346,346,Please give me some suggestions.,"I’m doing a school project which is building a chatbot to help students learn English and give tips for the TOEIC test (I dont come from English native speaking country), so far my ideas are using masked language models to help solving the reading test in TOEIC and I’m kinda stuck there. Can you give me some suggestions of what to implement and maybe some SOTA open source chatbots and how to tune it into specific domain (English and TOEIC) that would be super life saving. Thanks in advance",https://www.reddit.com/r/LanguageTechnology/comments/mt3xp2/please_give_me_some_suggestions/,LanguageTechnology,t3_mt3xp2,"Please give me some suggestions. I’m doing a school project which is building a chatbot to help students learn English and give tips for the TOEIC test (I dont come from English native speaking country), so far my ideas are using masked language models to help solving the reading test in TOEIC and I’m kinda stuck there. Can you give me some suggestions of what to implement and maybe some SOTA open source chatbots and how to tune it into specific domain (English and TOEIC) that would be super life saving. Thanks in advance",527
347,347,Project NLP / ML from scratch - Beginner,"Hi All, 

I am writing here because I wish to get in touch with those brilliant minds that are active in the group and learning from them :)   
In a course about Finance, I saw how I could use TextBlob and Scrapy on ICO whitepapers and how to exploit experts´ posts in [icobench.com](https://icobench.com) to determine a sentiment - based on Bayes Classifier. We have used Python. 

My goal is to demonstrate that I can be a point of reference for NLP and ML in a company (relative terms). I would proceed following: 

* Setup scraper/crawler to obtain data from several websites
* Store the data in google firebase /firestore
* Cleanup the data for ML
* Create a training set/test set
* Build a ML model (classification/prediction)
* Measure effectiveness
* Report on what I did 

A) Do you suggest me to be familiar first to Vue.js? I have no experience with HTML, CSS and java and I assume that crawl data &gt; store &gt; clean &gt; give label would take a relevant amount of time.

B) If I build a text corpus from wikipedia and use it for my data, which are the problems that I may encounter and take into account? Fx the text blob offers a classifier from movie database but if you apply it on another context like finance, then you need specific label for certain words. 

C) Which models can be more interesting to compare? 

I thank you in advance for the attention given to this post. 

  
Have a good weekend",https://www.reddit.com/r/LanguageTechnology/comments/mssi5w/project_nlp_ml_from_scratch_beginner/,LanguageTechnology,t3_mssi5w,"Project NLP / ML from scratch - Beginner Hi All, 

I am writing here because I wish to get in touch with those brilliant minds that are active in the group and learning from them :)   
In a course about Finance, I saw how I could use TextBlob and Scrapy on ICO whitepapers and how to exploit experts´ posts in [icobench.com](https://icobench.com) to determine a sentiment - based on Bayes Classifier. We have used Python. 

My goal is to demonstrate that I can be a point of reference for NLP and ML in a company (relative terms). I would proceed following: 

* Setup scraper/crawler to obtain data from several websites
* Store the data in google firebase /firestore
* Cleanup the data for ML
* Create a training set/test set
* Build a ML model (classification/prediction)
* Measure effectiveness
* Report on what I did 

A) Do you suggest me to be familiar first to Vue.js? I have no experience with HTML, CSS and java and I assume that crawl data &gt; store &gt; clean &gt; give label would take a relevant amount of time.

B) If I build a text corpus from wikipedia and use it for my data, which are the problems that I may encounter and take into account? Fx the text blob offers a classifier from movie database but if you apply it on another context like finance, then you need specific label for certain words. 

C) Which models can be more interesting to compare? 

I thank you in advance for the attention given to this post. 

  
Have a good weekend",1460
348,348,Di resources,What are some good document intelligence resources to begin with?,https://www.reddit.com/r/LanguageTechnology/comments/mswji6/di_resources/,LanguageTechnology,t3_mswji6,Di resources What are some good document intelligence resources to begin with?,78
349,349,Benchmarking of pretrained models for semantic textual similarity,"Hello community!

So basically what we want to achieve is a benchmarking of pretrained models in order to find out which ones are the most useful/efficient for calculating semantinc text similarity and whether one multi-lingual model would do, or separate models are better for this case (it's nothing really serious, this is for a scholar project but not the study per-se, just a way for us to argument a choice)

The context is not bound to a particular field. In practice, we will be comparing sentences from documents from any and all fields (a situation similar to plagiarism detection) so fine-tuning on a field-specific corpus is not an option and we will test the models as-is.

We are seeking recommendation:

* **For the corpora**: We will be benchmarking for languages other than english (but english is also included). Where can we find parallel corpora (for each language) that are suitable for this task? if not, what means can we use to build a small corpus of our own without doing manual paraphrase
* **For the metrics**: Is cosine distance good enough for the comparison? (by taking 1.0 as the perfect similarity score and the averages of all cosine distances accross the corpus, it will be pretty much like an accuracy  score).
   * What metrics/distances are better suited for the comparison, and what would you recommend for textual similarity in general?

oh and one last point that is not related to this benchmarking in particular. Supposing we have two documents (for instance 2 research papers) that we want to compare agaisnt eachother:

* What tokenization strategy would you recommend, considering we will compare the tokens from document 1 to those of document 2, then highlight the matching text in both documents (again, the usecase is very similar to plagiarism detection). The goal is minimal pairs loss.

Tokenization by sentence/punctuation doesn't seem to play nicely  as sentences in one document can be very long and can include many sentences of the second.

&amp;#x200B;",https://www.reddit.com/r/LanguageTechnology/comments/msh1sk/benchmarking_of_pretrained_models_for_semantic/,LanguageTechnology,t3_msh1sk,"Benchmarking of pretrained models for semantic textual similarity Hello community!

So basically what we want to achieve is a benchmarking of pretrained models in order to find out which ones are the most useful/efficient for calculating semantinc text similarity and whether one multi-lingual model would do, or separate models are better for this case (it's nothing really serious, this is for a scholar project but not the study per-se, just a way for us to argument a choice)

The context is not bound to a particular field. In practice, we will be comparing sentences from documents from any and all fields (a situation similar to plagiarism detection) so fine-tuning on a field-specific corpus is not an option and we will test the models as-is.

We are seeking recommendation:

* **For the corpora**: We will be benchmarking for languages other than english (but english is also included). Where can we find parallel corpora (for each language) that are suitable for this task? if not, what means can we use to build a small corpus of our own without doing manual paraphrase
* **For the metrics**: Is cosine distance good enough for the comparison? (by taking 1.0 as the perfect similarity score and the averages of all cosine distances accross the corpus, it will be pretty much like an accuracy  score).
   * What metrics/distances are better suited for the comparison, and what would you recommend for textual similarity in general?

oh and one last point that is not related to this benchmarking in particular. Supposing we have two documents (for instance 2 research papers) that we want to compare agaisnt eachother:

* What tokenization strategy would you recommend, considering we will compare the tokens from document 1 to those of document 2, then highlight the matching text in both documents (again, the usecase is very similar to plagiarism detection). The goal is minimal pairs loss.

Tokenization by sentence/punctuation doesn't seem to play nicely  as sentences in one document can be very long and can include many sentences of the second.

&amp;#x200B;",2077
350,350,"Links to nlp applied projects/thesis relating to ""law/legal""","Can anyone recommend any projects, thesis available online in which nlp methods are applied to data from the legal/law domain? I am trying to learn more about this topic, and so far couldnt find anything other than the ""LEGALBert"" paper.

Does anyone recommend checking out any masters university projects where nlp was applied to data from the legal domain? I already know the basics *about word clouds, lda topic modelling and sentiment analysis - I am looking for a bit more intermediate level stuff about information extraction, transfer learning, summarization, fuzzy match, etc. 

Thanks",https://www.reddit.com/r/LanguageTechnology/comments/msaync/links_to_nlp_applied_projectsthesis_relating_to/,LanguageTechnology,t3_msaync,"Links to nlp applied projects/thesis relating to ""law/legal"" Can anyone recommend any projects, thesis available online in which nlp methods are applied to data from the legal/law domain? I am trying to learn more about this topic, and so far couldnt find anything other than the ""LEGALBert"" paper.

Does anyone recommend checking out any masters university projects where nlp was applied to data from the legal domain? I already know the basics *about word clouds, lda topic modelling and sentiment analysis - I am looking for a bit more intermediate level stuff about information extraction, transfer learning, summarization, fuzzy match, etc. 

Thanks",654
351,351,MA in Linguistic and Literary Computing (TU Darmstadt): Thoughts?,"Hello, fellow Subredditors!

I'm curious to know if any of you are familiar with this program and if you could share your opinion about it.

I have a BA in Linguistics and I've done some work during my degree with corpora and have some experience in programming, specifically in Python. Mostly computer applications for linguistic research and digital humanities, more than anything else. I'm interested in studying a master's degree and Germany (for many reasons) is my place of choice. I've already looked at the programs at Tübingen and Stuttgart and the info I've seen on this subreddit about those two has been very useful. However, I haven't found much about the program at Darmstadt, and I'm particularly interested in this program, given its digital humanities component.

I would really appreciate your input! Thanks a lot!",https://www.reddit.com/r/LanguageTechnology/comments/ms63a1/ma_in_linguistic_and_literary_computing_tu/,LanguageTechnology,t3_ms63a1,"MA in Linguistic and Literary Computing (TU Darmstadt): Thoughts? Hello, fellow Subredditors!

I'm curious to know if any of you are familiar with this program and if you could share your opinion about it.

I have a BA in Linguistics and I've done some work during my degree with corpora and have some experience in programming, specifically in Python. Mostly computer applications for linguistic research and digital humanities, more than anything else. I'm interested in studying a master's degree and Germany (for many reasons) is my place of choice. I've already looked at the programs at Tübingen and Stuttgart and the info I've seen on this subreddit about those two has been very useful. However, I haven't found much about the program at Darmstadt, and I'm particularly interested in this program, given its digital humanities component.

I would really appreciate your input! Thanks a lot!",898
352,352,[D] WTF these results are incredible?!! What do you guys think of this? BERT seems to learn equally well on word-shuffled sentences?,"Link to paper: https://arxiv.org/abs/2104.06644

Is BERT just a giant bag-of-words??

Relevant meme: https://imgur.com/a/RGUtOvt",https://www.reddit.com/r/LanguageTechnology/comments/mrrcda/d_wtf_these_results_are_incredible_what_do_you/,LanguageTechnology,t3_mrrcda,"[D] WTF these results are incredible?!! What do you guys think of this? BERT seems to learn equally well on word-shuffled sentences? Link to paper: https://arxiv.org/abs/2104.06644

Is BERT just a giant bag-of-words??

Relevant meme: https://imgur.com/a/RGUtOvt",261
353,353,Text Generation from Another Text,"Hi everyone. I want to ask you if this is possible:

Consider we have a minimal text, or just a couple of keywords, say X. And we have another large text or corpus, Y, that we assume they are about similar topics. Assume that X is a sentence and Y is a book.

Is it possible to generate a text Z that may be to an answer or comment to X that using facts or style from Y?

E.g. consider X is a text or keywords like ""I like to swim in Maldives!"". Y is a news about Maldives. Then Z might be a generated text like ""Maldives has the most clean beaches in the world.""

Thank you all.",https://www.reddit.com/r/LanguageTechnology/comments/mrywon/text_generation_from_another_text/,LanguageTechnology,t3_mrywon,"Text Generation from Another Text Hi everyone. I want to ask you if this is possible:

Consider we have a minimal text, or just a couple of keywords, say X. And we have another large text or corpus, Y, that we assume they are about similar topics. Assume that X is a sentence and Y is a book.

Is it possible to generate a text Z that may be to an answer or comment to X that using facts or style from Y?

E.g. consider X is a text or keywords like ""I like to swim in Maldives!"". Y is a news about Maldives. Then Z might be a generated text like ""Maldives has the most clean beaches in the world.""

Thank you all.",613
354,354,The first ever Gesture Generation Challenge. More info in comments,,https://youtu.be/ja7IXGFrYGA,LanguageTechnology,t3_mrh9zp,The first ever Gesture Generation Challenge. More info in comments ,67
355,355,NLP equivalent to speaker diarization?,,/r/learnmachinelearning/comments/mrmaym/equivalent_to_speaker_diarization_for_books/,LanguageTechnology,t3_mrmc87,NLP equivalent to speaker diarization? ,39
356,356,Classification problem with text and numerical features,"I am working on a classification problem whose data includes both text and numerical features. My first approach to tacke this problem was to convert the text features into embeddings and append those as new features to original dataset. The problem with approach is that since embeddings are usually of high dimensions, they overwhelm the numerical features.

Second approach I used was append every feature together into a string, convert it into embedding and train the model. This gave me very poor accuracy.

Is there any other way I can handle this problem?",https://www.reddit.com/r/LanguageTechnology/comments/mr8rsi/classification_problem_with_text_and_numerical/,LanguageTechnology,t3_mr8rsi,"Classification problem with text and numerical features I am working on a classification problem whose data includes both text and numerical features. My first approach to tacke this problem was to convert the text features into embeddings and append those as new features to original dataset. The problem with approach is that since embeddings are usually of high dimensions, they overwhelm the numerical features.

Second approach I used was append every feature together into a string, convert it into embedding and train the model. This gave me very poor accuracy.

Is there any other way I can handle this problem?",619
357,357,Aspect analysis,Best method for aspect analysis ??,https://www.reddit.com/r/LanguageTechnology/comments/mrecsh/aspect_analysis/,LanguageTechnology,t3_mrecsh,Aspect analysis Best method for aspect analysis ??,50
358,358,How to do undergrad research the right way?,"I just graduated with a degree in CS and now I'm interested in doing research in NLP. The material available online, ever-changing technology and also the hype makes me overwhelmed. Also the real research happens at the PhD level which is far too above from an undergrad level. How do I approach things? Will reading more papers and learning more about the theory helps? Or should I just dive into the practical parts and start using pretrained models and libraries? 

The way I like to do things is first to have a solid theoretical foundations of a certain topic after which I look around for implementations. I am more of a theory person, but NLP is more practical than theory. 

My goal is to focus on only 1 field for my future studies and I've chosen Nlp. Now I want to get good at it, but it's not clear how?",https://www.reddit.com/r/LanguageTechnology/comments/mqwzpv/how_to_do_undergrad_research_the_right_way/,LanguageTechnology,t3_mqwzpv,"How to do undergrad research the right way? I just graduated with a degree in CS and now I'm interested in doing research in NLP. The material available online, ever-changing technology and also the hype makes me overwhelmed. Also the real research happens at the PhD level which is far too above from an undergrad level. How do I approach things? Will reading more papers and learning more about the theory helps? Or should I just dive into the practical parts and start using pretrained models and libraries? 

The way I like to do things is first to have a solid theoretical foundations of a certain topic after which I look around for implementations. I am more of a theory person, but NLP is more practical than theory. 

My goal is to focus on only 1 field for my future studies and I've chosen Nlp. Now I want to get good at it, but it's not clear how?",859
359,359,Research paper mapping for BERT: foundational work &amp; latest advancements,"Sharing our new [interactive research graph for BERT](https://crossminds.ai/graphlist/bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding-60709500c8663c4cfa875fc4/), which maps important prior contextual representation work and various pre-trained language models derived from BERT.  Hope you find it helpful!

Here are the papers (and video presentations) included in the graph:

* BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (core paper)
* Attention Is All You Need
* Semi-supervised Sequence Learning
* Deep contextualized word representations
* Universal Language Model Fine-tuning for Text Classification
* Improving Language Understanding by Generative Pre-Training
* RoBERTa: A Robustly Optimized BERT Pretraining Approach
* Defending Against Neural Fake News
* Language Models as Knowledge Bases?
* ALBERT: A Lite BERT for Self-supervised Learning of Language Representations
* XLNet: Generalized Autoregressive Pretraining for Language Understanding
* Cross-lingual Language Model Pretraining
* 75 Languages, 1 Model: Parsing Universal Dependencies Universally
* Multi-Task Deep Neural Networks for Natural Language Understanding
* MASS: Masked Sequence to Sequence Pre-training for Language Generation
* Unified Language Model Pre-training for Natural Language Understanding and Generation
* SpanBERT: Improving Pre-training by Representing and Predicting Spans
* ERNIE: Enhanced Language Representation with Informative Entities
* ERNIE: Enhanced Representation through Knowledge Integration
* Knowledge Enhanced Contextual Word Representations
* VideoBERT: A Joint Model for Video and Language Representation Learning
* Contrastive Bidirectional Transformer for Temporal Representation Learning
* ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks
* VisualBERT: A Simple and Performant Baseline for Vision and Language
* Fusion of Detected Objects in Text for Visual Question Answering
* Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training
* LXMERT: Learning Cross-Modality Encoder Representations from Transformers
* VL-BERT: Pre-training of Generic Visual-Linguistic Representations
* UNITER: Learning UNiversal Image-TExt Representations
* Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks
* DeBERTa: Decoding-enhanced BERT with Disentangled Attention",https://www.reddit.com/r/LanguageTechnology/comments/mqgqcz/research_paper_mapping_for_bert_foundational_work/,LanguageTechnology,t3_mqgqcz,"Research paper mapping for BERT: foundational work &amp; latest advancements Sharing our new [interactive research graph for BERT](https://crossminds.ai/graphlist/bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding-60709500c8663c4cfa875fc4/), which maps important prior contextual representation work and various pre-trained language models derived from BERT.  Hope you find it helpful!

Here are the papers (and video presentations) included in the graph:

* BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (core paper)
* Attention Is All You Need
* Semi-supervised Sequence Learning
* Deep contextualized word representations
* Universal Language Model Fine-tuning for Text Classification
* Improving Language Understanding by Generative Pre-Training
* RoBERTa: A Robustly Optimized BERT Pretraining Approach
* Defending Against Neural Fake News
* Language Models as Knowledge Bases?
* ALBERT: A Lite BERT for Self-supervised Learning of Language Representations
* XLNet: Generalized Autoregressive Pretraining for Language Understanding
* Cross-lingual Language Model Pretraining
* 75 Languages, 1 Model: Parsing Universal Dependencies Universally
* Multi-Task Deep Neural Networks for Natural Language Understanding
* MASS: Masked Sequence to Sequence Pre-training for Language Generation
* Unified Language Model Pre-training for Natural Language Understanding and Generation
* SpanBERT: Improving Pre-training by Representing and Predicting Spans
* ERNIE: Enhanced Language Representation with Informative Entities
* ERNIE: Enhanced Representation through Knowledge Integration
* Knowledge Enhanced Contextual Word Representations
* VideoBERT: A Joint Model for Video and Language Representation Learning
* Contrastive Bidirectional Transformer for Temporal Representation Learning
* ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks
* VisualBERT: A Simple and Performant Baseline for Vision and Language
* Fusion of Detected Objects in Text for Visual Question Answering
* Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training
* LXMERT: Learning Cross-Modality Encoder Representations from Transformers
* VL-BERT: Pre-training of Generic Visual-Linguistic Representations
* UNITER: Learning UNiversal Image-TExt Representations
* Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks
* DeBERTa: Decoding-enhanced BERT with Disentangled Attention",2500
360,360,"Finished an NLP based binary text classified for user reviews, what else can I do with this to add to my project?","Looking for other types or ways to use this data and come up with analysis on it. I feel like my project needs a little more but I’m unsure what else I can do with what I have. It takes in user reviews, like Yelp reviews, and tags them as either positive or negative.",https://www.reddit.com/r/LanguageTechnology/comments/mqtitw/finished_an_nlp_based_binary_text_classified_for/,LanguageTechnology,t3_mqtitw,"Finished an NLP based binary text classified for user reviews, what else can I do with this to add to my project? Looking for other types or ways to use this data and come up with analysis on it. I feel like my project needs a little more but I’m unsure what else I can do with what I have. It takes in user reviews, like Yelp reviews, and tags them as either positive or negative.",381
361,361,Is there a way to get document wise perplexity in gensim LDA,"For example, how perplexed is our model assigning the topic that it assigned to a document. The reason I want to know this is because I want to weed out low frequency documents that were wrongly assigned to high frequency topics",https://www.reddit.com/r/LanguageTechnology/comments/mqpuw5/is_there_a_way_to_get_document_wise_perplexity_in/,LanguageTechnology,t3_mqpuw5,"Is there a way to get document wise perplexity in gensim LDA For example, how perplexed is our model assigning the topic that it assigned to a document. The reason I want to know this is because I want to weed out low frequency documents that were wrongly assigned to high frequency topics",289
362,362,Checkout our team-based cloud-first text annotator.,"*Long time lurker, first time poster!* 

*otso has just launched our Annotator, and have built with the needs of many in this sub!*

&amp;#x200B;

**A cloud-based Text Annotator built for Machine Learning Engineers and Data Scientists.**

We have been working on otso Annotator for over two years. It began as an internal tool, used to manage annotation and data labelling for our own machine learning projects. As the tool and the interface developed, we began providing it to select enterprise customers. We’ve received so much significant positive feedback from our clients, that we decided to launch the Annotator as a standalone product.

otso Annotator provides three key benefits; the user experience, which prioritises ease-of-use and understanding. The project management features, which let you allocate and manage annotation tasks. Finally, as a cloud-first tool, you no longer need to have annotators use a CLI to get started, which makes it a much easier tool for teams to use.

**Why a focus on the user experience of teams?**

Text annotation is best done in a team environment. Ideally, machine learning engineers and data scientists will set up and run projects, while subject matter experts provide annotations. We have built otso Annotator with these different user types in mind - enabling seamless project setup for project admins and an easy and keyboard enabled annotation experience for annotators.

With this public launch, we are granting users and teams that sign up during April an extended trial period of 30 days.

To check it out, head to [otso.ai/annotator](https://otso.ai/annotator).No credit card required.",https://www.reddit.com/r/LanguageTechnology/comments/mqcra9/checkout_our_teambased_cloudfirst_text_annotator/,LanguageTechnology,t3_mqcra9,"Checkout our team-based cloud-first text annotator. *Long time lurker, first time poster!* 

*otso has just launched our Annotator, and have built with the needs of many in this sub!*

&amp;#x200B;

**A cloud-based Text Annotator built for Machine Learning Engineers and Data Scientists.**

We have been working on otso Annotator for over two years. It began as an internal tool, used to manage annotation and data labelling for our own machine learning projects. As the tool and the interface developed, we began providing it to select enterprise customers. We’ve received so much significant positive feedback from our clients, that we decided to launch the Annotator as a standalone product.

otso Annotator provides three key benefits; the user experience, which prioritises ease-of-use and understanding. The project management features, which let you allocate and manage annotation tasks. Finally, as a cloud-first tool, you no longer need to have annotators use a CLI to get started, which makes it a much easier tool for teams to use.

**Why a focus on the user experience of teams?**

Text annotation is best done in a team environment. Ideally, machine learning engineers and data scientists will set up and run projects, while subject matter experts provide annotations. We have built otso Annotator with these different user types in mind - enabling seamless project setup for project admins and an easy and keyboard enabled annotation experience for annotators.

With this public launch, we are granting users and teams that sign up during April an extended trial period of 30 days.

To check it out, head to [otso.ai/annotator](https://otso.ai/annotator).No credit card required.",1693
363,363,At which linguistic patterns and features attention heads of BERT look to ?,"Hello,

I am developing a an extractive text summarizer for french language, I would like to explore the self-attention mechanism to see at which linguistic patterns it looks to by generating a heat map or? Any help?",https://www.reddit.com/r/LanguageTechnology/comments/mq3ov5/at_which_linguistic_patterns_and_features/,LanguageTechnology,t3_mq3ov5,"At which linguistic patterns and features attention heads of BERT look to ? Hello,

I am developing a an extractive text summarizer for french language, I would like to explore the self-attention mechanism to see at which linguistic patterns it looks to by generating a heat map or? Any help?",292
364,364,Youtube Video Transcript Summarization with Hugging Face,,https://youtu.be/3V-MJhJvRWg,LanguageTechnology,t3_mq9rwa,Youtube Video Transcript Summarization with Hugging Face ,57
365,365,hello I need DUC 2004 dataset for my master project .... if anyone share it with me i'll so thankful,,https://www.reddit.com/r/LanguageTechnology/comments/mq18qz/hello_i_need_duc_2004_dataset_for_my_master/,LanguageTechnology,t3_mq18qz,hello I need DUC 2004 dataset for my master project .... if anyone share it with me i'll so thankful ,101
366,366,Deep learning on multiple computers,"Hello,

I'm using BERT language model for predicting mental health issues. Later, I'll be using more language models for comparison. The dataset is big and the whole computation requires GPUs which I don't have. I was wondering if there's any quick way to make a training cluster with multiple CPU based computers to make training faster. I'm no knowledge of distributed computing so idk how to proceed with this. Do you guys have any idea?

Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/mpgwsl/deep_learning_on_multiple_computers/,LanguageTechnology,t3_mpgwsl,"Deep learning on multiple computers Hello,

I'm using BERT language model for predicting mental health issues. Later, I'll be using more language models for comparison. The dataset is big and the whole computation requires GPUs which I don't have. I was wondering if there's any quick way to make a training cluster with multiple CPU based computers to make training faster. I'm no knowledge of distributed computing so idk how to proceed with this. Do you guys have any idea?

Thanks.",485
367,367,[Q:] MLM for short phrases,"Hello there,
Im currently working on my Bachelorthesis and have only little knowledge on NLP. 
My idea was to finetune a BERT Model on a task that is a mix of fill-mask and text-summarization. 

Basically i would scrape for short sentences about a specific topic and display those. The user would have to crate template sentences with masked entries. And finally the transformer guessing those masked entries.

Does this sound realistic?

Could someone provide any information about how to fine tune something like that? Is it eveb possible to focus the transformer on a specific text?

Thanks !",https://www.reddit.com/r/LanguageTechnology/comments/mpee92/q_mlm_for_short_phrases/,LanguageTechnology,t3_mpee92,"[Q:] MLM for short phrases Hello there,
Im currently working on my Bachelorthesis and have only little knowledge on NLP. 
My idea was to finetune a BERT Model on a task that is a mix of fill-mask and text-summarization. 

Basically i would scrape for short sentences about a specific topic and display those. The user would have to crate template sentences with masked entries. And finally the transformer guessing those masked entries.

Does this sound realistic?

Could someone provide any information about how to fine tune something like that? Is it eveb possible to focus the transformer on a specific text?

Thanks !",622
368,368,Tweet Scraping using Twint and Sentiment Analysis using Hugging Face Transformers #python #NLProc,,https://youtu.be/z-sFQVN7hgg,LanguageTechnology,t3_mp8fos,Tweet Scraping using Twint and Sentiment Analysis using Hugging Face Transformers #python #NLProc ,98
369,369,Plan to make twitter sentiment analysis,"Hello,

I am going to make a simple sentiment analysis of Twitter posts. Basically searching for a word(name) and than retrieving n tweets and later returning the distribution positive, negative, neutral.",https://www.reddit.com/r/LanguageTechnology/comments/mpbpel/plan_to_make_twitter_sentiment_analysis/,LanguageTechnology,t3_mpbpel,"Plan to make twitter sentiment analysis Hello,

I am going to make a simple sentiment analysis of Twitter posts. Basically searching for a word(name) and than retrieving n tweets and later returning the distribution positive, negative, neutral.",244
370,370,[D] is this a correct application of the cosine similarity?,"Suppose you have downloaded the pdf of every Shakespeare play on your computer. Suppose now you want to find the name of a Shakespeare play that you read in high school, but you can't remember it's name - however, you do remember the general plot of the play, e.g. ""a danish prince is visted by his father's ghost and holds a skull in his hand while delivering a speech"". (Btw this is the plot of hamlet)

Suppose you type this sentence in - could the cosine similarity be used to find out which play is most similar to this sentence? Is there a common way to solve this kind of problem?",https://www.reddit.com/r/LanguageTechnology/comments/mp5ipq/d_is_this_a_correct_application_of_the_cosine/,LanguageTechnology,t3_mp5ipq,"[D] is this a correct application of the cosine similarity? Suppose you have downloaded the pdf of every Shakespeare play on your computer. Suppose now you want to find the name of a Shakespeare play that you read in high school, but you can't remember it's name - however, you do remember the general plot of the play, e.g. ""a danish prince is visted by his father's ghost and holds a skull in his hand while delivering a speech"". (Btw this is the plot of hamlet)

Suppose you type this sentence in - could the cosine similarity be used to find out which play is most similar to this sentence? Is there a common way to solve this kind of problem?",647
371,371,Suggestion for web scraping,"Can somebody urgently suggest me the best method to extract a specified section from a .txt webpage.

Example-  [https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt](https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt)   

Suppose, I want to extract all text from the section ITEM 7. Management's Discussion and Analysis section. Now, the catch is that there are several such webpages and not all of them start with Item 7 \[they have Management's discussion and analysis common though\]. How to do this?",https://www.reddit.com/r/LanguageTechnology/comments/mpdt8m/suggestion_for_web_scraping/,LanguageTechnology,t3_mpdt8m,"Suggestion for web scraping Can somebody urgently suggest me the best method to extract a specified section from a .txt webpage.

Example-  [https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt](https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt)   

Suppose, I want to extract all text from the section ITEM 7. Management's Discussion and Analysis section. Now, the catch is that there are several such webpages and not all of them start with Item 7 \[they have Management's discussion and analysis common though\]. How to do this?",568
372,372,Can you suggest me a Transformer Model for fine-tuning for my thesis?,"Hello!  For my MSc Artificial Intelligence thesis I would like to work on fine-tuning transformers for NLP. I will have 5 months to complete my thesis. I don't have too much experience in NLP because the course was more focused on Computer Vision. I find transformers very interesting and I want to work on fine-tuning for dialogue systems and text classification. I haven't fully decided on the dataset or what classification I want to do. 

1. Can you suggest a topic for text classification? I am looking for an interesting subject that is also relevant for employers. 
2. There are so many different transformer models that I can work on. Which ones do you think would be the best? 

Thank you in advance!",https://www.reddit.com/r/LanguageTechnology/comments/mpaood/can_you_suggest_me_a_transformer_model_for/,LanguageTechnology,t3_mpaood,"Can you suggest me a Transformer Model for fine-tuning for my thesis? Hello!  For my MSc Artificial Intelligence thesis I would like to work on fine-tuning transformers for NLP. I will have 5 months to complete my thesis. I don't have too much experience in NLP because the course was more focused on Computer Vision. I find transformers very interesting and I want to work on fine-tuning for dialogue systems and text classification. I haven't fully decided on the dataset or what classification I want to do. 

1. Can you suggest a topic for text classification? I am looking for an interesting subject that is also relevant for employers. 
2. There are so many different transformer models that I can work on. Which ones do you think would be the best? 

Thank you in advance!",779
373,373,NER for Social Media Texts with Semantic Augmentation | Research Papers Summary 013,,https://youtu.be/FmnbBL0ems8,LanguageTechnology,t3_mow4oz,NER for Social Media Texts with Semantic Augmentation | Research Papers Summary 013 ,84
374,374,Given a corpus of about 10k keywords and another keyword x. How do I extract the top 5 most similar words to x.,"
I have found various topic modelling algorithms, but they seem to depend on the interrelationships among words used in a document to determine the similarity. I want to achieve something similar to keyword clustering based on its meaning and retrieve top 5 most similar words of a query keyword. Any suggestions or path to solve this problem will be very helpful.

This community has been amazing for a fresher like me and thank you to each and everyone who takes out their time to help out people like me.",https://www.reddit.com/r/LanguageTechnology/comments/moxlf4/given_a_corpus_of_about_10k_keywords_and_another/,LanguageTechnology,t3_moxlf4,"Given a corpus of about 10k keywords and another keyword x. How do I extract the top 5 most similar words to x. 
I have found various topic modelling algorithms, but they seem to depend on the interrelationships among words used in a document to determine the similarity. I want to achieve something similar to keyword clustering based on its meaning and retrieve top 5 most similar words of a query keyword. Any suggestions or path to solve this problem will be very helpful.

This community has been amazing for a fresher like me and thank you to each and everyone who takes out their time to help out people like me.",619
375,375,How to award a score (1-100) for closeness to the right answer?,"Have a product in the works which includes a quiz element. Would like to support fill-in-the-blank for entering text answers, but not require perfect spelling.

If correct answer is “Guatemala”, would like to give 100 pts for exact match, and (for example) 93 for Guatamela, and 45 for Gwattanala, and so on. 

Are there good examples of this in the wild?",https://www.reddit.com/r/LanguageTechnology/comments/moqi8s/how_to_award_a_score_1100_for_closeness_to_the/,LanguageTechnology,t3_moqi8s,"How to award a score (1-100) for closeness to the right answer? Have a product in the works which includes a quiz element. Would like to support fill-in-the-blank for entering text answers, but not require perfect spelling.

If correct answer is “Guatemala”, would like to give 100 pts for exact match, and (for example) 93 for Guatamela, and 45 for Gwattanala, and so on. 

Are there good examples of this in the wild?",419
376,376,Any good NLP roadmap?,"I'm a beginner in data science. I would like to have a roadmap to follow and understand the broad extent of this amazing field.

May be it could be difficult to find something specific for NLP. In that case, please share Machine Learning or Data Science roadmaps that you may have.

Beginners of this community would appreciate it!",https://www.reddit.com/r/LanguageTechnology/comments/moc365/any_good_nlp_roadmap/,LanguageTechnology,t3_moc365,"Any good NLP roadmap? I'm a beginner in data science. I would like to have a roadmap to follow and understand the broad extent of this amazing field.

May be it could be difficult to find something specific for NLP. In that case, please share Machine Learning or Data Science roadmaps that you may have.

Beginners of this community would appreciate it!",353
377,377,"Embedding2triples, which ML algorithm?","I have a training set of news articles that I wish to condense into triples, and I actually can evaluate how well these triples describe the original text and use it as a training signal, but I'm new to the field of NLP and uncertain about my options.  Which ML algorithms would you consider to take a BERT embedding layer as input and learn to turn/decode it to triples based on the mentioned training signal?",https://www.reddit.com/r/LanguageTechnology/comments/mopzoq/embedding2triples_which_ml_algorithm/,LanguageTechnology,t3_mopzoq,"Embedding2triples, which ML algorithm? I have a training set of news articles that I wish to condense into triples, and I actually can evaluate how well these triples describe the original text and use it as a training signal, but I'm new to the field of NLP and uncertain about my options.  Which ML algorithms would you consider to take a BERT embedding layer as input and learn to turn/decode it to triples based on the mentioned training signal?",449
378,378,Event extraction/Highlight detection from transcript,,/r/MachineLearning/comments/moc0zc/r_techniques_for_nlp_event_extraction_from_large/,LanguageTechnology,t3_moc42e,Event extraction/Highlight detection from transcript ,53
379,379,"when doing NLP, do you usually augment your data with a ""pre defined corpus"" specific to the field your data comes from?","when doing NLP, do you usually augment your data with a ""pre defined corpus"" specific to the field your data comes from?

E.g. if you are working with medical data, do nlp procedures require you to use a predefined corpus from the medical domain?",https://www.reddit.com/r/LanguageTechnology/comments/mnzami/when_doing_nlp_do_you_usually_augment_your_data/,LanguageTechnology,t3_mnzami,"when doing NLP, do you usually augment your data with a ""pre defined corpus"" specific to the field your data comes from? when doing NLP, do you usually augment your data with a ""pre defined corpus"" specific to the field your data comes from?

E.g. if you are working with medical data, do nlp procedures require you to use a predefined corpus from the medical domain?",367
380,380,[Tutorial] Neural Machine Translation With Attention With Keras,"This tutorial gives a step-by-step guide to implementing an RNN model (encoder-decoder sequence-to-sequence with attention mechanism) for French to English translation using Keras.

Additional topics covered include:

* The Problem With Sequence-to-Sequence Models for Neural Machine Translation
* An Introduction to Attention Mechanisms
* Categories of Attention Mechanisms
* Applications of Attention Mechanisms
* Neural Machine Translation Using an RNN With Attention Mechanism (Keras)

Tutorial link: [https://blog.paperspace.com/seq-to-seq-attention-mechanism-keras/](https://blog.paperspace.com/seq-to-seq-attention-mechanism-keras/)

Run all of the code on a free GPU: [https://ml-showcase.paperspace.com/projects/neural-machine-translation-with-keras](https://ml-showcase.paperspace.com/projects/neural-machine-translation-with-keras)",https://www.reddit.com/r/LanguageTechnology/comments/mnis25/tutorial_neural_machine_translation_with/,LanguageTechnology,t3_mnis25,"[Tutorial] Neural Machine Translation With Attention With Keras This tutorial gives a step-by-step guide to implementing an RNN model (encoder-decoder sequence-to-sequence with attention mechanism) for French to English translation using Keras.

Additional topics covered include:

* The Problem With Sequence-to-Sequence Models for Neural Machine Translation
* An Introduction to Attention Mechanisms
* Categories of Attention Mechanisms
* Applications of Attention Mechanisms
* Neural Machine Translation Using an RNN With Attention Mechanism (Keras)

Tutorial link: [https://blog.paperspace.com/seq-to-seq-attention-mechanism-keras/](https://blog.paperspace.com/seq-to-seq-attention-mechanism-keras/)

Run all of the code on a free GPU: [https://ml-showcase.paperspace.com/projects/neural-machine-translation-with-keras](https://ml-showcase.paperspace.com/projects/neural-machine-translation-with-keras)",906
381,381,Erasmus or Uppsala?,"Hi everyone!

I got accepted into the Erasmus master in Language and Communications Technology and also into the University of Uppsala master in Language Technology. I need help deciding between the two.

If you don't know, the Erasmus program implies attending two universities, one year each, out of the seven universities of the consortium. They will tell me what universities i will attend once i say yes. Therefore, i don't know exactly what the course will be.

I feel more inclined to choose Uppsala because:
The logistics of living in Sweden for two years are easier than living in two different countries.
The program is free, as opposed to Erasmus in which i have to pay a fee.
I actually know the course of studies program, as opposed to Erasmus in which i will find out later.
I believe studying in Uppsala will make it easier for me to find a job and a life in Sweden.
I have a boyfriend living four hours away from Uppsala (i try not to let this be a factor but who am I kidding, it is).

On the other hand, i think maybe the Erasmus program has a better reputation and also living in two random countries sounds like fun.

If you have any advice it would be welcome. thanks!",https://www.reddit.com/r/LanguageTechnology/comments/mnecov/erasmus_or_uppsala/,LanguageTechnology,t3_mnecov,"Erasmus or Uppsala? Hi everyone!

I got accepted into the Erasmus master in Language and Communications Technology and also into the University of Uppsala master in Language Technology. I need help deciding between the two.

If you don't know, the Erasmus program implies attending two universities, one year each, out of the seven universities of the consortium. They will tell me what universities i will attend once i say yes. Therefore, i don't know exactly what the course will be.

I feel more inclined to choose Uppsala because:
The logistics of living in Sweden for two years are easier than living in two different countries.
The program is free, as opposed to Erasmus in which i have to pay a fee.
I actually know the course of studies program, as opposed to Erasmus in which i will find out later.
I believe studying in Uppsala will make it easier for me to find a job and a life in Sweden.
I have a boyfriend living four hours away from Uppsala (i try not to let this be a factor but who am I kidding, it is).

On the other hand, i think maybe the Erasmus program has a better reputation and also living in two random countries sounds like fun.

If you have any advice it would be welcome. thanks!",1209
382,382,Intro to nlp and text mining,"I am completely to new to nlp/text mining and am interested in learning more about it (on an applied side). Suppose I have a dataset with 1000 doctor comments (no ""labels"", i.e. I don't know if they are positive or negative) for different comments. The question is now, what can I do? 

Just by doing some google searches, it seems like the two popular things to do with this data is LDA and sentiment analysis. Just by looking how to do this in R, this looks doable. But what are some other popular algorithms that can done on this kind of data? I assume that through LDA and sentiment analysis, you can ""cluster"" these doctor comments together? If you have a new comment, you can see which from clustering which cluster this comment belongs to? 

In this example, how would the newer BERT algorithm come into play? Is there a main way to extract ""insights"" from these comments? Based on the text in these comments, are there algorithms that can determine if its possible to see which medical conditions  are more lethal, which age groups/demographics of patients are healthier, which medications are people taking, etc. ? Or is this a very advanced problem?

Thanks",https://www.reddit.com/r/LanguageTechnology/comments/mnith5/intro_to_nlp_and_text_mining/,LanguageTechnology,t3_mnith5,"Intro to nlp and text mining I am completely to new to nlp/text mining and am interested in learning more about it (on an applied side). Suppose I have a dataset with 1000 doctor comments (no ""labels"", i.e. I don't know if they are positive or negative) for different comments. The question is now, what can I do? 

Just by doing some google searches, it seems like the two popular things to do with this data is LDA and sentiment analysis. Just by looking how to do this in R, this looks doable. But what are some other popular algorithms that can done on this kind of data? I assume that through LDA and sentiment analysis, you can ""cluster"" these doctor comments together? If you have a new comment, you can see which from clustering which cluster this comment belongs to? 

In this example, how would the newer BERT algorithm come into play? Is there a main way to extract ""insights"" from these comments? Based on the text in these comments, are there algorithms that can determine if its possible to see which medical conditions  are more lethal, which age groups/demographics of patients are healthier, which medications are people taking, etc. ? Or is this a very advanced problem?

Thanks",1196
383,383,NLP Problem," 

Hi all - I'm working on what I think could be an low-level NLP problem at work, and was wondering if anyone here had any ideas on modules I could/should look into that might provide a solution.

Problem: so, the company I work for deploys networked hardware into the field, and that hardware often requires repairs. Our repair folks take down a lot of unstructured data when they get the hardware back up and running, stored as a note on salesforce. I'm trying to figure out a way to process this information to get some meaning from it (e.g., are repair cases most often networking or electrical issues, or from weather damages...etc.,).

Solution: I've been trying to figure out a way to sort all of this information. One idea was to make a list of all strings in all notes, strip out all articles/conjunctions, and then create some word cloud. My hunch is that someone has probably solved something very similar to this, and I wanted to socialize it in this community to see if anyone had any thoughts!

I would massively appreciate any ideas, or pointers on what modules I should be looking into! Just to be clear, we use Python/Jupyter Notebooks.",https://www.reddit.com/r/LanguageTechnology/comments/mn36ij/nlp_problem/,LanguageTechnology,t3_mn36ij,"NLP Problem  

Hi all - I'm working on what I think could be an low-level NLP problem at work, and was wondering if anyone here had any ideas on modules I could/should look into that might provide a solution.

Problem: so, the company I work for deploys networked hardware into the field, and that hardware often requires repairs. Our repair folks take down a lot of unstructured data when they get the hardware back up and running, stored as a note on salesforce. I'm trying to figure out a way to process this information to get some meaning from it (e.g., are repair cases most often networking or electrical issues, or from weather damages...etc.,).

Solution: I've been trying to figure out a way to sort all of this information. One idea was to make a list of all strings in all notes, strip out all articles/conjunctions, and then create some word cloud. My hunch is that someone has probably solved something very similar to this, and I wanted to socialize it in this community to see if anyone had any thoughts!

I would massively appreciate any ideas, or pointers on what modules I should be looking into! Just to be clear, we use Python/Jupyter Notebooks.",1166
384,384,Means to detect plagiarism in textual documents,"Hello guys, 

I came here to ask you for a help. I'm writing my final thesis right now on Detecting plagiarism in text documents. And I have to be honest with you guys, It is over my head. Deadline is in 1 month and I don't know how to make a working piece of code. So I wanted to ask you if you are willing to help me or at least tell me if there is something I can do. 

So the task is to compare documents (preferably bunch of documents to one suspicious document) and find if the suspecious document is plagiarism to any of those documents in reference collection. Currently I have done loading multiple pdf files, making dataframe, preprocess the text data (tokenisation, lemmantisation, stemming, stopwords removal, punctuation removal, lowercased) and vectorization. Then I applied cosine similarity to it and it kinda works.

My question is if there is any possible way to apply Support Vector Machine or Naive Bayes to this task? and if so, how do I set it up? The main goal was to apply some Machine Learning algoritm but I took much bigger piece of pie than I was supposed to.

I am really really desperate and any information will help me. Thank you",https://www.reddit.com/r/LanguageTechnology/comments/mn2vpx/means_to_detect_plagiarism_in_textual_documents/,LanguageTechnology,t3_mn2vpx,"Means to detect plagiarism in textual documents Hello guys, 

I came here to ask you for a help. I'm writing my final thesis right now on Detecting plagiarism in text documents. And I have to be honest with you guys, It is over my head. Deadline is in 1 month and I don't know how to make a working piece of code. So I wanted to ask you if you are willing to help me or at least tell me if there is something I can do. 

So the task is to compare documents (preferably bunch of documents to one suspicious document) and find if the suspecious document is plagiarism to any of those documents in reference collection. Currently I have done loading multiple pdf files, making dataframe, preprocess the text data (tokenisation, lemmantisation, stemming, stopwords removal, punctuation removal, lowercased) and vectorization. Then I applied cosine similarity to it and it kinda works.

My question is if there is any possible way to apply Support Vector Machine or Naive Bayes to this task? and if so, how do I set it up? The main goal was to apply some Machine Learning algoritm but I took much bigger piece of pie than I was supposed to.

I am really really desperate and any information will help me. Thank you",1209
385,385,Summer schools in NLP 2021,"Hi, any leads on upcoming NLP summer schools.",https://www.reddit.com/r/LanguageTechnology/comments/mmnuhk/summer_schools_in_nlp_2021/,LanguageTechnology,t3_mmnuhk,"Summer schools in NLP 2021 Hi, any leads on upcoming NLP summer schools.",72
386,386,Stanford NLP Stanza NLP package - Biomedical NLP models demo #NLproc #python #clincialNLP,,https://youtu.be/iQ5kP2kOGNA,LanguageTechnology,t3_mmqvao,Stanford NLP Stanza NLP package - Biomedical NLP models demo #NLproc #python #clincialNLP ,90
387,387,Question Answering (Seq2Seq) Visualization with Transformer Neural Networks,,https://youtu.be/GTVgJhSlHEk,LanguageTechnology,t3_mmh89x,Question Answering (Seq2Seq) Visualization with Transformer Neural Networks ,76
388,388,"Are word embeddings semantically ""meaningful""?","It is a common consensus that words appearing in similar contexts are semantically similar. But this definition breaks drastically when we consider antonymy relationships - &gt; For. eg., the word ""positive"" and ""negative"" generally appear in similar contexts and are assigned spatially close vectors. In the inherent sense, it does not contain meaning. 

Word2vec was trained on contextual information is somehow not commonly referred to as contextualized word embeddings. However. embeddings realized through BERT and Elmo are termed contextualized word-embeddings. Is there a reason for this? Or perhaps I might be wrong here and it was already called contextual word embedding. The embeddings through BERT and ElMO can be called dynamic embeddings at best, but it is not difficult to construct dynamic embeddings through word2vec embeddings. Does BERT embedding inherently have any other semantic information (non-positional, non-context), other than a more complicated interaction layer (and perhaps more data)?",https://www.reddit.com/r/LanguageTechnology/comments/mmknon/are_word_embeddings_semantically_meaningful/,LanguageTechnology,t3_mmknon,"Are word embeddings semantically ""meaningful""? It is a common consensus that words appearing in similar contexts are semantically similar. But this definition breaks drastically when we consider antonymy relationships - &gt; For. eg., the word ""positive"" and ""negative"" generally appear in similar contexts and are assigned spatially close vectors. In the inherent sense, it does not contain meaning. 

Word2vec was trained on contextual information is somehow not commonly referred to as contextualized word embeddings. However. embeddings realized through BERT and Elmo are termed contextualized word-embeddings. Is there a reason for this? Or perhaps I might be wrong here and it was already called contextual word embedding. The embeddings through BERT and ElMO can be called dynamic embeddings at best, but it is not difficult to construct dynamic embeddings through word2vec embeddings. Does BERT embedding inherently have any other semantic information (non-positional, non-context), other than a more complicated interaction layer (and perhaps more data)?",1063
389,389,MarianMT usage with Spacy possible?,"Hi everyone,

is it possible to use MarianMT transformer models with spacy-transformers? Similar to [https://spacy.io/universe/project/spacy-transformers](https://spacy.io/universe/project/spacy-transformers)  
MarianMT: [https://huggingface.co/transformers/model\_doc/marian.html?highlight=mariantokenizer#multilingual-models](https://huggingface.co/transformers/model_doc/marian.html?highlight=mariantokenizer#multilingual-models)

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/mmnrmr/marianmt_usage_with_spacy_possible/,LanguageTechnology,t3_mmnrmr,"MarianMT usage with Spacy possible? Hi everyone,

is it possible to use MarianMT transformer models with spacy-transformers? Similar to [https://spacy.io/universe/project/spacy-transformers](https://spacy.io/universe/project/spacy-transformers)  
MarianMT: [https://huggingface.co/transformers/model\_doc/marian.html?highlight=mariantokenizer#multilingual-models](https://huggingface.co/transformers/model_doc/marian.html?highlight=mariantokenizer#multilingual-models)

Thanks!",477
390,390,Multi-Document Summarization: The Wikipedia Current Events Portal Dataset (Dataset and Colab notebook),,https://aylien.com/blog/multi-document-summarisation-and-the-wcep-dataset,LanguageTechnology,t3_mlynns,Multi-Document Summarization: The Wikipedia Current Events Portal Dataset (Dataset and Colab notebook) ,103
391,391,How do I predict sentiment of unseen text (After training and testing),"Using scikit learn, I managed to train my model but dont know how to use the model to predict new text passages. I have watched tons of tutorials but none of them go beyond training and testing. Below is the code Im using. Any help is appreciated.

        data_source_url = ""/path/to/file.csv""
        airline_tweets = pd.read_csv(data_source_url)
        
        features = airline_tweets.iloc[:, 10].values
        labels = airline_tweets.iloc[:, 1].values
        
        processed_features = []
        
          # I do some text processing here and then append the text to processed_features
        
                
        vectorizer = CountVectorizer(analyzer = 'word', lowercase = False)
        features = vectorizer.fit_transform(processed_features)
        features_nd = features.toarray() # for easy usage
        
        X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.80, random_state=1234)
        
        log_model = LogisticRegression()
        log_model = log_model.fit(X=X_train, y=y_train)
            
        predictions = log_model.predict(X_test)",https://www.reddit.com/r/LanguageTechnology/comments/mmfwr6/how_do_i_predict_sentiment_of_unseen_text_after/,LanguageTechnology,t3_mmfwr6,"How do I predict sentiment of unseen text (After training and testing) Using scikit learn, I managed to train my model but dont know how to use the model to predict new text passages. I have watched tons of tutorials but none of them go beyond training and testing. Below is the code Im using. Any help is appreciated.

        data_source_url = ""/path/to/file.csv""
        airline_tweets = pd.read_csv(data_source_url)
        
        features = airline_tweets.iloc[:, 10].values
        labels = airline_tweets.iloc[:, 1].values
        
        processed_features = []
        
          # I do some text processing here and then append the text to processed_features
        
                
        vectorizer = CountVectorizer(analyzer = 'word', lowercase = False)
        features = vectorizer.fit_transform(processed_features)
        features_nd = features.toarray() # for easy usage
        
        X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.80, random_state=1234)
        
        log_model = LogisticRegression()
        log_model = log_model.fit(X=X_train, y=y_train)
            
        predictions = log_model.predict(X_test)",1188
392,392,Overfitting? Input data with too many misspellings,"Im working on predicting answers given question using seq2seq. So far it is as simple as can be . Encoder and decoder are just an LSTM each.

However, even if train loss decreases w epochs, validation loss is too high.

And the question answer train data has many misspellings and words from another language sometimes.

How can I help this? I already included Dropout layers with learning rate 0.2 to 0.5 for input, and 0.8 for output but validation loss still too high..

Accuracy also is so low. Like 5%",https://www.reddit.com/r/LanguageTechnology/comments/mm12uc/overfitting_input_data_with_too_many_misspellings/,LanguageTechnology,t3_mm12uc,"Overfitting? Input data with too many misspellings Im working on predicting answers given question using seq2seq. So far it is as simple as can be . Encoder and decoder are just an LSTM each.

However, even if train loss decreases w epochs, validation loss is too high.

And the question answer train data has many misspellings and words from another language sometimes.

How can I help this? I already included Dropout layers with learning rate 0.2 to 0.5 for input, and 0.8 for output but validation loss still too high..

Accuracy also is so low. Like 5%",557
393,393,Simple corpus service,"Hi all,
Long time lurker, first time poster here. 

I’m turning to the hivemind because I’m at my wit’s end.

I’ve been tasked with providing a simple corpus service that returns tokens, sentences, etc. from a huge corpus based on certain criteria. These criteria are used to filter the corpus according to the annotations of the corpus entries. For example I should be able to return all nouns in the corpus back to the client. 

My first thought was to parse the corpus and load it into some sort of database which I could then query. But it didn’t work because of the technical limitations at my job. Also it seems like a lot of overhead to just do simple queries on the data. 

Then I thought I would load the corpus into a pandas dataframe, keeping it in memory for the lifecycle of the corpus service and querying it when client requests come in. But I find the solution a bit hacky. For example, it becomes very brittle when I try to map the schema of the corpus to my service’s own internal schema. 

Does anyone have experience with this problem? Is there a more straightforward approach that I haven’t thought of before? 

Thanks for taking the time to read this!",https://www.reddit.com/r/LanguageTechnology/comments/mm48xk/simple_corpus_service/,LanguageTechnology,t3_mm48xk,"Simple corpus service Hi all,
Long time lurker, first time poster here. 

I’m turning to the hivemind because I’m at my wit’s end.

I’ve been tasked with providing a simple corpus service that returns tokens, sentences, etc. from a huge corpus based on certain criteria. These criteria are used to filter the corpus according to the annotations of the corpus entries. For example I should be able to return all nouns in the corpus back to the client. 

My first thought was to parse the corpus and load it into some sort of database which I could then query. But it didn’t work because of the technical limitations at my job. Also it seems like a lot of overhead to just do simple queries on the data. 

Then I thought I would load the corpus into a pandas dataframe, keeping it in memory for the lifecycle of the corpus service and querying it when client requests come in. But I find the solution a bit hacky. For example, it becomes very brittle when I try to map the schema of the corpus to my service’s own internal schema. 

Does anyone have experience with this problem? Is there a more straightforward approach that I haven’t thought of before? 

Thanks for taking the time to read this!",1195
394,394,What's the word on Potsdam's MSc Cognitive Systems?,"Hey everyone!

I'm applying for my Master's right now and the threads in this sub have been tremendously helpful! I was wondering if anyone is studying / knows someone who's studying at Uni-Potsdam. I've seen next to nothing about the program in this sub. If I'm being honest, that program looks the most appealing of the European programs I've come across in my research. So, to anyone who can provide some insight, I ask:

* Is it as heavy on the Machine Learning / Deep Learning front as it would appear from the course plan?
* Is it technical and applied (as opposed to theoretical and scholarly)?
* What's the general vibe? How do you and/or the students like it?

You can totally stop reading now but in case anyone's interested:  
I've been accepted to UEF and Edinburgh so far, hearing from Uppsala and/or Gothenburg on Friday. I'm Canadian, so the Swedish schools are either scholarship or $$$$$$. German applications aren't due for a little while so I have this nice little intermission to pause and ponder. Any advice is welcome! Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/mlrmmy/whats_the_word_on_potsdams_msc_cognitive_systems/,LanguageTechnology,t3_mlrmmy,"What's the word on Potsdam's MSc Cognitive Systems? Hey everyone!

I'm applying for my Master's right now and the threads in this sub have been tremendously helpful! I was wondering if anyone is studying / knows someone who's studying at Uni-Potsdam. I've seen next to nothing about the program in this sub. If I'm being honest, that program looks the most appealing of the European programs I've come across in my research. So, to anyone who can provide some insight, I ask:

* Is it as heavy on the Machine Learning / Deep Learning front as it would appear from the course plan?
* Is it technical and applied (as opposed to theoretical and scholarly)?
* What's the general vibe? How do you and/or the students like it?

You can totally stop reading now but in case anyone's interested:  
I've been accepted to UEF and Edinburgh so far, hearing from Uppsala and/or Gothenburg on Friday. I'm Canadian, so the Swedish schools are either scholarship or $$$$$$. German applications aren't due for a little while so I have this nice little intermission to pause and ponder. Any advice is welcome! Thanks!",1100
395,395,AI (GPT-2) Text Generation in Python with Kaggle Dataset | FineTuning GPT Model,,https://youtu.be/6HcGTQKfeXY,LanguageTechnology,t3_mljed7,AI (GPT-2) Text Generation in Python with Kaggle Dataset | FineTuning GPT Model ,80
396,396,What are the top 15 conferences in Natural Language Processing?,"I see several websites listing top X conferences in NLP (Natural Language Processing), but I am not sure if there is some kind of ranking for these conferences. It will be amazing if anyone has some clue about it. Thank you very much for any hints or pointers or answers. :)",https://www.reddit.com/r/LanguageTechnology/comments/mlce0h/what_are_the_top_15_conferences_in_natural/,LanguageTechnology,t3_mlce0h,"What are the top 15 conferences in Natural Language Processing? I see several websites listing top X conferences in NLP (Natural Language Processing), but I am not sure if there is some kind of ranking for these conferences. It will be amazing if anyone has some clue about it. Thank you very much for any hints or pointers or answers. :)",338
397,397,[N] Grammarly releases a grammatical error correction (GEC) dataset for the Ukrainian language,,/r/MachineLearning/comments/mlcv28/n_grammarly_releases_a_grammatical_error/,LanguageTechnology,t3_mld6v9,[N] Grammarly releases a grammatical error correction (GEC) dataset for the Ukrainian language ,95
398,398,Requesting feedback on project related to tracking how news events change over time,"This sub has been very helpful in the past so I am hoping I can get some feedback. For my project, I am essentially trying to find a way to detect changes over time to a news narrative. At this stage I have applied an algorithm to successfully group together the stories that follow the development of the same event. So now I need to find a way to track, analyze, and maybe quantify how the events (and their coverage changes) . My current approach is using topic modeling to find important keywords in each of the articles. Then, I use those key words to map how the stories change overtime. So in the most basic of terms, I am identifying key words in the first article in each narrative chain and then comparing how those keywords change and are different from key words identified in subsequent articles about the same event.  Does this approach sound reasonable?  Is there anything else I should be trying instead?  Thanks everyone!",https://www.reddit.com/r/LanguageTechnology/comments/mliti6/requesting_feedback_on_project_related_to/,LanguageTechnology,t3_mliti6,"Requesting feedback on project related to tracking how news events change over time This sub has been very helpful in the past so I am hoping I can get some feedback. For my project, I am essentially trying to find a way to detect changes over time to a news narrative. At this stage I have applied an algorithm to successfully group together the stories that follow the development of the same event. So now I need to find a way to track, analyze, and maybe quantify how the events (and their coverage changes) . My current approach is using topic modeling to find important keywords in each of the articles. Then, I use those key words to map how the stories change overtime. So in the most basic of terms, I am identifying key words in the first article in each narrative chain and then comparing how those keywords change and are different from key words identified in subsequent articles about the same event.  Does this approach sound reasonable?  Is there anything else I should be trying instead?  Thanks everyone!",1022
399,399,LDA Topic Modelling Explained with implementation using gensim in Python -#NLPRoc tutorial,,https://youtu.be/nNvPvvuPnGs,LanguageTechnology,t3_ml2m65,LDA Topic Modelling Explained with implementation using gensim in Python -#NLPRoc tutorial ,91
400,400,Best practices in NLP,What's your experience in NLP and what do you think are the common strategies and best practices to follow as a beginner?,https://www.reddit.com/r/LanguageTechnology/comments/ml9g1l/best_practices_in_nlp/,LanguageTechnology,t3_ml9g1l,Best practices in NLP What's your experience in NLP and what do you think are the common strategies and best practices to follow as a beginner?,143
401,401,Dissertation Ideas - NLP + blockchain,"Hello everyone.

I am currently thinking about possible dissertation ideas that would combine NLP and blockchain. I got solid background in both modern NLP and distributed systems using blockchain (knowledge about theory, cryptography, investing, solidity...). 

If you have any idea that you are willing to share, it is more than welcome.",https://www.reddit.com/r/LanguageTechnology/comments/ml97ld/dissertation_ideas_nlp_blockchain/,LanguageTechnology,t3_ml97ld,"Dissertation Ideas - NLP + blockchain Hello everyone.

I am currently thinking about possible dissertation ideas that would combine NLP and blockchain. I got solid background in both modern NLP and distributed systems using blockchain (knowledge about theory, cryptography, investing, solidity...). 

If you have any idea that you are willing to share, it is more than welcome.",377
402,402,[D] Can we add CNN on top of BERT," I have dense neural network for BERT, How do I change that to Conv1D, maxpooling, and flatten, before connected to dense layer. 

\`\`\`

 

    class BertBinaryClassifier(nn.Module): 
    def __init__(self, dropout=0.1): 
    super(BertBinaryClassifier, self).__init__()         
    self.bert = BertModel.from_pretrained('bert-base-uncased')         
    self.dropout = nn.Dropout(dropout)         
    self.linear = nn.Linear(768, 1)        
     self.sigmoid = nn.Sigmoid()                   
    def forward(self, tokens, masks=None):         
    _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)         dropout_output = self.dropout(pooled_output)         
    linear_output = self.linear(dropout_output)        
     prediction = self.sigmoid(linear_output)         
    return prediction
     # Config setting 
    BATCH_SIZE = 4
     EPOCHS = 5

\`\`\`",https://www.reddit.com/r/LanguageTechnology/comments/ml5pe7/d_can_we_add_cnn_on_top_of_bert/,LanguageTechnology,t3_ml5pe7,"[D] Can we add CNN on top of BERT  I have dense neural network for BERT, How do I change that to Conv1D, maxpooling, and flatten, before connected to dense layer. 

\`\`\`

 

    class BertBinaryClassifier(nn.Module): 
    def __init__(self, dropout=0.1): 
    super(BertBinaryClassifier, self).__init__()         
    self.bert = BertModel.from_pretrained('bert-base-uncased')         
    self.dropout = nn.Dropout(dropout)         
    self.linear = nn.Linear(768, 1)        
     self.sigmoid = nn.Sigmoid()                   
    def forward(self, tokens, masks=None):         
    _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)         dropout_output = self.dropout(pooled_output)         
    linear_output = self.linear(dropout_output)        
     prediction = self.sigmoid(linear_output)         
    return prediction
     # Config setting 
    BATCH_SIZE = 4
     EPOCHS = 5

\`\`\`",940
403,403,Adding Keywords to a Classification Model,"Is it possible for one to add keywords on a classification model?  (eg different sentences present in a dataset that may relate to -- company, school , Monuments, temples etc)  
So if I have a sentence that is classified as 'school' --&gt; maybe I can map the keyword - 'School' , 'Boarding school' , ' classroom' etc in the model so it can give better accuracy.

This is just a hypothetical thought I had, nothing pertaining to any existing dataset/ problem",https://www.reddit.com/r/LanguageTechnology/comments/ml5w7a/adding_keywords_to_a_classification_model/,LanguageTechnology,t3_ml5w7a,"Adding Keywords to a Classification Model Is it possible for one to add keywords on a classification model?  (eg different sentences present in a dataset that may relate to -- company, school , Monuments, temples etc)  
So if I have a sentence that is classified as 'school' --&gt; maybe I can map the keyword - 'School' , 'Boarding school' , ' classroom' etc in the model so it can give better accuracy.

This is just a hypothetical thought I had, nothing pertaining to any existing dataset/ problem",500
404,404,Use word2vec for topic modelling,"Hi, so I'm working on a topic modelling project whereby I'm trying to extract relevant job skills from a corpus of UX Researcher job postings. 

I've gone through all the standard steps of pre-processing and EDA and have already achieved some meaningful results by using TF-IDF with K-means clustering. With trigrams I've been able to return several clusters of skills which have things like; 

* qualitative quantitative research
* quantitative research method
* quantitative qualitative research
* user centre design
* psychology human computer
* brand include vogue
* deliver high quality
* user behaviour attitude
* interview usability test
* communicate research result

So I'm quite happy so far but it can be better no doubt. I've made word vectors of the dataset using word2vec, and the model is able to provide meaningful similarities between words for example; 

    model = Word2Vec(gensim_input_set, min_count=10, size=100, workers=3, window=5, sg=1)
    print(model.wv.most_similar('psychology')[:5])
    
    &gt;&gt;&gt; [('cognitive', 0.9959733486175537), ('computer', 0.9905843734741211), ('experimental', 0.9882711172103882), ('hci', 0.9872062802314758), ('anthropology', 0.9846541285514832)]

But now I'd like to know if it's possible to take the word embeddings from the model and cluster them somehow?",https://www.reddit.com/r/LanguageTechnology/comments/mkum00/use_word2vec_for_topic_modelling/,LanguageTechnology,t3_mkum00,"Use word2vec for topic modelling Hi, so I'm working on a topic modelling project whereby I'm trying to extract relevant job skills from a corpus of UX Researcher job postings. 

I've gone through all the standard steps of pre-processing and EDA and have already achieved some meaningful results by using TF-IDF with K-means clustering. With trigrams I've been able to return several clusters of skills which have things like; 

* qualitative quantitative research
* quantitative research method
* quantitative qualitative research
* user centre design
* psychology human computer
* brand include vogue
* deliver high quality
* user behaviour attitude
* interview usability test
* communicate research result

So I'm quite happy so far but it can be better no doubt. I've made word vectors of the dataset using word2vec, and the model is able to provide meaningful similarities between words for example; 

    model = Word2Vec(gensim_input_set, min_count=10, size=100, workers=3, window=5, sg=1)
    print(model.wv.most_similar('psychology')[:5])
    
    &gt;&gt;&gt; [('cognitive', 0.9959733486175537), ('computer', 0.9905843734741211), ('experimental', 0.9882711172103882), ('hci', 0.9872062802314758), ('anthropology', 0.9846541285514832)]

But now I'd like to know if it's possible to take the word embeddings from the model and cluster them somehow?",1355
405,405,Question about BERT Embeddings,Am I correct in thinking that BERT uses wordpiece to create a unigram type vector that is then used as the input into the BERT system. But the embeddings we use after the pre-training is done is not just those initial embeddings it is the weights of all the parts of the network. Is this correct?,https://www.reddit.com/r/LanguageTechnology/comments/mkr306/question_about_bert_embeddings/,LanguageTechnology,t3_mkr306,Question about BERT Embeddings Am I correct in thinking that BERT uses wordpiece to create a unigram type vector that is then used as the input into the BERT system. But the embeddings we use after the pre-training is done is not just those initial embeddings it is the weights of all the parts of the network. Is this correct?,327
406,406,"Fuzzy Matching/Logic - Concept, Utility, Implementation, and Complex Scenarios","We’ve been seeing a surge in the requests for Fuzzy Matching/Logic techniques. We tried to learn more about these techniques and the implementation process and have written about it. We have also covered some complex scenarios and their solution.  


Here’s a detailed view on the concept, its utility, and the implementation: [https://nanonets.com/blog/fuzzy-matching-fuzzy-logic/](https://nanonets.com/blog/fuzzy-matching-fuzzy-logic/)  


Can anyone share their experience on implementing Fuzzy Matching in their product or solution?",https://www.reddit.com/r/LanguageTechnology/comments/mkgoiy/fuzzy_matchinglogic_concept_utility/,LanguageTechnology,t3_mkgoiy,"Fuzzy Matching/Logic - Concept, Utility, Implementation, and Complex Scenarios We’ve been seeing a surge in the requests for Fuzzy Matching/Logic techniques. We tried to learn more about these techniques and the implementation process and have written about it. We have also covered some complex scenarios and their solution.  


Here’s a detailed view on the concept, its utility, and the implementation: [https://nanonets.com/blog/fuzzy-matching-fuzzy-logic/](https://nanonets.com/blog/fuzzy-matching-fuzzy-logic/)  


Can anyone share their experience on implementing Fuzzy Matching in their product or solution?",615
407,407,How to use spacy and a tailor-made transformer in sentiment analysis?,"Hi

I m trying to set up a Spacy pipeline with my one transformer but it does not work as the transformer I generated is not compatible.

Dows anyone have an updated example of this pipeline set up, including the compatible method of creating the Transformer?

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/mjzxhu/how_to_use_spacy_and_a_tailormade_transformer_in/,LanguageTechnology,t3_mjzxhu,"How to use spacy and a tailor-made transformer in sentiment analysis? Hi

I m trying to set up a Spacy pipeline with my one transformer but it does not work as the transformer I generated is not compatible.

Dows anyone have an updated example of this pipeline set up, including the compatible method of creating the Transformer?

Thanks!",338
408,408,Deploying chatbot on a website?,"Hey,   
I'm trying to create a chatbot website. The chatbot is developed using Spacy and Tensorflow + Flask. I tried Heroku but ran into the limits pretty quickly. And since I'm a broke student, don't really want to pay for it just yet. 

Any suggestions? Is it impossible to avoid paying for it?",https://www.reddit.com/r/LanguageTechnology/comments/mk4a5z/deploying_chatbot_on_a_website/,LanguageTechnology,t3_mk4a5z,"Deploying chatbot on a website? Hey,   
I'm trying to create a chatbot website. The chatbot is developed using Spacy and Tensorflow + Flask. I tried Heroku but ran into the limits pretty quickly. And since I'm a broke student, don't really want to pay for it just yet. 

Any suggestions? Is it impossible to avoid paying for it?",328
409,409,Real-time language generation?,"Is there such a thing as a real time language generator? 

Apologies if the question may seem silly, I'm a researcher from a completely different field. I only know of gpt3 but it has a significant delay in the responses. We would like to use it to give some semblance of life to virtual characters in a research project. 

What would be the next best thing? Should I come back in 5-10 years? Any pointers would be greatly appreciated.",https://www.reddit.com/r/LanguageTechnology/comments/mjflif/realtime_language_generation/,LanguageTechnology,t3_mjflif,"Real-time language generation? Is there such a thing as a real time language generator? 

Apologies if the question may seem silly, I'm a researcher from a completely different field. I only know of gpt3 but it has a significant delay in the responses. We would like to use it to give some semblance of life to virtual characters in a research project. 

What would be the next best thing? Should I come back in 5-10 years? Any pointers would be greatly appreciated.",466
410,410,Kaggle Natural Language Processing with Disaster Tweets – Top 14% Solution with BERT (TensorFlow),,https://youtu.be/QrILL4Ch-aE,LanguageTechnology,t3_mj4yaw,Kaggle Natural Language Processing with Disaster Tweets – Top 14% Solution with BERT (TensorFlow) ,98
411,411,Most efficient method for converting ~300k sentences to word embeddings?,"I'm working on a project where I need to get the word embeddings of around 300,000 sentences so that I can compare them with other sentences using cosine similarity. Since I'm dealing with so many sentences, what would be the most efficient way to get the word embeddings? So far I've been using the [sentence-transformers](https://github.com/UKPLab/sentence-transformers) package (my model is initialized as SentenceTransformer('bert-base-nli-max-tokens')), but using this would take around 24 hours if not more to get the word embeddings of all sentences. If that's as fast as it can get I'm fine with that, but was wondering if there's a way to do this more efficiently?",https://www.reddit.com/r/LanguageTechnology/comments/miyrcq/most_efficient_method_for_converting_300k/,LanguageTechnology,t3_miyrcq,"Most efficient method for converting ~300k sentences to word embeddings? I'm working on a project where I need to get the word embeddings of around 300,000 sentences so that I can compare them with other sentences using cosine similarity. Since I'm dealing with so many sentences, what would be the most efficient way to get the word embeddings? So far I've been using the [sentence-transformers](https://github.com/UKPLab/sentence-transformers) package (my model is initialized as SentenceTransformer('bert-base-nli-max-tokens')), but using this would take around 24 hours if not more to get the word embeddings of all sentences. If that's as fast as it can get I'm fine with that, but was wondering if there's a way to do this more efficiently?",746
412,412,Conditional Text Generation (About Me),"I'm looking for resources/code which will allow me to generate text (Introduction/About Me) based on defined text inputs like Name, Place,  Occupation, etc.   


I was able to find a good relatable paper but there is no available code for [ToTTo: A Controlled Table-To-Text Generation Dataset](https://paperswithcode.com/paper/totto-a-controlled-table-to-text-generation) . If anyone have done something in generation or have some idea then it will be helpful.  
thanks in advance.",https://www.reddit.com/r/LanguageTechnology/comments/mis4ye/conditional_text_generation_about_me/,LanguageTechnology,t3_mis4ye,"Conditional Text Generation (About Me) I'm looking for resources/code which will allow me to generate text (Introduction/About Me) based on defined text inputs like Name, Place,  Occupation, etc.   


I was able to find a good relatable paper but there is no available code for [ToTTo: A Controlled Table-To-Text Generation Dataset](https://paperswithcode.com/paper/totto-a-controlled-table-to-text-generation) . If anyone have done something in generation or have some idea then it will be helpful.  
thanks in advance.",520
413,413,"Any good tutorial for NLP using Tensorflow for classification, word embedding, ... WITHOUT imdb dataset.","I can't find any good tutorial to learn all these strategies with my own csv dataset with labeled reviews. As I don't have the same data structure of imdb dataset, I can't follow any tutorial based on official documentation. Every f tutorial is based on the same example!

Anyway, I would appreciate any good resource!",https://www.reddit.com/r/LanguageTechnology/comments/mim9im/any_good_tutorial_for_nlp_using_tensorflow_for/,LanguageTechnology,t3_mim9im,"Any good tutorial for NLP using Tensorflow for classification, word embedding, ... WITHOUT imdb dataset. I can't find any good tutorial to learn all these strategies with my own csv dataset with labeled reviews. As I don't have the same data structure of imdb dataset, I can't follow any tutorial based on official documentation. Every f tutorial is based on the same example!

Anyway, I would appreciate any good resource!",423
414,414,"New date announced for language tech series, on Terminology Management Tools","The third webinar in the language tech series now has a date!

[https://us02web.zoom.us/webinar/register/8416174045220/WN\_DQnctbT7RD-Q7BzYzy2TsQ](https://us02web.zoom.us/webinar/register/8416174045220/WN_DQnctbT7RD-Q7BzYzy2TsQ)",https://www.reddit.com/r/LanguageTechnology/comments/miw0n9/new_date_announced_for_language_tech_series_on/,LanguageTechnology,t3_miw0n9,"New date announced for language tech series, on Terminology Management Tools The third webinar in the language tech series now has a date!

[https://us02web.zoom.us/webinar/register/8416174045220/WN\_DQnctbT7RD-Q7BzYzy2TsQ](https://us02web.zoom.us/webinar/register/8416174045220/WN_DQnctbT7RD-Q7BzYzy2TsQ)",305
415,415,More examples or longer examples for small dataset classification problem,"I have a problem in this vein, and was wondering what everyone thought:

**Problem:** Classify 2-line snippets of poems by their author.

**Data:** I have 9 poets from whom I've collected anywhere from 150-250 poems.  Assume that this dataset can't get any bigger.  

**Method:** Log. Reg./SVM/KNN as basline, ultimately implementing word-level and subword-level CNN (which is the point of the experiment, mining out the different between word-level vs. subword level models in this domain).

Now my question is, with such a small amount of data, should I split the poems into 2-line snippets for training, and thus have \~2500-5000 examples per author, or should I train with larger chunks that will have more semantic information (e.g. 4 lines, entire stanzas, entire poems)?  Additionally, assuming the answer is something along the line of ""it depends,"" what are some tools for exploring this tradeoff and deciding what to train with?

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/miiy76/more_examples_or_longer_examples_for_small/,LanguageTechnology,t3_miiy76,"More examples or longer examples for small dataset classification problem I have a problem in this vein, and was wondering what everyone thought:

**Problem:** Classify 2-line snippets of poems by their author.

**Data:** I have 9 poets from whom I've collected anywhere from 150-250 poems.  Assume that this dataset can't get any bigger.  

**Method:** Log. Reg./SVM/KNN as basline, ultimately implementing word-level and subword-level CNN (which is the point of the experiment, mining out the different between word-level vs. subword level models in this domain).

Now my question is, with such a small amount of data, should I split the poems into 2-line snippets for training, and thus have \~2500-5000 examples per author, or should I train with larger chunks that will have more semantic information (e.g. 4 lines, entire stanzas, entire poems)?  Additionally, assuming the answer is something along the line of ""it depends,"" what are some tools for exploring this tradeoff and deciding what to train with?

Thanks!",1021
416,416,How to Train a Joint Entities and Relation Extraction Classifier using BERT Transformer with spaCy 3," Looking to add relation extraction classifier to your NER?

Checkout our [new article](https://walidamamou.medium.com/how-to-train-a-joint-entities-and-relation-extraction-classifier-using-bert-transformer-with-spacy-49eb08d91b5c) on how to train a joint entities and relation extraction classifier using BERT Transformer with spaCy 3.",https://www.reddit.com/r/LanguageTechnology/comments/minujj/how_to_train_a_joint_entities_and_relation/,LanguageTechnology,t3_minujj,"How to Train a Joint Entities and Relation Extraction Classifier using BERT Transformer with spaCy 3  Looking to add relation extraction classifier to your NER?

Checkout our [new article](https://walidamamou.medium.com/how-to-train-a-joint-entities-and-relation-extraction-classifier-using-bert-transformer-with-spacy-49eb08d91b5c) on how to train a joint entities and relation extraction classifier using BERT Transformer with spaCy 3.",437
417,417,Machine Translation in Argos Translate (2021),,https://youtu.be/yn37-CpRzTc,LanguageTechnology,t3_mirlz0,Machine Translation in Argos Translate (2021) ,46
418,418,Made website with best resources I could find on Transformers,"I spent \~50 hours looking for the best resources on various Transformer models and organized them into a website [backprop.org](https://backprop.org/).

The website is intended to help everyone learn faster by directly connecting you to the best resources without having to hunt everything down yourself.

Check it out! If people find this useful I'll add more pages on more NLP topics. Already planning on adding pages about RNNs, LSTMs, GRUs, etc.

Also, if you know any great resources that I missed send it my way!",https://www.reddit.com/r/LanguageTechnology/comments/mhv7dw/made_website_with_best_resources_i_could_find_on/,LanguageTechnology,t3_mhv7dw,"Made website with best resources I could find on Transformers I spent \~50 hours looking for the best resources on various Transformer models and organized them into a website [backprop.org](https://backprop.org/).

The website is intended to help everyone learn faster by directly connecting you to the best resources without having to hunt everything down yourself.

Check it out! If people find this useful I'll add more pages on more NLP topics. Already planning on adding pages about RNNs, LSTMs, GRUs, etc.

Also, if you know any great resources that I missed send it my way!",581
419,419,"Beginners in NLP, need your feedback. Made this video explaining building neural semantic search using open-source project Jina(think search like google). How good is this explanation?",,https://www.youtube.com/watch?v=zvXkQkqd2I8&amp;feature=youtu.be,LanguageTechnology,t3_mhyapm,"Beginners in NLP, need your feedback. Made this video explaining building neural semantic search using open-source project Jina(think search like google). How good is this explanation? ",185
420,420,"The Conversational AI and NLP Summit takes place later this month. See the speaker list and agenda below! Speaking companies include Deepmind, Facebook and more.",,https://www.re-work.co/events/conversational-ai-nlp-summit-2021?utm_source=LK&amp;utm_medium=EB_Promo&amp;utm_campaign=LK_CONV_NLP_EB,LanguageTechnology,t3_mhtihs,"The Conversational AI and NLP Summit takes place later this month. See the speaker list and agenda below! Speaking companies include Deepmind, Facebook and more. ",162
421,421,Training AI on anti-corruption," Hi everyone, 

please excuse me if this is the wrong place to post! 

Myself and a small team are looking to train an existing AI tool to be able to identify corruption in organisations, and I am looking for historical examples to train it on. In particular, at this stage, I am looking for concrete text-based examples where evidence of corrupt practices is clearly visible (e.g. from meeting protocols/minutes, emails or other company communications, …) and should be from corruption scandals where text document-based leaks took place e.g. from Panama papers, Fifa scandal, Enron, 1MDB, Odebrecht, etc. 

At this stage of the project, we do not have the resources to go through the corpora manually to look for these concrete examples, therefore I have been looking for examples from the corpora which have been cited in academic papers or newspaper articles. At a later stage, the AI would be able to go through the corruption corpus itself. So far, my search to find such examples have been unsuccessful. 

I realise that corruption is a very clandestine topic, which is probably why I am having such difficulty. If anyone has ideas of how I can find articles etc where the data has already been interpreted and show concrete examples of corruption, then I would very much appreciate it!

Many thanks!",https://www.reddit.com/r/LanguageTechnology/comments/mhsk34/training_ai_on_anticorruption/,LanguageTechnology,t3_mhsk34,"Training AI on anti-corruption  Hi everyone, 

please excuse me if this is the wrong place to post! 

Myself and a small team are looking to train an existing AI tool to be able to identify corruption in organisations, and I am looking for historical examples to train it on. In particular, at this stage, I am looking for concrete text-based examples where evidence of corrupt practices is clearly visible (e.g. from meeting protocols/minutes, emails or other company communications, …) and should be from corruption scandals where text document-based leaks took place e.g. from Panama papers, Fifa scandal, Enron, 1MDB, Odebrecht, etc. 

At this stage of the project, we do not have the resources to go through the corpora manually to look for these concrete examples, therefore I have been looking for examples from the corpora which have been cited in academic papers or newspaper articles. At a later stage, the AI would be able to go through the corruption corpus itself. So far, my search to find such examples have been unsuccessful. 

I realise that corruption is a very clandestine topic, which is probably why I am having such difficulty. If anyone has ideas of how I can find articles etc where the data has already been interpreted and show concrete examples of corruption, then I would very much appreciate it!

Many thanks!",1338
422,422,Trankit v1.0.0 - An open-source Transformer-based Multilingual NLP Toolkit for 56 languages is out.,"Hi everyone,

We just released the version 1.0.0 for our Transformer-based Multilingual NLP toolkit named Trankit which outperforms the popular SOTA Stanford NLP (Stanza) in many tasks over 56 different languages.

### 💥 💥 💥 The new version v1.0.0 offers:

* **A trainable pipeline for fundamental NLP tasks over 100 languages**.
* **90 new pretrained transformer-based pipelines for 56 languages**. The new pipelines are trained with XLM-Roberta large, which further boosts the performance significantly over 90 treebanks of the Universal Dependencies v2.5 corpus. For **English**, Trankit is significantly better than Stanza on sentence segmentation (**+9.36%**) and dependency parsing (**+5.07%** for UAS and **+5.81%** for LAS). For **Arabic**, our toolkit substantially improves sentence segmentation performance by **16.36%** while **Chinese** observes **14.50%** and **15.0%** improvement of UAS and LAS for dependency parsing. Performance on other languages is also significantly improved. The detailed comparison between Trankit, Stanza, UDPipe, Spacy on other languages can be found  [here](https://trankit.readthedocs.io/en/latest/performance.html#universal-dependencies-v2-5) .
* **Auto Mode for multilingual pipelines**. In the Auto Mode, the language of the input will be automatically detected, enabling the multilingual pipelines to process the input without specifying its language.  Check out how to turn on the Auto Mode [here](https://trankit.readthedocs.io/en/latest/news.html#auto-mode-for-multilingual-pipelines). 
* **Command-line interface** is now available to use. This helps users who are not familiar with Python programming language can use Trankit more easily.  Check out the command-line tutorials on this [page](https://trankit.readthedocs.io/en/latest/commandline.html). 

**Trankit is written in Python** and can be easily installed via pip. Our code and pretrained models are publicly available at: [https://github.com/nlp-uoregon/trankit](https://github.com/nlp-uoregon/trankit)

We also created a documentation page and a demo website for Trankit.

Documentation page: [https://trankit.readthedocs.io/en/latest/index.html](https://trankit.readthedocs.io/en/latest/index.html)

Demo website: [http://nlp.uoregon.edu/trankit](http://nlp.uoregon.edu/trankit)

Technical details about Trankit can be found in our paper: [https://arxiv.org/pdf/2101.03289.pdf](https://arxiv.org/pdf/2101.03289.pdf)

Thank you for your time reading this post!

Hope you enjoy Trankit!",https://www.reddit.com/r/LanguageTechnology/comments/mhhs3a/trankit_v100_an_opensource_transformerbased/,LanguageTechnology,t3_mhhs3a,"Trankit v1.0.0 - An open-source Transformer-based Multilingual NLP Toolkit for 56 languages is out. Hi everyone,

We just released the version 1.0.0 for our Transformer-based Multilingual NLP toolkit named Trankit which outperforms the popular SOTA Stanford NLP (Stanza) in many tasks over 56 different languages.

### 💥 💥 💥 The new version v1.0.0 offers:

* **A trainable pipeline for fundamental NLP tasks over 100 languages**.
* **90 new pretrained transformer-based pipelines for 56 languages**. The new pipelines are trained with XLM-Roberta large, which further boosts the performance significantly over 90 treebanks of the Universal Dependencies v2.5 corpus. For **English**, Trankit is significantly better than Stanza on sentence segmentation (**+9.36%**) and dependency parsing (**+5.07%** for UAS and **+5.81%** for LAS). For **Arabic**, our toolkit substantially improves sentence segmentation performance by **16.36%** while **Chinese** observes **14.50%** and **15.0%** improvement of UAS and LAS for dependency parsing. Performance on other languages is also significantly improved. The detailed comparison between Trankit, Stanza, UDPipe, Spacy on other languages can be found  [here](https://trankit.readthedocs.io/en/latest/performance.html#universal-dependencies-v2-5) .
* **Auto Mode for multilingual pipelines**. In the Auto Mode, the language of the input will be automatically detected, enabling the multilingual pipelines to process the input without specifying its language.  Check out how to turn on the Auto Mode [here](https://trankit.readthedocs.io/en/latest/news.html#auto-mode-for-multilingual-pipelines). 
* **Command-line interface** is now available to use. This helps users who are not familiar with Python programming language can use Trankit more easily.  Check out the command-line tutorials on this [page](https://trankit.readthedocs.io/en/latest/commandline.html). 

**Trankit is written in Python** and can be easily installed via pip. Our code and pretrained models are publicly available at: [https://github.com/nlp-uoregon/trankit](https://github.com/nlp-uoregon/trankit)

We also created a documentation page and a demo website for Trankit.

Documentation page: [https://trankit.readthedocs.io/en/latest/index.html](https://trankit.readthedocs.io/en/latest/index.html)

Demo website: [http://nlp.uoregon.edu/trankit](http://nlp.uoregon.edu/trankit)

Technical details about Trankit can be found in our paper: [https://arxiv.org/pdf/2101.03289.pdf](https://arxiv.org/pdf/2101.03289.pdf)

Thank you for your time reading this post!

Hope you enjoy Trankit!",2599
423,423,Reformulating Unsupervised Style Transfer as Paraphrase Generation | Research Paper Walkthrough,,https://youtu.be/cjnk3PJljDs,LanguageTechnology,t3_mhsxa9,Reformulating Unsupervised Style Transfer as Paraphrase Generation | Research Paper Walkthrough ,96
424,424,A Python library to boost T5 models speed up to 5x &amp; reduce the model size by 3x.,"I wanted to share this new library I've been working on and that I open-sourced!.

here are some links to the library:

💻 [GitHub Repository](https://github.com/Ki6an/fastT5)

🐍 [PyPi project](https://pypi.org/project/fastt5/)

as the title suggests, you can increase the inference speed of any pretrained T5 model and also decrease the models' size, in a single line of code.

The library can be installed with `pip install fastt5`. This code snippet from the repository's README gives a concise overview:

    from fastT5 import export_and_get_onnx_model
    from transformers import AutoTokenizer
    
    model_name = 't5-small'
    model = export_and_get_onnx_model(model_name)
    
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    t_input = ""translate English to French: The universe is a dark forest.""
    token = tokenizer(t_input, return_tensors='pt')
    
    tokens = model.generate(input_ids=token['input_ids'],
                   attention_mask=token['attention_mask'],
                   num_beams=2)
    
    output = tokenizer.decode(tokens.squeeze(), skip_special_tokens=True)
    print(output)

The fastT5 library exports the T5 model to onnx with `past_key_values,` then quantizes it and runs it on onnxruntime.

The exported onnx models support the `generate()` method of huggingface transformers for inferencing.

for more information on the project refer to the repository [here](https://github.com/Ki6an/fastT5#reduce-t5-model-size-by-3x-and-increase-the-inference-speed-up-to-5x).",https://www.reddit.com/r/LanguageTechnology/comments/mh6dtg/a_python_library_to_boost_t5_models_speed_up_to/,LanguageTechnology,t3_mh6dtg,"A Python library to boost T5 models speed up to 5x &amp; reduce the model size by 3x. I wanted to share this new library I've been working on and that I open-sourced!.

here are some links to the library:

💻 [GitHub Repository](https://github.com/Ki6an/fastT5)

🐍 [PyPi project](https://pypi.org/project/fastt5/)

as the title suggests, you can increase the inference speed of any pretrained T5 model and also decrease the models' size, in a single line of code.

The library can be installed with `pip install fastt5`. This code snippet from the repository's README gives a concise overview:

    from fastT5 import export_and_get_onnx_model
    from transformers import AutoTokenizer
    
    model_name = 't5-small'
    model = export_and_get_onnx_model(model_name)
    
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    t_input = ""translate English to French: The universe is a dark forest.""
    token = tokenizer(t_input, return_tensors='pt')
    
    tokens = model.generate(input_ids=token['input_ids'],
                   attention_mask=token['attention_mask'],
                   num_beams=2)
    
    output = tokenizer.decode(tokens.squeeze(), skip_special_tokens=True)
    print(output)

The fastT5 library exports the T5 model to onnx with `past_key_values,` then quantizes it and runs it on onnxruntime.

The exported onnx models support the `generate()` method of huggingface transformers for inferencing.

for more information on the project refer to the repository [here](https://github.com/Ki6an/fastT5#reduce-t5-model-size-by-3x-and-increase-the-inference-speed-up-to-5x).",1603
425,425,Sentence Transformers: Sentence-BERT - Sentence Embeddings using Siamese BERT-Networks | arXiv demo,,https://youtu.be/4I3gS1cmqe4,LanguageTechnology,t3_mho2ia,Sentence Transformers: Sentence-BERT - Sentence Embeddings using Siamese BERT-Networks | arXiv demo ,100
426,426,Euphemism Corpora?,"Hello,

I am a Computational Linguistics graduate student, and my peers and I are searching for corpora dealing with euphemisms/dysphemisms. We are interested in automatic detection of euphemisms (and other non-literal speech usage), but have yet to find any substantial collections. 

We are willing to create a corpus if none exists, but would like to have a comprehensive idea of previous work before embarking on creating our own. Any help would be appreciated!",https://www.reddit.com/r/LanguageTechnology/comments/mh9xlm/euphemism_corpora/,LanguageTechnology,t3_mh9xlm,"Euphemism Corpora? Hello,

I am a Computational Linguistics graduate student, and my peers and I are searching for corpora dealing with euphemisms/dysphemisms. We are interested in automatic detection of euphemisms (and other non-literal speech usage), but have yet to find any substantial collections. 

We are willing to create a corpus if none exists, but would like to have a comprehensive idea of previous work before embarking on creating our own. Any help would be appreciated!",484
427,427,Google AI Proposes A Machine Learning Algorithm For Teaching Agents To Solve New Tasks By Providing Examples Of Success,"Most reinforcement learning algorithms work on a ‘reward’ function to teach the agents in an unknown environment. The reward is given if the action taken results in a good outcome. But it’s a difficult task to define rewards for situations lacking clear objectives. For example, whether a room is clean or if a door is sufficiently shut. In such scenarios, the user cannot describe the task in words or numbers; however, he can readily provide examples of how the world would look like if it were solved.

Thus, Google AI suggests an alternative, example-based control, which aims at teaching agents how to solve new tasks by providing examples of success. This is termed as **recursive classification of examples (RCE)**. It does not rely on formulated reward functions, distance functions, or features. It instead just uses the examples of success. RCE performs better than the prior approaches based on [imitation learning](https://arxiv.org/pdf/1811.06711.pdf) on simulated robotics tasks.

Summary: https://www.marktechpost.com/2021/03/31/google-ai-proposes-a-machine-learning-algorithm-for-teaching-agents-to-solve-new-tasks-by-providing-examples-of-success/

Summary: [https://www.marktechpost.com/2021/03/31/google-ai-proposes-a-machine-learning-algorithm-for-teaching-agents-to-solve-new-tasks-by-providing-examples-of-success/](https://www.marktechpost.com/2021/03/31/google-ai-proposes-a-machine-learning-algorithm-for-teaching-agents-to-solve-new-tasks-by-providing-examples-of-success/) 

Source: https://ai.googleblog.com/2021/03/recursive-classification-replacing.html

GitHub: https://github.com/google-research/google-research/tree/master/rce

Related videos: https://ben-eysenbach.github.io/rce/",https://www.reddit.com/r/LanguageTechnology/comments/mh8zao/google_ai_proposes_a_machine_learning_algorithm/,LanguageTechnology,t3_mh8zao,"Google AI Proposes A Machine Learning Algorithm For Teaching Agents To Solve New Tasks By Providing Examples Of Success Most reinforcement learning algorithms work on a ‘reward’ function to teach the agents in an unknown environment. The reward is given if the action taken results in a good outcome. But it’s a difficult task to define rewards for situations lacking clear objectives. For example, whether a room is clean or if a door is sufficiently shut. In such scenarios, the user cannot describe the task in words or numbers; however, he can readily provide examples of how the world would look like if it were solved.

Thus, Google AI suggests an alternative, example-based control, which aims at teaching agents how to solve new tasks by providing examples of success. This is termed as **recursive classification of examples (RCE)**. It does not rely on formulated reward functions, distance functions, or features. It instead just uses the examples of success. RCE performs better than the prior approaches based on [imitation learning](https://arxiv.org/pdf/1811.06711.pdf) on simulated robotics tasks.

Summary: https://www.marktechpost.com/2021/03/31/google-ai-proposes-a-machine-learning-algorithm-for-teaching-agents-to-solve-new-tasks-by-providing-examples-of-success/

Summary: [https://www.marktechpost.com/2021/03/31/google-ai-proposes-a-machine-learning-algorithm-for-teaching-agents-to-solve-new-tasks-by-providing-examples-of-success/](https://www.marktechpost.com/2021/03/31/google-ai-proposes-a-machine-learning-algorithm-for-teaching-agents-to-solve-new-tasks-by-providing-examples-of-success/) 

Source: https://ai.googleblog.com/2021/03/recursive-classification-replacing.html

GitHub: https://github.com/google-research/google-research/tree/master/rce

Related videos: https://ben-eysenbach.github.io/rce/",1833
428,428,Counting the length between syntactic elements / clauses,"This might be a little tricky, or even impossible without a previously tagged corpus but is there anyway to count the length between syntactic elements? 

For example, I may want to count the length between the matrix verb in a clause and up until the embedded verb as in 'I knew that last week I saw my friend' - so the count here would be 'knew that last week I' = 4. Is this possible at all using Python? Ideally I'd like to set more params but you get the idea.",https://www.reddit.com/r/LanguageTechnology/comments/mh29eb/counting_the_length_between_syntactic_elements/,LanguageTechnology,t3_mh29eb,"Counting the length between syntactic elements / clauses This might be a little tricky, or even impossible without a previously tagged corpus but is there anyway to count the length between syntactic elements? 

For example, I may want to count the length between the matrix verb in a clause and up until the embedded verb as in 'I knew that last week I saw my friend' - so the count here would be 'knew that last week I' = 4. Is this possible at all using Python? Ideally I'd like to set more params but you get the idea.",522
429,429,Hawking Date Time Parser is Open-Source Now,"It's a great pleasure to announce our Natural Language Date Time Parser using Stanford coreNLP in the backend is open-source now. Do Check and Let us Know the Feedback.  
Github: [https://github.com/zoho/hawking](https://github.com/zoho/hawking)

Blog : [https://www.zoho.com/blog/general/zias-nlp-based-hawking-date-time-parser-is-now-open-source.html](https://www.zoho.com/blog/general/zias-nlp-based-hawking-date-time-parser-is-now-open-source.html)  
Tweet from [Stanford University](https://twitter.com/stanfordnlp) :  [https://twitter.com/stanfordnlp/status/1376914683127492614?s=20](https://twitter.com/stanfordnlp/status/1376914683127492614?s=20)

\#nlp #stanfordnlp #datetimeparser",https://www.reddit.com/r/LanguageTechnology/comments/mgmkuh/hawking_date_time_parser_is_opensource_now/,LanguageTechnology,t3_mgmkuh,"Hawking Date Time Parser is Open-Source Now It's a great pleasure to announce our Natural Language Date Time Parser using Stanford coreNLP in the backend is open-source now. Do Check and Let us Know the Feedback.  
Github: [https://github.com/zoho/hawking](https://github.com/zoho/hawking)

Blog : [https://www.zoho.com/blog/general/zias-nlp-based-hawking-date-time-parser-is-now-open-source.html](https://www.zoho.com/blog/general/zias-nlp-based-hawking-date-time-parser-is-now-open-source.html)  
Tweet from [Stanford University](https://twitter.com/stanfordnlp) :  [https://twitter.com/stanfordnlp/status/1376914683127492614?s=20](https://twitter.com/stanfordnlp/status/1376914683127492614?s=20)

\#nlp #stanfordnlp #datetimeparser",734
430,430,How would you preprocess human names?," I have a dataset of names, full names which consist of three names, and they are labeled with their gender.

I am using Sklearn for this task. This is not a coding question I  guess, it theoretical. How I would represent or preprocess those names to predict their gender after the training of the model. I am aware of the many ways for this task such as vectorization and embedding but I am not sure if they are the best for data consists of names and gender.

I can't show any progress in my work since I am still in the data collection stage.

What I am trying to do is similar to what is going on in this paper: [https://arxiv.org/abs/2010.10852](https://arxiv.org/abs/2010.10852)

Appreciate the help, thank you",https://www.reddit.com/r/LanguageTechnology/comments/mgqyda/how_would_you_preprocess_human_names/,LanguageTechnology,t3_mgqyda,"How would you preprocess human names?  I have a dataset of names, full names which consist of three names, and they are labeled with their gender.

I am using Sklearn for this task. This is not a coding question I  guess, it theoretical. How I would represent or preprocess those names to predict their gender after the training of the model. I am aware of the many ways for this task such as vectorization and embedding but I am not sure if they are the best for data consists of names and gender.

I can't show any progress in my work since I am still in the data collection stage.

What I am trying to do is similar to what is going on in this paper: [https://arxiv.org/abs/2010.10852](https://arxiv.org/abs/2010.10852)

Appreciate the help, thank you",754
431,431,"Interactive Research Graph for New Paper ""Approximating How Single Head Attention Learns""","I am sharing our [new interactive graph](https://crossminds.ai/graphlist/approximating-how-single-head-attention-learns-605e84761fb2cdbb7230ffcf/) project that maps out knowledge-paper connections for the paper ""Approximating How Single Head Attention Learns"" published earlier this month by Berkeley NLP. You can click the graph nodes to explore the most relevant papers with videos and key knowledge areas. This page also includes a list of related papers without videos. [You can try it here.](https://crossminds.ai/graphlist/approximating-how-single-head-attention-learns-605e84761fb2cdbb7230ffcf/)

I'd be curious to learn your thoughts. Do you find it helpful? How can we make it more useful for understanding new research papers/areas? Thank you!",https://www.reddit.com/r/LanguageTechnology/comments/mgn2k0/interactive_research_graph_for_new_paper/,LanguageTechnology,t3_mgn2k0,"Interactive Research Graph for New Paper ""Approximating How Single Head Attention Learns"" I am sharing our [new interactive graph](https://crossminds.ai/graphlist/approximating-how-single-head-attention-learns-605e84761fb2cdbb7230ffcf/) project that maps out knowledge-paper connections for the paper ""Approximating How Single Head Attention Learns"" published earlier this month by Berkeley NLP. You can click the graph nodes to explore the most relevant papers with videos and key knowledge areas. This page also includes a list of related papers without videos. [You can try it here.](https://crossminds.ai/graphlist/approximating-how-single-head-attention-learns-605e84761fb2cdbb7230ffcf/)

I'd be curious to learn your thoughts. Do you find it helpful? How can we make it more useful for understanding new research papers/areas? Thank you!",843
432,432,Med7: A Clinical Named Entity Recognition Model | Paper Explained | #NLproc | #spaCy,,https://youtu.be/PTu89JoxBTw,LanguageTechnology,t3_mgaxq1,Med7: A Clinical Named Entity Recognition Model | Paper Explained | #NLproc | #spaCy ,85
433,433,[Q] How to truncate text to max. permissible tokens within Huggingface Pipeline?,"At the moment, I am having to manually correct for tokens in order to force limit them to 512 tokens -- the limit for distilBERT

Can some please guide me to a solution which works with Feature Extraction Pipeline?

`tokenizer = AutoTokenizer.from_pretrained(""distilbert-base-uncased"")`

`model = AutoModel.from_pretrained(""distilbert-base-uncased"")`

`model_use = pipeline('feature-extraction', model=model, tokenizer=tokenizer) `

`embedding = model_use( text )`



Thanks",https://www.reddit.com/r/LanguageTechnology/comments/mgcbfj/q_how_to_truncate_text_to_max_permissible_tokens/,LanguageTechnology,t3_mgcbfj,"[Q] How to truncate text to max. permissible tokens within Huggingface Pipeline? At the moment, I am having to manually correct for tokens in order to force limit them to 512 tokens -- the limit for distilBERT

Can some please guide me to a solution which works with Feature Extraction Pipeline?

`tokenizer = AutoTokenizer.from_pretrained(""distilbert-base-uncased"")`

`model = AutoModel.from_pretrained(""distilbert-base-uncased"")`

`model_use = pipeline('feature-extraction', model=model, tokenizer=tokenizer) `

`embedding = model_use( text )`



Thanks",555
434,434,BA Ling - Exchange Program,"Hei mates, I’m currently studying a BA in Linguistics and planning doing an international exchange program offered by my local faculty. I’m quite interested in the biolinguistics framework (yes, chomskyan), evolution of language experimental linguistics and language technologies. Since these fields are not deeply investigated at my university, I am looking for institutions whose programs include the topics mentioned above. Hope I can get a review/advise from any of you!! These are my options:

1. University College London - UK (not my best bc london is $$$$ but if u got any info i will rlly appreciate it)
2. Newcastle University - UK
3. Lund University - Sweden
4. Copenhagen University - Denmark
5. University of Bergen - Norway
6. Tübingen Universität - Germany 
7. University of Helsinki - Finland

Txs &lt;3",https://www.reddit.com/r/LanguageTechnology/comments/mg7q37/ba_ling_exchange_program/,LanguageTechnology,t3_mg7q37,"BA Ling - Exchange Program Hei mates, I’m currently studying a BA in Linguistics and planning doing an international exchange program offered by my local faculty. I’m quite interested in the biolinguistics framework (yes, chomskyan), evolution of language experimental linguistics and language technologies. Since these fields are not deeply investigated at my university, I am looking for institutions whose programs include the topics mentioned above. Hope I can get a review/advise from any of you!! These are my options:

1. University College London - UK (not my best bc london is $$$$ but if u got any info i will rlly appreciate it)
2. Newcastle University - UK
3. Lund University - Sweden
4. Copenhagen University - Denmark
5. University of Bergen - Norway
6. Tübingen Universität - Germany 
7. University of Helsinki - Finland

Txs &lt;3",846
435,435,XLM Roberta - Maximum File Size,"Hi guys. I’m playing about with XLM Roberta Large XNLI and Python and I’m conscious it has a maximum file size of 512 tokens. 

Can anybody advice me how they are handling inputs that are larger than this? Any suggestions on code edit to only query 512 tokens to the model and ignore any more? Thanks all",https://www.reddit.com/r/LanguageTechnology/comments/mfwnl5/xlm_roberta_maximum_file_size/,LanguageTechnology,t3_mfwnl5,"XLM Roberta - Maximum File Size Hi guys. I’m playing about with XLM Roberta Large XNLI and Python and I’m conscious it has a maximum file size of 512 tokens. 

Can anybody advice me how they are handling inputs that are larger than this? Any suggestions on code edit to only query 512 tokens to the model and ignore any more? Thanks all",336
436,436,Update on my project to debug and visualize Python code by using a combination of conventional static analysis tools and the attention based AI model. - Please ask me any questions!,"I am sorry if my post doesn't sound like an innovation to you, but would like you to take a look as it evolved out of a research project! I thought people in this subreddit might be interested :) Oh and yes! Anyone can use it!

The model has been trained on bug fixes in open source Github projects, and the tool itself is largely written in Python and hoping to help python coders!

The repository I visualized as an example is: [https://metabob.com/gh/galt2x/fastapi](https://metabob.com/gh/galt2x/fastapi?utm_source=Reddit&amp;utm_medium=Reddit%20Post&amp;utm_campaign=Reddit%20Post%20(r%2FLanguageTechnology)%203-29)

The program works best on Google Chrome, If you would like to check out the website, I linked it [here](https://www.metabob.com/?utm_source=Reddit&amp;utm_medium=Reddit%20Post&amp;utm_campaign=Reddit%20Post%20(r%2FLanguageTechnology)%203-29).",https://www.reddit.com/r/LanguageTechnology/comments/mfu7jr/update_on_my_project_to_debug_and_visualize/,LanguageTechnology,t3_mfu7jr,"Update on my project to debug and visualize Python code by using a combination of conventional static analysis tools and the attention based AI model. - Please ask me any questions! I am sorry if my post doesn't sound like an innovation to you, but would like you to take a look as it evolved out of a research project! I thought people in this subreddit might be interested :) Oh and yes! Anyone can use it!

The model has been trained on bug fixes in open source Github projects, and the tool itself is largely written in Python and hoping to help python coders!

The repository I visualized as an example is: [https://metabob.com/gh/galt2x/fastapi](https://metabob.com/gh/galt2x/fastapi?utm_source=Reddit&amp;utm_medium=Reddit%20Post&amp;utm_campaign=Reddit%20Post%20(r%2FLanguageTechnology)%203-29)

The program works best on Google Chrome, If you would like to check out the website, I linked it [here](https://www.metabob.com/?utm_source=Reddit&amp;utm_medium=Reddit%20Post&amp;utm_campaign=Reddit%20Post%20(r%2FLanguageTechnology)%203-29).",1046
437,437,deep-significance: Easy and Better Significance Testing for Deep Neural Networks,,https://github.com/Kaleidophon/deep-significance,LanguageTechnology,t3_mfq8xn,deep-significance: Easy and Better Significance Testing for Deep Neural Networks ,81
438,438,Unit Test Case Generation with Transformers (Research Paper Walkthrough),,https://youtu.be/3tMqXWnHlfs,LanguageTechnology,t3_mfi5c4,Unit Test Case Generation with Transformers (Research Paper Walkthrough) ,73
439,439,NeMo Getting Started. Prototyping Conversational AI Application,"Hey all! Hope everyone is having a great Monday, I know I am. I want to let everyone know about a NVIDIA AI platform piece I use daily, NeMo.

[NVIDIA NeMo](https://github.com/NVIDIA/NeMo) is a toolkit for building new State-of-the-Art Conversational AI models. NeMo has separate collections for Automatic Speech Recognition (ASR), Natural Language Processing (NLP), and Text-to-Speech (TTS) models. Each collection consists of prebuilt modules that include everything needed to train on your data. Every module can easily be customized, extended, and composed to create new Conversational AI model architectures.

Conversational AI architectures are typically large and require a lot of data and compute for training. NeMo uses PyTorch Lightning for easy and performant multi-GPU/multi-node mixed-precision training.

[Cool collab notebook for getting started with NeMo](https://colab.research.google.com/github/NVIDIA/NeMo/blob/r1.0.0rc1/tutorials/NeMo_Getting_Started.ipynb) shows how we can construct a toy demo showing the ability to translate Russian audio files into English. That's what is so neat about NeMo is the pipeline is so diverse; we can translate these audio files into English, then if we wanted to, use BERT for the NLP task for the translated English as well. And so on and so on.

Anyways, I hope you enjoy this collab book, and to have a poke around NeMo afterwards.",https://www.reddit.com/r/LanguageTechnology/comments/mfsdnx/nemo_getting_started_prototyping_conversational/,LanguageTechnology,t3_mfsdnx,"NeMo Getting Started. Prototyping Conversational AI Application Hey all! Hope everyone is having a great Monday, I know I am. I want to let everyone know about a NVIDIA AI platform piece I use daily, NeMo.

[NVIDIA NeMo](https://github.com/NVIDIA/NeMo) is a toolkit for building new State-of-the-Art Conversational AI models. NeMo has separate collections for Automatic Speech Recognition (ASR), Natural Language Processing (NLP), and Text-to-Speech (TTS) models. Each collection consists of prebuilt modules that include everything needed to train on your data. Every module can easily be customized, extended, and composed to create new Conversational AI model architectures.

Conversational AI architectures are typically large and require a lot of data and compute for training. NeMo uses PyTorch Lightning for easy and performant multi-GPU/multi-node mixed-precision training.

[Cool collab notebook for getting started with NeMo](https://colab.research.google.com/github/NVIDIA/NeMo/blob/r1.0.0rc1/tutorials/NeMo_Getting_Started.ipynb) shows how we can construct a toy demo showing the ability to translate Russian audio files into English. That's what is so neat about NeMo is the pipeline is so diverse; we can translate these audio files into English, then if we wanted to, use BERT for the NLP task for the translated English as well. And so on and so on.

Anyways, I hope you enjoy this collab book, and to have a poke around NeMo afterwards.",1453
440,440,Error after adding Embedding Layer to my ANN,"Hello,

After adding embedding layer to my ANN I'm facing this issue. 

InvalidArgumentError:  indices[6,1] = -11 is not in [0, 6505)
	 [[node model_10/embedding_15/embedding_lookup (defined at &lt;ipython-input-125-fcde7e47b9e9&gt;:3) ]] [Op:__inference_train_function_11619]

Errors may have originated from an input operation.
Input Source operations connected to node model_10/embedding_15/embedding_lookup:
 model_10/embedding_15/embedding_lookup/10457 (defined at C:\Users\erdiv\.conda\envs\python-tf2.0\lib\contextlib.py:81)

Function call stack:
train_function",https://www.reddit.com/r/LanguageTechnology/comments/mfpn8i/error_after_adding_embedding_layer_to_my_ann/,LanguageTechnology,t3_mfpn8i,"Error after adding Embedding Layer to my ANN Hello,

After adding embedding layer to my ANN I'm facing this issue. 

InvalidArgumentError:  indices[6,1] = -11 is not in [0, 6505)
	 [[node model_10/embedding_15/embedding_lookup (defined at &lt;ipython-input-125-fcde7e47b9e9&gt;:3) ]] [Op:__inference_train_function_11619]

Errors may have originated from an input operation.
Input Source operations connected to node model_10/embedding_15/embedding_lookup:
 model_10/embedding_15/embedding_lookup/10457 (defined at C:\Users\erdiv\.conda\envs\python-tf2.0\lib\contextlib.py:81)

Function call stack:
train_function",613
441,441,Embedding Layer to XGBClassifier,"I have an Embedding Matrix resultant from the Word2Vec model. How can I use that in my XGBClassifier? How can I add an Embedding Layer to my XGBClassifier? 
(I'm new to NLP, Plese correct me if I'm wrong)",https://www.reddit.com/r/LanguageTechnology/comments/mfp7qk/embedding_layer_to_xgbclassifier/,LanguageTechnology,t3_mfp7qk,"Embedding Layer to XGBClassifier I have an Embedding Matrix resultant from the Word2Vec model. How can I use that in my XGBClassifier? How can I add an Embedding Layer to my XGBClassifier? 
(I'm new to NLP, Plese correct me if I'm wrong)",237
442,442,Emotion detection question,"I have a data which is already labeled different type of emotions based on text context:

Some of the label types: 

    funny, anger, boredom, empty, fun relief, sadness, happines

when I use TFIDF alongside Logistic Regression to predict it gives me a shitty result.

Here is the code:

    ### HERE GOES PREPROCESSING FIRST
    and then
    
    #Encoding output labels 'sadness' as '1' &amp; 'happiness' as '0'
    lbl_enc = preprocessing.LabelEncoder()
    y = lbl_enc.fit_transform(data.sentiment.values)
    
    # Splitting into training and testing data in 90:10 ratio
    X_train, X_val, y_train, y_val = train_test_split(data.content.values, y, stratify=y, random_state=42, test_size=0.1, shuffle=True)
    
    # Extracting TF-IDF parameters
    tfidf = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,3))
    X_train_tfidf = tfidf.fit_transform(X_train)
    X_val_tfidf = tfidf.fit_transform(X_val)
    
    # Model 3: logistic regression
    logreg = LogisticRegression(C=1,solver='lbfgs', max_iter=3000)
    logreg.fit(X_train_tfidf, y_train)
    y_pred = logreg.predict(X_val_tfidf)
    print('log reg tfidf accuracy %s' % accuracy_score(y_pred, y_val))

this is giving me a very bad result something like 0.2342355%

however, if I remove all types of emotions but leave only two. For example Happiness and Sadness,

it gives me a better result of 0.782342342%

&amp;#x200B;

Why is this?

How can i make it so that the model can predict not only 2 types of emotions but also other types f emotions such as *""Excitement, Fun, Relief""* and so on?

'",https://www.reddit.com/r/LanguageTechnology/comments/mfc5zo/emotion_detection_question/,LanguageTechnology,t3_mfc5zo,"Emotion detection question I have a data which is already labeled different type of emotions based on text context:

Some of the label types: 

    funny, anger, boredom, empty, fun relief, sadness, happines

when I use TFIDF alongside Logistic Regression to predict it gives me a shitty result.

Here is the code:

    ### HERE GOES PREPROCESSING FIRST
    and then
    
    #Encoding output labels 'sadness' as '1' &amp; 'happiness' as '0'
    lbl_enc = preprocessing.LabelEncoder()
    y = lbl_enc.fit_transform(data.sentiment.values)
    
    # Splitting into training and testing data in 90:10 ratio
    X_train, X_val, y_train, y_val = train_test_split(data.content.values, y, stratify=y, random_state=42, test_size=0.1, shuffle=True)
    
    # Extracting TF-IDF parameters
    tfidf = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,3))
    X_train_tfidf = tfidf.fit_transform(X_train)
    X_val_tfidf = tfidf.fit_transform(X_val)
    
    # Model 3: logistic regression
    logreg = LogisticRegression(C=1,solver='lbfgs', max_iter=3000)
    logreg.fit(X_train_tfidf, y_train)
    y_pred = logreg.predict(X_val_tfidf)
    print('log reg tfidf accuracy %s' % accuracy_score(y_pred, y_val))

this is giving me a very bad result something like 0.2342355%

however, if I remove all types of emotions but leave only two. For example Happiness and Sadness,

it gives me a better result of 0.782342342%

&amp;#x200B;

Why is this?

How can i make it so that the model can predict not only 2 types of emotions but also other types f emotions such as *""Excitement, Fun, Relief""* and so on?

'",1609
443,443,Tunning GPT2,"I have a specific task which i would like to fine tune a pre-trained GPT2 model. I know those models require a lot of data to train, but what about fine tuning? And how can i measure if my model is actually working for this specific task? I’ve tried to fine tune with about 1600 samples, but after the third epoch the model starts to overfit",https://www.reddit.com/r/LanguageTechnology/comments/mfbz76/tunning_gpt2/,LanguageTechnology,t3_mfbz76,"Tunning GPT2 I have a specific task which i would like to fine tune a pre-trained GPT2 model. I know those models require a lot of data to train, but what about fine tuning? And how can i measure if my model is actually working for this specific task? I’ve tried to fine tune with about 1600 samples, but after the third epoch the model starts to overfit",354
444,444,AI based search engine { Startup idea },"Obviously AI based search engine is the next step . Because of too much data available today on internet . We need this tool . I think it will be more interactive version of google . Where you can search based on size or similarity to other website , article or post . Or specify some part of text and find similar parts from other data sources .  To rate the quality of the search after search query . And there could be a lot more features . 

Idea is quite simple , it's all about execution . That's why I am searching for cofounders . Feel free to DM me  .  Potential investors are welcome too . Thank you for reading this ! Stay hungry , stay foolish )",https://www.reddit.com/r/LanguageTechnology/comments/mfovwn/ai_based_search_engine_startup_idea/,LanguageTechnology,t3_mfovwn,"AI based search engine { Startup idea } Obviously AI based search engine is the next step . Because of too much data available today on internet . We need this tool . I think it will be more interactive version of google . Where you can search based on size or similarity to other website , article or post . Or specify some part of text and find similar parts from other data sources .  To rate the quality of the search after search query . And there could be a lot more features . 

Idea is quite simple , it's all about execution . That's why I am searching for cofounders . Feel free to DM me  .  Potential investors are welcome too . Thank you for reading this ! Stay hungry , stay foolish )",697
445,445,Google AI Introduces a New System for Open-Domain Long-Form Question Answering (LFQA),"Open-domain long-on answering (LFQA) form questions a fundamental challenge in natural language processing (NLP) that involves retrieving documents relevant to a given query and using them to generate a detailed paragraph-length answer. 

Recently, there has been significant progress in factoid open-domain question answering (QA). In this technique, a short phrase or entity is enough to answer a question, but significantly less work has been done in long-form question answering (LFQA). LFQA is an important task, primarily because it provides a testbed to measure generative text models’ factuality. But, the current benchmarks and evaluation metrics aren’t quite suitable for making progress on LFQA.

In a recent paper, [“Hurdles to Progress in Long-form Question Answering”,](https://arxiv.org/abs/2103.06332) that is set to appear at NAACL 2021, Google.ai present a new system for open-domain long-form question answering that utilizes two recent advances in NLP: One is the state-of-the-art sparse attention models, such as Routing Transformer (RT), which allows attention-based models to scale to long sequences, and other is the retrieval-based models, like REALM, that can facilitate retrievals of Wikipedia articles related to a given query.

Short Summary: [https://www.marktechpost.com/2021/03/27/google-ai-introduces-a-new-system-for-open-domain-long-form-question-answering-lfqa/](https://www.marktechpost.com/2021/03/27/google-ai-introduces-a-new-system-for-open-domain-long-form-question-answering-lfqa/)

Google blog: [https://ai.googleblog.com/2021/03/progress-and-challenges-in-long-form.html](https://ai.googleblog.com/2021/03/progress-and-challenges-in-long-form.html)

Paper: [https://arxiv.org/abs/2103.06332](https://arxiv.org/abs/2103.06332)",https://www.reddit.com/r/LanguageTechnology/comments/mehj2t/google_ai_introduces_a_new_system_for_opendomain/,LanguageTechnology,t3_mehj2t,"Google AI Introduces a New System for Open-Domain Long-Form Question Answering (LFQA) Open-domain long-on answering (LFQA) form questions a fundamental challenge in natural language processing (NLP) that involves retrieving documents relevant to a given query and using them to generate a detailed paragraph-length answer. 

Recently, there has been significant progress in factoid open-domain question answering (QA). In this technique, a short phrase or entity is enough to answer a question, but significantly less work has been done in long-form question answering (LFQA). LFQA is an important task, primarily because it provides a testbed to measure generative text models’ factuality. But, the current benchmarks and evaluation metrics aren’t quite suitable for making progress on LFQA.

In a recent paper, [“Hurdles to Progress in Long-form Question Answering”,](https://arxiv.org/abs/2103.06332) that is set to appear at NAACL 2021, Google.ai present a new system for open-domain long-form question answering that utilizes two recent advances in NLP: One is the state-of-the-art sparse attention models, such as Routing Transformer (RT), which allows attention-based models to scale to long sequences, and other is the retrieval-based models, like REALM, that can facilitate retrievals of Wikipedia articles related to a given query.

Short Summary: [https://www.marktechpost.com/2021/03/27/google-ai-introduces-a-new-system-for-open-domain-long-form-question-answering-lfqa/](https://www.marktechpost.com/2021/03/27/google-ai-introduces-a-new-system-for-open-domain-long-form-question-answering-lfqa/)

Google blog: [https://ai.googleblog.com/2021/03/progress-and-challenges-in-long-form.html](https://ai.googleblog.com/2021/03/progress-and-challenges-in-long-form.html)

Paper: [https://arxiv.org/abs/2103.06332](https://arxiv.org/abs/2103.06332)",1856
446,446,Best description of attention?,"Where can I find the best description of the attention mechanism for NLP?  Blog post or video is good, but both are great!",https://www.reddit.com/r/LanguageTechnology/comments/menliz/best_description_of_attention/,LanguageTechnology,t3_menliz,"Best description of attention? Where can I find the best description of the attention mechanism for NLP?  Blog post or video is good, but both are great!",153
447,447,"Linguistic Data Science at University of Eastern Finland, how is it?","Is there anyone who has any information about this program? I could not find much info online. I have a linguistics background with little computer knowledge, what is the state of the work prospects I might get after the completion of this program? What languages are prominently being worked upon here? Especially from the point of view of an international (non EU) student, is the university nice? Are the job prospects there for international applicants? 

Also, anything you could tell me about the place, accommodation and part time jobs that I might take to sustain myself while studying? I've heard Nordic countries are very expensive to live in. Any info would be helpful at this point.",https://www.reddit.com/r/LanguageTechnology/comments/meix62/linguistic_data_science_at_university_of_eastern/,LanguageTechnology,t3_meix62,"Linguistic Data Science at University of Eastern Finland, how is it? Is there anyone who has any information about this program? I could not find much info online. I have a linguistics background with little computer knowledge, what is the state of the work prospects I might get after the completion of this program? What languages are prominently being worked upon here? Especially from the point of view of an international (non EU) student, is the university nice? Are the job prospects there for international applicants? 

Also, anything you could tell me about the place, accommodation and part time jobs that I might take to sustain myself while studying? I've heard Nordic countries are very expensive to live in. Any info would be helpful at this point.",763
448,448,Running Transformer model nearly kills my machine,"I have just a list of 43 texts. I have encoded them via [Bert Base](https://huggingface.co/bert-base-uncased) model from Huggingface, limited to 512 tokens.

```py
tokenized = df.text.apply(lambda text: tokenizer.tokenize(text)).to_list()
inputs = tokenizer(tokenized, is_split_into_words=True, truncation=True, max_length=512, padding='max_length', return_tensors='pt')
outputs = model(**inputs)  # this line fills my ram
```

I have 16 GB of RAM and another 16 GB of swap. When the third line is being run, the RAM usage goes beyond my machine's limitations. I have tried many different ways but didn't helped.

What could be done? My texts have long sentences, some of them may be consist of no sentences at all; could this be the problem?",https://www.reddit.com/r/LanguageTechnology/comments/med9c2/running_transformer_model_nearly_kills_my_machine/,LanguageTechnology,t3_med9c2,"Running Transformer model nearly kills my machine I have just a list of 43 texts. I have encoded them via [Bert Base](https://huggingface.co/bert-base-uncased) model from Huggingface, limited to 512 tokens.

```py
tokenized = df.text.apply(lambda text: tokenizer.tokenize(text)).to_list()
inputs = tokenizer(tokenized, is_split_into_words=True, truncation=True, max_length=512, padding='max_length', return_tensors='pt')
outputs = model(**inputs)  # this line fills my ram
```

I have 16 GB of RAM and another 16 GB of swap. When the third line is being run, the RAM usage goes beyond my machine's limitations. I have tried many different ways but didn't helped.

What could be done? My texts have long sentences, some of them may be consist of no sentences at all; could this be the problem?",792
449,449,Emotions extraction,"how to measure emotions while retrieving data from the text?

I know about the keyword-based methods, now i am more interested in the **Vector space model ( TF-IDF )** method. However, I can't find a working example of it, only research papers without any code.",https://www.reddit.com/r/LanguageTechnology/comments/me98xd/emotions_extraction/,LanguageTechnology,t3_me98xd,"Emotions extraction how to measure emotions while retrieving data from the text?

I know about the keyword-based methods, now i am more interested in the **Vector space model ( TF-IDF )** method. However, I can't find a working example of it, only research papers without any code.",281
450,450,Thoughts on MSc Language Science &amp; Tech at Saarland University?,"I was recently accepted to the program and I was wondering if anyone had any comments on it. Also, is it really free? Even for international students?
I appreciate any info you can provide. There’s not much info on their website. Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/mdy7tf/thoughts_on_msc_language_science_tech_at_saarland/,LanguageTechnology,t3_mdy7tf,"Thoughts on MSc Language Science &amp; Tech at Saarland University? I was recently accepted to the program and I was wondering if anyone had any comments on it. Also, is it really free? Even for international students?
I appreciate any info you can provide. There’s not much info on their website. Thanks!",305
451,451,Computing Words per Error of an N-Gram tagger using NLTK in Python?,"I've got a question - I'm trying to evaluate some sets of ngrams using a training set and a data set from a corpus and write some statistics about it. I have to include two measures: accuracy (which is easy using the "".evaluate"" module in NLTK. But I also have to find out the ""words/error"" rate of it. So for example I'm:

- using the Brown corpus' subcorpus ""news""
- this supcorpus has 100,554 words in total 
- I've split the corpus in to a training set of 500 sentences, and the rest are the testing set (the suborpus has 4,623 phrases in all). 
- I have a partially filled chart with an example:
 -  The default ngram tagger has an accuracy of 30.41% (when comparing the training and testing sets) and a error rate of **1.4 words/error**

But I can't figure out how this 1.4 words/error was calculated. Anyone have any ideas? I think, and I may be wrong here, that it's calculated as a function of the rest of the corpus that is NOT accurate - that is, 100%-30.41% = **69.95%** of the corpus. That number is then related to the total number of words somehow I think?",https://www.reddit.com/r/LanguageTechnology/comments/me3l1w/computing_words_per_error_of_an_ngram_tagger/,LanguageTechnology,t3_me3l1w,"Computing Words per Error of an N-Gram tagger using NLTK in Python? I've got a question - I'm trying to evaluate some sets of ngrams using a training set and a data set from a corpus and write some statistics about it. I have to include two measures: accuracy (which is easy using the "".evaluate"" module in NLTK. But I also have to find out the ""words/error"" rate of it. So for example I'm:

- using the Brown corpus' subcorpus ""news""
- this supcorpus has 100,554 words in total 
- I've split the corpus in to a training set of 500 sentences, and the rest are the testing set (the suborpus has 4,623 phrases in all). 
- I have a partially filled chart with an example:
 -  The default ngram tagger has an accuracy of 30.41% (when comparing the training and testing sets) and a error rate of **1.4 words/error**

But I can't figure out how this 1.4 words/error was calculated. Anyone have any ideas? I think, and I may be wrong here, that it's calculated as a function of the rest of the corpus that is NOT accurate - that is, 100%-30.41% = **69.95%** of the corpus. That number is then related to the total number of words somehow I think?",1139
452,452,Feedback on post - Overview of reading comprehension systems,"I wrote an overview of QA systems that covers early heuristic methods to modern neural net methods. I would appreciate any feedback you give! Thank you :)

[https://www.wittwise.com/blog/reading\_comprehension/](https://www.wittwise.com/blog/reading_comprehension/)",https://www.reddit.com/r/LanguageTechnology/comments/me1jpc/feedback_on_post_overview_of_reading/,LanguageTechnology,t3_me1jpc,"Feedback on post - Overview of reading comprehension systems I wrote an overview of QA systems that covers early heuristic methods to modern neural net methods. I would appreciate any feedback you give! Thank you :)

[https://www.wittwise.com/blog/reading\_comprehension/](https://www.wittwise.com/blog/reading_comprehension/)",326
453,453,Existing Datasets/ Corpus of Word Families,"Hello! Hope this question makes sense. I'm new to NLP and Python in general. I am using NLTK. I'm getting a Masters in Strategic Communications, and want to do some NLP for a couple of my projects. Specifically, I've been researching Political-based speech.

I want to evaluate pieces of text based on keywords in the text, and match those keywords to broader concepts. As a very rough example, ""Heartland"", ""Farmer"", ""Towns"" might all be classed under ""Small City"" while ""Army"", ""War"", ""Defense"", might all be classed under ""Strength"". I'm pretty open to what style of concept groups are being used (issue based ideas vs. economic based ideas, etc...)- I really just want to see if databases like this already exist so I don't have to start from square one. I'm gathering a lot of ideas based off of the Diction software program, if anyone is familiar. Ideally the concept groups would be housed in a dictionary, with the specific terms being listed as keys, but I'm not picky and if I have to re-format existing work, so be it. 

Also if you know of databases that exist that are not Political-based, I would be happy to see those as well. 

Any ideas or directions? I appreciate it!",https://www.reddit.com/r/LanguageTechnology/comments/mdvwx3/existing_datasets_corpus_of_word_families/,LanguageTechnology,t3_mdvwx3,"Existing Datasets/ Corpus of Word Families Hello! Hope this question makes sense. I'm new to NLP and Python in general. I am using NLTK. I'm getting a Masters in Strategic Communications, and want to do some NLP for a couple of my projects. Specifically, I've been researching Political-based speech.

I want to evaluate pieces of text based on keywords in the text, and match those keywords to broader concepts. As a very rough example, ""Heartland"", ""Farmer"", ""Towns"" might all be classed under ""Small City"" while ""Army"", ""War"", ""Defense"", might all be classed under ""Strength"". I'm pretty open to what style of concept groups are being used (issue based ideas vs. economic based ideas, etc...)- I really just want to see if databases like this already exist so I don't have to start from square one. I'm gathering a lot of ideas based off of the Diction software program, if anyone is familiar. Ideally the concept groups would be housed in a dictionary, with the specific terms being listed as keys, but I'm not picky and if I have to re-format existing work, so be it. 

Also if you know of databases that exist that are not Political-based, I would be happy to see those as well. 

Any ideas or directions? I appreciate it!",1228
454,454,Looking for a Dataset study,"Hello everyone, I've been looking for an article for some time now that I can't for the life of me find anymore...

It was about an NLP dataset (SQuAD, SNLI, or something like that). I mean, you had a text and three theses and the system was supposed to recognise which thesis was covered. One was surprised how well systems performed on this. Then they found out that a large part of the theses was recognised by the wording alone, without the system even knowing the background text. Does anyone know the corresponding article on this?",https://www.reddit.com/r/LanguageTechnology/comments/mdkwx7/looking_for_a_dataset_study/,LanguageTechnology,t3_mdkwx7,"Looking for a Dataset study Hello everyone, I've been looking for an article for some time now that I can't for the life of me find anymore...

It was about an NLP dataset (SQuAD, SNLI, or something like that). I mean, you had a text and three theses and the system was supposed to recognise which thesis was covered. One was surprised how well systems performed on this. Then they found out that a large part of the theses was recognised by the wording alone, without the system even knowing the background text. Does anyone know the corresponding article on this?",565
455,455,Computing perplexity,"For language models, perplexity is defined as the inverse probability of the test set, normalized by the number of words. So far, so clear.  
What confuses me is the following section:  


""What we generally use for word sequence (...) is the entire sequence of words in some test set. Since this sequence will cross many sentence boundaries, we need to include the begin- and end-sentence markers &lt;s&gt; and &lt;/s&gt; in the probability computation. We also need to include the end-of-sentence marker &lt;/s&gt; (but not the beginning-of-sentence marker &lt;s&gt;) in the total count of word tokens *N*."" 

\- Speech and Language Processing. Daniel Jurafsky &amp; James H. Martin.   


Why do we not include the beginning-of-sentence marker?",https://www.reddit.com/r/LanguageTechnology/comments/mdqyrq/computing_perplexity/,LanguageTechnology,t3_mdqyrq,"Computing perplexity For language models, perplexity is defined as the inverse probability of the test set, normalized by the number of words. So far, so clear.  
What confuses me is the following section:  


""What we generally use for word sequence (...) is the entire sequence of words in some test set. Since this sequence will cross many sentence boundaries, we need to include the begin- and end-sentence markers &lt;s&gt; and &lt;/s&gt; in the probability computation. We also need to include the end-of-sentence marker &lt;/s&gt; (but not the beginning-of-sentence marker &lt;s&gt;) in the total count of word tokens *N*."" 

\- Speech and Language Processing. Daniel Jurafsky &amp; James H. Martin.   


Why do we not include the beginning-of-sentence marker?",767
456,456,Doing an ML project and feel others would benefit from what you're doing?,"If you're doing an ML project and you think others would benefit from what you're doing, please consider sharing in Learn Data Science with Expert Guidance: [https://discord.gg/Gg3EJrn3](https://discord.gg/Gg3EJrn3) I created a place to share my project publicly for others and I came to realize that people entering data science really need expert guidance, so this server has a focus on bringing together experts and novices so that new entrants can build relationships with more experienced data scientists and feel confident in what they're studying and working on. Consider joining if you feel you have something to teach",https://www.reddit.com/r/LanguageTechnology/comments/mdpytq/doing_an_ml_project_and_feel_others_would_benefit/,LanguageTechnology,t3_mdpytq,"Doing an ML project and feel others would benefit from what you're doing? If you're doing an ML project and you think others would benefit from what you're doing, please consider sharing in Learn Data Science with Expert Guidance: [https://discord.gg/Gg3EJrn3](https://discord.gg/Gg3EJrn3) I created a place to share my project publicly for others and I came to realize that people entering data science really need expert guidance, so this server has a focus on bringing together experts and novices so that new entrants can build relationships with more experienced data scientists and feel confident in what they're studying and working on. Consider joining if you feel you have something to teach",700
457,457,Extract name:value relationships from plain text,"I have a microservice that receives plain-text messages from an external API like:

""... You have received 1254.56 from Thomas Paine. Transaction id FGR412512 at 11:02 ...""

Using Regex I can get:

`double amount = 1254.56;`

`String transactionId = FGR412512;`

`String time = 11.02;`

However, I would like to make my code more resilient to possible changes in text to, say, ""... at 11.02, Thomas Pain sent you 1254.56 ... "" in the future.

Is there a Natural Language Processing library or framework that I can use to extract these relationships and convert them to variables like I do with Regex?",https://www.reddit.com/r/LanguageTechnology/comments/mdlq1y/extract_namevalue_relationships_from_plain_text/,LanguageTechnology,t3_mdlq1y,"Extract name:value relationships from plain text I have a microservice that receives plain-text messages from an external API like:

""... You have received 1254.56 from Thomas Paine. Transaction id FGR412512 at 11:02 ...""

Using Regex I can get:

`double amount = 1254.56;`

`String transactionId = FGR412512;`

`String time = 11.02;`

However, I would like to make my code more resilient to possible changes in text to, say, ""... at 11.02, Thomas Pain sent you 1254.56 ... "" in the future.

Is there a Natural Language Processing library or framework that I can use to extract these relationships and convert them to variables like I do with Regex?",649
458,458,Current Sota for Multiclass Text Classification?,"Does anyone know where i can find data on the best performing multiclass text classifiers? [This](https://github.com/sebastianruder/NLP-progress/blob/master/english/text_classification.md) is the only info i could find and it seems it hasn't been updated since 2019.

I'm looking to use one of these for 3 class sentiment classification, negative, neutral, positive. Looking for data comparing the likes of:  

Mpnet

Electra

RoBERTa

BERT

ALBERT

Or any other better models i haven't heard of. 

&amp;#x200B;

On a side note i see a lot of benchmarks such as SQUAD have ensembles of 2 or more models. How is this done? Do they get predictions from both and then take the highest output vector score between the two of them as the prediction?",https://www.reddit.com/r/LanguageTechnology/comments/mdgac2/current_sota_for_multiclass_text_classification/,LanguageTechnology,t3_mdgac2,"Current Sota for Multiclass Text Classification? Does anyone know where i can find data on the best performing multiclass text classifiers? [This](https://github.com/sebastianruder/NLP-progress/blob/master/english/text_classification.md) is the only info i could find and it seems it hasn't been updated since 2019.

I'm looking to use one of these for 3 class sentiment classification, negative, neutral, positive. Looking for data comparing the likes of:  

Mpnet

Electra

RoBERTa

BERT

ALBERT

Or any other better models i haven't heard of. 

&amp;#x200B;

On a side note i see a lot of benchmarks such as SQUAD have ensembles of 2 or more models. How is this done? Do they get predictions from both and then take the highest output vector score between the two of them as the prediction?",793
459,459,SOTA for Topic Modeling,"Hi everyone,

Does anyone know what is the state of the art for Topic Modeling and what kind of models do they use for production at Facebook, Amazon, Google etc.? I found a couple of recent papers on NTMs, but not sure how well they work and how well they would scale.

There are many approaches that are quite popular (like LDA, Neural Topic Models, topic models + BERT etc), but I was quite interested in something that is quite scalable for large datasets and is easy to use for production. Also, majority of the models are unsupervised and used on ""exploratory"" basis, is there something that you would recommend when looking for a particular narrative e.g. ""PC Gaming"" or something that will give you ""pure"" topics?

Any comments appreciated, thanks!",https://www.reddit.com/r/LanguageTechnology/comments/mcwv5n/sota_for_topic_modeling/,LanguageTechnology,t3_mcwv5n,"SOTA for Topic Modeling Hi everyone,

Does anyone know what is the state of the art for Topic Modeling and what kind of models do they use for production at Facebook, Amazon, Google etc.? I found a couple of recent papers on NTMs, but not sure how well they work and how well they would scale.

There are many approaches that are quite popular (like LDA, Neural Topic Models, topic models + BERT etc), but I was quite interested in something that is quite scalable for large datasets and is easy to use for production. Also, majority of the models are unsupervised and used on ""exploratory"" basis, is there something that you would recommend when looking for a particular narrative e.g. ""PC Gaming"" or something that will give you ""pure"" topics?

Any comments appreciated, thanks!",780
460,460,Libraries/tools to determine if same authorship of short text,"I'm fairly new to OSINT and would like to try and detect similarities in two different short-paragraph texts that I think are coming from the same author.

For example, a person or bot sends an English-language text message with about 100 words. Then I get another text message with about 150 words, but the words used and the abbreviations are common (e.g. ""St."" with a period used for street).

Is there an NLP library/tool that you can recommend that I can use to analyze 2 text corpus to get a percentage confidence that the two texts were created by the same author (authorship identification?)? Sort of like a plagiarism detector or a library/tool that can check for semantical identicalities (not sure if the manner of use of period, commas, etc. are also detected).

I would love to use a library/environment that uses python but if not, please suggest any other (even if its a hosted website that allows you to paste in texts to compare).

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/md9j4k/librariestools_to_determine_if_same_authorship_of/,LanguageTechnology,t3_md9j4k,"Libraries/tools to determine if same authorship of short text I'm fairly new to OSINT and would like to try and detect similarities in two different short-paragraph texts that I think are coming from the same author.

For example, a person or bot sends an English-language text message with about 100 words. Then I get another text message with about 150 words, but the words used and the abbreviations are common (e.g. ""St."" with a period used for street).

Is there an NLP library/tool that you can recommend that I can use to analyze 2 text corpus to get a percentage confidence that the two texts were created by the same author (authorship identification?)? Sort of like a plagiarism detector or a library/tool that can check for semantical identicalities (not sure if the manner of use of period, commas, etc. are also detected).

I would love to use a library/environment that uses python but if not, please suggest any other (even if its a hosted website that allows you to paste in texts to compare).

Thanks!",1018
461,461,Goodreads user interaction dataset,"Hi All,

I came across this exciting data set, follow the link: [https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/home?authuser=0](https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/home?authuser=0)

I want to try my hand at user interaction data for building a book recommendation system, but its too big for my machine, even Google Colab and Kaggle kernels. Anyone with ideas how to go about it?

&amp;#x200B;

cheers",https://www.reddit.com/r/LanguageTechnology/comments/md0xqr/goodreads_user_interaction_dataset/,LanguageTechnology,t3_md0xqr,"Goodreads user interaction dataset Hi All,

I came across this exciting data set, follow the link: [https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/home?authuser=0](https://sites.google.com/eng.ucsd.edu/ucsdbookgraph/home?authuser=0)

I want to try my hand at user interaction data for building a book recommendation system, but its too big for my machine, even Google Colab and Kaggle kernels. Anyone with ideas how to go about it?

&amp;#x200B;

cheers",458
462,462,Named Entity Recognition,"(Novice here)
What's the best method for NER? What do big companies like Google use? Can those methods used by big tech be used in a small research project?

 I am thinking about taking the most common /or the most efficient NER system used for English NLP and applying that to my native language (with modifications, off course). To see how it well it performs on my language.

And then maybe further improve on it... :)",https://www.reddit.com/r/LanguageTechnology/comments/mcwmhg/named_entity_recognition/,LanguageTechnology,t3_mcwmhg,"Named Entity Recognition (Novice here)
What's the best method for NER? What do big companies like Google use? Can those methods used by big tech be used in a small research project?

 I am thinking about taking the most common /or the most efficient NER system used for English NLP and applying that to my native language (with modifications, off course). To see how it well it performs on my language.

And then maybe further improve on it... :)",446
463,463,Uppsala University VS University of Tübingen,"Hello everyone,

My intention is to pursue a MA in computational linguistics/language technology in one of the two universities mentioned in the tittle.

Is there anybody who studies or have studied in one of the two programmes mentioned above? What are the pros and cons of each choice in terms of academic quality, international student's life etc?

Thank you in advance",https://www.reddit.com/r/LanguageTechnology/comments/mcw84m/uppsala_university_vs_university_of_tübingen/,LanguageTechnology,t3_mcw84m,"Uppsala University VS University of Tübingen Hello everyone,

My intention is to pursue a MA in computational linguistics/language technology in one of the two universities mentioned in the tittle.

Is there anybody who studies or have studied in one of the two programmes mentioned above? What are the pros and cons of each choice in terms of academic quality, international student's life etc?

Thank you in advance",417
464,464,Production-Ready Machine Learning NLP API with FastAPI and spaCy,"Hey,

FastAPI has been a nice addition to the Python ecosystem. In my opinion it makes API creation easier, and less error-prone. It also comes with great performances that make it perfectly suited for machine learning APIs.

The [NLPCloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=j80a8332-aaaf-11eb-bcbc-0242ac130002) API has been developed using FastAPI, so I thought it would be interesting to write a concrete article about how to set up an NLP API with FastAPI that is serving spaCy models for NER:

[https://juliensalinas.com/en/machine-learning-nlp-api-production-fastapi-nlpcloud/](https://juliensalinas.com/en/machine-learning-nlp-api-production-fastapi-nlpcloud/)

I'd love to have your feedback on this guys. Are you also FastAPI users? Did you notice caveats I'm not aware of? Or can you think of better tools for machine learning APIs?

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/mc6qta/productionready_machine_learning_nlp_api_with/,LanguageTechnology,t3_mc6qta,"Production-Ready Machine Learning NLP API with FastAPI and spaCy Hey,

FastAPI has been a nice addition to the Python ecosystem. In my opinion it makes API creation easier, and less error-prone. It also comes with great performances that make it perfectly suited for machine learning APIs.

The [NLPCloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=j80a8332-aaaf-11eb-bcbc-0242ac130002) API has been developed using FastAPI, so I thought it would be interesting to write a concrete article about how to set up an NLP API with FastAPI that is serving spaCy models for NER:

[https://juliensalinas.com/en/machine-learning-nlp-api-production-fastapi-nlpcloud/](https://juliensalinas.com/en/machine-learning-nlp-api-production-fastapi-nlpcloud/)

I'd love to have your feedback on this guys. Are you also FastAPI users? Did you notice caveats I'm not aware of? Or can you think of better tools for machine learning APIs?

Thanks!",941
465,465,"Compare my word embedding models (Count based, PMI, SPPMI)","I am going to build some models over wiki-dump dataset and then try to compare the results to WS353 (for word similarity). So, I need to **check** whether my understanding is correct or not. Firstly, I need to read the text from wiki file and tokenize it, so that I am able to build the co-occurrence matrix. I am going to build the co-occurrence matrix in 3 ways : based on count, based on PMI and based on SPPMI. Then, I am going to build the embedding matrix using SVD. So, after that, I can have the word embedding matrix and I can compare the results to WS353.

So, the way is correct ? Thanks",https://www.reddit.com/r/LanguageTechnology/comments/mccqk1/compare_my_word_embedding_models_count_based_pmi/,LanguageTechnology,t3_mccqk1,"Compare my word embedding models (Count based, PMI, SPPMI) I am going to build some models over wiki-dump dataset and then try to compare the results to WS353 (for word similarity). So, I need to **check** whether my understanding is correct or not. Firstly, I need to read the text from wiki file and tokenize it, so that I am able to build the co-occurrence matrix. I am going to build the co-occurrence matrix in 3 ways : based on count, based on PMI and based on SPPMI. Then, I am going to build the embedding matrix using SVD. So, after that, I can have the word embedding matrix and I can compare the results to WS353.

So, the way is correct ? Thanks",657
466,466,Computer Scientist wants to Parse Meaning from Language,"I want to create a database of written works that parses each work individually to determine subjects, authoritativeness, accuracy, intention and overall reliability.  I know this is a massive challenge and I'm looking for collaborators.  I think having a linguist or three onboard early is mandatory.  I can parse text all day long, but understanding how to classify words, phrases, sentences, etc is beyond my pay grade.",https://www.reddit.com/r/LanguageTechnology/comments/mc41ia/computer_scientist_wants_to_parse_meaning_from/,LanguageTechnology,t3_mc41ia,"Computer Scientist wants to Parse Meaning from Language I want to create a database of written works that parses each work individually to determine subjects, authoritativeness, accuracy, intention and overall reliability.  I know this is a massive challenge and I'm looking for collaborators.  I think having a linguist or three onboard early is mandatory.  I can parse text all day long, but understanding how to classify words, phrases, sentences, etc is beyond my pay grade.",478
467,467,NLP model with more than one dataset,"Hi I am new on nlp and need little bit help. I would like to train a model for filtering comments

I want to filter: Spam, offensive and toxic political comments. Also I have three dataset: spam messages, offansive words and comments approval status (all website comment data ).

How can I train a model for filtering comments?

Can I use three models for for each separate transaction ?Would this be efficient?

Or can I solve this problem in a one model?

&amp;#x200B;

Thank you.",https://www.reddit.com/r/LanguageTechnology/comments/mcgp6v/nlp_model_with_more_than_one_dataset/,LanguageTechnology,t3_mcgp6v,"NLP model with more than one dataset Hi I am new on nlp and need little bit help. I would like to train a model for filtering comments

I want to filter: Spam, offensive and toxic political comments. Also I have three dataset: spam messages, offansive words and comments approval status (all website comment data ).

How can I train a model for filtering comments?

Can I use three models for for each separate transaction ?Would this be efficient?

Or can I solve this problem in a one model?

&amp;#x200B;

Thank you.",519
468,468,BERT MLM,"Hi everyone,

I was wondering about the masked word prediction task of BERT and how exactly it is carried out.

In the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf) the authors wrote that the masked tokens are used to predict the real tokens using a cross entropy loss. 

Furthermore they wrote ""\[...\]  the final hidden vectors corresponding to the mask tokens are fed into an output softmax over the vocabulary, as in a standard LM.""

So from my understanding I would just use a fully connected layer with a softmax at the end of the BERT model to obtain a output matrix of shape `[vocab_size, input_length]` and then use the actual position of the masked words (15% words masked) to obtain the output matrix of shape `[vocab_size, input_length*0.15]`. This matrix can then be used for the (categorical) cross entropy loss.

Is my way of reasoning correct or am I missing something important here?

&amp;#x200B;

Thank you in advance!",https://www.reddit.com/r/LanguageTechnology/comments/mc37gf/bert_mlm/,LanguageTechnology,t3_mc37gf,"BERT MLM Hi everyone,

I was wondering about the masked word prediction task of BERT and how exactly it is carried out.

In the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf) the authors wrote that the masked tokens are used to predict the real tokens using a cross entropy loss. 

Furthermore they wrote ""\[...\]  the final hidden vectors corresponding to the mask tokens are fed into an output softmax over the vocabulary, as in a standard LM.""

So from my understanding I would just use a fully connected layer with a softmax at the end of the BERT model to obtain a output matrix of shape `[vocab_size, input_length]` and then use the actual position of the masked words (15% words masked) to obtain the output matrix of shape `[vocab_size, input_length*0.15]`. This matrix can then be used for the (categorical) cross entropy loss.

Is my way of reasoning correct or am I missing something important here?

&amp;#x200B;

Thank you in advance!",951
469,469,stanza's Arabic language model doesn't tokenize sentences properly,"I'm trying to take Arabic text (e-mail messages, each of which are a few sentences long) and segment it all into their individual sentences.

It's not working. Most of the time I'm getting the entire e-mail message as my output, meaning it thinks the entire thing is one sentence, but really there are 3-5 different sentences in there.

Why is this not working? The stanza language models are working properly for like 7 other languages I've tried. It's not working for Arabic. Occasionally it does separate real sentences, but most of the time it just prints out 3-5 sentences as if it's one tokenized sentence. Does anyone know why the Arabic language model isn't tokenizing these e-mail messages properly?",https://www.reddit.com/r/LanguageTechnology/comments/mccpii/stanzas_arabic_language_model_doesnt_tokenize/,LanguageTechnology,t3_mccpii,"stanza's Arabic language model doesn't tokenize sentences properly I'm trying to take Arabic text (e-mail messages, each of which are a few sentences long) and segment it all into their individual sentences.

It's not working. Most of the time I'm getting the entire e-mail message as my output, meaning it thinks the entire thing is one sentence, but really there are 3-5 different sentences in there.

Why is this not working? The stanza language models are working properly for like 7 other languages I've tried. It's not working for Arabic. Occasionally it does separate real sentences, but most of the time it just prints out 3-5 sentences as if it's one tokenized sentence. Does anyone know why the Arabic language model isn't tokenizing these e-mail messages properly?",775
470,470,Join an experienced data scientist in learning a new specialization,"I’m a data scientist with a background in image and natural language processing, and I’m stoked to get my feet wet with AI for audio. I’ll be taking on a paid audio processing project in the next couple months, so I decided to be very public about my learning process to allow others to gain the same knowledge and also observe my learning process. Plus we can all add a python project to our portfolios.

I've never tried sharing this process publicly before, so I'm going to start by sharing my journey on a few different mediums and I'll see what sticks. Please let me know if there's a platform you'd prefer I share this on. Here's how to follow along:

Twitter: ""@yacov\_lewis""

Whatsapp: [https://chat.whatsapp.com/HN3p0llOF9nJY0mQPX5WLe](https://chat.whatsapp.com/HN3p0llOF9nJY0mQPX5WLe)

Facebook group: [https://www.facebook.com/groups/dswithexperts](https://www.facebook.com/groups/dswithexperts)

Excited to share this journey!",https://www.reddit.com/r/LanguageTechnology/comments/mcakz9/join_an_experienced_data_scientist_in_learning_a/,LanguageTechnology,t3_mcakz9,"Join an experienced data scientist in learning a new specialization I’m a data scientist with a background in image and natural language processing, and I’m stoked to get my feet wet with AI for audio. I’ll be taking on a paid audio processing project in the next couple months, so I decided to be very public about my learning process to allow others to gain the same knowledge and also observe my learning process. Plus we can all add a python project to our portfolios.

I've never tried sharing this process publicly before, so I'm going to start by sharing my journey on a few different mediums and I'll see what sticks. Please let me know if there's a platform you'd prefer I share this on. Here's how to follow along:

Twitter: ""@yacov\_lewis""

Whatsapp: [https://chat.whatsapp.com/HN3p0llOF9nJY0mQPX5WLe](https://chat.whatsapp.com/HN3p0llOF9nJY0mQPX5WLe)

Facebook group: [https://www.facebook.com/groups/dswithexperts](https://www.facebook.com/groups/dswithexperts)

Excited to share this journey!",1006
471,471,How to compare a template sentence with a real sentence ?,"Hi all, does anyone knows what is the best algorithm to do something like that:

I have a template sentence: 

**""declare a {memType:constant|variable} called {name:term} with value {value:term}""**

That when compared with real life sentences such as: 

1. declare a variable called A with value 32
2. declare variable called XB with value ZA
3. declare a constant called C with **the** value 42

Should all return true.

I tried using regex and it works fine until it does not, because of small variations in the real life sentence such as articles (see the article ""**the""** in sentence number 3).

My question is: is there a better way to do that comparison ?",https://www.reddit.com/r/LanguageTechnology/comments/mc3sad/how_to_compare_a_template_sentence_with_a_real/,LanguageTechnology,t3_mc3sad,"How to compare a template sentence with a real sentence ? Hi all, does anyone knows what is the best algorithm to do something like that:

I have a template sentence: 

**""declare a {memType:constant|variable} called {name:term} with value {value:term}""**

That when compared with real life sentences such as: 

1. declare a variable called A with value 32
2. declare variable called XB with value ZA
3. declare a constant called C with **the** value 42

Should all return true.

I tried using regex and it works fine until it does not, because of small variations in the real life sentence such as articles (see the article ""**the""** in sentence number 3).

My question is: is there a better way to do that comparison ?",720
472,472,question RoBERTa doc sentances.,"Hi everyone,

in the Roberta paper ([https://arxiv.org/pdf/1907.11692.pdf](https://arxiv.org/pdf/1907.11692.pdf) page 5) they say they use doc-sentences formatted inputs (512 tokens taken contiguously across multiple documents, documents are separated by a sep token). 

e.g. if I understand well: tokenized-doc 1 : 220 tokens tokenized-doc 2: 350 tokens

\-&gt; corresponding Roberta pre-training inputs: 220 tokens from doc 1 + sep token + 291 first tokens of doc 2 

my question is as follows:

Is there a way to obtain this format of input from a corpus of documents in a convenient way using pytorch or hugging face and a custom BPE tokenizer?",https://www.reddit.com/r/LanguageTechnology/comments/mc6k6m/question_roberta_doc_sentances/,LanguageTechnology,t3_mc6k6m,"question RoBERTa doc sentances. Hi everyone,

in the Roberta paper ([https://arxiv.org/pdf/1907.11692.pdf](https://arxiv.org/pdf/1907.11692.pdf) page 5) they say they use doc-sentences formatted inputs (512 tokens taken contiguously across multiple documents, documents are separated by a sep token). 

e.g. if I understand well: tokenized-doc 1 : 220 tokens tokenized-doc 2: 350 tokens

\-&gt; corresponding Roberta pre-training inputs: 220 tokens from doc 1 + sep token + 291 first tokens of doc 2 

my question is as follows:

Is there a way to obtain this format of input from a corpus of documents in a convenient way using pytorch or hugging face and a custom BPE tokenizer?",680
473,473,A linguist pursuing career im tech industry!,"Hi!

I hold a BA and an MA in English language and literature.
Since I finished BA in 2008, I worked in translation, interpreting, NGOs and Arabic language lecturing. 
Even though I worked with big comlanies, I feel I need to improve my career and focus on a specific path, after I recently decided to not pursue PHD and academa. 
TBH, I am astonished at how IT and tech industry is defining the future with tech careers growing steadily, as other careers are dying. Unfortunately, my math skills suck and programming is not my thing.

So I noticed jobs posted as data linguist, QA linguist, linguist engineer and linguist posted in tech companies such as Apple and Amazon, where some of Arabic language major firends I know landed similar jobs.

I think these positions are in high demand, where I can be paid well, and work in something I enjoy! 
Esp. that I am fluent in English and a native Arabic speaker. 

Do I need to take courses or internships to imorove my chances to get these jobs? What sort of courses? Provided by which platforms?
Any advice on writing cv and preparing for interviews? 

And is it late too late make such a change in my mid career with no experience in tech industry? 

Thank you so much for for your advice, it means a lot to me!",https://www.reddit.com/r/LanguageTechnology/comments/mbv3pc/a_linguist_pursuing_career_im_tech_industry/,LanguageTechnology,t3_mbv3pc,"A linguist pursuing career im tech industry! Hi!

I hold a BA and an MA in English language and literature.
Since I finished BA in 2008, I worked in translation, interpreting, NGOs and Arabic language lecturing. 
Even though I worked with big comlanies, I feel I need to improve my career and focus on a specific path, after I recently decided to not pursue PHD and academa. 
TBH, I am astonished at how IT and tech industry is defining the future with tech careers growing steadily, as other careers are dying. Unfortunately, my math skills suck and programming is not my thing.

So I noticed jobs posted as data linguist, QA linguist, linguist engineer and linguist posted in tech companies such as Apple and Amazon, where some of Arabic language major firends I know landed similar jobs.

I think these positions are in high demand, where I can be paid well, and work in something I enjoy! 
Esp. that I am fluent in English and a native Arabic speaker. 

Do I need to take courses or internships to imorove my chances to get these jobs? What sort of courses? Provided by which platforms?
Any advice on writing cv and preparing for interviews? 

And is it late too late make such a change in my mid career with no experience in tech industry? 

Thank you so much for for your advice, it means a lot to me!",1307
474,474,What's the point of pre-trained tokenizers?,"I've come across the idea of pre-trained tokenizers, but I'm struggling to understand why and when these would be useful. Isn't it better if you train a tokenizer on your own training data? What if the pretrained tokenizer has only a small vocabulary or is domain-specific? Wouldn't that be more detrimental to your model?",https://www.reddit.com/r/LanguageTechnology/comments/mc2zzv/whats_the_point_of_pretrained_tokenizers/,LanguageTechnology,t3_mc2zzv,"What's the point of pre-trained tokenizers? I've come across the idea of pre-trained tokenizers, but I'm struggling to understand why and when these would be useful. Isn't it better if you train a tokenizer on your own training data? What if the pretrained tokenizer has only a small vocabulary or is domain-specific? Wouldn't that be more detrimental to your model?",366
475,475,SpaCy Loss Reduction,I've been training my model on a huge corpus. Loss right now is pretty high (100000ish) and I noticed that it does drop when I increase the number of iterations. I wanted to know is there something I'm missing out on or if there's any way to find out the optimal number of iterations without overtraining.,https://www.reddit.com/r/LanguageTechnology/comments/mc0s24/spacy_loss_reduction/,LanguageTechnology,t3_mc0s24,SpaCy Loss Reduction I've been training my model on a huge corpus. Loss right now is pretty high (100000ish) and I noticed that it does drop when I increase the number of iterations. I wanted to know is there something I'm missing out on or if there's any way to find out the optimal number of iterations without overtraining.,326
476,476,"EleutherAI releases gpt-neo models trained on GPT3, GPT2",,https://github.com/EleutherAI/gpt-neo,LanguageTechnology,t3_mbm5kq,"EleutherAI releases gpt-neo models trained on GPT3, GPT2 ",57
477,477,University of Helsinki language technology professor Jörg Tiedemann has released a dataset with over 500 million translated sentences in 188 languages,,https://github.com/Helsinki-NLP/Tatoeba-Challenge/blob/master/Backtranslations.md,LanguageTechnology,t3_mb12gd,University of Helsinki language technology professor Jörg Tiedemann has released a dataset with over 500 million translated sentences in 188 languages ,151
478,478,Be patient,,https://terrytao.wordpress.com/career-advice/be-patient/,LanguageTechnology,t3_mbojsq,Be patient ,11
479,479,Interpreting the topic of a streaming text-based group chat in real-time. Is this possible?," 

This may be a simple question for those with a better understanding. I’m trying to figure out if it is possible to use NLP to describe the topic of conversation in a group chat (text). For example, people in a chat are giving advice on surfing for beginners, and using machine learning we would be able to generate something like ‘learning to surf’ or ‘beginner tips for surfing’. My question for you all is (1) is this possible in real-time for an ongoing chat where the topic of conversation evolves/changes and (2) if possible, how specific can the generated topic be? Would it just be ‘surfing’ or can it be more specific such as ‘advice on learning to surf for beginners?

Any help would be much appreciated! Even a resource or guidance would be great if this is too simple of a question. Just haven’t been able to find the answer on google searches.",https://www.reddit.com/r/LanguageTechnology/comments/mbew6j/interpreting_the_topic_of_a_streaming_textbased/,LanguageTechnology,t3_mbew6j,"Interpreting the topic of a streaming text-based group chat in real-time. Is this possible?  

This may be a simple question for those with a better understanding. I’m trying to figure out if it is possible to use NLP to describe the topic of conversation in a group chat (text). For example, people in a chat are giving advice on surfing for beginners, and using machine learning we would be able to generate something like ‘learning to surf’ or ‘beginner tips for surfing’. My question for you all is (1) is this possible in real-time for an ongoing chat where the topic of conversation evolves/changes and (2) if possible, how specific can the generated topic be? Would it just be ‘surfing’ or can it be more specific such as ‘advice on learning to surf for beginners?

Any help would be much appreciated! Even a resource or guidance would be great if this is too simple of a question. Just haven’t been able to find the answer on google searches.",950
480,480,"How does Reddit show ""Trending Today"" topics? What algorithm does it use?","The trending Today topics show up when you click search bar, and below the recent searches, appear the Trending topics. I would like to know how reddit clusters these sub-reddits, how it ranks various topics, and how it identifies various topics in the first place. The names of the algorithms used would be helpful. Thanks in advance!",https://www.reddit.com/r/LanguageTechnology/comments/mar9z8/how_does_reddit_show_trending_today_topics_what/,LanguageTechnology,t3_mar9z8,"How does Reddit show ""Trending Today"" topics? What algorithm does it use? The trending Today topics show up when you click search bar, and below the recent searches, appear the Trending topics. I would like to know how reddit clusters these sub-reddits, how it ranks various topics, and how it identifies various topics in the first place. The names of the algorithms used would be helpful. Thanks in advance!",409
481,481,"John Snow Labs Spark-NLP 3.0.0: Supporting Spark 3.x, Scala 2.12, more Databricks runtimes, more EMR versions, performance improvements &amp; lots more",,https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.0.0,LanguageTechnology,t3_mav0s8,"John Snow Labs Spark-NLP 3.0.0: Supporting Spark 3.x, Scala 2.12, more Databricks runtimes, more EMR versions, performance improvements &amp; lots more ",152
482,482,Masters in Voice Technology (Europe) online webinar this Wed/Thursday,"There’s also a Voice Tech MSc at the University of Groningen (in the Netherlands) which could be interesting for you

The basics:

- It is only one year
- There is no NLP/NLU — only speech synthesis and speech recognition
- It is  very interdisciplinary, students from Linguistics, CS, AI, digital humanities, etc. are welcome, so long as they are not scared to learn programming!
- It is an English language program


Check it out here 

https://www.rug.nl/masters/voice-technology/

There are two (free!) online webinars next week, if you want to lean more! Register at the links below to get the link to the event. 

- March 23rd: https://www.rug.nl/cf/campus-fryslan/cf-masters/events/online-master-week-voice-technology
- March 24th: https://www.rug.nl/cf/campus-fryslan/cf-masters/events/online-master-week-voice-technology",https://www.reddit.com/r/LanguageTechnology/comments/mah7v7/masters_in_voice_technology_europe_online_webinar/,LanguageTechnology,t3_mah7v7,"Masters in Voice Technology (Europe) online webinar this Wed/Thursday There’s also a Voice Tech MSc at the University of Groningen (in the Netherlands) which could be interesting for you

The basics:

- It is only one year
- There is no NLP/NLU — only speech synthesis and speech recognition
- It is  very interdisciplinary, students from Linguistics, CS, AI, digital humanities, etc. are welcome, so long as they are not scared to learn programming!
- It is an English language program


Check it out here 

https://www.rug.nl/masters/voice-technology/

There are two (free!) online webinars next week, if you want to lean more! Register at the links below to get the link to the event. 

- March 23rd: https://www.rug.nl/cf/campus-fryslan/cf-masters/events/online-master-week-voice-technology
- March 24th: https://www.rug.nl/cf/campus-fryslan/cf-masters/events/online-master-week-voice-technology",899
483,483,A Directory of Online Newspaper Sources for 70+ Languages,,https://github.com/divkakwani/awesome-newspapers,LanguageTechnology,t3_maum7o,A Directory of Online Newspaper Sources for 70+ Languages ,58
484,484,[Article] Survey of Visual Question Answering,"A task that has grasped the attention of the AI community recently is that of visual question answering.

Visual question answering involves answering questions about images in natural language. It is an interesting problem, as it combines aspects of both computer vision and natural language processing.

This article explores the problem of visual question answering, different approaches to solve it, associated challenges, datasets, and evaluation methods. Topics such as image featurization, question featurization, joint feature representation, and answer generation will be explained, along with a survey of recent research efforts tackling each of these problems.

Article link: [https://blog.paperspace.com/introduction-to-visual-question-answering/](https://blog.paperspace.com/introduction-to-visual-question-answering/)",https://www.reddit.com/r/LanguageTechnology/comments/masglx/article_survey_of_visual_question_answering/,LanguageTechnology,t3_masglx,"[Article] Survey of Visual Question Answering A task that has grasped the attention of the AI community recently is that of visual question answering.

Visual question answering involves answering questions about images in natural language. It is an interesting problem, as it combines aspects of both computer vision and natural language processing.

This article explores the problem of visual question answering, different approaches to solve it, associated challenges, datasets, and evaluation methods. Topics such as image featurization, question featurization, joint feature representation, and answer generation will be explained, along with a survey of recent research efforts tackling each of these problems.

Article link: [https://blog.paperspace.com/introduction-to-visual-question-answering/](https://blog.paperspace.com/introduction-to-visual-question-answering/)",877
485,485,Handwritten Recognition and Analysis,,https://community.wolfram.com/groups/-/m/t/2091085,LanguageTechnology,t3_maqcol,Handwritten Recognition and Analysis ,37
486,486,Help understanding a NLP methodology in a research paper,,/r/learnmachinelearning/comments/mapc3c/help_understanding_a_nlp_methodology_in_a/,LanguageTechnology,t3_mapdqs,Help understanding a NLP methodology in a research paper ,57
487,487,Kindly give constructive feedback on my first NLP blog post.,"Hi Guys,

I am getting started with my blogging journey in NLP and written my first blog post. Would really appreciate it if you guys give constructive feedback on content /quality-wise so that I can improve and provide more useful content to the NLP community. Thanks!!

[https://raghavakotala.medium.com/how-to-choose-embedding-effectively-for-task-specific-use-cases-a-developer-notes-f60f707ac162](https://raghavakotala.medium.com/how-to-choose-embedding-effectively-for-task-specific-use-cases-a-developer-notes-f60f707ac162)",https://www.reddit.com/r/LanguageTechnology/comments/mafc1y/kindly_give_constructive_feedback_on_my_first_nlp/,LanguageTechnology,t3_mafc1y,"Kindly give constructive feedback on my first NLP blog post. Hi Guys,

I am getting started with my blogging journey in NLP and written my first blog post. Would really appreciate it if you guys give constructive feedback on content /quality-wise so that I can improve and provide more useful content to the NLP community. Thanks!!

[https://raghavakotala.medium.com/how-to-choose-embedding-effectively-for-task-specific-use-cases-a-developer-notes-f60f707ac162](https://raghavakotala.medium.com/how-to-choose-embedding-effectively-for-task-specific-use-cases-a-developer-notes-f60f707ac162)",591
488,488,Ex2: Neural Data Augmentation via Example Extrapolation (Research Paper Walkthrough),,https://youtu.be/d0KUF_aNS_s,LanguageTechnology,t3_m9xrxl,Ex2: Neural Data Augmentation via Example Extrapolation (Research Paper Walkthrough) ,85
489,489,"Integrating Ray Tune, Hugging Face Transformers and W&amp;B",,https://ruanchaves.com/blog/ray-wandb-transformers-integration/,LanguageTechnology,t3_m9ffg3,"Integrating Ray Tune, Hugging Face Transformers and W&amp;B ",60
490,490,Where can I find a dataset of annotated Arabic to Arabizi dataset?,"I am currently working on an NLP project that deals with dialectal Arabic. Resources are scarce for most dialects, so I want a dataset that has annotated words from Arabizi to Arabic in whichever Arabic dialect. Problem is I don't speak Arabic, so I can't create the dataset myself.

Ps: Arabizi is Arabic written in latin characters.",https://www.reddit.com/r/LanguageTechnology/comments/m9e2rn/where_can_i_find_a_dataset_of_annotated_arabic_to/,LanguageTechnology,t3_m9e2rn,"Where can I find a dataset of annotated Arabic to Arabizi dataset? I am currently working on an NLP project that deals with dialectal Arabic. Resources are scarce for most dialects, so I want a dataset that has annotated words from Arabizi to Arabic in whichever Arabic dialect. Problem is I don't speak Arabic, so I can't create the dataset myself.

Ps: Arabizi is Arabic written in latin characters.",401
491,491,Superior tools than Gensim's Similarity module,"We  have a project that with a given of arbitrary number of phrases, we  want to find to best fitting document in a bunch of documents.

Consider this as, with a given set of phrases of skillsets, we want to find the best candidate for a job.

So Gensim's Similarity module seems like a good fit for this problem, especially [soft cosine similarity](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb) checking. But inside I can't get comfortable, because transformers are very popular lately.

I  can't be sure if Gensim's similarity is the best fit but I'm not an  expert on transformers either to tell how it can be done with  transformers or do I even need them. Any suggestions on this? Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/m9eynv/superior_tools_than_gensims_similarity_module/,LanguageTechnology,t3_m9eynv,"Superior tools than Gensim's Similarity module We  have a project that with a given of arbitrary number of phrases, we  want to find to best fitting document in a bunch of documents.

Consider this as, with a given set of phrases of skillsets, we want to find the best candidate for a job.

So Gensim's Similarity module seems like a good fit for this problem, especially [soft cosine similarity](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/soft_cosine_tutorial.ipynb) checking. But inside I can't get comfortable, because transformers are very popular lately.

I  can't be sure if Gensim's similarity is the best fit but I'm not an  expert on transformers either to tell how it can be done with  transformers or do I even need them. Any suggestions on this? Thanks.",794
492,492,A Transformers Tutorial in Plain English To Get You Thinking,,https://towardsdatascience.com/everything-product-people-need-to-know-about-transformers-part-3-bert-a1227cead488,LanguageTechnology,t3_m8t7sd,A Transformers Tutorial in Plain English To Get You Thinking ,61
493,493,NLP Pipeline Completely on the GPU,"Hey all, I had to take a day off from posting our DSotD. I think sometimes the amount of information we through daily at everyone is exhausting, and it's better to not overload and instead digest.

So today we have an [awesome blog post](https://forums.developer.nvidia.com/t/nlp-is-not-just-a-domain-solved-by-deep-learning-this-is-also-in-the-ml-wheelhouse/165337?u=kasmith), which explains how we can do an entire NLP pipeline on a GPU... creating incredible fast lightening speeds for NLP solutions. Now, this is not diving into the transformer craze like BERT or GPT, so don't get your hopes up (though you can see easily where those models can be placed in the pipeline).

What's interesting is the majority feel that Deep Transformers are the way to solve all NLP, but it's not always the case. [Here](https://www.kaggle.com/cdeotte/rapids-cuml-tfidfvectorizer-and-knn) is an example of a Nvidia Kaggle Grandmaster (and absolute Kaggle tank!) using the described pipeline above to Kaggle's Shopee - Price Match Guarantee, determining if two products are the same by their images and product description. Also, a even more streamlined Kaggle memory efficient book can be seen [here](https://www.kaggle.com/cdeotte/part-2-rapids-tfidfvectorizer-cv-0-700) .  


Let me know what you think, and we can get a great discussion going. Anyone want to vent about transformers being the solution to all NLP? *(laughing face emoji, I think of Walid Saba and his many posts on LinkedIn. Give him a follow, it's amazing pure linguist information).* ",https://www.reddit.com/r/LanguageTechnology/comments/m8gsto/nlp_pipeline_completely_on_the_gpu/,LanguageTechnology,t3_m8gsto,"NLP Pipeline Completely on the GPU Hey all, I had to take a day off from posting our DSotD. I think sometimes the amount of information we through daily at everyone is exhausting, and it's better to not overload and instead digest.

So today we have an [awesome blog post](https://forums.developer.nvidia.com/t/nlp-is-not-just-a-domain-solved-by-deep-learning-this-is-also-in-the-ml-wheelhouse/165337?u=kasmith), which explains how we can do an entire NLP pipeline on a GPU... creating incredible fast lightening speeds for NLP solutions. Now, this is not diving into the transformer craze like BERT or GPT, so don't get your hopes up (though you can see easily where those models can be placed in the pipeline).

What's interesting is the majority feel that Deep Transformers are the way to solve all NLP, but it's not always the case. [Here](https://www.kaggle.com/cdeotte/rapids-cuml-tfidfvectorizer-and-knn) is an example of a Nvidia Kaggle Grandmaster (and absolute Kaggle tank!) using the described pipeline above to Kaggle's Shopee - Price Match Guarantee, determining if two products are the same by their images and product description. Also, a even more streamlined Kaggle memory efficient book can be seen [here](https://www.kaggle.com/cdeotte/part-2-rapids-tfidfvectorizer-cv-0-700) .  


Let me know what you think, and we can get a great discussion going. Anyone want to vent about transformers being the solution to all NLP? *(laughing face emoji, I think of Walid Saba and his many posts on LinkedIn. Give him a follow, it's amazing pure linguist information).* ",1578
494,494,Typo correction using NLP,"
Hello everyone! We are studying NLP in the university, and I have been given a task to implement a typo correction using NLP. Are there guides and examples that could help me in my work?

Also wonder about NLP-based punctuation and grammar correction.",https://www.reddit.com/r/LanguageTechnology/comments/m8nrgt/typo_correction_using_nlp/,LanguageTechnology,t3_m8nrgt,"Typo correction using NLP 
Hello everyone! We are studying NLP in the university, and I have been given a task to implement a typo correction using NLP. Are there guides and examples that could help me in my work?

Also wonder about NLP-based punctuation and grammar correction.",278
495,495,What Are Some Open Source NLP Framework Pipelines For QA Task,"I am trying to build a QA pipeline. My end goal is that :  
There are total X documents in database. given a query fetch top Y documents using some fast model (tfidf/bm25 etc) where Y is a subset of X. Then run a deep learning model (bert, longformer etc) to fetch and rank Z number of documents where Z is a subset of Y. 

I am using haystack and although I heard good things about it but for some reason its not working for me. its slower than my own pipeline, its retriever (the first/recall module which runs keyword model) is buggy (returning duplicate documents even though my data did not have any duplicate). 

So I was wondering if there are any other tried and tested frameworks that you guys know of. 

Thank you in advance.",https://www.reddit.com/r/LanguageTechnology/comments/m8rpaz/what_are_some_open_source_nlp_framework_pipelines/,LanguageTechnology,t3_m8rpaz,"What Are Some Open Source NLP Framework Pipelines For QA Task I am trying to build a QA pipeline. My end goal is that :  
There are total X documents in database. given a query fetch top Y documents using some fast model (tfidf/bm25 etc) where Y is a subset of X. Then run a deep learning model (bert, longformer etc) to fetch and rank Z number of documents where Z is a subset of Y. 

I am using haystack and although I heard good things about it but for some reason its not working for me. its slower than my own pipeline, its retriever (the first/recall module which runs keyword model) is buggy (returning duplicate documents even though my data did not have any duplicate). 

So I was wondering if there are any other tried and tested frameworks that you guys know of. 

Thank you in advance.",797
496,496,Build ASR for Any Language with Hugginface Transformers,,https://www.youtube.com/watch?v=dAbtQRDaoro,LanguageTechnology,t3_m8hzci,Build ASR for Any Language with Hugginface Transformers ,56
497,497,NLP in Finance,"Hey guys, I have been following this sub for quite some time now and I am always excited to learn about the new technologies that people post here. I wanted to some advice/guidance on what topics are there in NLP that are related to Finance. I obviously know about stock prediction and sentiment analysis of financial documents but I wanted to know if there are any other ideas/tasks that I could pursue for my undergraduate thesis. I have been reading papers on Finance related NLP tasks but I have been unable to narrow down a topic for which I can start collecting data and formulating potential models. Could you guys please help me out?",https://www.reddit.com/r/LanguageTechnology/comments/m8iz81/nlp_in_finance/,LanguageTechnology,t3_m8iz81,"NLP in Finance Hey guys, I have been following this sub for quite some time now and I am always excited to learn about the new technologies that people post here. I wanted to some advice/guidance on what topics are there in NLP that are related to Finance. I obviously know about stock prediction and sentiment analysis of financial documents but I wanted to know if there are any other ideas/tasks that I could pursue for my undergraduate thesis. I have been reading papers on Finance related NLP tasks but I have been unable to narrow down a topic for which I can start collecting data and formulating potential models. Could you guys please help me out?",656
498,498,Anyone know where I could find a dataset that contains song lyrics and genre tags?,"I’ve been searching around but haven’t had much luck on kaggle, anywhere else i could look?",https://www.reddit.com/r/LanguageTechnology/comments/m8qm05/anyone_know_where_i_could_find_a_dataset_that/,LanguageTechnology,t3_m8qm05,"Anyone know where I could find a dataset that contains song lyrics and genre tags? I’ve been searching around but haven’t had much luck on kaggle, anywhere else i could look?",174
499,499,Open-source libraries for machine translation,,https://modelfront.com/compare#machine-translation-libraries,LanguageTechnology,t3_m8csmr,Open-source libraries for machine translation ,46
500,500,Introduction to Named Entity Recognition (NER),"Hey!

I made a quick article about Named Entity Recognition (NER). What is it and why is it a useful NLP technique?

[https://nlpcloud.io/nlp-named-entity-recognition-ner-api.html](https://nlpcloud.io/nlp-named-entity-recognition-ner-api.html)

Hope some of you will find it useful.

If you have any comment, please feel free!",https://www.reddit.com/r/LanguageTechnology/comments/m8lsgd/introduction_to_named_entity_recognition_ner/,LanguageTechnology,t3_m8lsgd,"Introduction to Named Entity Recognition (NER) Hey!

I made a quick article about Named Entity Recognition (NER). What is it and why is it a useful NLP technique?

[https://nlpcloud.io/nlp-named-entity-recognition-ner-api.html](https://nlpcloud.io/nlp-named-entity-recognition-ner-api.html)

Hope some of you will find it useful.

If you have any comment, please feel free!",373
501,501,Corpus Specific Vectors with BeRT,"I want to create BeRT embeddings for a corpus representing a specific subject or topic. I know how to extract embeddings from the general BeRT model and how to work with those embeddings, but I'm curious to see if I can finetune BeRT on a corpus and then extract embeddings that are more attuned to the subject that corpus represents.

Would this involve creating my own language model by applying transfer learning to BeRT?

Basically, I want to know if I can use BeRT to create/fine-tune custom embeddings similar to how this [tutorial shows how to create custom W2V embeddings using gensim](https://machinelearningmastery.com/develop-word-embeddings-python-gensim/).

Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/m83qqc/corpus_specific_vectors_with_bert/,LanguageTechnology,t3_m83qqc,"Corpus Specific Vectors with BeRT I want to create BeRT embeddings for a corpus representing a specific subject or topic. I know how to extract embeddings from the general BeRT model and how to work with those embeddings, but I'm curious to see if I can finetune BeRT on a corpus and then extract embeddings that are more attuned to the subject that corpus represents.

Would this involve creating my own language model by applying transfer learning to BeRT?

Basically, I want to know if I can use BeRT to create/fine-tune custom embeddings similar to how this [tutorial shows how to create custom W2V embeddings using gensim](https://machinelearningmastery.com/develop-word-embeddings-python-gensim/).

Thanks.",712
502,502,Recommendations for structure for AIML + Python bot,"So I am trying to make a rules based bot using AIML + Python that can perform task like fill in forms, execute queries, and do a couple simple things like look up the time.

I have trouble finding the docs to the Python-AIML library but the best tutorial is [here](https://www.devdungeon.com/content/ai-chat-bot-python-aiml) 

To execute code from python you put it in as conditional statements inside a while loop, you can see the example for quitting and saving the brn file in the example. I have two questions on how I should organize and structure my code:

1. What would be the best way to structure the following task: 
Match the correct user inputs to run specific task? I can do this by using regex to match words or spacy's matching system for matching intents using cosine similarities. 

2. Create dialog trees for filling in forms? How do I structure file and code for a dialog tree where a user has to answer questions for a specific input like a query or filling a form? Adding a bunch of code inside the while loop can get messy.",https://www.reddit.com/r/LanguageTechnology/comments/m8bi4r/recommendations_for_structure_for_aiml_python_bot/,LanguageTechnology,t3_m8bi4r,"Recommendations for structure for AIML + Python bot So I am trying to make a rules based bot using AIML + Python that can perform task like fill in forms, execute queries, and do a couple simple things like look up the time.

I have trouble finding the docs to the Python-AIML library but the best tutorial is [here](https://www.devdungeon.com/content/ai-chat-bot-python-aiml) 

To execute code from python you put it in as conditional statements inside a while loop, you can see the example for quitting and saving the brn file in the example. I have two questions on how I should organize and structure my code:

1. What would be the best way to structure the following task: 
Match the correct user inputs to run specific task? I can do this by using regex to match words or spacy's matching system for matching intents using cosine similarities. 

2. Create dialog trees for filling in forms? How do I structure file and code for a dialog tree where a user has to answer questions for a specific input like a query or filling a form? Adding a bunch of code inside the while loop can get messy.",1097
503,503,"When I vectorize words, what are vector dimensions actually?",Word co-occurrencies? What are these hundreds of dimensions?,https://www.reddit.com/r/LanguageTechnology/comments/m7nwcw/when_i_vectorize_words_what_are_vector_dimensions/,LanguageTechnology,t3_m7nwcw,"When I vectorize words, what are vector dimensions actually? Word co-occurrencies? What are these hundreds of dimensions?",121
504,504,[D] What is currently the best SENTENCE level tokenizer ?,"Hello ! Spacy isn't that good for that, nltk works but it's quite old. What do you use for sentence tokenization in english ?",https://www.reddit.com/r/LanguageTechnology/comments/m7qal4/d_what_is_currently_the_best_sentence_level/,LanguageTechnology,t3_m7qal4,"[D] What is currently the best SENTENCE level tokenizer ? Hello ! Spacy isn't that good for that, nltk works but it's quite old. What do you use for sentence tokenization in english ?",183
505,505,Do ASIC and FPGA have any use in NLP?,,https://www.reddit.com/r/LanguageTechnology/comments/m7y1wd/do_asic_and_fpga_have_any_use_in_nlp/,LanguageTechnology,t3_m7y1wd,Do ASIC and FPGA have any use in NLP? ,38
506,506,Automatic poll generation with transformers similar to guestion generation?,"Hi,

I would like to generate questions out of a text corpus. However, I can only find models (based on T5) that generate exam like questions.

Does anybody know question generation models that create opionion questions that are useable for polls? e.g. ""How do you feel about NLP?""  


Thanks in advance!",https://www.reddit.com/r/LanguageTechnology/comments/m7slmu/automatic_poll_generation_with_transformers/,LanguageTechnology,t3_m7slmu,"Automatic poll generation with transformers similar to guestion generation? Hi,

I would like to generate questions out of a text corpus. However, I can only find models (based on T5) that generate exam like questions.

Does anybody know question generation models that create opionion questions that are useable for polls? e.g. ""How do you feel about NLP?""  


Thanks in advance!",380
507,507,AI app to help you read your book smartly,"Greetings folks,

4 months ago, I started working on a ***machine learning based website which helps readers***

***find exiting content from a book*** or a pdf file without reading all of it.

And now after working hard on it for the past few months, I have come up with a

prototype version. You can upload any pdf and ask questions to get to the interesting part quickly.

Here is the link :

[https://read-what-you-need.firebaseapp.com/](https://read-what-you-need.firebaseapp.com/)

I hope the app saves your time, and fuels your love for reading.

Have a great day ahead!

**ps: here's an account to try the app quickly, set up just for our reddit users**

username: reddit

password: reddit2021

Enjoy !",https://www.reddit.com/r/LanguageTechnology/comments/m7xpqg/ai_app_to_help_you_read_your_book_smartly/,LanguageTechnology,t3_m7xpqg,"AI app to help you read your book smartly Greetings folks,

4 months ago, I started working on a ***machine learning based website which helps readers***

***find exiting content from a book*** or a pdf file without reading all of it.

And now after working hard on it for the past few months, I have come up with a

prototype version. You can upload any pdf and ask questions to get to the interesting part quickly.

Here is the link :

[https://read-what-you-need.firebaseapp.com/](https://read-what-you-need.firebaseapp.com/)

I hope the app saves your time, and fuels your love for reading.

Have a great day ahead!

**ps: here's an account to try the app quickly, set up just for our reddit users**

username: reddit

password: reddit2021

Enjoy !",752
508,508,"Healthcare NLP Summit, April 8-9","Those in the NLP community interested in building language understanding applications used in the healthcare industry should check out this NLP summit event. Learn from and engage with leading experts and a growing community in the space. 

The tickets are free.",https://www.reddit.com/r/LanguageTechnology/comments/m7trsz/healthcare_nlp_summit_april_89/,LanguageTechnology,t3_m7trsz,"Healthcare NLP Summit, April 8-9 Those in the NLP community interested in building language understanding applications used in the healthcare industry should check out this NLP summit event. Learn from and engage with leading experts and a growing community in the space. 

The tickets are free.",295
509,509,BERT pre-training with only masked words,"Hi everyone, 

i am new to the world of NLP. For an upcoming project I would like to use BERT in order to do sentiment analysis with just the headlines of news articles. But BERT has two training tasks 1. Predict masked words and 2. Next sentence prediction. But since I will use only the headlines of an article the second training task becomes obsolet. 

My question : Is it possible to just train BERT with the 'predict the masked words' task ?

&amp;#x200B;

And maybe an off-topic question: Do you know how difficult it is to make a tokenizer from scratch ?

&amp;#x200B;

Thank you in advance!",https://www.reddit.com/r/LanguageTechnology/comments/m7q6ys/bert_pretraining_with_only_masked_words/,LanguageTechnology,t3_m7q6ys,"BERT pre-training with only masked words Hi everyone, 

i am new to the world of NLP. For an upcoming project I would like to use BERT in order to do sentiment analysis with just the headlines of news articles. But BERT has two training tasks 1. Predict masked words and 2. Next sentence prediction. But since I will use only the headlines of an article the second training task becomes obsolet. 

My question : Is it possible to just train BERT with the 'predict the masked words' task ?

&amp;#x200B;

And maybe an off-topic question: Do you know how difficult it is to make a tokenizer from scratch ?

&amp;#x200B;

Thank you in advance!",640
510,510,My side project: Cloud GPUs for 1/3 the cost of AWS/GCP,"\[cross posting from /r/MachineLearning\]

I’ve just finished building a little side project of mine - [https://gpu.land/](https://gpu.land/).

**What is it?** Cheap GPU instances in the cloud.

**Why is it awesome?**

* It’s dirt-cheap. You get a Tesla V100 for $0.99/hr, which is 1/3 the cost of AWS/GCP/Azure/\[insert big cloud name\].
* It’s dead simple. It takes 2mins from registration to a launched instance. Instances come pre-installed with everything you need for Deep Learning, including a 1-click Jupyter server.
* It sports a retro, MS-DOS-like look. Because why not:)

I’m a self-taught ML engineer. I built this because when I was starting my ML journey I was totally lost and frustrated by AWS. Hope this saves some of you some nerve cells (and some pennies)!

The most common question I get is - how is this so cheap? The answer is because AWS/GCP are charging you a huge markup and I’m not. In fact I’m charging just enough to break even, and built this project really to give back to community (and to learn some of the tech in the process). 

AMA!",https://www.reddit.com/r/LanguageTechnology/comments/m74aj5/my_side_project_cloud_gpus_for_13_the_cost_of/,LanguageTechnology,t3_m74aj5,"My side project: Cloud GPUs for 1/3 the cost of AWS/GCP \[cross posting from /r/MachineLearning\]

I’ve just finished building a little side project of mine - [https://gpu.land/](https://gpu.land/).

**What is it?** Cheap GPU instances in the cloud.

**Why is it awesome?**

* It’s dirt-cheap. You get a Tesla V100 for $0.99/hr, which is 1/3 the cost of AWS/GCP/Azure/\[insert big cloud name\].
* It’s dead simple. It takes 2mins from registration to a launched instance. Instances come pre-installed with everything you need for Deep Learning, including a 1-click Jupyter server.
* It sports a retro, MS-DOS-like look. Because why not:)

I’m a self-taught ML engineer. I built this because when I was starting my ML journey I was totally lost and frustrated by AWS. Hope this saves some of you some nerve cells (and some pennies)!

The most common question I get is - how is this so cheap? The answer is because AWS/GCP are charging you a huge markup and I’m not. In fact I’m charging just enough to break even, and built this project really to give back to community (and to learn some of the tech in the process). 

AMA!",1123
511,511,preprocessing reddit submissions in python (html tag stripping etc...),"Hi there, 

I am preprocessing some reddit submission downloaded from Pushshift, which I'll later feed to a Bert sentiment encoder.

Is there any predefined pipeline (possibly in Python) for which preprocessing steps to perform (e.g., stripping html tags, etc.)?

Thank you in advance!",https://www.reddit.com/r/LanguageTechnology/comments/m7pmtx/preprocessing_reddit_submissions_in_python_html/,LanguageTechnology,t3_m7pmtx,"preprocessing reddit submissions in python (html tag stripping etc...) Hi there, 

I am preprocessing some reddit submission downloaded from Pushshift, which I'll later feed to a Bert sentiment encoder.

Is there any predefined pipeline (possibly in Python) for which preprocessing steps to perform (e.g., stripping html tags, etc.)?

Thank you in advance!",356
512,512,Tutorial on how to create categorical variables based on integers and numerical ranges,"Hey, I've created a tutorial on how to create categorical variables based on integers and numerical ranges using the R programming language: [https://statisticsglobe.com/create-categories-based-on-integer-and-numeric-range-r](https://statisticsglobe.com/create-categories-based-on-integer-and-numeric-range-r)",https://www.reddit.com/r/LanguageTechnology/comments/m7lc3s/tutorial_on_how_to_create_categorical_variables/,LanguageTechnology,t3_m7lc3s,"Tutorial on how to create categorical variables based on integers and numerical ranges Hey, I've created a tutorial on how to create categorical variables based on integers and numerical ranges using the R programming language: [https://statisticsglobe.com/create-categories-based-on-integer-and-numeric-range-r](https://statisticsglobe.com/create-categories-based-on-integer-and-numeric-range-r)",396
513,513,Extracting related keywords from a specific topic/class,"Hi all,

With only a little experience on NLP, I was wondering if you guys could help me out.  
From a list of keywords/subclasses/objects, I have to extract all relevant elements that are closely related to a certain topic/class.

So, let's say we have the following topic/class as input: ""Human"".  
Then, ideally, I would like to extract the following keywords:

1. Synonyms, i.e. {Person, Individual, Child} (This should be relatively simple with NLTK/WordNet)
2. Subclass and/or profession, i.e. {Man, Girl, Boy, Grandma, Cousin, Chef, Professor}
3. Body parts, i.e. {Arm, Leg, Knee, Eyes}

One way to deal with this, is to hard code each different subclass or body part and obtain their synonyms using synset. But for obvious reasons, this is not desireable.

Therefore, I was wondering if there are any tips/sources how to effectively approach this operation (preferably in Python)?

Thanks in advance.",https://www.reddit.com/r/LanguageTechnology/comments/m7exk1/extracting_related_keywords_from_a_specific/,LanguageTechnology,t3_m7exk1,"Extracting related keywords from a specific topic/class Hi all,

With only a little experience on NLP, I was wondering if you guys could help me out.  
From a list of keywords/subclasses/objects, I have to extract all relevant elements that are closely related to a certain topic/class.

So, let's say we have the following topic/class as input: ""Human"".  
Then, ideally, I would like to extract the following keywords:

1. Synonyms, i.e. {Person, Individual, Child} (This should be relatively simple with NLTK/WordNet)
2. Subclass and/or profession, i.e. {Man, Girl, Boy, Grandma, Cousin, Chef, Professor}
3. Body parts, i.e. {Arm, Leg, Knee, Eyes}

One way to deal with this, is to hard code each different subclass or body part and obtain their synonyms using synset. But for obvious reasons, this is not desireable.

Therefore, I was wondering if there are any tips/sources how to effectively approach this operation (preferably in Python)?

Thanks in advance.",964
514,514,How to aggregate overall text sentiment from sentences?,"Since I am new to NLP, I would like to run something by this community. I appreciate in advance any pointers you may provide.

I am using Stanza to compute the sentiment of a tweet. As far as I can tell, Stanza can only compute the sentiment of one sentence at a time. So I devised the following simple computation to aggregate the sentiment of a whole tweet:

1. Get list of sentiments for each sentence as -1 (negative), 0 (neutral), and 1 (positive).

2. Sum up the sentiments.

3. If it’s &lt;= -1, the overall sentiment is negative, if it’s &gt;= 1, it’s positive, otherwise it’s neutral.

It’s a straightforward calculation where neutral sentences don’t affect the outcome, and whichever sentiment appears on the largest number of sentences will determine the overall sentiment of a tweet. Otherwise it’s a tie and the tweet is neutral. Does this make sense?

In case this method is not suitable, I was wondering if anyone had any suggestions on tried-and-tested methods to aggregate the sentiment of a text from its sentences.",https://www.reddit.com/r/LanguageTechnology/comments/m79wow/how_to_aggregate_overall_text_sentiment_from/,LanguageTechnology,t3_m79wow,"How to aggregate overall text sentiment from sentences? Since I am new to NLP, I would like to run something by this community. I appreciate in advance any pointers you may provide.

I am using Stanza to compute the sentiment of a tweet. As far as I can tell, Stanza can only compute the sentiment of one sentence at a time. So I devised the following simple computation to aggregate the sentiment of a whole tweet:

1. Get list of sentiments for each sentence as -1 (negative), 0 (neutral), and 1 (positive).

2. Sum up the sentiments.

3. If it’s &lt;= -1, the overall sentiment is negative, if it’s &gt;= 1, it’s positive, otherwise it’s neutral.

It’s a straightforward calculation where neutral sentences don’t affect the outcome, and whichever sentiment appears on the largest number of sentences will determine the overall sentiment of a tweet. Otherwise it’s a tie and the tweet is neutral. Does this make sense?

In case this method is not suitable, I was wondering if anyone had any suggestions on tried-and-tested methods to aggregate the sentiment of a text from its sentences.",1089
515,515,Do we really need to Dstill Language Models? Joint loss is all we need - Albert-Joint .,"Hi NLP folks,

I have create a new model focused mainly on smaller size with decent performance. And my experiments with GLUE proved that Joint Loss is all we need. With just  **14 million parameters and half the computation ( 6 layers instead of 12 layers** , we got a **GLUE score of 81.0**, which is **4 points** ahead of **DistillBERT** which has **60 million parameters** and **requires more training ( may be few days in a single GPU )**. The **Albert-Joint** model is even better than **MobileBERT.**

You can read more about that 

[https://www.reddit.com/r/LanguageTechnology/comments/m5j2hi/tftransformers\_state\_of\_the\_art\_faster\_nlp\_in/](https://www.reddit.com/r/LanguageTechnology/comments/m5j2hi/tftransformers_state_of_the_art_faster_nlp_in/)

For Code and Models

[https://github.com/legacyai/tf-transformers](https://github.com/legacyai/tf-transformers)

[Benchmarks](https://github.com/legacyai/tf-transformers/blob/main/src/tf_transformers/notebooks/tutorials/joint_loss_experiments/glue/glue_benchmark.png)

&amp;#x200B;

Please share feedback, comments, and raise if any issues in Github

                                                    glue_score
    Abert-Joint-layer_0	                        0.504815
    Abert-Joint-layer_1	                        0.682751
    Abert-Joint-layer_2	                        0.743739
    Abert-Joint-layer_3	                        0.773670
    Abert-Joint-layer_4	                        0.798181
    Abert-Joint-layer_5	                        0.810039
    Abert-Joint-layer_6	                        0.813973
    Abert-Joint-layer_7	                        0.822181
    Abert-Joint-layer_8	                        0.823916
    Abert-Joint-layer_9	                        0.823932
    Abert-Joint-layer_10	                        0.827925
    Abert-Joint-layer_11	                        0.821628
    DistillBert	                                0.776625",https://www.reddit.com/r/LanguageTechnology/comments/m6svod/do_we_really_need_to_dstill_language_models_joint/,LanguageTechnology,t3_m6svod,"Do we really need to Dstill Language Models? Joint loss is all we need - Albert-Joint . Hi NLP folks,

I have create a new model focused mainly on smaller size with decent performance. And my experiments with GLUE proved that Joint Loss is all we need. With just  **14 million parameters and half the computation ( 6 layers instead of 12 layers** , we got a **GLUE score of 81.0**, which is **4 points** ahead of **DistillBERT** which has **60 million parameters** and **requires more training ( may be few days in a single GPU )**. The **Albert-Joint** model is even better than **MobileBERT.**

You can read more about that 

[https://www.reddit.com/r/LanguageTechnology/comments/m5j2hi/tftransformers\_state\_of\_the\_art\_faster\_nlp\_in/](https://www.reddit.com/r/LanguageTechnology/comments/m5j2hi/tftransformers_state_of_the_art_faster_nlp_in/)

For Code and Models

[https://github.com/legacyai/tf-transformers](https://github.com/legacyai/tf-transformers)

[Benchmarks](https://github.com/legacyai/tf-transformers/blob/main/src/tf_transformers/notebooks/tutorials/joint_loss_experiments/glue/glue_benchmark.png)

&amp;#x200B;

Please share feedback, comments, and raise if any issues in Github

                                                    glue_score
    Abert-Joint-layer_0	                        0.504815
    Abert-Joint-layer_1	                        0.682751
    Abert-Joint-layer_2	                        0.743739
    Abert-Joint-layer_3	                        0.773670
    Abert-Joint-layer_4	                        0.798181
    Abert-Joint-layer_5	                        0.810039
    Abert-Joint-layer_6	                        0.813973
    Abert-Joint-layer_7	                        0.822181
    Abert-Joint-layer_8	                        0.823916
    Abert-Joint-layer_9	                        0.823932
    Abert-Joint-layer_10	                        0.827925
    Abert-Joint-layer_11	                        0.821628
    DistillBert	                                0.776625",2009
516,516,Edinburgh MSc Speech &amp; Language Processing,"Hi everyone, 

I'm considering applying for this masters for September entry this year. I've had it on my mind for a few months, and really can't decide if I should focus on studying for my undergrad finals right now and wait to apply next year, or apply now so I can start asap. 

My questions: how long did it take you to write your personal statement? What did it contain? I would really appreciate any guidance! Were you interviewed?

And do you think this course will be much harder coming from a linguistics background rather than STEM? I haven't done any programming beyond tinkering in my spare time.

thank you - any help is really appreciated",https://www.reddit.com/r/LanguageTechnology/comments/m6yih7/edinburgh_msc_speech_language_processing/,LanguageTechnology,t3_m6yih7,"Edinburgh MSc Speech &amp; Language Processing Hi everyone, 

I'm considering applying for this masters for September entry this year. I've had it on my mind for a few months, and really can't decide if I should focus on studying for my undergrad finals right now and wait to apply next year, or apply now so I can start asap. 

My questions: how long did it take you to write your personal statement? What did it contain? I would really appreciate any guidance! Were you interviewed?

And do you think this course will be much harder coming from a linguistics background rather than STEM? I haven't done any programming beyond tinkering in my spare time.

thank you - any help is really appreciated",699
517,517,An end-to-end NLP Pipeline Tutorial Applied to Landscape Restoration in Kenya,"An open-source project, where you can learn more about NLP pipelines while looking at an impactful use case.  The project was done in collaboration with a group at Stanford University, Code for Africa, WRI, and 40+ individual collaborators. 

From collecting and preparing more than 32.000 notices, legal entities, and court documents to build a web-based dashboard displaying land ownership in Kenya. The purpose of this project is to boost Kenya’s efforts to restore degraded land in an equitable way.  
https://omdena.com/blog/identifying-land-ownership/",https://www.reddit.com/r/LanguageTechnology/comments/m72w2q/an_endtoend_nlp_pipeline_tutorial_applied_to/,LanguageTechnology,t3_m72w2q,"An end-to-end NLP Pipeline Tutorial Applied to Landscape Restoration in Kenya An open-source project, where you can learn more about NLP pipelines while looking at an impactful use case.  The project was done in collaboration with a group at Stanford University, Code for Africa, WRI, and 40+ individual collaborators. 

From collecting and preparing more than 32.000 notices, legal entities, and court documents to build a web-based dashboard displaying land ownership in Kenya. The purpose of this project is to boost Kenya’s efforts to restore degraded land in an equitable way.  
https://omdena.com/blog/identifying-land-ownership/",635
518,518,Coreference resolution with spaCy 3.0,"I was wondering if there are any solutions to using coreference resolution in spaCy 3.0 currently as neuralcoref has not been updated for it yet. I unfortunately can’t wait as I it is for a class project.

It is just a small part of the pipeline and I am using it to help with with a question generation system. So if there is a paragraph like “John went to the cleaners. He also ate dinner.” I could link He to John to create the question “Did John eat dinner”. I want to use 3.0 as it sounds like it has improved dependency parsing in English which is essential. Any help is appreciated thanks!",https://www.reddit.com/r/LanguageTechnology/comments/m77loy/coreference_resolution_with_spacy_30/,LanguageTechnology,t3_m77loy,"Coreference resolution with spaCy 3.0 I was wondering if there are any solutions to using coreference resolution in spaCy 3.0 currently as neuralcoref has not been updated for it yet. I unfortunately can’t wait as I it is for a class project.

It is just a small part of the pipeline and I am using it to help with with a question generation system. So if there is a paragraph like “John went to the cleaners. He also ate dinner.” I could link He to John to create the question “Did John eat dinner”. I want to use 3.0 as it sounds like it has improved dependency parsing in English which is essential. Any help is appreciated thanks!",634
519,519,Free GPU alternatives to Google Colab for ML/DL,"Google Colab is an undeniably popular choice for free GPU-backed Jupyter notebooks for deep learning projects, but it's not without its drawbacks.

This article discusses alternate sources of free GPUs in cloud-hosted Jupyter environments:

[https://blog.paperspace.com/best-google-colab-alternatives/](https://blog.paperspace.com/best-google-colab-alternatives/)

Really curious what others' experiences with Google Colab are like, and if any of these issues resonate. Also interested in what the community has to say about the alternates presented here!",https://www.reddit.com/r/LanguageTechnology/comments/m74blu/free_gpu_alternatives_to_google_colab_for_mldl/,LanguageTechnology,t3_m74blu,"Free GPU alternatives to Google Colab for ML/DL Google Colab is an undeniably popular choice for free GPU-backed Jupyter notebooks for deep learning projects, but it's not without its drawbacks.

This article discusses alternate sources of free GPUs in cloud-hosted Jupyter environments:

[https://blog.paperspace.com/best-google-colab-alternatives/](https://blog.paperspace.com/best-google-colab-alternatives/)

Really curious what others' experiences with Google Colab are like, and if any of these issues resonate. Also interested in what the community has to say about the alternates presented here!",603
520,520,Optional Entities in Named Entity Recognition?,"I'm new to the field of natural language processing so please forgive me if I say something incorrectly. I've been reading information and running some basic experiments on the task of Named Entity Recognition. I've seen a wide range of definitions on what constitutes a ""named entity"" including the following list: [https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119268567.app5#:\~:text=BUSINESS%20ANALYTICS%3A%20%E2%80%9CIn%20data%20mining,phone%20numbers%2C%20companies%20and%20addresses](https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119268567.app5#:~:text=BUSINESS%20ANALYTICS%3A%20%E2%80%9CIn%20data%20mining,phone%20numbers%2C%20companies%20and%20addresses).

Since there is not exact agreement on what constitutes a named entity, have there been any studies on optional entities? 

In my basic experiments I wanted to build familiarity with some of the different tools that are available so I tagged some text data that I have and compared the results of the different tools. But as I was tagging I had some difficulty deciding whether certain noun phrases should be considered named entities or not. For the time being, I created an OPTIONAL tag and used that for entities where they fit some definitions of named entity but not others. I wrote a simple script that would score the list of named entities returned by each tool against my taggings where OPTIONAL entities are skipped - neither counted as correct or incorrect. And I can imagine real scenarios where I might not care whether a tool counts certain noun phrases as entities or non-entities. 

I was wondering if there are more sophisticated analyses of these kinds of scenarios? Has this been explored? If so, can anyone point me to resources where I can learn more about it?

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/m6z3bo/optional_entities_in_named_entity_recognition/,LanguageTechnology,t3_m6z3bo,"Optional Entities in Named Entity Recognition? I'm new to the field of natural language processing so please forgive me if I say something incorrectly. I've been reading information and running some basic experiments on the task of Named Entity Recognition. I've seen a wide range of definitions on what constitutes a ""named entity"" including the following list: [https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119268567.app5#:\~:text=BUSINESS%20ANALYTICS%3A%20%E2%80%9CIn%20data%20mining,phone%20numbers%2C%20companies%20and%20addresses](https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119268567.app5#:~:text=BUSINESS%20ANALYTICS%3A%20%E2%80%9CIn%20data%20mining,phone%20numbers%2C%20companies%20and%20addresses).

Since there is not exact agreement on what constitutes a named entity, have there been any studies on optional entities? 

In my basic experiments I wanted to build familiarity with some of the different tools that are available so I tagged some text data that I have and compared the results of the different tools. But as I was tagging I had some difficulty deciding whether certain noun phrases should be considered named entities or not. For the time being, I created an OPTIONAL tag and used that for entities where they fit some definitions of named entity but not others. I wrote a simple script that would score the list of named entities returned by each tool against my taggings where OPTIONAL entities are skipped - neither counted as correct or incorrect. And I can imagine real scenarios where I might not care whether a tool counts certain noun phrases as entities or non-entities. 

I was wondering if there are more sophisticated analyses of these kinds of scenarios? Has this been explored? If so, can anyone point me to resources where I can learn more about it?

Thanks!",1814
521,521,VAEs for text generation,"Hi, I'm very interested in Variational Autoencoders (VAEs) for text generation but struggle to find the current state of the art method. Does someone know a reference?

At the moment all I can find for basically any nlp task are these huge uninterpretable models from Google. Is any research towards anything else dead?

Is there an example of transformers being used for the encoder-decoder parts of a VAE?",https://www.reddit.com/r/LanguageTechnology/comments/m6vsl5/vaes_for_text_generation/,LanguageTechnology,t3_m6vsl5,"VAEs for text generation Hi, I'm very interested in Variational Autoencoders (VAEs) for text generation but struggle to find the current state of the art method. Does someone know a reference?

At the moment all I can find for basically any nlp task are these huge uninterpretable models from Google. Is any research towards anything else dead?

Is there an example of transformers being used for the encoder-decoder parts of a VAE?",432
522,522,"With GPUs, K-nearest Neighbor Algorithm Crosses the Finish Line When Others are in the Starting Blocks","Good morning all! I'm going to try and keep up these Data Science of the Day posts. I think they are fun to share and the feedback has been great so far.

Yesterday I talked to [u/drekalo](https://www.reddit.com/u/drekalo/) in my [r/datascience](https://www.reddit.com/r/datascience/) [post](https://www.reddit.com/r/datascience/comments/m6axq4/embed_your_sql_query_into_your_python_code_and/)(I think might have gotten removed) but I posted it in a few other subs too, here is the [post](https://www.reddit.com/r/MachineLearning/comments/m6b047/p_embed_your_sql_query_into_your_python_code_and/) in [r/MachineLearning](https://www.reddit.com/r/MachineLearning/). We talked a bit about RAPIDS, which is an Nvidia library for accelerated data engineering/science (it's quit awesome). Today I want to shed light on another [RAPIDS](https://rapids.ai/) ability and that's doing classic ML algorithms **FAST**. This article talks about K-Nearest Neighbors (KNN) probably the most well known ML algorithm there is. One of Nvidia's Kaggle Grandmasters wrote this great [article](https://forums.developer.nvidia.com/t/with-gpus-k-nearest-neighbor-algorithm-crosses-the-finish-line-when-others-are-in-the-starting-blocks/168785?u=kasmith) on how RAPIDS accelerates KNN **600x** versus CPU. This speed up might be what many of you need to help get a benchmark on large or complicated data sets, OR get a medal in Kaggle! It's rudimentary, and not as attractive as a DL Algo like BERT, but you can use KNN for text classification to get that first step.

&amp;#x200B;",https://www.reddit.com/r/LanguageTechnology/comments/m6zqym/with_gpus_knearest_neighbor_algorithm_crosses_the/,LanguageTechnology,t3_m6zqym,"With GPUs, K-nearest Neighbor Algorithm Crosses the Finish Line When Others are in the Starting Blocks Good morning all! I'm going to try and keep up these Data Science of the Day posts. I think they are fun to share and the feedback has been great so far.

Yesterday I talked to [u/drekalo](https://www.reddit.com/u/drekalo/) in my [r/datascience](https://www.reddit.com/r/datascience/) [post](https://www.reddit.com/r/datascience/comments/m6axq4/embed_your_sql_query_into_your_python_code_and/)(I think might have gotten removed) but I posted it in a few other subs too, here is the [post](https://www.reddit.com/r/MachineLearning/comments/m6b047/p_embed_your_sql_query_into_your_python_code_and/) in [r/MachineLearning](https://www.reddit.com/r/MachineLearning/). We talked a bit about RAPIDS, which is an Nvidia library for accelerated data engineering/science (it's quit awesome). Today I want to shed light on another [RAPIDS](https://rapids.ai/) ability and that's doing classic ML algorithms **FAST**. This article talks about K-Nearest Neighbors (KNN) probably the most well known ML algorithm there is. One of Nvidia's Kaggle Grandmasters wrote this great [article](https://forums.developer.nvidia.com/t/with-gpus-k-nearest-neighbor-algorithm-crosses-the-finish-line-when-others-are-in-the-starting-blocks/168785?u=kasmith) on how RAPIDS accelerates KNN **600x** versus CPU. This speed up might be what many of you need to help get a benchmark on large or complicated data sets, OR get a medal in Kaggle! It's rudimentary, and not as attractive as a DL Algo like BERT, but you can use KNN for text classification to get that first step.

&amp;#x200B;",1660
523,523,"Language Identification using XGBoost. Code for training and application of a language identification model. Trained on the WiLI-2018 database, the classifier achieves an accuracy of 85.97% on the WiLi test dataset for 235 languages.",,https://github.com/PhilWicke/Language_Identifier,LanguageTechnology,t3_m6ycet,"Language Identification using XGBoost. Code for training and application of a language identification model. Trained on the WiLI-2018 database, the classifier achieves an accuracy of 85.97% on the WiLi test dataset for 235 languages. ",234
524,524,Why do we need a [SEP] token needed for the end of the input for a transformer model?,"I can understand if there are two inputs, like in next sentence prediction, where the inputs need to be separated. But why do we have a 2nd separator token at the end. 

I am especially curious about cases where there is a single input. And in that case, is a CLS token even needed?",https://www.reddit.com/r/LanguageTechnology/comments/m6urd0/why_do_we_need_a_sep_token_needed_for_the_end_of/,LanguageTechnology,t3_m6urd0,"Why do we need a [SEP] token needed for the end of the input for a transformer model? I can understand if there are two inputs, like in next sentence prediction, where the inputs need to be separated. But why do we have a 2nd separator token at the end. 

I am especially curious about cases where there is a single input. And in that case, is a CLS token even needed?",368
525,525,Anyone have experience doing TTS with Mozzilla TTS or Ossian (especially for low-resource languages)?,"Apologies, I realize this is tangentially related to this subreddit, but the TTS and NLP community is small and (perhaps I am wrong) fairly overlapped. Just looking to hear about experiences using one over another. Trying to use this on very low resource languages with a very small linguistics team for commercial purposes, so apologies for being vague. We initially tried Festival/FestVox before realizing that calling that 'a hot mess' is a serious understatement.",https://www.reddit.com/r/LanguageTechnology/comments/m6m8xm/anyone_have_experience_doing_tts_with_mozzilla/,LanguageTechnology,t3_m6m8xm,"Anyone have experience doing TTS with Mozzilla TTS or Ossian (especially for low-resource languages)? Apologies, I realize this is tangentially related to this subreddit, but the TTS and NLP community is small and (perhaps I am wrong) fairly overlapped. Just looking to hear about experiences using one over another. Trying to use this on very low resource languages with a very small linguistics team for commercial purposes, so apologies for being vague. We initially tried Festival/FestVox before realizing that calling that 'a hot mess' is a serious understatement.",569
526,526,Confusion choosing between two CS PhD programs! Please help! 🙏,,/r/gradadmissions/comments/m59zpc/confusion_choosing_between_two_cs_phd_programs/,LanguageTechnology,t3_m6kww9,Confusion choosing between two CS PhD programs! Please help! 🙏 ,63
527,527,Finding the distance between two sentences that that share mostly the same words.,"I am trying to find the difference between the following examples:

&gt;I am writing this sentence on a Reddit thread.  
&gt;  
&gt;I am right in this sentence on a ready thread.

The output should be something like

&gt;I am --- this sentence on a --- thread

or

&gt;{""writing"" : ""right in"", ""Reddit"" : ""ready""}

I had a very uneducated idea of looping each word from one of the sentences against the other one. Then define a threshold of how many words to go forward in hope of finding the exact word in the second sentence (3-4 words for example) and give up if there is no occurrence. However this method falls short on many points.


Is this a known NLP task? If so, I would appreciate to know what is the keyword for this problem.

I am wondering if someone know/used/developed some algorithm/package/functionality for a similar task? I try to keep my development in Python, so I would appreciate Python suggestions as well as any algorithmic suggestions.


Thanks!

Edit: Wow people, thanks a lot! All of the responses were helpful and creative. I have found my solution and leaving this post here for others who are looking for similar solutions

Edit 2: Come on, guys. What's up with down voting all these people's comments? All these people were trying to help and I can tell they spend time on it. Please let's respect it, let's discuss if there is wrong information and let's be supportive to each other. We are here to share and grow, right?",https://www.reddit.com/r/LanguageTechnology/comments/m681fh/finding_the_distance_between_two_sentences_that/,LanguageTechnology,t3_m681fh,"Finding the distance between two sentences that that share mostly the same words. I am trying to find the difference between the following examples:

&gt;I am writing this sentence on a Reddit thread.  
&gt;  
&gt;I am right in this sentence on a ready thread.

The output should be something like

&gt;I am --- this sentence on a --- thread

or

&gt;{""writing"" : ""right in"", ""Reddit"" : ""ready""}

I had a very uneducated idea of looping each word from one of the sentences against the other one. Then define a threshold of how many words to go forward in hope of finding the exact word in the second sentence (3-4 words for example) and give up if there is no occurrence. However this method falls short on many points.


Is this a known NLP task? If so, I would appreciate to know what is the keyword for this problem.

I am wondering if someone know/used/developed some algorithm/package/functionality for a similar task? I try to keep my development in Python, so I would appreciate Python suggestions as well as any algorithmic suggestions.


Thanks!

Edit: Wow people, thanks a lot! All of the responses were helpful and creative. I have found my solution and leaving this post here for others who are looking for similar solutions

Edit 2: Come on, guys. What's up with down voting all these people's comments? All these people were trying to help and I can tell they spend time on it. Please let's respect it, let's discuss if there is wrong information and let's be supportive to each other. We are here to share and grow, right?",1537
528,528,Facebook comments to build a language model,"Hello, fellow NLPers,  


I am currently working on a low-resource language that practically has no raw corpus whatsoever.  The language in question is an Arabic dialect and it's mainly used on social media or for chatting. Consequently, I was forced to collect data from public Facebook pages in order to build a raw corpus for such dialect. The purpose behind this is to build a general transformer language model (such as BERT), that can then be used/fine-tuned on other specific tasks. The issue I have is the legality and ethicality of publishing such corpus on a scientific paper. In short here are few questions that I need some help with:  
1. Is it legal/ethically correct to just publish the corpus as is for research purposes?  
2. If not, is it possible to instead apply some preprocessing techniques to the corpus in a way that makes this ethical?  
3. Are there any publications that you know of that have done something similar or related to collecting data from Facebook and so forth?  


Any information you can provide is very appreciated.

Thanks a lot and have a great day.",https://www.reddit.com/r/LanguageTechnology/comments/m62ma4/facebook_comments_to_build_a_language_model/,LanguageTechnology,t3_m62ma4,"Facebook comments to build a language model Hello, fellow NLPers,  


I am currently working on a low-resource language that practically has no raw corpus whatsoever.  The language in question is an Arabic dialect and it's mainly used on social media or for chatting. Consequently, I was forced to collect data from public Facebook pages in order to build a raw corpus for such dialect. The purpose behind this is to build a general transformer language model (such as BERT), that can then be used/fine-tuned on other specific tasks. The issue I have is the legality and ethicality of publishing such corpus on a scientific paper. In short here are few questions that I need some help with:  
1. Is it legal/ethically correct to just publish the corpus as is for research purposes?  
2. If not, is it possible to instead apply some preprocessing techniques to the corpus in a way that makes this ethical?  
3. Are there any publications that you know of that have done something similar or related to collecting data from Facebook and so forth?  


Any information you can provide is very appreciated.

Thanks a lot and have a great day.",1137
529,529,"Computational Linguistics study shows how Metaphors, Figurative Framings and Sentiments are changing in the Covid-19 discourse over the course of the Pandemic. The War-Terminology is increasingly literal with the onset of the BlackLivesMatter Protests in 2020.",,https://www.frontiersin.org/articles/10.3389/fcomm.2021.651997/full,LanguageTechnology,t3_m66b5b,"Computational Linguistics study shows how Metaphors, Figurative Framings and Sentiments are changing in the Covid-19 discourse over the course of the Pandemic. The War-Terminology is increasingly literal with the onset of the BlackLivesMatter Protests in 2020. ",261
530,530,Embed Your SQL Query Into Your Python Code and Let It Rip on a GPU - Data Science of the Day,"*Okay! Thanks to /u/*[*themajesticcalf*](https://www.reddit.com/user/themajesticcalf) *for pointing out the google doc to me on the original post. This community is great, and thank you all for not doing crazy things to it.*

Back to the original post. It's great to get as much information and resources possible out to our community. Here at Nvidia, a cool thing we do is ""Data Science of the Day"" (DSotD). It's tips and information from subject matter experts to better equip anyone doing data science/machine learning to perform their job to the maximum potential.

Today's DSotD is about embedding SQL code into python to query tables at blazing speeds, with the help of GPUs. Click the link (and then the picture) to check out the blog post on how to perform this task. [Embed SQL into Python for Blazing Speeds](https://forums.developer.nvidia.com/t/embed-your-sql-query-into-your-python-code-and-let-it-rip-on-a-gpu/170506?u=kasmith) .

Also, don't forget to register for our **FREE** conference, [GTC 2021 FREE REGISTRATION](https://www.nvidia.com/en-us/gtc/?ncid=GTCS21-NVKASMITH) , to have access to a week of great talks and presentations that show real world scenarios/applications where data science/machine learning skills like these above can help solve complicated problems.",https://www.reddit.com/r/LanguageTechnology/comments/m6aya3/embed_your_sql_query_into_your_python_code_and/,LanguageTechnology,t3_m6aya3,"Embed Your SQL Query Into Your Python Code and Let It Rip on a GPU - Data Science of the Day *Okay! Thanks to /u/*[*themajesticcalf*](https://www.reddit.com/user/themajesticcalf) *for pointing out the google doc to me on the original post. This community is great, and thank you all for not doing crazy things to it.*

Back to the original post. It's great to get as much information and resources possible out to our community. Here at Nvidia, a cool thing we do is ""Data Science of the Day"" (DSotD). It's tips and information from subject matter experts to better equip anyone doing data science/machine learning to perform their job to the maximum potential.

Today's DSotD is about embedding SQL code into python to query tables at blazing speeds, with the help of GPUs. Click the link (and then the picture) to check out the blog post on how to perform this task. [Embed SQL into Python for Blazing Speeds](https://forums.developer.nvidia.com/t/embed-your-sql-query-into-your-python-code-and-let-it-rip-on-a-gpu/170506?u=kasmith) .

Also, don't forget to register for our **FREE** conference, [GTC 2021 FREE REGISTRATION](https://www.nvidia.com/en-us/gtc/?ncid=GTCS21-NVKASMITH) , to have access to a week of great talks and presentations that show real world scenarios/applications where data science/machine learning skills like these above can help solve complicated problems.",1384
531,531,tf-transformers : State of the art faster NLP in Tensorflow 2.0 . 80 % faster to existing TF based libraries.,"Hi NLP folks,

I have developed a library for NLP with different transformer architectures in Tensorflow 2.0 . The natural question will be, how it is different compared to hugging Face. Hugging face is amazing, no doubt in that, But the Tf 2.0 implementation of Hugging face is way slower compared to PT implementation. Which actually made me think why? 

The lack of proper serialization of models is the main reason. To do so, we actually needed to re-design the code. tf-transformers if serialization and more.

As per the benchmarks for **text generation using GPT2 and t5 models, it is 80 % faster than HF TF implementations and even faster than PT implementations.** All the codes + benchmarks + tutorials released. 

## Unique Features

&amp;#x200B;

* **Faster Auto Regressive Decoding** using Tensorflow2. Faster than PyTorch in most experiments (V100 GPU). **80%** faster compared to existing TF based libraries (relative difference) Refer [benchmark code](https://github.com/legacyai/tf-transformers/blob/main/tests/notebooks/benchmarks).
* Complete **TFlite** support for **BERT, RoBERTA, T5, Albert, mt5** for all down stream tasks except text-generation
* **Faster sentence-piece alignment** (no more LCS overhead)
* **Variable batch text generation** for Encoder only models like GPT2
* No more hassle of writing long codes for **TFRecords. minimal and simple**.
* Off the shelf support for auto-batching **tf.data.dataset** or **tf.ragged** tensors
* Pass dictionary outputs directly to loss functions inside tf.keras.Model.fit  
 using **model.compile2** . Refer [examples](https://github.com/legacyai/tf-transformers/blob/main/src/tf_transformers/notebooks/tutorials) or [blog](https://legacyai-org.medium.com/tf-transformers-f7722536ba61)
* Multiple mask modes like **causal**, **user-defined**, **prefix** by changing one argument . Refer [examples](https://github.com/legacyai/tf-transformers/blob/main/src/tf_transformers/notebooks/tutorials) or [blog](https://legacyai-org.medium.com/tf-transformers-f7722536ba61)

&amp;#x200B;

[https://github.com/legacyai/tf-transformers](https://github.com/legacyai/tf-transformers)

&amp;#x200B;

Please share your thoughts, comments and feedback .",https://www.reddit.com/r/LanguageTechnology/comments/m5j2hi/tftransformers_state_of_the_art_faster_nlp_in/,LanguageTechnology,t3_m5j2hi,"tf-transformers : State of the art faster NLP in Tensorflow 2.0 . 80 % faster to existing TF based libraries. Hi NLP folks,

I have developed a library for NLP with different transformer architectures in Tensorflow 2.0 . The natural question will be, how it is different compared to hugging Face. Hugging face is amazing, no doubt in that, But the Tf 2.0 implementation of Hugging face is way slower compared to PT implementation. Which actually made me think why? 

The lack of proper serialization of models is the main reason. To do so, we actually needed to re-design the code. tf-transformers if serialization and more.

As per the benchmarks for **text generation using GPT2 and t5 models, it is 80 % faster than HF TF implementations and even faster than PT implementations.** All the codes + benchmarks + tutorials released. 

## Unique Features

&amp;#x200B;

* **Faster Auto Regressive Decoding** using Tensorflow2. Faster than PyTorch in most experiments (V100 GPU). **80%** faster compared to existing TF based libraries (relative difference) Refer [benchmark code](https://github.com/legacyai/tf-transformers/blob/main/tests/notebooks/benchmarks).
* Complete **TFlite** support for **BERT, RoBERTA, T5, Albert, mt5** for all down stream tasks except text-generation
* **Faster sentence-piece alignment** (no more LCS overhead)
* **Variable batch text generation** for Encoder only models like GPT2
* No more hassle of writing long codes for **TFRecords. minimal and simple**.
* Off the shelf support for auto-batching **tf.data.dataset** or **tf.ragged** tensors
* Pass dictionary outputs directly to loss functions inside tf.keras.Model.fit  
 using **model.compile2** . Refer [examples](https://github.com/legacyai/tf-transformers/blob/main/src/tf_transformers/notebooks/tutorials) or [blog](https://legacyai-org.medium.com/tf-transformers-f7722536ba61)
* Multiple mask modes like **causal**, **user-defined**, **prefix** by changing one argument . Refer [examples](https://github.com/legacyai/tf-transformers/blob/main/src/tf_transformers/notebooks/tutorials) or [blog](https://legacyai-org.medium.com/tf-transformers-f7722536ba61)

&amp;#x200B;

[https://github.com/legacyai/tf-transformers](https://github.com/legacyai/tf-transformers)

&amp;#x200B;

Please share your thoughts, comments and feedback .",2320
532,532,Complaint redressal system,"Hey guys! Im planning to develop a complaint redressal system. So I have continuously flowing in complaints. The aim is to identify a issue that is being written in majority of the complaints. Is there any paper/ article that can help me achieve this?

I have found many solutions, that go well with static data, that is when you have no Incoming data, and are computing on whatever's available, but here I have continuously incoming data, so I will need an appropriate ML/NLP algorithm to find the common issues faced in all the complaints.
Thanks in advance for your help",https://www.reddit.com/r/LanguageTechnology/comments/m63e18/complaint_redressal_system/,LanguageTechnology,t3_m63e18,"Complaint redressal system Hey guys! Im planning to develop a complaint redressal system. So I have continuously flowing in complaints. The aim is to identify a issue that is being written in majority of the complaints. Is there any paper/ article that can help me achieve this?

I have found many solutions, that go well with static data, that is when you have no Incoming data, and are computing on whatever's available, but here I have continuously incoming data, so I will need an appropriate ML/NLP algorithm to find the common issues faced in all the complaints.
Thanks in advance for your help",600
533,533,Into NLP - Tokenization,,https://www.qualicen.de/nlp-article-3-numerous-language-pieces-tokenization/,LanguageTechnology,t3_m5kidb,Into NLP - Tokenization ,24
534,534,NVIDIA Grandmaster Series – Building World-Class NLP Models with Transformers and Hugging Face,"So I want to be more active in all the subs and let everyone know the best available material out there. NVIDIA has been steam rolling the Kaggle competitions using some subject matter expertise and the NVIDIA platform. Here are four stellar Kaggle Grandmasters from NVIDIA talking a short history of state-of-the-art NLP models and best practices using Hugging Face.

It's an hour long on no speed up, but legitimately a great source for anyone new or experienced in NLP.

[Building World-Class NLP Models with Transformers and Hugging Face](https://bit.ly/2Nq5yqs)",https://www.reddit.com/r/LanguageTechnology/comments/m5lje2/nvidia_grandmaster_series_building_worldclass_nlp/,LanguageTechnology,t3_m5lje2,"NVIDIA Grandmaster Series – Building World-Class NLP Models with Transformers and Hugging Face So I want to be more active in all the subs and let everyone know the best available material out there. NVIDIA has been steam rolling the Kaggle competitions using some subject matter expertise and the NVIDIA platform. Here are four stellar Kaggle Grandmasters from NVIDIA talking a short history of state-of-the-art NLP models and best practices using Hugging Face.

It's an hour long on no speed up, but legitimately a great source for anyone new or experienced in NLP.

[Building World-Class NLP Models with Transformers and Hugging Face](https://bit.ly/2Nq5yqs)",661
535,535,Are there other supervised ml tasks in NLP besides text classification?,"I’m doing some internet sleuthing but I’m mostly seeing text classification, are there other applications?",https://www.reddit.com/r/LanguageTechnology/comments/m5ols9/are_there_other_supervised_ml_tasks_in_nlp/,LanguageTechnology,t3_m5ols9,"Are there other supervised ml tasks in NLP besides text classification? I’m doing some internet sleuthing but I’m mostly seeing text classification, are there other applications?",178
536,536,COMPARISION OF DUC DATASETS ACCURACY,"which Duc dataset gives good evaluation rouge score in text summarization? like is it DUC 2001 or DUC 2002,...?can anyone provide me a link to refer it.",https://www.reddit.com/r/LanguageTechnology/comments/m5j9bt/comparision_of_duc_datasets_accuracy/,LanguageTechnology,t3_m5j9bt,"COMPARISION OF DUC DATASETS ACCURACY which Duc dataset gives good evaluation rouge score in text summarization? like is it DUC 2001 or DUC 2002,...?can anyone provide me a link to refer it.",189
537,537,How to parse a sentence by writing grammar rules in NLTK CFG ?," Below is the original code : 

 `import nltk`

&amp;#x200B;

`# flight grammar rules`

`flight_grammar = nltk.CFG.fromstring(""""""`

  `S -&gt; NP VP | VP`

  `VP -&gt; V NP | V NP PP`

  `PP -&gt; P NP`

  `NP -&gt; Prop | Det N | Det N PP`

  `V -&gt; ""walked"" | ""book"" | ""prefer"" | ""gave"" | ""want""`

  `Prop -&gt; ""Jack"" | ""John"" | ""I"" | ""Houston""`

  `Det -&gt; ""a"" | ""an"" | ""the"" | ""my"" | ""that""`

  `N -&gt; ""dog"" | ""bone"" | ""flight""`

  `P -&gt; ""in"" | ""on"" | ""by"" | ""with"" | ""to"" | ""through""`

  `"""""")`

&amp;#x200B;

`# make a recursive descent parser and parse the sentence`

`rd_parser = nltk.RecursiveDescentParser(flight_grammar)`

&amp;#x200B;

`#define first sentence`

`senttext = ""I prefer a flight through Houston""`

`#tokenize sentence by splitting on white space`

`sentlist = senttext.split()`

`# run the parse function on the tokenized sentence and print the tree strucutre`

`for tree in rd_parser.parse(sentlist):`

	`print (tree)`

It is able to parse the sentence mentioned in the code, but fails to do parse this sentence : """"Jack walked with the dog""

Modifying the rule to : `VP -&gt; V NP | V NP PP | V PP`, can parse that as well. However, I am unable to parse the following sentences : 

""John gave the dog a bone"" , ""I want to book that flight""",https://www.reddit.com/r/LanguageTechnology/comments/m5ally/how_to_parse_a_sentence_by_writing_grammar_rules/,LanguageTechnology,t3_m5ally,"How to parse a sentence by writing grammar rules in NLTK CFG ?  Below is the original code : 

 `import nltk`

&amp;#x200B;

`# flight grammar rules`

`flight_grammar = nltk.CFG.fromstring(""""""`

  `S -&gt; NP VP | VP`

  `VP -&gt; V NP | V NP PP`

  `PP -&gt; P NP`

  `NP -&gt; Prop | Det N | Det N PP`

  `V -&gt; ""walked"" | ""book"" | ""prefer"" | ""gave"" | ""want""`

  `Prop -&gt; ""Jack"" | ""John"" | ""I"" | ""Houston""`

  `Det -&gt; ""a"" | ""an"" | ""the"" | ""my"" | ""that""`

  `N -&gt; ""dog"" | ""bone"" | ""flight""`

  `P -&gt; ""in"" | ""on"" | ""by"" | ""with"" | ""to"" | ""through""`

  `"""""")`

&amp;#x200B;

`# make a recursive descent parser and parse the sentence`

`rd_parser = nltk.RecursiveDescentParser(flight_grammar)`

&amp;#x200B;

`#define first sentence`

`senttext = ""I prefer a flight through Houston""`

`#tokenize sentence by splitting on white space`

`sentlist = senttext.split()`

`# run the parse function on the tokenized sentence and print the tree strucutre`

`for tree in rd_parser.parse(sentlist):`

	`print (tree)`

It is able to parse the sentence mentioned in the code, but fails to do parse this sentence : """"Jack walked with the dog""

Modifying the rule to : `VP -&gt; V NP | V NP PP | V PP`, can parse that as well. However, I am unable to parse the following sentences : 

""John gave the dog a bone"" , ""I want to book that flight""",1340
538,538,Alternate approaches to TF-IDF?,"I'm trying to rank words in a corpus of political speeches. TF-IDF seems to work really nice to identify ""important"" words, much better than raw frequency at least.

I'm wondering if there are any alternate or similar techniques to TF-IDF to rank the importance of words in a corpus.

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/m51t0z/alternate_approaches_to_tfidf/,LanguageTechnology,t3_m51t0z,"Alternate approaches to TF-IDF? I'm trying to rank words in a corpus of political speeches. TF-IDF seems to work really nice to identify ""important"" words, much better than raw frequency at least.

I'm wondering if there are any alternate or similar techniques to TF-IDF to rank the importance of words in a corpus.

Thanks!",324
539,539,Best approach for automatic key word extraction,"Hi all,

I'm wondering if there are SOTA approach for automatic keyword extraction. I have following questions, I hope someone answer them.

1 are there any good data set to work on keyword extraction

2 what are the best ML and DL techniques used for it

3 are there any tools to prepare data for keyword extraction

4 is it possible to solve this problem using unsupervised approach

5 what are the key performance metrics to measure performance

Ps: my question is not limited to NER

Cheers",https://www.reddit.com/r/LanguageTechnology/comments/m5f6vk/best_approach_for_automatic_key_word_extraction/,LanguageTechnology,t3_m5f6vk,"Best approach for automatic key word extraction Hi all,

I'm wondering if there are SOTA approach for automatic keyword extraction. I have following questions, I hope someone answer them.

1 are there any good data set to work on keyword extraction

2 what are the best ML and DL techniques used for it

3 are there any tools to prepare data for keyword extraction

4 is it possible to solve this problem using unsupervised approach

5 what are the key performance metrics to measure performance

Ps: my question is not limited to NER

Cheers",542
540,540,Structured Nearest Neighbour Learning for Few-Shot NER | Research Papers Summary 012,,https://youtu.be/bbhCN3rVwrU,LanguageTechnology,t3_m5226j,Structured Nearest Neighbour Learning for Few-Shot NER | Research Papers Summary 012 ,85
541,541,Learning resources for chatbots / conversational AI?,"I'm looking to learn the theory, latest research, and development best practices around chatbots and conversational AI. I'm open to all mediums (e.g., books, lecture videos, courses, articles). 

So far I'm aware of the Jurafsky &amp; Martin [chapter](https://web.stanford.edu/~jurafsky/slp3/) on it. I know Rasa should have some material floating around somewhere, but my feeling is that it'll be too specific to the Rasa library. 

Any resources y'all have really enjoyed/found useful?",https://www.reddit.com/r/LanguageTechnology/comments/m58hnw/learning_resources_for_chatbots_conversational_ai/,LanguageTechnology,t3_m58hnw,"Learning resources for chatbots / conversational AI? I'm looking to learn the theory, latest research, and development best practices around chatbots and conversational AI. I'm open to all mediums (e.g., books, lecture videos, courses, articles). 

So far I'm aware of the Jurafsky &amp; Martin [chapter](https://web.stanford.edu/~jurafsky/slp3/) on it. I know Rasa should have some material floating around somewhere, but my feeling is that it'll be too specific to the Rasa library. 

Any resources y'all have really enjoyed/found useful?",540
542,542,Is there a python based speaker diarization system you would recommend?,"I have audio files with two speakers and I want to have speech to text conversation. For this I plan on using Huggingface. But I also want to separate text from the two speakers so I need diarization as well.

Any tips or suggestions based on your experience so I don't make the same mistakes. 

I see pyannote and Bob from idiap as potential options but I haven't used them before.",https://www.reddit.com/r/LanguageTechnology/comments/m557kh/is_there_a_python_based_speaker_diarization/,LanguageTechnology,t3_m557kh,"Is there a python based speaker diarization system you would recommend? I have audio files with two speakers and I want to have speech to text conversation. For this I plan on using Huggingface. But I also want to separate text from the two speakers so I need diarization as well.

Any tips or suggestions based on your experience so I don't make the same mistakes. 

I see pyannote and Bob from idiap as potential options but I haven't used them before.",454
543,543,"When batch size = n, does this mean parameter updates are performed after processing n characters, words, or sentences? [mini-batch stochastic gradient descent]","When performing mini-batch stochastic gradient descent in an NLP setting, what does the batch size represent? If I am training a character-level LSTM language model with batch size 100, does this mean I process 100 characters, 100 words or 100 sentences? 

&amp;#x200B;

Suppose it meant characters. And so I process 100 characters, average the gradients, update parameters, but what happens next? Do I re-initialize the model and input a new sequence of 100 characters sampled randomly from a corpus? Or do I just input the 100th to 200th characters that continue the first sequence? If the latter, at what point do I sample an entirely new sequence of characters from the corpus?",https://www.reddit.com/r/LanguageTechnology/comments/m587yq/when_batch_size_n_does_this_mean_parameter/,LanguageTechnology,t3_m587yq,"When batch size = n, does this mean parameter updates are performed after processing n characters, words, or sentences? [mini-batch stochastic gradient descent] When performing mini-batch stochastic gradient descent in an NLP setting, what does the batch size represent? If I am training a character-level LSTM language model with batch size 100, does this mean I process 100 characters, 100 words or 100 sentences? 

&amp;#x200B;

Suppose it meant characters. And so I process 100 characters, average the gradients, update parameters, but what happens next? Do I re-initialize the model and input a new sequence of 100 characters sampled randomly from a corpus? Or do I just input the 100th to 200th characters that continue the first sequence? If the latter, at what point do I sample an entirely new sequence of characters from the corpus?",842
544,544,LARA implementation,"Hi all

I am wondering if there's any good implementation of latent aspect rating analysis (LARA). I googled it but surprisingly no libraries support it. I'm too dumb to go through paper and implement it myself. I don't even know how to prepare data for it.

Also now I'm curious how does the guys at Amazon do it?

Cheers",https://www.reddit.com/r/LanguageTechnology/comments/m4sdkp/lara_implementation/,LanguageTechnology,t3_m4sdkp,"LARA implementation Hi all

I am wondering if there's any good implementation of latent aspect rating analysis (LARA). I googled it but surprisingly no libraries support it. I'm too dumb to go through paper and implement it myself. I don't even know how to prepare data for it.

Also now I'm curious how does the guys at Amazon do it?

Cheers",342
545,545,Seeking help in NLP assignment,"I am actively seeking help somebody who is good at NLP in finishing my assignment. The raw data is in an XML file. I need to build probably a LSTM.model. if you are interested, please ping me for more details. Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/m51y7p/seeking_help_in_nlp_assignment/,LanguageTechnology,t3_m51y7p,"Seeking help in NLP assignment I am actively seeking help somebody who is good at NLP in finishing my assignment. The raw data is in an XML file. I need to build probably a LSTM.model. if you are interested, please ping me for more details. Thanks.",248
546,546,DUC DATASET,can anyone send me DUC dataset for text summarization??,https://www.reddit.com/r/LanguageTechnology/comments/m4qcw4/duc_dataset/,LanguageTechnology,t3_m4qcw4,DUC DATASET can anyone send me DUC dataset for text summarization??,67
547,547,MA in CompLing with a Linguistic background,"&amp;#x200B;

&amp;#x200B;

Hello everyone,

I am a senior student of English Language and Literature with a specialization in Linguistics. I am currently interested in pursuing a MA degree in Computational Linguistics but I am afraid that I am not qualified enough given that I lack basic programming skills.

I have already applied to the Language Technology MA degree in Uppsala University and I am planning to apply to both Stuttgart and Tuebingen Computational Linguistics programmes.

Do you think that is possible to be accepted with solely a linguistic background?

Do you have any other similar MA programmes in mind?

Thank you in advance",https://www.reddit.com/r/LanguageTechnology/comments/m4as1e/ma_in_compling_with_a_linguistic_background/,LanguageTechnology,t3_m4as1e,"MA in CompLing with a Linguistic background &amp;#x200B;

&amp;#x200B;

Hello everyone,

I am a senior student of English Language and Literature with a specialization in Linguistics. I am currently interested in pursuing a MA degree in Computational Linguistics but I am afraid that I am not qualified enough given that I lack basic programming skills.

I have already applied to the Language Technology MA degree in Uppsala University and I am planning to apply to both Stuttgart and Tuebingen Computational Linguistics programmes.

Do you think that is possible to be accepted with solely a linguistic background?

Do you have any other similar MA programmes in mind?

Thank you in advance",692
548,548,Systematically Exploring Redundancy Reduction in Summarizing Long Documents (Research Paper Walkthrough),"Text Summarization is the task of shortening a given document while maintaining the most important information. In general, a good summarizer should generate a summary that is syntactically accurate, semantically correct, coherent, and non-redundant. While extractive methods tend to have better performance on the first two aspects, they are typically less coherent and more redundant than abstractive ones, where new sentences are often generated by sentence fusion and compression, which helps detecting and removing redundancy. This work talks about existing and also proposes new techniques to deal with redundancy in long document summarisation.

Paper walkthrough: https://youtu.be/GFUwKDGYkuI",https://www.reddit.com/r/LanguageTechnology/comments/m46g0o/systematically_exploring_redundancy_reduction_in/,LanguageTechnology,t3_m46g0o,"Systematically Exploring Redundancy Reduction in Summarizing Long Documents (Research Paper Walkthrough) Text Summarization is the task of shortening a given document while maintaining the most important information. In general, a good summarizer should generate a summary that is syntactically accurate, semantically correct, coherent, and non-redundant. While extractive methods tend to have better performance on the first two aspects, they are typically less coherent and more redundant than abstractive ones, where new sentences are often generated by sentence fusion and compression, which helps detecting and removing redundancy. This work talks about existing and also proposes new techniques to deal with redundancy in long document summarisation.

Paper walkthrough: https://youtu.be/GFUwKDGYkuI",805
549,549,What are the ways to handle out of domain inputs for text classification?,Out-domain random inputs unwantedly giving very high confidence value. What are the available ways to get rid of it? What to do when we have no negative class data or the negative class is too big to cover?,https://www.reddit.com/r/LanguageTechnology/comments/m46mz4/what_are_the_ways_to_handle_out_of_domain_inputs/,LanguageTechnology,t3_m46mz4,What are the ways to handle out of domain inputs for text classification? Out-domain random inputs unwantedly giving very high confidence value. What are the available ways to get rid of it? What to do when we have no negative class data or the negative class is too big to cover?,280
550,550,Will NLP have a good future even if we reach AGI?,"I am an aspiring NLP student and I had this bizarre or some may say amateurish question. I want to know whether this field of AI has good future or not. I know prediction about AGI is like asking when will Avatar sequels come. I just wanted to know if we achieved human level in language, will the field of NLP die or will it move towards Super Intelligence?

So in short I want to know whether NLP will have a good future in terms of research or job opportunities in this century. If this question sounded like non sense, ignore this post, or if you are interested in this question please respond. I am struck at this question for days, so please help me with this.",https://www.reddit.com/r/LanguageTechnology/comments/m3nb23/will_nlp_have_a_good_future_even_if_we_reach_agi/,LanguageTechnology,t3_m3nb23,"Will NLP have a good future even if we reach AGI? I am an aspiring NLP student and I had this bizarre or some may say amateurish question. I want to know whether this field of AI has good future or not. I know prediction about AGI is like asking when will Avatar sequels come. I just wanted to know if we achieved human level in language, will the field of NLP die or will it move towards Super Intelligence?

So in short I want to know whether NLP will have a good future in terms of research or job opportunities in this century. If this question sounded like non sense, ignore this post, or if you are interested in this question please respond. I am struck at this question for days, so please help me with this.",716
551,551,Date extraction from text code/API's,"Does anyone have experience with extracting dates from text? An example follows. Any pointers to code, papers, API's will be highly appreciated. I've tried out a few API's and tools already, and they did not work. Please reply only if you know that your tool/API of choice will work. Thanks!

Text: ""I signed contract with a vendor to provide a dance floor for my wedding. The Wedding was planned for March 21, 2020. The contract was signed in February.""

Desired output: ""March 21, 2020; February 1, 2020"".",https://www.reddit.com/r/LanguageTechnology/comments/m3s1vk/date_extraction_from_text_codeapis/,LanguageTechnology,t3_m3s1vk,"Date extraction from text code/API's Does anyone have experience with extracting dates from text? An example follows. Any pointers to code, papers, API's will be highly appreciated. I've tried out a few API's and tools already, and they did not work. Please reply only if you know that your tool/API of choice will work. Thanks!

Text: ""I signed contract with a vendor to provide a dance floor for my wedding. The Wedding was planned for March 21, 2020. The contract was signed in February.""

Desired output: ""March 21, 2020; February 1, 2020"".",544
552,552,[Tutorial] How to Implement Seq2Seq Models for Text Summarization with Keras,"Seq2seq models are advantageous for their ability to process text inputs without a constrained length. This tutorial covers how to build, train, and test a seq2seq model for text summarization using Keras. 

Article link: [https://blog.paperspace.com/implement-seq2seq-for-text-summarization-keras/](https://blog.paperspace.com/implement-seq2seq-for-text-summarization-keras/)

You can also run the full code on a free GPU: [https://ml-showcase.paperspace.com/projects/text-summarization-with-seq2seq-models](https://ml-showcase.paperspace.com/projects/text-summarization-with-seq2seq-models)

For more information on the theory behind seq2seq models (architecture, applications, and the data loading/processing steps for the model implemented here), check out [Part 1](https://blog.paperspace.com/introduction-to-seq2seq-models/). 

Comments and questions welcome!",https://www.reddit.com/r/LanguageTechnology/comments/m3lk2k/tutorial_how_to_implement_seq2seq_models_for_text/,LanguageTechnology,t3_m3lk2k,"[Tutorial] How to Implement Seq2Seq Models for Text Summarization with Keras Seq2seq models are advantageous for their ability to process text inputs without a constrained length. This tutorial covers how to build, train, and test a seq2seq model for text summarization using Keras. 

Article link: [https://blog.paperspace.com/implement-seq2seq-for-text-summarization-keras/](https://blog.paperspace.com/implement-seq2seq-for-text-summarization-keras/)

You can also run the full code on a free GPU: [https://ml-showcase.paperspace.com/projects/text-summarization-with-seq2seq-models](https://ml-showcase.paperspace.com/projects/text-summarization-with-seq2seq-models)

For more information on the theory behind seq2seq models (architecture, applications, and the data loading/processing steps for the model implemented here), check out [Part 1](https://blog.paperspace.com/introduction-to-seq2seq-models/). 

Comments and questions welcome!",942
553,553,Constraint Detection,"Hello,

I am new to NLP so please bear with me. I am wondering if there is a common solution/framework to extracting constraint phrases from a string.


Examples and what I wanted to detect:

Shirt not more than $10. (More than $10)

Topic published  Before January first.  (before January first)

Pants that are exactly $10. (exactly $10)

I did find a library called LexNLP but I cannot use this framework.

https://lexpredict-lexnlp.readthedocs.io/en/docs-0.1.6/modules/extract_en_constraints.html

Thanks in advance.",https://www.reddit.com/r/LanguageTechnology/comments/m3h92a/constraint_detection/,LanguageTechnology,t3_m3h92a,"Constraint Detection Hello,

I am new to NLP so please bear with me. I am wondering if there is a common solution/framework to extracting constraint phrases from a string.


Examples and what I wanted to detect:

Shirt not more than $10. (More than $10)

Topic published  Before January first.  (before January first)

Pants that are exactly $10. (exactly $10)

I did find a library called LexNLP but I cannot use this framework.

https://lexpredict-lexnlp.readthedocs.io/en/docs-0.1.6/modules/extract_en_constraints.html

Thanks in advance.",541
554,554,Beginner questions about NER model evaluation.,"Hi all! I'm new in NLP and still learning, so I'm sorry, this is a noob post. I'm a bit confused with all the information on the internet and I could really use some advice from people with experience.

The problem is that I haven't worked with other people's trained models yet. I get the process of training and evaluating my own ML/deep learning models, but I'm not sure how to proceed with this task and I don't have an expert hotline to ask for help (except for Reddit).

Task: For a course, I need to evaluate the performance of an NER ML model, and compare that to the performance of a deep learning NER model.

At my disposal I have:

* The training data used to train these models + a test and a dev set.
* A large labelled NER corpus of which parts were used to train both of these models.
* The deep learning model works with HuggingFace Transformers (which I'm completely new to, and I don't know if this changes anything).
* Both models have a command-line interface that provide bite-sized NER-tagged output when you load in a .txt file. (e.g.:  ""my name is Rob"" would return the token such as ""Rob"" + label ""B-PER"" for ""person"")

My current plan of action:

* Stripping the test data .txt file from all tags to get ""unseen data"" to test the trained models on.
* Let the command-line tools of both the deep learning model and the ML model generate labelled output on this test data.
* Calculate F1, confusion matrix, etc. on 1) the labelled output of these command-line tools and 2) the labelled ""golden standard"" test data set.

My questions:

* Main question: I don't need to retrain these models to evaluate them, right? Am I correct to assume that I can just work with the labelled output the models provide on the unseen test data set + the golden standard labelled test data, and calculate evaluation metrics on that?
* Is there a better way to evaluate these models beside metrics such as F1?  Can I also do other things to evaluate and compare these models?
* Is there a way to evaluate the performance of the models for each of the NER tags separately?

Thank you, any input is most welcome! ",https://www.reddit.com/r/LanguageTechnology/comments/m3i0ie/beginner_questions_about_ner_model_evaluation/,LanguageTechnology,t3_m3i0ie,"Beginner questions about NER model evaluation. Hi all! I'm new in NLP and still learning, so I'm sorry, this is a noob post. I'm a bit confused with all the information on the internet and I could really use some advice from people with experience.

The problem is that I haven't worked with other people's trained models yet. I get the process of training and evaluating my own ML/deep learning models, but I'm not sure how to proceed with this task and I don't have an expert hotline to ask for help (except for Reddit).

Task: For a course, I need to evaluate the performance of an NER ML model, and compare that to the performance of a deep learning NER model.

At my disposal I have:

* The training data used to train these models + a test and a dev set.
* A large labelled NER corpus of which parts were used to train both of these models.
* The deep learning model works with HuggingFace Transformers (which I'm completely new to, and I don't know if this changes anything).
* Both models have a command-line interface that provide bite-sized NER-tagged output when you load in a .txt file. (e.g.:  ""my name is Rob"" would return the token such as ""Rob"" + label ""B-PER"" for ""person"")

My current plan of action:

* Stripping the test data .txt file from all tags to get ""unseen data"" to test the trained models on.
* Let the command-line tools of both the deep learning model and the ML model generate labelled output on this test data.
* Calculate F1, confusion matrix, etc. on 1) the labelled output of these command-line tools and 2) the labelled ""golden standard"" test data set.

My questions:

* Main question: I don't need to retrain these models to evaluate them, right? Am I correct to assume that I can just work with the labelled output the models provide on the unseen test data set + the golden standard labelled test data, and calculate evaluation metrics on that?
* Is there a better way to evaluate these models beside metrics such as F1?  Can I also do other things to evaluate and compare these models?
* Is there a way to evaluate the performance of the models for each of the NER tags separately?

Thank you, any input is most welcome! ",2162
555,555,State of the Art Spelling Correction,"I am trying to build a really good spell corrector for our search engine. We have a lot of domain specific terms so using an off the shelf one is not going to work well. I found the Peter Norvig spelling corrector post but am having trouble finding more sophisticated (and also scalable) spelling correctors. I need a model that can smartly pick between a set of generated corrections, as the most common one with the lowest edit distance is often not the best (it's right about 65% of the time). I switched to using a contextual corrector based on bigrams which made a small improvement (68% accurate), but am looking for something better. The type of error affects the likelihood of a correction being right as some errors are more likely than others. There's also the issue of speed, as doing an edit distance algo is inherently slow. AFAICT this doesn't seem to be actively being researched, unless i am looking in the wrong places. Is this problem seen as 'solved' by the broader NLP community?",https://www.reddit.com/r/LanguageTechnology/comments/m3mva9/state_of_the_art_spelling_correction/,LanguageTechnology,t3_m3mva9,"State of the Art Spelling Correction I am trying to build a really good spell corrector for our search engine. We have a lot of domain specific terms so using an off the shelf one is not going to work well. I found the Peter Norvig spelling corrector post but am having trouble finding more sophisticated (and also scalable) spelling correctors. I need a model that can smartly pick between a set of generated corrections, as the most common one with the lowest edit distance is often not the best (it's right about 65% of the time). I switched to using a contextual corrector based on bigrams which made a small improvement (68% accurate), but am looking for something better. The type of error affects the likelihood of a correction being right as some errors are more likely than others. There's also the issue of speed, as doing an edit distance algo is inherently slow. AFAICT this doesn't seem to be actively being researched, unless i am looking in the wrong places. Is this problem seen as 'solved' by the broader NLP community?",1036
556,556,Gradient symbolic Computation... Do you know concrete implementations?,"I'm reading a couple of papers by Smolensky and Goldrick on their Gradient Symbolic Computation and similar models unifying neural networks and symbolic computation. (Ex. [Cho, Goldrick &amp; Smolensky (2017)](https://faculty.wcas.northwestern.edu/matt-goldrick/publications/pdfs/GSC_LV_final3.pdf) or [Goldrick &amp; Smolensky (2016)](http://roa.rutgers.edu/content/article/files/1552_smolensky_1.pdf)
Really awesome! 

Does anyone of you know where to find a concrete example implemented in Python or R?",https://www.reddit.com/r/LanguageTechnology/comments/m3l7q7/gradient_symbolic_computation_do_you_know/,LanguageTechnology,t3_m3l7q7,"Gradient symbolic Computation... Do you know concrete implementations? I'm reading a couple of papers by Smolensky and Goldrick on their Gradient Symbolic Computation and similar models unifying neural networks and symbolic computation. (Ex. [Cho, Goldrick &amp; Smolensky (2017)](https://faculty.wcas.northwestern.edu/matt-goldrick/publications/pdfs/GSC_LV_final3.pdf) or [Goldrick &amp; Smolensky (2016)](http://roa.rutgers.edu/content/article/files/1552_smolensky_1.pdf)
Really awesome! 

Does anyone of you know where to find a concrete example implemented in Python or R?",576
557,557,Gpt-2 simple isnt good enough for the chatbot I want.,"So I'm running gpt-2 simple in a google colab and I have two simple problems.

Firstly, the text generation speed is far too slow. With minimal input for the medium model I get around 12+ seconds to generate.

So to try and solve this problem I downgraded the model to 124M but the model wasnt capable of a basic conversation.

I need a model that's not only capable of generating text fast but is also just as effect as gpt-2 355M if not more effective.

I'm wondering if any of you may know a gpt-2 alternative or a way to customize gpt-2 simple to generate faster?",https://www.reddit.com/r/LanguageTechnology/comments/m39se2/gpt2_simple_isnt_good_enough_for_the_chatbot_i/,LanguageTechnology,t3_m39se2,"Gpt-2 simple isnt good enough for the chatbot I want. So I'm running gpt-2 simple in a google colab and I have two simple problems.

Firstly, the text generation speed is far too slow. With minimal input for the medium model I get around 12+ seconds to generate.

So to try and solve this problem I downgraded the model to 124M but the model wasnt capable of a basic conversation.

I need a model that's not only capable of generating text fast but is also just as effect as gpt-2 355M if not more effective.

I'm wondering if any of you may know a gpt-2 alternative or a way to customize gpt-2 simple to generate faster?",621
558,558,SpaCy VS Transformers for NER,"It seems that both spaCy and transform based models (like [https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)) are suite for good entity extraction in English. So it's hard for me to know which one I should use...

Do you have an opinion on this in terms of accuracy and performance ?

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/m2s4ko/spacy_vs_transformers_for_ner/,LanguageTechnology,t3_m2s4ko,"SpaCy VS Transformers for NER It seems that both spaCy and transform based models (like [https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english](https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)) are suite for good entity extraction in English. So it's hard for me to know which one I should use...

Do you have an opinion on this in terms of accuracy and performance ?

Thanks!",418
559,559,On Generating Extended Summaries of Long Documents (Research Paper Walkthrough),,https://youtu.be/Inc63mLLInA,LanguageTechnology,t3_m2pkl0,On Generating Extended Summaries of Long Documents (Research Paper Walkthrough) ,80
560,560,Libraries/tools to determine if same authorship of short text,"I'm fairly new to NLP and would like to try and detect similarities in two different short-paragraph texts that I think are coming from the same author.

For example, a person or bot sends an English-language text message with about 100 words.  Then I get another text message with about 150 words, but the words used and the abbreviations are common (e.g. ""St."" with a period used for street).  

&amp;nbsp;

Is there an NLP library/tool that you can recommend that I can use to analyze 2 text corpus to get a percentage confidence that the two texts were created by the same author (authorship identification?)? Sort of like a plagiarism detector or a library/tool that can check for semantical identicalities (not sure if the manner of use of period, commas, etc. are also detected).

&amp;nbsp;

I would love to use a  library/environment that uses python but if not, please suggest any other (even if its a hosted website that allows you to paste in texts to compare).

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/m2xugm/librariestools_to_determine_if_same_authorship_of/,LanguageTechnology,t3_m2xugm,"Libraries/tools to determine if same authorship of short text I'm fairly new to NLP and would like to try and detect similarities in two different short-paragraph texts that I think are coming from the same author.

For example, a person or bot sends an English-language text message with about 100 words.  Then I get another text message with about 150 words, but the words used and the abbreviations are common (e.g. ""St."" with a period used for street).  

&amp;nbsp;

Is there an NLP library/tool that you can recommend that I can use to analyze 2 text corpus to get a percentage confidence that the two texts were created by the same author (authorship identification?)? Sort of like a plagiarism detector or a library/tool that can check for semantical identicalities (not sure if the manner of use of period, commas, etc. are also detected).

&amp;nbsp;

I would love to use a  library/environment that uses python but if not, please suggest any other (even if its a hosted website that allows you to paste in texts to compare).

Thanks!",1044
561,561,Paraphrase Dataset for Slovak,looking for a paraphrase dataset for Slovak. Any link ?,https://www.reddit.com/r/LanguageTechnology/comments/m2vbko/paraphrase_dataset_for_slovak/,LanguageTechnology,t3_m2vbko,Paraphrase Dataset for Slovak looking for a paraphrase dataset for Slovak. Any link ?,85
562,562,Sentiment Analysis with Transformers vs. Textblob,"Hi,

&amp;#x200B;

I'm pretty new to NLP and was experimenting with spacy to do serveral basic NLP tasks. Now I wanted to do some sentiment analysis.

First I tried Textblob, but it only works for English. After some research I thought using Hugging/Face Transformers might be a better solution.

What do you think is the best option for doing a sentiment analysis? Preferably I would like to use pretrained models.

&amp;#x200B;

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/m2pnrk/sentiment_analysis_with_transformers_vs_textblob/,LanguageTechnology,t3_m2pnrk,"Sentiment Analysis with Transformers vs. Textblob Hi,

&amp;#x200B;

I'm pretty new to NLP and was experimenting with spacy to do serveral basic NLP tasks. Now I wanted to do some sentiment analysis.

First I tried Textblob, but it only works for English. After some research I thought using Hugging/Face Transformers might be a better solution.

What do you think is the best option for doing a sentiment analysis? Preferably I would like to use pretrained models.

&amp;#x200B;

Thanks!",488
563,563,Topic Modeling using Reddit jokes,"Has anyone ever tried to do NLP Topic Modeling using Reddit jokes? Currently I'm trying to figure out the best topics for reddit jokes but I'm having a hard time how as the scores using LDA, LSI and HDP are very low. Scores are only around 0.3, 0.2 and the words are just son, man, beer. It just doesn't make sense. My dataset contains jokes from the subreddit dadjokes, 3amjokes, antijokes, darkjokes and jokes.

Here's my code - [https://github.com/ZL63388/c6\_sprint4/blob/main/Reddit\_Joke\_Classifier.ipynb](https://github.com/ZL63388/c6_sprint4/blob/main/Reddit_Joke_Classifier.ipynb)",https://www.reddit.com/r/LanguageTechnology/comments/m2l47p/topic_modeling_using_reddit_jokes/,LanguageTechnology,t3_m2l47p,"Topic Modeling using Reddit jokes Has anyone ever tried to do NLP Topic Modeling using Reddit jokes? Currently I'm trying to figure out the best topics for reddit jokes but I'm having a hard time how as the scores using LDA, LSI and HDP are very low. Scores are only around 0.3, 0.2 and the words are just son, man, beer. It just doesn't make sense. My dataset contains jokes from the subreddit dadjokes, 3amjokes, antijokes, darkjokes and jokes.

Here's my code - [https://github.com/ZL63388/c6\_sprint4/blob/main/Reddit\_Joke\_Classifier.ipynb](https://github.com/ZL63388/c6_sprint4/blob/main/Reddit_Joke_Classifier.ipynb)",624
564,564,Topic Modelling (LDA) on DUC 2004 dataset,"Hi, Has anyone here has done topic Modelling on the DUC 2004 plain text dataset? 

I'm not having good results. If you don't know about the dataset, it is similar to a news dataset. 

Can someone guide me to a quality tutorial as i have gone through every video and article and it doesn't seem cover my problem.",https://www.reddit.com/r/LanguageTechnology/comments/m2t10g/topic_modelling_lda_on_duc_2004_dataset/,LanguageTechnology,t3_m2t10g,"Topic Modelling (LDA) on DUC 2004 dataset Hi, Has anyone here has done topic Modelling on the DUC 2004 plain text dataset? 

I'm not having good results. If you don't know about the dataset, it is similar to a news dataset. 

Can someone guide me to a quality tutorial as i have gone through every video and article and it doesn't seem cover my problem.",353
565,565,Next models on nlpcloud.io?,"I'm asking the question here because I know that some of you liked the idea behind [nlpcloud.io](https://nlpcloud.io), so here's the question: which NLP models should we now add to NLP Cloud?

We initially proposed all the spaCy pre-trained models for NER and POS tagging, and we then heard a lot of users asking for transformer-based models. That's why we added the following transformer-based models last week:

* Facebook's Bart Large MNLI model, for **text classification**
* Facebook's Bart Large CNN model, for **text summarization**
* Deepset's Roberta Base Squad 2 model, for **question answering**
* DistilBERT Base Uncased Finetuned SST-2 English model, for **sentiment analysis**

We are now wondering which models we should add next. Should we add more transformer-based models? Or pre-trained models from another framework? What would you find the most useful for your own situation that we are lacking for the moment?

Thanks a lot!",https://www.reddit.com/r/LanguageTechnology/comments/m2sjh5/next_models_on_nlpcloudio/,LanguageTechnology,t3_m2sjh5,"Next models on nlpcloud.io? I'm asking the question here because I know that some of you liked the idea behind [nlpcloud.io](https://nlpcloud.io), so here's the question: which NLP models should we now add to NLP Cloud?

We initially proposed all the spaCy pre-trained models for NER and POS tagging, and we then heard a lot of users asking for transformer-based models. That's why we added the following transformer-based models last week:

* Facebook's Bart Large MNLI model, for **text classification**
* Facebook's Bart Large CNN model, for **text summarization**
* Deepset's Roberta Base Squad 2 model, for **question answering**
* DistilBERT Base Uncased Finetuned SST-2 English model, for **sentiment analysis**

We are now wondering which models we should add next. Should we add more transformer-based models? Or pre-trained models from another framework? What would you find the most useful for your own situation that we are lacking for the moment?

Thanks a lot!",974
566,566,"Video introduction to the join functions of the dplyr package in R programming. The tutorial provides programming examples and explains the difference between inner, left, right, full, semi, and anti joins",,https://youtu.be/Yg-pNqzDuN4,LanguageTechnology,t3_m2pjst,"Video introduction to the join functions of the dplyr package in R programming. The tutorial provides programming examples and explains the difference between inner, left, right, full, semi, and anti joins ",206
567,567,Semantic Search and Fuzzy string matching,"I know that bert has been used extensively for semantic search; getting similar documents, articles, etc. Word embeddings capture the context better; but is there a way to implement fuzzy string matching with bert's word embeddings, or is tfidf the better solution for that?",https://www.reddit.com/r/LanguageTechnology/comments/m1zob5/semantic_search_and_fuzzy_string_matching/,LanguageTechnology,t3_m1zob5,"Semantic Search and Fuzzy string matching I know that bert has been used extensively for semantic search; getting similar documents, articles, etc. Word embeddings capture the context better; but is there a way to implement fuzzy string matching with bert's word embeddings, or is tfidf the better solution for that?",316
568,568,NAACL 2021 results are out,I've heard on twitter that NAACL 2021 final decisions are out. Anyone got the news yet?,https://www.reddit.com/r/LanguageTechnology/comments/m268vf/naacl_2021_results_are_out/,LanguageTechnology,t3_m268vf,NAACL 2021 results are out I've heard on twitter that NAACL 2021 final decisions are out. Anyone got the news yet?,114
569,569,Paper Implementation Suggestions,Trying to practice my NLP and was hoping for some good paper implementation suggestions. Any ideas? I could simply pick papers related exactly to what my research focuses on but I guess I am wondering what papers people think would provide general valuable skills.,https://www.reddit.com/r/LanguageTechnology/comments/m2a8bn/paper_implementation_suggestions/,LanguageTechnology,t3_m2a8bn,Paper Implementation Suggestions Trying to practice my NLP and was hoping for some good paper implementation suggestions. Any ideas? I could simply pick papers related exactly to what my research focuses on but I guess I am wondering what papers people think would provide general valuable skills.,297
570,570,"Turing Award Winners Yoshua Bengio, Geoffrey Hinton, and Yann LeCun to Speak at GTC21"," 

Hey all, I'm an NVIDIA Senior Data Scientist and have a activate personal account on the sub here and across many ML/AI/DL sub-reddits. I think some of the best discussions and debates I've been apart of or read have come on these subs. I'd love to just throw in a plug here and have you all join NVIDIA virtually for our GTC conference this year. Like the title says, the ""granddaddy's"" of modern AI are going to be speaking at the conference! This is a great opportunity to get online and listen to some quality talks and science across many domains and product talks etc.

Here's a sign up link, I get zero commission for this, just want to share the love.[https://www.nvidia.com/en-us/gtc/?ncid=GTCS21-NVKASMITH](https://www.nvidia.com/en-us/gtc/?ncid=GTCS21-NVKASMITH)

Also here are some bullets of what GTC has in store.

* GTC is a **free** online conference and happening **April 12-16** with live sessions across the world.
* **Keynote** requires **no registration** and happens **Monday, April 12, at 8:30 AM PST**, with a second broadcast at **6:00 PM PST** for APAC audiences.
* The conference will have live webinars, on-demand sessions, posters. Connect With Experts, DLI (with a fee), and multiple panels that include industry pioneers, researchers, developers, start-ups, venture capitalists, and more.
* There is an amazing line-up of speakers including Gordon Bell award winners, AI pioneers, Oscar-winning artists, and thought leaders from every industry.",https://www.reddit.com/r/LanguageTechnology/comments/m2d741/turing_award_winners_yoshua_bengio_geoffrey/,LanguageTechnology,t3_m2d741,"Turing Award Winners Yoshua Bengio, Geoffrey Hinton, and Yann LeCun to Speak at GTC21  

Hey all, I'm an NVIDIA Senior Data Scientist and have a activate personal account on the sub here and across many ML/AI/DL sub-reddits. I think some of the best discussions and debates I've been apart of or read have come on these subs. I'd love to just throw in a plug here and have you all join NVIDIA virtually for our GTC conference this year. Like the title says, the ""granddaddy's"" of modern AI are going to be speaking at the conference! This is a great opportunity to get online and listen to some quality talks and science across many domains and product talks etc.

Here's a sign up link, I get zero commission for this, just want to share the love.[https://www.nvidia.com/en-us/gtc/?ncid=GTCS21-NVKASMITH](https://www.nvidia.com/en-us/gtc/?ncid=GTCS21-NVKASMITH)

Also here are some bullets of what GTC has in store.

* GTC is a **free** online conference and happening **April 12-16** with live sessions across the world.
* **Keynote** requires **no registration** and happens **Monday, April 12, at 8:30 AM PST**, with a second broadcast at **6:00 PM PST** for APAC audiences.
* The conference will have live webinars, on-demand sessions, posters. Connect With Experts, DLI (with a fee), and multiple panels that include industry pioneers, researchers, developers, start-ups, venture capitalists, and more.
* There is an amazing line-up of speakers including Gordon Bell award winners, AI pioneers, Oscar-winning artists, and thought leaders from every industry.",1564
571,571,Tokenizing / picking words out of non-english languages,"Greetings!

I'm a CompSci major interested in NLP - however I'm very new to NLP. I currently know Spanish and Japanese - and am making a tool that allows users to learn Japanese easier. It's very similar to the windows snipping tool, once you've made a selection, it uses OCR to scan a bitmap for text. My main question is: 

How can I tokenize sentences into individual words, when Japanese doesn't have spaces? 

In English we can simply split up sentences based on spaces, but Japanese text does not have this.

Example: この文にスぺースがありません。 (English: ""In this sentence, there are no spaces"")

The goal I'm working towards is being able to click each word within the sentence, allowing for the program to do SQL queries to a Japanese datasbe containing linguistic information. This will then display back to the user things like the word's meaning, and how to read it. I have the data and database part set up, it's specifically the process of breaking Japanese sentences into easily tokenized strings. 

&amp;#x200B;

Apologies for any mistakes I might have made in writing this, I'm still relatively new to NLP and Data Science in general!",https://www.reddit.com/r/LanguageTechnology/comments/m22r5j/tokenizing_picking_words_out_of_nonenglish/,LanguageTechnology,t3_m22r5j,"Tokenizing / picking words out of non-english languages Greetings!

I'm a CompSci major interested in NLP - however I'm very new to NLP. I currently know Spanish and Japanese - and am making a tool that allows users to learn Japanese easier. It's very similar to the windows snipping tool, once you've made a selection, it uses OCR to scan a bitmap for text. My main question is: 

How can I tokenize sentences into individual words, when Japanese doesn't have spaces? 

In English we can simply split up sentences based on spaces, but Japanese text does not have this.

Example: この文にスぺースがありません。 (English: ""In this sentence, there are no spaces"")

The goal I'm working towards is being able to click each word within the sentence, allowing for the program to do SQL queries to a Japanese datasbe containing linguistic information. This will then display back to the user things like the word's meaning, and how to read it. I have the data and database part set up, it's specifically the process of breaking Japanese sentences into easily tokenized strings. 

&amp;#x200B;

Apologies for any mistakes I might have made in writing this, I'm still relatively new to NLP and Data Science in general!",1195
572,572,[Tutorial] Introduction to Encoder-Decoder Sequence-to-Sequence Models (Seq2Seq),"Seq2seq models are advantageous for their ability to process text inputs without a constrained length. This tutorial covers encoder-decoder sequence-to-sequence models (seq2seq) in-depth. Topics covered include:

1. Seq2seq architecture
2. Applications
3. Implementing seq2seq for text summarization with Keras

Note that the third point only goes up until the data loading and text processing steps. Training and inference are covered in Part 2, which is coming out on Friday. :)

Article link: [https://blog.paperspace.com/introduction-to-seq2seq-models/](https://blog.paperspace.com/introduction-to-seq2seq-models/)

You can also run the full code on a free GPU: https://ml-showcase.paperspace.com/projects/text-summarization-with-seq2seq-models",https://www.reddit.com/r/LanguageTechnology/comments/m1zzyc/tutorial_introduction_to_encoderdecoder/,LanguageTechnology,t3_m1zzyc,"[Tutorial] Introduction to Encoder-Decoder Sequence-to-Sequence Models (Seq2Seq) Seq2seq models are advantageous for their ability to process text inputs without a constrained length. This tutorial covers encoder-decoder sequence-to-sequence models (seq2seq) in-depth. Topics covered include:

1. Seq2seq architecture
2. Applications
3. Implementing seq2seq for text summarization with Keras

Note that the third point only goes up until the data loading and text processing steps. Training and inference are covered in Part 2, which is coming out on Friday. :)

Article link: [https://blog.paperspace.com/introduction-to-seq2seq-models/](https://blog.paperspace.com/introduction-to-seq2seq-models/)

You can also run the full code on a free GPU: https://ml-showcase.paperspace.com/projects/text-summarization-with-seq2seq-models",829
573,573,How to predict a word in a corpus given its description,Idk what this task is called in NLP. But is there any dataset that allows me to do this?,https://www.reddit.com/r/LanguageTechnology/comments/m1shj4/how_to_predict_a_word_in_a_corpus_given_its/,LanguageTechnology,t3_m1shj4,How to predict a word in a corpus given its description Idk what this task is called in NLP. But is there any dataset that allows me to do this?,144
574,574,Got Confused going through a documentation.,"I have a doubt someone explain please: we have seen this classic example of why we use bert and other sentence level embedding rather than glove or doc2vec etc. for sentence level task because the same word ""bank"" used in different context will carry different meaning.

But if we are using it in two sentence :
1) man went to bank to withdraw money.
2) man went to bank for fishing.

Wouldn't adding bank embedding with deposit for 1st sentence and fishing for 2nd sentence be well enough to differentiate between sentences...so why do we do this sentence embedding when avg. of word embedding are just good enough, I don't see this reason justify the meaning behind it well enough.",https://www.reddit.com/r/LanguageTechnology/comments/m20dgi/got_confused_going_through_a_documentation/,LanguageTechnology,t3_m20dgi,"Got Confused going through a documentation. I have a doubt someone explain please: we have seen this classic example of why we use bert and other sentence level embedding rather than glove or doc2vec etc. for sentence level task because the same word ""bank"" used in different context will carry different meaning.

But if we are using it in two sentence :
1) man went to bank to withdraw money.
2) man went to bank for fishing.

Wouldn't adding bank embedding with deposit for 1st sentence and fishing for 2nd sentence be well enough to differentiate between sentences...so why do we do this sentence embedding when avg. of word embedding are just good enough, I don't see this reason justify the meaning behind it well enough.",727
575,575,Custom Word Embeddings or Word2Vec,"Hi friends,

I have a huge documents(tickets) raised by users in company.But most of those are not more than 50 words and after preprocessing it came down to hardly 20-30 words
If I use Word2vec it is increasing the dimension to 300 
Still is it advisable to go for word2vec for proper relation between words or Custom word embeddings of less dimension",https://www.reddit.com/r/LanguageTechnology/comments/m1wiux/custom_word_embeddings_or_word2vec/,LanguageTechnology,t3_m1wiux,"Custom Word Embeddings or Word2Vec Hi friends,

I have a huge documents(tickets) raised by users in company.But most of those are not more than 50 words and after preprocessing it came down to hardly 20-30 words
If I use Word2vec it is increasing the dimension to 300 
Still is it advisable to go for word2vec for proper relation between words or Custom word embeddings of less dimension",387
576,576,Question About ACL2018 Tutorial5,"Hey guys!

Hope you are all well.

I found the attractive tutorial in ACL 2018 '*Beyond Multiword Expressions: Processing Idioms and Metaphors',* and am very interested in this topic about modeling metaphors.  
But it was unfortunate that the link provided in ACL2018 ([https://www.angl.hu-berlin.de/department/staff-faculty/other/kordoni/acl18\_tutorial)](https://www.angl.hu-berlin.de/department/staff-faculty/other/kordoni/acl18_tutorial)) was down. 

Is there anyone willing to share a copy or a reachable link?

Thank you in advance!",https://www.reddit.com/r/LanguageTechnology/comments/m1sn0c/question_about_acl2018_tutorial5/,LanguageTechnology,t3_m1sn0c,"Question About ACL2018 Tutorial5 Hey guys!

Hope you are all well.

I found the attractive tutorial in ACL 2018 '*Beyond Multiword Expressions: Processing Idioms and Metaphors',* and am very interested in this topic about modeling metaphors.  
But it was unfortunate that the link provided in ACL2018 ([https://www.angl.hu-berlin.de/department/staff-faculty/other/kordoni/acl18\_tutorial)](https://www.angl.hu-berlin.de/department/staff-faculty/other/kordoni/acl18_tutorial)) was down. 

Is there anyone willing to share a copy or a reachable link?

Thank you in advance!",571
577,577,Fun failure compilation from our gesture synthesis research,,https://youtu.be/-C2H1YojjWI,LanguageTechnology,t3_m18oa2,Fun failure compilation from our gesture synthesis research ,60
578,578,How to fine-tune BERT with Spacy 3: tutorial,"Looking to train an NER model using your favorite transformer?

Checkout this new article [https://walidamamou.medium.com/how-to-fine-tune-bert...](https://walidamamou.medium.com/how-to-fine-tune-bert-transformer-with-spacy-3-6a90bfe57647?fbclid=IwAR0MrqwSjdlkJq3F58F_rGUqGRPHwaKnAzUyv-87Z6jzPtZMgRR2Bwfhqaw) on how to fine tune BERT transformer for NER using the newly released spaCy 3.

On a different note, we are looking for NLP experts to join our team (https://ubiai.tools), if anyone is interested please DM me!",https://www.reddit.com/r/LanguageTechnology/comments/m0pcrf/how_to_finetune_bert_with_spacy_3_tutorial/,LanguageTechnology,t3_m0pcrf,"How to fine-tune BERT with Spacy 3: tutorial Looking to train an NER model using your favorite transformer?

Checkout this new article [https://walidamamou.medium.com/how-to-fine-tune-bert...](https://walidamamou.medium.com/how-to-fine-tune-bert-transformer-with-spacy-3-6a90bfe57647?fbclid=IwAR0MrqwSjdlkJq3F58F_rGUqGRPHwaKnAzUyv-87Z6jzPtZMgRR2Bwfhqaw) on how to fine tune BERT transformer for NER using the newly released spaCy 3.

On a different note, we are looking for NLP experts to join our team (https://ubiai.tools), if anyone is interested please DM me!",563
579,579,NLU learning path,"Hi all,

Hope everyone is keeping safe in these tough times. I'm a noob in NLP related technologies, I'm working on a lot of projects to consolidate my learnings. I want to understand the lifecycle of process of making a chat bot for that I want to learn NLU concepts can anyone suggest me some good resource for that. I'll really appreciate it",https://www.reddit.com/r/LanguageTechnology/comments/m0fxir/nlu_learning_path/,LanguageTechnology,t3_m0fxir,"NLU learning path Hi all,

Hope everyone is keeping safe in these tough times. I'm a noob in NLP related technologies, I'm working on a lot of projects to consolidate my learnings. I want to understand the lifecycle of process of making a chat bot for that I want to learn NLU concepts can anyone suggest me some good resource for that. I'll really appreciate it",362
580,580,"Intent and Action Classification, analyze Chinese News and the Crypto market, train a classifier that understands 100+ languages, translate between 200 + languages, answer questions, summarize text and much more on NLU 1.1.3","# Intent and Action Classification,  analyze Chinese News and the Crypto market, train a classifier that understands 100+ languages, translate between 200 + languages, answer questions, summarize text, and much more in NLU 1.1.3 

## NLU 1.1.3 Release Notes
We are very excited to announce that the latest NLU release comes with a new pretrained Intent Classifier and NER Action Extractor for text related to
music, restaurants, and movies trained on the SNIPS dataset. Make sure to check out the models hub and the easy 1-liners for more info!

In addition to that, new NER and Embedding models for Bengali are now available

Finally, there is a new NLU Webinar with 9 accompanying tutorial notebooks which teach you  a lot of things and is segmented into the following parts :

- Part1: Easy 1 Liners 
  - Spell checking/Sentiment/POS/NER/ BERTtology embeddings
- Part2: Data analysis and NLP tasks on [Crypto News Headline dataset](https://www.kaggle.com/kashnitsky/news-about-major-cryptocurrencies-20132018-40k)
  - Preprocessing and extracting Emotions, Keywords, Named Entities and visualize them
- Part3: NLU Multi-Lingual 1 Liners with [Microsoft's Marian Models](https://marian-nmt.github.io/publications/)
  - Translate between 200+ languages (and classify lang afterward)
- Part 4: Data analysis and NLP tasks on [Chinese News Article Dataset](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/4_Unsupervise_Chinese_Keyword_Extraction_NER_and_Translation_from_Chinese_News.ipynb)
  - Word Segmentation, Lemmatization, Extract Keywords, Named Entities and translate to english
- Part 5: Train a sentiment Classifier that understands 100+ Languages
  - Train on a french sentiment dataset and predict the sentiment of 100+ languages with [language-agnostic BERT Sentence Embedding](https://arxiv.org/abs/2007.01852)
- Part 6: Question answering, Summarization, Squad and more with [Google's T5](https://arxiv.org/abs/1910.10683)
  - T5 Question answering and 18 + other NLP tasks ([SQUAD](https://arxiv.org/abs/1606.05250) / [GLUE](https://arxiv.org/abs/1804.07461) / [SUPER GLUE](https://super.gluebenchmark.com/))


### New Models

#### NLU 1.1.3 New Non-English Models

| Language | nlu.load() reference                                         | Spark NLP Model reference                                    | Type                  |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------------------- |
| Bengali  | [bn.ner.cc_300d](https://nlp.johnsnowlabs.com/2021/02/10/bengali_cc_300d_bn.html) | [ bengaliner_cc_300d](https://nlp.johnsnowlabs.com/2021/02/10/bengali_cc_300d_bn.html) | NerDLModel    |
| Bengali  | [bn.embed](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html) | [bengali_cc_300d](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html) | NerDLModel            |
| Bengali  | [bn.embed.cc_300d](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html) | [bengali_cc_300d](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html) | Word Embeddings Model (Alias)    |
| Bengali  | [bn.embed.glove](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html) | [bengali_cc_300d](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html) |  Word Embeddings Model (Alias)|





#### NLU 1.1.3 New English Models

|Language | nlu.load() reference | Spark NLP Model reference | Type |
|---------|---------------------|----------------------------|------|
| English | [en.classify.snips](https://nlp.johnsnowlabs.com/2021/02/15/nerdl_snips_100d_en.html) |[nerdl_snips_100d](https://nlp.johnsnowlabs.com/2021/02/15/nerdl_snips_100d_en.html)     | NerDLModel |
| English | [en.ner.snips](https://nlp.johnsnowlabs.com/2021/02/15/classifierdl_use_snips_en.html) |[classifierdl_use_snips](https://nlp.johnsnowlabs.com/2021/02/15/classifierdl_use_snips_en.html)|ClassifierDLModel|




### New NLU Webinar
#### [State-of-the-art Natural Language Processing for 200+ Languages with 1 Line of code](https://events.johnsnowlabs.com/state-of-the-art-natural-language-processing-for-200-languages-with-1-line-of-code)


##### Talk Abstract 
Learn to harness the power of 1,000+ production-grade &amp; scalable NLP models for 200+ languages - all available with just 1 line of Python code by leveraging the open-source NLU library, which is powered by the widely popular Spark NLP.

John Snow Labs has delivered over 80 releases of Spark NLP to date, making it the most widely used NLP library in the enterprise and providing the AI community with state-of-the-art accuracy and scale for a variety of common NLP tasks. The most recent releases include pre-trained models for over 200 languages - including languages that do not use spaces for word segmentation algorithms like Chinese, Japanese, and Korean, and languages written from right to left like Arabic, Farsi, Urdu, and Hebrew. All software and models are free and open source under an Apache 2.0 license.

This webinar will show you how to leverage the multi-lingual capabilities of Spark NLP &amp; NLU - including automated language detection for up to 375 languages, and the ability to perform translation, named entity recognition, stopword removal, lemmatization, and more in a variety of language families. We will create Python code in real-time and solve these problems in just 30 minutes. The notebooks will then be made freely available online.

You can watch the [video here,](https://events.johnsnowlabs.com/state-of-the-art-natural-language-processing-for-200-languages-with-1-line-of-code) 

### NLU 1.1.3 New Notebooks and tutorials


#### New Webinar Notebooks

1. [NLU basics, easy 1-liners (Spellchecking, sentiment, NER, POS, BERT](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/0_liners_intro.ipynb)
2. [Analyze Crypto News dataset with Keyword extraction, NER, Emotional distribution, and stemming](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/1_NLU_base_features_on_dataset_with_YAKE_Lemma_Stemm_classifiers_NER_.ipynb)
3. [Translate Crypto News dataset between 300 Languages with the Marian Model (German, French, Hebrew examples)](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/2_multilingual_translation_with_marian_intro.ipynb)
4. [Translate Crypto News dataset between 300 Languages with the Marian Model (Hindi, Russian, Chinese examples)](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/3_more_multi_lingual_NLP_translation_Asian_languages_with_Marian.ipynb)
5. [Analyze Chinese News Headlines with Chinese Word Segmentation, Lemmatization, NER, and Keyword extraction](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/4_Unsupervise_Chinese_Keyword_Extraction_NER_and_Translation_from_Chinese_News.ipynb)
6. [Train a Sentiment Classifier that will understand 100+ languages on just a French Dataset with the powerful Language Agnostic Bert Embeddings](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/5_multi_lingual_sentiment_classifier_training_for_over_100_languages.ipynb)
7. [Summarize text and Answer Questions with T5](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/6_T5_question_answering_and_Text_summarization.ipynb)
8. [Solve any task in 1 line from SQUAD, GLUE and SUPER GLUE with T5](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/7_T5_SQUAD_GLUE_SUPER_GLUE_TASKS.ipynb)
9. [Overview of models for various languages](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/8_Multi_lingual_ner_pos_stop_words_sentiment_pretrained.ipynb)





#### New easy NLU 1-liners in NLU 1.1.3

####  [Detect actions in general commands related to music, restaurant, movies.](https://nlp.johnsnowlabs.com/2021/02/15/nerdl_snips_100d_en.html)


```python
nlu.load(""en.classify.snips"").predict(""book a spot for nona gray  myrtle and alison at a top-rated brasserie that is distant from wilson av on nov  the 4th  2030 that serves ouzeri"",output_level = ""document"")
```

outputs :

|                                               ner_confidence | entities                                                     | document                                                     | Entities_Classes                                             |
| -----------------------------------------------------------: | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| [1.0, 1.0, 0.9997000098228455, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9990000128746033, 1.0, 1.0, 1.0, 0.9965000152587891, 0.9998999834060669, 0.9567000269889832, 1.0, 1.0, 1.0, 0.9980000257492065, 0.9991999864578247, 0.9988999962806702, 1.0, 1.0, 0.9998999834060669] | ['nona gray myrtle and alison', 'top-rated', 'brasserie', 'distant', 'wilson av', 'nov the 4th 2030', 'ouzeri'] | book a spot for nona gray myrtle and alison at a top-rated brasserie that is distant from wilson av on nov the 4th 2030 that serves ouzeri | ['party_size_description', 'sort', 'restaurant_type', 'spatial_relation', 'poi', 'timeRange', 'cuisine'] |

####  [Named Entity Recognition (NER) Model in Bengali (bengaliner_cc_300d)](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html)


```python
# Bengali for: 'Iajuddin Ahmed passed Matriculation from Munshiganj High School in 1947 and Intermediate from Munshiganj Horganga College in 1950.'
nlu.load(""bn.ner.cc_300d"").predict(""১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন"",output_level = ""document"")
```

outputs :

| ner_confidence                                                                                                                                                                                                                                                                                                                                                                                                                       | entities                                                                           | Entities_Classes   | document                                                                                                                         |
|---------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------|:--------------------------------------|
| [0.9987999796867371, 0.9854000210762024, 0.8604000210762024, 0.6686999797821045, 0.5289999842643738, 0.7009999752044678, 0.7684999704360962, 0.9979000091552734, 0.9976000189781189, 0.9930999875068665, 0.9994000196456909, 0.9879000186920166, 0.7407000064849854, 0.9215999841690063, 0.7657999992370605, 0.39419999718666077, 0.9124000072479248, 0.9932000041007996, 0.9919999837875366, 0.995199978351593, 0.9991999864578247] | ['সালে', 'ইয়াজউদ্দিন আহম্মেদ', 'মুন্সিগঞ্জ উচ্চ বিদ্যালয়', 'সালে', 'মুন্সিগঞ্জ হরগঙ্গা কলেজ'] | ['TIME', 'PER', 'ORG', 'TIME', 'ORG'] | ১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন |

#### [Identify intent in general text - SNIPS dataset](https://nlp.johnsnowlabs.com/2021/02/15/classifierdl_use_snips_en.html)


```python
nlu.load(""en.ner.snips"").predict(""I want to bring six of us to a bistro in town that serves hot chicken sandwich that is within the same area"",output_level = ""document"")
```

outputs :


| document | snips | snips_confidence|
|----------|------|------------------|
| I want to bring six of us to a bistro in town that serves hot chicken sandwich that is within the same area | BookRestaurant |                  1 |


#### [Word Embeddings for Bengali (bengali_cc_300d)](https://nlp.johnsnowlabs.com/2021/02/10/bengali_cc_300d_bn.html)




```python
# Bengali for : 'Iajuddin Ahmed passed Matriculation from Munshiganj High School in 1947 and Intermediate from Munshiganj Horganga College in 1950.'
nlu.load(""bn.embed"").predict(""১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন"",output_level = ""document"")
```

outputs :

|                                                     document | bn_embed_embeddings                                          |
| -----------------------------------------------------------: | :----------------------------------------------------------- |
| ১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন | [-0.0828      0.0683      0.0215     ...  0.0679     -0.0484...] |



### NLU 1.1.3 Enhancements
- Added automatic conversion  to Sentence Embeddings of Word Embeddings when there is no Sentence Embedding Avaiable and a model needs the converted version to run.


### NLU 1.1.3 Bug Fixes
- Fixed a bug that caused `ur.sentiment` NLU pipeline to build incorrectly
- Fixed a bug that caused `sentiment.imdb.glove` NLU pipeline to build incorrectly
- Fixed a bug that caused `en.sentiment.glove.imdb` NLU pipeline to build incorrectly
- Fixed a bug that caused Spark 2.3.X environments to crash.

### NLU Installation

```bash
# PyPi
!pip install nlu pyspark==2.4.7
#Conda
# Install NLU from Anaconda/Conda
conda install -c johnsnowlabs nlu
```

### Additional NLU ressources

- [NLU Website](https://nlu.johnsnowlabs.com/)
- [All NLU Tutorial Notebooks](https://nlu.johnsnowlabs.com/docs/en/notebooks)
- [NLU Videos and Blogposts on NLU](https://nlp.johnsnowlabs.com/learn#pythons-nlu-library)
- [NLU on Github](https://github.com/JohnSnowLabs/nlu)
- [Suggestions or Questions? Contact us in Slack!](https://join.slack.com/t/spark-nlp/shared_invite/zt-lutct9gm-kuUazcyFKhuGY3_0AMkxqA)",https://www.reddit.com/r/LanguageTechnology/comments/m0chul/intent_and_action_classification_analyze_chinese/,LanguageTechnology,t3_m0chul,"Intent and Action Classification, analyze Chinese News and the Crypto market, train a classifier that understands 100+ languages, translate between 200 + languages, answer questions, summarize text and much more on NLU 1.1.3 # Intent and Action Classification,  analyze Chinese News and the Crypto market, train a classifier that understands 100+ languages, translate between 200 + languages, answer questions, summarize text, and much more in NLU 1.1.3 

## NLU 1.1.3 Release Notes
We are very excited to announce that the latest NLU release comes with a new pretrained Intent Classifier and NER Action Extractor for text related to
music, restaurants, and movies trained on the SNIPS dataset. Make sure to check out the models hub and the easy 1-liners for more info!

In addition to that, new NER and Embedding models for Bengali are now available

Finally, there is a new NLU Webinar with 9 accompanying tutorial notebooks which teach you  a lot of things and is segmented into the following parts :

- Part1: Easy 1 Liners 
  - Spell checking/Sentiment/POS/NER/ BERTtology embeddings
- Part2: Data analysis and NLP tasks on [Crypto News Headline dataset](https://www.kaggle.com/kashnitsky/news-about-major-cryptocurrencies-20132018-40k)
  - Preprocessing and extracting Emotions, Keywords, Named Entities and visualize them
- Part3: NLU Multi-Lingual 1 Liners with [Microsoft's Marian Models](https://marian-nmt.github.io/publications/)
  - Translate between 200+ languages (and classify lang afterward)
- Part 4: Data analysis and NLP tasks on [Chinese News Article Dataset](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/4_Unsupervise_Chinese_Keyword_Extraction_NER_and_Translation_from_Chinese_News.ipynb)
  - Word Segmentation, Lemmatization, Extract Keywords, Named Entities and translate to english
- Part 5: Train a sentiment Classifier that understands 100+ Languages
  - Train on a french sentiment dataset and predict the sentiment of 100+ languages with [language-agnostic BERT Sentence Embedding](https://arxiv.org/abs/2007.01852)
- Part 6: Question answering, Summarization, Squad and more with [Google's T5](https://arxiv.org/abs/1910.10683)
  - T5 Question answering and 18 + other NLP tasks ([SQUAD](https://arxiv.org/abs/1606.05250) / [GLUE](https://arxiv.org/abs/1804.07461) / [SUPER GLUE](https://super.gluebenchmark.com/))


### New Models

#### NLU 1.1.3 New Non-English Models

| Language | nlu.load() reference                                         | Spark NLP Model reference                                    | Type                  |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | --------------------- |
| Bengali  | [bn.ner.cc_300d](https://nlp.johnsnowlabs.com/2021/02/10/bengali_cc_300d_bn.html) | [ bengaliner_cc_300d](https://nlp.johnsnowlabs.com/2021/02/10/bengali_cc_300d_bn.html) | NerDLModel    |
| Bengali  | [bn.embed](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html) | [bengali_cc_300d](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html) | NerDLModel            |
| Bengali  | [bn.embed.cc_300d](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html) | [bengali_cc_300d](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html) | Word Embeddings Model (Alias)    |
| Bengali  | [bn.embed.glove](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html) | [bengali_cc_300d](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html) |  Word Embeddings Model (Alias)|





#### NLU 1.1.3 New English Models

|Language | nlu.load() reference | Spark NLP Model reference | Type |
|---------|---------------------|----------------------------|------|
| English | [en.classify.snips](https://nlp.johnsnowlabs.com/2021/02/15/nerdl_snips_100d_en.html) |[nerdl_snips_100d](https://nlp.johnsnowlabs.com/2021/02/15/nerdl_snips_100d_en.html)     | NerDLModel |
| English | [en.ner.snips](https://nlp.johnsnowlabs.com/2021/02/15/classifierdl_use_snips_en.html) |[classifierdl_use_snips](https://nlp.johnsnowlabs.com/2021/02/15/classifierdl_use_snips_en.html)|ClassifierDLModel|




### New NLU Webinar
#### [State-of-the-art Natural Language Processing for 200+ Languages with 1 Line of code](https://events.johnsnowlabs.com/state-of-the-art-natural-language-processing-for-200-languages-with-1-line-of-code)


##### Talk Abstract 
Learn to harness the power of 1,000+ production-grade &amp; scalable NLP models for 200+ languages - all available with just 1 line of Python code by leveraging the open-source NLU library, which is powered by the widely popular Spark NLP.

John Snow Labs has delivered over 80 releases of Spark NLP to date, making it the most widely used NLP library in the enterprise and providing the AI community with state-of-the-art accuracy and scale for a variety of common NLP tasks. The most recent releases include pre-trained models for over 200 languages - including languages that do not use spaces for word segmentation algorithms like Chinese, Japanese, and Korean, and languages written from right to left like Arabic, Farsi, Urdu, and Hebrew. All software and models are free and open source under an Apache 2.0 license.

This webinar will show you how to leverage the multi-lingual capabilities of Spark NLP &amp; NLU - including automated language detection for up to 375 languages, and the ability to perform translation, named entity recognition, stopword removal, lemmatization, and more in a variety of language families. We will create Python code in real-time and solve these problems in just 30 minutes. The notebooks will then be made freely available online.

You can watch the [video here,](https://events.johnsnowlabs.com/state-of-the-art-natural-language-processing-for-200-languages-with-1-line-of-code) 

### NLU 1.1.3 New Notebooks and tutorials


#### New Webinar Notebooks

1. [NLU basics, easy 1-liners (Spellchecking, sentiment, NER, POS, BERT](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/0_liners_intro.ipynb)
2. [Analyze Crypto News dataset with Keyword extraction, NER, Emotional distribution, and stemming](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/1_NLU_base_features_on_dataset_with_YAKE_Lemma_Stemm_classifiers_NER_.ipynb)
3. [Translate Crypto News dataset between 300 Languages with the Marian Model (German, French, Hebrew examples)](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/2_multilingual_translation_with_marian_intro.ipynb)
4. [Translate Crypto News dataset between 300 Languages with the Marian Model (Hindi, Russian, Chinese examples)](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/3_more_multi_lingual_NLP_translation_Asian_languages_with_Marian.ipynb)
5. [Analyze Chinese News Headlines with Chinese Word Segmentation, Lemmatization, NER, and Keyword extraction](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/4_Unsupervise_Chinese_Keyword_Extraction_NER_and_Translation_from_Chinese_News.ipynb)
6. [Train a Sentiment Classifier that will understand 100+ languages on just a French Dataset with the powerful Language Agnostic Bert Embeddings](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/5_multi_lingual_sentiment_classifier_training_for_over_100_languages.ipynb)
7. [Summarize text and Answer Questions with T5](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/6_T5_question_answering_and_Text_summarization.ipynb)
8. [Solve any task in 1 line from SQUAD, GLUE and SUPER GLUE with T5](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/7_T5_SQUAD_GLUE_SUPER_GLUE_TASKS.ipynb)
9. [Overview of models for various languages](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/8_Multi_lingual_ner_pos_stop_words_sentiment_pretrained.ipynb)





#### New easy NLU 1-liners in NLU 1.1.3

####  [Detect actions in general commands related to music, restaurant, movies.](https://nlp.johnsnowlabs.com/2021/02/15/nerdl_snips_100d_en.html)


```python
nlu.load(""en.classify.snips"").predict(""book a spot for nona gray  myrtle and alison at a top-rated brasserie that is distant from wilson av on nov  the 4th  2030 that serves ouzeri"",output_level = ""document"")
```

outputs :

|                                               ner_confidence | entities                                                     | document                                                     | Entities_Classes                                             |
| -----------------------------------------------------------: | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| [1.0, 1.0, 0.9997000098228455, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9990000128746033, 1.0, 1.0, 1.0, 0.9965000152587891, 0.9998999834060669, 0.9567000269889832, 1.0, 1.0, 1.0, 0.9980000257492065, 0.9991999864578247, 0.9988999962806702, 1.0, 1.0, 0.9998999834060669] | ['nona gray myrtle and alison', 'top-rated', 'brasserie', 'distant', 'wilson av', 'nov the 4th 2030', 'ouzeri'] | book a spot for nona gray myrtle and alison at a top-rated brasserie that is distant from wilson av on nov the 4th 2030 that serves ouzeri | ['party_size_description', 'sort', 'restaurant_type', 'spatial_relation', 'poi', 'timeRange', 'cuisine'] |

####  [Named Entity Recognition (NER) Model in Bengali (bengaliner_cc_300d)](https://nlp.johnsnowlabs.com/2021/02/10/bengaliner_cc_300d_bn.html)


```python
# Bengali for: 'Iajuddin Ahmed passed Matriculation from Munshiganj High School in 1947 and Intermediate from Munshiganj Horganga College in 1950.'
nlu.load(""bn.ner.cc_300d"").predict(""১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন"",output_level = ""document"")
```

outputs :

| ner_confidence                                                                                                                                                                                                                                                                                                                                                                                                                       | entities                                                                           | Entities_Classes   | document                                                                                                                         |
|---------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------|:--------------------------------------|
| [0.9987999796867371, 0.9854000210762024, 0.8604000210762024, 0.6686999797821045, 0.5289999842643738, 0.7009999752044678, 0.7684999704360962, 0.9979000091552734, 0.9976000189781189, 0.9930999875068665, 0.9994000196456909, 0.9879000186920166, 0.7407000064849854, 0.9215999841690063, 0.7657999992370605, 0.39419999718666077, 0.9124000072479248, 0.9932000041007996, 0.9919999837875366, 0.995199978351593, 0.9991999864578247] | ['সালে', 'ইয়াজউদ্দিন আহম্মেদ', 'মুন্সিগঞ্জ উচ্চ বিদ্যালয়', 'সালে', 'মুন্সিগঞ্জ হরগঙ্গা কলেজ'] | ['TIME', 'PER', 'ORG', 'TIME', 'ORG'] | ১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন |

#### [Identify intent in general text - SNIPS dataset](https://nlp.johnsnowlabs.com/2021/02/15/classifierdl_use_snips_en.html)


```python
nlu.load(""en.ner.snips"").predict(""I want to bring six of us to a bistro in town that serves hot chicken sandwich that is within the same area"",output_level = ""document"")
```

outputs :


| document | snips | snips_confidence|
|----------|------|------------------|
| I want to bring six of us to a bistro in town that serves hot chicken sandwich that is within the same area | BookRestaurant |                  1 |


#### [Word Embeddings for Bengali (bengali_cc_300d)](https://nlp.johnsnowlabs.com/2021/02/10/bengali_cc_300d_bn.html)




```python
# Bengali for : 'Iajuddin Ahmed passed Matriculation from Munshiganj High School in 1947 and Intermediate from Munshiganj Horganga College in 1950.'
nlu.load(""bn.embed"").predict(""১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন"",output_level = ""document"")
```

outputs :

|                                                     document | bn_embed_embeddings                                          |
| -----------------------------------------------------------: | :----------------------------------------------------------- |
| ১৯৪৮ সালে ইয়াজউদ্দিন আহম্মেদ মুন্সিগঞ্জ উচ্চ বিদ্যালয় থেকে মেট্রিক পাশ করেন এবং ১৯৫০ সালে মুন্সিগঞ্জ হরগঙ্গা কলেজ থেকে ইন্টারমেডিয়েট পাশ করেন | [-0.0828      0.0683      0.0215     ...  0.0679     -0.0484...] |



### NLU 1.1.3 Enhancements
- Added automatic conversion  to Sentence Embeddings of Word Embeddings when there is no Sentence Embedding Avaiable and a model needs the converted version to run.


### NLU 1.1.3 Bug Fixes
- Fixed a bug that caused `ur.sentiment` NLU pipeline to build incorrectly
- Fixed a bug that caused `sentiment.imdb.glove` NLU pipeline to build incorrectly
- Fixed a bug that caused `en.sentiment.glove.imdb` NLU pipeline to build incorrectly
- Fixed a bug that caused Spark 2.3.X environments to crash.

### NLU Installation

```bash
# PyPi
!pip install nlu pyspark==2.4.7
#Conda
# Install NLU from Anaconda/Conda
conda install -c johnsnowlabs nlu
```

### Additional NLU ressources

- [NLU Website](https://nlu.johnsnowlabs.com/)
- [All NLU Tutorial Notebooks](https://nlu.johnsnowlabs.com/docs/en/notebooks)
- [NLU Videos and Blogposts on NLU](https://nlp.johnsnowlabs.com/learn#pythons-nlu-library)
- [NLU on Github](https://github.com/JohnSnowLabs/nlu)
- [Suggestions or Questions? Contact us in Slack!](https://join.slack.com/t/spark-nlp/shared_invite/zt-lutct9gm-kuUazcyFKhuGY3_0AMkxqA)",14979
581,581,NLP for a general object classification?,"Hey there, I'm interested in experimenting with natural language processing to see if it's possible to perform some sort of object classification with a large dataset, most likely wikipedia. An example scenario would be where a user can formulate questions about what can and cannot be done with an object, and the model can answer these questions.

&amp;#x200B;

An example of this could be:  
User: ""can a cup be filled with water?""

Model: ""yes""

User: ""does a cat bark?""

Model: ""no""

&amp;#x200B;

I am aware that projects like GPT-3 and similar are \*very\* complex and can (to some degree) reason, however my intention with this is \*not\* to perform advanced language processing that requires advanced analysis. Also, the example provided above is not representative of what my goals are with this; the conversation may be represented with some simple class or structure that conveys the object you're asking about (cup/motorcycle), and the subject in question (can it be filled with water/does it bark). Therefore the purpose of this question does not pertain to the question asked by the user but the ability to parse text from an available database and extract useful facts and key information from the text.

&amp;#x200B;

Any advice? Thanks",https://www.reddit.com/r/LanguageTechnology/comments/m0l9zv/nlp_for_a_general_object_classification/,LanguageTechnology,t3_m0l9zv,"NLP for a general object classification? Hey there, I'm interested in experimenting with natural language processing to see if it's possible to perform some sort of object classification with a large dataset, most likely wikipedia. An example scenario would be where a user can formulate questions about what can and cannot be done with an object, and the model can answer these questions.

&amp;#x200B;

An example of this could be:  
User: ""can a cup be filled with water?""

Model: ""yes""

User: ""does a cat bark?""

Model: ""no""

&amp;#x200B;

I am aware that projects like GPT-3 and similar are \*very\* complex and can (to some degree) reason, however my intention with this is \*not\* to perform advanced language processing that requires advanced analysis. Also, the example provided above is not representative of what my goals are with this; the conversation may be represented with some simple class or structure that conveys the object you're asking about (cup/motorcycle), and the subject in question (can it be filled with water/does it bark). Therefore the purpose of this question does not pertain to the question asked by the user but the ability to parse text from an available database and extract useful facts and key information from the text.

&amp;#x200B;

Any advice? Thanks",1294
582,582,Using own POS Tagger with a UD parser,"I have created a POS tagger with a decent accuracy (Ukrainian only, if that matters). I need to apply it in an existing UD parser. I know C# and also I have briefly looked at Python syntax, in case I need it. I can change my tagger to be compatible with a specific parser.

Could you suggest specific parsers that would allow me to use my own part-of-speech tagger?",https://www.reddit.com/r/LanguageTechnology/comments/m0dne1/using_own_pos_tagger_with_a_ud_parser/,LanguageTechnology,t3_m0dne1,"Using own POS Tagger with a UD parser I have created a POS tagger with a decent accuracy (Ukrainian only, if that matters). I need to apply it in an existing UD parser. I know C# and also I have briefly looked at Python syntax, in case I need it. I can change my tagger to be compatible with a specific parser.

Could you suggest specific parsers that would allow me to use my own part-of-speech tagger?",403
583,583,Embeddings of Label Components for Fine-grained NER | Research Papers Summary 011,,https://youtu.be/GBsu1YVBHsQ,LanguageTechnology,t3_lzxalx,Embeddings of Label Components for Fine-grained NER | Research Papers Summary 011 ,82
584,584,Start Japanese text processing without installing any tokenizer on your local environment (tokenizers are on docker container),,https://github.com/himkt/konoha/releases/tag/v4.6.4,LanguageTechnology,t3_m0dbiq,Start Japanese text processing without installing any tokenizer on your local environment (tokenizers are on docker container) ,127
585,585,HyperBand and BOHB: understanding hyperparameter optimization algorithms,"If you want to learn about state-of-the-art hyperparameter optimization algorithms (HPO), in this article I’ll tell you what they are and how they work.

We cover:
- A bit about HPO Approaches 
- What is Bayesian Optimization, and why is this method effective? 
- How do state-of-the-art Hyperparameter Optimization algorithms work? 
- **Hyperband vs BOHB comparison**

[HyperBand vs. BOHB](https://neptune.ai/blog/hyperband-and-bohb-understanding-state-of-the-art-hyperparameter-optimization-algorithms?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-hyperband-and-bohb-understanding-state-of-the-art-hyperparameter-optimization-algorithms&amp;utm_content=languagetechnology)",https://www.reddit.com/r/LanguageTechnology/comments/m0bdh3/hyperband_and_bohb_understanding_hyperparameter/,LanguageTechnology,t3_m0bdh3,"HyperBand and BOHB: understanding hyperparameter optimization algorithms If you want to learn about state-of-the-art hyperparameter optimization algorithms (HPO), in this article I’ll tell you what they are and how they work.

We cover:
- A bit about HPO Approaches 
- What is Bayesian Optimization, and why is this method effective? 
- How do state-of-the-art Hyperparameter Optimization algorithms work? 
- **Hyperband vs BOHB comparison**

[HyperBand vs. BOHB](https://neptune.ai/blog/hyperband-and-bohb-understanding-state-of-the-art-hyperparameter-optimization-algorithms?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-hyperband-and-bohb-understanding-state-of-the-art-hyperparameter-optimization-algorithms&amp;utm_content=languagetechnology)",761
586,586,Generator for related words/ ideas/ concepts?,"Not sure where else to ask this, but I figured people who traffic in machine learning circles might have some idea.

I'm  certain tools like this must exist in some corner of the internet. I'm looking for some sort of algorithm-generated word cloud tool that expands upon ideas/concepts/words fed to it. Preferably, the more words fed into it, the more refined/related the suggestions. Anybody know of any tools that may work like this, or of any other subs that might help find such a tool?",https://www.reddit.com/r/LanguageTechnology/comments/m0802a/generator_for_related_words_ideas_concepts/,LanguageTechnology,t3_m0802a,"Generator for related words/ ideas/ concepts? Not sure where else to ask this, but I figured people who traffic in machine learning circles might have some idea.

I'm  certain tools like this must exist in some corner of the internet. I'm looking for some sort of algorithm-generated word cloud tool that expands upon ideas/concepts/words fed to it. Preferably, the more words fed into it, the more refined/related the suggestions. Anybody know of any tools that may work like this, or of any other subs that might help find such a tool?",537
587,587,PMI for WordClouds,"Hello!

I'm currently developing an NLP project and I'm stuck on something. I'm a NLP beginner (using Python) and I have some questions I'm hoping the community might help me address.

I've built a dataset of several hundred political speeches and I'm building Word Clouds out of the content of these speeches. To make the story short, I want to tokenize ""phrases"" or ""concepts""; for example the name of an institution or a commonly used phrase by politicians, so that my word cloud will reflect the actual ""phrase"" or ""concept"" instead of showing me the individual words.

I'm aware of the concept of PMI (Pointwise Mutual Information) and how it can help identify these patterns in my data. I haven't been able to find any resources that show a code pipeline to do this.

Any suggestions would be gladly appreciated.

Thanks in advance!",https://www.reddit.com/r/LanguageTechnology/comments/m020dj/pmi_for_wordclouds/,LanguageTechnology,t3_m020dj,"PMI for WordClouds Hello!

I'm currently developing an NLP project and I'm stuck on something. I'm a NLP beginner (using Python) and I have some questions I'm hoping the community might help me address.

I've built a dataset of several hundred political speeches and I'm building Word Clouds out of the content of these speeches. To make the story short, I want to tokenize ""phrases"" or ""concepts""; for example the name of an institution or a commonly used phrase by politicians, so that my word cloud will reflect the actual ""phrase"" or ""concept"" instead of showing me the individual words.

I'm aware of the concept of PMI (Pointwise Mutual Information) and how it can help identify these patterns in my data. I haven't been able to find any resources that show a code pipeline to do this.

Any suggestions would be gladly appreciated.

Thanks in advance!",857
588,588,ANNOY and Semantic Search,"I am trying to build a semantic search algorithm using Bert embeddings and using annoy for indexing. AnnoyIndex() is built to take in pooled embeddings (I think); but what about word embeddings?  For example a word embedding of 100 docs of shape\[100, 256, 768\].  An example of working with pooled embeddings shape (100, 768): - 

from annoy import AnnoyIndex

\# Bert emits 768 dim vectors

D = 768

n\_trees = 300

ann = AnnoyIndex(D, 'angular')

pooled

for index, embed in enumerate(pooled\_embeddings):

ann.add\_item(index, embed)

[ann.build](https://ann.build)(n\_trees)

&amp;#x200B;

Should I flatten the word vectors? should I reduce the dimensionality in some other way?",https://www.reddit.com/r/LanguageTechnology/comments/m01iex/annoy_and_semantic_search/,LanguageTechnology,t3_m01iex,"ANNOY and Semantic Search I am trying to build a semantic search algorithm using Bert embeddings and using annoy for indexing. AnnoyIndex() is built to take in pooled embeddings (I think); but what about word embeddings?  For example a word embedding of 100 docs of shape\[100, 256, 768\].  An example of working with pooled embeddings shape (100, 768): - 

from annoy import AnnoyIndex

\# Bert emits 768 dim vectors

D = 768

n\_trees = 300

ann = AnnoyIndex(D, 'angular')

pooled

for index, embed in enumerate(pooled\_embeddings):

ann.add\_item(index, embed)

[ann.build](https://ann.build)(n\_trees)

&amp;#x200B;

Should I flatten the word vectors? should I reduce the dimensionality in some other way?",709
589,589,Is there a way to deploy NLP models into a Chrome extension?,"I would like to be able to process text data from newspaper sites, tweets, or whatever piece of a text an user can select from a web site and run different NLP inferences (sentiment, polarity, entity recognition, etc.) Within the client side. 

I'm relatively new and ,I don't know, may be Tensorflow could be used? 

Any thoughts?",https://www.reddit.com/r/LanguageTechnology/comments/lziqxi/is_there_a_way_to_deploy_nlp_models_into_a_chrome/,LanguageTechnology,t3_lziqxi,"Is there a way to deploy NLP models into a Chrome extension? I would like to be able to process text data from newspaper sites, tweets, or whatever piece of a text an user can select from a web site and run different NLP inferences (sentiment, polarity, entity recognition, etc.) Within the client side. 

I'm relatively new and ,I don't know, may be Tensorflow could be used? 

Any thoughts?",392
590,590,How to add OOV words into an already pre-trained embedding,"If one has a pre-trained embedding (e.g. fasttext, glove) What is the best way to create embedding vectors for a new word that was not originally in the vocabulary of the pretrained embedding. There is an interesting approach called ""a la carte embeddings"" ([https://arxiv.org/abs/1805.05388](https://arxiv.org/abs/1805.05388)) but seems to be only limited to GLoVe. Anyone aware of any other published or *ad hoc* methods for doing this for any flavour of embedding models?",https://www.reddit.com/r/LanguageTechnology/comments/lzm4q5/how_to_add_oov_words_into_an_already_pretrained/,LanguageTechnology,t3_lzm4q5,"How to add OOV words into an already pre-trained embedding If one has a pre-trained embedding (e.g. fasttext, glove) What is the best way to create embedding vectors for a new word that was not originally in the vocabulary of the pretrained embedding. There is an interesting approach called ""a la carte embeddings"" ([https://arxiv.org/abs/1805.05388](https://arxiv.org/abs/1805.05388)) but seems to be only limited to GLoVe. Anyone aware of any other published or *ad hoc* methods for doing this for any flavour of embedding models?",533
591,591,tNodeEmbed: Node Embeddings with Temporal Graphs | ML with Graphs (Research Paper Walkthrough),,https://youtu.be/Ol1UYsPvsT8,LanguageTechnology,t3_lzja5d,tNodeEmbed: Node Embeddings with Temporal Graphs | ML with Graphs (Research Paper Walkthrough) ,95
592,592,Is it possible to test whether a tokenizer can losslessly tokenize and detokenize a given corpus solely from its vocabulary?,"I am trying to test whether a given vocabulary list contains the tokens necessary to reconstruct a corpus of text losslessly. That is, if a tokenizer trained on a corpus of text were to attempt to tokenize the training corpus according to its associated vocabulary, would it be able to tokenize and detokenize the entire training corpus without losing any text to \[unk\] tokens? Are there ways to test this?

Suppose you had a corpus of text - I’ll use a small one for this example

    corpus = ‘the cat in the hat’

Suppose you had a trained tokenizer which tokenizes according to its vocab list where each token id is simply the index of the token in the list.

    vocab = [‘t’, ‘h’, ‘e’, ‘ ‘, ‘c’, ‘a’, ‘i’, ‘n’]
    print(len(vocab))
    8
    tokens = tokenize(corpus, vocab))
    print(tokens)
    [0, 1, 2, 3, 4, 5, 0, 3, 6, 7, 3, 0, 1, 2, 3, 2, 5, 0]
    print(“Tokenized length: {}”.format(len(tokens)))
    Tokenized length: 18

If I then detokenize from here I can obviously reconstruct the corpus as it originally was. However, this process is suboptimal as we can combine tokens to reduce the length of the tokenized representation.

    vocab = [‘t’, ‘h’, ‘e’, ‘ ‘, ‘c’, ‘a’, ‘i’, ‘n’, ‘th’]
    print(len(vocab))
    9
    tokens = tokenize(corpus, vocab))
    print(tokens)
    [8, 2, 3, 4, 5, 0, 3, 6, 7, 3, 8, 2, 3, 2, 5, 0]
    print(“Tokenized length: {}”.format(len(tokens)))
    Tokenized length: 16

This is obviously still lossless, though it adds an extra token to the vocabulary list, which will increase the possibility space of a model trying to predict the next token in a sequence. But if I remove a necessary token, it becomes lossy. Supppose our tokenizer outputs ‘\[unk\]’ for all tokens not in the vocabulary and that the ‘\[unk\]’ token is always the last token in the vocabulary regardless of the content of the vocabulary.

    vocab = [‘t’, ‘h’, ‘e’, ‘ ‘, ‘c’, ‘a’, ‘i’, ‘th’]
    print(len(vocab))
    8
    tokens = tokenize(corpus, vocab))
    print(tokens)
    [7, 2, 3, 4, 5, 0, 3, 6, 8, 3, 7, 2, 3, 2, 5, 0]
    print(“Tokenized length: {}”.format(len(tokens)))
    Tokenized length: 16

The length of the representation does not change but we can tell that it is lossy just from the vocabulary, therefore the compression is not lossless.

    print(detokenize(tokens, vocab))
    [‘the cat i[unk] the hat’]

This example makes it easy to tell the compression is lossy because our vocabulary is small and made of suboptimally combined tokens. We can go further with the combination of the vocabulary and combine ‘t’, ‘h’, ‘e’, and ‘ ‘ to form a single token covering all instances of “the “. Since ‘e’ doesn’t occur outside of its place in ‘the’ we can delete it from the vocabulary list and still maintain the same level of loss in compression, ditto ‘i’ and ‘n’.

    vocab = [‘t’, ‘h’, ‘the  ‘, ‘ ‘, ‘c’, ‘a’, ‘in’]
    print(len(vocab))
    7
    tokens = tokenize(corpus, vocab)
    print(tokens)
    [2, 4, 5, 0, 3, 6, 3, 2, 1, 5, 0]
    print(len(tokens)
    11

Thus far this is the most optimally compressed form of the sentence (though I don’t claim for it to be the most optimally compressed) and it has the smallest vocabulary size, making it easier for a model to guess the next token. In all of these examples we have been able to tell unambiguously whether or not the compression is lossless just by eyeballing it.

However, there is more than one way to tokenize a sentence. If our tokenizer sees the ‘t’ and ‘h’ without the context of the ‘e ‘, it will run into a problem: \*\*there is no ‘e’ in our vocabulary list\*\* and, if not properly trained, it will be forced to replace that ‘e’ with an ‘\[unk\]’ token, making it lossy while also expanding the length of its representation significantly.

Therefore, even though we have just proven lossless compression is possible given this corpus and the last vocabulary list, if the recognition of the sequence by the tokenizer is poor, it won’t be capable of losslessly tokenizing even though the vocabulary list is suited for it. As corpus size increases, it becomes harder and harder to tell just by looking that the vocabulary list can losslessly reconstruct the corpus.

With something like SentencePiece, which defaults to a vocabulary size in the thousands, trying to reconstruct the Wiki-sentences corpus, which is millions and millions of sentences long, it becomes untenable to pore over every output vocabulary size and manually check if it can reconstruct the corpus.

Thus my question: given a vocabulary list and a corpus, is there an automatic way to tell that that it is \*possible\* to reconstruct the given corpus losslessly using the given vocabulary assuming a well trained tokenizer? In other words is there a function to determine if lossless tokenization is possible which returns true or false given an input corpus and vocabulary?",https://www.reddit.com/r/LanguageTechnology/comments/lzer14/is_it_possible_to_test_whether_a_tokenizer_can/,LanguageTechnology,t3_lzer14,"Is it possible to test whether a tokenizer can losslessly tokenize and detokenize a given corpus solely from its vocabulary? I am trying to test whether a given vocabulary list contains the tokens necessary to reconstruct a corpus of text losslessly. That is, if a tokenizer trained on a corpus of text were to attempt to tokenize the training corpus according to its associated vocabulary, would it be able to tokenize and detokenize the entire training corpus without losing any text to \[unk\] tokens? Are there ways to test this?

Suppose you had a corpus of text - I’ll use a small one for this example

    corpus = ‘the cat in the hat’

Suppose you had a trained tokenizer which tokenizes according to its vocab list where each token id is simply the index of the token in the list.

    vocab = [‘t’, ‘h’, ‘e’, ‘ ‘, ‘c’, ‘a’, ‘i’, ‘n’]
    print(len(vocab))
    8
    tokens = tokenize(corpus, vocab))
    print(tokens)
    [0, 1, 2, 3, 4, 5, 0, 3, 6, 7, 3, 0, 1, 2, 3, 2, 5, 0]
    print(“Tokenized length: {}”.format(len(tokens)))
    Tokenized length: 18

If I then detokenize from here I can obviously reconstruct the corpus as it originally was. However, this process is suboptimal as we can combine tokens to reduce the length of the tokenized representation.

    vocab = [‘t’, ‘h’, ‘e’, ‘ ‘, ‘c’, ‘a’, ‘i’, ‘n’, ‘th’]
    print(len(vocab))
    9
    tokens = tokenize(corpus, vocab))
    print(tokens)
    [8, 2, 3, 4, 5, 0, 3, 6, 7, 3, 8, 2, 3, 2, 5, 0]
    print(“Tokenized length: {}”.format(len(tokens)))
    Tokenized length: 16

This is obviously still lossless, though it adds an extra token to the vocabulary list, which will increase the possibility space of a model trying to predict the next token in a sequence. But if I remove a necessary token, it becomes lossy. Supppose our tokenizer outputs ‘\[unk\]’ for all tokens not in the vocabulary and that the ‘\[unk\]’ token is always the last token in the vocabulary regardless of the content of the vocabulary.

    vocab = [‘t’, ‘h’, ‘e’, ‘ ‘, ‘c’, ‘a’, ‘i’, ‘th’]
    print(len(vocab))
    8
    tokens = tokenize(corpus, vocab))
    print(tokens)
    [7, 2, 3, 4, 5, 0, 3, 6, 8, 3, 7, 2, 3, 2, 5, 0]
    print(“Tokenized length: {}”.format(len(tokens)))
    Tokenized length: 16

The length of the representation does not change but we can tell that it is lossy just from the vocabulary, therefore the compression is not lossless.

    print(detokenize(tokens, vocab))
    [‘the cat i[unk] the hat’]

This example makes it easy to tell the compression is lossy because our vocabulary is small and made of suboptimally combined tokens. We can go further with the combination of the vocabulary and combine ‘t’, ‘h’, ‘e’, and ‘ ‘ to form a single token covering all instances of “the “. Since ‘e’ doesn’t occur outside of its place in ‘the’ we can delete it from the vocabulary list and still maintain the same level of loss in compression, ditto ‘i’ and ‘n’.

    vocab = [‘t’, ‘h’, ‘the  ‘, ‘ ‘, ‘c’, ‘a’, ‘in’]
    print(len(vocab))
    7
    tokens = tokenize(corpus, vocab)
    print(tokens)
    [2, 4, 5, 0, 3, 6, 3, 2, 1, 5, 0]
    print(len(tokens)
    11

Thus far this is the most optimally compressed form of the sentence (though I don’t claim for it to be the most optimally compressed) and it has the smallest vocabulary size, making it easier for a model to guess the next token. In all of these examples we have been able to tell unambiguously whether or not the compression is lossless just by eyeballing it.

However, there is more than one way to tokenize a sentence. If our tokenizer sees the ‘t’ and ‘h’ without the context of the ‘e ‘, it will run into a problem: \*\*there is no ‘e’ in our vocabulary list\*\* and, if not properly trained, it will be forced to replace that ‘e’ with an ‘\[unk\]’ token, making it lossy while also expanding the length of its representation significantly.

Therefore, even though we have just proven lossless compression is possible given this corpus and the last vocabulary list, if the recognition of the sequence by the tokenizer is poor, it won’t be capable of losslessly tokenizing even though the vocabulary list is suited for it. As corpus size increases, it becomes harder and harder to tell just by looking that the vocabulary list can losslessly reconstruct the corpus.

With something like SentencePiece, which defaults to a vocabulary size in the thousands, trying to reconstruct the Wiki-sentences corpus, which is millions and millions of sentences long, it becomes untenable to pore over every output vocabulary size and manually check if it can reconstruct the corpus.

Thus my question: given a vocabulary list and a corpus, is there an automatic way to tell that that it is \*possible\* to reconstruct the given corpus losslessly using the given vocabulary assuming a well trained tokenizer? In other words is there a function to determine if lossless tokenization is possible which returns true or false given an input corpus and vocabulary?",4991
593,593,Linguistic resources?,"Hi all. I'm looking for resources that computer science students can use to learn more about linguistics. As my professor likes to put it, we're good at the P part of NLP but aren't the best at the NL part. Any help is greatly appreciated!",https://www.reddit.com/r/LanguageTechnology/comments/lyw5v9/linguistic_resources/,LanguageTechnology,t3_lyw5v9,"Linguistic resources? Hi all. I'm looking for resources that computer science students can use to learn more about linguistics. As my professor likes to put it, we're good at the P part of NLP but aren't the best at the NL part. Any help is greatly appreciated!",261
594,594,Looking for En-Zh bilingual medical corpora,"Hi everyone 

I am building an MT engine and looking for En-Zh bilingual medical corpora to download. If anyone can share it here with me will be much appreciated!",https://www.reddit.com/r/LanguageTechnology/comments/lz0gqq/looking_for_enzh_bilingual_medical_corpora/,LanguageTechnology,t3_lz0gqq,"Looking for En-Zh bilingual medical corpora Hi everyone 

I am building an MT engine and looking for En-Zh bilingual medical corpora to download. If anyone can share it here with me will be much appreciated!",207
595,595,"How NLP might revolutionize scholarship, collaboration, and reasoning.","The most recent episode of the [Futurati Podcast](https://www.youtube.com/channel/UCRSov16ZLE2UgekgBTgnrjw/videos) is a big one. [We had Jungwon Byun and Andreas Stuhlmüller on](https://www.youtube.com/watch?v=Lef5q1xPTU0) to talk about their startup ['Ought'](https://ought.org/) and, to the best of my knowledge, this is the first public, long-form discussion of their work around.

(It's also probably our funniest episode.)

Their ambition is to wrap a sleek GUI around advanced language models to build a platform which could transform scholarship, education, research, and almost every other place people think about stuff.

The process is powered by GPT-3, and mostly boils down to teaching it how to do something you want it to do by showing it a couple of examples. To complete a list of potential essay topics you'd just show it 3-4 essay topics, and it'd respond by showing you a few more.

The more you interact with it, the better it gets.

There's all sorts of subtlety and detail, but that's the essence of it.

This may not sound all that impressive, but consider what it means. You can have Elicit (a separate spinoff of Ought) generate counterarguments to your position, brainstorm failure modes (and potential solutions) to a course of action, summarize papers, and rephrase a statement as a question or in a more emotionally positive tone.

The team is working on some integrations to extend these capabilities. Soon enough, Elicit will be able to connect to databases of published scientific papers, newspapers, blogs, or audio transcripts. When you ask it a research question, it'll be able to link out to millions of documents and offer high-level overviews of every major theme; it'll be able to test your comprehensions by asking you questions as you read; it'll be able to assemble concept hierarchies; it'll be able to extract all the figures from scientific papers and summarize them; it'll be able to extract all the proper names, find where those people are located, get their email addresses where available, and write them messages inviting them on your podcast.

We might one day be able to train a model on Einstein or Feynman and create lectures in their style.

What's more, people can share workflows they've developed. If I work out a good approach to learning about the subdisciplines of a field, for example, I can make that available to anyone to save them the effort of discovering it on their own.

There will be algorithms of thought that can make detailed, otherwise inaccessible aspects of other people's cognitive processes available.

And this is just researchers. It could help teachers dynamically adjust material on the basis of up-to-the-minute assessments of student performance. It could handle rudimentary aspects of therapy. It could help people retrain if they've been displaced by automation. It could summarize case law. It could help develop language skills in children.

I don't know if the future will look the way we hope it will, but I do think something like this could power huge parts of the knowledge work economy in the future, making everyone dramatically more productive.

It's tremendously exciting, and I'm honored to have been able to learn about it directly.",https://www.reddit.com/r/LanguageTechnology/comments/lyhs6j/how_nlp_might_revolutionize_scholarship/,LanguageTechnology,t3_lyhs6j,"How NLP might revolutionize scholarship, collaboration, and reasoning. The most recent episode of the [Futurati Podcast](https://www.youtube.com/channel/UCRSov16ZLE2UgekgBTgnrjw/videos) is a big one. [We had Jungwon Byun and Andreas Stuhlmüller on](https://www.youtube.com/watch?v=Lef5q1xPTU0) to talk about their startup ['Ought'](https://ought.org/) and, to the best of my knowledge, this is the first public, long-form discussion of their work around.

(It's also probably our funniest episode.)

Their ambition is to wrap a sleek GUI around advanced language models to build a platform which could transform scholarship, education, research, and almost every other place people think about stuff.

The process is powered by GPT-3, and mostly boils down to teaching it how to do something you want it to do by showing it a couple of examples. To complete a list of potential essay topics you'd just show it 3-4 essay topics, and it'd respond by showing you a few more.

The more you interact with it, the better it gets.

There's all sorts of subtlety and detail, but that's the essence of it.

This may not sound all that impressive, but consider what it means. You can have Elicit (a separate spinoff of Ought) generate counterarguments to your position, brainstorm failure modes (and potential solutions) to a course of action, summarize papers, and rephrase a statement as a question or in a more emotionally positive tone.

The team is working on some integrations to extend these capabilities. Soon enough, Elicit will be able to connect to databases of published scientific papers, newspapers, blogs, or audio transcripts. When you ask it a research question, it'll be able to link out to millions of documents and offer high-level overviews of every major theme; it'll be able to test your comprehensions by asking you questions as you read; it'll be able to assemble concept hierarchies; it'll be able to extract all the figures from scientific papers and summarize them; it'll be able to extract all the proper names, find where those people are located, get their email addresses where available, and write them messages inviting them on your podcast.

We might one day be able to train a model on Einstein or Feynman and create lectures in their style.

What's more, people can share workflows they've developed. If I work out a good approach to learning about the subdisciplines of a field, for example, I can make that available to anyone to save them the effort of discovering it on their own.

There will be algorithms of thought that can make detailed, otherwise inaccessible aspects of other people's cognitive processes available.

And this is just researchers. It could help teachers dynamically adjust material on the basis of up-to-the-minute assessments of student performance. It could handle rudimentary aspects of therapy. It could help people retrain if they've been displaced by automation. It could summarize case law. It could help develop language skills in children.

I don't know if the future will look the way we hope it will, but I do think something like this could power huge parts of the knowledge work economy in the future, making everyone dramatically more productive.

It's tremendously exciting, and I'm honored to have been able to learn about it directly.",3304
596,596,NLP Cloud now serves transformers-based models,"We just released several important additions to the NLP Cloud API.

Many users were asking us for transformers-based models in addition to our existing spaCy models. So here we go, NLP Cloud now serves some of the best transformers-based models with PyTorch from [Hugging Face](https://huggingface.co/models):

* Facebook's Bart Large MNLI model, for **text classification**     
* Facebook's Bart Large CNN model, for **text summarization** 
* Deepset's Roberta Base Squad 2 model, for **question answering**
* DistilBERT Base Uncased Finetuned SST-2 English model, for **sentiment analysis**

Of  course our spaCy models are still available for Named Entity Recognition and POS tagging. And you can even upload your own spaCy  models. Important change: from now on, all the **large** spaCy models will be available for free.

All our models are available **for free** for a limited amount of requests per minute, and pricing for paid plans is very fair.

Hope you will like it, and can't wait for your feedbacks and suggestions!

Website: [https://nlpcloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=3ec10c28-ab0d-11eb-bcbc-0242ac130002)

Documentation: [https://docs.nlpcloud.io](https://nlpcloud.io)",https://www.reddit.com/r/LanguageTechnology/comments/lya2zi/nlp_cloud_now_serves_transformersbased_models/,LanguageTechnology,t3_lya2zi,"NLP Cloud now serves transformers-based models We just released several important additions to the NLP Cloud API.

Many users were asking us for transformers-based models in addition to our existing spaCy models. So here we go, NLP Cloud now serves some of the best transformers-based models with PyTorch from [Hugging Face](https://huggingface.co/models):

* Facebook's Bart Large MNLI model, for **text classification**     
* Facebook's Bart Large CNN model, for **text summarization** 
* Deepset's Roberta Base Squad 2 model, for **question answering**
* DistilBERT Base Uncased Finetuned SST-2 English model, for **sentiment analysis**

Of  course our spaCy models are still available for Named Entity Recognition and POS tagging. And you can even upload your own spaCy  models. Important change: from now on, all the **large** spaCy models will be available for free.

All our models are available **for free** for a limited amount of requests per minute, and pricing for paid plans is very fair.

Hope you will like it, and can't wait for your feedbacks and suggestions!

Website: [https://nlpcloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=3ec10c28-ab0d-11eb-bcbc-0242ac130002)

Documentation: [https://docs.nlpcloud.io](https://nlpcloud.io)",1267
597,597,Help with tf-idf for job description extraction,"Hi, this isn't really a question asking for help with code syntax, more so on the general theory / workflow side of things. 

I'm doing a small Python project where I'm trying to extract relevant job 'requirements' from UX Researcher job listings on Google. I've scraped a load of jobs, cleaned them using NLTK, Spacy etc and I have saved each job description as a text file respectively. I also made one large text file corpus with all the cleaned job descriptions in. 

I've heard that tf-idf is a good way to go about extracting just the employers' desired 'requirements' from these job descriptions (i.e., 'PhD in Psychology' or 'Agile and Scrum experience'). 

My problem however is i'm not sure in what format to load the documents in to process using tf-idf. Should I load in all of the documents which each contain one job description, or use the one text file which has all of the documents in itself? My thinking is I need to load each individual document given that tf-idf uses document frequency right? Any help would be appreciated, thanks!",https://www.reddit.com/r/LanguageTechnology/comments/lyml6j/help_with_tfidf_for_job_description_extraction/,LanguageTechnology,t3_lyml6j,"Help with tf-idf for job description extraction Hi, this isn't really a question asking for help with code syntax, more so on the general theory / workflow side of things. 

I'm doing a small Python project where I'm trying to extract relevant job 'requirements' from UX Researcher job listings on Google. I've scraped a load of jobs, cleaned them using NLTK, Spacy etc and I have saved each job description as a text file respectively. I also made one large text file corpus with all the cleaned job descriptions in. 

I've heard that tf-idf is a good way to go about extracting just the employers' desired 'requirements' from these job descriptions (i.e., 'PhD in Psychology' or 'Agile and Scrum experience'). 

My problem however is i'm not sure in what format to load the documents in to process using tf-idf. Should I load in all of the documents which each contain one job description, or use the one text file which has all of the documents in itself? My thinking is I need to load each individual document given that tf-idf uses document frequency right? Any help would be appreciated, thanks!",1101
598,598,NLP - Summarization - SeekingAlpha - interesting observation,"Hello guys.

I am trying to summarize (compare approaches) articles at seekingalpha. To compare various approaches I've created oracle summaries (5 sentences) using greedy algorithm as described in [Bertsumm](https://arxiv.org/pdf/1903.10318.pdf) . As an input to create oracle summaries I have used the author conclusion (can be seen here in section [Conclusion Thoughts and Outlook](https://seekingalpha.com/article/4411395-project-1m-higher-yields-bite-in-february)). 

Fully excited I have jumped into trying novel approaches and I have used for example [PreSumm](https://github.com/nlpyang/PreSumm) (BertSumExt). The problem is that the articles are much longer than PreSumm can process. I solved this problem by dividing the article into blocks of length of 512 tokens, then summarized each block by itself and merged the blocks together. I repeated this process until the final output was between 100 - 200 subword tokens. Allright, it works but...

Then I have tried [TextRank](https://radimrehurek.com/gensim_3.8.3/summarization/summariser.html) that has no length constraints. I selected the ratio of the output to be in the length of 5 sentences which is usually between 100 - 200 subword tokens. 

Finally I have compared the outputs using ROUGE F R1,R2 and RL score and to my suprise the TextRank yielded the score aroung 50 at R1 and RL, and around 39 at R2. On the other hand the PreSumm (or [facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)) showed score only around 23 at R1 or 14 at R2.

I have also tried to implement trigram blocking for TextRank which havent significanlty lowered the results.

Do you have any suggestions why the current models compared to TextRank perform so much worse? Might it be because of the ""block by block summarization""? I have also tried to find out if creating oracle summaries as described in Bertsumm favors graph based summarization algorithms but I was not able to come up with any reasonable conclusion (yes or not). Do you guys have any hints what I can improve (besides training new model) when using huge language models to summarize longer inputs? Or is it normal that the current approaches fails at longer inputs (at least in my case using above mentioned approach)

Thanks for your suggestions :-)",https://www.reddit.com/r/LanguageTechnology/comments/lyf161/nlp_summarization_seekingalpha_interesting/,LanguageTechnology,t3_lyf161,"NLP - Summarization - SeekingAlpha - interesting observation Hello guys.

I am trying to summarize (compare approaches) articles at seekingalpha. To compare various approaches I've created oracle summaries (5 sentences) using greedy algorithm as described in [Bertsumm](https://arxiv.org/pdf/1903.10318.pdf) . As an input to create oracle summaries I have used the author conclusion (can be seen here in section [Conclusion Thoughts and Outlook](https://seekingalpha.com/article/4411395-project-1m-higher-yields-bite-in-february)). 

Fully excited I have jumped into trying novel approaches and I have used for example [PreSumm](https://github.com/nlpyang/PreSumm) (BertSumExt). The problem is that the articles are much longer than PreSumm can process. I solved this problem by dividing the article into blocks of length of 512 tokens, then summarized each block by itself and merged the blocks together. I repeated this process until the final output was between 100 - 200 subword tokens. Allright, it works but...

Then I have tried [TextRank](https://radimrehurek.com/gensim_3.8.3/summarization/summariser.html) that has no length constraints. I selected the ratio of the output to be in the length of 5 sentences which is usually between 100 - 200 subword tokens. 

Finally I have compared the outputs using ROUGE F R1,R2 and RL score and to my suprise the TextRank yielded the score aroung 50 at R1 and RL, and around 39 at R2. On the other hand the PreSumm (or [facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)) showed score only around 23 at R1 or 14 at R2.

I have also tried to implement trigram blocking for TextRank which havent significanlty lowered the results.

Do you have any suggestions why the current models compared to TextRank perform so much worse? Might it be because of the ""block by block summarization""? I have also tried to find out if creating oracle summaries as described in Bertsumm favors graph based summarization algorithms but I was not able to come up with any reasonable conclusion (yes or not). Do you guys have any hints what I can improve (besides training new model) when using huge language models to summarize longer inputs? Or is it normal that the current approaches fails at longer inputs (at least in my case using above mentioned approach)

Thanks for your suggestions :-)",2345
599,599,Dialogflow CX - Issues with Enabling Voice Input,"Hello,

I am trying to test my Dialogflow CX agent with voice, but I am having difficulties understanding where to start. I followed the instructions on this github page:

[https://github.com/googleapis/python-dialogflow-cx](https://github.com/googleapis/python-dialogflow-cx)

But when I try to run my python script to test my voice file, it gives me an error.

    grpc._channel._MultiThreadedRendezvous: &lt;_MultiThreadedRendezvous of RPC that terminated with: 
    status = StatusCode.UNKNOWN 
    details = ""Exception iterating requests!"" 
    debug_error_string = ""None""

I've also tried following the instructions on this page which gives me a script similarly to the one related to the github:

[https://cloud.google.com/dialogflow/cx/docs/how/detect-intent-stream](https://cloud.google.com/dialogflow/cx/docs/how/detect-intent-stream)

Has anyone successfully worked with Dialogflow and if so, what steps did you take to enable voice input?

I need to make a demonstration and I decided to use the ES agent, but also having difficulties with it recognizing what I want to say. When I say ""Hello LuPal"", it'll give me a response of ""Hello loophole"" (??). Thank you for your response, I'd really appreciate any suggestions!",https://www.reddit.com/r/LanguageTechnology/comments/lyo4qi/dialogflow_cx_issues_with_enabling_voice_input/,LanguageTechnology,t3_lyo4qi,"Dialogflow CX - Issues with Enabling Voice Input Hello,

I am trying to test my Dialogflow CX agent with voice, but I am having difficulties understanding where to start. I followed the instructions on this github page:

[https://github.com/googleapis/python-dialogflow-cx](https://github.com/googleapis/python-dialogflow-cx)

But when I try to run my python script to test my voice file, it gives me an error.

    grpc._channel._MultiThreadedRendezvous: &lt;_MultiThreadedRendezvous of RPC that terminated with: 
    status = StatusCode.UNKNOWN 
    details = ""Exception iterating requests!"" 
    debug_error_string = ""None""

I've also tried following the instructions on this page which gives me a script similarly to the one related to the github:

[https://cloud.google.com/dialogflow/cx/docs/how/detect-intent-stream](https://cloud.google.com/dialogflow/cx/docs/how/detect-intent-stream)

Has anyone successfully worked with Dialogflow and if so, what steps did you take to enable voice input?

I need to make a demonstration and I decided to use the ES agent, but also having difficulties with it recognizing what I want to say. When I say ""Hello LuPal"", it'll give me a response of ""Hello loophole"" (??). Thank you for your response, I'd really appreciate any suggestions!",1280
600,600,Hosting PDF for public view: how to make it as much OCR-friendly as possible?,"Hello!

&amp;#x200B;

 My company is going to make available many PDF files for the public.

&amp;#x200B;

 Which settings/encoding should I recommend them to use in order for the software to be as much OCR-friendly as possible? For example, saving a MS Word file in PDF instead of scanning a printed image. (but that's a non-technical example)",https://www.reddit.com/r/LanguageTechnology/comments/lyg9e9/hosting_pdf_for_public_view_how_to_make_it_as/,LanguageTechnology,t3_lyg9e9,"Hosting PDF for public view: how to make it as much OCR-friendly as possible? Hello!

&amp;#x200B;

 My company is going to make available many PDF files for the public.

&amp;#x200B;

 Which settings/encoding should I recommend them to use in order for the software to be as much OCR-friendly as possible? For example, saving a MS Word file in PDF instead of scanning a printed image. (but that's a non-technical example)",422
601,601,How does event extraction differ from information extraction/ retrieval?,"Based on some additional research I am revising a question I asked yesterday. So new question, how does event extraction differ from information extraction? Could I use information extraction type code to accomplish event extraction from a written corpus? Any help would be much appreciated!",https://www.reddit.com/r/LanguageTechnology/comments/lydxyz/how_does_event_extraction_differ_from_information/,LanguageTechnology,t3_lydxyz,"How does event extraction differ from information extraction/ retrieval? Based on some additional research I am revising a question I asked yesterday. So new question, how does event extraction differ from information extraction? Could I use information extraction type code to accomplish event extraction from a written corpus? Any help would be much appreciated!",364
602,602,Is rule-based NLP officially dead?,"Machine learning i taking over everything, including training text, speech, and language prediction models to do what they need to do. What's the need for rules in the NLP space anymore? Rules are for non-technical linguists and grammar writers, us NLP people are long past that and are doing it all with ML and neural nets.

Rule-based NLP is dead. Am I wrong? Prove me wrong, please. What USE is there for rule-based models in this field when we have machine learning models trained on mountains of meticulously-labeled data? Maybe if you didn't have any annotated labeled data, you might want to use rules in a pinch, but that's all ad hoc bullshit that will have to keep building up more and more as you find more and more things you didn't think of that will force you to make new rules. With ML all of those little things you don't think of are picked up in training so it knows how to deal with them right off the bat.",https://www.reddit.com/r/LanguageTechnology/comments/ly68xm/is_rulebased_nlp_officially_dead/,LanguageTechnology,t3_ly68xm,"Is rule-based NLP officially dead? Machine learning i taking over everything, including training text, speech, and language prediction models to do what they need to do. What's the need for rules in the NLP space anymore? Rules are for non-technical linguists and grammar writers, us NLP people are long past that and are doing it all with ML and neural nets.

Rule-based NLP is dead. Am I wrong? Prove me wrong, please. What USE is there for rule-based models in this field when we have machine learning models trained on mountains of meticulously-labeled data? Maybe if you didn't have any annotated labeled data, you might want to use rules in a pinch, but that's all ad hoc bullshit that will have to keep building up more and more as you find more and more things you didn't think of that will force you to make new rules. With ML all of those little things you don't think of are picked up in training so it knows how to deal with them right off the bat.",960
603,603,Visualizing the Distribution of Several $Billions of #NGO Grants through Natural Language Processing (Case Study),"I thought this could be of interest. A team of 40+ changemakers built an NLP analysis pipeline for feature extraction, scraping Twitter, Google, and 1200 PDF files through automated APIs.   


https://omdena.com/blog/nlp-analysis/",https://www.reddit.com/r/LanguageTechnology/comments/lyczme/visualizing_the_distribution_of_several_billions/,LanguageTechnology,t3_lyczme,"Visualizing the Distribution of Several $Billions of #NGO Grants through Natural Language Processing (Case Study) I thought this could be of interest. A team of 40+ changemakers built an NLP analysis pipeline for feature extraction, scraping Twitter, Google, and 1200 PDF files through automated APIs.   


https://omdena.com/blog/nlp-analysis/",344
604,604,How long did it take to get access to gpt3?,I heard it takes around a month. I haven't heard back in 6 months.,https://www.reddit.com/r/LanguageTechnology/comments/lyalog/how_long_did_it_take_to_get_access_to_gpt3/,LanguageTechnology,t3_lyalog,How long did it take to get access to gpt3? I heard it takes around a month. I haven't heard back in 6 months.,110
605,605,How does event extraction differ from topic modeling?,"Can anyone explain how event extraction coding techniques differ from topic modeling? A lot of the code examples I’ve looked at seem to be using topic modeling then organizing discerned topics by date. Is there more to event extraction than that? I assume there is. I feel like I must be missing something and I hope someone here has some insight. Also, if anyone has any materials regarding event extraction that are helpful I would love to hear about them. Thanks all!",https://www.reddit.com/r/LanguageTechnology/comments/lxsgio/how_does_event_extraction_differ_from_topic/,LanguageTechnology,t3_lxsgio,"How does event extraction differ from topic modeling? Can anyone explain how event extraction coding techniques differ from topic modeling? A lot of the code examples I’ve looked at seem to be using topic modeling then organizing discerned topics by date. Is there more to event extraction than that? I assume there is. I feel like I must be missing something and I hope someone here has some insight. Also, if anyone has any materials regarding event extraction that are helpful I would love to hear about them. Thanks all!",524
606,606,Attention over Ground-Truth Image Caption?,"I'm a bit of a newbie when it comes to image captioning and was wondering if it would make sense to feed an image and a *ground-truth* *caption* to a pre-trained image-captioning model and visualize the attention scores over the image for every word? I.e. in order to see how much the model *would have had* to rely on the image features as opposed to the language model in order to generate such a caption?  If so, does anyone have experience implementing this or could point me to a repo that does?",https://www.reddit.com/r/LanguageTechnology/comments/lxldzm/attention_over_groundtruth_image_caption/,LanguageTechnology,t3_lxldzm,"Attention over Ground-Truth Image Caption? I'm a bit of a newbie when it comes to image captioning and was wondering if it would make sense to feed an image and a *ground-truth* *caption* to a pre-trained image-captioning model and visualize the attention scores over the image for every word? I.e. in order to see how much the model *would have had* to rely on the image features as opposed to the language model in order to generate such a caption?  If so, does anyone have experience implementing this or could point me to a repo that does?",543
607,607,King -Man +Woman = King ?,,https://blog.esciencecenter.nl/king-man-woman-king-9a7fd2935a85,LanguageTechnology,t3_lxu1ct,King -Man +Woman = King ? ,26
608,608,How to best determine changing news event coverage— semantic similarity or no?,I am looking to figure out a way to show how news events unfold over time : ie how early articles described an event like the us capitol riot versus what they say now. I’m guessing semantic similarity is the best way to achieve this? Does anyone have other/ better ideas? I’m fairly new to nlp and appreciate any help anyone can provide. I have gotten great help from this subreddit in the past.,https://www.reddit.com/r/LanguageTechnology/comments/lxtrsz/how_to_best_determine_changing_news_event/,LanguageTechnology,t3_lxtrsz,How to best determine changing news event coverage— semantic similarity or no? I am looking to figure out a way to show how news events unfold over time : ie how early articles described an event like the us capitol riot versus what they say now. I’m guessing semantic similarity is the best way to achieve this? Does anyone have other/ better ideas? I’m fairly new to nlp and appreciate any help anyone can provide. I have gotten great help from this subreddit in the past.,474
609,609,Tutorial on how to perform a Shapiro-Wilk normality test,"Hey, I've created a tutorial on how to perform a Shapiro-Wilk normality test in the R programming language: [https://statisticsglobe.com/shapiro-wilk-normality-test-in-r](https://statisticsglobe.com/shapiro-wilk-normality-test-in-r)",https://www.reddit.com/r/LanguageTechnology/comments/lxgx5l/tutorial_on_how_to_perform_a_shapirowilk/,LanguageTechnology,t3_lxgx5l,"Tutorial on how to perform a Shapiro-Wilk normality test Hey, I've created a tutorial on how to perform a Shapiro-Wilk normality test in the R programming language: [https://statisticsglobe.com/shapiro-wilk-normality-test-in-r](https://statisticsglobe.com/shapiro-wilk-normality-test-in-r)",289
610,610,"Using bag or words, bigrams and tf-idf together","I’m trying to build a model that will decide if a review is positive or negative. I’d like to use the above methods but am unsure if they can all be used together. I think my order of operations would be clean data(case, punctuation, stop words etc) then get bigrams, as a bag of bigrams instead of just words? And then get the tf-idf scores for these bigrams. Use those scores with with something like naive bayes classifier to make my predictions? Is this doable? Or Will I mangle some methods that aren’t really meant to be used together?",https://www.reddit.com/r/LanguageTechnology/comments/lx47ms/using_bag_or_words_bigrams_and_tfidf_together/,LanguageTechnology,t3_lx47ms,"Using bag or words, bigrams and tf-idf together I’m trying to build a model that will decide if a review is positive or negative. I’d like to use the above methods but am unsure if they can all be used together. I think my order of operations would be clean data(case, punctuation, stop words etc) then get bigrams, as a bag of bigrams instead of just words? And then get the tf-idf scores for these bigrams. Use those scores with with something like naive bayes classifier to make my predictions? Is this doable? Or Will I mangle some methods that aren’t really meant to be used together?",589
611,611,Combining BERT with Static Word Embedding for Categorizing Social Media | Research Paper Walkthrough,,https://youtu.be/VqlA_ALWQdM,LanguageTechnology,t3_lwzppi,Combining BERT with Static Word Embedding for Categorizing Social Media | Research Paper Walkthrough ,101
612,612,"""All terrorists are [MASK]"": Self-Diagnosis and Self-Debiasing for Pretrained Language Models","We recently wrote a paper that investigates whether pretrained language models can use their internal knowledge to detect🩺 and discard🩹 undesired behaviors and reduce biases in their own outputs: [https://arxiv.org/abs/2103.00453](https://arxiv.org/abs/2103.00453)

This is still a very early draft. We plan to extend the paper along several axes and to conduct extensive further experiments, so I'd be happy to hear your thoughts 😊",https://www.reddit.com/r/LanguageTechnology/comments/lwqxqd/all_terrorists_are_mask_selfdiagnosis_and/,LanguageTechnology,t3_lwqxqd,"""All terrorists are [MASK]"": Self-Diagnosis and Self-Debiasing for Pretrained Language Models We recently wrote a paper that investigates whether pretrained language models can use their internal knowledge to detect🩺 and discard🩹 undesired behaviors and reduce biases in their own outputs: [https://arxiv.org/abs/2103.00453](https://arxiv.org/abs/2103.00453)

This is still a very early draft. We plan to extend the paper along several axes and to conduct extensive further experiments, so I'd be happy to hear your thoughts 😊",526
613,613,"For a bag of bigrams, do you tag things positive or negative?","I have two corpora, one with 5k positive review and one with 5k negative reviews. If use a bag of words or bag of bigrams method to do sentiment analysis, should I keep the the corpora separate or do I rage each review in each corpus as pos/neg and merge them?",https://www.reddit.com/r/LanguageTechnology/comments/lxb80e/for_a_bag_of_bigrams_do_you_tag_things_positive/,LanguageTechnology,t3_lxb80e,"For a bag of bigrams, do you tag things positive or negative? I have two corpora, one with 5k positive review and one with 5k negative reviews. If use a bag of words or bag of bigrams method to do sentiment analysis, should I keep the the corpora separate or do I rage each review in each corpus as pos/neg and merge them?",322
614,614,Is LIWC machine learning?,I am reading a paper and it uses the LIWC to estimate risk of certain mental health disorders. I am confused if LIWC is an example of machine learning. Or whether it is part of processing the data to be used in a ML algorithm. Thanks in advance,https://www.reddit.com/r/LanguageTechnology/comments/lx629u/is_liwc_machine_learning/,LanguageTechnology,t3_lx629u,Is LIWC machine learning? I am reading a paper and it uses the LIWC to estimate risk of certain mental health disorders. I am confused if LIWC is an example of machine learning. Or whether it is part of processing the data to be used in a ML algorithm. Thanks in advance,270
615,615,Is a corpus of 5million reviews large or small or midsized for a corpus?,"Like if you were a data scientist working at an actual company Doing nlp, what would your average corpus size be? I’m writing a paper on serializing classifiers and trimming down/preprocessing data but only have exposure to smaller data sets we would use in a class room and was wondering what the typical load would look like. Thank you!",https://www.reddit.com/r/LanguageTechnology/comments/lx33zm/is_a_corpus_of_5million_reviews_large_or_small_or/,LanguageTechnology,t3_lx33zm,"Is a corpus of 5million reviews large or small or midsized for a corpus? Like if you were a data scientist working at an actual company Doing nlp, what would your average corpus size be? I’m writing a paper on serializing classifiers and trimming down/preprocessing data but only have exposure to smaller data sets we would use in a class room and was wondering what the typical load would look like. Thank you!",411
616,616,Best/good practices for evaluating deep learning NER models?,"Hi all, I'm supposed to evaluate a Dutch DL NER model (Huggingface) for a course, and compare it to a rule-based model. I'm feeling a bit lost and don't know where to start. Does anyone have any tips/good practices? What metrics should I use, and are there other evaluation techniques besides metrics? I appreciate all input!",https://www.reddit.com/r/LanguageTechnology/comments/lx6lps/bestgood_practices_for_evaluating_deep_learning/,LanguageTechnology,t3_lx6lps,"Best/good practices for evaluating deep learning NER models? Hi all, I'm supposed to evaluate a Dutch DL NER model (Huggingface) for a course, and compare it to a rule-based model. I'm feeling a bit lost and don't know where to start. Does anyone have any tips/good practices? What metrics should I use, and are there other evaluation techniques besides metrics? I appreciate all input!",386
617,617,Labeling adjective+noun pairs with themes,"I'm a hobbyist with no background in machine learning. Lately, I have been entertaining the idea of creating a very minimalist story prompt generator for use in solo role playing games (the tabletop sort). I want it to generate only an adjective and a noun, such as ""open cage"", ""endless parade"", or ""timely arrival""; so I data-mined some books for adjectives and nouns that are commonly used together. Now my problem is that these pairs that I have extracted cover a wild range of themes, and in most cases are not applicable to the situation the game is in. I at least want to be able to separate them into some general categories like ""objects"", ""events"", ""threats"" etc. I was wondering if I can somehow do this with machine learning. 

Since I don't fully know the capabilities of the current models, I'm not sure about the doability of what I want to do (i.e. labeling two-word strings). So far, I've tried using Logistic Regression with only a single category and 200 datapoints (half belonging to the category, half not). The model was only able to label 2 out of 7 new pairs correctly, not very successful. I haven't tried doing the same with more data, but my gut feeling tells me that what the model is learning is the relatedness of each token in a pair to the category label (this might be an obvious thing, but like I said, I'm a noob). If that is the case, it is not very ideal for me because I have tens of thousands of pairs and I cannot cover each single word related to a specific category by coding a part of the data by hand.  

Is there a good way to tackle this problem? Is it doable? Can you give me some pointers about where to look before I invest tens of hours in a fruitless endeavor?",https://www.reddit.com/r/LanguageTechnology/comments/lx0lfd/labeling_adjectivenoun_pairs_with_themes/,LanguageTechnology,t3_lx0lfd,"Labeling adjective+noun pairs with themes I'm a hobbyist with no background in machine learning. Lately, I have been entertaining the idea of creating a very minimalist story prompt generator for use in solo role playing games (the tabletop sort). I want it to generate only an adjective and a noun, such as ""open cage"", ""endless parade"", or ""timely arrival""; so I data-mined some books for adjectives and nouns that are commonly used together. Now my problem is that these pairs that I have extracted cover a wild range of themes, and in most cases are not applicable to the situation the game is in. I at least want to be able to separate them into some general categories like ""objects"", ""events"", ""threats"" etc. I was wondering if I can somehow do this with machine learning. 

Since I don't fully know the capabilities of the current models, I'm not sure about the doability of what I want to do (i.e. labeling two-word strings). So far, I've tried using Logistic Regression with only a single category and 200 datapoints (half belonging to the category, half not). The model was only able to label 2 out of 7 new pairs correctly, not very successful. I haven't tried doing the same with more data, but my gut feeling tells me that what the model is learning is the relatedness of each token in a pair to the category label (this might be an obvious thing, but like I said, I'm a noob). If that is the case, it is not very ideal for me because I have tens of thousands of pairs and I cannot cover each single word related to a specific category by coding a part of the data by hand.  

Is there a good way to tackle this problem? Is it doable? Can you give me some pointers about where to look before I invest tens of hours in a fruitless endeavor?",1753
618,618,Named Entity Recognition: What's the best way to handle entity labeling for variations in HTML encoding for symbols like trademarks(™) and registered trademarks(®)?,"I'm using Google AI Platform. When importing a JSONL file with various HTML entities, the encoding changes during the import. So for example, a registered name like **Nintendo®** is appearing in my dataset as **NintendoÂ®** and a trademarked name like **Animal Crossing™** is appearing as **Animal Crossingâ¢**.

When it comes to training an accurate model, should I be selecting the longer and stranger encoded version for the label since technically that's all part of the name (encoded differently)? Or am I missing a way to better encode my Google datasets?

**Edit:** More information... I'm uploading it in UTF-8 format and it appears correctly when viewed in Google Cloud Storage but during labeling it's appearing differently (ISO-8859-1 format). I guess my main question is only is it okay to proceed with labeling in this format (since I assume all data coming in will be converted in the same fashion)?",https://www.reddit.com/r/LanguageTechnology/comments/lwz8zb/named_entity_recognition_whats_the_best_way_to/,LanguageTechnology,t3_lwz8zb,"Named Entity Recognition: What's the best way to handle entity labeling for variations in HTML encoding for symbols like trademarks(™) and registered trademarks(®)? I'm using Google AI Platform. When importing a JSONL file with various HTML entities, the encoding changes during the import. So for example, a registered name like **Nintendo®** is appearing in my dataset as **NintendoÂ®** and a trademarked name like **Animal Crossing™** is appearing as **Animal Crossingâ¢**.

When it comes to training an accurate model, should I be selecting the longer and stranger encoded version for the label since technically that's all part of the name (encoded differently)? Or am I missing a way to better encode my Google datasets?

**Edit:** More information... I'm uploading it in UTF-8 format and it appears correctly when viewed in Google Cloud Storage but during labeling it's appearing differently (ISO-8859-1 format). I guess my main question is only is it okay to proceed with labeling in this format (since I assume all data coming in will be converted in the same fashion)?",1079
619,619,Beginner Research Papers to Read,"I've been wanting to spend some time reading through research to gain technical computational linguistics knowledge. Are there any more basic papers I can explore in the realm of research? I'm beginning my CS degree, so my knowledge base is pretty sparse at this point, but I'm exploring topics that interest me like Universal Grammar or Phonology/Prosody.",https://www.reddit.com/r/LanguageTechnology/comments/lwkniu/beginner_research_papers_to_read/,LanguageTechnology,t3_lwkniu,"Beginner Research Papers to Read I've been wanting to spend some time reading through research to gain technical computational linguistics knowledge. Are there any more basic papers I can explore in the realm of research? I'm beginning my CS degree, so my knowledge base is pretty sparse at this point, but I'm exploring topics that interest me like Universal Grammar or Phonology/Prosody.",389
620,620,Best way to do unsupervised long document similarity?,"Do you think it would be splitting it up into sentences and using a BERT to generate a single average doc embedding from which you could calculate cosines distance on, or should it be employing some kind of long document transformer?",https://www.reddit.com/r/LanguageTechnology/comments/lx1e15/best_way_to_do_unsupervised_long_document/,LanguageTechnology,t3_lx1e15,"Best way to do unsupervised long document similarity? Do you think it would be splitting it up into sentences and using a BERT to generate a single average doc embedding from which you could calculate cosines distance on, or should it be employing some kind of long document transformer?",287
621,621,Academic Course Question,"Hello all!

I apologize of this is the wrong place to ask this question, but I am starting a PhD program in ECE next year focusing on SLP. I mainly have experience with NLP and was wondering if different ial equations are useful for Speech? In my final quarter of undergrad I can either take ODE or Multivariate stats and was wondering if I could get some insight on which one may be more useful?

Thank you!",https://www.reddit.com/r/LanguageTechnology/comments/lx15vi/academic_course_question/,LanguageTechnology,t3_lx15vi,"Academic Course Question Hello all!

I apologize of this is the wrong place to ask this question, but I am starting a PhD program in ECE next year focusing on SLP. I mainly have experience with NLP and was wondering if different ial equations are useful for Speech? In my final quarter of undergrad I can either take ODE or Multivariate stats and was wondering if I could get some insight on which one may be more useful?

Thank you!",433
622,622,How to benefit from Q&amp;A dataset,"I have a large db with questions and answers but the problem is that there is no context. So the question is, how can I benefit from this data to train a model? Which type of a model (downstream task) could I train with it? I think I am onto something but can't find out what and how.",https://www.reddit.com/r/LanguageTechnology/comments/lwwunt/how_to_benefit_from_qa_dataset/,LanguageTechnology,t3_lwwunt,"How to benefit from Q&amp;A dataset I have a large db with questions and answers but the problem is that there is no context. So the question is, how can I benefit from this data to train a model? Which type of a model (downstream task) could I train with it? I think I am onto something but can't find out what and how.",320
623,623,Help with dissertation survey - Automatic Quiz Qeneration,"Hey all, 
Hope it’s okay to post link to surveys here.

I’m currently writing my final year dissertation on Automatic Quiz generation  and need data about the quality of the generated questions.

[form](https://forms.gle/TMYcr63HjhVN33P77) 

Thank you for your time!
Any feedback would be appreciated!",https://www.reddit.com/r/LanguageTechnology/comments/lws3fe/help_with_dissertation_survey_automatic_quiz/,LanguageTechnology,t3_lws3fe,"Help with dissertation survey - Automatic Quiz Qeneration Hey all, 
Hope it’s okay to post link to surveys here.

I’m currently writing my final year dissertation on Automatic Quiz generation  and need data about the quality of the generated questions.

[form](https://forms.gle/TMYcr63HjhVN33P77) 

Thank you for your time!
Any feedback would be appreciated!",359
624,624,Why and how to set up a machine-learning pipeline from the home office,"Hello, community! We are running a machine-learning startup with a focus on #LanguageTechnology ([https://reason.al/](https://reason.al/?utm_source=reddit.com&amp;utm_medium=referral&amp;utm_campaign=BL-share-comm-RD-001)) and started to publish very practical and hands-on blog posts on machine-learning and broader coding insights.

Our latest one is on why and how to set up a machine-learning pipeline from home:

[https://reason.al/blog/ml-from-home-1](https://reason.al/blog/ml-from-home-1/?utm_source=linkedin.com&amp;utm_medium=referral&amp;utm_campaign=BL-share-comm-LI-001)

I hope that's of interest for you here, would be great to see you subscribe to the (monthly) newsletter, too!",https://www.reddit.com/r/LanguageTechnology/comments/lwr173/why_and_how_to_set_up_a_machinelearning_pipeline/,LanguageTechnology,t3_lwr173,"Why and how to set up a machine-learning pipeline from the home office Hello, community! We are running a machine-learning startup with a focus on #LanguageTechnology ([https://reason.al/](https://reason.al/?utm_source=reddit.com&amp;utm_medium=referral&amp;utm_campaign=BL-share-comm-RD-001)) and started to publish very practical and hands-on blog posts on machine-learning and broader coding insights.

Our latest one is on why and how to set up a machine-learning pipeline from home:

[https://reason.al/blog/ml-from-home-1](https://reason.al/blog/ml-from-home-1/?utm_source=linkedin.com&amp;utm_medium=referral&amp;utm_campaign=BL-share-comm-LI-001)

I hope that's of interest for you here, would be great to see you subscribe to the (monthly) newsletter, too!",765
625,625,"How are the Q,K &amp; V matrices learned in Self-Attention networks?","Apologies for the super-beginner's level question -- I've tried looking around, and there's not a ton out there. 

I understand at least vaguely what's meant when we talk about what the Queries, Keys, and Values in networks with Self-Attention. What I'm not fully understanding is how these Matrices are learned during training. How does the LM converge on these final Matrices?",https://www.reddit.com/r/LanguageTechnology/comments/lwcriy/how_are_the_qk_v_matrices_learned_in/,LanguageTechnology,t3_lwcriy,"How are the Q,K &amp; V matrices learned in Self-Attention networks? Apologies for the super-beginner's level question -- I've tried looking around, and there's not a ton out there. 

I understand at least vaguely what's meant when we talk about what the Queries, Keys, and Values in networks with Self-Attention. What I'm not fully understanding is how these Matrices are learned during training. How does the LM converge on these final Matrices?",447
626,626,NLU subreddit search app,"Hi all, I just finished my subreddit browser that organizes subs by tags.  It also queries wikipedia for pages for each tag, analyzes those pages with Watson, and color codes them based on the main emotion.  I'm having fun learning relationships between concepts.  Hope you do too.  www.dao.af",https://www.reddit.com/r/LanguageTechnology/comments/lwjv0e/nlu_subreddit_search_app/,LanguageTechnology,t3_lwjv0e,"NLU subreddit search app Hi all, I just finished my subreddit browser that organizes subs by tags.  It also queries wikipedia for pages for each tag, analyzes those pages with Watson, and color codes them based on the main emotion.  I'm having fun learning relationships between concepts.  Hope you do too.  www.dao.af",318
627,627,Does anyone know Chinese version for otter.ai?,,https://www.reddit.com/r/LanguageTechnology/comments/lwjeeh/does_anyone_know_chinese_version_for_otterai/,LanguageTechnology,t3_lwjeeh,Does anyone know Chinese version for otter.ai? ,47
628,628,"Researchers From Stanford, UCI and UC Santa Barbara Conducted a Study to Understand How The mBERT Model Encodes Grammatical Features","Over the past few decades, Deep neural network-based models have been developed to complete a broad range of tasks. Some of them are mainly designed to process and generate coherent texts in multiple languages, answer questions about a text, translate texts, and create summaries of the online content.

Several Deep learning systems are already available with linguistic capabilities, for instance, text analysis tools, in the form of applications for real-time translation, and virtual assistants such as Alexa, Bixby, Siri, Google Assistant, and Cortana. Some of the above systems use a specific deep-learning model called Multilingual BERT (mBERT). mBERT is released by Google and is trained on approximately 100 languages simultaneously. 

Paper summary: [https://www.marktechpost.com/2021/03/01/researchers-from-stanford-uci-and-uc-santa-barbara-conducted-a-study-to-understand-how-the-mbert-model-encodes-grammatical-features/](https://www.marktechpost.com/2021/03/01/researchers-from-stanford-uci-and-uc-santa-barbara-conducted-a-study-to-understand-how-the-mbert-model-encodes-grammatical-features/) 

Paper: [https://arxiv.org/abs/2101.11043](https://arxiv.org/abs/2101.11043) 

Github: [https://github.com/toizzy/deep-subjecthood](https://github.com/toizzy/deep-subjecthood)",https://www.reddit.com/r/LanguageTechnology/comments/lvv25w/researchers_from_stanford_uci_and_uc_santa/,LanguageTechnology,t3_lvv25w,"Researchers From Stanford, UCI and UC Santa Barbara Conducted a Study to Understand How The mBERT Model Encodes Grammatical Features Over the past few decades, Deep neural network-based models have been developed to complete a broad range of tasks. Some of them are mainly designed to process and generate coherent texts in multiple languages, answer questions about a text, translate texts, and create summaries of the online content.

Several Deep learning systems are already available with linguistic capabilities, for instance, text analysis tools, in the form of applications for real-time translation, and virtual assistants such as Alexa, Bixby, Siri, Google Assistant, and Cortana. Some of the above systems use a specific deep-learning model called Multilingual BERT (mBERT). mBERT is released by Google and is trained on approximately 100 languages simultaneously. 

Paper summary: [https://www.marktechpost.com/2021/03/01/researchers-from-stanford-uci-and-uc-santa-barbara-conducted-a-study-to-understand-how-the-mbert-model-encodes-grammatical-features/](https://www.marktechpost.com/2021/03/01/researchers-from-stanford-uci-and-uc-santa-barbara-conducted-a-study-to-understand-how-the-mbert-model-encodes-grammatical-features/) 

Paper: [https://arxiv.org/abs/2101.11043](https://arxiv.org/abs/2101.11043) 

Github: [https://github.com/toizzy/deep-subjecthood](https://github.com/toizzy/deep-subjecthood)",1418
629,629,Conference for Truth and Trust Online Calls for Paper and Talk Proposal Submissions,"Are you working on fact-checking, detection of misinformation, hate speech or other problems related to trust and truth online? You can now **submit a paper or talk proposal to the Truth and Trust Online 2021 (TTO 2021). https://truthandtrustonline.com/call-for-papers-2/**

The annual Conference for Truth and Trust Online is organised as a unique collaboration between practitioners, technologists, academics and platforms, to share, discuss, and collaborate on useful technical innovations and research in the space. This year’s **TTO is virtual and will take place online Oct 7-8 2021.** 

We welcome technical papers of the following types: surveys, methods, reproduction papers, resource papers, case studies. 

**Topics of interest include:**

* Misinformation and disinformation 
* Trustworthiness of COVID-19 news and guidance
* Hate speech
* Online harassment and cyberbullying
* Credibility and fake reviews
* Hyper-partisanship and bias
* Image/video/audio verification
* Fake amplification, polarization, and echo chambers
* Transparency in content and source moderation 
* Privacy and anonymity requirements

We encourage wide participation from all interested parties and stakeholders on online media, including academics, startups and large industry, non-profit organizations and governmental institutions.

**Technical paper submission deadline: July 30, 2021**

**Talk proposal submission deadline: August 13, 2021**

More details can be found: https://truthandtrustonline.com/call-for-papers-2/",https://www.reddit.com/r/LanguageTechnology/comments/lwfp2m/conference_for_truth_and_trust_online_calls_for/,LanguageTechnology,t3_lwfp2m,"Conference for Truth and Trust Online Calls for Paper and Talk Proposal Submissions Are you working on fact-checking, detection of misinformation, hate speech or other problems related to trust and truth online? You can now **submit a paper or talk proposal to the Truth and Trust Online 2021 (TTO 2021). https://truthandtrustonline.com/call-for-papers-2/**

The annual Conference for Truth and Trust Online is organised as a unique collaboration between practitioners, technologists, academics and platforms, to share, discuss, and collaborate on useful technical innovations and research in the space. This year’s **TTO is virtual and will take place online Oct 7-8 2021.** 

We welcome technical papers of the following types: surveys, methods, reproduction papers, resource papers, case studies. 

**Topics of interest include:**

* Misinformation and disinformation 
* Trustworthiness of COVID-19 news and guidance
* Hate speech
* Online harassment and cyberbullying
* Credibility and fake reviews
* Hyper-partisanship and bias
* Image/video/audio verification
* Fake amplification, polarization, and echo chambers
* Transparency in content and source moderation 
* Privacy and anonymity requirements

We encourage wide participation from all interested parties and stakeholders on online media, including academics, startups and large industry, non-profit organizations and governmental institutions.

**Technical paper submission deadline: July 30, 2021**

**Talk proposal submission deadline: August 13, 2021**

More details can be found: https://truthandtrustonline.com/call-for-papers-2/",1597
630,630,NLP course,"Hi,

I've peripherally worked with NLP in the past mainly through my work with Python and machine learning. I'd love to get more in-depth knowledge and so would my company, so much so they've offered to pay for any NLP course I want.

Does anyone have any good recommendations for NLP courses?",https://www.reddit.com/r/LanguageTechnology/comments/lwenyp/nlp_course/,LanguageTechnology,t3_lwenyp,"NLP course Hi,

I've peripherally worked with NLP in the past mainly through my work with Python and machine learning. I'd love to get more in-depth knowledge and so would my company, so much so they've offered to pay for any NLP course I want.

Does anyone have any good recommendations for NLP courses?",304
631,631,Why a YouTube Chat About Chess Got Flagged for Hate Speech,,https://www.wired.com/story/why-youtube-chat-chess-flagged-hate-speech/,LanguageTechnology,t3_lw98tw,Why a YouTube Chat About Chess Got Flagged for Hate Speech ,59
632,632,[D] Annotation tool for entity sentiment analysis,"Hi everyone, we are a marketing company and going to start an annotation project for entity sentiment analysis. Can you please share what are best practices for starting an NLP annotation project? What is most efficient approach? What techniques are mostly used to automate the annotation process?",https://www.reddit.com/r/LanguageTechnology/comments/lw07f5/d_annotation_tool_for_entity_sentiment_analysis/,LanguageTechnology,t3_lw07f5,"[D] Annotation tool for entity sentiment analysis Hi everyone, we are a marketing company and going to start an annotation project for entity sentiment analysis. Can you please share what are best practices for starting an NLP annotation project? What is most efficient approach? What techniques are mostly used to automate the annotation process?",347
633,633,"Paper ""M6: A Chinese Multimodal Pretrainer"". Dataset contains 1900GB of images and 292GB of text. Models contain 10B parameters and 100B (Mixture-of-Experts) parameters. Images shown are text-to-image examples from the paper. Paper link is in a comment.",,https://www.reddit.com/gallery/lvv2mo,LanguageTechnology,t3_lvv7fc,"Paper ""M6: A Chinese Multimodal Pretrainer"". Dataset contains 1900GB of images and 292GB of text. Models contain 10B parameters and 100B (Mixture-of-Experts) parameters. Images shown are text-to-image examples from the paper. Paper link is in a comment. ",254
634,634,Corpus Research Study Advice,,/r/linguistics/comments/lvqp2v/corpus_research_study_advice/,LanguageTechnology,t3_lvvdgi,Corpus Research Study Advice ,29
635,635,"LAMA AI's weekly news, updates, and events.","Hey guys!

This week, LAMA ([https://lamaai.io](https://lamaai.io)) has a couple of updates. Let's start with this weeks AI news!

You can find the video [here](https://www.lamaai.io/posts/ai-360-01-03-2021-unified-transformer-sebastian-ruder-openais-dall-e-glom-and-studiogan), but as for the key highlights:

* [Facebook AI Research](https://ai.facebook.com/) announce a new multi-modal Transformer architecture, [UniT](https://arxiv.org/abs/2102.10772)
* [Sebastian Ruder updates](https://ruder.io/recent-advances-lm-fine-tuning/) us on the latest advances in language model fine-tuning
* [OpenAI](http://openai.com/) have news about DALL-E
* Geoffrey Hinton [proposes an idea paper](https://arxiv.org/abs/2102.12627) he dubs GLOM
* [StudioGAN](https://github.com/POSTECH-CVLab/PyTorch-StudioGAN) is introduced: A PyTorch library for SoTA GAN models

&amp;#x200B;

Would you like to know how we can use Machine Learning to detect COVID symptoms? Imperial College's **Björn Schuller** is going to be presenting  his recent and topical work on detecting COVID symptoms through the use of Computer Audition (think Computer Vision but for audio instead!). As a little introduction, Björn is a Full Professor at the University of Augsburg in Germany, where he is also Chair of Embedded Intelligence for Health Care and Wellbeing. He is also a Professor of Artificial Intelligence at Imperial College London and heads GLAM (Group for Language, Audio and Music). He has over 1000 publications which feature his name (🤯) and his recent research interests focus on audio and multi-modal approaches to emotion detection. Björn will be discussing his paper: [COVID-19 and Computer Audition](https://arxiv.org/abs/2003.11117) which was written during the outbreak last year. In this paper, he overviews the usage of speech and sound analysis by artificial intelligence/machine learning to detect a presence of COVID. If you're interested in attending the talk, register on the eventbrite: [https://www.eventbrite.com/e/bjorn-schuller-lama-ai-covid-19-and-computer-audition-tickets-143203512561](https://www.eventbrite.com/e/bjorn-schuller-lama-ai-covid-19-and-computer-audition-tickets-143203512561)

&amp;#x200B;

Finally, last week we had a paper presentation on the current state of AI's progress towards Natural Language Understanding. You can find the video/talk [here](https://www.lamaai.io/posts/progress-towards-natural-language-understanding)! As for some key points from the talk:

* (Bender and Koller, 2020) discuss the question whether a system exposed only to the form of language in its training data, can in principle learn its meaning
* They underline their arguments with multiple thought experiments and a comparison to human children language acquisition which is grounded in the real world and in interaction with others
* The NLP research community is called to reflect on the current research trends and to take a more top-down approach by asking “whether the hill we are climbing so rapidly is the right hill”
* (Linzen, 2020) discusses common evaluation practices in NLP research and their limitations
* He proposes a new evaluation paradigm which takes into consideration pre-training corpora of different sizes, as well as normative and efficiency attributes while comparing ML models to each other.",https://www.reddit.com/r/LanguageTechnology/comments/lvnwe4/lama_ais_weekly_news_updates_and_events/,LanguageTechnology,t3_lvnwe4,"LAMA AI's weekly news, updates, and events. Hey guys!

This week, LAMA ([https://lamaai.io](https://lamaai.io)) has a couple of updates. Let's start with this weeks AI news!

You can find the video [here](https://www.lamaai.io/posts/ai-360-01-03-2021-unified-transformer-sebastian-ruder-openais-dall-e-glom-and-studiogan), but as for the key highlights:

* [Facebook AI Research](https://ai.facebook.com/) announce a new multi-modal Transformer architecture, [UniT](https://arxiv.org/abs/2102.10772)
* [Sebastian Ruder updates](https://ruder.io/recent-advances-lm-fine-tuning/) us on the latest advances in language model fine-tuning
* [OpenAI](http://openai.com/) have news about DALL-E
* Geoffrey Hinton [proposes an idea paper](https://arxiv.org/abs/2102.12627) he dubs GLOM
* [StudioGAN](https://github.com/POSTECH-CVLab/PyTorch-StudioGAN) is introduced: A PyTorch library for SoTA GAN models

&amp;#x200B;

Would you like to know how we can use Machine Learning to detect COVID symptoms? Imperial College's **Björn Schuller** is going to be presenting  his recent and topical work on detecting COVID symptoms through the use of Computer Audition (think Computer Vision but for audio instead!). As a little introduction, Björn is a Full Professor at the University of Augsburg in Germany, where he is also Chair of Embedded Intelligence for Health Care and Wellbeing. He is also a Professor of Artificial Intelligence at Imperial College London and heads GLAM (Group for Language, Audio and Music). He has over 1000 publications which feature his name (🤯) and his recent research interests focus on audio and multi-modal approaches to emotion detection. Björn will be discussing his paper: [COVID-19 and Computer Audition](https://arxiv.org/abs/2003.11117) which was written during the outbreak last year. In this paper, he overviews the usage of speech and sound analysis by artificial intelligence/machine learning to detect a presence of COVID. If you're interested in attending the talk, register on the eventbrite: [https://www.eventbrite.com/e/bjorn-schuller-lama-ai-covid-19-and-computer-audition-tickets-143203512561](https://www.eventbrite.com/e/bjorn-schuller-lama-ai-covid-19-and-computer-audition-tickets-143203512561)

&amp;#x200B;

Finally, last week we had a paper presentation on the current state of AI's progress towards Natural Language Understanding. You can find the video/talk [here](https://www.lamaai.io/posts/progress-towards-natural-language-understanding)! As for some key points from the talk:

* (Bender and Koller, 2020) discuss the question whether a system exposed only to the form of language in its training data, can in principle learn its meaning
* They underline their arguments with multiple thought experiments and a comparison to human children language acquisition which is grounded in the real world and in interaction with others
* The NLP research community is called to reflect on the current research trends and to take a more top-down approach by asking “whether the hill we are climbing so rapidly is the right hill”
* (Linzen, 2020) discusses common evaluation practices in NLP research and their limitations
* He proposes a new evaluation paradigm which takes into consideration pre-training corpora of different sizes, as well as normative and efficiency attributes while comparing ML models to each other.",3361
636,636,[Need Advice]PhD in NLP @ reputed US institute/Prof. Worth it?,"Hi, 

I recently got admitted to a good PhD program in the US to work on natural language processing. The advisor is great too. A question to this reddit community - do you think going for a PhD in this domain is worth it? 

Background: Im already working at a great organization where my learning curve is increasing for the last two years. Im getting to work on state of the art things, I get to read papers, implement them, come up with my own architectures etc. My peers are very supportive, and Im assuming this is paving path for great industry opportunities in general. 

However, I applied for a PhD for two reasons: I want to learn more about the domain and stick to an area to get more expertise, understand the theory etc. And eventually I want to be a research lead, for which I think a PhD will provide me with immense credibility. However the idea of starting a PhD at 27, and going back to school and that lifestyle for another five years is very very scary. Im starting to have cold feet. 

Any words of wisdom from someone in the process, or someone who has been through this? 

Thank you so much!",https://www.reddit.com/r/LanguageTechnology/comments/lvbkfr/need_advicephd_in_nlp_reputed_us_instituteprof/,LanguageTechnology,t3_lvbkfr,"[Need Advice]PhD in NLP @ reputed US institute/Prof. Worth it? Hi, 

I recently got admitted to a good PhD program in the US to work on natural language processing. The advisor is great too. A question to this reddit community - do you think going for a PhD in this domain is worth it? 

Background: Im already working at a great organization where my learning curve is increasing for the last two years. Im getting to work on state of the art things, I get to read papers, implement them, come up with my own architectures etc. My peers are very supportive, and Im assuming this is paving path for great industry opportunities in general. 

However, I applied for a PhD for two reasons: I want to learn more about the domain and stick to an area to get more expertise, understand the theory etc. And eventually I want to be a research lead, for which I think a PhD will provide me with immense credibility. However the idea of starting a PhD at 27, and going back to school and that lifestyle for another five years is very very scary. Im starting to have cold feet. 

Any words of wisdom from someone in the process, or someone who has been through this? 

Thank you so much!",1177
637,637,Any pre-trained longformers for this task?,"My goal is to have a network I can feed large amounts of text and complex questions to receive full length through answers.

Firstly is such a thing even possible with current models?  


Here is an example of what I want to be done

Input: the entire book of animal farm

Question: How does the book animal farm depict the issues with communism.

Full length answer. Animal farm depicts the failure of communism in several ways. The book shows us that people working with equal pay results in laziness among certain individuals and people having less motivation to work harder jobs. ETC ETC

Answer length should be anywhere from sentence s to paragraphs.

Also Id prefer that the model would have a higher bias to include reasoning for the questions.

For example Bob is 20 years old. Is Bob 30 years old?

Answer: No, Bob cannot be 30 years old because he is 20 years old.

This might be ambitious but the goal is something that I could use continuously through high school/college to save a ton of time. Maybe ill have to wait for bigger models like GPT-4 Im not sure but im hoping anyone here can give me some pointers?",https://www.reddit.com/r/LanguageTechnology/comments/lvjkoo/any_pretrained_longformers_for_this_task/,LanguageTechnology,t3_lvjkoo,"Any pre-trained longformers for this task? My goal is to have a network I can feed large amounts of text and complex questions to receive full length through answers.

Firstly is such a thing even possible with current models?  


Here is an example of what I want to be done

Input: the entire book of animal farm

Question: How does the book animal farm depict the issues with communism.

Full length answer. Animal farm depicts the failure of communism in several ways. The book shows us that people working with equal pay results in laziness among certain individuals and people having less motivation to work harder jobs. ETC ETC

Answer length should be anywhere from sentence s to paragraphs.

Also Id prefer that the model would have a higher bias to include reasoning for the questions.

For example Bob is 20 years old. Is Bob 30 years old?

Answer: No, Bob cannot be 30 years old because he is 20 years old.

This might be ambitious but the goal is something that I could use continuously through high school/college to save a ton of time. Maybe ill have to wait for bigger models like GPT-4 Im not sure but im hoping anyone here can give me some pointers?",1167
638,638,Where can I find an online resource of voice cloning?,"Is there a website where I can upload a snippet of speech and clone a voice? Just for demo purposes. 

I tried the method in this link but it didn’t work. https://youtu.be/CkZJ1knpZmo

Do you know of a good resource?",https://www.reddit.com/r/LanguageTechnology/comments/lv4ipg/where_can_i_find_an_online_resource_of_voice/,LanguageTechnology,t3_lv4ipg,"Where can I find an online resource of voice cloning? Is there a website where I can upload a snippet of speech and clone a voice? Just for demo purposes. 

I tried the method in this link but it didn’t work. https://youtu.be/CkZJ1knpZmo

Do you know of a good resource?",270
639,639,Extracting information from text,"Hello,

I am a NLP noob so please forgive my naive questions. I have a problem and looking for pointers to find a solution.

I have a list of keywords and have loads of unstructured data. Based on the keywords in my list, I want to extract information like values from the text. For example I have a sentence like 'His age is 15'. and my keyword is 'AGE'. Now I want to extract the age and the number from the text. THe thing is since the text is unstructured, the exact semantics of the sentence would differ in different texts. So I am looking to find/implement some solution that identifies the keyword (Simple enough) and extracts the associated information. I have tried using regexp, they work sometimes and sometimes start getting too complex to extract the info. Any help would be appreciated.

Thanks",https://www.reddit.com/r/LanguageTechnology/comments/lv9k9u/extracting_information_from_text/,LanguageTechnology,t3_lv9k9u,"Extracting information from text Hello,

I am a NLP noob so please forgive my naive questions. I have a problem and looking for pointers to find a solution.

I have a list of keywords and have loads of unstructured data. Based on the keywords in my list, I want to extract information like values from the text. For example I have a sentence like 'His age is 15'. and my keyword is 'AGE'. Now I want to extract the age and the number from the text. THe thing is since the text is unstructured, the exact semantics of the sentence would differ in different texts. So I am looking to find/implement some solution that identifies the keyword (Simple enough) and extracts the associated information. I have tried using regexp, they work sometimes and sometimes start getting too complex to extract the info. Any help would be appreciated.

Thanks",842
640,640,Into NLP - Fuzzy String Matching and the Edit Distance,,https://www.qualicen.de/into-nlp-2-fuzzy-string-matching-and-the-edit-distance/,LanguageTechnology,t3_lv6z3i,Into NLP - Fuzzy String Matching and the Edit Distance ,55
641,641,Training a Multi-Label Emotion Classifier with Tez and PyTorch to detect +20 different emotions,"Hello everyone!

I built an end-to-end tutorial to train an emotion classifier using SqueezeBERT, a state-of-the-art lightweight version of BERT.  
I got +0.9 on test data in a few lines of code.  
I thought I'd share with you my approach and the code so that you can maybe apply it to your projects.

The trained model is also available so that you can use it on your own data without retraining from scratch.

* Here's the code: [https://github.com/ahmedbesbes/multi-label-sentiment-classifier](https://github.com/ahmedbesbes/multi-label-sentiment-classifier)
* and the blog post: [https://medium.com/@ahmedbesbes/training-a-multi-label-emotion-classifier-with-tez-and-pytorch-af04c899a63a](https://medium.com/@ahmedbesbes/training-a-multi-label-emotion-classifier-with-tez-and-pytorch-af04c899a63a)

Please let me know if you have an issue

Feedbacks more than welcome :)

Best!",https://www.reddit.com/r/LanguageTechnology/comments/lurnhc/training_a_multilabel_emotion_classifier_with_tez/,LanguageTechnology,t3_lurnhc,"Training a Multi-Label Emotion Classifier with Tez and PyTorch to detect +20 different emotions Hello everyone!

I built an end-to-end tutorial to train an emotion classifier using SqueezeBERT, a state-of-the-art lightweight version of BERT.  
I got +0.9 on test data in a few lines of code.  
I thought I'd share with you my approach and the code so that you can maybe apply it to your projects.

The trained model is also available so that you can use it on your own data without retraining from scratch.

* Here's the code: [https://github.com/ahmedbesbes/multi-label-sentiment-classifier](https://github.com/ahmedbesbes/multi-label-sentiment-classifier)
* and the blog post: [https://medium.com/@ahmedbesbes/training-a-multi-label-emotion-classifier-with-tez-and-pytorch-af04c899a63a](https://medium.com/@ahmedbesbes/training-a-multi-label-emotion-classifier-with-tez-and-pytorch-af04c899a63a)

Please let me know if you have an issue

Feedbacks more than welcome :)

Best!",977
642,642,SummPip: Multi-Document Summarization with Sentence Graph Compression | Research Paper Walkthrough,,https://youtu.be/1jwUOMQVCo4,LanguageTechnology,t3_luk23p,SummPip: Multi-Document Summarization with Sentence Graph Compression | Research Paper Walkthrough ,99
643,643,An effective joint sentence and token labelling method for Low-Resource NER | Research Papers Summary 010,,https://youtu.be/HR5qa1ElLeA,LanguageTechnology,t3_lunnjs,An effective joint sentence and token labelling method for Low-Resource NER | Research Papers Summary 010 ,106
644,644,I have an issue with GPT-2 Reading comprehension for a task.,"Scroll down to bottom for TLDR.

So ive been working on fine-tuning GPT2 to be capable of reading comprehension using CoQa dataset. It works good but my goal is to create a system that can read an entire book and then answer questions given about the book. The problem is there is too much data being sent into the bot within a single input. It can handle multiple paragraphs quite well and perhaps even an essay but a book is just too much data. There are a few solutions ive thought of such as using reading comprehension to create a pre-generated data set with each paragraph of the book followed by generated questions. However, even using google colab such data generation would take an excruciatingly long time. If there are 400 paragraphs it would take nearly 3 hours to finish the data generation. I also thought I could perhaps remove words like ""You, but or"" etc those kind of conjunctions and pronouns that don't at to the story. But I feel as if its comprehension capabilities may be diminished. Perhaps such a task would not be feasible until I can get my hands on GPT-3?

Anyways ill break down the methods that I have thought of

Method 1: Take the specified book and allow GPT-2 to generate reading comprehension dataset from it. Then feed that data back into the model so that it learns specific things about said book. ETA 4+ hours

Method 2: Take the book and remove conjunctions and pronouns from the text. then do the same as method 1

ETA &lt;2 hours

Method 3: No clue how this would work but perhaps I could just throw the whole book into the training data along with reading comprehension data to see if it might pick up on some of the questions Eta &lt; 1 hour

Method 4: Find a dataset that specifically answers questions from a variety of books and add that to CoQa. Eta &lt; 1 hour + how long to find said dataset.

The end goal is to create a system where I can have an AI answer questions about a book. Which would completely remove any need for me to read said book. Also be just as capable of reading pages from a text book and completing questions. Such a system would greatly enhance my ability to complete school work and free up hours of wasted time on learning about 50 year old books.

TLDR:

Book is too big to feed into GPT-2 reading comprehension model. How do I design/train my model to quickly answer questions about entire books?

My Question to you:

If you are reading, my questions to you are exactly which methods I should approach and is this challenge even feasible using the current GPT-2 model.",https://www.reddit.com/r/LanguageTechnology/comments/lunlfh/i_have_an_issue_with_gpt2_reading_comprehension/,LanguageTechnology,t3_lunlfh,"I have an issue with GPT-2 Reading comprehension for a task. Scroll down to bottom for TLDR.

So ive been working on fine-tuning GPT2 to be capable of reading comprehension using CoQa dataset. It works good but my goal is to create a system that can read an entire book and then answer questions given about the book. The problem is there is too much data being sent into the bot within a single input. It can handle multiple paragraphs quite well and perhaps even an essay but a book is just too much data. There are a few solutions ive thought of such as using reading comprehension to create a pre-generated data set with each paragraph of the book followed by generated questions. However, even using google colab such data generation would take an excruciatingly long time. If there are 400 paragraphs it would take nearly 3 hours to finish the data generation. I also thought I could perhaps remove words like ""You, but or"" etc those kind of conjunctions and pronouns that don't at to the story. But I feel as if its comprehension capabilities may be diminished. Perhaps such a task would not be feasible until I can get my hands on GPT-3?

Anyways ill break down the methods that I have thought of

Method 1: Take the specified book and allow GPT-2 to generate reading comprehension dataset from it. Then feed that data back into the model so that it learns specific things about said book. ETA 4+ hours

Method 2: Take the book and remove conjunctions and pronouns from the text. then do the same as method 1

ETA &lt;2 hours

Method 3: No clue how this would work but perhaps I could just throw the whole book into the training data along with reading comprehension data to see if it might pick up on some of the questions Eta &lt; 1 hour

Method 4: Find a dataset that specifically answers questions from a variety of books and add that to CoQa. Eta &lt; 1 hour + how long to find said dataset.

The end goal is to create a system where I can have an AI answer questions about a book. Which would completely remove any need for me to read said book. Also be just as capable of reading pages from a text book and completing questions. Such a system would greatly enhance my ability to complete school work and free up hours of wasted time on learning about 50 year old books.

TLDR:

Book is too big to feed into GPT-2 reading comprehension model. How do I design/train my model to quickly answer questions about entire books?

My Question to you:

If you are reading, my questions to you are exactly which methods I should approach and is this challenge even feasible using the current GPT-2 model.",2608
645,645,Struggling With Terminology From Linguistics,"Hi all, 

Starting to make a switch toward NLP research in my Ph.D. and find I struggle to read many papers which use terminology from linguistics. Does anyone have any book suggestions that might help me better understand grammar / linguistic terminology? I am a native English speaker, I just am not familiar, for example, with Chomsky's surface vs deep structures, what frame semantics are, etc. 

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/lujkt5/struggling_with_terminology_from_linguistics/,LanguageTechnology,t3_lujkt5,"Struggling With Terminology From Linguistics Hi all, 

Starting to make a switch toward NLP research in my Ph.D. and find I struggle to read many papers which use terminology from linguistics. Does anyone have any book suggestions that might help me better understand grammar / linguistic terminology? I am a native English speaker, I just am not familiar, for example, with Chomsky's surface vs deep structures, what frame semantics are, etc. 

Thanks!",453
646,646,Does anyone know of any domain-specific pretrained language models?,"Hi everyone. The title is the question. I'm just wondering whether there may be any language models like BERT that were pretrained on domain-specific corpora.

For example, the BioBERT model is known to have been pretrained on biomedical text, and hence achieves better performance than BERT on biomedical NLP tasks.

Would there be anything else along the same lines? Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/luvxbh/does_anyone_know_of_any_domainspecific_pretrained/,LanguageTechnology,t3_luvxbh,"Does anyone know of any domain-specific pretrained language models? Hi everyone. The title is the question. I'm just wondering whether there may be any language models like BERT that were pretrained on domain-specific corpora.

For example, the BioBERT model is known to have been pretrained on biomedical text, and hence achieves better performance than BERT on biomedical NLP tasks.

Would there be anything else along the same lines? Thanks.",444
647,647,"University of Wisconsin-Madison, UC Berkeley, and Google Brain Introduce Nystromformer: A Nystrom-based Algorithm for Approximating Self-Attention","Early days of research in Natural language processing established long-term dependencies. It also brought the vanishing gradient problem in front of us because nascent models were handling the input sequences one by one, without parallelization. Recently, revolutionary transformer-based architectures and the self-attention mechanisms have enabled token pairs’ interactions across complete sequences resulting in modeling arbitrary dependencies in a constant number of layers. The above helped achieve state-of-the-art performance across many Natural language processing tasks.

However, these advantages came to a high-cost barrier because the transformer-based networks’ memory and computational requirements grow quadratically with sequence length. The above results in significant efficiency bottlenecks when dealing with long sequences. Researchers from the University of Wisconsin-Madison, American Family Insurance, UC Berkeley, and Google Brain propose Nyströmformer. Nyströmformer is an O(n) approximation in both memory and time for self-attention. The above is designed to rescue us from the[ quadratic cost](https://syncedreview.com/2020/07/31/applying-linearly-scalable-transformers-to-model-longer-protein-sequences/) associated with the long input sequences

Paper Summary: https://www.marktechpost.com/2021/02/27/university-of-wisconsin-madison-uc-berkeley-and-google-brain-introduce-nystromformer-a-nystrom-based-algorithm-for-approximating-self-attention/

Paper: https://arxiv.org/pdf/2102.03902.pdf

Github: https://github.com/mlpen/Nystromformer",https://www.reddit.com/r/LanguageTechnology/comments/lu37h4/university_of_wisconsinmadison_uc_berkeley_and/,LanguageTechnology,t3_lu37h4,"University of Wisconsin-Madison, UC Berkeley, and Google Brain Introduce Nystromformer: A Nystrom-based Algorithm for Approximating Self-Attention Early days of research in Natural language processing established long-term dependencies. It also brought the vanishing gradient problem in front of us because nascent models were handling the input sequences one by one, without parallelization. Recently, revolutionary transformer-based architectures and the self-attention mechanisms have enabled token pairs’ interactions across complete sequences resulting in modeling arbitrary dependencies in a constant number of layers. The above helped achieve state-of-the-art performance across many Natural language processing tasks.

However, these advantages came to a high-cost barrier because the transformer-based networks’ memory and computational requirements grow quadratically with sequence length. The above results in significant efficiency bottlenecks when dealing with long sequences. Researchers from the University of Wisconsin-Madison, American Family Insurance, UC Berkeley, and Google Brain propose Nyströmformer. Nyströmformer is an O(n) approximation in both memory and time for self-attention. The above is designed to rescue us from the[ quadratic cost](https://syncedreview.com/2020/07/31/applying-linearly-scalable-transformers-to-model-longer-protein-sequences/) associated with the long input sequences

Paper Summary: https://www.marktechpost.com/2021/02/27/university-of-wisconsin-madison-uc-berkeley-and-google-brain-introduce-nystromformer-a-nystrom-based-algorithm-for-approximating-self-attention/

Paper: https://arxiv.org/pdf/2102.03902.pdf

Github: https://github.com/mlpen/Nystromformer",1714
648,648,How to generate sentences from a set of keywords?,"like this: 

[https://towardsdatascience.com/data-to-text-generation-with-t5-building-a-simple-yet-advanced-nlg-model-b5cce5a6df45](https://towardsdatascience.com/data-to-text-generation-with-t5-building-a-simple-yet-advanced-nlg-model-b5cce5a6df45) 

Sample Input: ""Teacher"", ""Great"".

Output: ""He is a great teacher and everyone needs to learn from him""

&amp;#x200B;

I want to do this for a university project and  I don't have a lot of time. do you think this is a good idea or should I change the topic. 

I have a dataset of sample outputs. I am new to this. Any help is appreciated thanks.",https://www.reddit.com/r/LanguageTechnology/comments/luam24/how_to_generate_sentences_from_a_set_of_keywords/,LanguageTechnology,t3_luam24,"How to generate sentences from a set of keywords? like this: 

[https://towardsdatascience.com/data-to-text-generation-with-t5-building-a-simple-yet-advanced-nlg-model-b5cce5a6df45](https://towardsdatascience.com/data-to-text-generation-with-t5-building-a-simple-yet-advanced-nlg-model-b5cce5a6df45) 

Sample Input: ""Teacher"", ""Great"".

Output: ""He is a great teacher and everyone needs to learn from him""

&amp;#x200B;

I want to do this for a university project and  I don't have a lot of time. do you think this is a good idea or should I change the topic. 

I have a dataset of sample outputs. I am new to this. Any help is appreciated thanks.",647
649,649,Apache Superset for textual data ?,"The github description of Apache Superset is:

&gt; Apache Superset is a Data Visualization and Data Exploration Platform 

ref: https://github.com/apache/superset

The data I am looking at is semi-structured text (html), and I can reach to some structured data (knowledge base) related to the texts.

Questions:

A) Do you use Superset for exploring textual data? How?

B) Is there another tool similar to Superset that is specifically crafted to visualize / explore / analyze text such a html?

C) If there is no existing library / app / api / service, what would be the bare minimal features you would need in such tool?",https://www.reddit.com/r/LanguageTechnology/comments/lucpm8/apache_superset_for_textual_data/,LanguageTechnology,t3_lucpm8,"Apache Superset for textual data ? The github description of Apache Superset is:

&gt; Apache Superset is a Data Visualization and Data Exploration Platform 

ref: https://github.com/apache/superset

The data I am looking at is semi-structured text (html), and I can reach to some structured data (knowledge base) related to the texts.

Questions:

A) Do you use Superset for exploring textual data? How?

B) Is there another tool similar to Superset that is specifically crafted to visualize / explore / analyze text such a html?

C) If there is no existing library / app / api / service, what would be the bare minimal features you would need in such tool?",658
650,650,"Is it just me, or are the majority of research papers dealing with relation extraction written by Chinese institutions?","So...yeah this has really been on the back of my mind and it may be more appropriate for r/TooAfraidToAsk but yeah...

I'm working on a relation extraction research project, and I've noticed that almost every single paper that I read is written by something related to China (school, institution, author, etc.).

Is there some sort of reason why this might be? Or have I just not read enough papers?",https://www.reddit.com/r/LanguageTechnology/comments/lugq47/is_it_just_me_or_are_the_majority_of_research/,LanguageTechnology,t3_lugq47,"Is it just me, or are the majority of research papers dealing with relation extraction written by Chinese institutions? So...yeah this has really been on the back of my mind and it may be more appropriate for r/TooAfraidToAsk but yeah...

I'm working on a relation extraction research project, and I've noticed that almost every single paper that I read is written by something related to China (school, institution, author, etc.).

Is there some sort of reason why this might be? Or have I just not read enough papers?",519
651,651,Applying gensim topic model on new document,"Hi,

I am currently working on a topic modelling project with gensim and i have some issues, regarding the tf\_idf vectors for adding a new document.

&amp;#x200B;

The preprocessed and tokenized data is stored in a pandas dataframe (using spaCy). I splitted the data into 2 parts train and test. (2 seperate dataframes). 

Gensim requires to first create a dictionary. The dictionary is expandable, so i first created it with only the train data and afterwards expand it with the test data, if there are possibly some new tokens.

Afterward the corpus is created ( which are basically just BOW vectors). The tf-idf vectorizer is created on top of this corpus and then applyed on the corpus:

""""""

dataset = corpora.Dictionary()

dataset.add\_documents(dataframe\['tokens'\].tolist())

corpus = \[dataset.doc2bow(text) for text in dataframe\['tokens'\].tolist()\]

tfidf\_vectorizer = TfidfModel(corpus)

tfidf = tfidf\_vectorizer\[corpus\]

""""""

&amp;#x200B;

Question 1: For applying the model to a new document, i would need the tfidf vectors of the new document. Do i have to just add the document to the old corpus, create a new tfidf\_vectorizer with that corpus and then just apply the vectorizer to only the new document? Or am i missing something?

Question 2: As i saw in the documentation, the model is applied to a new document with the following code( i am using LsiModel):

""""""

model = LsiModel(tfidf\_vect\[corpus\], id2word=dataset)

vector = model\[tfidf\_vect\[new\_corpus\]

""""""

Print(vector) prints :  &lt;gensim.interfaces.TransformedCorpus at 0x245468431&gt;. 

How can i visualize / just print the resulting vector ( i guess it should be the topic distribution of the new document)? Or am i doing something wrong here ?",https://www.reddit.com/r/LanguageTechnology/comments/lufpot/applying_gensim_topic_model_on_new_document/,LanguageTechnology,t3_lufpot,"Applying gensim topic model on new document Hi,

I am currently working on a topic modelling project with gensim and i have some issues, regarding the tf\_idf vectors for adding a new document.

&amp;#x200B;

The preprocessed and tokenized data is stored in a pandas dataframe (using spaCy). I splitted the data into 2 parts train and test. (2 seperate dataframes). 

Gensim requires to first create a dictionary. The dictionary is expandable, so i first created it with only the train data and afterwards expand it with the test data, if there are possibly some new tokens.

Afterward the corpus is created ( which are basically just BOW vectors). The tf-idf vectorizer is created on top of this corpus and then applyed on the corpus:

""""""

dataset = corpora.Dictionary()

dataset.add\_documents(dataframe\['tokens'\].tolist())

corpus = \[dataset.doc2bow(text) for text in dataframe\['tokens'\].tolist()\]

tfidf\_vectorizer = TfidfModel(corpus)

tfidf = tfidf\_vectorizer\[corpus\]

""""""

&amp;#x200B;

Question 1: For applying the model to a new document, i would need the tfidf vectors of the new document. Do i have to just add the document to the old corpus, create a new tfidf\_vectorizer with that corpus and then just apply the vectorizer to only the new document? Or am i missing something?

Question 2: As i saw in the documentation, the model is applied to a new document with the following code( i am using LsiModel):

""""""

model = LsiModel(tfidf\_vect\[corpus\], id2word=dataset)

vector = model\[tfidf\_vect\[new\_corpus\]

""""""

Print(vector) prints :  &lt;gensim.interfaces.TransformedCorpus at 0x245468431&gt;. 

How can i visualize / just print the resulting vector ( i guess it should be the topic distribution of the new document)? Or am i doing something wrong here ?",1788
652,652,Paper: Investigating the Limitations of the Transformers with Simple Arithmetic Tasks,,https://arxiv.org/abs/2102.13019,LanguageTechnology,t3_lu1m4b,Paper: Investigating the Limitations of the Transformers with Simple Arithmetic Tasks ,86
653,653,Best MOOCs/Projects for MS in CL/NLP (Linguistics Background),"Hi everyone! 

I come from a language/linguistics background. I got my BA in Spanish with a minor in Linguistics. I’ve taken classes like Syntax, phonetics, phonology, language technology, Hispanic linguistics, and “understanding machine learning.”

I’m looking to apply to masters in Voice Tech, comp ling or NLP this year and I would like to boost the technical side of my knowledge and CV so that the universities see that I could be a good fit for their programs. 

I’ve already completed two courses on Python on Coursera and Codecademy, and I trained a language detection model using naive bayes to distinguish between Spanish and Portuguese texts. I am really eager to keep learning, I just don’t know where to start or what direction to go in.

Are there any online courses or portfolio projects you would recommend to show admissions that I have some background knowledge? Unfortunately I can’t re-enroll at my university at the moment as they are already half way through the semester and it would cost thousands. 

Thanks in advance!",https://www.reddit.com/r/LanguageTechnology/comments/ltqyv2/best_moocsprojects_for_ms_in_clnlp_linguistics/,LanguageTechnology,t3_ltqyv2,"Best MOOCs/Projects for MS in CL/NLP (Linguistics Background) Hi everyone! 

I come from a language/linguistics background. I got my BA in Spanish with a minor in Linguistics. I’ve taken classes like Syntax, phonetics, phonology, language technology, Hispanic linguistics, and “understanding machine learning.”

I’m looking to apply to masters in Voice Tech, comp ling or NLP this year and I would like to boost the technical side of my knowledge and CV so that the universities see that I could be a good fit for their programs. 

I’ve already completed two courses on Python on Coursera and Codecademy, and I trained a language detection model using naive bayes to distinguish between Spanish and Portuguese texts. I am really eager to keep learning, I just don’t know where to start or what direction to go in.

Are there any online courses or portfolio projects you would recommend to show admissions that I have some background knowledge? Unfortunately I can’t re-enroll at my university at the moment as they are already half way through the semester and it would cost thousands. 

Thanks in advance!",1106
654,654,New Masters program in Voice and Speech Tech (in Europe),"There is a new 1-year Master’s program at the University of Groningen (the Netherlands) dedicated exclusively to voice/speech tech. Focus is on speech recognition and voice synthesis. 

This is an interdisciplinary program for students from CS, AI,  Linguistics, or similar. 

https://youtu.be/297BY6uTHB8
https://www.rug.nl/masters/voice-technology/",https://www.reddit.com/r/LanguageTechnology/comments/ltxrhd/new_masters_program_in_voice_and_speech_tech_in/,LanguageTechnology,t3_ltxrhd,"New Masters program in Voice and Speech Tech (in Europe) There is a new 1-year Master’s program at the University of Groningen (the Netherlands) dedicated exclusively to voice/speech tech. Focus is on speech recognition and voice synthesis. 

This is an interdisciplinary program for students from CS, AI,  Linguistics, or similar. 

https://youtu.be/297BY6uTHB8
https://www.rug.nl/masters/voice-technology/",407
655,655,Contextual matching of category names,"Hi everyone!  


I am trying to find a solution for following problem:  
I have a large data frame where documents are labeled with &gt;400 different category names.   
I built a simple ""data explorer"" that takes a free-text query as user input and runs fuzzywuzzy string matching over those category names.

For example, user searches for ""climate change"" and the fuzzy string matching returns the top 10 most similar category names - let's say ""climate\_change\_mitigation"", ""climate\_change\_programme"", etc...Then the user can select all the desired categories and the data-frame is filtered accordingly. So this is quite simple but works well.

Now, I would like to also take some contextual information into account. For example, when user searches for ""plastic"" the fuzzy string matching, of course, only matches with category names that contain the string ""plastic"" or very similar. However, I would like to also obtain categories such as ""Clean Oceans"", ""Marine Ecosystem"", etc.

I was thinking of training a basic word/doc2vec model on the documents, but I am not sure how to use it to match similarity between a string and another lists of strings (the category names), also perhaps this could help in some cases but usually the simple fuzzy string matching would outperform it still I suppose.

Any ideas?

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/ltjqjk/contextual_matching_of_category_names/,LanguageTechnology,t3_ltjqjk,"Contextual matching of category names Hi everyone!  


I am trying to find a solution for following problem:  
I have a large data frame where documents are labeled with &gt;400 different category names.   
I built a simple ""data explorer"" that takes a free-text query as user input and runs fuzzywuzzy string matching over those category names.

For example, user searches for ""climate change"" and the fuzzy string matching returns the top 10 most similar category names - let's say ""climate\_change\_mitigation"", ""climate\_change\_programme"", etc...Then the user can select all the desired categories and the data-frame is filtered accordingly. So this is quite simple but works well.

Now, I would like to also take some contextual information into account. For example, when user searches for ""plastic"" the fuzzy string matching, of course, only matches with category names that contain the string ""plastic"" or very similar. However, I would like to also obtain categories such as ""Clean Oceans"", ""Marine Ecosystem"", etc.

I was thinking of training a basic word/doc2vec model on the documents, but I am not sure how to use it to match similarity between a string and another lists of strings (the category names), also perhaps this could help in some cases but usually the simple fuzzy string matching would outperform it still I suppose.

Any ideas?

Thanks!",1364
656,656,Some questions regarding word embeddings,"Hey! I have a bunch of questions for a project of mine.

1. For word embeddings, do I need to perform other similarity measures like Tf-Idf? Cause I read somewhere about BoW and Skip-Gram methods used for creating embeddings. 


2. What do we do with word embeddings? Like once we get the word vectors, what is the next step in the process? I'm trying to make a sentiment analysis project with LSTM and word embeddings but I'm not sure how to use the word embeddings. 


3. Are embeddings, features? If not, how do I extract features from data? 

I'm a noob so I'll probably be asking more questions here.",https://www.reddit.com/r/LanguageTechnology/comments/ltgppq/some_questions_regarding_word_embeddings/,LanguageTechnology,t3_ltgppq,"Some questions regarding word embeddings Hey! I have a bunch of questions for a project of mine.

1. For word embeddings, do I need to perform other similarity measures like Tf-Idf? Cause I read somewhere about BoW and Skip-Gram methods used for creating embeddings. 


2. What do we do with word embeddings? Like once we get the word vectors, what is the next step in the process? I'm trying to make a sentiment analysis project with LSTM and word embeddings but I'm not sure how to use the word embeddings. 


3. Are embeddings, features? If not, how do I extract features from data? 

I'm a noob so I'll probably be asking more questions here.",646
657,657,"Researchers From UC Berkeley, University of Maryland, and UC Irvine Introduce A new Contextual Calibration Approach That Significantly Improves GPT-3 Accuracy Up to 30%","A team of researchers at UC Berkeley, University of Maryland, and UC Irvine conducted a study to identify that can cause instability in the GPT-3 language model. The team proposes a contextual calibration procedure that consistently improves GPT-3 accuracy across diverse prompt format choices and examples.

GPT-3 can perform numerous tasks when provided a natural language prompt that contains a few training examples. Large language models have significantly improved their few-shot performance, with top models like GPT-3. Few-shot learning allows users to prototype NLP models swiftly. It enables non-technical users to create NLP systems and efficiently reuse models reducing system memory and complexity.

Paper Summary: [https://www.marktechpost.com/2021/02/26/researchers-from-uc-berkeley-university-of-maryland-and-uc-irvine-introduce-a-new-contextual-calibration-approach-that-significantly-improves-gpt-3-accuracy-up-to-30/](https://www.marktechpost.com/2021/02/26/researchers-from-uc-berkeley-university-of-maryland-and-uc-irvine-introduce-a-new-contextual-calibration-approach-that-significantly-improves-gpt-3-accuracy-up-to-30/) 

Paper Source: [https://arxiv.org/pdf/2102.09690.pdf](https://arxiv.org/pdf/2102.09690.pdf) 

Github: [https://github.com/tonyzhaozh/few-shot-learning](https://github.com/tonyzhaozh/few-shot-learning)",https://www.reddit.com/r/LanguageTechnology/comments/lt0z99/researchers_from_uc_berkeley_university_of/,LanguageTechnology,t3_lt0z99,"Researchers From UC Berkeley, University of Maryland, and UC Irvine Introduce A new Contextual Calibration Approach That Significantly Improves GPT-3 Accuracy Up to 30% A team of researchers at UC Berkeley, University of Maryland, and UC Irvine conducted a study to identify that can cause instability in the GPT-3 language model. The team proposes a contextual calibration procedure that consistently improves GPT-3 accuracy across diverse prompt format choices and examples.

GPT-3 can perform numerous tasks when provided a natural language prompt that contains a few training examples. Large language models have significantly improved their few-shot performance, with top models like GPT-3. Few-shot learning allows users to prototype NLP models swiftly. It enables non-technical users to create NLP systems and efficiently reuse models reducing system memory and complexity.

Paper Summary: [https://www.marktechpost.com/2021/02/26/researchers-from-uc-berkeley-university-of-maryland-and-uc-irvine-introduce-a-new-contextual-calibration-approach-that-significantly-improves-gpt-3-accuracy-up-to-30/](https://www.marktechpost.com/2021/02/26/researchers-from-uc-berkeley-university-of-maryland-and-uc-irvine-introduce-a-new-contextual-calibration-approach-that-significantly-improves-gpt-3-accuracy-up-to-30/) 

Paper Source: [https://arxiv.org/pdf/2102.09690.pdf](https://arxiv.org/pdf/2102.09690.pdf) 

Github: [https://github.com/tonyzhaozh/few-shot-learning](https://github.com/tonyzhaozh/few-shot-learning)",1515
658,658,How to extract keywords important to a text classification problem?,"Hi.

I have a text multi-class text classification problem, in which I'm trying to classify different subreddits' comments using a very simple TFIDF + PCA + SVM pipeline. What I'm really keen to know is that how different keywords in each class contribute to this classification problem. How can I do this? I have around 10 classes each having 5000 comments with 30 words in average.",https://www.reddit.com/r/LanguageTechnology/comments/lt5k5m/how_to_extract_keywords_important_to_a_text/,LanguageTechnology,t3_lt5k5m,"How to extract keywords important to a text classification problem? Hi.

I have a text multi-class text classification problem, in which I'm trying to classify different subreddits' comments using a very simple TFIDF + PCA + SVM pipeline. What I'm really keen to know is that how different keywords in each class contribute to this classification problem. How can I do this? I have around 10 classes each having 5000 comments with 30 words in average.",451
659,659,Intro to AI Bias,,https://beluis3d.medium.com/introduction-to-bias-in-ai-5058429ba0e,LanguageTechnology,t3_lt9p6b,Intro to AI Bias ,17
660,660,Bringing deep learning into our work tools: Waitlist open &amp; Feedback welcome!,"We're building an ML-(graph)-based tool for file &amp; knowledge management and are just onboarding our first alpha &amp; beta users 🙆🏼‍♀️ !

(Just building our little community here [r/reasonal](https://www.reddit.com/r/reasonal/))

You probably know how difficult it is to keep track of knowledge snippets, files, and links. **In fact,** [**30%**](https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-social-economy) **of the average ""knowledge worker's"" time is spent searching and locating files, as well as communicating &amp; collaborating internally 🤯**

We are happy to finally bring some ""intelligence"" into our work tools and combine it with an intuitive UX. If you would like to see how our tool can bring structure, transparency, and insights to your work content across your Google Drive, Dropbox, Slack, MS Teams, and browser bookmarks, add yourself to the waitlist and get early access to our beta version: ➡️ [https://reason.al](https://reason.al/?utm_source=reddit.com&amp;utm_medium=referral&amp;utm_campaign=WL-comm-rd-003-LT)

❗ If you fill in the survey and are onboarded on the closed beta, you'll receive 5 premium accounts for a lifetime (to be used by yourself or given to your friends 😻). The premium account gets all features and integrations and includes one workspace with up to 10 members 👍🏼

💡 In a nutshell, the underlying ML surfaces the right content among work files or highlights outdated/unreliable/faulty files before you open them. It is based on (combined 😇 ) more than 10 years of our founders' [/u/btabibian](https://www.reddit.com/u/btabibian/) [/u/musically\_ut](https://www.reddit.com/u/musically_ut/) research:

[https://dl.acm.org/doi/abs/10.1145/3038912.3052672](https://dl.acm.org/doi/abs/10.1145/3038912.3052672)

[https://arxiv.org/abs/1905.05305](https://arxiv.org/abs/1905.05305)

[http://proceedings.mlr.press/v124/tabibian20a](http://proceedings.mlr.press/v124/tabibian20a)

[https://www.pnas.org/content/116/10/3988.short](https://www.pnas.org/content/116/10/3988.short)

[https://dl.acm.org/doi/abs/10.1145/3018661.3018685](https://dl.acm.org/doi/abs/10.1145/3018661.3018685)

[https://dl.acm.org/doi/abs/10.1145/2939672.2939875](https://dl.acm.org/doi/abs/10.1145/2939672.2939875)

[https://arxiv.org/abs/1805.09360](https://arxiv.org/abs/1805.09360)",https://www.reddit.com/r/LanguageTechnology/comments/lsuhqw/bringing_deep_learning_into_our_work_tools/,LanguageTechnology,t3_lsuhqw,"Bringing deep learning into our work tools: Waitlist open &amp; Feedback welcome! We're building an ML-(graph)-based tool for file &amp; knowledge management and are just onboarding our first alpha &amp; beta users 🙆🏼‍♀️ !

(Just building our little community here [r/reasonal](https://www.reddit.com/r/reasonal/))

You probably know how difficult it is to keep track of knowledge snippets, files, and links. **In fact,** [**30%**](https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/the-social-economy) **of the average ""knowledge worker's"" time is spent searching and locating files, as well as communicating &amp; collaborating internally 🤯**

We are happy to finally bring some ""intelligence"" into our work tools and combine it with an intuitive UX. If you would like to see how our tool can bring structure, transparency, and insights to your work content across your Google Drive, Dropbox, Slack, MS Teams, and browser bookmarks, add yourself to the waitlist and get early access to our beta version: ➡️ [https://reason.al](https://reason.al/?utm_source=reddit.com&amp;utm_medium=referral&amp;utm_campaign=WL-comm-rd-003-LT)

❗ If you fill in the survey and are onboarded on the closed beta, you'll receive 5 premium accounts for a lifetime (to be used by yourself or given to your friends 😻). The premium account gets all features and integrations and includes one workspace with up to 10 members 👍🏼

💡 In a nutshell, the underlying ML surfaces the right content among work files or highlights outdated/unreliable/faulty files before you open them. It is based on (combined 😇 ) more than 10 years of our founders' [/u/btabibian](https://www.reddit.com/u/btabibian/) [/u/musically\_ut](https://www.reddit.com/u/musically_ut/) research:

[https://dl.acm.org/doi/abs/10.1145/3038912.3052672](https://dl.acm.org/doi/abs/10.1145/3038912.3052672)

[https://arxiv.org/abs/1905.05305](https://arxiv.org/abs/1905.05305)

[http://proceedings.mlr.press/v124/tabibian20a](http://proceedings.mlr.press/v124/tabibian20a)

[https://www.pnas.org/content/116/10/3988.short](https://www.pnas.org/content/116/10/3988.short)

[https://dl.acm.org/doi/abs/10.1145/3018661.3018685](https://dl.acm.org/doi/abs/10.1145/3018661.3018685)

[https://dl.acm.org/doi/abs/10.1145/2939672.2939875](https://dl.acm.org/doi/abs/10.1145/2939672.2939875)

[https://arxiv.org/abs/1805.09360](https://arxiv.org/abs/1805.09360)",2430
661,661,Information Retrieval in Rust,"Hello everyone,

  
I wrote an article on Information Retrieval and implemented a basic search engine in Rust.

Feedback is much appreciated :)

[https://luc-sydney-georges.medium.com/how-to-never-lose-your-stuff-again-pt-1-b06a9d4e0040](https://luc-sydney-georges.medium.com/how-to-never-lose-your-stuff-again-pt-1-b06a9d4e0040)",https://www.reddit.com/r/LanguageTechnology/comments/lswr6g/information_retrieval_in_rust/,LanguageTechnology,t3_lswr6g,"Information Retrieval in Rust Hello everyone,

  
I wrote an article on Information Retrieval and implemented a basic search engine in Rust.

Feedback is much appreciated :)

[https://luc-sydney-georges.medium.com/how-to-never-lose-your-stuff-again-pt-1-b06a9d4e0040](https://luc-sydney-georges.medium.com/how-to-never-lose-your-stuff-again-pt-1-b06a9d4e0040)",359
662,662,Debugging Transformer based classification model for its behavior,"Hi,

I have fined tuned a based-based classification model. I want to understand why model predicting a certain tag. Are there any tools for checking this behavior or study  what's going on inside the hood.",https://www.reddit.com/r/LanguageTechnology/comments/lsx7te/debugging_transformer_based_classification_model/,LanguageTechnology,t3_lsx7te,"Debugging Transformer based classification model for its behavior Hi,

I have fined tuned a based-based classification model. I want to understand why model predicting a certain tag. Are there any tools for checking this behavior or study  what's going on inside the hood.",272
663,663,Is there a bare-bones text rank package for python?,"I'm working on an unsupervised summary extraction problem for an under-resourced language.

I would prefer to use an out-of-the-box solution in the following form - I provide sentence embeddings (e.g. using a trained BERT model), and the text rank package uses them to find the most relevant ones.

However, a google search made me realize that existing solutions mostly rely on popular packages, e.g. PyTextRank works on top of spacy, and when I run it I get an error that 'noun\_chunks' syntax iterator is not implemented for my language.

Any suggestions how to do it better?",https://www.reddit.com/r/LanguageTechnology/comments/lszpsn/is_there_a_barebones_text_rank_package_for_python/,LanguageTechnology,t3_lszpsn,"Is there a bare-bones text rank package for python? I'm working on an unsupervised summary extraction problem for an under-resourced language.

I would prefer to use an out-of-the-box solution in the following form - I provide sentence embeddings (e.g. using a trained BERT model), and the text rank package uses them to find the most relevant ones.

However, a google search made me realize that existing solutions mostly rely on popular packages, e.g. PyTextRank works on top of spacy, and when I run it I get an error that 'noun\_chunks' syntax iterator is not implemented for my language.

Any suggestions how to do it better?",630
664,664,[R] AAMAS 2021: A framework for integrating gesture generation models into interactive conversational agents,,https://youtu.be/jhgUBS0125A,LanguageTechnology,t3_lszl8y,[R] AAMAS 2021: A framework for integrating gesture generation models into interactive conversational agents ,109
665,665,"Want to extract semantic meaning from implied context and norms, I need direction of what to search for","I’m curious about determining semantic meaning in cases where context implies more than what is available in the sentence. 

For example: “I only wear that shirt because she gave it to me”. The implied meaning is that “I” don’t like the shirt. 

Is there any dataset or tool to extract these implied or norm based meanings? Thank you!",https://www.reddit.com/r/LanguageTechnology/comments/lstkqa/want_to_extract_semantic_meaning_from_implied/,LanguageTechnology,t3_lstkqa,"Want to extract semantic meaning from implied context and norms, I need direction of what to search for I’m curious about determining semantic meaning in cases where context implies more than what is available in the sentence. 

For example: “I only wear that shirt because she gave it to me”. The implied meaning is that “I” don’t like the shirt. 

Is there any dataset or tool to extract these implied or norm based meanings? Thank you!",438
666,666,Emotion extraction from subtitles of the movies,"Hi everyone, 

i'm trying to implement a system that from the subtitles of movies/tv series extracts emotion that film causes. I found dataset named DailyDialog that contain 103K sentences labelled with 6 based Ekman's emotion plus no\_emotion label.

I'm trying to use BERT and i reached an 85% of accuracy. The problem is that dataset is very unbalanced. I'm trying to use BERT for data augmentation using it as masked language modelling (MLM) for generate new sentences with new words that fit in the context of the sentence. For every sentence the data aug generates ten sencentes. The problem is  that the word outputed by BERT it is not sure it is conforms to the emotion of the sencente. I can try to see with SenticNet if the word is related to the emotion of sentence.

Another thing is that Bert immediately goes into overfitting.

\- Anyone have any suggestions if the project is feasible?  
\- Do you know any datasets related to the described task?  
\- Do you have any suggestions on how to do a good data augmentation?",https://www.reddit.com/r/LanguageTechnology/comments/lsygna/emotion_extraction_from_subtitles_of_the_movies/,LanguageTechnology,t3_lsygna,"Emotion extraction from subtitles of the movies Hi everyone, 

i'm trying to implement a system that from the subtitles of movies/tv series extracts emotion that film causes. I found dataset named DailyDialog that contain 103K sentences labelled with 6 based Ekman's emotion plus no\_emotion label.

I'm trying to use BERT and i reached an 85% of accuracy. The problem is that dataset is very unbalanced. I'm trying to use BERT for data augmentation using it as masked language modelling (MLM) for generate new sentences with new words that fit in the context of the sentence. For every sentence the data aug generates ten sencentes. The problem is  that the word outputed by BERT it is not sure it is conforms to the emotion of the sencente. I can try to see with SenticNet if the word is related to the emotion of sentence.

Another thing is that Bert immediately goes into overfitting.

\- Anyone have any suggestions if the project is feasible?  
\- Do you know any datasets related to the described task?  
\- Do you have any suggestions on how to do a good data augmentation?",1081
667,667,"Given the vast amount of unstructured data captured in e-Health Records, there's an immediate high demand for NLP to facilitate automatic extraction &amp; structuring of clinical data for decision support",,https://www.re-work.co/events/ai-in-healthcare-summit-2021?utm_source=LinkedIn&amp;utm_medium=Message&amp;utm_campaign=JM_Healthcare_2021,LanguageTechnology,t3_lsv8mc,"Given the vast amount of unstructured data captured in e-Health Records, there's an immediate high demand for NLP to facilitate automatic extraction &amp; structuring of clinical data for decision support ",205
668,668,"Train Multi-Lingual classifier for 100 languages in 1 Line, Hindi Word Embeddings, Bengali NER NYC/DC Meetup Webinar, in NLU 1.1.2","
## NLU 1.1.2 Release Notes

We are very happy to announce NLU 1.1.2 has been released with the integration of 30+ models and pipelines Bengali Named Entity Recognition, Hindi Word Embeddings,
and state-of-the-art transformer based OntoNotes models and pipelines from the [incredible Spark NLP 2.7.3 Release](https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.3) in addition to a few bugfixes.  
In addition to that, there is a [new NLU Webinar video](https://www.youtube.com/watch?t=2141&amp;v=hJR9m3NYnwk&amp;feature=youtu.be) showcasing in detail 
how to use NLU to analyze a crypto news dataset to extract keywords unsupervised and predict sentimential/emotional distributions of the dataset and much more!

### [Python's NLU library: 1,000+ models, 200+ Languages, State of the Art Accuracy, 1 Line of code - NLU NYC/DC NLP Meetup Webinar](https://www.youtube.com/watch?t=2141&amp;v=hJR9m3NYnwk&amp;feature=youtu.be)
Using just 1 line of Python code by leveraging the NLU library, which is powered by the award-winning Spark NLP.

This webinar covers, using live coding in real-time,
how to deliver summarization, translation, unsupervised keyword extraction, emotion analysis,
question answering, spell checking, named entity recognition, document classification, and other common NLP tasks. T
his is all done with a single line of code, that works directly on Python strings or pandas data frames.
Since NLU is based on Spark NLP, no code changes are required to scale processing to multi-core or cluster environment - integrating natively with Ray, Dask, or Spark data frames.

The recent releases for Spark NLP and NLU include pre-trained models for over 200 languages and language detection for 375 languages.
This includes 20 languages families; non-Latin alphabets; languages that do not use spaces for word segmentation like
Chinese, Japanese, and Korean; and languages written from right to left like Arabic, Farsi, Urdu, and Hebrew.
We'll also cover some of the algorithms and models that are included. The code notebooks will be freely available online.

 

### NLU 1.1.2 New Models  and Pipelines

#### NLU 1.1.2 New Non-English Models

|Language | nlu.load() reference | Spark NLP Model reference | Type |
|---------|---------------------|----------------------------|------|
|Bengali | [bn.ner](https://nlp.johnsnowlabs.com/2021/01/27/ner_jifs_glove_840B_300d_bn.html) |[ner_jifs_glove_840B_300d](https://nlp.johnsnowlabs.com/2021/01/27/ner_jifs_glove_840B_300d_bn.html) | Word Embeddings Model (Alias) |
| Bengali  | [bn.ner.glove](https://nlp.johnsnowlabs.com/2021/01/27/ner_jifs_glove_840B_300d_bn.html) | [ner_jifs_glove_840B_300d](https://nlp.johnsnowlabs.com/2021/01/27/ner_jifs_glove_840B_300d_bn.html) | Word Embeddings Model (Alias) |
|Hindi|[hi.embed](https://nlp.johnsnowlabs.com/2021/02/03/hindi_cc_300d_hi.html)|[hindi_cc_300d](https://nlp.johnsnowlabs.com/2021/02/03/hindi_cc_300d_hi.html)|NerDLModel|
|Bengali | [bn.lemma](https://nlp.johnsnowlabs.com/2021/01/20/lemma_bn.html) |[lemma](https://nlp.johnsnowlabs.com/2021/01/20/lemma_bn.html) | Lemmatizer                    |
|Japanese | [ja.lemma](https://nlp.johnsnowlabs.com/2021/01/15/lemma_ja.html) |[lemma](https://nlp.johnsnowlabs.com/2021/01/15/lemma_ja.html) | Lemmatizer                    |
|Bihari | [bh.lemma](https://nlp.johnsnowlabs.com/2021/01/18/lemma_bh.html) |[lemma](https://nlp.johnsnowlabs.com/2021/01/18/lemma_bh.html) | Lemma                    |
|Amharic | [am.lemma](https://nlp.johnsnowlabs.com/2021/01/20/lemma_am.html) |[lemma](https://nlp.johnsnowlabs.com/2021/01/20/lemma_am.html) | Lemma                    |

#### NLU 1.1.2 New English Models and Pipelines

|Language | nlu.load() reference | Spark NLP Model reference | Type |
|---------|---------------------|----------------------------|------|
| English | [en.ner.onto.bert.small_l2_128](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L2_128_en.html) |[onto_small_bert_L2_128](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L2_128_en.html)     | NerDLModel |
| English | [en.ner.onto.bert.small_l4_256](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L4_256_en.html) |[onto_small_bert_L4_256](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L4_256_en.html)     | NerDLModel |
| English | [en.ner.onto.bert.small_l4_512](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L4_512_en.html) |[onto_small_bert_L4_512](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L4_512_en.html)     | NerDLModel |
| English | [en.ner.onto.bert.small_l8_512](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L8_512_en.html) |[onto_small_bert_L8_512](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L8_512_en.html)     | NerDLModel |
| English | [en.ner.onto.bert.cased_base](https://nlp.johnsnowlabs.com/2020/12/05/onto_bert_base_cased_en.html) |[onto_bert_base_cased](https://nlp.johnsnowlabs.com/2020/12/05/onto_bert_base_cased_en.html)     | NerDLModel |
| English | [en.ner.onto.bert.cased_large](https://nlp.johnsnowlabs.com/2020/12/05/onto_bert_large_cased_en.html) |[onto_bert_large_cased](https://nlp.johnsnowlabs.com/2020/12/05/onto_bert_large_cased_en.html)     | NerDLModel |
| English | [en.ner.onto.electra.uncased_small](https://nlp.johnsnowlabs.com/2020/12/05/onto_electra_small_uncased_en.html) |[onto_electra_small_uncased](https://nlp.johnsnowlabs.com/2020/12/05/onto_electra_small_uncased_en.html)     | NerDLModel |
| English  | [en.ner.onto.electra.uncased_base](https://nlp.johnsnowlabs.com/2020/12/05/onto_electra_base_uncased_en.html) |[onto_electra_base_uncased](https://nlp.johnsnowlabs.com/2020/12/05/onto_electra_base_uncased_en.html)     | NerDLModel |
| English | [en.ner.onto.electra.uncased_large](https://nlp.johnsnowlabs.com/2020/12/05/onto_electra_large_uncased_en.html) |[onto_electra_large_uncased](https://nlp.johnsnowlabs.com/2020/12/05/onto_electra_large_uncased_en.html)     | NerDLModel |
| English | [en.ner.onto.bert.tiny](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_tiny_en.html) | [onto_recognize_entities_bert_tiny](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_tiny_en.html) | Pipeline |
| English | [en.ner.onto.bert.mini](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_mini_en.html) |[onto_recognize_entities_bert_mini](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_mini_en.html)     | Pipeline |
| English | [en.ner.onto.bert.small](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_small_en.html) | [onto_recognize_entities_bert_small](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_small_en.html) | Pipeline |
| English | [en.ner.onto.bert.medium](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_medium_en.html) |[onto_recognize_entities_bert_medium](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_medium_en.html)     | Pipeline |
| English | [en.ner.onto.bert.base](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_base_en.html) |[onto_recognize_entities_bert_base](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_base_en.html)     | Pipeline |
|English|[en.ner.onto.bert.large](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_large_en.html)|[onto_recognize_entities_bert_large](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_large_en.html)|Pipeline|
|English|[en.ner.onto.electra.small](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_small_en.html)|[onto_recognize_entities_electra_small](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_small_en.html)|Pipeline|
|English|[en.ner.onto.electra.base](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_base_en.html)|[onto_recognize_entities_electra_base](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_base_en.html)|Pipeline|
|English|[en.ner.onto.large](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_large_en.html)|[onto_recognize_entities_electra_large](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_large_en.html)|Pipeline|



### New Tutorials and Notebooks

- [NYC/DC NLP Meetup Webinar video analyze Crypto News, Unsupervised Keywords, Translate between 300 Languages, Question Answering, Summerization, POS, NER in 1 line of code in almost just 20 minutes](https://www.youtube.com/watch?t=2141&amp;v=hJR9m3NYnwk&amp;feature=youtu.be)
- [NLU basics POS/NER/Sentiment Classification/BERTology Embeddings](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/NYC_DC_NLP_MEETUP/0_liners_intro.ipynb)
- [Explore Crypto Newsarticle dataset, unsupervised Keyword extraction, Stemming, Emotion/Sentiment distribution Analysis](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/NYC_DC_NLP_MEETUP/1_NLU_base_features_on_dataset_with_YAKE_Lemma_Stemm_classifiers_NER_.ipynb)
- [Translate between more than 300 Languages in 1 line of code with the Marian Models](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/NYC_DC_NLP_MEETUP/2_multilingual_translation_with_marian.ipynb)
- [New NLU 1.1.2 Models Showcase Notebooks, Bengali NER, Hindi Embeddings, 30 new_models](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/release_notebooks/NLU1.1.2_Bengali_ner_Hindi_Embeddings_30_new_models.ipynb)


### NLU 1.1.2 Bug Fixes

- Fixed a bug that caused NER confidences not beeing extracted
- Fixed a bug that caused nlu.load('spell') to crash
- Fixed a bug that caused Uralic/Estonian/ET language models not to be loaded properly


### New  Easy NLU 1-liners in 1.1.2


#### [Named Entity Recognition for Bengali (GloVe 840B 300d)](https://nlp.johnsnowlabs.com/2021/01/27/ner_jifs_glove_840B_300d_bn.html)


```python
#Bengali for :  It began to be widely used in the United States in the early '90s.
nlu.load(""bn.ner"").predict(""৯০ এর দশকের শুরুর দিকে বৃহৎ আকারে মার্কিন যুক্তরাষ্ট্রে এর প্রয়োগের প্রক্রিয়া শুরু হয়'"")
```
output :

|   entities             | token     | Entities_classes   |   ner_confidence |
|:---------------------|:----------|:----------------------|-----------------:|
| ['মার্কিন যুক্তরাষ্ট্রে'] | ৯০        | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | এর        | ['LOC']               |           0.9999 |
| ['মার্কিন যুক্তরাষ্ট্রে'] | দশকের     | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | শুরুর       | ['LOC']               |           0.9969 |
| ['মার্কিন যুক্তরাষ্ট্রে'] | দিকে      | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | বৃহৎ       | ['LOC']               |           0.9994 |
| ['মার্কিন যুক্তরাষ্ট্রে'] | আকারে     | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | মার্কিন    | ['LOC']               |           0.9602 |
| ['মার্কিন যুক্তরাষ্ট্রে'] | যুক্তরাষ্ট্রে | ['LOC']               |           0.4134 |
| ['মার্কিন যুক্তরাষ্ট্রে'] | এর        | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | প্রয়োগের   | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | প্রক্রিয়া   | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | শুরু        | ['LOC']               |           0.9999 |
| ['মার্কিন যুক্তরাষ্ট্রে'] | হয়        | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | '         | ['LOC']               |           1      |


#### [Bengali Lemmatizer](https://nlp.johnsnowlabs.com/2021/01/20/lemma_bn.html)


```python
#Bengali for :  One morning in the marble-decorated building of Vaidyanatha, an obese monk was engaged in the enchantment of Duis and the milk service of one and a half Vaidyanatha. Give me two to eat
nlu.load(""bn.lemma"").predict(""একদিন প্রাতে বৈদ্যনাথের মার্বলমণ্ডিত দালানে একটি স্থূলোদর সন্ন্যাসী দুইসের মোহনভোগ এবং দেড়সের দুগ্ধ সেবায় নিযুক্ত আছে বৈদ্যনাথ গায়ে একখানি চাদর দিয়া জোড়করে একান্ত বিনীতভাবে ভূতলে বসিয়া ভক্তিভরে পবিত্র ভোজনব্যাপার নিরীক্ষণ করিতেছিলেন এমন সময় কোনোমতে দ্বারীদের দৃষ্টি এড়াইয়া জীর্ণদেহ বালক সহিত একটি অতি শীর্ণকায়া রমণী গৃহে প্রবেশ করিয়া ক্ষীণস্বরে কহিল বাবু দুটি খেতে দাও"")

```
output :

| lemma                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | document                                                                                                                                                                                                                                                                                                                                          |
|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| ['একদিন', 'প্রাতঃ', 'বৈদ্যনাথ', 'মার্বলমণ্ডিত', 'দালান', 'এক', 'স্থূলউদর', 'সন্ন্যাসী', 'দুইসের', 'মোহনভোগ', 'এবং', 'দেড়সের', 'দুগ্ধ', 'সেবা', 'নিযুক্ত', 'আছে', 'বৈদ্যনাথ', 'গা', 'একখান', 'চাদর', 'দেওয়া', 'জোড়কর', 'একান্ত', 'বিনীতভাব', 'ভূতল', 'বসা', 'ভক্তিভরা', 'পবিত্র', 'ভোজনব্যাপার', 'নিরীক্ষণ', 'করা', 'এমন', 'সময়', 'কোনোমত', 'দ্বারী', 'দৃষ্টি', 'এড়ানো', 'জীর্ণদেহ', 'বালক', 'সহিত', 'এক', 'অতি', 'শীর্ণকায়া', 'রমণী', 'গৃহ', 'প্রবেশ', 'বিশ্বাস', 'ক্ষীণস্বর', 'কহা', 'বাবু', 'দুই', 'খাওয়া', 'দাওয়া'] | একদিন প্রাতে বৈদ্যনাথের মার্বলমণ্ডিত দালানে একটি স্থূলোদর সন্ন্যাসী দুইসের মোহনভোগ এবং দেড়সের দুগ্ধ সেবায় নিযুক্ত আছে বৈদ্যনাথ গায়ে একখানি চাদর দিয়া জোড়করে একান্ত বিনীতভাবে ভূতলে বসিয়া ভক্তিভরে পবিত্র ভোজনব্যাপার নিরীক্ষণ করিতেছিলেন এমন সময় কোনোমতে দ্বারীদের দৃষ্টি এড়াইয়া জীর্ণদেহ বালক সহিত একটি অতি শীর্ণকায়া রমণী গৃহে প্রবেশ করিয়া ক্ষীণস্বরে কহিল বাবু দুটি খেতে দাও |


#### [Japanese Lemmatizer](https://nlp.johnsnowlabs.com/2021/01/15/lemma_ja.html)


```python
#Japanese for :  Some residents were uncomfortable with this, but it seems that no one is now openly protesting or protesting.
nlu.load(""ja.lemma"").predict(""これに不快感を示す住民はいましたが,現在,表立って反対や抗議の声を挙げている住民はいないようです。"")

```
output :

| lemma                                                                                                                                                                                                                                                          | document                                                                                         |
|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------|
| ['これ', 'にる', '不快', '感', 'を', '示す', '住民', 'はる', 'いる', 'まする', 'たる', 'がる', ',', '現在', ',', '表立つ', 'てる', '反対', 'やる', '抗議', 'のる', '声', 'を', '挙げる', 'てる', 'いる', '住民', 'はる', 'いる', 'なぐ', 'よう', 'です', '。'] | これに不快感を示す住民はいましたが,現在,表立って反対や抗議の声を挙げている住民はいないようです。 |

#### [Aharic Lemmatizer](https://nlp.johnsnowlabs.com/2021/01/20/lemma_am.html)


```python
#Aharic for :  Bookmark the permalink.
nlu.load(""am.lemma"").predict(""መጽሐፉን መጽሐፍ ኡ ን አስያዛት አስያዝ ኧ ኣት ።"")

```
output  :

| lemma                                                | document                         |
|:-----------------------------------------------------|:---------------------------------|
| ['_', 'መጽሐፍ', 'ኡ', 'ን', '_', 'አስያዝ', 'ኧ', 'ኣት', '።'] | መጽሐፉን መጽሐፍ ኡ ን አስያዛት አስያዝ ኧ ኣት ። |

#### [Bhojpuri Lemmatizer](https://nlp.johnsnowlabs.com/2021/01/18/lemma_bh.html)


```python
#Bhojpuri for : In this event, participation of World Bhojpuri Conference, Purvanchal Ekta Manch, Veer Kunwar Singh Foundation, Purvanchal Bhojpuri Mahasabha, and Herf - Media.
nlu.load(""bh.lemma"").predict(""एह आयोजन में विश्व भोजपुरी सम्मेलन , पूर्वांचल एकता मंच , वीर कुँवर सिंह फाउन्डेशन , पूर्वांचल भोजपुरी महासभा , अउर हर्फ - मीडिया के सहभागिता बा ।"")
```

output :

| lemma                                                                                                                                                                                                                               | document                                                                                                                      |
|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|
| ['एह', 'आयोजन', 'में', 'विश्व', 'भोजपुरी', 'सम्मेलन', 'COMMA', 'पूर्वांचल', 'एकता', 'मंच', 'COMMA', 'वीर', 'कुँवर', 'सिंह', 'फाउन्डेशन', 'COMMA', 'पूर्वांचल', 'भोजपुरी', 'महासभा', 'COMMA', 'अउर', 'हर्फ', '-', 'मीडिया', 'को', 'सहभागिता', 'बा', '।'] | एह आयोजन में विश्व भोजपुरी सम्मेलन , पूर्वांचल एकता मंच , वीर कुँवर सिंह फाउन्डेशन , पूर्वांचल भोजपुरी महासभा , अउर हर्फ - मीडिया के सहभागिता बा । |

#### [Named Entity Recognition - BERT Tiny (OntoNotes)](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L2_128_en.html)
```python
nlu.load(""en.ner.onto.bert.small_l2_128"").predict(""""""William Henry Gates III (born October 28, 1955) is an American business magnate,
 software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft,
  Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect,
   while also being the largest individual shareholder until May 2014.
    He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico;
     it went on to become the world's largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect.
     During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time
      role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000.
 He gradually transferred his duties to Ray Ozzie and Craig Mundie.
  He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella."""""",output_level = ""document"")
```

output  :

| ner_confidence | entities | Entities_classes                                          |
| :------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| [0.8536999821662903, 0.7195000052452087, 0.746...] | ['PERSON', 'DATE', 'NORP', 'ORG', 'ORG', 'PERSON', 'DATE', 'CARDINAL', 'DATE', 'DATE', 'GPE', 'GPE', 'PERSON', 'DATE', 'GPE', 'GPE'] | ['William Henry Gates III', 'October 28, 1955', 'American', 'Microsoft Corporation', 'Microsoft', 'Gates', 'May 2014', 'one', '1970s', '1980s', 'Seattle', 'Washington', 'Paul Allen', '1975', 'Albuquerque', 'New Mexico'] |

####  [Named Entity Recognition - BERT Mini (OntoNotes)](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L4_256_en.html)
```python
nlu.load(""en.ner.onto.bert.small_l4_256"").predict(""""""William Henry Gates III (born October 28, 1955) is an American business magnate,
 software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft,
  Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect,
   while also being the largest individual shareholder until May 2014.
    He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico;
     it went on to become the world's largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect.
     During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time
      role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000.
 He gradually transferred his duties to Ray Ozzie and Craig Mundie.
  He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella."""""",output_level = ""document"")
```

output :

|  ner_confidence	  | entities                                                                                                                                                                                                                                           | Entities_classes                                                                                                                     |
|---------------:|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------|
|          [0.835099995136261, 0.40450000762939453, 0.331...] | ['William Henry Gates III', 'October 28, 1955', 'American', 'Microsoft Corporation', 'Microsoft', 'Gates', 'May 2014', 'one', '1970s and 1980s', 'Seattle', 'Washington', 'Gates', 'Microsoft', 'Paul Allen', '1975', 'Albuquerque', 'New Mexico'] | ['PERSON', 'DATE', 'NORP', 'ORG', 'ORG', 'ORG', 'DATE', 'CARDINAL', 'DATE', 'GPE', 'GPE', 'ORG', 'ORG', 'PERSON', 'DATE', 'GPE', 'GPE'] |




#### [Named Entity Recognition - BERT Small (OntoNotes)](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L4_512_en.html)

```python
nlu.load(""en.ner.onto.bert.small_l4_512"").predict(""""""William Henry Gates III (born October 28, 1955) is an American business magnate,
 software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft,
  Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect,
   while also being the largest individual shareholder until May 2014.
    He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico;
     it went on to become the world's largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect.
     During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time
      role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000.
 He gradually transferred his duties to Ray Ozzie and Craig Mundie.
  He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella."""""",output_level = ""document"")
```
output :

|   ner_confidence | entities                                                                                                                                                                                                                                               | Entities_classes                                                                                                                           |
|---------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------|
|              [0.964900016784668, 0.8299000263214111, 0.9607...]| ['William Henry Gates III', 'October 28, 1955', 'American', 'Microsoft Corporation', 'Microsoft', 'Gates', 'May 2014', 'one', 'the 1970s and 1980s', 'Seattle', 'Washington', 'Gates', 'Microsoft', 'Paul Allen', '1975', 'Albuquerque', 'New Mexico'] | ['PERSON', 'DATE', 'NORP', 'ORG', 'ORG', 'PERSON', 'DATE', 'CARDINAL', 'DATE', 'GPE', 'GPE', 'PERSON', 'ORG', 'PERSON', 'DATE', 'GPE', 'GPE'] |


#### [Named Entity Recognition - BERT Medium (OntoNotes)](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L8_512_en.html)

```python
nlu.load(""en.ner.onto.bert.small_l8_512"").predict(""""""William Henry Gates III (born October 28, 1955) is an American business magnate,
 software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft,
  Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect,
   while also being the largest individual shareholder until May 2014.
    He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico;
     it went on to become the world's largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect.
     During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time
      role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000.
 He gradually transferred his duties to Ray Ozzie and Craig Mundie.
  He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella."""""",output_level = ""document"")
```
output :

| ner_confidence   | entities                                                                                                                                                                                                                           | Entities_classes                                                                                                        |
|---------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------|
|        [0.916700005531311, 0.5873000025749207, 0.8816...] | ['William Henry Gates III', 'October 28, 1955', 'American', 'Microsoft Corporation', 'Microsoft', 'Gates', 'May 2014', 'the 1970s and 1980s', 'Seattle', 'Washington', 'Gates', 'Paul Allen', '1975', 'Albuquerque', 'New Mexico'] | ['PERSON', 'DATE', 'NORP', 'ORG', 'ORG', 'PERSON', 'DATE', 'DATE', 'GPE', 'GPE', 'PERSON', 'PERSON', 'DATE', 'GPE', 'GPE'] |



#### [Named Entity Recognition - BERT Base (OntoNotes)](https://nlp.johnsnowlabs.com/2020/12/05/onto_bert_base_cased_en.html)

```python
nlu.load(""en.ner.onto.bert.cased_base"").predict(""""""William Henry Gates III (born October 28, 1955) is an American business magnate,
 software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft,
  Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect,
   while also being the largest individual shareholder until May 2014.
    He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico;
     it went on to become the world's largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect.
     During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time
      role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000.
 He gradually transferred his duties to Ray Ozzie and Craig Mundie.
  He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella."""""",output_level = ""document"")
```
output :

|   ner_confidence | entities                                                                                                                                                                                                                                               | Entities_classes                                                                                                                           |
|---------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------|
|              [0.504800021648407, 0.47290000319480896, 0.462...] | ['William Henry Gates III', 'October 28, 1955', 'American', 'Microsoft Corporation', 'Microsoft', 'Gates', 'May 2014', 'one', 'the 1970s and 1980s', 'Seattle', 'Washington', 'Gates', 'Microsoft', 'Paul Allen', '1975', 'Albuquerque', 'New Mexico'] | ['PERSON', 'DATE', 'NORP', 'ORG', 'ORG', 'PERSON', 'DATE', 'CARDINAL', 'DATE', 'GPE', 'GPE', 'PERSON', 'ORG', 'PERSON', 'DATE', 'GPE', 'GPE'] |





### NLU Installation

```bash
# PyPi
!pip install nlu pyspark==2.4.7
#Conda
# Install NLU from Anaconda/Conda
conda install -c johnsnowlabs nlu
```

### Additional NLU ressources
- [NLU Website](https://nlu.johnsnowlabs.com/)
- [All NLU Tutorial Notebooks](https://nlu.johnsnowlabs.com/docs/en/notebooks)
- [NLU Videos and Blogposts on NLU](https://nlp.johnsnowlabs.com/learn#pythons-nlu-library)
- [NLU on Github](https://github.com/JohnSnowLabs/nlu)",https://www.reddit.com/r/LanguageTechnology/comments/lsckqc/train_multilingual_classifier_for_100_languages/,LanguageTechnology,t3_lsckqc,"Train Multi-Lingual classifier for 100 languages in 1 Line, Hindi Word Embeddings, Bengali NER NYC/DC Meetup Webinar, in NLU 1.1.2 
## NLU 1.1.2 Release Notes

We are very happy to announce NLU 1.1.2 has been released with the integration of 30+ models and pipelines Bengali Named Entity Recognition, Hindi Word Embeddings,
and state-of-the-art transformer based OntoNotes models and pipelines from the [incredible Spark NLP 2.7.3 Release](https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.3) in addition to a few bugfixes.  
In addition to that, there is a [new NLU Webinar video](https://www.youtube.com/watch?t=2141&amp;v=hJR9m3NYnwk&amp;feature=youtu.be) showcasing in detail 
how to use NLU to analyze a crypto news dataset to extract keywords unsupervised and predict sentimential/emotional distributions of the dataset and much more!

### [Python's NLU library: 1,000+ models, 200+ Languages, State of the Art Accuracy, 1 Line of code - NLU NYC/DC NLP Meetup Webinar](https://www.youtube.com/watch?t=2141&amp;v=hJR9m3NYnwk&amp;feature=youtu.be)
Using just 1 line of Python code by leveraging the NLU library, which is powered by the award-winning Spark NLP.

This webinar covers, using live coding in real-time,
how to deliver summarization, translation, unsupervised keyword extraction, emotion analysis,
question answering, spell checking, named entity recognition, document classification, and other common NLP tasks. T
his is all done with a single line of code, that works directly on Python strings or pandas data frames.
Since NLU is based on Spark NLP, no code changes are required to scale processing to multi-core or cluster environment - integrating natively with Ray, Dask, or Spark data frames.

The recent releases for Spark NLP and NLU include pre-trained models for over 200 languages and language detection for 375 languages.
This includes 20 languages families; non-Latin alphabets; languages that do not use spaces for word segmentation like
Chinese, Japanese, and Korean; and languages written from right to left like Arabic, Farsi, Urdu, and Hebrew.
We'll also cover some of the algorithms and models that are included. The code notebooks will be freely available online.

 

### NLU 1.1.2 New Models  and Pipelines

#### NLU 1.1.2 New Non-English Models

|Language | nlu.load() reference | Spark NLP Model reference | Type |
|---------|---------------------|----------------------------|------|
|Bengali | [bn.ner](https://nlp.johnsnowlabs.com/2021/01/27/ner_jifs_glove_840B_300d_bn.html) |[ner_jifs_glove_840B_300d](https://nlp.johnsnowlabs.com/2021/01/27/ner_jifs_glove_840B_300d_bn.html) | Word Embeddings Model (Alias) |
| Bengali  | [bn.ner.glove](https://nlp.johnsnowlabs.com/2021/01/27/ner_jifs_glove_840B_300d_bn.html) | [ner_jifs_glove_840B_300d](https://nlp.johnsnowlabs.com/2021/01/27/ner_jifs_glove_840B_300d_bn.html) | Word Embeddings Model (Alias) |
|Hindi|[hi.embed](https://nlp.johnsnowlabs.com/2021/02/03/hindi_cc_300d_hi.html)|[hindi_cc_300d](https://nlp.johnsnowlabs.com/2021/02/03/hindi_cc_300d_hi.html)|NerDLModel|
|Bengali | [bn.lemma](https://nlp.johnsnowlabs.com/2021/01/20/lemma_bn.html) |[lemma](https://nlp.johnsnowlabs.com/2021/01/20/lemma_bn.html) | Lemmatizer                    |
|Japanese | [ja.lemma](https://nlp.johnsnowlabs.com/2021/01/15/lemma_ja.html) |[lemma](https://nlp.johnsnowlabs.com/2021/01/15/lemma_ja.html) | Lemmatizer                    |
|Bihari | [bh.lemma](https://nlp.johnsnowlabs.com/2021/01/18/lemma_bh.html) |[lemma](https://nlp.johnsnowlabs.com/2021/01/18/lemma_bh.html) | Lemma                    |
|Amharic | [am.lemma](https://nlp.johnsnowlabs.com/2021/01/20/lemma_am.html) |[lemma](https://nlp.johnsnowlabs.com/2021/01/20/lemma_am.html) | Lemma                    |

#### NLU 1.1.2 New English Models and Pipelines

|Language | nlu.load() reference | Spark NLP Model reference | Type |
|---------|---------------------|----------------------------|------|
| English | [en.ner.onto.bert.small_l2_128](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L2_128_en.html) |[onto_small_bert_L2_128](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L2_128_en.html)     | NerDLModel |
| English | [en.ner.onto.bert.small_l4_256](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L4_256_en.html) |[onto_small_bert_L4_256](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L4_256_en.html)     | NerDLModel |
| English | [en.ner.onto.bert.small_l4_512](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L4_512_en.html) |[onto_small_bert_L4_512](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L4_512_en.html)     | NerDLModel |
| English | [en.ner.onto.bert.small_l8_512](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L8_512_en.html) |[onto_small_bert_L8_512](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L8_512_en.html)     | NerDLModel |
| English | [en.ner.onto.bert.cased_base](https://nlp.johnsnowlabs.com/2020/12/05/onto_bert_base_cased_en.html) |[onto_bert_base_cased](https://nlp.johnsnowlabs.com/2020/12/05/onto_bert_base_cased_en.html)     | NerDLModel |
| English | [en.ner.onto.bert.cased_large](https://nlp.johnsnowlabs.com/2020/12/05/onto_bert_large_cased_en.html) |[onto_bert_large_cased](https://nlp.johnsnowlabs.com/2020/12/05/onto_bert_large_cased_en.html)     | NerDLModel |
| English | [en.ner.onto.electra.uncased_small](https://nlp.johnsnowlabs.com/2020/12/05/onto_electra_small_uncased_en.html) |[onto_electra_small_uncased](https://nlp.johnsnowlabs.com/2020/12/05/onto_electra_small_uncased_en.html)     | NerDLModel |
| English  | [en.ner.onto.electra.uncased_base](https://nlp.johnsnowlabs.com/2020/12/05/onto_electra_base_uncased_en.html) |[onto_electra_base_uncased](https://nlp.johnsnowlabs.com/2020/12/05/onto_electra_base_uncased_en.html)     | NerDLModel |
| English | [en.ner.onto.electra.uncased_large](https://nlp.johnsnowlabs.com/2020/12/05/onto_electra_large_uncased_en.html) |[onto_electra_large_uncased](https://nlp.johnsnowlabs.com/2020/12/05/onto_electra_large_uncased_en.html)     | NerDLModel |
| English | [en.ner.onto.bert.tiny](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_tiny_en.html) | [onto_recognize_entities_bert_tiny](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_tiny_en.html) | Pipeline |
| English | [en.ner.onto.bert.mini](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_mini_en.html) |[onto_recognize_entities_bert_mini](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_mini_en.html)     | Pipeline |
| English | [en.ner.onto.bert.small](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_small_en.html) | [onto_recognize_entities_bert_small](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_small_en.html) | Pipeline |
| English | [en.ner.onto.bert.medium](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_medium_en.html) |[onto_recognize_entities_bert_medium](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_medium_en.html)     | Pipeline |
| English | [en.ner.onto.bert.base](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_base_en.html) |[onto_recognize_entities_bert_base](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_base_en.html)     | Pipeline |
|English|[en.ner.onto.bert.large](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_large_en.html)|[onto_recognize_entities_bert_large](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_bert_large_en.html)|Pipeline|
|English|[en.ner.onto.electra.small](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_small_en.html)|[onto_recognize_entities_electra_small](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_small_en.html)|Pipeline|
|English|[en.ner.onto.electra.base](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_base_en.html)|[onto_recognize_entities_electra_base](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_base_en.html)|Pipeline|
|English|[en.ner.onto.large](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_large_en.html)|[onto_recognize_entities_electra_large](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_large_en.html)|Pipeline|



### New Tutorials and Notebooks

- [NYC/DC NLP Meetup Webinar video analyze Crypto News, Unsupervised Keywords, Translate between 300 Languages, Question Answering, Summerization, POS, NER in 1 line of code in almost just 20 minutes](https://www.youtube.com/watch?t=2141&amp;v=hJR9m3NYnwk&amp;feature=youtu.be)
- [NLU basics POS/NER/Sentiment Classification/BERTology Embeddings](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/NYC_DC_NLP_MEETUP/0_liners_intro.ipynb)
- [Explore Crypto Newsarticle dataset, unsupervised Keyword extraction, Stemming, Emotion/Sentiment distribution Analysis](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/NYC_DC_NLP_MEETUP/1_NLU_base_features_on_dataset_with_YAKE_Lemma_Stemm_classifiers_NER_.ipynb)
- [Translate between more than 300 Languages in 1 line of code with the Marian Models](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/NYC_DC_NLP_MEETUP/2_multilingual_translation_with_marian.ipynb)
- [New NLU 1.1.2 Models Showcase Notebooks, Bengali NER, Hindi Embeddings, 30 new_models](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/release_notebooks/NLU1.1.2_Bengali_ner_Hindi_Embeddings_30_new_models.ipynb)


### NLU 1.1.2 Bug Fixes

- Fixed a bug that caused NER confidences not beeing extracted
- Fixed a bug that caused nlu.load('spell') to crash
- Fixed a bug that caused Uralic/Estonian/ET language models not to be loaded properly


### New  Easy NLU 1-liners in 1.1.2


#### [Named Entity Recognition for Bengali (GloVe 840B 300d)](https://nlp.johnsnowlabs.com/2021/01/27/ner_jifs_glove_840B_300d_bn.html)


```python
#Bengali for :  It began to be widely used in the United States in the early '90s.
nlu.load(""bn.ner"").predict(""৯০ এর দশকের শুরুর দিকে বৃহৎ আকারে মার্কিন যুক্তরাষ্ট্রে এর প্রয়োগের প্রক্রিয়া শুরু হয়'"")
```
output :

|   entities             | token     | Entities_classes   |   ner_confidence |
|:---------------------|:----------|:----------------------|-----------------:|
| ['মার্কিন যুক্তরাষ্ট্রে'] | ৯০        | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | এর        | ['LOC']               |           0.9999 |
| ['মার্কিন যুক্তরাষ্ট্রে'] | দশকের     | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | শুরুর       | ['LOC']               |           0.9969 |
| ['মার্কিন যুক্তরাষ্ট্রে'] | দিকে      | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | বৃহৎ       | ['LOC']               |           0.9994 |
| ['মার্কিন যুক্তরাষ্ট্রে'] | আকারে     | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | মার্কিন    | ['LOC']               |           0.9602 |
| ['মার্কিন যুক্তরাষ্ট্রে'] | যুক্তরাষ্ট্রে | ['LOC']               |           0.4134 |
| ['মার্কিন যুক্তরাষ্ট্রে'] | এর        | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | প্রয়োগের   | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | প্রক্রিয়া   | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | শুরু        | ['LOC']               |           0.9999 |
| ['মার্কিন যুক্তরাষ্ট্রে'] | হয়        | ['LOC']               |           1      |
| ['মার্কিন যুক্তরাষ্ট্রে'] | '         | ['LOC']               |           1      |


#### [Bengali Lemmatizer](https://nlp.johnsnowlabs.com/2021/01/20/lemma_bn.html)


```python
#Bengali for :  One morning in the marble-decorated building of Vaidyanatha, an obese monk was engaged in the enchantment of Duis and the milk service of one and a half Vaidyanatha. Give me two to eat
nlu.load(""bn.lemma"").predict(""একদিন প্রাতে বৈদ্যনাথের মার্বলমণ্ডিত দালানে একটি স্থূলোদর সন্ন্যাসী দুইসের মোহনভোগ এবং দেড়সের দুগ্ধ সেবায় নিযুক্ত আছে বৈদ্যনাথ গায়ে একখানি চাদর দিয়া জোড়করে একান্ত বিনীতভাবে ভূতলে বসিয়া ভক্তিভরে পবিত্র ভোজনব্যাপার নিরীক্ষণ করিতেছিলেন এমন সময় কোনোমতে দ্বারীদের দৃষ্টি এড়াইয়া জীর্ণদেহ বালক সহিত একটি অতি শীর্ণকায়া রমণী গৃহে প্রবেশ করিয়া ক্ষীণস্বরে কহিল বাবু দুটি খেতে দাও"")

```
output :

| lemma                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | document                                                                                                                                                                                                                                                                                                                                          |
|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| ['একদিন', 'প্রাতঃ', 'বৈদ্যনাথ', 'মার্বলমণ্ডিত', 'দালান', 'এক', 'স্থূলউদর', 'সন্ন্যাসী', 'দুইসের', 'মোহনভোগ', 'এবং', 'দেড়সের', 'দুগ্ধ', 'সেবা', 'নিযুক্ত', 'আছে', 'বৈদ্যনাথ', 'গা', 'একখান', 'চাদর', 'দেওয়া', 'জোড়কর', 'একান্ত', 'বিনীতভাব', 'ভূতল', 'বসা', 'ভক্তিভরা', 'পবিত্র', 'ভোজনব্যাপার', 'নিরীক্ষণ', 'করা', 'এমন', 'সময়', 'কোনোমত', 'দ্বারী', 'দৃষ্টি', 'এড়ানো', 'জীর্ণদেহ', 'বালক', 'সহিত', 'এক', 'অতি', 'শীর্ণকায়া', 'রমণী', 'গৃহ', 'প্রবেশ', 'বিশ্বাস', 'ক্ষীণস্বর', 'কহা', 'বাবু', 'দুই', 'খাওয়া', 'দাওয়া'] | একদিন প্রাতে বৈদ্যনাথের মার্বলমণ্ডিত দালানে একটি স্থূলোদর সন্ন্যাসী দুইসের মোহনভোগ এবং দেড়সের দুগ্ধ সেবায় নিযুক্ত আছে বৈদ্যনাথ গায়ে একখানি চাদর দিয়া জোড়করে একান্ত বিনীতভাবে ভূতলে বসিয়া ভক্তিভরে পবিত্র ভোজনব্যাপার নিরীক্ষণ করিতেছিলেন এমন সময় কোনোমতে দ্বারীদের দৃষ্টি এড়াইয়া জীর্ণদেহ বালক সহিত একটি অতি শীর্ণকায়া রমণী গৃহে প্রবেশ করিয়া ক্ষীণস্বরে কহিল বাবু দুটি খেতে দাও |


#### [Japanese Lemmatizer](https://nlp.johnsnowlabs.com/2021/01/15/lemma_ja.html)


```python
#Japanese for :  Some residents were uncomfortable with this, but it seems that no one is now openly protesting or protesting.
nlu.load(""ja.lemma"").predict(""これに不快感を示す住民はいましたが,現在,表立って反対や抗議の声を挙げている住民はいないようです。"")

```
output :

| lemma                                                                                                                                                                                                                                                          | document                                                                                         |
|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------|
| ['これ', 'にる', '不快', '感', 'を', '示す', '住民', 'はる', 'いる', 'まする', 'たる', 'がる', ',', '現在', ',', '表立つ', 'てる', '反対', 'やる', '抗議', 'のる', '声', 'を', '挙げる', 'てる', 'いる', '住民', 'はる', 'いる', 'なぐ', 'よう', 'です', '。'] | これに不快感を示す住民はいましたが,現在,表立って反対や抗議の声を挙げている住民はいないようです。 |

#### [Aharic Lemmatizer](https://nlp.johnsnowlabs.com/2021/01/20/lemma_am.html)


```python
#Aharic for :  Bookmark the permalink.
nlu.load(""am.lemma"").predict(""መጽሐፉን መጽሐፍ ኡ ን አስያዛት አስያዝ ኧ ኣት ።"")

```
output  :

| lemma                                                | document                         |
|:-----------------------------------------------------|:---------------------------------|
| ['_', 'መጽሐፍ', 'ኡ', 'ን', '_', 'አስያዝ', 'ኧ', 'ኣት', '።'] | መጽሐፉን መጽሐፍ ኡ ን አስያዛት አስያዝ ኧ ኣት ። |

#### [Bhojpuri Lemmatizer](https://nlp.johnsnowlabs.com/2021/01/18/lemma_bh.html)


```python
#Bhojpuri for : In this event, participation of World Bhojpuri Conference, Purvanchal Ekta Manch, Veer Kunwar Singh Foundation, Purvanchal Bhojpuri Mahasabha, and Herf - Media.
nlu.load(""bh.lemma"").predict(""एह आयोजन में विश्व भोजपुरी सम्मेलन , पूर्वांचल एकता मंच , वीर कुँवर सिंह फाउन्डेशन , पूर्वांचल भोजपुरी महासभा , अउर हर्फ - मीडिया के सहभागिता बा ।"")
```

output :

| lemma                                                                                                                                                                                                                               | document                                                                                                                      |
|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|
| ['एह', 'आयोजन', 'में', 'विश्व', 'भोजपुरी', 'सम्मेलन', 'COMMA', 'पूर्वांचल', 'एकता', 'मंच', 'COMMA', 'वीर', 'कुँवर', 'सिंह', 'फाउन्डेशन', 'COMMA', 'पूर्वांचल', 'भोजपुरी', 'महासभा', 'COMMA', 'अउर', 'हर्फ', '-', 'मीडिया', 'को', 'सहभागिता', 'बा', '।'] | एह आयोजन में विश्व भोजपुरी सम्मेलन , पूर्वांचल एकता मंच , वीर कुँवर सिंह फाउन्डेशन , पूर्वांचल भोजपुरी महासभा , अउर हर्फ - मीडिया के सहभागिता बा । |

#### [Named Entity Recognition - BERT Tiny (OntoNotes)](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L2_128_en.html)
```python
nlu.load(""en.ner.onto.bert.small_l2_128"").predict(""""""William Henry Gates III (born October 28, 1955) is an American business magnate,
 software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft,
  Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect,
   while also being the largest individual shareholder until May 2014.
    He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico;
     it went on to become the world's largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect.
     During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time
      role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000.
 He gradually transferred his duties to Ray Ozzie and Craig Mundie.
  He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella."""""",output_level = ""document"")
```

output  :

| ner_confidence | entities | Entities_classes                                          |
| :------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| [0.8536999821662903, 0.7195000052452087, 0.746...] | ['PERSON', 'DATE', 'NORP', 'ORG', 'ORG', 'PERSON', 'DATE', 'CARDINAL', 'DATE', 'DATE', 'GPE', 'GPE', 'PERSON', 'DATE', 'GPE', 'GPE'] | ['William Henry Gates III', 'October 28, 1955', 'American', 'Microsoft Corporation', 'Microsoft', 'Gates', 'May 2014', 'one', '1970s', '1980s', 'Seattle', 'Washington', 'Paul Allen', '1975', 'Albuquerque', 'New Mexico'] |

####  [Named Entity Recognition - BERT Mini (OntoNotes)](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L4_256_en.html)
```python
nlu.load(""en.ner.onto.bert.small_l4_256"").predict(""""""William Henry Gates III (born October 28, 1955) is an American business magnate,
 software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft,
  Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect,
   while also being the largest individual shareholder until May 2014.
    He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico;
     it went on to become the world's largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect.
     During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time
      role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000.
 He gradually transferred his duties to Ray Ozzie and Craig Mundie.
  He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella."""""",output_level = ""document"")
```

output :

|  ner_confidence	  | entities                                                                                                                                                                                                                                           | Entities_classes                                                                                                                     |
|---------------:|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------|
|          [0.835099995136261, 0.40450000762939453, 0.331...] | ['William Henry Gates III', 'October 28, 1955', 'American', 'Microsoft Corporation', 'Microsoft', 'Gates', 'May 2014', 'one', '1970s and 1980s', 'Seattle', 'Washington', 'Gates', 'Microsoft', 'Paul Allen', '1975', 'Albuquerque', 'New Mexico'] | ['PERSON', 'DATE', 'NORP', 'ORG', 'ORG', 'ORG', 'DATE', 'CARDINAL', 'DATE', 'GPE', 'GPE', 'ORG', 'ORG', 'PERSON', 'DATE', 'GPE', 'GPE'] |




#### [Named Entity Recognition - BERT Small (OntoNotes)](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L4_512_en.html)

```python
nlu.load(""en.ner.onto.bert.small_l4_512"").predict(""""""William Henry Gates III (born October 28, 1955) is an American business magnate,
 software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft,
  Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect,
   while also being the largest individual shareholder until May 2014.
    He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico;
     it went on to become the world's largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect.
     During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time
      role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000.
 He gradually transferred his duties to Ray Ozzie and Craig Mundie.
  He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella."""""",output_level = ""document"")
```
output :

|   ner_confidence | entities                                                                                                                                                                                                                                               | Entities_classes                                                                                                                           |
|---------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------|
|              [0.964900016784668, 0.8299000263214111, 0.9607...]| ['William Henry Gates III', 'October 28, 1955', 'American', 'Microsoft Corporation', 'Microsoft', 'Gates', 'May 2014', 'one', 'the 1970s and 1980s', 'Seattle', 'Washington', 'Gates', 'Microsoft', 'Paul Allen', '1975', 'Albuquerque', 'New Mexico'] | ['PERSON', 'DATE', 'NORP', 'ORG', 'ORG', 'PERSON', 'DATE', 'CARDINAL', 'DATE', 'GPE', 'GPE', 'PERSON', 'ORG', 'PERSON', 'DATE', 'GPE', 'GPE'] |


#### [Named Entity Recognition - BERT Medium (OntoNotes)](https://nlp.johnsnowlabs.com/2020/12/05/onto_small_bert_L8_512_en.html)

```python
nlu.load(""en.ner.onto.bert.small_l8_512"").predict(""""""William Henry Gates III (born October 28, 1955) is an American business magnate,
 software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft,
  Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect,
   while also being the largest individual shareholder until May 2014.
    He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico;
     it went on to become the world's largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect.
     During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time
      role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000.
 He gradually transferred his duties to Ray Ozzie and Craig Mundie.
  He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella."""""",output_level = ""document"")
```
output :

| ner_confidence   | entities                                                                                                                                                                                                                           | Entities_classes                                                                                                        |
|---------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------|
|        [0.916700005531311, 0.5873000025749207, 0.8816...] | ['William Henry Gates III', 'October 28, 1955', 'American', 'Microsoft Corporation', 'Microsoft', 'Gates', 'May 2014', 'the 1970s and 1980s', 'Seattle', 'Washington', 'Gates', 'Paul Allen', '1975', 'Albuquerque', 'New Mexico'] | ['PERSON', 'DATE', 'NORP', 'ORG', 'ORG', 'PERSON', 'DATE', 'DATE', 'GPE', 'GPE', 'PERSON', 'PERSON', 'DATE', 'GPE', 'GPE'] |



#### [Named Entity Recognition - BERT Base (OntoNotes)](https://nlp.johnsnowlabs.com/2020/12/05/onto_bert_base_cased_en.html)

```python
nlu.load(""en.ner.onto.bert.cased_base"").predict(""""""William Henry Gates III (born October 28, 1955) is an American business magnate,
 software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft,
  Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect,
   while also being the largest individual shareholder until May 2014.
    He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico;
     it went on to become the world's largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect.
     During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time
      role at Microsoft and full-time work at the Bill &amp; Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000.
 He gradually transferred his duties to Ray Ozzie and Craig Mundie.
  He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella."""""",output_level = ""document"")
```
output :

|   ner_confidence | entities                                                                                                                                                                                                                                               | Entities_classes                                                                                                                           |
|---------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------|
|              [0.504800021648407, 0.47290000319480896, 0.462...] | ['William Henry Gates III', 'October 28, 1955', 'American', 'Microsoft Corporation', 'Microsoft', 'Gates', 'May 2014', 'one', 'the 1970s and 1980s', 'Seattle', 'Washington', 'Gates', 'Microsoft', 'Paul Allen', '1975', 'Albuquerque', 'New Mexico'] | ['PERSON', 'DATE', 'NORP', 'ORG', 'ORG', 'PERSON', 'DATE', 'CARDINAL', 'DATE', 'GPE', 'GPE', 'PERSON', 'ORG', 'PERSON', 'DATE', 'GPE', 'GPE'] |





### NLU Installation

```bash
# PyPi
!pip install nlu pyspark==2.4.7
#Conda
# Install NLU from Anaconda/Conda
conda install -c johnsnowlabs nlu
```

### Additional NLU ressources
- [NLU Website](https://nlu.johnsnowlabs.com/)
- [All NLU Tutorial Notebooks](https://nlu.johnsnowlabs.com/docs/en/notebooks)
- [NLU Videos and Blogposts on NLU](https://nlp.johnsnowlabs.com/learn#pythons-nlu-library)
- [NLU on Github](https://github.com/JohnSnowLabs/nlu)",33401
669,669,"OpenAI has released the paper associated with DALL-E: ""Zero-Shot Text-to-Image Generation""",,https://arxiv.org/abs/2102.12092,LanguageTechnology,t3_lrxmgl,"OpenAI has released the paper associated with DALL-E: ""Zero-Shot Text-to-Image Generation"" ",91
670,670,MBart Language Translation (English to Multilanguage) using Hugging Face,,https://youtu.be/oO7k5lH8Oe8,LanguageTechnology,t3_lsdh5m,MBart Language Translation (English to Multilanguage) using Hugging Face ,73
671,671,Retrain GPT-2 model with tensorflow2,"I was trying to catch up with transformer and gpt-2 implementation detail. So I have created some scripts to support retraining gpt-2 model using tensorflow2: [https://github.com/wenxichen/gpt-2](https://github.com/wenxichen/gpt-2)

Have fun!",https://www.reddit.com/r/LanguageTechnology/comments/ls3tqc/retrain_gpt2_model_with_tensorflow2/,LanguageTechnology,t3_ls3tqc,"Retrain GPT-2 model with tensorflow2 I was trying to catch up with transformer and gpt-2 implementation detail. So I have created some scripts to support retraining gpt-2 model using tensorflow2: [https://github.com/wenxichen/gpt-2](https://github.com/wenxichen/gpt-2)

Have fun!",279
672,672,How do you make a model for gender recognition of speech in an audio file?,"I have short audio segments, lasting 5-10 seconds each, of a single speaker speaking a single sentence. I need gender recognition on this. I need an algorithm that I feed an audio file into, and it spit out a result of if this is a male speaker, or this is a female speaker. And I need to run this on tens of thousands of audio files in a dataset.

How do I do this? What features do I use to determine this? Do I need machine learning or can I use some fixed numbers to figure it out? How do I access these stats/numbers that I need to figure this out?",https://www.reddit.com/r/LanguageTechnology/comments/lsapbl/how_do_you_make_a_model_for_gender_recognition_of/,LanguageTechnology,t3_lsapbl,"How do you make a model for gender recognition of speech in an audio file? I have short audio segments, lasting 5-10 seconds each, of a single speaker speaking a single sentence. I need gender recognition on this. I need an algorithm that I feed an audio file into, and it spit out a result of if this is a male speaker, or this is a female speaker. And I need to run this on tens of thousands of audio files in a dataset.

How do I do this? What features do I use to determine this? Do I need machine learning or can I use some fixed numbers to figure it out? How do I access these stats/numbers that I need to figure this out?",628
673,673,Parsing with statistical method,"Hello, I'm quite new to parsing in NLP and I'm still confuse about some stuff.

1) I saw that CKY algorithm only work with CNF grammar, but on some research paper i saw they use CKY with PCFG and CCG. Can PCFG and CCG, be transformed into CNF?

2) I would like to make a parser from scratch, using my own lexicon and grammar extracted from a corpus in my language, with probabilistic method. I wanted to start with probabilistic CKY is it a good idea?

Thanks in advance Have a nice day!",https://www.reddit.com/r/LanguageTechnology/comments/ls70lb/parsing_with_statistical_method/,LanguageTechnology,t3_ls70lb,"Parsing with statistical method Hello, I'm quite new to parsing in NLP and I'm still confuse about some stuff.

1) I saw that CKY algorithm only work with CNF grammar, but on some research paper i saw they use CKY with PCFG and CCG. Can PCFG and CCG, be transformed into CNF?

2) I would like to make a parser from scratch, using my own lexicon and grammar extracted from a corpus in my language, with probabilistic method. I wanted to start with probabilistic CKY is it a good idea?

Thanks in advance Have a nice day!",519
674,674,"Text-to-image Google Colab notebook ""Aleph-Image: CLIPxDAll-E"" has been released. This notebook uses OpenAI's CLIP neural network to steer OpenAI's DALL-E image generator to try to match a given text description.",,/r/MachineLearning/comments/ls0e0f/p_texttoimage_google_colab_notebook_alephimage/,LanguageTechnology,t3_ls0nhf,"Text-to-image Google Colab notebook ""Aleph-Image: CLIPxDAll-E"" has been released. This notebook uses OpenAI's CLIP neural network to steer OpenAI's DALL-E image generator to try to match a given text description. ",213
675,675,Looking for machine translation papers in other languages,"mt-archive.info is a really neat site, it's an archive of papers on machine translation. However, they're only in English. I know such research has been going on outside the Anglosphere as well since the beginning, do you know where I can find similar archives in other languages?",https://www.reddit.com/r/LanguageTechnology/comments/ls4kus/looking_for_machine_translation_papers_in_other/,LanguageTechnology,t3_ls4kus,"Looking for machine translation papers in other languages mt-archive.info is a really neat site, it's an archive of papers on machine translation. However, they're only in English. I know such research has been going on outside the Anglosphere as well since the beginning, do you know where I can find similar archives in other languages?",338
676,676,Tutorial on how to calculate summary statistics by group,"Hey, I've created a tutorial on how to calculate summary statistics by group in the R programming language: [https://statisticsglobe.com/summary-statistics-by-group-in-r](https://statisticsglobe.com/summary-statistics-by-group-in-r)",https://www.reddit.com/r/LanguageTechnology/comments/ls0a0k/tutorial_on_how_to_calculate_summary_statistics/,LanguageTechnology,t3_ls0a0k,"Tutorial on how to calculate summary statistics by group Hey, I've created a tutorial on how to calculate summary statistics by group in the R programming language: [https://statisticsglobe.com/summary-statistics-by-group-in-r](https://statisticsglobe.com/summary-statistics-by-group-in-r)",289
677,677,Swearing in programming,,/r/github/comments/lrznai/swearing_in_programming/,LanguageTechnology,t3_ls0cyn,Swearing in programming ,24
678,678,Does anyone know where I could get some tagged pos/neg/neutral restaurant reviews?,I want to create a sentiment analysis for a class using NLTK but not on movie reviews or Twitter data which seem to be the two most popular. Does anyone know where I could find a large set of sentiment tagged restaurant reviews? Thank you,https://www.reddit.com/r/LanguageTechnology/comments/lrqhlr/does_anyone_know_where_i_could_get_some_tagged/,LanguageTechnology,t3_lrqhlr,Does anyone know where I could get some tagged pos/neg/neutral restaurant reviews? I want to create a sentiment analysis for a class using NLTK but not on movie reviews or Twitter data which seem to be the two most popular. Does anyone know where I could find a large set of sentiment tagged restaurant reviews? Thank you,321
679,679,Recent Advances in Language Model Fine-tuning,,https://ruder.io/recent-advances-lm-fine-tuning/,LanguageTechnology,t3_lr96o0,Recent Advances in Language Model Fine-tuning ,46
680,680,How do cross-lingual encoders work?,"Hello! I have a small question about cross lingual encoders (after having read numerous papers and going through so much code, I am still a little lost about something pretty basic lol)

Once we train cross lingual word embeddings (using a mapping method like [VecMap](https://github.com/artetxem/vecmap)), we get two resultant word embeddings: source_mapped and target_mapped. So when we use a ""cross-lingual"" encoder and we just copy the source_mapped embedding parameters into the encoder, how are we utilising the cross-lingual signal exactly? I would understand if the initial encoder mapping is done like source_mapped-&gt;target_mapped-&gt;decoder hidden state-&gt;backward pass-&gt;....-&gt; trained model, but that doesn't seem to be the case. So if someone has experience with cross-lingual encoders, could you explain how exactly it would work/be implement after getting the source and target embeddings mapped (similarly, how it would work if they were trained in a joint fashion)? Thank you so much!!",https://www.reddit.com/r/LanguageTechnology/comments/lrnvkh/how_do_crosslingual_encoders_work/,LanguageTechnology,t3_lrnvkh,"How do cross-lingual encoders work? Hello! I have a small question about cross lingual encoders (after having read numerous papers and going through so much code, I am still a little lost about something pretty basic lol)

Once we train cross lingual word embeddings (using a mapping method like [VecMap](https://github.com/artetxem/vecmap)), we get two resultant word embeddings: source_mapped and target_mapped. So when we use a ""cross-lingual"" encoder and we just copy the source_mapped embedding parameters into the encoder, how are we utilising the cross-lingual signal exactly? I would understand if the initial encoder mapping is done like source_mapped-&gt;target_mapped-&gt;decoder hidden state-&gt;backward pass-&gt;....-&gt; trained model, but that doesn't seem to be the case. So if someone has experience with cross-lingual encoders, could you explain how exactly it would work/be implement after getting the source and target embeddings mapped (similarly, how it would work if they were trained in a joint fashion)? Thank you so much!!",1049
681,681,Paper: Calibrate Before Use: Improving Few-Shot Performance of GPT-3,,/r/MachineLearning/comments/lpvb1z/r_calibrate_before_use_improving_fewshot/,LanguageTechnology,t3_lrschd,Paper: Calibrate Before Use: Improving Few-Shot Performance of GPT-3 ,69
682,682,Whats the state of art for anaphora resolution?,"I'm trying to think of a fun project to do for a class, and I found the problem of anaphora resolution interesting. 

Is this a problem that is essentially ""solved"" or is it still being actively researched? 

What are some state-of-the-art methods? Could I apply BERT? What are some papers I could read about?  Thank you!",https://www.reddit.com/r/LanguageTechnology/comments/lrmumd/whats_the_state_of_art_for_anaphora_resolution/,LanguageTechnology,t3_lrmumd,"Whats the state of art for anaphora resolution? I'm trying to think of a fun project to do for a class, and I found the problem of anaphora resolution interesting. 

Is this a problem that is essentially ""solved"" or is it still being actively researched? 

What are some state-of-the-art methods? Could I apply BERT? What are some papers I could read about?  Thank you!",369
683,683,Question: What is the commercial value of NLP?,"I am very interested in this topic but learning and getting academic certifications takes time and effort, as topic, is it worth it?",https://www.reddit.com/r/LanguageTechnology/comments/lrv476/question_what_is_the_commercial_value_of_nlp/,LanguageTechnology,t3_lrv476,"Question: What is the commercial value of NLP? I am very interested in this topic but learning and getting academic certifications takes time and effort, as topic, is it worth it?",179
684,684,How to convert pre-processed text into feature vectors,"I have used pos tagging, stop words removal and lemmatization to pre process the given sentence. After that I've got the output as list of lists. 

    Somethin like this :   [['explain', 'VERB'], ['briefly', 'ADV'], ['working', 'NOUN'], ['merge', 'NOUN'], ['sort', 'NOUN'], ['.', 'PUNCT']] 

Now I have to convert this into feature vectors so that I could pass these vectors as an input to an classification model. But I'm not sure how to use pre processed text as an input to feature vectorizers.

If anybody has any inputs regarding this, it would be helpful. Any links that address the same problem would be appreciated. If it's not the sub to ask these questions, please guide me to the proper sub  
Thanks a lot in advance :)",https://www.reddit.com/r/LanguageTechnology/comments/lrj76a/how_to_convert_preprocessed_text_into_feature/,LanguageTechnology,t3_lrj76a,"How to convert pre-processed text into feature vectors I have used pos tagging, stop words removal and lemmatization to pre process the given sentence. After that I've got the output as list of lists. 

    Somethin like this :   [['explain', 'VERB'], ['briefly', 'ADV'], ['working', 'NOUN'], ['merge', 'NOUN'], ['sort', 'NOUN'], ['.', 'PUNCT']] 

Now I have to convert this into feature vectors so that I could pass these vectors as an input to an classification model. But I'm not sure how to use pre processed text as an input to feature vectorizers.

If anybody has any inputs regarding this, it would be helpful. Any links that address the same problem would be appreciated. If it's not the sub to ask these questions, please guide me to the proper sub  
Thanks a lot in advance :)",786
685,685,BERT-QE: Contextualized Query Expansion for Document Re-ranking (Research Paper Walkthrough),"Query expansion is the process of reformulating a given query to improve retrieval performance in information retrieval operations, particularly in the context of query understanding. 🤠
This paper uses BERT to find relevant chunks from the documents as possible augmentations to the given query. 🔥 

Paper Walkthrough: https://youtu.be/WAv6LsIJZbs",https://www.reddit.com/r/LanguageTechnology/comments/lr8o8g/bertqe_contextualized_query_expansion_for/,LanguageTechnology,t3_lr8o8g,"BERT-QE: Contextualized Query Expansion for Document Re-ranking (Research Paper Walkthrough) Query expansion is the process of reformulating a given query to improve retrieval performance in information retrieval operations, particularly in the context of query understanding. 🤠
This paper uses BERT to find relevant chunks from the documents as possible augmentations to the given query. 🔥 

Paper Walkthrough: https://youtu.be/WAv6LsIJZbs",440
686,686,Any interest in BERT-related (or LDA) acceleration (5x)? &lt;5-min Survey&gt;,"I'm a graduate student on the east coast working with a postdoc researcher focused on ML acceleration. We are trying to see what pain points researchers and engineers experience with their ML project to help direct our future research projects.

We have the belief that the team is capable of developing a solution towards accelerating BERT through training times and model sizes.

We are hoping to get some opinions from the community on whether this would be something for us as researchers worthwhile to pursue. We also would be interested in finding teams looking to test this solution in the future.

If you can spare 5 minutes, please help us by filling out this survey: [https://tufts.qualtrics.com/jfe/form/SV\_bI9I7IDELoJveC2](https://tufts.qualtrics.com/jfe/form/SV_bI9I7IDELoJveC2)",https://www.reddit.com/r/LanguageTechnology/comments/lqolib/any_interest_in_bertrelated_or_lda_acceleration/,LanguageTechnology,t3_lqolib,"Any interest in BERT-related (or LDA) acceleration (5x)? &lt;5-min Survey&gt; I'm a graduate student on the east coast working with a postdoc researcher focused on ML acceleration. We are trying to see what pain points researchers and engineers experience with their ML project to help direct our future research projects.

We have the belief that the team is capable of developing a solution towards accelerating BERT through training times and model sizes.

We are hoping to get some opinions from the community on whether this would be something for us as researchers worthwhile to pursue. We also would be interested in finding teams looking to test this solution in the future.

If you can spare 5 minutes, please help us by filling out this survey: [https://tufts.qualtrics.com/jfe/form/SV\_bI9I7IDELoJveC2](https://tufts.qualtrics.com/jfe/form/SV_bI9I7IDELoJveC2)",870
687,687,Should you standardize/normalize embeddings when using them with a classifier?,"Standardizing/normalizing is known to help learning when fitting a model using gradient descent.

When using a mix of embeddings and non-text features, how should you approach standardization/normalization? 

a) Standardize/normalize everything per usual.

b) Standardize/normalize non-text features, but leave the word embeddings alone.

c) Don't standardize/normalize anything.

So far I'm leaning towards option c. My reasoning:

\- For embeddings extracted from transformers-based models, there's no sensible notion of mean and standard deviation (in the case of standardization) or maximum or minimum (in the case of normalization).

\- For a fixed vocabulary of word vectors (such as from word2vec), gensim supports norming all the vectors, but I worry that this procedure would lose useful information contained in the embeddings.

\- If you standardize/normalize non-text features only, the model would likely update weights associated with the word embeddings faster due to them likely being on a larger scale, which would hurt learning.",https://www.reddit.com/r/LanguageTechnology/comments/lqm5kp/should_you_standardizenormalize_embeddings_when/,LanguageTechnology,t3_lqm5kp,"Should you standardize/normalize embeddings when using them with a classifier? Standardizing/normalizing is known to help learning when fitting a model using gradient descent.

When using a mix of embeddings and non-text features, how should you approach standardization/normalization? 

a) Standardize/normalize everything per usual.

b) Standardize/normalize non-text features, but leave the word embeddings alone.

c) Don't standardize/normalize anything.

So far I'm leaning towards option c. My reasoning:

\- For embeddings extracted from transformers-based models, there's no sensible notion of mean and standard deviation (in the case of standardization) or maximum or minimum (in the case of normalization).

\- For a fixed vocabulary of word vectors (such as from word2vec), gensim supports norming all the vectors, but I worry that this procedure would lose useful information contained in the embeddings.

\- If you standardize/normalize non-text features only, the model would likely update weights associated with the word embeddings faster due to them likely being on a larger scale, which would hurt learning.",1125
688,688,Master Thesis: Matching companies that are potential cooperation partners,,/r/MLQuestions/comments/lqdh6b/master_thesis_matching_companies_that_are/,LanguageTechnology,t3_lqdjhg,Master Thesis: Matching companies that are potential cooperation partners ,74
689,689,Have you ever had the opportunity to be in Europe and learn Slovak? 😄,,https://youtu.be/rULMctrwd78,LanguageTechnology,t3_lqnrvj,Have you ever had the opportunity to be in Europe and learn Slovak? 😄 ,70
690,690,A unique self-assessment algorithm App that simulates changes taking place in personality over time based,[https://youtu.be/IeACb0nqK24](https://youtu.be/IeACb0nqK24),https://www.reddit.com/r/LanguageTechnology/comments/lqg852/a_unique_selfassessment_algorithm_app_that/,LanguageTechnology,t3_lqg852,A unique self-assessment algorithm App that simulates changes taking place in personality over time based [https://youtu.be/IeACb0nqK24](https://youtu.be/IeACb0nqK24),166
691,691,Hierarchical Transformers for Long Document Classification (Research Paper Walkthrough),,https://youtu.be/3IOl5d9PZeM,LanguageTechnology,t3_lpxl51,Hierarchical Transformers for Long Document Classification (Research Paper Walkthrough) ,88
692,692,NLP generated Zork-like text adventure games,"I forgot where I saw it, and now I can't find it, so now I was hoping someone could tell me where it was.

Someone had been using NLP to create text adventure games.  I remember trying it, selecting a genre, and it was a mess but it was pretty interesting / good.  I wanted to try it again but I can't find it.  They were using some sort of neural net.  Everytime I checked my inventory it was different but still made for a novel game experience.",https://www.reddit.com/r/LanguageTechnology/comments/lq9ai6/nlp_generated_zorklike_text_adventure_games/,LanguageTechnology,t3_lq9ai6,"NLP generated Zork-like text adventure games I forgot where I saw it, and now I can't find it, so now I was hoping someone could tell me where it was.

Someone had been using NLP to create text adventure games.  I remember trying it, selecting a genre, and it was a mess but it was pretty interesting / good.  I wanted to try it again but I can't find it.  They were using some sort of neural net.  Everytime I checked my inventory it was different but still made for a novel game experience.",492
693,693,Looking for a code base to implement multi-task learning in NLP,"I am looking for library or code base to implement MTL. Any ideas on this 

Things on my checklist.

1. Should be able to mix different datasets.
2. Able to accumulate gradients for separate task and propagate.
3. Ability to define custom layers on pretrained models.
4. Single head or specific heads for MTL.
5. Implement my custom loss",https://www.reddit.com/r/LanguageTechnology/comments/lpl5ja/looking_for_a_code_base_to_implement_multitask/,LanguageTechnology,t3_lpl5ja,"Looking for a code base to implement multi-task learning in NLP I am looking for library or code base to implement MTL. Any ideas on this 

Things on my checklist.

1. Should be able to mix different datasets.
2. Able to accumulate gradients for separate task and propagate.
3. Ability to define custom layers on pretrained models.
4. Single head or specific heads for MTL.
5. Implement my custom loss",401
694,694,How to use Instance-based Learning to improve the INTERPRETABILITY of NER models | Research Papers Summary 009,,https://youtu.be/OGiyOz4oy54,LanguageTechnology,t3_lp45xe,How to use Instance-based Learning to improve the INTERPRETABILITY of NER models | Research Papers Summary 009 ,111
695,695,torch.nn.Embedding explained (+ Character-level language model),,https://youtu.be/euwN5DHfLEo,LanguageTechnology,t3_lp6afl,torch.nn.Embedding explained (+ Character-level language model) ,64
696,696,NLP Real World Challenge to Detect Bias &amp; Misinformation in Articles," 

In case you are looking for a real-world project (not a hackathon) to make an impact while building up your project portfolio, here is a collaborative two-month project where 50 engineers from all around the world will work together. 

You can apply here [https://omdena.com/projects/bias/](https://omdena.com/projects/bias/?fbclid=IwAR2WIXjaZuY8vNTMm8uUDqE57cqHftC8NlWQzSLnSiTLrLBV4y6IgnuYd_Q)",https://www.reddit.com/r/LanguageTechnology/comments/lotgl4/nlp_real_world_challenge_to_detect_bias/,LanguageTechnology,t3_lotgl4,"NLP Real World Challenge to Detect Bias &amp; Misinformation in Articles  

In case you are looking for a real-world project (not a hackathon) to make an impact while building up your project portfolio, here is a collaborative two-month project where 50 engineers from all around the world will work together. 

You can apply here [https://omdena.com/projects/bias/](https://omdena.com/projects/bias/?fbclid=IwAR2WIXjaZuY8vNTMm8uUDqE57cqHftC8NlWQzSLnSiTLrLBV4y6IgnuYd_Q)",470
697,697,Future advancements and unsolved problems,"I am curious to hear about your opinions regarding future advancements and possible solutions to the issues that exist now in the field of language technology.

What do you see as the main issues and do you think something radically has to change in the way we process language data in order to solve those issues? 

Do you think that new paradigms will emerge in the years to come? I guess that's impossible to predict but do you see a tendency towards new ways of processing languages?

What are you excited about the most?",https://www.reddit.com/r/LanguageTechnology/comments/lou3qo/future_advancements_and_unsolved_problems/,LanguageTechnology,t3_lou3qo,"Future advancements and unsolved problems I am curious to hear about your opinions regarding future advancements and possible solutions to the issues that exist now in the field of language technology.

What do you see as the main issues and do you think something radically has to change in the way we process language data in order to solve those issues? 

Do you think that new paradigms will emerge in the years to come? I guess that's impossible to predict but do you see a tendency towards new ways of processing languages?

What are you excited about the most?",567
698,698,"What are some classification tasks where BERT-based models don't work well? In a similar vein, what are some generative tasks where fine-tuning GPT-2/LM does not work well?","I am looking for problems where BERT has been shown to perform poorly. Additionally, what are some English to English NLP (or any other - same language to the same language)  tasks where fine-tuning GPT-2 is not helpful at all?",https://www.reddit.com/r/LanguageTechnology/comments/lomb87/what_are_some_classification_tasks_where/,LanguageTechnology,t3_lomb87,"What are some classification tasks where BERT-based models don't work well? In a similar vein, what are some generative tasks where fine-tuning GPT-2/LM does not work well? I am looking for problems where BERT has been shown to perform poorly. Additionally, what are some English to English NLP (or any other - same language to the same language)  tasks where fine-tuning GPT-2 is not helpful at all?",400
699,699,"I was wondering if there were any new insights for text representation using transformers, did a lit search, here are a few highlights","

&gt;tween 0 and 1 by a sigmoid activation function.
Our proposed model (model (b) in Fig. 1) uses additional information from
final hidden states of input tokens t1, t2,...tN . The BERT’s sequence output
is fetched into time-distributed fully connected dense layer with the number of
neurons equal to the number of labels. The output of this layer is pooled in
two different ways using the max-pooling and the average-pooling. Max-pooling
outputs the maximum of each feature across all tokens, thus it reacts on strong
class-related keywords. The average-pooling, on the other hand, outputs the
average of each feature over the sequence and thus attends to all tokens in
the sequence evenly. To compute average-pooling, we clipped all features into
interval [−1, 1] to intentionally suppress the influence of strong keywords. When
computing pooled values, we ignored all padding tokens (denoted as [PAD]).
Finally, the features generated from the pooled output and the output for the
[CLS] token are summed together. 

https://link.springer.com/chapter/10.1007%2F978-3-030-58323-1_23

From this paper, mean pool is best, followed by max pool, cls token rep, and sep token rep. 

https://arxiv.org/pdf/1910.07973.pdf",https://www.reddit.com/r/LanguageTechnology/comments/lorzly/i_was_wondering_if_there_were_any_new_insights/,LanguageTechnology,t3_lorzly,"I was wondering if there were any new insights for text representation using transformers, did a lit search, here are a few highlights 

&gt;tween 0 and 1 by a sigmoid activation function.
Our proposed model (model (b) in Fig. 1) uses additional information from
final hidden states of input tokens t1, t2,...tN . The BERT’s sequence output
is fetched into time-distributed fully connected dense layer with the number of
neurons equal to the number of labels. The output of this layer is pooled in
two different ways using the max-pooling and the average-pooling. Max-pooling
outputs the maximum of each feature across all tokens, thus it reacts on strong
class-related keywords. The average-pooling, on the other hand, outputs the
average of each feature over the sequence and thus attends to all tokens in
the sequence evenly. To compute average-pooling, we clipped all features into
interval [−1, 1] to intentionally suppress the influence of strong keywords. When
computing pooled values, we ignored all padding tokens (denoted as [PAD]).
Finally, the features generated from the pooled output and the output for the
[CLS] token are summed together. 

https://link.springer.com/chapter/10.1007%2F978-3-030-58323-1_23

From this paper, mean pool is best, followed by max pool, cls token rep, and sep token rep. 

https://arxiv.org/pdf/1910.07973.pdf",1352
700,700,How do you download data from the Linguistic Data Consortium?,"Hi. I'm currently trying to download the TACRED dataset. According the Stanford NLP's website, you can download it for free from LDC if you're an LDC member or pay $25.

At the TACRED page on LDC (https://catalog.ldc.upenn.edu/LDC2018T24) I see at the bottom ""Available Media"" and nothing under ""View Fees."" I don't see any way to download the data though.

On my account page it says that the administrator for my school hasn't approved my account yet, but would this matter? I'm still an LDC member even if I'm not officially verified to be a member of my school, right?

Any tips are appreciated. Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/lorvz4/how_do_you_download_data_from_the_linguistic_data/,LanguageTechnology,t3_lorvz4,"How do you download data from the Linguistic Data Consortium? Hi. I'm currently trying to download the TACRED dataset. According the Stanford NLP's website, you can download it for free from LDC if you're an LDC member or pay $25.

At the TACRED page on LDC (https://catalog.ldc.upenn.edu/LDC2018T24) I see at the bottom ""Available Media"" and nothing under ""View Fees."" I don't see any way to download the data though.

On my account page it says that the administrator for my school hasn't approved my account yet, but would this matter? I'm still an LDC member even if I'm not officially verified to be a member of my school, right?

Any tips are appreciated. Thanks.",669
701,701,Does anybody know of relation extraction datasets that are at the document level?,"Hey guys. Working on a document-level relation extraction (DocRE) task and I'm wondering what kind of datasets there may be.

In the general domain I've only been able to come across DocRED, and there are also the BC5CDR and GDA datasets in the biomedical domain. I'm wondering what else may be out there that I've missed.

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/loncah/does_anybody_know_of_relation_extraction_datasets/,LanguageTechnology,t3_loncah,"Does anybody know of relation extraction datasets that are at the document level? Hey guys. Working on a document-level relation extraction (DocRE) task and I'm wondering what kind of datasets there may be.

In the general domain I've only been able to come across DocRED, and there are also the BC5CDR and GDA datasets in the biomedical domain. I'm wondering what else may be out there that I've missed.

Thanks!",413
702,702,Nucleus Sampling: The Curious Case of Neural Text Degeneration (Research Paper Walkthrough),,https://youtu.be/dCORspO2yVY,LanguageTechnology,t3_lo4ymm,Nucleus Sampling: The Curious Case of Neural Text Degeneration (Research Paper Walkthrough) ,92
703,703,Finding good NLP developers?,"Hi everyone, any idea as to where I can find a good NLP developer? I tried Upwork but it seems like there are more AI generalists than NLP specialists.

Specifically, 

I need a AI/NLP Developer with AWS Lambda experience to train and deploy GPT-2 model. 

End goal to make a chatbot that will be used as a ‘friend’ for lonely people (see www.replika.ai [advanced] and chatty-app https://apps.apple.com/ca/app/chatty-your-robot-friend/id1020581003 [less advanced]). The chatty-app is based on GPT-2 architecture and is what the first iteration should be similar to.

The first iteration of this project will be a multi user web app that will communicate back and forth with a machine learning API (accessible via high performance gPRC protobufs) running on AWS lambda endpoint. The final product should be maintained 100% by amazon so I won’t need a system engineer/admin.

The GPT-2 model itself will need to be fine tuned on an empathetic dialogue corpus (which I will provide). To keep server costs low, the training should be done via GPU but once trained, the model should use CPU. I am open to any suggestions that will help keep on-going operational server costs lows (for ex. Imposing a slight delay 1-2 seconds between user questions and chatbot response). Ideally the architecture should allow for:

- multi-user support;
- up/down voting of responses so that the model can adapt to each user (via beam search [ex. You could create a tensor of weights assigned to multiple outputs from each question, have the model generate multiple output sequences via beam search, and then promote or penalize the weight associated with that response based on the upvote/downvote]); and
- allow for transfer learning so that the model output can be biased towards end user’s topical and stylistic preferences via Q&amp;A script (or another method).

Any suggestions regarding the overall app and NLP architecture are welcome.",https://www.reddit.com/r/LanguageTechnology/comments/lnof83/finding_good_nlp_developers/,LanguageTechnology,t3_lnof83,"Finding good NLP developers? Hi everyone, any idea as to where I can find a good NLP developer? I tried Upwork but it seems like there are more AI generalists than NLP specialists.

Specifically, 

I need a AI/NLP Developer with AWS Lambda experience to train and deploy GPT-2 model. 

End goal to make a chatbot that will be used as a ‘friend’ for lonely people (see www.replika.ai [advanced] and chatty-app https://apps.apple.com/ca/app/chatty-your-robot-friend/id1020581003 [less advanced]). The chatty-app is based on GPT-2 architecture and is what the first iteration should be similar to.

The first iteration of this project will be a multi user web app that will communicate back and forth with a machine learning API (accessible via high performance gPRC protobufs) running on AWS lambda endpoint. The final product should be maintained 100% by amazon so I won’t need a system engineer/admin.

The GPT-2 model itself will need to be fine tuned on an empathetic dialogue corpus (which I will provide). To keep server costs low, the training should be done via GPU but once trained, the model should use CPU. I am open to any suggestions that will help keep on-going operational server costs lows (for ex. Imposing a slight delay 1-2 seconds between user questions and chatbot response). Ideally the architecture should allow for:

- multi-user support;
- up/down voting of responses so that the model can adapt to each user (via beam search [ex. You could create a tensor of weights assigned to multiple outputs from each question, have the model generate multiple output sequences via beam search, and then promote or penalize the weight associated with that response based on the upvote/downvote]); and
- allow for transfer learning so that the model output can be biased towards end user’s topical and stylistic preferences via Q&amp;A script (or another method).

Any suggestions regarding the overall app and NLP architecture are welcome.",1951
704,704,Do you think OpenAI's GPT3 is good enough to pass the Turing Test? / The world's largest scale Turing Test,,/r/artificial/comments/lncumk/do_you_think_openais_gpt3_is_good_enough_to_pass/,LanguageTechnology,t3_lnpjqu,Do you think OpenAI's GPT3 is good enough to pass the Turing Test? / The world's largest scale Turing Test ,107
705,705,"Some questions about Spacy vs Hugging face transformers, fine-tuning and wav2vec.","I am new to the NLP game and exploring the available options. I have stumbled across both Spacy and Hugging Face Transformers as python packages that seem applicable to my use cases. However, I am having a surprisingly hard time differentiation between the two packages. I would like to hear your input on the differences between Spacy and Hugging Face and perhaps some use cases in which you would prefer on over the other.

A second question relates to the fine-tuning of the models. It is my understanding that both Spacy and Hugging Face typically require fine-tuning before reasonable accuracy can be expected on domain-specific use cases. Could anyone give an estimate of the number of labeled text files one should expect to need for fine-tuning a model? Again, I am having a hard time finding an estimate for these numbers as most blogs use pre-existing datasets with large amounts of data.

Finally, a third question relates to the Wav2Vec 2 model, which can transcribe audio into text. It is my understanding that this model was trained on multiple languages. However, on [huggingface.co/models](https://huggingface.co/models), I am only finding english models at the moment. Is there some way in which I could use Wav2Vec (preferably with the hugging face package) to transcribe for example French texts?

I would very much appreciate it if you could share your expertise and help me to navigate the woods here.",https://www.reddit.com/r/LanguageTechnology/comments/lnca2q/some_questions_about_spacy_vs_hugging_face/,LanguageTechnology,t3_lnca2q,"Some questions about Spacy vs Hugging face transformers, fine-tuning and wav2vec. I am new to the NLP game and exploring the available options. I have stumbled across both Spacy and Hugging Face Transformers as python packages that seem applicable to my use cases. However, I am having a surprisingly hard time differentiation between the two packages. I would like to hear your input on the differences between Spacy and Hugging Face and perhaps some use cases in which you would prefer on over the other.

A second question relates to the fine-tuning of the models. It is my understanding that both Spacy and Hugging Face typically require fine-tuning before reasonable accuracy can be expected on domain-specific use cases. Could anyone give an estimate of the number of labeled text files one should expect to need for fine-tuning a model? Again, I am having a hard time finding an estimate for these numbers as most blogs use pre-existing datasets with large amounts of data.

Finally, a third question relates to the Wav2Vec 2 model, which can transcribe audio into text. It is my understanding that this model was trained on multiple languages. However, on [huggingface.co/models](https://huggingface.co/models), I am only finding english models at the moment. Is there some way in which I could use Wav2Vec (preferably with the hugging face package) to transcribe for example French texts?

I would very much appreciate it if you could share your expertise and help me to navigate the woods here.",1504
706,706,Can I apply for a PhD after a Master's if I don't have Research Experience? Help!," 

Hey Reddit community, 

I am a recent graduate from Columbia University with a masters in financial engineering and a minor in machine learning and I'm looking for advice as I am sort of in a dilemma. I have been actively involved in data science and machine learning since 2017 and have loved working in the space and applying concepts to real-world problems (Worked Full time 2018-2019). In order to build on my knowledge and attain expertise applying ML to financial problems, I took up a masters in financial engineering hoping to leverage the program to work in FinTech roles and startup in the US. Through the course of my masters, I actively took up courses from the CS &amp; Data Science department taking a total of 5 courses (NLP, Applied Deep Learning, Cloud Computing &amp; Big Data, Artificial Intelligence and Recommender Systems) and realized that more than the financial engineering degree wasn't exactly what I wanted to do as I was in love with the field of NLP and the possible applications it can have across the spectrum rather than just limiting myself to applications of AI in finance. 

Unfortunately due to the course load and relatively short term course (3 semesters with 36 credits = 12 courses over 3 semesters) as well as the impact of COVID with classes going virtual since March 2020 I never really got the opportunity to take up roles in research during my masters despite the fact that I was extremely keen on it. The usual process would be to take a class with a professor, excel in the class, approach them for research and work with them after. However, due to the structure of my program, this never panned out. 

Currently, I feel capable enough to take up roles in the industry and work as a data scientist or machine learning engineer but have this burning desire to continue exploring NLP and topics in the space. I am extremely passionate about Abstractive Summarization, Search and Information Retrieval, and also keen to explore Speech Recognition systems. I want to be involved in both developing better algorithms and systems in these areas as well as finding robust inter-disciplinary applications for current systems. As I don't have any research experience I am highly doubtful of my chances as a PhD student. I would love to take up a program like the CMU MLT which gives you the chance to start out as a masters student and then transition to a full-time PhD student. 

I would be grateful for any advice you could provide to me. Would it be better to work for a year and try to be involved in projects in NLP before applying for a PhD and how can an individual with my profile successfully get into a PhD program? (Hopefully Top 10 eventually but more than anything I want to work with a driven like-minded advisor who can guide me in my development)",https://www.reddit.com/r/LanguageTechnology/comments/lnr82k/can_i_apply_for_a_phd_after_a_masters_if_i_dont/,LanguageTechnology,t3_lnr82k,"Can I apply for a PhD after a Master's if I don't have Research Experience? Help!  

Hey Reddit community, 

I am a recent graduate from Columbia University with a masters in financial engineering and a minor in machine learning and I'm looking for advice as I am sort of in a dilemma. I have been actively involved in data science and machine learning since 2017 and have loved working in the space and applying concepts to real-world problems (Worked Full time 2018-2019). In order to build on my knowledge and attain expertise applying ML to financial problems, I took up a masters in financial engineering hoping to leverage the program to work in FinTech roles and startup in the US. Through the course of my masters, I actively took up courses from the CS &amp; Data Science department taking a total of 5 courses (NLP, Applied Deep Learning, Cloud Computing &amp; Big Data, Artificial Intelligence and Recommender Systems) and realized that more than the financial engineering degree wasn't exactly what I wanted to do as I was in love with the field of NLP and the possible applications it can have across the spectrum rather than just limiting myself to applications of AI in finance. 

Unfortunately due to the course load and relatively short term course (3 semesters with 36 credits = 12 courses over 3 semesters) as well as the impact of COVID with classes going virtual since March 2020 I never really got the opportunity to take up roles in research during my masters despite the fact that I was extremely keen on it. The usual process would be to take a class with a professor, excel in the class, approach them for research and work with them after. However, due to the structure of my program, this never panned out. 

Currently, I feel capable enough to take up roles in the industry and work as a data scientist or machine learning engineer but have this burning desire to continue exploring NLP and topics in the space. I am extremely passionate about Abstractive Summarization, Search and Information Retrieval, and also keen to explore Speech Recognition systems. I want to be involved in both developing better algorithms and systems in these areas as well as finding robust inter-disciplinary applications for current systems. As I don't have any research experience I am highly doubtful of my chances as a PhD student. I would love to take up a program like the CMU MLT which gives you the chance to start out as a masters student and then transition to a full-time PhD student. 

I would be grateful for any advice you could provide to me. Would it be better to work for a year and try to be involved in projects in NLP before applying for a PhD and how can an individual with my profile successfully get into a PhD program? (Hopefully Top 10 eventually but more than anything I want to work with a driven like-minded advisor who can guide me in my development)",2888
707,707,What are some good open problems in/applications of Paraphrase Generation?,"The most pertinent use-case I have found for Paraphrase Generation models deals with data-augmentation and adversarial example generation. However, I am looking for other potential applications and would be interested to dive deep into one topic.  Broadly I am also interested in open problems in Controlled Text Generation. Any leads would be helpful.",https://www.reddit.com/r/LanguageTechnology/comments/ln52j2/what_are_some_good_open_problems_inapplications/,LanguageTechnology,t3_ln52j2,"What are some good open problems in/applications of Paraphrase Generation? The most pertinent use-case I have found for Paraphrase Generation models deals with data-augmentation and adversarial example generation. However, I am looking for other potential applications and would be interested to dive deep into one topic.  Broadly I am also interested in open problems in Controlled Text Generation. Any leads would be helpful.",427
708,708,"NLP Infrastructure with Docker Swarm, Docker Compose, and Traefik","Hey, I know this is more of a devops thing, but as more and more people are asking questions about how to deploy their NLP models to production and which kind of infrastructure they should set up, I thought I would share 2 articles I wrote about that recently:

Container orchestration with Docker Swarm: [https://juliensalinas.com/en/container-orchestration-docker-swarm-nlpcloud/](https://juliensalinas.com/en/container-orchestration-docker-swarm-nlpcloud/)

Routing requests to the right NLP model with Traefik: [https://juliensalinas.com/en/traefik-reverse-proxy-docker-compose-docker-swarm-nlpcloud/](https://juliensalinas.com/en/traefik-reverse-proxy-docker-compose-docker-swarm-nlpcloud/)

I'm basically talking about how we're doing things behind the hood at [NLP Cloud](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=2fc10c28-ab0d-11eb-bcbc-0242ac130002), where each spaCy NLP model is running inside its own container.

I hope some of you will find these posts useful.",https://www.reddit.com/r/LanguageTechnology/comments/lmo3jk/nlp_infrastructure_with_docker_swarm_docker/,LanguageTechnology,t3_lmo3jk,"NLP Infrastructure with Docker Swarm, Docker Compose, and Traefik Hey, I know this is more of a devops thing, but as more and more people are asking questions about how to deploy their NLP models to production and which kind of infrastructure they should set up, I thought I would share 2 articles I wrote about that recently:

Container orchestration with Docker Swarm: [https://juliensalinas.com/en/container-orchestration-docker-swarm-nlpcloud/](https://juliensalinas.com/en/container-orchestration-docker-swarm-nlpcloud/)

Routing requests to the right NLP model with Traefik: [https://juliensalinas.com/en/traefik-reverse-proxy-docker-compose-docker-swarm-nlpcloud/](https://juliensalinas.com/en/traefik-reverse-proxy-docker-compose-docker-swarm-nlpcloud/)

I'm basically talking about how we're doing things behind the hood at [NLP Cloud](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=2fc10c28-ab0d-11eb-bcbc-0242ac130002), where each spaCy NLP model is running inside its own container.

I hope some of you will find these posts useful.",1053
709,709,How do you make a text normalizer NOT based on rules but based on TRAINING DATA?,"I need a good text normalization algorithm. Every single thing I've looked up on the subject just has a bunch of ad hoc rules that are blanket regex-replacements and they're frankly horrible. I want human-corrected text to a normalized format, using HUMAN INTELLIGENCE to normalize the text, and then I want to use it to actually train a normalizer. Example of how garbage rule-based normalization is is here:

The team is 7-0 and took a 7-0 lead in the first quarter.

What the normalization SHOULD be (if done with human intelligence and full knowledge of context):

The team is seven and O and took a seven nothing lead in the first quarter.

What most garbage rule-based normalizers would do with this sentence:

The team is seven minus zero and took a seven minus zero lead in the first quarter.

So obviously, you can see why I need human intelligence to do this properly, and if I do it by machine, I need it TRAINED on normalizations done with human intelligence. The issue is I have no idea how to do that, does anyone know how this might be done? What library, algorithm etc. is best for this? I REFUSE to use a rule-based model to do this, I've just proven how stupid it is to do that.",https://www.reddit.com/r/LanguageTechnology/comments/lnnne0/how_do_you_make_a_text_normalizer_not_based_on/,LanguageTechnology,t3_lnnne0,"How do you make a text normalizer NOT based on rules but based on TRAINING DATA? I need a good text normalization algorithm. Every single thing I've looked up on the subject just has a bunch of ad hoc rules that are blanket regex-replacements and they're frankly horrible. I want human-corrected text to a normalized format, using HUMAN INTELLIGENCE to normalize the text, and then I want to use it to actually train a normalizer. Example of how garbage rule-based normalization is is here:

The team is 7-0 and took a 7-0 lead in the first quarter.

What the normalization SHOULD be (if done with human intelligence and full knowledge of context):

The team is seven and O and took a seven nothing lead in the first quarter.

What most garbage rule-based normalizers would do with this sentence:

The team is seven minus zero and took a seven minus zero lead in the first quarter.

So obviously, you can see why I need human intelligence to do this properly, and if I do it by machine, I need it TRAINED on normalizations done with human intelligence. The issue is I have no idea how to do that, does anyone know how this might be done? What library, algorithm etc. is best for this? I REFUSE to use a rule-based model to do this, I've just proven how stupid it is to do that.",1277
710,710,"GPT-3, Esq? Evaluating AI Legal Summaries","Hi all,

As an attorney &amp; ML enthusiast alarmed by the prospect of losing my profession to AI, I ran a few experiments of legal summaries using GPT-3 that I thought the community might find interesting. My comments follow. I would love to hear your thoughts, particularly anyone who has had success using GPT-3 for high-accuracy summarization.

[http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3\_esq\_-\_evaluating\_ai\_legal\_summaries.pdf](http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf)",https://www.reddit.com/r/LanguageTechnology/comments/lmsxxq/gpt3_esq_evaluating_ai_legal_summaries/,LanguageTechnology,t3_lmsxxq,"GPT-3, Esq? Evaluating AI Legal Summaries Hi all,

As an attorney &amp; ML enthusiast alarmed by the prospect of losing my profession to AI, I ran a few experiments of legal summaries using GPT-3 that I thought the community might find interesting. My comments follow. I would love to hear your thoughts, particularly anyone who has had success using GPT-3 for high-accuracy summarization.

[http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3\_esq\_-\_evaluating\_ai\_legal\_summaries.pdf](http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf)",613
711,711,Is classifying word categories with word embeddings a thing?,"I'm new to NLP and I'd like to get some of your input on a random idea I had. 

I'd like to know if there's any use to the idea of using word embeddings to predict types of words. Let's say I download 50k words and convert them to some set of labels (POS tags, LIWC categories, etc) and then I use the N-dimensional vectors to classify those labels using a standard ML algorithm.  If this is successful then I could point a subset of those features/dimensions and show they have strong correlations with certain types of words. And I could use my model to appraise texts based on the selected categories.

Please let me know if this makes sense or if this is a totally nonsensical idea. 

Thanks!!",https://www.reddit.com/r/LanguageTechnology/comments/ln4435/is_classifying_word_categories_with_word/,LanguageTechnology,t3_ln4435,"Is classifying word categories with word embeddings a thing? I'm new to NLP and I'd like to get some of your input on a random idea I had. 

I'd like to know if there's any use to the idea of using word embeddings to predict types of words. Let's say I download 50k words and convert them to some set of labels (POS tags, LIWC categories, etc) and then I use the N-dimensional vectors to classify those labels using a standard ML algorithm.  If this is successful then I could point a subset of those features/dimensions and show they have strong correlations with certain types of words. And I could use my model to appraise texts based on the selected categories.

Please let me know if this makes sense or if this is a totally nonsensical idea. 

Thanks!!",758
712,712,Going into DevOps?,"Hey all,

I graduated from uni with a master's in linguistics and worked as a PhD researcher in NLP (had some knowledge of ML beforehand). After a few years I decided research wasn't for me and quit. Now I find myself in the (European) job market with decent experience as a researcher, but little to no development experience -- my coding work was all academic. I've done a number of interviews for NLP engineer roles and was always passed over for my lack of development/company experience. I love coding, though, and so I'd like to transition to more of a DevOps role.

Trouble is, I don't know where to start, and the companies I found aren't willing to take on a junior right now. Not even sure what extra skills I need. How do I get into DevOps? Are there resources floating around for that? Good courses that focus on the scaling &amp; production side of NLP work? Any personal experience you can share?",https://www.reddit.com/r/LanguageTechnology/comments/lmrti0/going_into_devops/,LanguageTechnology,t3_lmrti0,"Going into DevOps? Hey all,

I graduated from uni with a master's in linguistics and worked as a PhD researcher in NLP (had some knowledge of ML beforehand). After a few years I decided research wasn't for me and quit. Now I find myself in the (European) job market with decent experience as a researcher, but little to no development experience -- my coding work was all academic. I've done a number of interviews for NLP engineer roles and was always passed over for my lack of development/company experience. I love coding, though, and so I'd like to transition to more of a DevOps role.

Trouble is, I don't know where to start, and the companies I found aren't willing to take on a junior right now. Not even sure what extra skills I need. How do I get into DevOps? Are there resources floating around for that? Good courses that focus on the scaling &amp; production side of NLP work? Any personal experience you can share?",929
713,713,Best OCR converter for magazine images?,"My grandma has a Canadian pen pal but she doesn’t speak English so I translate for her. She recently received magazines from her pen pal and asked me if I could translate them for her. She really enjoys the images and the overall magazine style so I wanted to keep that format. I figured converting it would do the trick but all online converters just scramble and mess up the resulting word document. Here is a sample of the scanned pdf file of the magazine [here](https://imgur.com/a/7DcIAIo)
Thanks for any help you can give!

P.S: I would really prefer to have a free converter since I don’t normally use them for such a hard task.",https://www.reddit.com/r/LanguageTechnology/comments/lmmu7z/best_ocr_converter_for_magazine_images/,LanguageTechnology,t3_lmmu7z,"Best OCR converter for magazine images? My grandma has a Canadian pen pal but she doesn’t speak English so I translate for her. She recently received magazines from her pen pal and asked me if I could translate them for her. She really enjoys the images and the overall magazine style so I wanted to keep that format. I figured converting it would do the trick but all online converters just scramble and mess up the resulting word document. Here is a sample of the scanned pdf file of the magazine [here](https://imgur.com/a/7DcIAIo)
Thanks for any help you can give!

P.S: I would really prefer to have a free converter since I don’t normally use them for such a hard task.",675
714,714,Best pratice for pdf classification/clustering,"Hi y’all, I have a large volume of searchable PDFs. Based on their structure (and text) I’d like to cluster or classify them into 3 categories: A, B and other (C). I 

What is best practice for this task? I’ve experimented with extracting the structure and the text content as hOCR and plain text respectively. However, I’m not sure how to use this information efficiently. 

I could simply do a text-based model using a tf-idf matrix but I’m interested in how I can use the structure to classify or cluster. 

Any suggestions? Thanks 

Btw, I love this subreddit! It seems I bookmark every other post.",https://www.reddit.com/r/LanguageTechnology/comments/lmllo4/best_pratice_for_pdf_classificationclustering/,LanguageTechnology,t3_lmllo4,"Best pratice for pdf classification/clustering Hi y’all, I have a large volume of searchable PDFs. Based on their structure (and text) I’d like to cluster or classify them into 3 categories: A, B and other (C). I 

What is best practice for this task? I’ve experimented with extracting the structure and the text content as hOCR and plain text respectively. However, I’m not sure how to use this information efficiently. 

I could simply do a text-based model using a tf-idf matrix but I’m interested in how I can use the structure to classify or cluster. 

Any suggestions? Thanks 

Btw, I love this subreddit! It seems I bookmark every other post.",649
715,715,Split audio based on text tokenization,I have a long audio message and the text. I want to split the sentence in the sentence bases on full stop and also split the relevant audio path. Can anyone recommend the relevant source,https://www.reddit.com/r/LanguageTechnology/comments/lmpcst/split_audio_based_on_text_tokenization/,LanguageTechnology,t3_lmpcst,Split audio based on text tokenization I have a long audio message and the text. I want to split the sentence in the sentence bases on full stop and also split the relevant audio path. Can anyone recommend the relevant source,225
716,716,Europe Boot camp/Courses on Natural Language Processing?,"Hi,

Does somebody have first-hand experience from bootcamps/short courses (strongly preferred in-person)  to get into the NLP space?",https://www.reddit.com/r/LanguageTechnology/comments/lmo8d2/europe_boot_campcourses_on_natural_language/,LanguageTechnology,t3_lmo8d2,"Europe Boot camp/Courses on Natural Language Processing? Hi,

Does somebody have first-hand experience from bootcamps/short courses (strongly preferred in-person)  to get into the NLP space?",190
717,717,Question about cross lingual pretraining,"I was consulting the following paper about cross lingual language models (XLMs): https://arxiv.org/pdf/1901.07291.pdf

I am having a bit of trouble understanding the cross lingual aspect in the MLM and CLM objectives. I have read the paper quite a few times, but I don’t see how they use any cross lingual signal in the monolingual case. In the TLM+MLM objective it’s pretty clear to me that the encoder is a cross lingual space but in the others I don’t see where the cross lingual aspect is taking place. I hope someone can clear this for me :) thanks!!",https://www.reddit.com/r/LanguageTechnology/comments/lm7mgt/question_about_cross_lingual_pretraining/,LanguageTechnology,t3_lm7mgt,"Question about cross lingual pretraining I was consulting the following paper about cross lingual language models (XLMs): https://arxiv.org/pdf/1901.07291.pdf

I am having a bit of trouble understanding the cross lingual aspect in the MLM and CLM objectives. I have read the paper quite a few times, but I don’t see how they use any cross lingual signal in the monolingual case. In the TLM+MLM objective it’s pretty clear to me that the encoder is a cross lingual space but in the others I don’t see where the cross lingual aspect is taking place. I hope someone can clear this for me :) thanks!!",596
718,718,Anyone know of a Farsi TTS?,,/r/farsi/comments/llfnsv/looking_for_a_good_speech_synthesizer_to_read_out/,LanguageTechnology,t3_llsmlh,Anyone know of a Farsi TTS? ,28
719,719,Dehyphenation,"Hi,

Are there any available libraries for the task of word dehyphenation (removing unwanted hyphens within words, when they are a result of document hyphenation)? This occurs especially when converting PDFs to TXTs.

Thank you!

&amp;#x200B;

EDIT: I'm not working with PDFs; i just have plain text which is already in the hyphenated format (without newline or space-newline after the hyphen). Therefore words like ""bag-of-words"" and ""fu-ture"" are not differentiated in any way. I've now just tried a vocabulary-based approach, which is basically: given a hyphenated word in the ""x-y"" form, if it is more frequent in the corpus in its ""xy"" form, dehyphenate to ""xy"". Seems to work. Any other suggestions?",https://www.reddit.com/r/LanguageTechnology/comments/lm3gpa/dehyphenation/,LanguageTechnology,t3_lm3gpa,"Dehyphenation Hi,

Are there any available libraries for the task of word dehyphenation (removing unwanted hyphens within words, when they are a result of document hyphenation)? This occurs especially when converting PDFs to TXTs.

Thank you!

&amp;#x200B;

EDIT: I'm not working with PDFs; i just have plain text which is already in the hyphenated format (without newline or space-newline after the hyphen). Therefore words like ""bag-of-words"" and ""fu-ture"" are not differentiated in any way. I've now just tried a vocabulary-based approach, which is basically: given a hyphenated word in the ""x-y"" form, if it is more frequent in the corpus in its ""xy"" form, dehyphenate to ""xy"". Seems to work. Any other suggestions?",719
720,720,Multiple Frameworks in the same projekt?,"Hi,

is it okay to use multiple frameworks/libraries in the same project? 

i am currently writing my bachelorthesis about analyzing online lectures and would like to use gensim for it. But i already used spacy for data preperation like filtering stopwords e.g. 

Is it okay to mix these tools or better use the same tool over the span of the project?",https://www.reddit.com/r/LanguageTechnology/comments/lluwlh/multiple_frameworks_in_the_same_projekt/,LanguageTechnology,t3_lluwlh,"Multiple Frameworks in the same projekt? Hi,

is it okay to use multiple frameworks/libraries in the same project? 

i am currently writing my bachelorthesis about analyzing online lectures and would like to use gensim for it. But i already used spacy for data preperation like filtering stopwords e.g. 

Is it okay to mix these tools or better use the same tool over the span of the project?",392
721,721,What proper method to aggregate embeddings?,"Hi,

I am working on NLP projects where I usually extract context embeddings for some given tokens. As an example, when I am performing a filling-mask task using hugging face transformers, I always wonder how to properly aggregate context embedding vectors for each \[MASK\] token in the same sentence. Usual methods to proceed are :

\- Averaging them all (e.g using np.mean())

\- Summing over embedding space dimensions

\- Concatenates them (and probably apply a PCA to get a more compact representation)

&amp;#x200B;

Is there any better way to perform multidimensional vector aggregation while preserving most of the information?",https://www.reddit.com/r/LanguageTechnology/comments/llgeoa/what_proper_method_to_aggregate_embeddings/,LanguageTechnology,t3_llgeoa,"What proper method to aggregate embeddings? Hi,

I am working on NLP projects where I usually extract context embeddings for some given tokens. As an example, when I am performing a filling-mask task using hugging face transformers, I always wonder how to properly aggregate context embedding vectors for each \[MASK\] token in the same sentence. Usual methods to proceed are :

\- Averaging them all (e.g using np.mean())

\- Summing over embedding space dimensions

\- Concatenates them (and probably apply a PCA to get a more compact representation)

&amp;#x200B;

Is there any better way to perform multidimensional vector aggregation while preserving most of the information?",680
722,722,[R] SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning,"This paper digs into a new algorithm called SpAtten, an efficient algorithm-architecture co-design that leverages token sparsity, head sparsity, and quantization opportunities to reduce attention computation and memory access. 

\[[Paper Video Presentation](https://crossminds.ai/video/602b30c3d8d2f96ed18b0d23/)\] \[[arXiv Link](https://arxiv.org/abs/2012.09852)\]

&amp;#x200B;

**Abstract:** The attention mechanism is becoming increasingly popular in Natural Language Processing (NLP) applications, showing superior performance than convolutional and recurrent architectures. However, general-purpose platforms such as CPUs and GPUs are inefficient when performing attention inference due to complicated data movement and low arithmetic intensity. Moreover, existing NN accelerators mainly focus on optimizing convolutional or recurrent models, and cannot efficiently support attention. In this paper, we present SpAtten, an efficient algorithm-architecture co-design that leverages token sparsity, head sparsity, and quantization opportunities to reduce the attention computation and memory access. Inspired by the high redundancy of human languages, we propose the novel cascade token pruning to prune away unimportant tokens in the sentence. We also propose cascade head pruning to remove unessential heads. Cascade pruning is fundamentally different from weight pruning since there is no trainable weight in the attention mechanism, and the pruned tokens and heads are selected on the fly. To efficiently support them on hardware, we design a novel top-k engine to rank token and head importance scores with high throughput. Furthermore, we propose progressive quantization that first fetches MSBs only and performs the computation; if the confidence is low, it fetches LSBs and recomputes the attention outputs, trading computation for memory reduction. Extensive experiments on 30 benchmarks show that, on average, SpAtten reduces DRAM access by 10.0x with no accuracy loss, and achieves 1.6x, 3.0x, 162x, 347x speedup, and 1,4x, 3.2x, 1193x, 4059x energy savings over A3 accelerator, MNNFast accelerator, TITAN Xp GPU, Xeon CPU, respectively.

&amp;#x200B;

Authors: Hanrui Wang, Zhekai Zhang, Song Han (MIT)",https://www.reddit.com/r/LanguageTechnology/comments/llkerj/r_spatten_efficient_sparse_attention_architecture/,LanguageTechnology,t3_llkerj,"[R] SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning This paper digs into a new algorithm called SpAtten, an efficient algorithm-architecture co-design that leverages token sparsity, head sparsity, and quantization opportunities to reduce attention computation and memory access. 

\[[Paper Video Presentation](https://crossminds.ai/video/602b30c3d8d2f96ed18b0d23/)\] \[[arXiv Link](https://arxiv.org/abs/2012.09852)\]

&amp;#x200B;

**Abstract:** The attention mechanism is becoming increasingly popular in Natural Language Processing (NLP) applications, showing superior performance than convolutional and recurrent architectures. However, general-purpose platforms such as CPUs and GPUs are inefficient when performing attention inference due to complicated data movement and low arithmetic intensity. Moreover, existing NN accelerators mainly focus on optimizing convolutional or recurrent models, and cannot efficiently support attention. In this paper, we present SpAtten, an efficient algorithm-architecture co-design that leverages token sparsity, head sparsity, and quantization opportunities to reduce the attention computation and memory access. Inspired by the high redundancy of human languages, we propose the novel cascade token pruning to prune away unimportant tokens in the sentence. We also propose cascade head pruning to remove unessential heads. Cascade pruning is fundamentally different from weight pruning since there is no trainable weight in the attention mechanism, and the pruned tokens and heads are selected on the fly. To efficiently support them on hardware, we design a novel top-k engine to rank token and head importance scores with high throughput. Furthermore, we propose progressive quantization that first fetches MSBs only and performs the computation; if the confidence is low, it fetches LSBs and recomputes the attention outputs, trading computation for memory reduction. Extensive experiments on 30 benchmarks show that, on average, SpAtten reduces DRAM access by 10.0x with no accuracy loss, and achieves 1.6x, 3.0x, 162x, 347x speedup, and 1,4x, 3.2x, 1193x, 4059x energy savings over A3 accelerator, MNNFast accelerator, TITAN Xp GPU, Xeon CPU, respectively.

&amp;#x200B;

Authors: Hanrui Wang, Zhekai Zhang, Song Han (MIT)",2308
723,723,Anything to be doing alongside Jurafsky &amp; Martin SLP?,"Apologies if this is a broken record post-- I tried looking around and couldn't find anything on this. 

I've heard in here multiple times that Speech &amp; Language Processing is sort of the Bible for NLP stuff. I've been going through it, doing the exercises, and trying to implement the algorithms it talks about where possible. I'm also trying to follow along with Relevant Papers for each chapter (like the original Word2Vec &amp; Negative Sampling papers for Word Vectors, etc)

That said, I'm not certain I'm really holding onto information in any manner where I'm actually going to implement it in my own projects. Are there any other supplements to this? Or is it sort of just drill this until you have it down?",https://www.reddit.com/r/LanguageTechnology/comments/lla9md/anything_to_be_doing_alongside_jurafsky_martin_slp/,LanguageTechnology,t3_lla9md,"Anything to be doing alongside Jurafsky &amp; Martin SLP? Apologies if this is a broken record post-- I tried looking around and couldn't find anything on this. 

I've heard in here multiple times that Speech &amp; Language Processing is sort of the Bible for NLP stuff. I've been going through it, doing the exercises, and trying to implement the algorithms it talks about where possible. I'm also trying to follow along with Relevant Papers for each chapter (like the original Word2Vec &amp; Negative Sampling papers for Word Vectors, etc)

That said, I'm not certain I'm really holding onto information in any manner where I'm actually going to implement it in my own projects. Are there any other supplements to this? Or is it sort of just drill this until you have it down?",778
724,724,Paper: 65 Million Probably-Asked Questions and What You Can Do With Them,,https://arxiv.org/abs/2102.07033,LanguageTechnology,t3_llcqjw,Paper: 65 Million Probably-Asked Questions and What You Can Do With Them ,73
725,725,"Paper: ""Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm""",,https://arxiv.org/abs/2102.07350,LanguageTechnology,t3_llb807,"Paper: ""Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm"" ",84
726,726,Question Regarding LSTM-CRF architecture for NER,"Hello. I'm reading the paper titled [_Neural Architectures for Named Entity Recognition (Lample et al., 2016)_](https://www.aclweb.org/anthology/N16-1030/) and had a question regarding some details of the paper.

In section 2.3 Parameterization and Training, the paper claims:

&gt; These representations (i.e., the hidden representations $h$ for left- and right-going LSTM) are concatenated and linearly projected onto a layer **whose size is equal to the number of distinct tags**. Instead of using the softmax output from this layer, we use a CRF as previously described to take into account neighboring tags, yielding the final predictions for every word.

The part that's confusing me is in bold. My understanding is that if we have an input sequence of length _n_, then the output of a CRF should also be of size _n_ since we're essentially predicting the labels for the entire sequence. If we linearly project the hidden representations onto a layer whose size is the number of distinct tags (say, _k_) then wouldn't there be a size mismatch?",https://www.reddit.com/r/LanguageTechnology/comments/lljnlj/question_regarding_lstmcrf_architecture_for_ner/,LanguageTechnology,t3_lljnlj,"Question Regarding LSTM-CRF architecture for NER Hello. I'm reading the paper titled [_Neural Architectures for Named Entity Recognition (Lample et al., 2016)_](https://www.aclweb.org/anthology/N16-1030/) and had a question regarding some details of the paper.

In section 2.3 Parameterization and Training, the paper claims:

&gt; These representations (i.e., the hidden representations $h$ for left- and right-going LSTM) are concatenated and linearly projected onto a layer **whose size is equal to the number of distinct tags**. Instead of using the softmax output from this layer, we use a CRF as previously described to take into account neighboring tags, yielding the final predictions for every word.

The part that's confusing me is in bold. My understanding is that if we have an input sequence of length _n_, then the output of a CRF should also be of size _n_ since we're essentially predicting the labels for the entire sequence. If we linearly project the hidden representations onto a layer whose size is the number of distinct tags (say, _k_) then wouldn't there be a size mismatch?",1098
727,727,CLIP - Learning Transferable Visual Models From Natural Language Supervision,,https://www.lamaai.io/posts/clip-learning-transferable-visual-models-from-natural-language-supervision,LanguageTechnology,t3_llgw3n,CLIP - Learning Transferable Visual Models From Natural Language Supervision ,77
728,728,Shortformer: Better Language Modeling using Shorter Inputs (Paper Explained),,https://youtu.be/WuwR5WTMteM,LanguageTechnology,t3_lkjakf,Shortformer: Better Language Modeling using Shorter Inputs (Paper Explained) ,77
729,729,Single Sentence Simplification,"I've seen some posts on this in the far past (half a decade or more ago). Looking to see if anyone has any up to date ideas on the subject. Process of simplifying a single sentence. I know there are a lot of tools and models out there for summarizing multi-sentence corpora but I'm looking for one that can operate on a single sentence. Bonus points if it doesn't require training, domain-specific knowledge, or tuning.",https://www.reddit.com/r/LanguageTechnology/comments/lksosf/single_sentence_simplification/,LanguageTechnology,t3_lksosf,"Single Sentence Simplification I've seen some posts on this in the far past (half a decade or more ago). Looking to see if anyone has any up to date ideas on the subject. Process of simplifying a single sentence. I know there are a lot of tools and models out there for summarizing multi-sentence corpora but I'm looking for one that can operate on a single sentence. Bonus points if it doesn't require training, domain-specific knowledge, or tuning.",450
730,730,Has anyone here studied Computational Linguistics at Tübingen University (Germany) or at UAM university ( Poland) ?,I would just like to know more about what the student experience is like at those universities for CL.,https://www.reddit.com/r/LanguageTechnology/comments/lkka02/has_anyone_here_studied_computational_linguistics/,LanguageTechnology,t3_lkka02,Has anyone here studied Computational Linguistics at Tübingen University (Germany) or at UAM university ( Poland) ? I would just like to know more about what the student experience is like at those universities for CL.,218
731,731,Computational linguistics in Stuttgart university and Saarland university,"struggling to choose Saarland or Stuttgart university.
How about work opportunity after graduating from both universities?",https://www.reddit.com/r/LanguageTechnology/comments/lks7r3/computational_linguistics_in_stuttgart_university/,LanguageTechnology,t3_lks7r3,"Computational linguistics in Stuttgart university and Saarland university struggling to choose Saarland or Stuttgart university.
How about work opportunity after graduating from both universities?",196
732,732,How to source support for a project,"Hi all, I am looking to source some support to do some text summarization and sentiment analysis from some transcripts of interviews. 

I have a pretty small budget but I was wondering if this community could guide me to somewhere or someone who could take this on?",https://www.reddit.com/r/LanguageTechnology/comments/lki3rv/how_to_source_support_for_a_project/,LanguageTechnology,t3_lki3rv,"How to source support for a project Hi all, I am looking to source some support to do some text summarization and sentiment analysis from some transcripts of interviews. 

I have a pretty small budget but I was wondering if this community could guide me to somewhere or someone who could take this on?",301
733,733,Is AIML worth considering in 2021?,"I work in a company and was recently assigned to an NLP team (it's a startup). Recently, my superior asked me to research technology that can be used to solve a particular problem he described that sounds a lot like a QnA chat bot.   


For example if the system is meant to be used by tenants to ask question about the building they live in, and the building has an automated locking system that uses keycards (and RFID) to get in, one use case may be: 

  
Tenant: I can't unlock the door

Bot: Is there a green light on the lock? 

Tenant: Yes

Bot: Is there any video feed on the screen? 

Tenant: No

Bot: Solution 1

&amp;#x200B;

I work in a company and was recently assigned to an NLP team (it's a startup). Recently, my superior asked me to research technology that can be used to solve a particular problem he described that sounds a lot like a QnA chatbot.   
 

Is AIML still used to build systems like these?",https://www.reddit.com/r/LanguageTechnology/comments/lk5kf5/is_aiml_worth_considering_in_2021/,LanguageTechnology,t3_lk5kf5,"Is AIML worth considering in 2021? I work in a company and was recently assigned to an NLP team (it's a startup). Recently, my superior asked me to research technology that can be used to solve a particular problem he described that sounds a lot like a QnA chat bot.   


For example if the system is meant to be used by tenants to ask question about the building they live in, and the building has an automated locking system that uses keycards (and RFID) to get in, one use case may be: 

  
Tenant: I can't unlock the door

Bot: Is there a green light on the lock? 

Tenant: Yes

Bot: Is there any video feed on the screen? 

Tenant: No

Bot: Solution 1

&amp;#x200B;

I work in a company and was recently assigned to an NLP team (it's a startup). Recently, my superior asked me to research technology that can be used to solve a particular problem he described that sounds a lot like a QnA chatbot.   
 

Is AIML still used to build systems like these?",956
734,734,How do fake news video have audio matching almost perfectly to chosen hosts voice?,"Or are those audio snippets collection from host characters real videos

If not what technology is used to create them.",https://www.reddit.com/r/LanguageTechnology/comments/lkey2a/how_do_fake_news_video_have_audio_matching_almost/,LanguageTechnology,t3_lkey2a,"How do fake news video have audio matching almost perfectly to chosen hosts voice? Or are those audio snippets collection from host characters real videos

If not what technology is used to create them.",202
735,735,Did spaCy Used to Allow LEMMA exceptions?,"*edit:* formatting

Hello everyone. I'm working my way through *Natural Language Processing with Python and spaCy* by Yuli Vasilev and have hit an error in chapter 2.

The chapter wants me to add a special case to set the `LEMMA` of ""Frisco"" to ""San Francisco."" I have written the following code:

    import spacy
    from spacy.symbols import ORTH, LEMMA
    
    nlp = spacy.load('en_core_web_sm')
    doc = nlp(u'I am flying to Frisco')
    print([w.text for w in doc])
    
    special_case = [{ORTH: u'Frisco', LEMMA: u'San Francisco'}]
    nlp.tokenizer.add_special_case(u'Frisco', special_case)
    print([w.lemma_ for w in nlp(u'I am flying to Frisco')])

but when I run this, I get the following exception:

    Traceback (most recent call last):
      File "".\lemmatization2.py"", line 6, in &lt;module&gt;
        nlp.tokenizer.add_special_case(u'Frisco', special_case)
      File ""spacy\tokenizer.pyx"", line 601, in spacy.tokenizer.Tokenizer.add_special_case
      File ""spacy\tokenizer.pyx"", line 589, in spacy.tokenizer.Tokenizer._validate_special_case
    ValueError: [E1005] Unable to set attribute 'LEMMA' in tokenizer exception for 'Frisco'. Tokenizer exceptions are only allowed to specify ORTH and NORM.

I've tried to look up how to change the `LEMMA` value of a token and there's some Stack Overflow answers where people are doing the same thing the book is telling me to do. I can't find any information on this outside of GitHub issues that seem related at first but then aren't.

So I figure maybe when this book was written (looks like 2020?), spaCy let you add exceptions for `LEMMA`, but now it doesn't. Is that accurate? Should I use `NORM` instead? Is there a different problem that I might be overlooking?",https://www.reddit.com/r/LanguageTechnology/comments/lk56p2/did_spacy_used_to_allow_lemma_exceptions/,LanguageTechnology,t3_lk56p2,"Did spaCy Used to Allow LEMMA exceptions? *edit:* formatting

Hello everyone. I'm working my way through *Natural Language Processing with Python and spaCy* by Yuli Vasilev and have hit an error in chapter 2.

The chapter wants me to add a special case to set the `LEMMA` of ""Frisco"" to ""San Francisco."" I have written the following code:

    import spacy
    from spacy.symbols import ORTH, LEMMA
    
    nlp = spacy.load('en_core_web_sm')
    doc = nlp(u'I am flying to Frisco')
    print([w.text for w in doc])
    
    special_case = [{ORTH: u'Frisco', LEMMA: u'San Francisco'}]
    nlp.tokenizer.add_special_case(u'Frisco', special_case)
    print([w.lemma_ for w in nlp(u'I am flying to Frisco')])

but when I run this, I get the following exception:

    Traceback (most recent call last):
      File "".\lemmatization2.py"", line 6, in &lt;module&gt;
        nlp.tokenizer.add_special_case(u'Frisco', special_case)
      File ""spacy\tokenizer.pyx"", line 601, in spacy.tokenizer.Tokenizer.add_special_case
      File ""spacy\tokenizer.pyx"", line 589, in spacy.tokenizer.Tokenizer._validate_special_case
    ValueError: [E1005] Unable to set attribute 'LEMMA' in tokenizer exception for 'Frisco'. Tokenizer exceptions are only allowed to specify ORTH and NORM.

I've tried to look up how to change the `LEMMA` value of a token and there's some Stack Overflow answers where people are doing the same thing the book is telling me to do. I can't find any information on this outside of GitHub issues that seem related at first but then aren't.

So I figure maybe when this book was written (looks like 2020?), spaCy let you add exceptions for `LEMMA`, but now it doesn't. Is that accurate? Should I use `NORM` instead? Is there a different problem that I might be overlooking?",1778
736,736,How we have been evaluating Knowledge Graph Completion models INACCURATELY | Research Papers Summary 008,,https://youtu.be/uGRyWQRcyjY,LanguageTechnology,t3_ljuuux,How we have been evaluating Knowledge Graph Completion models INACCURATELY | Research Papers Summary 008 ,105
737,737,Most influential ACL papers by year (1980-2020),[https://www.paperdigest.org/2021/02/most-influential-acl-papers/](https://www.paperdigest.org/2021/02/most-influential-acl-papers/),https://www.reddit.com/r/LanguageTechnology/comments/ljr9ld/most_influential_acl_papers_by_year_19802020/,LanguageTechnology,t3_ljr9ld,Most influential ACL papers by year (1980-2020) [https://www.paperdigest.org/2021/02/most-influential-acl-papers/](https://www.paperdigest.org/2021/02/most-influential-acl-papers/),180
738,738,"Happy Valentine's, everyone! This year, I used NLP to solve me being single by programming an autocomplete program using Markov Chains and RNNs trained on romantic movies! The results were REALLY unexpected so I turned that whole experience into a video. I hope y'all like it!",,https://youtu.be/QdsEeFmbOyw,LanguageTechnology,t3_ljogla,"Happy Valentine's, everyone! This year, I used NLP to solve me being single by programming an autocomplete program using Markov Chains and RNNs trained on romantic movies! The results were REALLY unexpected so I turned that whole experience into a video. I hope y'all like it! ",277
739,739,How to implement self supervision in GCN [D]," Q1: where is self supervision implemented in this code ([https://github.com/Shen-Lab/SS-GCNs/blob/master/SS-GCNs/main.py](https://github.com/Shen-Lab/SS-GCNs/blob/master/SS-GCNs/main.py)) . please mention the line numbers and give a small explanation

Q2:Also how to implement self super vision if i want to implement in this code [https://github.com/tkipf/pygcn](https://github.com/tkipf/pygcn)",https://www.reddit.com/r/LanguageTechnology/comments/lk2rv7/how_to_implement_self_supervision_in_gcn_d/,LanguageTechnology,t3_lk2rv7,"How to implement self supervision in GCN [D]  Q1: where is self supervision implemented in this code ([https://github.com/Shen-Lab/SS-GCNs/blob/master/SS-GCNs/main.py](https://github.com/Shen-Lab/SS-GCNs/blob/master/SS-GCNs/main.py)) . please mention the line numbers and give a small explanation

Q2:Also how to implement self super vision if i want to implement in this code [https://github.com/tkipf/pygcn](https://github.com/tkipf/pygcn)",441
740,740,Discovering topics in NEW document using Mallet,"I've been playing around with Mallet and I know how to discover the per-document topic distributions, per-topic word distributions, and how to find similar documents within an existing corpus.

&amp;#x200B;

But what I'm not clear on and can't find anywhere is how to deal with NEW documents without running the entire topic model again.

&amp;#x200B;

So given a new document, discovering what topics are within in and also similar documents within the base corpus.

&amp;#x200B;

Can anyone offer some light on this?",https://www.reddit.com/r/LanguageTechnology/comments/ljy7zs/discovering_topics_in_new_document_using_mallet/,LanguageTechnology,t3_ljy7zs,"Discovering topics in NEW document using Mallet I've been playing around with Mallet and I know how to discover the per-document topic distributions, per-topic word distributions, and how to find similar documents within an existing corpus.

&amp;#x200B;

But what I'm not clear on and can't find anywhere is how to deal with NEW documents without running the entire topic model again.

&amp;#x200B;

So given a new document, discovering what topics are within in and also similar documents within the base corpus.

&amp;#x200B;

Can anyone offer some light on this?",566
741,741,How to train large models on a normal laptop?,"Hi, so if you've seen a previous post of mine, I mentioned a class project where we were designing a new model. The problem here is, that our advisory board wants us to show a comparison between the results of this model and existing models in the field.

The Transformer and the Reformer are two such models, among others. The problem is that I assume it would be impossible to train them for an extended period of time, on a dataset on the scale of enwik9 or so. My laptop specs are 8GB RAM with 256 GB SSD and I'm not really sure about the GPU but I think there is some sort of NVidia GeForce.

Colab crashed the last time I tried to train the model. And we can't really afford to shell out a lot for cloud instances, being undergrads on a budget.

Does anybody have any suggestions about what to do?",https://www.reddit.com/r/LanguageTechnology/comments/ljsyrt/how_to_train_large_models_on_a_normal_laptop/,LanguageTechnology,t3_ljsyrt,"How to train large models on a normal laptop? Hi, so if you've seen a previous post of mine, I mentioned a class project where we were designing a new model. The problem here is, that our advisory board wants us to show a comparison between the results of this model and existing models in the field.

The Transformer and the Reformer are two such models, among others. The problem is that I assume it would be impossible to train them for an extended period of time, on a dataset on the scale of enwik9 or so. My laptop specs are 8GB RAM with 256 GB SSD and I'm not really sure about the GPU but I think there is some sort of NVidia GeForce.

Colab crashed the last time I tried to train the model. And we can't really afford to shell out a lot for cloud instances, being undergrads on a budget.

Does anybody have any suggestions about what to do?",849
742,742,Best Masters/PhD programs in Computational Linguistics in Europe,"I have been exploring some options like Gothenburg and Saarbrucken. Wanted to hear some thoughts from current or past students, about these and other such programs.

If it helps, I am quite interested in common sense reasoning and explainability so if the Unis have research labs focused on such topics will be an added bonus.",https://www.reddit.com/r/LanguageTechnology/comments/ljhkjs/best_mastersphd_programs_in_computational/,LanguageTechnology,t3_ljhkjs,"Best Masters/PhD programs in Computational Linguistics in Europe I have been exploring some options like Gothenburg and Saarbrucken. Wanted to hear some thoughts from current or past students, about these and other such programs.

If it helps, I am quite interested in common sense reasoning and explainability so if the Unis have research labs focused on such topics will be an added bonus.",391
743,743,MS in CL at Montclair?,"Has anyone here done the MS in Computational linguistics at Montclair? Or is currently in the program? I’m considering applying but I would like to know if anyone would recommend it/what they think about it. 
Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/ljcdju/ms_in_cl_at_montclair/,LanguageTechnology,t3_ljcdju,"MS in CL at Montclair? Has anyone here done the MS in Computational linguistics at Montclair? Or is currently in the program? I’m considering applying but I would like to know if anyone would recommend it/what they think about it. 
Thanks!",239
744,744,How to create a model for Question Answering on the SQuAD Dataset?,"Hi guys! I'm new here and I have to create a model for the Question Answering task using only as training data the SQuAD dataset. It's very difficult find something that match my requests, cause all the model used in this task are pretained model like BERT or LUKE and I want to trained the model by myself. 

I would be really grateful to any of you who know how or where to find tutorials or resources.",https://www.reddit.com/r/LanguageTechnology/comments/lj29ww/how_to_create_a_model_for_question_answering_on/,LanguageTechnology,t3_lj29ww,"How to create a model for Question Answering on the SQuAD Dataset? Hi guys! I'm new here and I have to create a model for the Question Answering task using only as training data the SQuAD dataset. It's very difficult find something that match my requests, cause all the model used in this task are pretained model like BERT or LUKE and I want to trained the model by myself. 

I would be really grateful to any of you who know how or where to find tutorials or resources.",471
745,745,Any standard textbooks on Bangla Natural Language Processing or other Indian languages? --Where data preprocessing is nicely explained.,,https://www.reddit.com/r/LanguageTechnology/comments/lj5358/any_standard_textbooks_on_bangla_natural_language/,LanguageTechnology,t3_lj5358,Any standard textbooks on Bangla Natural Language Processing or other Indian languages? --Where data preprocessing is nicely explained. ,136
746,746,"New multilingual models, Spark 2.3 support, new tutorials for Bengali, Bhojpuri, Japanese, T5, and more in 1 line of Python code with NLU 1.1.1!","# John Snow Labs NLU 1.1.1 : New multilingual models, Spark 2.3 support, new tutorials and more! 

## NLU 1.1.1 Release Notes
We are very excited to release NLU 1.1.1!
This release features 3 new tutorial notebooks for Open/Closed book question answering with Google's T5, Intent classification, and Aspect Based NER.
In Addition, NLU 1.1.0 comes with  25+ pre-trained models and pipelines in Amharic, Bengali, Bhojpuri, Japanese, and Korean languages from the [amazing Spark2.7.2 release](https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.2)
Finally, NLU now supports running on Spark 2.3 clusters.


### NLU 1.1.0 New Non-English Models
|Language | nlu.load() reference | Spark NLP Model reference | Type |
|---------|---------------------|----------------------------|------|
|Arabic | [ar.ner](https://nlp.johnsnowlabs.com/2020/12/05/aner_cc_300d_ar.html) |[arabic_w2v_cc_300d](https://nlp.johnsnowlabs.com/2020/12/05/aner_cc_300d_ar.html) | Named Entity Recognizer                    |
|Arabic | [ar.embed.aner](https://nlp.johnsnowlabs.com/2020/12/05/aner_cc_300d_ar.html) |[aner_cc_300d](https://nlp.johnsnowlabs.com/2020/12/05/aner_cc_300d_ar.html) | Word Embedding                    |
|Arabic | [ar.embed.aner.300d](https://nlp.johnsnowlabs.com/2020/12/05/aner_cc_300d_ar.html) |[aner_cc_300d](https://nlp.johnsnowlabs.com/2020/12/05/aner_cc_300d_ar.html) | Word Embedding (Alias)                    |
|Bengali | [bn.stopwords](https://nlp.johnsnowlabs.com/2020/07/14/stopwords_bn.html) |[stopwords_bn](https://nlp.johnsnowlabs.com/2020/07/14/stopwords_bn.html) | Stopwords Cleaner                    |
|Bengali | [bn.pos](https://nlp.johnsnowlabs.com/2021/01/20/pos_msri_bn.html) |[pos_msri](https://nlp.johnsnowlabs.com/2021/01/20/pos_msri_bn.html) | Part of Speech                    |
|Thai | [th.segment_words](https://nlp.johnsnowlabs.com/2021/01/11/ner_lst20_glove_840B_300d_th.html) |[wordseg_best](https://nlp.johnsnowlabs.com/2021/01/11/ner_lst20_glove_840B_300d_th.html) | Word Segmenter                    |
|Thai | [th.pos](https://nlp.johnsnowlabs.com/2021/01/13/pos_lst20_th.html) |[pos_lst20](https://nlp.johnsnowlabs.com/2021/01/13/pos_lst20_th.html) | Part of Speech                    |
|Thai |   [th.sentiment](https://nlp.johnsnowlabs.com/2021/01/14/sentiment_jager_use_th.html) |[sentiment_jager_use](https://nlp.johnsnowlabs.com/2021/01/14/sentiment_jager_use_th.html) | Sentiment Classifier                     |
|Thai |    [th.classify.sentiment](https://nlp.johnsnowlabs.com/2021/01/14/sentiment_jager_use_th.html) |[sentiment_jager_use](https://nlp.johnsnowlabs.com/2021/01/14/sentiment_jager_use_th.html) | Sentiment Classifier (Alias)                    |
|Chinese | [zh.pos.ud_gsd_trad](https://nlp.johnsnowlabs.com/2021/01/25/pos_ud_gsd_trad_zh.html) |[pos_ud_gsd_trad](https://nlp.johnsnowlabs.com/2021/01/25/pos_ud_gsd_trad_zh.html) | Part of Speech                    |
|Chinese | [zh.segment_words.gsd](https://nlp.johnsnowlabs.com/2021/01/25/wordseg_gsd_ud_trad_zh.html) |[wordseg_gsd_ud_trad](https://nlp.johnsnowlabs.com/2021/01/25/wordseg_gsd_ud_trad_zh.html) | Word Segmenter                    |
|Bihari | [bh.pos](https://nlp.johnsnowlabs.com/2021/01/18/pos_ud_bhtb_bh.html) |[pos_ud_bhtb](https://nlp.johnsnowlabs.com/2021/01/18/pos_ud_bhtb_bh.html) | Part of Speech                    |
|Amharic | [am.pos](https://nlp.johnsnowlabs.com/2021/01/20/pos_ud_att_am.html) |[pos_ud_att](https://nlp.johnsnowlabs.com/2021/01/20/pos_ud_att_am.html) | Part of Speech                    |



### NLU 1.1.1 New English Models and Pipelines
|Language | nlu.load() reference | Spark NLP Model reference | Type |
|---------|---------------------|----------------------------|------|
| English | [en.sentiment.glove](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html) |[analyze_sentimentdl_glove_imdb](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html)     | Sentiment Classifier |
| English | [en.sentiment.glove.imdb](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html) |[analyze_sentimentdl_glove_imdb](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html)     | Sentiment Classifier (Alias) |
| English | [en.classify.sentiment.glove.imdb](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html) |[analyze_sentimentdl_glove_imdb](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html)     | Sentiment Classifier (Alias) |
| English | [en.classify.sentiment.glove](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html) |[analyze_sentimentdl_glove_imdb](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html)     | Sentiment Classifier (Alias) |
| English | [en.classify.trec50.pipe](https://nlp.johnsnowlabs.com/2021/01/08/classifierdl_use_trec50_pipeline_en.html) |[classifierdl_use_trec50_pipeline](https://nlp.johnsnowlabs.com/2021/01/08/classifierdl_use_trec50_pipeline_en.html)     | Language Classifier |
| English | [en.ner.onto.large](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_large_en.html) |[onto_recognize_entities_electra_large](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_large_en.html)     | Named Entity Recognizer |
| English | [en.classify.questions.atis](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html) |[classifierdl_use_atis](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html)     | Intent Classifier |
| English  | [en.classify.questions.airline](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html) |[classifierdl_use_atis](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html)     | Intent Classifier (Alias) |
| English | [en.classify.intent.atis](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html) |[classifierdl_use_atis](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html)     | Intent Classifier (Alias) |
| English | [en.classify.intent.airline](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html) |[classifierdl_use_atis](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html)     | Intent Classifier (Alias) |
| English | [en.ner.atis](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html) |[nerdl_atis_840b_300d](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html)     | Aspect based NER |
| English | [en.ner.airline](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html) |[nerdl_atis_840b_300d](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html)     | Aspect based NER (Alias) |
| English | [en.ner.aspect.airline](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html) |[nerdl_atis_840b_300d](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html)     | Aspect based NER (Alias) |
| English | [en.ner.aspect.atis](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html) |[nerdl_atis_840b_300d](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html)     | Aspect based NER (Alias) |

### New Easy NLU 1-liner Examples : 

#### Extract aspects and entities from airline questions (ATIS dataset)
```python
	
nlu.load(""en.ner.atis"").predict(""i want to fly from baltimore to dallas round trip"")
output:  [""baltimore"","" dallas"", ""round trip""]
```



#### Intent Classification for Airline Traffic Information System queries (ATIS dataset)


```python

nlu.load(""en.classify.questions.atis"").predict(""what is the price of flight from newyork to washington"")
output:  ""atis_airfare""	
```



#### Recognize Entities OntoNotes - ELECTRA Large


```python

nlu.load(""en.ner.onto.large"").predict(""Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London."")	
output:  [""Johnson"", ""first"", ""2001"", ""eight years"", ""London""]	
```

#### Question classification of open-domain and fact-based questions Pipeline - TREC50


```python
nlu.load(""en.classify.trec50.pipe"").predict(""When did the construction of stone circles begin in the UK? "")
output:  LOC_other
```

#### Traditional Chinese Word Segmentation

```python
# 'However, this treatment also creates some problems' in Chinese
nlu.load(""zh.segment_words.gsd"").predict(""然而，這樣的處理也衍生了一些問題。"")
output:  [""然而"","","",""這樣"",""的"",""處理"",""也"",""衍生"",""了"",""一些"",""問題"",""。""]

```


#### Part of Speech for Traditional Chinese

```python
# 'However, this treatment also creates some problems' in Chinese
nlu.load(""zh.pos.ud_gsd_trad"").predict(""然而，這樣的處理也衍生了一些問題。"")
```
Output:

|Token |  POS   |
| ----- | ----- |
| 然而  | ADV   |
| ，    | PUNCT |
| 這樣  | PRON  |
| 的    | PART  |
| 處理  | NOUN  |
| 也    | ADV   |
| 衍生  | VERB  |
| 了    | PART  |
| 一些  | ADJ   |
| 問題  | NOUN  |
| 。    | PUNCT |

#### Thai Word Segment Recognition


```python
# 'Mona Lisa is a 16th-century oil painting created by Leonardo held at the Louvre in Paris' in Thai
nlu.loadnlu.load(""th.segment_words"").predict(""Mona Lisa เป็นภาพวาดสีน้ำมันในศตวรรษที่ 16 ที่สร้างโดย Leonardo จัดขึ้นที่พิพิธภัณฑ์ลูฟร์ในปารีส"")

```
Output:

| token |
| --------- |
| M         |
| o         |
| n         |
| a         |
| Lisa      |
| เป็น       |
| ภาพ       |
| ว         |
| า         |
| ด         |
| สีน้ำ       |
| มัน        |
| ใน        |
| ศตวรรษ    |
| ที่         |
| 16        |
| ที่         |
| สร้าง      |
| โ         |
| ด         |
| ย         |
| L         |
| e         |
| o         |
| n         |
| a         |
| r         |
| d         |
| o         |
| จัด        |
| ขึ้น        |
| ที่         |
| พิพิธภัณฑ์    |
| ลูฟร์       |
| ใน        |
| ปารีส      |

#### Part of Speech for Bengali (POS)

```python
# 'The village is also called 'Mod' in Tora language' in Bengali 
nlu.load(""bn.pos"").predict(""বাসস্থান-ঘরগৃহস্থালি তোড়া ভাষায় গ্রামকেও বলে ` মোদ ' ৷"")
```
Output:

| token             | pos  |
| ----------------- | ---- |
| বাসস্থান-ঘরগৃহস্থালি | NN   |
| তোড়া              | NNP  |
| ভাষায়             | NN   |
| গ্রামকেও           | NN   |
| বলে               | VM   |
| `                 | SYM  |
| মোদ               | NN   |
| '                 | SYM  |
| ৷                 | SYM  |



#### Stop Words Cleaner for Bengali


```python
# 'This language is not enough' in Bengali 
df = nlu.load(""bn.stopwords"").predict(""এই ভাষা যথেষ্ট নয়"")

```
Output:

| cleanTokens | token |
| :---------- | :---- |
| ভাষা        | এই    |
| যথেষ্ট       | ভাষা  |
| নয়          | যথেষ্ট |
| None        | নয়    |


#### Part of Speech for Bengali
```python

# 'The people of Ohu know that the foundation of Bhojpuri was shaken' in Bengali
nlu.load('bh.pos').predict(""ओहु लोग के मालूम बा कि श्लील होखते भोजपुरी के नींव हिल जाई"")
```
Output:

| pos   | token   |
| :---- | :------ |
| DET   | ओहु     |
| NOUN  | लोग     |
| ADP   | के      |
| NOUN  | मालूम   |
| VERB  | बा      |
| SCONJ | कि      |
| ADJ   | श्लील   |
| VERB  | होखते   |
| PROPN | भोजपुरी |
| ADP   | के      |
| NOUN  | नींव    |
| VERB  | हिल     |
| AUX   | जाई     |


#### Amharic Part of Speech (POS)
```python
# ' ""Son, finish the job,"" he said.' in Amharic
nlu.load('am.pos').predict('ልጅ ኡ ን ሥራ ው ን አስጨርስ ኧው ኣል ኧሁ ።""')
```

Output:

| pos   | token   |
|:------|:--------|
| NOUN  | ልጅ      |
| DET   | ኡ       |
| PART  | ን       |
| NOUN  | ሥራ      |
| DET   | ው       |
| PART  | ን       |
| VERB  | አስጨርስ   |
| PRON  | ኧው      |
| AUX   | ኣል      |
| PRON  | ኧሁ      |
| PUNCT | ።       |
| NOUN  | ""       |


#### Thai Sentiment Classification
```python
#  'I love peanut butter and jelly!' in thai
nlu.load('th.classify.sentiment').predict('ฉันชอบเนยถั่วและเยลลี่!')[['sentiment','sentiment_confidence']]
```

Output:

| sentiment   |   sentiment_confidence |
|:------------|-----------------------:|
| positive    |               0.999998 |


#### Arabic Named Entity Recognition (NER)
```python
# 'In 1918, the forces of the Arab Revolt liberated Damascus with the help of the British' in Arabic
nlu.load('ar.ner').predict('في عام 1918 حررت قوات الثورة العربية دمشق بمساعدة من الإنكليز',output_level='chunk')[['entities_confidence','ner_confidence','entities']]
```

Output:

| entity_class   | ner_confidence                                                                                                                                                                  | entities            |
|:----------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------|
| ORG                   | [1.0, 1.0, 1.0, 0.9997000098228455, 0.9840999841690063, 0.9987999796867371, 0.9990000128746033, 0.9998999834060669, 0.9998999834060669, 0.9993000030517578, 0.9998999834060669] | قوات الثورة العربية |
| LOC                   | [1.0, 1.0, 1.0, 0.9997000098228455, 0.9840999841690063, 0.9987999796867371, 0.9990000128746033, 0.9998999834060669, 0.9998999834060669, 0.9993000030517578, 0.9998999834060669] | دمشق                |
| PER                   | [1.0, 1.0, 1.0, 0.9997000098228455, 0.9840999841690063, 0.9987999796867371, 0.9990000128746033, 0.9998999834060669, 0.9998999834060669, 0.9993000030517578, 0.9998999834060669] | الإنكليز            |



### NLU 1.1.0 Enhancements : 
-  Spark 2.3 compatibility

### New NLU Notebooks and Tutorials 
- [Open and Closed book question Ansering](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_question_answering.ipynb)
- [Aspect based NER for Airline ATIS]New multilingual models, Spark 2.3 support, new tutorials for Bengali, Bhojpuri, Japanese, T5  and more in 1 line of Python code with NLU 1.1.1!(https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/classifiers/intent_classification_airlines_ATIS.ipynb)
- [Intent Classification for Airline emssages ATIS](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/named_entity_recognition_(NER)/NER_aspect_airline_ATIS.ipynb)

### Installation

```bash
# PyPi
!pip install nlu pyspark==2.4.7
#Conda
# Install NLU from Anaconda/Conda
conda install -c johnsnowlabs nlu
```

### Additional NLU ressources
- [NLU Website](https://nlu.johnsnowlabs.com/)
- [All NLU Tutorial Notebooks](https://nlu.johnsnowlabs.com/docs/en/notebooks)
- [NLU Videos and Blogposts on NLU](https://nlp.johnsnowlabs.com/learn#pythons-nlu-library)
- [NLU on Github](https://github.com/JohnSnowLabs/nlu)",https://www.reddit.com/r/LanguageTechnology/comments/liv1mj/new_multilingual_models_spark_23_support_new/,LanguageTechnology,t3_liv1mj,"New multilingual models, Spark 2.3 support, new tutorials for Bengali, Bhojpuri, Japanese, T5, and more in 1 line of Python code with NLU 1.1.1! # John Snow Labs NLU 1.1.1 : New multilingual models, Spark 2.3 support, new tutorials and more! 

## NLU 1.1.1 Release Notes
We are very excited to release NLU 1.1.1!
This release features 3 new tutorial notebooks for Open/Closed book question answering with Google's T5, Intent classification, and Aspect Based NER.
In Addition, NLU 1.1.0 comes with  25+ pre-trained models and pipelines in Amharic, Bengali, Bhojpuri, Japanese, and Korean languages from the [amazing Spark2.7.2 release](https://github.com/JohnSnowLabs/spark-nlp/releases/tag/2.7.2)
Finally, NLU now supports running on Spark 2.3 clusters.


### NLU 1.1.0 New Non-English Models
|Language | nlu.load() reference | Spark NLP Model reference | Type |
|---------|---------------------|----------------------------|------|
|Arabic | [ar.ner](https://nlp.johnsnowlabs.com/2020/12/05/aner_cc_300d_ar.html) |[arabic_w2v_cc_300d](https://nlp.johnsnowlabs.com/2020/12/05/aner_cc_300d_ar.html) | Named Entity Recognizer                    |
|Arabic | [ar.embed.aner](https://nlp.johnsnowlabs.com/2020/12/05/aner_cc_300d_ar.html) |[aner_cc_300d](https://nlp.johnsnowlabs.com/2020/12/05/aner_cc_300d_ar.html) | Word Embedding                    |
|Arabic | [ar.embed.aner.300d](https://nlp.johnsnowlabs.com/2020/12/05/aner_cc_300d_ar.html) |[aner_cc_300d](https://nlp.johnsnowlabs.com/2020/12/05/aner_cc_300d_ar.html) | Word Embedding (Alias)                    |
|Bengali | [bn.stopwords](https://nlp.johnsnowlabs.com/2020/07/14/stopwords_bn.html) |[stopwords_bn](https://nlp.johnsnowlabs.com/2020/07/14/stopwords_bn.html) | Stopwords Cleaner                    |
|Bengali | [bn.pos](https://nlp.johnsnowlabs.com/2021/01/20/pos_msri_bn.html) |[pos_msri](https://nlp.johnsnowlabs.com/2021/01/20/pos_msri_bn.html) | Part of Speech                    |
|Thai | [th.segment_words](https://nlp.johnsnowlabs.com/2021/01/11/ner_lst20_glove_840B_300d_th.html) |[wordseg_best](https://nlp.johnsnowlabs.com/2021/01/11/ner_lst20_glove_840B_300d_th.html) | Word Segmenter                    |
|Thai | [th.pos](https://nlp.johnsnowlabs.com/2021/01/13/pos_lst20_th.html) |[pos_lst20](https://nlp.johnsnowlabs.com/2021/01/13/pos_lst20_th.html) | Part of Speech                    |
|Thai |   [th.sentiment](https://nlp.johnsnowlabs.com/2021/01/14/sentiment_jager_use_th.html) |[sentiment_jager_use](https://nlp.johnsnowlabs.com/2021/01/14/sentiment_jager_use_th.html) | Sentiment Classifier                     |
|Thai |    [th.classify.sentiment](https://nlp.johnsnowlabs.com/2021/01/14/sentiment_jager_use_th.html) |[sentiment_jager_use](https://nlp.johnsnowlabs.com/2021/01/14/sentiment_jager_use_th.html) | Sentiment Classifier (Alias)                    |
|Chinese | [zh.pos.ud_gsd_trad](https://nlp.johnsnowlabs.com/2021/01/25/pos_ud_gsd_trad_zh.html) |[pos_ud_gsd_trad](https://nlp.johnsnowlabs.com/2021/01/25/pos_ud_gsd_trad_zh.html) | Part of Speech                    |
|Chinese | [zh.segment_words.gsd](https://nlp.johnsnowlabs.com/2021/01/25/wordseg_gsd_ud_trad_zh.html) |[wordseg_gsd_ud_trad](https://nlp.johnsnowlabs.com/2021/01/25/wordseg_gsd_ud_trad_zh.html) | Word Segmenter                    |
|Bihari | [bh.pos](https://nlp.johnsnowlabs.com/2021/01/18/pos_ud_bhtb_bh.html) |[pos_ud_bhtb](https://nlp.johnsnowlabs.com/2021/01/18/pos_ud_bhtb_bh.html) | Part of Speech                    |
|Amharic | [am.pos](https://nlp.johnsnowlabs.com/2021/01/20/pos_ud_att_am.html) |[pos_ud_att](https://nlp.johnsnowlabs.com/2021/01/20/pos_ud_att_am.html) | Part of Speech                    |



### NLU 1.1.1 New English Models and Pipelines
|Language | nlu.load() reference | Spark NLP Model reference | Type |
|---------|---------------------|----------------------------|------|
| English | [en.sentiment.glove](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html) |[analyze_sentimentdl_glove_imdb](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html)     | Sentiment Classifier |
| English | [en.sentiment.glove.imdb](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html) |[analyze_sentimentdl_glove_imdb](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html)     | Sentiment Classifier (Alias) |
| English | [en.classify.sentiment.glove.imdb](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html) |[analyze_sentimentdl_glove_imdb](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html)     | Sentiment Classifier (Alias) |
| English | [en.classify.sentiment.glove](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html) |[analyze_sentimentdl_glove_imdb](https://nlp.johnsnowlabs.com/2021/01/15/analyze_sentimentdl_glove_imdb_en.html)     | Sentiment Classifier (Alias) |
| English | [en.classify.trec50.pipe](https://nlp.johnsnowlabs.com/2021/01/08/classifierdl_use_trec50_pipeline_en.html) |[classifierdl_use_trec50_pipeline](https://nlp.johnsnowlabs.com/2021/01/08/classifierdl_use_trec50_pipeline_en.html)     | Language Classifier |
| English | [en.ner.onto.large](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_large_en.html) |[onto_recognize_entities_electra_large](https://nlp.johnsnowlabs.com/2020/12/09/onto_recognize_entities_electra_large_en.html)     | Named Entity Recognizer |
| English | [en.classify.questions.atis](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html) |[classifierdl_use_atis](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html)     | Intent Classifier |
| English  | [en.classify.questions.airline](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html) |[classifierdl_use_atis](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html)     | Intent Classifier (Alias) |
| English | [en.classify.intent.atis](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html) |[classifierdl_use_atis](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html)     | Intent Classifier (Alias) |
| English | [en.classify.intent.airline](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html) |[classifierdl_use_atis](https://nlp.johnsnowlabs.com/2021/01/25/classifierdl_use_atis_en.html)     | Intent Classifier (Alias) |
| English | [en.ner.atis](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html) |[nerdl_atis_840b_300d](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html)     | Aspect based NER |
| English | [en.ner.airline](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html) |[nerdl_atis_840b_300d](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html)     | Aspect based NER (Alias) |
| English | [en.ner.aspect.airline](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html) |[nerdl_atis_840b_300d](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html)     | Aspect based NER (Alias) |
| English | [en.ner.aspect.atis](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html) |[nerdl_atis_840b_300d](https://nlp.johnsnowlabs.com/2021/01/25/nerdl_atis_840b_300d_en.html)     | Aspect based NER (Alias) |

### New Easy NLU 1-liner Examples : 

#### Extract aspects and entities from airline questions (ATIS dataset)
```python
	
nlu.load(""en.ner.atis"").predict(""i want to fly from baltimore to dallas round trip"")
output:  [""baltimore"","" dallas"", ""round trip""]
```



#### Intent Classification for Airline Traffic Information System queries (ATIS dataset)


```python

nlu.load(""en.classify.questions.atis"").predict(""what is the price of flight from newyork to washington"")
output:  ""atis_airfare""	
```



#### Recognize Entities OntoNotes - ELECTRA Large


```python

nlu.load(""en.ner.onto.large"").predict(""Johnson first entered politics when elected in 2001 as a member of Parliament. He then served eight years as the mayor of London."")	
output:  [""Johnson"", ""first"", ""2001"", ""eight years"", ""London""]	
```

#### Question classification of open-domain and fact-based questions Pipeline - TREC50


```python
nlu.load(""en.classify.trec50.pipe"").predict(""When did the construction of stone circles begin in the UK? "")
output:  LOC_other
```

#### Traditional Chinese Word Segmentation

```python
# 'However, this treatment also creates some problems' in Chinese
nlu.load(""zh.segment_words.gsd"").predict(""然而，這樣的處理也衍生了一些問題。"")
output:  [""然而"","","",""這樣"",""的"",""處理"",""也"",""衍生"",""了"",""一些"",""問題"",""。""]

```


#### Part of Speech for Traditional Chinese

```python
# 'However, this treatment also creates some problems' in Chinese
nlu.load(""zh.pos.ud_gsd_trad"").predict(""然而，這樣的處理也衍生了一些問題。"")
```
Output:

|Token |  POS   |
| ----- | ----- |
| 然而  | ADV   |
| ，    | PUNCT |
| 這樣  | PRON  |
| 的    | PART  |
| 處理  | NOUN  |
| 也    | ADV   |
| 衍生  | VERB  |
| 了    | PART  |
| 一些  | ADJ   |
| 問題  | NOUN  |
| 。    | PUNCT |

#### Thai Word Segment Recognition


```python
# 'Mona Lisa is a 16th-century oil painting created by Leonardo held at the Louvre in Paris' in Thai
nlu.loadnlu.load(""th.segment_words"").predict(""Mona Lisa เป็นภาพวาดสีน้ำมันในศตวรรษที่ 16 ที่สร้างโดย Leonardo จัดขึ้นที่พิพิธภัณฑ์ลูฟร์ในปารีส"")

```
Output:

| token |
| --------- |
| M         |
| o         |
| n         |
| a         |
| Lisa      |
| เป็น       |
| ภาพ       |
| ว         |
| า         |
| ด         |
| สีน้ำ       |
| มัน        |
| ใน        |
| ศตวรรษ    |
| ที่         |
| 16        |
| ที่         |
| สร้าง      |
| โ         |
| ด         |
| ย         |
| L         |
| e         |
| o         |
| n         |
| a         |
| r         |
| d         |
| o         |
| จัด        |
| ขึ้น        |
| ที่         |
| พิพิธภัณฑ์    |
| ลูฟร์       |
| ใน        |
| ปารีส      |

#### Part of Speech for Bengali (POS)

```python
# 'The village is also called 'Mod' in Tora language' in Bengali 
nlu.load(""bn.pos"").predict(""বাসস্থান-ঘরগৃহস্থালি তোড়া ভাষায় গ্রামকেও বলে ` মোদ ' ৷"")
```
Output:

| token             | pos  |
| ----------------- | ---- |
| বাসস্থান-ঘরগৃহস্থালি | NN   |
| তোড়া              | NNP  |
| ভাষায়             | NN   |
| গ্রামকেও           | NN   |
| বলে               | VM   |
| `                 | SYM  |
| মোদ               | NN   |
| '                 | SYM  |
| ৷                 | SYM  |



#### Stop Words Cleaner for Bengali


```python
# 'This language is not enough' in Bengali 
df = nlu.load(""bn.stopwords"").predict(""এই ভাষা যথেষ্ট নয়"")

```
Output:

| cleanTokens | token |
| :---------- | :---- |
| ভাষা        | এই    |
| যথেষ্ট       | ভাষা  |
| নয়          | যথেষ্ট |
| None        | নয়    |


#### Part of Speech for Bengali
```python

# 'The people of Ohu know that the foundation of Bhojpuri was shaken' in Bengali
nlu.load('bh.pos').predict(""ओहु लोग के मालूम बा कि श्लील होखते भोजपुरी के नींव हिल जाई"")
```
Output:

| pos   | token   |
| :---- | :------ |
| DET   | ओहु     |
| NOUN  | लोग     |
| ADP   | के      |
| NOUN  | मालूम   |
| VERB  | बा      |
| SCONJ | कि      |
| ADJ   | श्लील   |
| VERB  | होखते   |
| PROPN | भोजपुरी |
| ADP   | के      |
| NOUN  | नींव    |
| VERB  | हिल     |
| AUX   | जाई     |


#### Amharic Part of Speech (POS)
```python
# ' ""Son, finish the job,"" he said.' in Amharic
nlu.load('am.pos').predict('ልጅ ኡ ን ሥራ ው ን አስጨርስ ኧው ኣል ኧሁ ።""')
```

Output:

| pos   | token   |
|:------|:--------|
| NOUN  | ልጅ      |
| DET   | ኡ       |
| PART  | ን       |
| NOUN  | ሥራ      |
| DET   | ው       |
| PART  | ን       |
| VERB  | አስጨርስ   |
| PRON  | ኧው      |
| AUX   | ኣል      |
| PRON  | ኧሁ      |
| PUNCT | ።       |
| NOUN  | ""       |


#### Thai Sentiment Classification
```python
#  'I love peanut butter and jelly!' in thai
nlu.load('th.classify.sentiment').predict('ฉันชอบเนยถั่วและเยลลี่!')[['sentiment','sentiment_confidence']]
```

Output:

| sentiment   |   sentiment_confidence |
|:------------|-----------------------:|
| positive    |               0.999998 |


#### Arabic Named Entity Recognition (NER)
```python
# 'In 1918, the forces of the Arab Revolt liberated Damascus with the help of the British' in Arabic
nlu.load('ar.ner').predict('في عام 1918 حررت قوات الثورة العربية دمشق بمساعدة من الإنكليز',output_level='chunk')[['entities_confidence','ner_confidence','entities']]
```

Output:

| entity_class   | ner_confidence                                                                                                                                                                  | entities            |
|:----------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------|
| ORG                   | [1.0, 1.0, 1.0, 0.9997000098228455, 0.9840999841690063, 0.9987999796867371, 0.9990000128746033, 0.9998999834060669, 0.9998999834060669, 0.9993000030517578, 0.9998999834060669] | قوات الثورة العربية |
| LOC                   | [1.0, 1.0, 1.0, 0.9997000098228455, 0.9840999841690063, 0.9987999796867371, 0.9990000128746033, 0.9998999834060669, 0.9998999834060669, 0.9993000030517578, 0.9998999834060669] | دمشق                |
| PER                   | [1.0, 1.0, 1.0, 0.9997000098228455, 0.9840999841690063, 0.9987999796867371, 0.9990000128746033, 0.9998999834060669, 0.9998999834060669, 0.9993000030517578, 0.9998999834060669] | الإنكليز            |



### NLU 1.1.0 Enhancements : 
-  Spark 2.3 compatibility

### New NLU Notebooks and Tutorials 
- [Open and Closed book question Ansering](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_question_answering.ipynb)
- [Aspect based NER for Airline ATIS]New multilingual models, Spark 2.3 support, new tutorials for Bengali, Bhojpuri, Japanese, T5  and more in 1 line of Python code with NLU 1.1.1!(https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/classifiers/intent_classification_airlines_ATIS.ipynb)
- [Intent Classification for Airline emssages ATIS](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/named_entity_recognition_(NER)/NER_aspect_airline_ATIS.ipynb)

### Installation

```bash
# PyPi
!pip install nlu pyspark==2.4.7
#Conda
# Install NLU from Anaconda/Conda
conda install -c johnsnowlabs nlu
```

### Additional NLU ressources
- [NLU Website](https://nlu.johnsnowlabs.com/)
- [All NLU Tutorial Notebooks](https://nlu.johnsnowlabs.com/docs/en/notebooks)
- [NLU Videos and Blogposts on NLU](https://nlp.johnsnowlabs.com/learn#pythons-nlu-library)
- [NLU on Github](https://github.com/JohnSnowLabs/nlu)",14777
747,747,Any recommendations for NLP learning material in 2021?,"Could someone recommend some updated NLP learning material? I am looking specifically for NLG and text summarisation. 

One of the most recent books I found is: [Hands-On Python Natural Language Processing: Explore tools and techniques to analyze and process text with a view to building real-world NLP applications](https://www.goodreads.com/book/show/54412967-hands-on-python-natural-language-processing)

by [Aman Kedia](https://www.goodreads.com/author/show/20480128.Aman_Kedia), [Mayank Rasu](https://www.goodreads.com/author/show/20480129.Mayank_Rasu)

but couldn't find any reviews or opinions.. 

Looking forward to your recommendations.",https://www.reddit.com/r/LanguageTechnology/comments/liwfkz/any_recommendations_for_nlp_learning_material_in/,LanguageTechnology,t3_liwfkz,"Any recommendations for NLP learning material in 2021? Could someone recommend some updated NLP learning material? I am looking specifically for NLG and text summarisation. 

One of the most recent books I found is: [Hands-On Python Natural Language Processing: Explore tools and techniques to analyze and process text with a view to building real-world NLP applications](https://www.goodreads.com/book/show/54412967-hands-on-python-natural-language-processing)

by [Aman Kedia](https://www.goodreads.com/author/show/20480128.Aman_Kedia), [Mayank Rasu](https://www.goodreads.com/author/show/20480129.Mayank_Rasu)

but couldn't find any reviews or opinions.. 

Looking forward to your recommendations.",700
748,748,Neural Query Expansion for Code Search,"Searching repositories of existing source code for code snippets is a key task in software engineering. Earlier techniques like Neural Code Search(NCS), takes in a natural language query and outputs relevant code snippets, often suffers incase of short queries or query that have vague intent. Researchers propose NQE for expanding search queries to improve results. 🤠

Blog- https://link.medium.com/uFDypem4Pdb",https://www.reddit.com/r/LanguageTechnology/comments/lix441/neural_query_expansion_for_code_search/,LanguageTechnology,t3_lix441,"Neural Query Expansion for Code Search Searching repositories of existing source code for code snippets is a key task in software engineering. Earlier techniques like Neural Code Search(NCS), takes in a natural language query and outputs relevant code snippets, often suffers incase of short queries or query that have vague intent. Researchers propose NQE for expanding search queries to improve results. 🤠

Blog- https://link.medium.com/uFDypem4Pdb",450
749,749,NLP work in politics/intelligence,"Hi! I will be starting grad school to get my MS in CS this fall and am planning on specializing in NLP and working as an NLP engineer afterwards. I have always been very interested in politics + government work as well and I imagine there's need for NLP work in intelligence. Does anyone in this sub have any experience in this field? Or knows how much opportunity there is, or anything else worth sharing?

Also a bit more generally, how prevalent are CS/NLP jobs related to the humanities? For example, working in a technical role on investigative work for a news company. So roles working in politics/social/advocacy/news (esp if they require writing and communication alongside the CS). Maybe this is more applicable to leadership positions? But is it plausible that I could get a job in these fields/roles after grad school?",https://www.reddit.com/r/LanguageTechnology/comments/lidu7y/nlp_work_in_politicsintelligence/,LanguageTechnology,t3_lidu7y,"NLP work in politics/intelligence Hi! I will be starting grad school to get my MS in CS this fall and am planning on specializing in NLP and working as an NLP engineer afterwards. I have always been very interested in politics + government work as well and I imagine there's need for NLP work in intelligence. Does anyone in this sub have any experience in this field? Or knows how much opportunity there is, or anything else worth sharing?

Also a bit more generally, how prevalent are CS/NLP jobs related to the humanities? For example, working in a technical role on investigative work for a news company. So roles working in politics/social/advocacy/news (esp if they require writing and communication alongside the CS). Maybe this is more applicable to leadership positions? But is it plausible that I could get a job in these fields/roles after grad school?",863
750,750,Semantic Viz: a semantic distance visualizer written in Haskell - let me know what you think!,,https://github.com/malwaredllc/semantic-viz,LanguageTechnology,t3_lip7mb,Semantic Viz: a semantic distance visualizer written in Haskell - let me know what you think! ,94
751,751,How should I go about creating an API to summarize text automatically?,I would like to take the abstractive approach. Eager to learn more about this.,https://www.reddit.com/r/LanguageTechnology/comments/lio1l9/how_should_i_go_about_creating_an_api_to/,LanguageTechnology,t3_lio1l9,How should I go about creating an API to summarize text automatically? I would like to take the abstractive approach. Eager to learn more about this.,149
752,752,Which are some good papers on political science applications of NLP?,"I'm looking for some papers applying NLP to politics.

It doesn't matter if it is new or old, groundbreaking or not, as long as you enjoyed it, I'd like to know about it!",https://www.reddit.com/r/LanguageTechnology/comments/li7q77/which_are_some_good_papers_on_political_science/,LanguageTechnology,t3_li7q77,"Which are some good papers on political science applications of NLP? I'm looking for some papers applying NLP to politics.

It doesn't matter if it is new or old, groundbreaking or not, as long as you enjoyed it, I'd like to know about it!",239
753,753,Recommendations for OpenSource NLP Projects to contribute at,"Hello everyone! I would like to ask you all for recommendations on some interesting NLP projects that are running at the moment and need contributors. I do not have extensive experience, but I'd love a starting point. **Feel free to advertise your open source project here**!",https://www.reddit.com/r/LanguageTechnology/comments/li7hal/recommendations_for_opensource_nlp_projects_to/,LanguageTechnology,t3_li7hal,"Recommendations for OpenSource NLP Projects to contribute at Hello everyone! I would like to ask you all for recommendations on some interesting NLP projects that are running at the moment and need contributors. I do not have extensive experience, but I'd love a starting point. **Feel free to advertise your open source project here**!",336
754,754,Try to improve a DL model with Attention,"Hello everybody,

I've been working with a deep learning model (a parser) for some time to make dependency parsing.

In brief, the model is composed of several embeddings that are passed to a BiLSTM and finally to two classifiers (one for the labels and one for the positions). An idea to improve the model is to integrate a self-attention mechanism to BiLSTM. In particular, the attempts I have made are:

* add self-attention to BiLSTM using this [gist](https://gist.github.com/cbaziotis/94e53bdd6e4852756e0395560ff38aa4)
* add multi head (self) attention using the [function](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html) provided by pytorch

The results obtained are not very comforting ... with self-attention I have a very slight improvement in performance, while with multi head (self) attention I have no improvements.

Being self-attention mechanisms, in the multi head the vectors corresponding to Q (query), K (key) and V (value) are the same and correspond to the BiLSTM output. What I did was to vary the number of heads (2, 4, 6, 8, 10, 12: no improvement). 

The only other attempt I can think of is to use a [BatchNormalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html) layer after the BiLSTM and before the attention or after the attention, but honestly I doubt it will do anything ...

Obviously, adding an attention mechanism does not mean that the model necessarily improves. But I don't know exactly how to justify it. Anyone have any ideas? Or, does anyone have any ideas on how I might try to insert self attention / multi head self attention into BiLSTM?

If you have read this far, thank you very much!",https://www.reddit.com/r/LanguageTechnology/comments/liacim/try_to_improve_a_dl_model_with_attention/,LanguageTechnology,t3_liacim,"Try to improve a DL model with Attention Hello everybody,

I've been working with a deep learning model (a parser) for some time to make dependency parsing.

In brief, the model is composed of several embeddings that are passed to a BiLSTM and finally to two classifiers (one for the labels and one for the positions). An idea to improve the model is to integrate a self-attention mechanism to BiLSTM. In particular, the attempts I have made are:

* add self-attention to BiLSTM using this [gist](https://gist.github.com/cbaziotis/94e53bdd6e4852756e0395560ff38aa4)
* add multi head (self) attention using the [function](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html) provided by pytorch

The results obtained are not very comforting ... with self-attention I have a very slight improvement in performance, while with multi head (self) attention I have no improvements.

Being self-attention mechanisms, in the multi head the vectors corresponding to Q (query), K (key) and V (value) are the same and correspond to the BiLSTM output. What I did was to vary the number of heads (2, 4, 6, 8, 10, 12: no improvement). 

The only other attempt I can think of is to use a [BatchNormalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html) layer after the BiLSTM and before the attention or after the attention, but honestly I doubt it will do anything ...

Obviously, adding an attention mechanism does not mean that the model necessarily improves. But I don't know exactly how to justify it. Anyone have any ideas? Or, does anyone have any ideas on how I might try to insert self attention / multi head self attention into BiLSTM?

If you have read this far, thank you very much!",1726
755,755,[N] ICMI 2020 Best Paper | Gesticulator: A framework for semantically-aware speech-driven gesture generation,,/r/MachineLearning/comments/li16oy/n_icmi_2020_best_paper_gesticulator_a_framework/,LanguageTechnology,t3_liepa3,[N] ICMI 2020 Best Paper | Gesticulator: A framework for semantically-aware speech-driven gesture generation ,109
756,756,Text-generation frontiers,"Hello all. Im a data science graduate student and NLP research assistant looking to write my thesis about generative language models. 

As I understand it, the current field is largely concerned with large scale pre-trained transformer-based models such as the GPT and BERT projects. 

It seems that the scale and computational cost of such models sets very high barriers of entry for researchers aspiring to challenge state-of-the-art or do interesting research in this sub-field. 

So, I’m curious as to what you may consider interesting frontiers within text-generation/generative models. In your opinion, is there anything that would be worth exploring in this subfield, that do not require access to GPT-level resources?

So far I have considered a comparative study of traditional models (word2vec etc) and these pre-trained models on the new Allen Institute [GENIE testbank](https://leaderboard.allenai.org/genie-anlg/submissions/get-started). However, I’d also very much like to build my own model somehow. 

In relation, are there any other NLP frontiers that you might suggest for a thesis project? 

Thanks for reading and for you time. Any inputs would be appreciated and I would be happy to discuss with further with anyone interested. Naturally, I don’t mind sharing credit either.",https://www.reddit.com/r/LanguageTechnology/comments/lidvu7/textgeneration_frontiers/,LanguageTechnology,t3_lidvu7,"Text-generation frontiers Hello all. Im a data science graduate student and NLP research assistant looking to write my thesis about generative language models. 

As I understand it, the current field is largely concerned with large scale pre-trained transformer-based models such as the GPT and BERT projects. 

It seems that the scale and computational cost of such models sets very high barriers of entry for researchers aspiring to challenge state-of-the-art or do interesting research in this sub-field. 

So, I’m curious as to what you may consider interesting frontiers within text-generation/generative models. In your opinion, is there anything that would be worth exploring in this subfield, that do not require access to GPT-level resources?

So far I have considered a comparative study of traditional models (word2vec etc) and these pre-trained models on the new Allen Institute [GENIE testbank](https://leaderboard.allenai.org/genie-anlg/submissions/get-started). However, I’d also very much like to build my own model somehow. 

In relation, are there any other NLP frontiers that you might suggest for a thesis project? 

Thanks for reading and for you time. Any inputs would be appreciated and I would be happy to discuss with further with anyone interested. Naturally, I don’t mind sharing credit either.",1321
757,757,English Speech-to-Text Transcript with Hugging Face,,https://youtu.be/dJAoK5zK36M,LanguageTechnology,t3_lhphom,English Speech-to-Text Transcript with Hugging Face ,52
758,758,Looking for a job!!,"
I want to get a job as a freelancer

Interests 

 - deeplearning
  - NLP
  - Recommender System

Additionally, i am also looking for teammate to do any project with deeplearning.",https://www.reddit.com/r/LanguageTechnology/comments/libjyz/looking_for_a_job/,LanguageTechnology,t3_libjyz,"Looking for a job!! 
I want to get a job as a freelancer

Interests 

 - deeplearning
  - NLP
  - Recommender System

Additionally, i am also looking for teammate to do any project with deeplearning.",199
759,759,"Rebuilding the spellchecker: Well, akchualy...",,https://zverok.github.io/blog/2021-02-10-spellchecker-6.html,LanguageTechnology,t3_lhrb23,"Rebuilding the spellchecker: Well, akchualy... ",47
760,760,Need Reviews Of Saarland and Stuttgart’s Masters NLP Program,"Saarland nlp program = language science and technology
Stuttgart’s nlp program= computational linguistics.

I have got admission in stuttgart nlp program and have applied in saarland’s and will also probably get an admit from there too. So i will be deciding between them for masters.

Both programs “look” great (by module book)  but i need review of real experience of studying there. I guess since saarland is more like a university town hence there will be less work opportunities in the CS or NLP field outside university, compared to stuttgart. But on the other hand saarland is cheaper than stuttgart.

Any other thing i should know about before making the decision. Also, note that i think first 1 or 2 semesters will be online because of covid.

TIA.


Edit: I am unable to find people from stuttgart university in this program (not just on this post, but generally). so if you know someone from this program, can you kindly ask them to help me out here. thanks",https://www.reddit.com/r/LanguageTechnology/comments/lhgvsz/need_reviews_of_saarland_and_stuttgarts_masters/,LanguageTechnology,t3_lhgvsz,"Need Reviews Of Saarland and Stuttgart’s Masters NLP Program Saarland nlp program = language science and technology
Stuttgart’s nlp program= computational linguistics.

I have got admission in stuttgart nlp program and have applied in saarland’s and will also probably get an admit from there too. So i will be deciding between them for masters.

Both programs “look” great (by module book)  but i need review of real experience of studying there. I guess since saarland is more like a university town hence there will be less work opportunities in the CS or NLP field outside university, compared to stuttgart. But on the other hand saarland is cheaper than stuttgart.

Any other thing i should know about before making the decision. Also, note that i think first 1 or 2 semesters will be online because of covid.

TIA.


Edit: I am unable to find people from stuttgart university in this program (not just on this post, but generally). so if you know someone from this program, can you kindly ask them to help me out here. thanks",1031
761,761,Are there more practical tools for KNN searches and storing documents/embeddings?,"I have a semantic searcher that retrieves the most similar documents, and then the similarity for each segment (which are sentences). I have been using FAISS for the KNN search over the documents, then I retrieve the sentences to do a dot product operation and highlight the most similar ones.

I also need to keep my data either pickled, in hdf5, or in json, to be able to build the searcher, but after a while, it takes too long to rebuild. I need to rebuild the searcher because I don't have the option to neither update nor delete from a FAISS index, and I don't think I can save the FAISS index either - can't pickle because it yields an error related to using C++ objects.

I also have to have the searcher object in memory (plus the embedding model itself, which is unavoidable). If you have tried Whoosh (probably is similar to Elastic\_Search), it creates an index file which opened/closed per search/data\_manipulation. I can update and delete documents easily, and besides being fast, doesn't have concurrency problems either, I'd love an option like this.

EDIT: another issue I have with FAISS (and other KNN I have tried at the time), is that they don't handle IDs, instead, they retrieve positions and I need to keep a mapping to the original data.",https://www.reddit.com/r/LanguageTechnology/comments/lhhmec/are_there_more_practical_tools_for_knn_searches/,LanguageTechnology,t3_lhhmec,"Are there more practical tools for KNN searches and storing documents/embeddings? I have a semantic searcher that retrieves the most similar documents, and then the similarity for each segment (which are sentences). I have been using FAISS for the KNN search over the documents, then I retrieve the sentences to do a dot product operation and highlight the most similar ones.

I also need to keep my data either pickled, in hdf5, or in json, to be able to build the searcher, but after a while, it takes too long to rebuild. I need to rebuild the searcher because I don't have the option to neither update nor delete from a FAISS index, and I don't think I can save the FAISS index either - can't pickle because it yields an error related to using C++ objects.

I also have to have the searcher object in memory (plus the embedding model itself, which is unavoidable). If you have tried Whoosh (probably is similar to Elastic\_Search), it creates an index file which opened/closed per search/data\_manipulation. I can update and delete documents easily, and besides being fast, doesn't have concurrency problems either, I'd love an option like this.

EDIT: another issue I have with FAISS (and other KNN I have tried at the time), is that they don't handle IDs, instead, they retrieve positions and I need to keep a mapping to the original data.",1345
762,762,Researchers from the University of Sheffield &amp; Beihang University Introduce a New Approach Based on Transfer Learning to Automate Historical Text Summarization,"The researchers at the University of Sheffield, Beihang University, and Open University’s Knowledge Media Institute have introduced historical text summarization task, where documents in historical forms of a language are summarised in the corresponding modern language.

The process of text summarization is a fundamentally important routine to historians and digital humanities researchers. Historical text summarization is regarded as a particular case of cross-lingual summarization. However, summarizing and interpreting historical documents can cost a lot of time and effort, even for experts. This is due to the limited historical and modern language corpora and cultural and linguistic variations over time.

Paper summary: https://www.marktechpost.com/2021/02/10/researchers-from-the-university-of-sheffield-beihang-university-introduce-a-new-approach-based-on-transfer-learning-to-automate-historical-text-summarization/

Paper: https://arxiv.org/pdf/2101.10759.pdf

Github: https://github.com/Pzoom522/HistSumm",https://www.reddit.com/r/LanguageTechnology/comments/lhb1x7/researchers_from_the_university_of_sheffield/,LanguageTechnology,t3_lhb1x7,"Researchers from the University of Sheffield &amp; Beihang University Introduce a New Approach Based on Transfer Learning to Automate Historical Text Summarization The researchers at the University of Sheffield, Beihang University, and Open University’s Knowledge Media Institute have introduced historical text summarization task, where documents in historical forms of a language are summarised in the corresponding modern language.

The process of text summarization is a fundamentally important routine to historians and digital humanities researchers. Historical text summarization is regarded as a particular case of cross-lingual summarization. However, summarizing and interpreting historical documents can cost a lot of time and effort, even for experts. This is due to the limited historical and modern language corpora and cultural and linguistic variations over time.

Paper summary: https://www.marktechpost.com/2021/02/10/researchers-from-the-university-of-sheffield-beihang-university-introduce-a-new-approach-based-on-transfer-learning-to-automate-historical-text-summarization/

Paper: https://arxiv.org/pdf/2101.10759.pdf

Github: https://github.com/Pzoom522/HistSumm",1185
763,763,Large archive of papers on machine translation starting from the beginning of the field,,http://mt-archive.info,LanguageTechnology,t3_lhal82,Large archive of papers on machine translation starting from the beginning of the field ,88
764,764,NLP Cloud for spaCy NLP models in production,"So many ML projects are failing because teams don't have the skills to deploy their new model to production... [NLP Cloud](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=7fc10c28-ab0d-11eb-bcbc-0242ac130002) wants to solve this problem by providing spaCy users with an easy way to deploy their models to production.

More and more companies are using [spaCy](https://spacy.io/) for their NLP projects as it's a modern and production-ready framework for NLP.

Successfully  serving spaCy NLP models in production is a tough job that has nothing  to do with data science, but that is nevertheless critical to the  success of a project. The goal of [https://nlpcloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=7fc10c28-ab0d-11eb-bcbc-0242ac130002)  is to take care of this DevOps task: developers or data scientists only  have to upload their spaCy models to NLP Cloud and their models are  then served through a RESTful API. NLP Cloud ensures high availability  of the models by automatically scaling the instances, adding redundancy,  managing memory consumption, etc.

All the pre-trained spaCy models are also available and small pre-trained models are actually completely free.

For more details here is the API documentation: [https://docs.nlpcloud.io](https://docs.nlpcloud.io/)

If any question or feedback, don't hesitate to answer this post!",https://www.reddit.com/r/LanguageTechnology/comments/lgum9p/nlp_cloud_for_spacy_nlp_models_in_production/,LanguageTechnology,t3_lgum9p,"NLP Cloud for spaCy NLP models in production So many ML projects are failing because teams don't have the skills to deploy their new model to production... [NLP Cloud](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=7fc10c28-ab0d-11eb-bcbc-0242ac130002) wants to solve this problem by providing spaCy users with an easy way to deploy their models to production.

More and more companies are using [spaCy](https://spacy.io/) for their NLP projects as it's a modern and production-ready framework for NLP.

Successfully  serving spaCy NLP models in production is a tough job that has nothing  to do with data science, but that is nevertheless critical to the  success of a project. The goal of [https://nlpcloud.io](https://nlpcloud.io/?utm_source=reddit&amp;utm_campaign=7fc10c28-ab0d-11eb-bcbc-0242ac130002)  is to take care of this DevOps task: developers or data scientists only  have to upload their spaCy models to NLP Cloud and their models are  then served through a RESTful API. NLP Cloud ensures high availability  of the models by automatically scaling the instances, adding redundancy,  managing memory consumption, etc.

All the pre-trained spaCy models are also available and small pre-trained models are actually completely free.

For more details here is the API documentation: [https://docs.nlpcloud.io](https://docs.nlpcloud.io/)

If any question or feedback, don't hesitate to answer this post!",1419
765,765,"I see mean pool and max pool output of transformer models as representations of passages of text, why not concatenate the two?",I actually tried this and the representation seems to perform worse than using just one of these. Is there a theoretical reason why this might be so?,https://www.reddit.com/r/LanguageTechnology/comments/lh16bv/i_see_mean_pool_and_max_pool_output_of/,LanguageTechnology,t3_lh16bv,"I see mean pool and max pool output of transformer models as representations of passages of text, why not concatenate the two? I actually tried this and the representation seems to perform worse than using just one of these. Is there a theoretical reason why this might be so?",276
766,766,Creating a domain specific part of speech tagger,I tried using parser that are readily available but for some domain specific tasks the parsers do not work well. Could you please recommend me a way to create my own parser or fine tune available ones with some supervision? How do I jump start?,https://www.reddit.com/r/LanguageTechnology/comments/lgx71d/creating_a_domain_specific_part_of_speech_tagger/,LanguageTechnology,t3_lgx71d,Creating a domain specific part of speech tagger I tried using parser that are readily available but for some domain specific tasks the parsers do not work well. Could you please recommend me a way to create my own parser or fine tune available ones with some supervision? How do I jump start?,293
767,767,LibreTranslate - Free and Open Source Machine Translation API,,https://libretranslate.com/,LanguageTechnology,t3_lgijcu,LibreTranslate - Free and Open Source Machine Translation API ,62
768,768,"Intro to Embodied AI: How to combine NLP, CV, and RL",,https://medium.com/machinevision/overview-of-embodied-artificial-intelligence-b7f19d18022,LanguageTechnology,t3_lgfc7h,"Intro to Embodied AI: How to combine NLP, CV, and RL ",53
769,769,Simple question about attention in NLP,"Attention is all the rage (at least, it gets a lot of press) in NLP DL. I have been trying to wrap my head around how and why it works so well. I have embarked on a journey of reading papers and watching YouTube videos (e.g., [https://distill.pub/2016/augmented-rnns/](https://distill.pub/2016/augmented-rnns/) and [https://www.youtube.com/watch?v=KN3ZL65Dze0](https://www.youtube.com/watch?v=KN3ZL65Dze0))

I have one nagging question. One of the key ideas in attention is that the model learns a weight from each item in the input sequence to each item in the output sequence. And I can see that for a single input/output pair (e.g., the input sequence ""The agreement on the European Economic Area was signed in August 1992."" and the corresponding output sequence ""l' accord sur la zone economique europeene a ete signe en aout 1992.""), how the weights are very helpful and important. In this example, the 5th input token ""European"" should/will have a high weight to the 7th output token ""europeene"". Paper figures indeed show nice examples of the weights for single input/output pairs, and those figures make sense to me. But my understanding is in these attention models, there is only *one* set of weights to be learned (and later used) for all input/output pairs. So my question is: how does that work, given the enormous variations possible in sentence structure? For example, does the model expect that there should always be a strong weight between the 5th input token and the 7th output token?  It seems like the weights should be drastically different depending on the specific input/output pair, and that a single, global set of weights won't work well.

Any help or guidance would be much appreciated.",https://www.reddit.com/r/LanguageTechnology/comments/lg3zko/simple_question_about_attention_in_nlp/,LanguageTechnology,t3_lg3zko,"Simple question about attention in NLP Attention is all the rage (at least, it gets a lot of press) in NLP DL. I have been trying to wrap my head around how and why it works so well. I have embarked on a journey of reading papers and watching YouTube videos (e.g., [https://distill.pub/2016/augmented-rnns/](https://distill.pub/2016/augmented-rnns/) and [https://www.youtube.com/watch?v=KN3ZL65Dze0](https://www.youtube.com/watch?v=KN3ZL65Dze0))

I have one nagging question. One of the key ideas in attention is that the model learns a weight from each item in the input sequence to each item in the output sequence. And I can see that for a single input/output pair (e.g., the input sequence ""The agreement on the European Economic Area was signed in August 1992."" and the corresponding output sequence ""l' accord sur la zone economique europeene a ete signe en aout 1992.""), how the weights are very helpful and important. In this example, the 5th input token ""European"" should/will have a high weight to the 7th output token ""europeene"". Paper figures indeed show nice examples of the weights for single input/output pairs, and those figures make sense to me. But my understanding is in these attention models, there is only *one* set of weights to be learned (and later used) for all input/output pairs. So my question is: how does that work, given the enormous variations possible in sentence structure? For example, does the model expect that there should always be a strong weight between the 5th input token and the 7th output token?  It seems like the weights should be drastically different depending on the specific input/output pair, and that a single, global set of weights won't work well.

Any help or guidance would be much appreciated.",1753
770,770,Unit testing neural networks (BERT example),,https://youtu.be/_KVV9jXSzvo,LanguageTechnology,t3_lgat6y,Unit testing neural networks (BERT example) ,44
771,771,Commercial data scientist to NLP-specialist?,"Hello there,

&amp;#x200B;

Long time lurking, never posting, but I'll break the habit here. I saw every now and then there's a post about NLP-focused jobs in the real world, and I wanted to get a bit of discussion going about the future of DS/ML jobs that focus on NLP.

&amp;#x200B;

I'm mainly interested as that is a future I wish to build for myself. Worked in academia in scientific research for some time (physics and psychology) but been a data scientist for the past 2 years-ish, although since Covid started I pretty much became a BI engineer as my firm needed that gap to be filled. I guess the skills of building and monitoring ETL processes, containerisation, as well as plugging in analytics to integrate with other tools or BI frontend can be useful in the long run, so that's why I didn't mind the slight change. 

&amp;#x200B;

Ever since I have worked as a data scientist, I really enjoyed reading and studying about NLP (thank you Dan Jurafsky and Chris Manning for the courses!) , I feel like it hits close to my kinds of challenges. Even though I have not really used it in many projects at work, apart from occasional named entity recognition and lots of regex usage and stuff like that, it still excites me more than other tasks I had to tackle before. I am doing some basic projects on my own every now and then (news for sentiment analysis for trading, decomposing TedX transcripts for some basic insights) but would hardly call that a portfolio. 

&amp;#x200B;

So kind of as a bundle of questions, I was wondering what's a general consensus on someone entering the NLP field without specific research background, ML engineering experience, or computational linguistics studies. To get to a stage where most of my work is with NLP, is it wiser to apply for junior NLP roles given I have experience in data science and some engineering too, or build a stronger NLP portfolio and apply for mid-level role and demonstrate experience and skills in language tech through that rather than work? Plus, projecting for the next 2-3-5 years, what trends should we envisage happening in the NLP workforce/community? 

&amp;#x200B;

Thanks, and take care!",https://www.reddit.com/r/LanguageTechnology/comments/lge15e/commercial_data_scientist_to_nlpspecialist/,LanguageTechnology,t3_lge15e,"Commercial data scientist to NLP-specialist? Hello there,

&amp;#x200B;

Long time lurking, never posting, but I'll break the habit here. I saw every now and then there's a post about NLP-focused jobs in the real world, and I wanted to get a bit of discussion going about the future of DS/ML jobs that focus on NLP.

&amp;#x200B;

I'm mainly interested as that is a future I wish to build for myself. Worked in academia in scientific research for some time (physics and psychology) but been a data scientist for the past 2 years-ish, although since Covid started I pretty much became a BI engineer as my firm needed that gap to be filled. I guess the skills of building and monitoring ETL processes, containerisation, as well as plugging in analytics to integrate with other tools or BI frontend can be useful in the long run, so that's why I didn't mind the slight change. 

&amp;#x200B;

Ever since I have worked as a data scientist, I really enjoyed reading and studying about NLP (thank you Dan Jurafsky and Chris Manning for the courses!) , I feel like it hits close to my kinds of challenges. Even though I have not really used it in many projects at work, apart from occasional named entity recognition and lots of regex usage and stuff like that, it still excites me more than other tasks I had to tackle before. I am doing some basic projects on my own every now and then (news for sentiment analysis for trading, decomposing TedX transcripts for some basic insights) but would hardly call that a portfolio. 

&amp;#x200B;

So kind of as a bundle of questions, I was wondering what's a general consensus on someone entering the NLP field without specific research background, ML engineering experience, or computational linguistics studies. To get to a stage where most of my work is with NLP, is it wiser to apply for junior NLP roles given I have experience in data science and some engineering too, or build a stronger NLP portfolio and apply for mid-level role and demonstrate experience and skills in language tech through that rather than work? Plus, projecting for the next 2-3-5 years, what trends should we envisage happening in the NLP workforce/community? 

&amp;#x200B;

Thanks, and take care!",2214
772,772,How important is classical (non-Neural) ML for NLP?,"My introduction to NLP was from the Stanford lectures on **NLP with Deep Learning** (available freely online - see [here](http://web.stanford.edu/class/cs224n/) for links to the course pages from different years).

I was wondering how much is missed by having jumped straight into neural methods and if I should supplement this with something more classical (e.g. the book **Natural Language Processing with Python**). I also saw there's an older [course](https://web.stanford.edu/~jurafsky/NLPCourseraSlides.html) from Stanford (also available freely online) focusing on more classical methods.",https://www.reddit.com/r/LanguageTechnology/comments/lgawtg/how_important_is_classical_nonneural_ml_for_nlp/,LanguageTechnology,t3_lgawtg,"How important is classical (non-Neural) ML for NLP? My introduction to NLP was from the Stanford lectures on **NLP with Deep Learning** (available freely online - see [here](http://web.stanford.edu/class/cs224n/) for links to the course pages from different years).

I was wondering how much is missed by having jumped straight into neural methods and if I should supplement this with something more classical (e.g. the book **Natural Language Processing with Python**). I also saw there's an older [course](https://web.stanford.edu/~jurafsky/NLPCourseraSlides.html) from Stanford (also available freely online) focusing on more classical methods.",647
773,773,INTERLINGO: Mi nueva APP para aprender idiomas,,https://youtube.com/watch?v=uF3zA60BbXk&amp;feature=share,LanguageTechnology,t3_lgky9k,INTERLINGO: Mi nueva APP para aprender idiomas ,47
774,774,Interesting models for character prediction?,"Hi, I'm taking a course on NLP and the class' final project is about character prediction. The task is to predict the next character given a sequence of characters.

I'm trying to find an interesting model I can use. The default answer would probably be LSTMs, but I want to try using something more interesting.

Any suggestions for a model architecture I could use that's more interesting than LSTMs but still doable by an undergrad without much experience?",https://www.reddit.com/r/LanguageTechnology/comments/lgbrcp/interesting_models_for_character_prediction/,LanguageTechnology,t3_lgbrcp,"Interesting models for character prediction? Hi, I'm taking a course on NLP and the class' final project is about character prediction. The task is to predict the next character given a sequence of characters.

I'm trying to find an interesting model I can use. The default answer would probably be LSTMs, but I want to try using something more interesting.

Any suggestions for a model architecture I could use that's more interesting than LSTMs but still doable by an undergrad without much experience?",504
775,775,Microsoft spelling correction for 100 languages,,https://www.microsoft.com/en-us/research/blog/speller100-zero-shot-spelling-correction-at-scale-for-100-plus-languages/,LanguageTechnology,t3_lfm30k,Microsoft spelling correction for 100 languages ,48
776,776,Detect hate speech using a Transformer with only a few lines of code.,,https://youtu.be/jti2sPQYzeQ,LanguageTechnology,t3_lffvyi,Detect hate speech using a Transformer with only a few lines of code. ,70
777,777,Are there any methods for extracting tokens that make a category unique in a dataset?,"For example, if I have a text classification problem that's trying to determine if a document belongs to ""politics"" or ""sports"", is there a way that I could ""pull out"" a list of the tokens and/or n-grams in ""politics"" that set it apart from ""sports"" as a category? I assume it would be some process of comparing the difference in word frequency across each corpus, and then finding the terms that have the biggest difference in word frequency, but I'm wondering if there is a more efficient or smarter way to do this. Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/lfp5qz/are_there_any_methods_for_extracting_tokens_that/,LanguageTechnology,t3_lfp5qz,"Are there any methods for extracting tokens that make a category unique in a dataset? For example, if I have a text classification problem that's trying to determine if a document belongs to ""politics"" or ""sports"", is there a way that I could ""pull out"" a list of the tokens and/or n-grams in ""politics"" that set it apart from ""sports"" as a category? I assume it would be some process of comparing the difference in word frequency across each corpus, and then finding the terms that have the biggest difference in word frequency, but I'm wondering if there is a more efficient or smarter way to do this. Thanks.",611
778,778,Looking for dataset with empathic language,"Does anyone know of publicly available data which includes labels for levels of empathy/kindness/compassion in text?

I am trying to reproduce old results with new data.",https://www.reddit.com/r/LanguageTechnology/comments/lfkbzf/looking_for_dataset_with_empathic_language/,LanguageTechnology,t3_lfkbzf,"Looking for dataset with empathic language Does anyone know of publicly available data which includes labels for levels of empathy/kindness/compassion in text?

I am trying to reproduce old results with new data.",212
779,779,Help with Named Entity Recognition (I think?) project,"Hey all! Im new to ML and Im working on an iOS project that I am needing a little advice on. I am trying to extract information from advertisements and categorize them. On top of that, I need to associate certain categories with each other so that when they are processed by my computer vision algorithm, they are associated together and presented as a single item. I am kind of stumped on how to approach this problem. I think I need to use some kind of vision algorithm to recognize the relevant parts of the advertisement and then either a vision or NLP algorithm to associate the particular categories within each ad together correctly. Any advice would be greatly, greatly appreciated!",https://www.reddit.com/r/LanguageTechnology/comments/lfjyts/help_with_named_entity_recognition_i_think_project/,LanguageTechnology,t3_lfjyts,"Help with Named Entity Recognition (I think?) project Hey all! Im new to ML and Im working on an iOS project that I am needing a little advice on. I am trying to extract information from advertisements and categorize them. On top of that, I need to associate certain categories with each other so that when they are processed by my computer vision algorithm, they are associated together and presented as a single item. I am kind of stumped on how to approach this problem. I think I need to use some kind of vision algorithm to recognize the relevant parts of the advertisement and then either a vision or NLP algorithm to associate the particular categories within each ad together correctly. Any advice would be greatly, greatly appreciated!",744
780,780,INTERLINGO: Tu nueva APP para aprender INGLES,,https://youtube.com/watch?v=wgFudaFZQpo&amp;feature=share,LanguageTechnology,t3_lfdvwj,INTERLINGO: Tu nueva APP para aprender INGLES ,46
781,781,Where should I start?,"Hi, I'd like to learn NLP by using python3. What should I do to learn? What do I have to know before start? Should I firstly check AI? It's related? Could you share documents or complete course videos. Thanks. 😊",https://www.reddit.com/r/LanguageTechnology/comments/lf97qy/where_should_i_start/,LanguageTechnology,t3_lf97qy,"Where should I start? Hi, I'd like to learn NLP by using python3. What should I do to learn? What do I have to know before start? Should I firstly check AI? It's related? Could you share documents or complete course videos. Thanks. 😊",233
782,782,A Robust and Domain-Adaptive Approach for Low-Resource NER | Research Papers Summary 007,,https://youtu.be/cPngQMYV_CE,LanguageTechnology,t3_letc3i,A Robust and Domain-Adaptive Approach for Low-Resource NER | Research Papers Summary 007 ,89
783,783,Studying linguistic features in emotion analysis with deep learning,"Hello every one 

I am new in NLP , and I want to perform emotion analysis especially (worry) emotion. I have collected tweets related to COVID-19  to classify into 2 classes with deep learning. Someone said you have to make a linguistic study related to the Worry concept to use it as linguistic features and get good results. Does anyone know any resources that can help me or any linguistic resources? Thanks",https://www.reddit.com/r/LanguageTechnology/comments/lesb4q/studying_linguistic_features_in_emotion_analysis/,LanguageTechnology,t3_lesb4q,"Studying linguistic features in emotion analysis with deep learning Hello every one 

I am new in NLP , and I want to perform emotion analysis especially (worry) emotion. I have collected tweets related to COVID-19  to classify into 2 classes with deep learning. Someone said you have to make a linguistic study related to the Worry concept to use it as linguistic features and get good results. Does anyone know any resources that can help me or any linguistic resources? Thanks",479
784,784,I'm looking for nice resources on information retrieval,"I need to retrieve information from papers and I found few tools, but still I don't know how a workflow should be. Can anyone post resources from data preprocessing to model training for information retrieval? Any pre-trained models that I can use (I checked pegasus for summarization, T5 and few others) Help is appreciated.",https://www.reddit.com/r/LanguageTechnology/comments/lepaak/im_looking_for_nice_resources_on_information/,LanguageTechnology,t3_lepaak,"I'm looking for nice resources on information retrieval I need to retrieve information from papers and I found few tools, but still I don't know how a workflow should be. Can anyone post resources from data preprocessing to model training for information retrieval? Any pre-trained models that I can use (I checked pegasus for summarization, T5 and few others) Help is appreciated.",381
785,785,Amazon Alexa Team -- Data Linguist Roles,"Alexa team is hiring ""Data Linguists"", are these literal manual annotation roles? Is Alexa literally hand-tuned based manual decision trees?

&gt; Sample JD Description

&gt; Amazon is seeking a Data Linguist-II to join our Amazon Devices Team. This role focuses on language data, primarily in the areas of text annotation and general data analysis deliverables.

&gt;The Data Linguist-II must have a passion for data, efficiency, accuracy, and should be capable of:

&gt;• Handling unique data analysis requests from a range of data customers

&gt;• Providing data quality expertise to other team members and coaching improvements

&gt;• Delivering high quality work under aggressive deadlines

&gt;• Working autonomously with minimum direction

&gt;• Building a thorough understanding of conventions and providing support to global sites

&gt;• Understanding changes to conventions deployed in response to customers’ requests and modifying workflows accordingly

&gt;• Contributing to process improvements to reduce handling time and improve output

&gt;• Improving software tools by identifying bugs and suggesting enhancements

&gt;• Diving deep into issues and implementing solutions independently

&gt;• Proactively addressing issues and problems

&gt;• Keeping up with changing project conventions and priorities

&gt;Basic Qualifications

&gt;• Bachelor’s degree

&gt;• 2+ years of experience working with written language data, including experience with annotation and other forms of data markup

&gt;• 1+ year(s) of experience working with command line interfaces and basic UNIX commands

&gt;• Near-native level fluency in one or more non-English language

&gt;• Business level fluency in English

&gt;• Working knowledge of Microsoft Office products (e.g. Word, Excel, Access, etc.)


&gt;Preferred Qualifications

&gt;• Bachelor’s degree in Linguistics or Computational Linguistics

&gt;• Interest in semantics and related areas

&gt;• Comfortable working with text from various languages and dialects

&gt;• Ability to quickly grasp technical concepts and learn in-house data processing tools

&gt;• Strong analytical, problem-solving, and critical-thinking skills

&gt;• Practical knowledge of data processing needs and trade-offs

&gt;• Detail-oriented with excellent communication and strong organizational skills

&gt;• Team player with exceptional interpersonal skills and a solution-oriented attitude

&gt;• Comfortable working in a fast-paced, highly-collaborative, dynamic work environment

&gt;• Willingness to support several projects at one time and to accept reprioritization as necessary",https://www.reddit.com/r/LanguageTechnology/comments/lew97t/amazon_alexa_team_data_linguist_roles/,LanguageTechnology,t3_lew97t,"Amazon Alexa Team -- Data Linguist Roles Alexa team is hiring ""Data Linguists"", are these literal manual annotation roles? Is Alexa literally hand-tuned based manual decision trees?

&gt; Sample JD Description

&gt; Amazon is seeking a Data Linguist-II to join our Amazon Devices Team. This role focuses on language data, primarily in the areas of text annotation and general data analysis deliverables.

&gt;The Data Linguist-II must have a passion for data, efficiency, accuracy, and should be capable of:

&gt;• Handling unique data analysis requests from a range of data customers

&gt;• Providing data quality expertise to other team members and coaching improvements

&gt;• Delivering high quality work under aggressive deadlines

&gt;• Working autonomously with minimum direction

&gt;• Building a thorough understanding of conventions and providing support to global sites

&gt;• Understanding changes to conventions deployed in response to customers’ requests and modifying workflows accordingly

&gt;• Contributing to process improvements to reduce handling time and improve output

&gt;• Improving software tools by identifying bugs and suggesting enhancements

&gt;• Diving deep into issues and implementing solutions independently

&gt;• Proactively addressing issues and problems

&gt;• Keeping up with changing project conventions and priorities

&gt;Basic Qualifications

&gt;• Bachelor’s degree

&gt;• 2+ years of experience working with written language data, including experience with annotation and other forms of data markup

&gt;• 1+ year(s) of experience working with command line interfaces and basic UNIX commands

&gt;• Near-native level fluency in one or more non-English language

&gt;• Business level fluency in English

&gt;• Working knowledge of Microsoft Office products (e.g. Word, Excel, Access, etc.)


&gt;Preferred Qualifications

&gt;• Bachelor’s degree in Linguistics or Computational Linguistics

&gt;• Interest in semantics and related areas

&gt;• Comfortable working with text from various languages and dialects

&gt;• Ability to quickly grasp technical concepts and learn in-house data processing tools

&gt;• Strong analytical, problem-solving, and critical-thinking skills

&gt;• Practical knowledge of data processing needs and trade-offs

&gt;• Detail-oriented with excellent communication and strong organizational skills

&gt;• Team player with exceptional interpersonal skills and a solution-oriented attitude

&gt;• Comfortable working in a fast-paced, highly-collaborative, dynamic work environment

&gt;• Willingness to support several projects at one time and to accept reprioritization as necessary",2655
786,786,How can I look up for early-stage NLP companies?,,https://www.reddit.com/r/LanguageTechnology/comments/leks8f/how_can_i_look_up_for_earlystage_nlp_companies/,LanguageTechnology,t3_leks8f,How can I look up for early-stage NLP companies? ,49
787,787,Obsei: OBserve SEgment and Inform,"I created an open source tool to collect textual information from various sources (Social media, app stores and Reddit), then applying NLP models (Sentiment, NER and Classification)  on it and later report them back to various places (Slack, ES, Jira etc). My main aim to add many integrations and use existing opensource NLP models (instead of reinvent the wheel) so user can create practical workflow as fast as possible.

Please try it and gives feedback. [Obsei repo](https://github.com/lalitpagaria/obsei)

![Image](https://raw.githubusercontent.com/lalitpagaria/obsei/master/images/Obsei-flow-diagram.png)",https://www.reddit.com/r/LanguageTechnology/comments/levvxk/obsei_observe_segment_and_inform/,LanguageTechnology,t3_levvxk,"Obsei: OBserve SEgment and Inform I created an open source tool to collect textual information from various sources (Social media, app stores and Reddit), then applying NLP models (Sentiment, NER and Classification)  on it and later report them back to various places (Slack, ES, Jira etc). My main aim to add many integrations and use existing opensource NLP models (instead of reinvent the wheel) so user can create practical workflow as fast as possible.

Please try it and gives feedback. [Obsei repo](https://github.com/lalitpagaria/obsei)

![Image](https://raw.githubusercontent.com/lalitpagaria/obsei/master/images/Obsei-flow-diagram.png)",645
788,788,Small Neural Text Generator Models,"Hi.

I have a very specific dataset with around 20K sentences, that I want to use for a neural text generation pipeline. I'm looking for really lightweight models, which can train fast and give decent (not at all perfect) result. I'm currently using Markov chain models, but while they are decent, they aren't that original, so I'm trying to experiment with NN models.

I've tested textgenrnn, it's good but the model I think is pretty heavy still, not as heavy as XLNet or other transformer models, but still pretty heavy. Any suggestions would be greatly appreciated.",https://www.reddit.com/r/LanguageTechnology/comments/lemmr8/small_neural_text_generator_models/,LanguageTechnology,t3_lemmr8,"Small Neural Text Generator Models Hi.

I have a very specific dataset with around 20K sentences, that I want to use for a neural text generation pipeline. I'm looking for really lightweight models, which can train fast and give decent (not at all perfect) result. I'm currently using Markov chain models, but while they are decent, they aren't that original, so I'm trying to experiment with NN models.

I've tested textgenrnn, it's good but the model I think is pretty heavy still, not as heavy as XLNet or other transformer models, but still pretty heavy. Any suggestions would be greatly appreciated.",604
789,789,NLP model in Python,"Hey everyone! 

I am currently trying to do a sentiment analysis of different text documents. I am using pyhton 3 and jupyter Notebook. The underlying issue is that I am completely new to programming and have probably taking too much on. I was wondering if someone could explain how I can read a .csv file into [textblob.de](https://textblob.de) and actually get a sentiment analysis 

&amp;#x200B;

PS: sorry for all the terrible simplifications but I am a total noob in this field",https://www.reddit.com/r/LanguageTechnology/comments/lel26z/nlp_model_in_python/,LanguageTechnology,t3_lel26z,"NLP model in Python Hey everyone! 

I am currently trying to do a sentiment analysis of different text documents. I am using pyhton 3 and jupyter Notebook. The underlying issue is that I am completely new to programming and have probably taking too much on. I was wondering if someone could explain how I can read a .csv file into [textblob.de](https://textblob.de) and actually get a sentiment analysis 

&amp;#x200B;

PS: sorry for all the terrible simplifications but I am a total noob in this field",502
790,790,Need help with NLU task of getting insights into a real short story,"Hello, I have experimented with an Natural Language Understanding task on a real short story.  The original text is as follows:

&amp;#x200B;

&gt;""The Doctor's Word"", Short Story From ""Maguldi Days"", by R.K. Narayan (1972):  
&gt;  
&gt;People came to him when the patient was on his last legs. Dr Raman often burst out, 'Why couldn't you have come a day earlier?' The reason was obvious - visiting fee twenty-five rupees, and more than that, people liked to shirk the fact that the time had come to call in Dr Raman; for them there was something ominous in the very association. As a result, when the big man came on the scene it was always a quick decision one way or another. There was no scope or time for any kind of wavering or whitewashing. Long years of practice of this kind had bred in the doctor a certain curt truthfulness; for that very reason his opinion was valued; he was not a mere doctor expressing an opinion but a judge pronouncing a verdict. The patient's life hung on his words. This never unduly worried Dr Raman. He never believed that agreeable words ever saved lives. He did not think it was any of his business to provide comforting lies when as a matter of course nature would tell them the truth in a few hours. However, when he glimpsed the faintest sign of hope, he rolled up his sleeve and stepped into the arena: it might be hours or days, but he never withdrew till he wrested the prize from Yama's hands.  
&gt;  
&gt;Today, standing over a bed, the doctor felt that he himself needed someone to tell him soothing lies. He mopped his brow with his kerchief and sat down in the chair beside the bed. On the bed lay his dearest friend in the world: Gopal. They had known each other for forty years now, starting with their kindergarten days. They could not, of course, meet as much as they wanted, each being wrapped in his own family and profession. Occasionally, on a Sunday, Gopal would walk into the consulting room and wait patiently in a corner till the doctor was free. And then they would dine together, see a picture and talk of each other's life and activities. It was a classic friendship, which endured untouched by changing times, circumstances and activities.  
&gt;  
&gt;In his busy round of work, Dr Raman had not noticed that Gopal had not called in for over three months now. He only remembered it when he saw Gopal's son sitting on a bench in the consulting hall one crowded morning.  Dr Raman could not talk to him for over an hour. When he got up and was about to pass on to the operating room, he called up the young man and asked, 'What brings you here, sir?' The youth was nervous and shy. 'Mother sent me here.'  
&gt;  
&gt;'What can I do for you?'  
&gt;  
&gt;'Father is ill...'  
&gt;  
&gt;It was an operation day and he was not free till three in the afternoon. He rushed off straight from the clinic to his friend's house, in Lawley Extension.  
&gt;  
&gt;Gopal lay in bed as if in sleep. The doctor stood over him and asked Gopal's wife, 'How long has he been in bed?'  
&gt;  
&gt;'A month and a half, Doctor.'  
&gt;  
&gt;'Who is attending him?'  
&gt;  
&gt;'A doctor in the next street. He comes down once in three days and gives him medicine.'  
&gt;  
&gt;'What is his name?' He had never heard of him. 'Someone I don't know, but I wish he had had the goodness to tell me about it. Why, why couldn't you have sent me word earlier?'  
&gt;  
&gt;'We thought you would be busy and did not wish to trouble you unnecessarily.' They were apologetic and miserable. There was hardly any time to be lost. He took off his coat and opened his bag. He took out an injection tube, the needle sizzled over the stove. The sick man's wife whimpered in a corner and essayed to ask questions.  
&gt;  
&gt;'Please don't ask questions,' snapped the doctor. He looked at the children, who were watching the sterilizer, and said, 'Send them all away somewhere, except the eldest.'  
&gt;  
&gt;He shot in the drug, sat back in his chair and gazed at the patient's face for over an hour. The patient still remained motionless. The doctor's face gleamed with perspiration, and his eyelids drooped with fatigue. The sick man's wife stood in a corner and watched silently. She asked timidly, 'Doctor, shall I make some coffee for you?' 'No,' he replied, although he felt famished, having missed his midday meal. He got up and said, 'I will be back in a few minutes. Don't disturb him on any account.' He picked up his bag and went to his car. In a quarter of an hour he was back, followed by an assistant and a nurse. The doctor told the lady of the house, ' I have to perform an operation.'  
&gt;  
&gt;'Why, why? Why?' she asked faintly.  
&gt;  
&gt;'I will tell you all that soon. Will you leave your son here to help us, and go over to the next house and stay there till I call you?'  
&gt;  
&gt;The lady felt giddy and sank down on the floor, unable to bear the strain. The nurse attended to her and led her out.  
&gt;  
&gt;At about eight in the evening the patient opened his eyes and stirred slightly in bed. The assistant was overjoyed. He exclaimed enthusiastically, 'Sir, he will pull through.' The doctor looked at him coldly and whispered, ' I would give anything to see him pull through but, but the heart...'  
&gt;  
&gt;'The pulse has improved, sir.'  
&gt;  
&gt;'Well, well,' replied the doctor. 'Don't trust it. It is only a false flash-up, very common in these cases.' He ruminated for a while and added, 'If the pulse keeps up till eight in the morning it will go on for the next forty years, but I doubt very much if we shall see anything of it at all after two tonight.'  
&gt;  
&gt;He sent away the assistant and sat beside the patient. At about eleven the patient opened his eyes and smiled at his friend. He showed a slight improvement, he was able to take in a little food. A great feeling of relief and joy went through the household. They swarmed around the doctor and poured out their gratitude. He sat in his seat beside the bed, gazing sternly at the patient's face, hardly showing any signs of hearing what they were saying to him. The sick man's wife asked, 'Is he now out of danger?' Without turning his head the doctor said, 'Give glucose and brandy every forty minutes; just a couple of spoons will do.' The lady went away to the kitchen. She felt restless. She felt she must know the truth whatever it was. Why was the great man so evasive? The suspense was unbearable.. Perhaps he could not speak so near the patient's bed. She beckoned to him from the kitchen doorway. The doctor rose and went over. She asked, 'What about him now? How is he?' The doctor bit his lips and replied, looking at the floor, 'Don't get excited. Unless you must know about it, don't ask now.' Her eyes opened wide in terror. She clasped her hands together and implored, 'Tell me the truth.' The doctor replied, 'I would rather not talk to you now.' He turned round and went back to his chair. A terrible wailing shot through the still house; the patient stirred and looked about in bewilderment. The doctor got up again, went over to the kitchen door, drew it in securely and shut off the wail.  
&gt;  
&gt;When the doctor resumed his seat the patient asked in the faintest whisper possible, 'Is that someone crying?' The doctor advised, 'Don't exert yourself. You mustn't talk.' He felt the pulse. It was already agitated by the exertion. The patient asked, 'Am I going? Don't hide it from me.' The doctor made a deprecating noise and sat back in his chair. He had never faced a situation like this. It was not in his nature to whitewash. People attached great value to his word because of that. He stole a look at the other. The patient motioned a finger to draw him nearer and whispered, 'I must know how long I am going to last. I must sign the will. It is all ready. Ask my wife for the despatch box. You must sign as a witness.'  
&gt;  
&gt;'Oh!' the doctor exclaimed. 'You are exerting yourself too much. You must be quieter.' He felt idiotic to be repeating it. 'How fine it would be,' he reflected, 'to drop the whole business and run away somewhere without answering anybody any question!' The patient clutched the doctor's wrist with his weak fingers and said, 'Ramu, it is my good fortune that you are here at this moment. I can trust your word. I can't leave my property unsettled. That will mean endless misery for my wife and children. You know all about Subbiah and his gang. Let me sign before it is too late. Tell me...'  
&gt;  
&gt;'Yes, presently,' replied the doctor. He walked off to his car, sat in the back seat and reflected. He looked at his watch. Midnight. If the will was to be signed, it must be done within the next two hours, or never. He could not be responsible for a mess there; he knew the family affairs too well and about those wolves, Subbiah and his gang. But what could he do? If he asked him to sign the will, it would virtually mean a death sentence and destroy the thousandth part of a chance that the patient had of survival. he got down from the car and went in. He resumed his seat in the chair. The patient was staring at him appealingly. The doctor said to himself, 'If my word can save his life, he shall not die. The will be damned.' He called, 'Gopal, listen.' This was the first time he was going to do a piece of acting before a patient, simulate a feeling and conceal his judgement. He stooped over the patient and said, with deliberate emphasis, 'Don't worry about the will now. You are going to live. Your heart is absolutely sound.' A new glow suffused the patient's face as he heard it. He asked in a tone of relief, 'Do you say so? If it comes from your lips it must be true...' The doctor said, 'Quite right. You are improving every second. Sleep in peace. You must not exert yourself on any account. You must sleep very soundly. I will see you in the morning.' The patient looked at him gratefully for a moment and then closed his eyes. The doctor picked up his bag and went out, shutting the door softly behind him.  
&gt;  
&gt;On his way home he stopped for a moment at his hospital, called out his assistant and said, 'That Lawley Extension case. You might expect the collapse any second now. Go there with a tube of --- in hand, and give it in case the struggle is too hard at the end. Hurry up.'  
&gt;  
&gt;Next morning he was back at Lawley Extension at ten. From his car he made a dash for the sick bed. The patient was awake and looked very well. The assistant reported satisfactory pulse. The doctor put his tube to his heart, listened for a while and told the sick man's wife, 'Don't look so unhappy, lady. Your husband will live to be ninety.' When they were going back to the hospital, the assistant sitting beside him in the car asked, 'Is he going to live, sir?'  
&gt;  
&gt;'I will bet on it. He will live to be ninety. He has turned the corner. How he has survived this attack will be a puzzle to me all my life,' replied the doctor.

&amp;#x200B;

Next, I have prepped the data by removing punctuation marks and capital letters etc, resulting in a cleaned up version like this:

&amp;#x200B;

&gt;people came to him when the patient was on his last legs dr raman often burst out why couldnt you have come a day earlier the reason was obvious - visiting fee twenty-five rupees and more than that people liked to shirk the fact that the time had come to call in dr raman for them there was something ominous in the very association as a result when the big man came on the scene it was always a quick decision one way or another there was no scope or time for any kind of wavering or whitewashing long years of practice of this kind had bred in the doctor a certain curt truthfulness for that very reason his opinion was valued he was not a mere doctor expressing an opinion but a judge pronouncing a verdict the patients life hung on his words this never unduly worried dr raman he never believed that agreeable words ever saved lives he did not think it was any of his business to provide comforting lies when as a matter of course nature would tell them the truth in a few hours however when he glimpsed the faintest sign of hope he rolled up his sleeve and stepped into the arena: it might be hours or days but he never withdrew till he wrested the prize from yamas hands today standing over a bed the doctor felt that he himself needed someone to tell him soothing lies he mopped his brow with his kerchief and sat down in the chair beside the bed on the bed lay his dearest friend in the world: gopal they had known each other for forty years now starting with their kindergarten days they could not of course meet as much as they wanted each being wrapped in his own family and profession occasionally on a sunday gopal would walk into the consulting room and wait patiently in a corner till the doctor was free and then they would dine together see a picture and talk of each others life and activities it was a classic friendship which endured untouched by changing times circumstances and activities in his busy round of work dr raman had not noticed that gopal had not called in for over three months now he only remembered it when he saw gopals son sitting on a bench in the consulting hall one crowded morning dr raman could not talk to him for over an hour when he got up and was about to pass on to the operating room he called up the young man and asked what brings you here sir the youth was nervous and shy mother sent me here what can i do for you father is ill it was an operation day and he was not free till three in the afternoon he rushed off straight from the clinic to his friends house in lawley extension gopal lay in bed as if in sleep the doctor stood over him and asked gopals wife how long has he been in bed a month and a half doctor who is attending him a doctor in the next street he comes down once in three days and gives him medicine what is his name he had never heard of him someone i dont know but i wish he had had the goodness to tell me about it why why couldnt you have sent me word earlier we thought you would be busy and did not wish to trouble you unnecessarily they were apologetic and miserable there was hardly any time to be lost he took off his coat and opened his bag he took out an injection tube the needle sizzled over the stove the sick mans wife whimpered in a corner and essayed to ask questions please dont ask questions snapped the doctor he looked at the children who were watching the sterilizer and said send them all away somewhere except the eldest he shot in the drug sat back in his chair and gazed at the patients face for over an hour the patient still remained motionless the doctors face gleamed with perspiration and his eyelids drooped with fatigue the sick mans wife stood in a corner and watched silently she asked timidly doctor shall i make some coffee for you no he replied although he felt famished having missed his midday meal he got up and said i will be back in a few minutes dont disturb him on any account he picked up his bag and went to his car in a quarter of an hour he was back followed by an assistant and a nurse the doctor told the lady of the house i have to perform an operation why why why she asked faintly i will tell you all that soon will you leave your son here to help us and go over to the next house and stay there till i call you the lady felt giddy and sank down on the floor unable to bear the strain the nurse attended to her and led her out at about eight in the evening the patient opened his eyes and stirred slightly in bed the assistant was overjoyed he exclaimed enthusiastically sir he will pull through the doctor looked at him coldly and whispered i would give anything to see him pull through but but the heart the pulse has improved sir well well replied the doctor dont trust it it is only a false flash-up very common in these cases he ruminated for a while and added if the pulse keeps up till eight in the morning it will go on for the next forty years but i doubt very much if we shall see anything of it at all after two tonight he sent away the assistant and sat beside the patient at about eleven the patient opened his eyes and smiled at his friend he showed a slight improvement he was able to take in a little food a great feeling of relief and joy went through the household they swarmed around the doctor and poured out their gratitude he sat in his seat beside the bed gazing sternly at the patients face hardly showing any signs of hearing what they were saying to him the sick mans wife asked is he now out of danger without turning his head the doctor said give glucose and brandy every forty minutes just a couple of spoons will do the lady went away to the kitchen she felt restless she felt she must know the truth whatever it was why was the great man so evasive the suspense was unbearable perhaps he could not speak so near the patients bed she beckoned to him from the kitchen doorway the doctor rose and went over she asked what about him now how is he the doctor bit his lips and replied looking at the floor dont get excited unless you must know about it dont ask now her eyes opened wide in terror she clasped her hands together and implored tell me the truth the doctor replied i would rather not talk to you now he turned round and went back to his chair a terrible wailing shot through the still house the patient stirred and looked about in bewilderment the doctor got up again went over to the kitchen door drew it in securely and shut off the wail when the doctor resumed his seat the patient asked in the faintest whisper possible is that someone crying the doctor advised dont exert yourself you mustnt talk he felt the pulse it was already agitated by the exertion the patient asked am i going dont hide it from me the doctor made a deprecating noise and sat back in his chair he had never faced a situation like this it was not in his nature to whitewash people attached great value to his word because of that he stole a look at the other the patient motioned a finger to draw him nearer and whispered i must know how long i am going to last i must sign the will it is all ready ask my wife for the despatch box you must sign as a witness oh the doctor exclaimed you are exerting yourself too much you must be quieter he felt idiotic to be repeating it how fine it would be he reflected to drop the whole business and run away somewhere without answering anybody any question the patient clutched the doctors wrist with his weak fingers and said ramu it is my good fortune that you are here at this moment i can trust your word i cant leave my property unsettled that will mean endless misery for my wife and children you know all about subbiah and his gang let me sign before it is too late tell me yes presently replied the doctor he walked off to his car sat in the back seat and reflected he looked at his watch midnight if the will was to be signed it must be done within the next two hours or never he could not be responsible for a mess there he knew the family affairs too well and about those wolves subbiah and his gang but what could he do if he asked him to sign the will it would virtually mean a death sentence and destroy the thousandth part of a chance that the patient had of survival he got down from the car and went in he resumed his seat in the chair the patient was staring at him appealingly the doctor said to himself if my word can save his life he shall not die the will be damned he called gopal listen this was the first time he was going to do a piece of acting before a patient simulate a feeling and conceal his judgement he stooped over the patient and said with deliberate emphasis dont worry about the will now you are going to live your heart is absolutely sound a new glow suffused the patients face as he heard it he asked in a tone of relief do you say so if it comes from your lips it must be true the doctor said quite right you are improving every second sleep in peace you must not exert yourself on any account you must sleep very soundly i will see you in the morning the patient looked at him gratefully for a moment and then closed his eyes the doctor picked up his bag and went out shutting the door softly behind him on his way home he stopped for a moment at his hospital called out his assistant and said that lawley extension case you might expect the collapse any second now go there with a tube of --- in hand and give it in case the struggle is too hard at the end hurry up next morning he was back at lawley extension at ten from his car he made a dash for the sick bed the patient was awake and looked very well the assistant reported satisfactory pulse the doctor put his tube to his heart listened for a while and told the sick mans wife dont look so unhappy lady your husband will live to be ninety when they were going back to the hospital the assistant sitting beside him in the car asked is he going to live sir i will bet on it he will live to be ninety he has turned the corner how he has survived this attack will be a puzzle to me all my life replied the doctor

&amp;#x200B;

Next, i extracted a list of unique words used in the text, of which there are a total of 653 unique words in this short story:

&amp;#x200B;

&gt;people came to him when the patient was on his last legs dr raman often burst out why couldnt you have come a day earlier reason obvious - visiting fee twenty-five rupees and more than that liked shirk fact time had call in for them there something ominous very association as result big man scene it always quick decision one way or another no scope any kind of wavering whitewashing long years practice this bred doctor certain curt truthfulness opinion valued he not mere expressing an but judge pronouncing verdict patients life hung words never unduly worried believed agreeable ever saved lives did think business provide comforting lies matter course nature would tell truth few hours however glimpsed faintest sign hope rolled up sleeve stepped into arena: might be days withdrew till wrested prize from yamas hands today standing over bed felt himself needed someone soothing mopped brow with kerchief sat down chair beside lay dearest friend world: gopal they known each other forty now starting their kindergarten could meet much wanted being wrapped own family profession occasionally sunday walk consulting room wait patiently corner free then dine together see picture talk others activities classic friendship which endured untouched by changing times circumstances busy round work noticed called three months only remembered saw gopals son sitting bench hall crowded morning hour got about pass operating young asked what brings here sir youth nervous shy mother sent me can i do father is ill operation afternoon rushed off straight clinic friends house lawley extension if sleep stood wife how has been month half who attending next street comes once gives medicine name heard dont know wish goodness word we thought trouble unnecessarily were apologetic miserable hardly lost took coat opened bag injection tube needle sizzled stove sick mans whimpered

&amp;#x200B;

Then, I have searched for all co-occuring pair of words, neighboring incidents of two-words and three-words phrases, and listed out the most common of those:

&amp;#x200B;

&gt;Index \[2, 5\] Co-occurence of phrase ' to the ' = 5  
Index \[2, 9\] Co-occurence of phrase ' to his ' = 6  
Index \[2, 210\] Co-occurence of phrase ' to be ' = 5  
Index \[5, 6\] Co-occurence of phrase ' the patient ' = 15  
Index \[5, 109\] Co-occurence of phrase ' the doctor ' = 23  
Index \[5, 138\] Co-occurence of phrase ' the patients ' = 5  
Index \[5, 623\] Co-occurence of phrase ' the sick ' = 5  
Index \[12, 13\] Co-occurence of phrase ' dr raman ' = 5  
Index \[51, 5\] Co-occurence of phrase ' in the ' = 15  
Index \[51, 9\] Co-occurence of phrase ' in his ' = 6  
Index \[51, 22\] Co-occurence of phrase ' in a ' = 8  
Index \[54, 22\] Co-occurence of phrase ' for a ' = 5  
Index \[75, 7\] Co-occurence of phrase ' it was ' = 7  
Index \[122, 7\] Co-occurence of phrase ' he was ' = 6  
  
&gt;  
&gt;Index \[5, 6, 7\] Co-occurence of phrase ' the patient was ' = 3  
Index \[5, 6, 433\] Co-occurence of phrase ' the patient asked ' = 2  
Index \[5, 6, 607\] Co-occurence of phrase ' the patient opened ' = 2  
Index \[5, 109, 122\] Co-occurence of phrase ' the doctor he ' = 2  
Index \[5, 623, 624\] Co-occurence of phrase ' the sick mans ' = 4  
Index \[6, 607, 9\] Co-occurence of phrase ' patient opened his ' = 2  
Index \[9, 609, 34\] Co-occurence of phrase ' his bag and ' = 2

&amp;#x200B;

My question is that I feel stuck at a dead end here, because those co-occurrences do not seem to provide any meaningful data by which we can gain insight into the story at hand.

For example, taking out filler words like 'to', 'in' and so forth, the most common occurring word-pair is ""The doctor"" at 23 times. The most common word-triples are only used 3 or 4 times, and not very interesting.

What other tools in the Natural Language Processing toolkit can allow us to gain deeper insights into a short story such as this?

Thank you beforehand!

Cheers!",https://www.reddit.com/r/LanguageTechnology/comments/leo34k/need_help_with_nlu_task_of_getting_insights_into/,LanguageTechnology,t3_leo34k,"Need help with NLU task of getting insights into a real short story Hello, I have experimented with an Natural Language Understanding task on a real short story.  The original text is as follows:

&amp;#x200B;

&gt;""The Doctor's Word"", Short Story From ""Maguldi Days"", by R.K. Narayan (1972):  
&gt;  
&gt;People came to him when the patient was on his last legs. Dr Raman often burst out, 'Why couldn't you have come a day earlier?' The reason was obvious - visiting fee twenty-five rupees, and more than that, people liked to shirk the fact that the time had come to call in Dr Raman; for them there was something ominous in the very association. As a result, when the big man came on the scene it was always a quick decision one way or another. There was no scope or time for any kind of wavering or whitewashing. Long years of practice of this kind had bred in the doctor a certain curt truthfulness; for that very reason his opinion was valued; he was not a mere doctor expressing an opinion but a judge pronouncing a verdict. The patient's life hung on his words. This never unduly worried Dr Raman. He never believed that agreeable words ever saved lives. He did not think it was any of his business to provide comforting lies when as a matter of course nature would tell them the truth in a few hours. However, when he glimpsed the faintest sign of hope, he rolled up his sleeve and stepped into the arena: it might be hours or days, but he never withdrew till he wrested the prize from Yama's hands.  
&gt;  
&gt;Today, standing over a bed, the doctor felt that he himself needed someone to tell him soothing lies. He mopped his brow with his kerchief and sat down in the chair beside the bed. On the bed lay his dearest friend in the world: Gopal. They had known each other for forty years now, starting with their kindergarten days. They could not, of course, meet as much as they wanted, each being wrapped in his own family and profession. Occasionally, on a Sunday, Gopal would walk into the consulting room and wait patiently in a corner till the doctor was free. And then they would dine together, see a picture and talk of each other's life and activities. It was a classic friendship, which endured untouched by changing times, circumstances and activities.  
&gt;  
&gt;In his busy round of work, Dr Raman had not noticed that Gopal had not called in for over three months now. He only remembered it when he saw Gopal's son sitting on a bench in the consulting hall one crowded morning.  Dr Raman could not talk to him for over an hour. When he got up and was about to pass on to the operating room, he called up the young man and asked, 'What brings you here, sir?' The youth was nervous and shy. 'Mother sent me here.'  
&gt;  
&gt;'What can I do for you?'  
&gt;  
&gt;'Father is ill...'  
&gt;  
&gt;It was an operation day and he was not free till three in the afternoon. He rushed off straight from the clinic to his friend's house, in Lawley Extension.  
&gt;  
&gt;Gopal lay in bed as if in sleep. The doctor stood over him and asked Gopal's wife, 'How long has he been in bed?'  
&gt;  
&gt;'A month and a half, Doctor.'  
&gt;  
&gt;'Who is attending him?'  
&gt;  
&gt;'A doctor in the next street. He comes down once in three days and gives him medicine.'  
&gt;  
&gt;'What is his name?' He had never heard of him. 'Someone I don't know, but I wish he had had the goodness to tell me about it. Why, why couldn't you have sent me word earlier?'  
&gt;  
&gt;'We thought you would be busy and did not wish to trouble you unnecessarily.' They were apologetic and miserable. There was hardly any time to be lost. He took off his coat and opened his bag. He took out an injection tube, the needle sizzled over the stove. The sick man's wife whimpered in a corner and essayed to ask questions.  
&gt;  
&gt;'Please don't ask questions,' snapped the doctor. He looked at the children, who were watching the sterilizer, and said, 'Send them all away somewhere, except the eldest.'  
&gt;  
&gt;He shot in the drug, sat back in his chair and gazed at the patient's face for over an hour. The patient still remained motionless. The doctor's face gleamed with perspiration, and his eyelids drooped with fatigue. The sick man's wife stood in a corner and watched silently. She asked timidly, 'Doctor, shall I make some coffee for you?' 'No,' he replied, although he felt famished, having missed his midday meal. He got up and said, 'I will be back in a few minutes. Don't disturb him on any account.' He picked up his bag and went to his car. In a quarter of an hour he was back, followed by an assistant and a nurse. The doctor told the lady of the house, ' I have to perform an operation.'  
&gt;  
&gt;'Why, why? Why?' she asked faintly.  
&gt;  
&gt;'I will tell you all that soon. Will you leave your son here to help us, and go over to the next house and stay there till I call you?'  
&gt;  
&gt;The lady felt giddy and sank down on the floor, unable to bear the strain. The nurse attended to her and led her out.  
&gt;  
&gt;At about eight in the evening the patient opened his eyes and stirred slightly in bed. The assistant was overjoyed. He exclaimed enthusiastically, 'Sir, he will pull through.' The doctor looked at him coldly and whispered, ' I would give anything to see him pull through but, but the heart...'  
&gt;  
&gt;'The pulse has improved, sir.'  
&gt;  
&gt;'Well, well,' replied the doctor. 'Don't trust it. It is only a false flash-up, very common in these cases.' He ruminated for a while and added, 'If the pulse keeps up till eight in the morning it will go on for the next forty years, but I doubt very much if we shall see anything of it at all after two tonight.'  
&gt;  
&gt;He sent away the assistant and sat beside the patient. At about eleven the patient opened his eyes and smiled at his friend. He showed a slight improvement, he was able to take in a little food. A great feeling of relief and joy went through the household. They swarmed around the doctor and poured out their gratitude. He sat in his seat beside the bed, gazing sternly at the patient's face, hardly showing any signs of hearing what they were saying to him. The sick man's wife asked, 'Is he now out of danger?' Without turning his head the doctor said, 'Give glucose and brandy every forty minutes; just a couple of spoons will do.' The lady went away to the kitchen. She felt restless. She felt she must know the truth whatever it was. Why was the great man so evasive? The suspense was unbearable.. Perhaps he could not speak so near the patient's bed. She beckoned to him from the kitchen doorway. The doctor rose and went over. She asked, 'What about him now? How is he?' The doctor bit his lips and replied, looking at the floor, 'Don't get excited. Unless you must know about it, don't ask now.' Her eyes opened wide in terror. She clasped her hands together and implored, 'Tell me the truth.' The doctor replied, 'I would rather not talk to you now.' He turned round and went back to his chair. A terrible wailing shot through the still house; the patient stirred and looked about in bewilderment. The doctor got up again, went over to the kitchen door, drew it in securely and shut off the wail.  
&gt;  
&gt;When the doctor resumed his seat the patient asked in the faintest whisper possible, 'Is that someone crying?' The doctor advised, 'Don't exert yourself. You mustn't talk.' He felt the pulse. It was already agitated by the exertion. The patient asked, 'Am I going? Don't hide it from me.' The doctor made a deprecating noise and sat back in his chair. He had never faced a situation like this. It was not in his nature to whitewash. People attached great value to his word because of that. He stole a look at the other. The patient motioned a finger to draw him nearer and whispered, 'I must know how long I am going to last. I must sign the will. It is all ready. Ask my wife for the despatch box. You must sign as a witness.'  
&gt;  
&gt;'Oh!' the doctor exclaimed. 'You are exerting yourself too much. You must be quieter.' He felt idiotic to be repeating it. 'How fine it would be,' he reflected, 'to drop the whole business and run away somewhere without answering anybody any question!' The patient clutched the doctor's wrist with his weak fingers and said, 'Ramu, it is my good fortune that you are here at this moment. I can trust your word. I can't leave my property unsettled. That will mean endless misery for my wife and children. You know all about Subbiah and his gang. Let me sign before it is too late. Tell me...'  
&gt;  
&gt;'Yes, presently,' replied the doctor. He walked off to his car, sat in the back seat and reflected. He looked at his watch. Midnight. If the will was to be signed, it must be done within the next two hours, or never. He could not be responsible for a mess there; he knew the family affairs too well and about those wolves, Subbiah and his gang. But what could he do? If he asked him to sign the will, it would virtually mean a death sentence and destroy the thousandth part of a chance that the patient had of survival. he got down from the car and went in. He resumed his seat in the chair. The patient was staring at him appealingly. The doctor said to himself, 'If my word can save his life, he shall not die. The will be damned.' He called, 'Gopal, listen.' This was the first time he was going to do a piece of acting before a patient, simulate a feeling and conceal his judgement. He stooped over the patient and said, with deliberate emphasis, 'Don't worry about the will now. You are going to live. Your heart is absolutely sound.' A new glow suffused the patient's face as he heard it. He asked in a tone of relief, 'Do you say so? If it comes from your lips it must be true...' The doctor said, 'Quite right. You are improving every second. Sleep in peace. You must not exert yourself on any account. You must sleep very soundly. I will see you in the morning.' The patient looked at him gratefully for a moment and then closed his eyes. The doctor picked up his bag and went out, shutting the door softly behind him.  
&gt;  
&gt;On his way home he stopped for a moment at his hospital, called out his assistant and said, 'That Lawley Extension case. You might expect the collapse any second now. Go there with a tube of --- in hand, and give it in case the struggle is too hard at the end. Hurry up.'  
&gt;  
&gt;Next morning he was back at Lawley Extension at ten. From his car he made a dash for the sick bed. The patient was awake and looked very well. The assistant reported satisfactory pulse. The doctor put his tube to his heart, listened for a while and told the sick man's wife, 'Don't look so unhappy, lady. Your husband will live to be ninety.' When they were going back to the hospital, the assistant sitting beside him in the car asked, 'Is he going to live, sir?'  
&gt;  
&gt;'I will bet on it. He will live to be ninety. He has turned the corner. How he has survived this attack will be a puzzle to me all my life,' replied the doctor.

&amp;#x200B;

Next, I have prepped the data by removing punctuation marks and capital letters etc, resulting in a cleaned up version like this:

&amp;#x200B;

&gt;people came to him when the patient was on his last legs dr raman often burst out why couldnt you have come a day earlier the reason was obvious - visiting fee twenty-five rupees and more than that people liked to shirk the fact that the time had come to call in dr raman for them there was something ominous in the very association as a result when the big man came on the scene it was always a quick decision one way or another there was no scope or time for any kind of wavering or whitewashing long years of practice of this kind had bred in the doctor a certain curt truthfulness for that very reason his opinion was valued he was not a mere doctor expressing an opinion but a judge pronouncing a verdict the patients life hung on his words this never unduly worried dr raman he never believed that agreeable words ever saved lives he did not think it was any of his business to provide comforting lies when as a matter of course nature would tell them the truth in a few hours however when he glimpsed the faintest sign of hope he rolled up his sleeve and stepped into the arena: it might be hours or days but he never withdrew till he wrested the prize from yamas hands today standing over a bed the doctor felt that he himself needed someone to tell him soothing lies he mopped his brow with his kerchief and sat down in the chair beside the bed on the bed lay his dearest friend in the world: gopal they had known each other for forty years now starting with their kindergarten days they could not of course meet as much as they wanted each being wrapped in his own family and profession occasionally on a sunday gopal would walk into the consulting room and wait patiently in a corner till the doctor was free and then they would dine together see a picture and talk of each others life and activities it was a classic friendship which endured untouched by changing times circumstances and activities in his busy round of work dr raman had not noticed that gopal had not called in for over three months now he only remembered it when he saw gopals son sitting on a bench in the consulting hall one crowded morning dr raman could not talk to him for over an hour when he got up and was about to pass on to the operating room he called up the young man and asked what brings you here sir the youth was nervous and shy mother sent me here what can i do for you father is ill it was an operation day and he was not free till three in the afternoon he rushed off straight from the clinic to his friends house in lawley extension gopal lay in bed as if in sleep the doctor stood over him and asked gopals wife how long has he been in bed a month and a half doctor who is attending him a doctor in the next street he comes down once in three days and gives him medicine what is his name he had never heard of him someone i dont know but i wish he had had the goodness to tell me about it why why couldnt you have sent me word earlier we thought you would be busy and did not wish to trouble you unnecessarily they were apologetic and miserable there was hardly any time to be lost he took off his coat and opened his bag he took out an injection tube the needle sizzled over the stove the sick mans wife whimpered in a corner and essayed to ask questions please dont ask questions snapped the doctor he looked at the children who were watching the sterilizer and said send them all away somewhere except the eldest he shot in the drug sat back in his chair and gazed at the patients face for over an hour the patient still remained motionless the doctors face gleamed with perspiration and his eyelids drooped with fatigue the sick mans wife stood in a corner and watched silently she asked timidly doctor shall i make some coffee for you no he replied although he felt famished having missed his midday meal he got up and said i will be back in a few minutes dont disturb him on any account he picked up his bag and went to his car in a quarter of an hour he was back followed by an assistant and a nurse the doctor told the lady of the house i have to perform an operation why why why she asked faintly i will tell you all that soon will you leave your son here to help us and go over to the next house and stay there till i call you the lady felt giddy and sank down on the floor unable to bear the strain the nurse attended to her and led her out at about eight in the evening the patient opened his eyes and stirred slightly in bed the assistant was overjoyed he exclaimed enthusiastically sir he will pull through the doctor looked at him coldly and whispered i would give anything to see him pull through but but the heart the pulse has improved sir well well replied the doctor dont trust it it is only a false flash-up very common in these cases he ruminated for a while and added if the pulse keeps up till eight in the morning it will go on for the next forty years but i doubt very much if we shall see anything of it at all after two tonight he sent away the assistant and sat beside the patient at about eleven the patient opened his eyes and smiled at his friend he showed a slight improvement he was able to take in a little food a great feeling of relief and joy went through the household they swarmed around the doctor and poured out their gratitude he sat in his seat beside the bed gazing sternly at the patients face hardly showing any signs of hearing what they were saying to him the sick mans wife asked is he now out of danger without turning his head the doctor said give glucose and brandy every forty minutes just a couple of spoons will do the lady went away to the kitchen she felt restless she felt she must know the truth whatever it was why was the great man so evasive the suspense was unbearable perhaps he could not speak so near the patients bed she beckoned to him from the kitchen doorway the doctor rose and went over she asked what about him now how is he the doctor bit his lips and replied looking at the floor dont get excited unless you must know about it dont ask now her eyes opened wide in terror she clasped her hands together and implored tell me the truth the doctor replied i would rather not talk to you now he turned round and went back to his chair a terrible wailing shot through the still house the patient stirred and looked about in bewilderment the doctor got up again went over to the kitchen door drew it in securely and shut off the wail when the doctor resumed his seat the patient asked in the faintest whisper possible is that someone crying the doctor advised dont exert yourself you mustnt talk he felt the pulse it was already agitated by the exertion the patient asked am i going dont hide it from me the doctor made a deprecating noise and sat back in his chair he had never faced a situation like this it was not in his nature to whitewash people attached great value to his word because of that he stole a look at the other the patient motioned a finger to draw him nearer and whispered i must know how long i am going to last i must sign the will it is all ready ask my wife for the despatch box you must sign as a witness oh the doctor exclaimed you are exerting yourself too much you must be quieter he felt idiotic to be repeating it how fine it would be he reflected to drop the whole business and run away somewhere without answering anybody any question the patient clutched the doctors wrist with his weak fingers and said ramu it is my good fortune that you are here at this moment i can trust your word i cant leave my property unsettled that will mean endless misery for my wife and children you know all about subbiah and his gang let me sign before it is too late tell me yes presently replied the doctor he walked off to his car sat in the back seat and reflected he looked at his watch midnight if the will was to be signed it must be done within the next two hours or never he could not be responsible for a mess there he knew the family affairs too well and about those wolves subbiah and his gang but what could he do if he asked him to sign the will it would virtually mean a death sentence and destroy the thousandth part of a chance that the patient had of survival he got down from the car and went in he resumed his seat in the chair the patient was staring at him appealingly the doctor said to himself if my word can save his life he shall not die the will be damned he called gopal listen this was the first time he was going to do a piece of acting before a patient simulate a feeling and conceal his judgement he stooped over the patient and said with deliberate emphasis dont worry about the will now you are going to live your heart is absolutely sound a new glow suffused the patients face as he heard it he asked in a tone of relief do you say so if it comes from your lips it must be true the doctor said quite right you are improving every second sleep in peace you must not exert yourself on any account you must sleep very soundly i will see you in the morning the patient looked at him gratefully for a moment and then closed his eyes the doctor picked up his bag and went out shutting the door softly behind him on his way home he stopped for a moment at his hospital called out his assistant and said that lawley extension case you might expect the collapse any second now go there with a tube of --- in hand and give it in case the struggle is too hard at the end hurry up next morning he was back at lawley extension at ten from his car he made a dash for the sick bed the patient was awake and looked very well the assistant reported satisfactory pulse the doctor put his tube to his heart listened for a while and told the sick mans wife dont look so unhappy lady your husband will live to be ninety when they were going back to the hospital the assistant sitting beside him in the car asked is he going to live sir i will bet on it he will live to be ninety he has turned the corner how he has survived this attack will be a puzzle to me all my life replied the doctor

&amp;#x200B;

Next, i extracted a list of unique words used in the text, of which there are a total of 653 unique words in this short story:

&amp;#x200B;

&gt;people came to him when the patient was on his last legs dr raman often burst out why couldnt you have come a day earlier reason obvious - visiting fee twenty-five rupees and more than that liked shirk fact time had call in for them there something ominous very association as result big man scene it always quick decision one way or another no scope any kind of wavering whitewashing long years practice this bred doctor certain curt truthfulness opinion valued he not mere expressing an but judge pronouncing verdict patients life hung words never unduly worried believed agreeable ever saved lives did think business provide comforting lies matter course nature would tell truth few hours however glimpsed faintest sign hope rolled up sleeve stepped into arena: might be days withdrew till wrested prize from yamas hands today standing over bed felt himself needed someone soothing mopped brow with kerchief sat down chair beside lay dearest friend world: gopal they known each other forty now starting their kindergarten could meet much wanted being wrapped own family profession occasionally sunday walk consulting room wait patiently corner free then dine together see picture talk others activities classic friendship which endured untouched by changing times circumstances busy round work noticed called three months only remembered saw gopals son sitting bench hall crowded morning hour got about pass operating young asked what brings here sir youth nervous shy mother sent me can i do father is ill operation afternoon rushed off straight clinic friends house lawley extension if sleep stood wife how has been month half who attending next street comes once gives medicine name heard dont know wish goodness word we thought trouble unnecessarily were apologetic miserable hardly lost took coat opened bag injection tube needle sizzled stove sick mans whimpered

&amp;#x200B;

Then, I have searched for all co-occuring pair of words, neighboring incidents of two-words and three-words phrases, and listed out the most common of those:

&amp;#x200B;

&gt;Index \[2, 5\] Co-occurence of phrase ' to the ' = 5  
Index \[2, 9\] Co-occurence of phrase ' to his ' = 6  
Index \[2, 210\] Co-occurence of phrase ' to be ' = 5  
Index \[5, 6\] Co-occurence of phrase ' the patient ' = 15  
Index \[5, 109\] Co-occurence of phrase ' the doctor ' = 23  
Index \[5, 138\] Co-occurence of phrase ' the patients ' = 5  
Index \[5, 623\] Co-occurence of phrase ' the sick ' = 5  
Index \[12, 13\] Co-occurence of phrase ' dr raman ' = 5  
Index \[51, 5\] Co-occurence of phrase ' in the ' = 15  
Index \[51, 9\] Co-occurence of phrase ' in his ' = 6  
Index \[51, 22\] Co-occurence of phrase ' in a ' = 8  
Index \[54, 22\] Co-occurence of phrase ' for a ' = 5  
Index \[75, 7\] Co-occurence of phrase ' it was ' = 7  
Index \[122, 7\] Co-occurence of phrase ' he was ' = 6  
  
&gt;  
&gt;Index \[5, 6, 7\] Co-occurence of phrase ' the patient was ' = 3  
Index \[5, 6, 433\] Co-occurence of phrase ' the patient asked ' = 2  
Index \[5, 6, 607\] Co-occurence of phrase ' the patient opened ' = 2  
Index \[5, 109, 122\] Co-occurence of phrase ' the doctor he ' = 2  
Index \[5, 623, 624\] Co-occurence of phrase ' the sick mans ' = 4  
Index \[6, 607, 9\] Co-occurence of phrase ' patient opened his ' = 2  
Index \[9, 609, 34\] Co-occurence of phrase ' his bag and ' = 2

&amp;#x200B;

My question is that I feel stuck at a dead end here, because those co-occurrences do not seem to provide any meaningful data by which we can gain insight into the story at hand.

For example, taking out filler words like 'to', 'in' and so forth, the most common occurring word-pair is ""The doctor"" at 23 times. The most common word-triples are only used 3 or 4 times, and not very interesting.

What other tools in the Natural Language Processing toolkit can allow us to gain deeper insights into a short story such as this?

Thank you beforehand!

Cheers!",25317
791,791,How does working on NLP job looks like?,,https://www.reddit.com/r/LanguageTechnology/comments/le717k/how_does_working_on_nlp_job_looks_like/,LanguageTechnology,t3_le717k,How does working on NLP job looks like? ,40
792,792,Book recommendations,"Hi there,

I am completely new to nlp but already fascinated - especially by the concept of word embeddings. 

Since I am novel to programming in general, can someone recommend a book that gives an overview into different nlp models/techniques without getting to technical? I have no idea whether this even exists or if books are the go to way to acquire knowledge in machine learning. Alternatively if someone could explain good websites/youtube channels/podcasts I highly appreciate.

Fyi, I do have a thorough understanding of linear algebra including matrix-operations so if it gets very detailed on the mathematical layer I am happy to explore. 

Thanks in advance",https://www.reddit.com/r/LanguageTechnology/comments/lelmaa/book_recommendations/,LanguageTechnology,t3_lelmaa,"Book recommendations Hi there,

I am completely new to nlp but already fascinated - especially by the concept of word embeddings. 

Since I am novel to programming in general, can someone recommend a book that gives an overview into different nlp models/techniques without getting to technical? I have no idea whether this even exists or if books are the go to way to acquire knowledge in machine learning. Alternatively if someone could explain good websites/youtube channels/podcasts I highly appreciate.

Fyi, I do have a thorough understanding of linear algebra including matrix-operations so if it gets very detailed on the mathematical layer I am happy to explore. 

Thanks in advance",690
793,793,Beyond Accuracy: Behavioral Testing of NLP models with CheckList,"Often in Natural Language Processing(NLP), we see some kind of accuracy measure as the proof of our model’s correctness. But clearly, such automated objective evaluations end-up resulting in overestimating the performance.  This paper exactly talks about that and proposes new framework for evaluation called CheckList. 🎉 

This paper won Best Paper Award at ACL 2020. 🥇 


Blog - https://lnkd.in/dhgFKRE",https://www.reddit.com/r/LanguageTechnology/comments/ldsuun/beyond_accuracy_behavioral_testing_of_nlp_models/,LanguageTechnology,t3_ldsuun,"Beyond Accuracy: Behavioral Testing of NLP models with CheckList Often in Natural Language Processing(NLP), we see some kind of accuracy measure as the proof of our model’s correctness. But clearly, such automated objective evaluations end-up resulting in overestimating the performance.  This paper exactly talks about that and proposes new framework for evaluation called CheckList. 🎉 

This paper won Best Paper Award at ACL 2020. 🥇 


Blog - https://lnkd.in/dhgFKRE",469
794,794,Interlingo - App de Ingles para MÓVIL (próximo lanzamiento),,https://youtube.com/watch?v=JVMC1QRK6rE&amp;feature=share,LanguageTechnology,t3_le94f1,Interlingo - App de Ingles para MÓVIL (próximo lanzamiento) ,60
795,795,How to match headlines with countries?,"I've been a professional web developer for a couple of years, but never took on a project that uses any kind of ML. Now I have a problem that I'd like to solve with ML, but am having a hard time figuring out what kind of technology is fit for this purpose.

What I want to do is to tag articles by country, based on the headline. A few examples of expected mappings:

""Interview with Martin Jacques on BBC Coverage of China "" =&gt; ""China""  
""The Senate says no to $15"" =&gt; ""United States""  
""Why Memes Will Never Be Monetized "" =&gt; ""International""  
""Along the Thames "" =&gt; ""United Kingdom""  
""Rising Tides: Diving Into Mumbai’s Flooding Challenges "" =&gt; ""India""  
""US Election: What’s at stake for Brazil "" =&gt; ""United States, Brazil""  


What's a reasonable way to solve this problem? Preferably something I can run myself, without using a paid service",https://www.reddit.com/r/LanguageTechnology/comments/ldzyxa/how_to_match_headlines_with_countries/,LanguageTechnology,t3_ldzyxa,"How to match headlines with countries? I've been a professional web developer for a couple of years, but never took on a project that uses any kind of ML. Now I have a problem that I'd like to solve with ML, but am having a hard time figuring out what kind of technology is fit for this purpose.

What I want to do is to tag articles by country, based on the headline. A few examples of expected mappings:

""Interview with Martin Jacques on BBC Coverage of China "" =&gt; ""China""  
""The Senate says no to $15"" =&gt; ""United States""  
""Why Memes Will Never Be Monetized "" =&gt; ""International""  
""Along the Thames "" =&gt; ""United Kingdom""  
""Rising Tides: Diving Into Mumbai’s Flooding Challenges "" =&gt; ""India""  
""US Election: What’s at stake for Brazil "" =&gt; ""United States, Brazil""  


What's a reasonable way to solve this problem? Preferably something I can run myself, without using a paid service",904
796,796,[question] What kind of resources are required to train a decoder-only Transformer end-to-end?,"I would like to train a Transformer to perform a next-word prediction task, using a basic corpus (e.g., a native corpus from Python nltk). Is this doable with the resources I have?

&amp;#x200B;

**Processor**: Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz 3.19 GHz

**RAM:** 16.0 GB (15.8 GB usable)

**GPU:** My Device Manager indicates that I have two: NVIDIA GeForce GTX 1070 &amp;  Intel UHD Graphics 630",https://www.reddit.com/r/LanguageTechnology/comments/ldngxd/question_what_kind_of_resources_are_required_to/,LanguageTechnology,t3_ldngxd,"[question] What kind of resources are required to train a decoder-only Transformer end-to-end? I would like to train a Transformer to perform a next-word prediction task, using a basic corpus (e.g., a native corpus from Python nltk). Is this doable with the resources I have?

&amp;#x200B;

**Processor**: Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz 3.19 GHz

**RAM:** 16.0 GB (15.8 GB usable)

**GPU:** My Device Manager indicates that I have two: NVIDIA GeForce GTX 1070 &amp;  Intel UHD Graphics 630",498
797,797,What are some document-level relation extraction datasets I may have missed?,"Hey guys. Working on a document-level relation extraction (DocRE) task and I'm wondering what kind of datasets there may be.

In the general domain I've only been able to come across DocRED, and there are also the BC5CDR and GDA datasets in the biomedical domain. I'm wondering what else may be out there that I've missed.

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/ldnm43/what_are_some_documentlevel_relation_extraction/,LanguageTechnology,t3_ldnm43,"What are some document-level relation extraction datasets I may have missed? Hey guys. Working on a document-level relation extraction (DocRE) task and I'm wondering what kind of datasets there may be.

In the general domain I've only been able to come across DocRED, and there are also the BC5CDR and GDA datasets in the biomedical domain. I'm wondering what else may be out there that I've missed.

Thanks!",408
798,798,I want to find out popular issues faced by consumers,"Hello everyone!
I'm doing this project where, I'll be taking in consumer complaints. 
The basic aim of my project is to highlight most common issues faced by consumers by using either keyword extraction or document clustering.

Kindly suggest some techniques/tools using which I could implement this.",https://www.reddit.com/r/LanguageTechnology/comments/lde6ci/i_want_to_find_out_popular_issues_faced_by/,LanguageTechnology,t3_lde6ci,"I want to find out popular issues faced by consumers Hello everyone!
I'm doing this project where, I'll be taking in consumer complaints. 
The basic aim of my project is to highlight most common issues faced by consumers by using either keyword extraction or document clustering.

Kindly suggest some techniques/tools using which I could implement this.",353
799,799,"Trained a Markov Chain on a bunch of r/WSB posts and comments. Only 2-word conditional probabilities but honestly, that's all that's necessary 🚀🚀","First two words are the seeds

* your wife didn't marry you because we've understood all along . Deep Fucking Value . Salute !
* gamestop is still a 300% green day . Hold the line , the funds most likely rebought
* the retard you must not be earth shattering dump . Don’t worry everyone always wipes their first
* the retard strength in this nonsense lmao ! Priceless . Good shit Edit: In discovery we could
* stonks can only place I can warm my tendies . Can someone explain how this movie 2
* your wife and her boyfriend extra close tonight . J . Simpson to do another paper trading
* your wife may have covered the shorts to have joined . I can’t buy more shares
* stonks can only hope for the word ""tendies"" . # HOLD HOLD HOLD ! 💎🙌 . Guys
* gamestop is going to $100 Million . DO NOT SELL 💎🙌🏻 , BUY ! ! ! ! Available shares just got bodied ",https://www.reddit.com/r/LanguageTechnology/comments/lcn2ee/trained_a_markov_chain_on_a_bunch_of_rwsb_posts/,LanguageTechnology,t3_lcn2ee,"Trained a Markov Chain on a bunch of r/WSB posts and comments. Only 2-word conditional probabilities but honestly, that's all that's necessary 🚀🚀 First two words are the seeds

* your wife didn't marry you because we've understood all along . Deep Fucking Value . Salute !
* gamestop is still a 300% green day . Hold the line , the funds most likely rebought
* the retard you must not be earth shattering dump . Don’t worry everyone always wipes their first
* the retard strength in this nonsense lmao ! Priceless . Good shit Edit: In discovery we could
* stonks can only place I can warm my tendies . Can someone explain how this movie 2
* your wife and her boyfriend extra close tonight . J . Simpson to do another paper trading
* your wife may have covered the shorts to have joined . I can’t buy more shares
* stonks can only hope for the word ""tendies"" . # HOLD HOLD HOLD ! 💎🙌 . Guys
* gamestop is going to $100 Million . DO NOT SELL 💎🙌🏻 , BUY ! ! ! ! Available shares just got bodied ",990
800,800,Automatic Glossary Creation and Definition Extraction from Text in Unsupervised way,"This blog reflects my learnings from a recent project that I wrapped up as a part of my last semester course. I hope this will be helpful to many of you looking forward to solving similar problems. The task is to come up with an unsupervised technique for automatic extraction of glossary and their respective definitions from some input text (could be the book, chapter, etc)

Blog Link: https://link.medium.com/hjgUMtjECdb",https://www.reddit.com/r/LanguageTechnology/comments/ld25oz/automatic_glossary_creation_and_definition/,LanguageTechnology,t3_ld25oz,"Automatic Glossary Creation and Definition Extraction from Text in Unsupervised way This blog reflects my learnings from a recent project that I wrapped up as a part of my last semester course. I hope this will be helpful to many of you looking forward to solving similar problems. The task is to come up with an unsupervised technique for automatic extraction of glossary and their respective definitions from some input text (could be the book, chapter, etc)

Blog Link: https://link.medium.com/hjgUMtjECdb",508
801,801,POS tagging practice,"NLP enthusiasts - we all know POS tagging is an important task for so many applications. I made a mastery-based assignment to help you practice and learn the Penn Treebank POS tags. Please feel free to share any feedback with me on the assignment. Thank you!

[https://open.openclass.ai/resource/assignment-601c5ae255950e64a8c0d581?code=94s5gGSI1PZKSg](https://open.openclass.ai/resource/assignment-601c5ae255950e64a8c0d581?code=94s5gGSI1PZKSg)",https://www.reddit.com/r/LanguageTechnology/comments/lcw7ld/pos_tagging_practice/,LanguageTechnology,t3_lcw7ld,"POS tagging practice NLP enthusiasts - we all know POS tagging is an important task for so many applications. I made a mastery-based assignment to help you practice and learn the Penn Treebank POS tags. Please feel free to share any feedback with me on the assignment. Thank you!

[https://open.openclass.ai/resource/assignment-601c5ae255950e64a8c0d581?code=94s5gGSI1PZKSg](https://open.openclass.ai/resource/assignment-601c5ae255950e64a8c0d581?code=94s5gGSI1PZKSg)",465
802,802,[Best Practices] on how to organize deep learning projects,"In this article you’ll see how to structure work on deep learning projects — from the inception to deployment, and everything in between. You will learn:

- About the lifecycle of the project.
- Importance of defining an objective or goal of the project.
- Collecting data based on the requirements of the project.
- Model training and results exploration including:
    - Establishing baselines for better results.
    -Adopting techniques and approaches from the existing open-source state-of-the-art models research papers and code repositories.
    - Experiment tracking and management management 
- Model refinement techniques to avoid underfitting and overfitting like:
    - Controlling hyperparameters
    - Regularisation
    - Pruning
- Testing and evaluating your project before deployment.
- Model deployment
- Project maintenance

[Structuring deep learning projects](https://neptune.ai/blog/how-to-organize-deep-learning-projects-best-practices?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-how-to-organize-deep-learning-projects-best-practices&amp;utm_content=languagetechnology)",https://www.reddit.com/r/LanguageTechnology/comments/lcj064/best_practices_on_how_to_organize_deep_learning/,LanguageTechnology,t3_lcj064,"[Best Practices] on how to organize deep learning projects In this article you’ll see how to structure work on deep learning projects — from the inception to deployment, and everything in between. You will learn:

- About the lifecycle of the project.
- Importance of defining an objective or goal of the project.
- Collecting data based on the requirements of the project.
- Model training and results exploration including:
    - Establishing baselines for better results.
    -Adopting techniques and approaches from the existing open-source state-of-the-art models research papers and code repositories.
    - Experiment tracking and management management 
- Model refinement techniques to avoid underfitting and overfitting like:
    - Controlling hyperparameters
    - Regularisation
    - Pruning
- Testing and evaluating your project before deployment.
- Model deployment
- Project maintenance

[Structuring deep learning projects](https://neptune.ai/blog/how-to-organize-deep-learning-projects-best-practices?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-how-to-organize-deep-learning-projects-best-practices&amp;utm_content=languagetechnology)",1167
803,803,The most Spoken Languages in the World - 1900/2021,,https://youtu.be/XMf-XhqLlbo,LanguageTechnology,t3_lcg3pb,The most Spoken Languages in the World - 1900/2021 ,51
804,804,Recognition of logical document structures,"First approach for recognizing logical document structures like texts, sentences, segments, words, chars and sentence/segment depth based on recurrent neural network grammars.

The model is able to recognizing the followig logical document structures

* (t - text start
* (s - sentence start
* (seg - segment start
* (w - word start
* (c - char start
* )- end of logical document structure
* Ti - sentence/segment depth will be measured recursive

 

The sentence

Georg Bendemann, ein junger Kaufmann, saß in seinem Privatzimmer im ersten Stock eines der niedrigen leichtgebauten Häuser, die entlang des Flusses in einer langen Reihe, fast nur in der Höhe und Färbung unterschieden, sich hinzogen.

should be predicted as

(s (seg (w Georg) (w Bendemann) (c ,)) (seg (w ein) (w junger) (w Kaufmann) (c ,)) (seg (w saß) (w in) (w seinem) (w Privatzimmer) (w im) (w ersten) (w Stock) (w eines) (w der) (w niedrigen) (c ,)) (seg (w leichtgebauten) (w Häuser) (c ,)) (seg (w die) (w entlang) (w des) (w Flusses) (w in) (w einer) (w langen) (w Reihe) (c,)) (seg (w fast) (w nur) (w in) (w der) (w Höhe) (w und) (w Färbung) (w unterschieden) (c ,)) (seg (w sich) (w hinzogen) (c .)))

Check out my Github for the full source Code: [https://github.com/Psarpei/Recognition-of-logical-document-structures](https://github.com/Psarpei/Recognition-of-logical-document-structures)",https://www.reddit.com/r/LanguageTechnology/comments/lcqft8/recognition_of_logical_document_structures/,LanguageTechnology,t3_lcqft8,"Recognition of logical document structures First approach for recognizing logical document structures like texts, sentences, segments, words, chars and sentence/segment depth based on recurrent neural network grammars.

The model is able to recognizing the followig logical document structures

* (t - text start
* (s - sentence start
* (seg - segment start
* (w - word start
* (c - char start
* )- end of logical document structure
* Ti - sentence/segment depth will be measured recursive

 

The sentence

Georg Bendemann, ein junger Kaufmann, saß in seinem Privatzimmer im ersten Stock eines der niedrigen leichtgebauten Häuser, die entlang des Flusses in einer langen Reihe, fast nur in der Höhe und Färbung unterschieden, sich hinzogen.

should be predicted as

(s (seg (w Georg) (w Bendemann) (c ,)) (seg (w ein) (w junger) (w Kaufmann) (c ,)) (seg (w saß) (w in) (w seinem) (w Privatzimmer) (w im) (w ersten) (w Stock) (w eines) (w der) (w niedrigen) (c ,)) (seg (w leichtgebauten) (w Häuser) (c ,)) (seg (w die) (w entlang) (w des) (w Flusses) (w in) (w einer) (w langen) (w Reihe) (c,)) (seg (w fast) (w nur) (w in) (w der) (w Höhe) (w und) (w Färbung) (w unterschieden) (c ,)) (seg (w sich) (w hinzogen) (c .)))

Check out my Github for the full source Code: [https://github.com/Psarpei/Recognition-of-logical-document-structures](https://github.com/Psarpei/Recognition-of-logical-document-structures)",1411
805,805,How to stem plural words properly?,"I'm looking for a way to avoid removing ending s when s isn't a suffix. In order to do that, I first check if a word exists in my index, if it does, I don't remove the ending s but If it doesn't, I go on and remove the ending s and add it to the index. But the problem is what to do when starting to build the index.

Imagine we encounter ""books"", I remove s and add ""book"" to my index. On the other hand, I may encounter  ""dangerous"" for the first time, since it doesn't exists in my index yet, I remove s and add ""dangerou"" which is obviously wrong. What should I do?

Specifically I'm looking for ways to properly detect if suffixes and prefixes are indeed one or part of the original word.

P.S: I'm not working on English docs. Therefore I'm looking for general ideas about these situations not ready to use libraries.",https://www.reddit.com/r/LanguageTechnology/comments/lces4e/how_to_stem_plural_words_properly/,LanguageTechnology,t3_lces4e,"How to stem plural words properly? I'm looking for a way to avoid removing ending s when s isn't a suffix. In order to do that, I first check if a word exists in my index, if it does, I don't remove the ending s but If it doesn't, I go on and remove the ending s and add it to the index. But the problem is what to do when starting to build the index.

Imagine we encounter ""books"", I remove s and add ""book"" to my index. On the other hand, I may encounter  ""dangerous"" for the first time, since it doesn't exists in my index yet, I remove s and add ""dangerou"" which is obviously wrong. What should I do?

Specifically I'm looking for ways to properly detect if suffixes and prefixes are indeed one or part of the original word.

P.S: I'm not working on English docs. Therefore I'm looking for general ideas about these situations not ready to use libraries.",858
806,806,Folks'Talks human-computer interaction test 11,,https://youtube.com/watch?v=fl-a-8LEJfU&amp;feature=share,LanguageTechnology,t3_lc8g6b,Folks'Talks human-computer interaction test 11 ,47
807,807,I have a question,"So I'm going through [TensorFlows NLP Zero to Hero](https://www.youtube.com/watch?v=fNxaJsNG3-s) video playlist as an introduction to NLP.

The host shows the word LISTEN and talks about how it may be encoded letter by letter with ASCII.

He then proceeds to show the word SILENT and claims that because it contains the same letters and numbers, it is hard for us to understand the sentiment of the word.

Am I stupid or is it easy as hell to read something in order?",https://www.reddit.com/r/LanguageTechnology/comments/lbvm4u/i_have_a_question/,LanguageTechnology,t3_lbvm4u,"I have a question So I'm going through [TensorFlows NLP Zero to Hero](https://www.youtube.com/watch?v=fNxaJsNG3-s) video playlist as an introduction to NLP.

The host shows the word LISTEN and talks about how it may be encoded letter by letter with ASCII.

He then proceeds to show the word SILENT and claims that because it contains the same letters and numbers, it is hard for us to understand the sentiment of the word.

Am I stupid or is it easy as hell to read something in order?",485
808,808,"How to get an accurate text similarity score between very large documents (dozens or even hundreds of pages of text), when token order matters?","Levenshtein woud be ideal, but it's not computationally feasible to compare hundreds of pages long documents with it. Hamming and other edit-based metrics look good but are also way too time consuming.

Cosine similarity is very fast, but it doesn't take into account the order of appearance of tokens, which matters to me. Same goes for Jaccard and other token-based similarity metrics I've ran across.

Is there a fast algorithm out there which takes into account the order of the sequence?

I don't care about semantic stuff btw, I need to compare texts superficially.",https://www.reddit.com/r/LanguageTechnology/comments/lbl7wk/how_to_get_an_accurate_text_similarity_score/,LanguageTechnology,t3_lbl7wk,"How to get an accurate text similarity score between very large documents (dozens or even hundreds of pages of text), when token order matters? Levenshtein woud be ideal, but it's not computationally feasible to compare hundreds of pages long documents with it. Hamming and other edit-based metrics look good but are also way too time consuming.

Cosine similarity is very fast, but it doesn't take into account the order of appearance of tokens, which matters to me. Same goes for Jaccard and other token-based similarity metrics I've ran across.

Is there a fast algorithm out there which takes into account the order of the sequence?

I don't care about semantic stuff btw, I need to compare texts superficially.",715
809,809,Master’s in NLP or CompLing in Europe (non CS background),"Hello everyone! 
I’m from the US. Recently graduated with BA in Spanish with a minor in Linguistics (3.75 GPA). I have coursework in Spanish, phonology, phonetics, syntax, language and technology and machine learning (only one class).

I’m looking for Master’s in NLP or CL in Europe that are open to applicants from a non CS background. I have intermediate level knowledge of Python and I am taking Python classes through Coursera. I have already completed a few. Are there any programs that are willing to consider applicants from a strictly a language/linguistics background?

Thank you!",https://www.reddit.com/r/LanguageTechnology/comments/lbg5qv/masters_in_nlp_or_compling_in_europe_non_cs/,LanguageTechnology,t3_lbg5qv,"Master’s in NLP or CompLing in Europe (non CS background) Hello everyone! 
I’m from the US. Recently graduated with BA in Spanish with a minor in Linguistics (3.75 GPA). I have coursework in Spanish, phonology, phonetics, syntax, language and technology and machine learning (only one class).

I’m looking for Master’s in NLP or CL in Europe that are open to applicants from a non CS background. I have intermediate level knowledge of Python and I am taking Python classes through Coursera. I have already completed a few. Are there any programs that are willing to consider applicants from a strictly a language/linguistics background?

Thank you!",648
810,810,Connection between WIKIDATA and WORDNETS,Just a quick question.... Are wordnet synsets linked to opendata in any way like wikidata or dbpedia ?,https://www.reddit.com/r/LanguageTechnology/comments/lbkz8e/connection_between_wikidata_and_wordnets/,LanguageTechnology,t3_lbkz8e,Connection between WIKIDATA and WORDNETS Just a quick question.... Are wordnet synsets linked to opendata in any way like wikidata or dbpedia ?,143
811,811,Best module for my project? Please help,"Hi there NLP friends,
Im pretty new to python and NLP. Please help point me in the right direction.

Im curious about potential causes to an effect. Casual inference but maybe not just directly cause and effect, and even more like potential causes that may lead to effect.
I would want to be able to type in an effect and get a collection of all the potential causes and vice versa.
As well the negative or nullifying forces that may potentially oppose the effect.
My project needs me to type in a sentence not just a bag of words. And would return phrases and words that meet the criteria.

Eg. Forest Fire.
 Potential causes and correlations: cigarette, spark, negligence, firepit, lightening strike, fireworks, spontaneous combustion of mulch, dry weather, dry plant matter.
Potentially causes: burn down homes, fear, 
Potential opposing elements: rain, firefighters, fire extinguisher, dump water on camp fire, careful, etc.

Preferably trained on a blend of General academic subjects, psychology, physics, phrases and quotes, and large web commons like wiki, google, etc.",https://www.reddit.com/r/LanguageTechnology/comments/lbrctb/best_module_for_my_project_please_help/,LanguageTechnology,t3_lbrctb,"Best module for my project? Please help Hi there NLP friends,
Im pretty new to python and NLP. Please help point me in the right direction.

Im curious about potential causes to an effect. Casual inference but maybe not just directly cause and effect, and even more like potential causes that may lead to effect.
I would want to be able to type in an effect and get a collection of all the potential causes and vice versa.
As well the negative or nullifying forces that may potentially oppose the effect.
My project needs me to type in a sentence not just a bag of words. And would return phrases and words that meet the criteria.

Eg. Forest Fire.
 Potential causes and correlations: cigarette, spark, negligence, firepit, lightening strike, fireworks, spontaneous combustion of mulch, dry weather, dry plant matter.
Potentially causes: burn down homes, fear, 
Potential opposing elements: rain, firefighters, fire extinguisher, dump water on camp fire, careful, etc.

Preferably trained on a blend of General academic subjects, psychology, physics, phrases and quotes, and large web commons like wiki, google, etc.",1116
812,812,Language acquisition by virtual agent (The Folks’Talks game project), [https://drive.google.com/file/d/1cWNqnOyowoAr3d\_DJZbdIpKuvlAYu7eu/view?usp=sharing](https://drive.google.com/file/d/1cWNqnOyowoAr3d_DJZbdIpKuvlAYu7eu/view?usp=sharing),https://www.reddit.com/r/LanguageTechnology/comments/lbqzvm/language_acquisition_by_virtual_agent_the/,LanguageTechnology,t3_lbqzvm,Language acquisition by virtual agent (The Folks’Talks game project)  [https://drive.google.com/file/d/1cWNqnOyowoAr3d\_DJZbdIpKuvlAYu7eu/view?usp=sharing](https://drive.google.com/file/d/1cWNqnOyowoAr3d_DJZbdIpKuvlAYu7eu/view?usp=sharing),239
813,813,Pororo: A Deep Learning based Multilingual Natural Language Processing Library,"Pororo: A Deep Learning based Multilingual Natural Language Processing Library

Hello, we at Kakao Brain made [Pororo](https://github.com/kakaobrain/pororo) open source based Natural Language and Speech Processing library

Pororo is a Python library that implements more than 30 natural language processing models in various languages ​​such as English, Korean, Chinese, and Japanese.

 Even if you don't know anything about artificial intelligence or natural language processing, you can easily perform various tasks such as name entity recognition, machine reading comprehension, machine translation, summarization, and sentiment classification by writing 3 to 4 lines of code.  For example, NER can be performed with the code below.

 If you install it with pip install pororo, you can use it immediately, and we plan to expand models and tasks by language, so please use and feedback a lot.
 More details can be found at https://github.com/kakaobrain/pororo.  Thank you.",https://www.reddit.com/r/LanguageTechnology/comments/lawow3/pororo_a_deep_learning_based_multilingual_natural/,LanguageTechnology,t3_lawow3,"Pororo: A Deep Learning based Multilingual Natural Language Processing Library Pororo: A Deep Learning based Multilingual Natural Language Processing Library

Hello, we at Kakao Brain made [Pororo](https://github.com/kakaobrain/pororo) open source based Natural Language and Speech Processing library

Pororo is a Python library that implements more than 30 natural language processing models in various languages ​​such as English, Korean, Chinese, and Japanese.

 Even if you don't know anything about artificial intelligence or natural language processing, you can easily perform various tasks such as name entity recognition, machine reading comprehension, machine translation, summarization, and sentiment classification by writing 3 to 4 lines of code.  For example, NER can be performed with the code below.

 If you install it with pip install pororo, you can use it immediately, and we plan to expand models and tasks by language, so please use and feedback a lot.
 More details can be found at https://github.com/kakaobrain/pororo.  Thank you.",1053
814,814,How do you explain NLP to someone who's never heard of NLP?,"I'm a marketing, college student learning about AI and NLP. I have noticed that when I try to explain NLP to my non-technical friends, they have a hard time understanding. I know this group talks about more technical stuff (and I cannot understand 90% of the conversations), but does anyone have any suggestions on how I can explain NLP to someone who's never heard of NLP?",https://www.reddit.com/r/LanguageTechnology/comments/lb4lg5/how_do_you_explain_nlp_to_someone_whos_never/,LanguageTechnology,t3_lb4lg5,"How do you explain NLP to someone who's never heard of NLP? I'm a marketing, college student learning about AI and NLP. I have noticed that when I try to explain NLP to my non-technical friends, they have a hard time understanding. I know this group talks about more technical stuff (and I cannot understand 90% of the conversations), but does anyone have any suggestions on how I can explain NLP to someone who's never heard of NLP?",433
815,815,What is a good task to demonstrate the power of a new language modeling architecture?,"So we are doing a class project, which requires use to use NLP. We have chosen to design a model akin to the Transformer. The faculty evaluating us is a tad inexperienced with language modeling, so we would like to demonstrate the performance gains and competency of our model using a simple task, like article generation, for example.
What other tasks would you recommend, especially those that have comprehensive datasets available?",https://www.reddit.com/r/LanguageTechnology/comments/lasuz2/what_is_a_good_task_to_demonstrate_the_power_of_a/,LanguageTechnology,t3_lasuz2,"What is a good task to demonstrate the power of a new language modeling architecture? So we are doing a class project, which requires use to use NLP. We have chosen to design a model akin to the Transformer. The faculty evaluating us is a tad inexperienced with language modeling, so we would like to demonstrate the performance gains and competency of our model using a simple task, like article generation, for example.
What other tasks would you recommend, especially those that have comprehensive datasets available?",520
816,816,[DATASET] Massive multi-turn conversational dataset based on cleaned discord data,"This is a long-context, anonymized, clean, multi-turn and single-turn conversational dataset based on discord data scraped from a large variety of severs, big and small.

The goal is to use this data to pretrain a small conversational model on a big variety of data.

The raw data for this version contained 51,826,268 messages5103788 (regex) + 696161 (toxic)/51826268, or 0.11% of the messages were removed**The dataset's final size is 46,026,319 messages across 456810 conversations**, which is reduced from 33.06 GB of raw json data to 968.87 MB

[https://www.kaggle.com/jef1056/discord-data](https://www.kaggle.com/jef1056/discord-data)",https://www.reddit.com/r/LanguageTechnology/comments/lap9r9/dataset_massive_multiturn_conversational_dataset/,LanguageTechnology,t3_lap9r9,"[DATASET] Massive multi-turn conversational dataset based on cleaned discord data This is a long-context, anonymized, clean, multi-turn and single-turn conversational dataset based on discord data scraped from a large variety of severs, big and small.

The goal is to use this data to pretrain a small conversational model on a big variety of data.

The raw data for this version contained 51,826,268 messages5103788 (regex) + 696161 (toxic)/51826268, or 0.11% of the messages were removed**The dataset's final size is 46,026,319 messages across 456810 conversations**, which is reduced from 33.06 GB of raw json data to 968.87 MB

[https://www.kaggle.com/jef1056/discord-data](https://www.kaggle.com/jef1056/discord-data)",722
817,817,"What do you do at work? I’m a student in computational linguistics, wondering what the actuality of the degree is","Title explains itself. I’m a sophomore studying linguistics with a concentration in computational linguistics. If you feel so inclined the include salary, I would not mind either!",https://www.reddit.com/r/LanguageTechnology/comments/lah4yg/what_do_you_do_at_work_im_a_student_in/,LanguageTechnology,t3_lah4yg,"What do you do at work? I’m a student in computational linguistics, wondering what the actuality of the degree is Title explains itself. I’m a sophomore studying linguistics with a concentration in computational linguistics. If you feel so inclined the include salary, I would not mind either!",293
818,818,Why don't we fine-tune BERT tokenizer?,We fine-tune the work representations in BERT to learn information from the task but we don't touch the tokenizer. Why don't we learn better subword representations from the task too?,https://www.reddit.com/r/LanguageTechnology/comments/lap79p/why_dont_we_finetune_bert_tokenizer/,LanguageTechnology,t3_lap79p,Why don't we fine-tune BERT tokenizer? We fine-tune the work representations in BERT to learn information from the task but we don't touch the tokenizer. Why don't we learn better subword representations from the task too?,222
819,819,How should I go with training a word decompounder?,"I would like to look into and train a word decompounder for Nordic languages. However, I have never done it, so I am not really familiar with which methods work best. Would anyone have any advice?",https://www.reddit.com/r/LanguageTechnology/comments/lau3dm/how_should_i_go_with_training_a_word_decompounder/,LanguageTechnology,t3_lau3dm,"How should I go with training a word decompounder? I would like to look into and train a word decompounder for Nordic languages. However, I have never done it, so I am not really familiar with which methods work best. Would anyone have any advice?",247
820,820,Current state of the art for document classification?,"I have a problem where I need to classify chunks of text as to whether they pertain to the pharmaceutical industry or not. It will be a supervised learning task but I will need to go through the process of manually labeling the text to come up with the training data.

What are the current state-of-the-art text classifiers and are they feasible to use given my constraints?",https://www.reddit.com/r/LanguageTechnology/comments/laliqu/current_state_of_the_art_for_document/,LanguageTechnology,t3_laliqu,"Current state of the art for document classification? I have a problem where I need to classify chunks of text as to whether they pertain to the pharmaceutical industry or not. It will be a supervised learning task but I will need to go through the process of manually labeling the text to come up with the training data.

What are the current state-of-the-art text classifiers and are they feasible to use given my constraints?",428
821,821,Do companies offer NLP Research Internships for the summer before starting grad school?,"I have been fortunate enough to be accepted into three schools so far for an MS degree and am waiting on others. Therefore, I have begun searching for internships for this upcoming summer. I have found that most research internships only want Ph.D. students. I have tried cold-emailing, connecting, asking research scientists for a ""coffee chat,"" etc. Unfortunately, I have had no success. Is there any place I should be looking? Is it rare for people in my position not to get internships?

I have almost two years of research experience working and leading NLP research projects. However, I do not have any publications. I am also located in the US if that makes a difference.",https://www.reddit.com/r/LanguageTechnology/comments/lakttx/do_companies_offer_nlp_research_internships_for/,LanguageTechnology,t3_lakttx,"Do companies offer NLP Research Internships for the summer before starting grad school? I have been fortunate enough to be accepted into three schools so far for an MS degree and am waiting on others. Therefore, I have begun searching for internships for this upcoming summer. I have found that most research internships only want Ph.D. students. I have tried cold-emailing, connecting, asking research scientists for a ""coffee chat,"" etc. Unfortunately, I have had no success. Is there any place I should be looking? Is it rare for people in my position not to get internships?

I have almost two years of research experience working and leading NLP research projects. However, I do not have any publications. I am also located in the US if that makes a difference.",766
822,822,Is there any difference between sentence embedding and document embedding?,"I thought sentence and document embeddings are different. I thought one is one that embeds sentences whereas another is one that embeds more then a sentence such as paragraph or whole document text. However, some research paper got me confusing.

[LASER](https://arxiv.org/pdf/1812.10464.pdf) paper describes it as sentence embeddings whereas [T-LASER](https://arxiv.org/pdf/2008.08567.pdf) metions LASER as document embedding. In LASER paper, text classification experiment is done, as well as multiple text classification experiments are carrying using sentence embeddings. If there would be sentence classification, I wouldn't be confused. But don't text usually means a document and instead would be efficient to use document embeddings instead?",https://www.reddit.com/r/LanguageTechnology/comments/la8yd5/is_there_any_difference_between_sentence/,LanguageTechnology,t3_la8yd5,"Is there any difference between sentence embedding and document embedding? I thought sentence and document embeddings are different. I thought one is one that embeds sentences whereas another is one that embeds more then a sentence such as paragraph or whole document text. However, some research paper got me confusing.

[LASER](https://arxiv.org/pdf/1812.10464.pdf) paper describes it as sentence embeddings whereas [T-LASER](https://arxiv.org/pdf/2008.08567.pdf) metions LASER as document embedding. In LASER paper, text classification experiment is done, as well as multiple text classification experiments are carrying using sentence embeddings. If there would be sentence classification, I wouldn't be confused. But don't text usually means a document and instead would be efficient to use document embeddings instead?",824
823,823,What is topic modeling?,,https://shyambhu20.blogspot.com/2021/01/what-is-topic-modeling.html,LanguageTechnology,t3_la1es9,What is topic modeling? ,24
824,824,What's a good dataset to demonstrate LDA?,,/r/textdatamining/comments/lac4jk/whats_a_good_dataset_to_demonstrate_lda/,LanguageTechnology,t3_lahvoj,What's a good dataset to demonstrate LDA? ,42
825,825,What is the latest research on NLU and decision making?,I would be really interested if anyone a list of links/reading resources in this area as it of particular interest for a project i am working on.,https://www.reddit.com/r/LanguageTechnology/comments/la1b4m/what_is_the_latest_research_on_nlu_and_decision/,LanguageTechnology,t3_la1b4m,What is the latest research on NLU and decision making? I would be really interested if anyone a list of links/reading resources in this area as it of particular interest for a project i am working on.,201
826,826,How can I summarize text with an unsupervised technique these days?,"Hi, I have been reading that the state of the art for summarizing, and probably other NLP tasks are done with supervised training, with huge data sets and complex architectures like transformers with pre training. 

That is awesome, but I don't have the GPU power nor access to the datasets to explore that part. Also, I'm OK achieving acceptable results for a start.

That's why I was thinking on unsupervised ways to summarize.

Could you recommend what are the state of the art techniques to do it? Where should I start to dig in?

Thanks!

**Edit for clarification**: I have already read about the abstractive and extractive approaches. What I would like to learn is how to do unsupervised abstractive summarization for a generic text corpora, and the concepts behind this task.",https://www.reddit.com/r/LanguageTechnology/comments/la9bz6/how_can_i_summarize_text_with_an_unsupervised/,LanguageTechnology,t3_la9bz6,"How can I summarize text with an unsupervised technique these days? Hi, I have been reading that the state of the art for summarizing, and probably other NLP tasks are done with supervised training, with huge data sets and complex architectures like transformers with pre training. 

That is awesome, but I don't have the GPU power nor access to the datasets to explore that part. Also, I'm OK achieving acceptable results for a start.

That's why I was thinking on unsupervised ways to summarize.

Could you recommend what are the state of the art techniques to do it? Where should I start to dig in?

Thanks!

**Edit for clarification**: I have already read about the abstractive and extractive approaches. What I would like to learn is how to do unsupervised abstractive summarization for a generic text corpora, and the concepts behind this task.",850
827,827,How To Profit From Alexa Skill Development Using Node JS,,https://www.youtube.com/watch?v=m35DBGM2ncE,LanguageTechnology,t3_la4zbo,How To Profit From Alexa Skill Development Using Node JS ,57
828,828,Do distributed semantic word embeddings such as word2vec have a theoretical foundation in linguistics?,,/r/linguistics/comments/l9q6eg/do_distributed_semantic_word_embeddings_such_as/,LanguageTechnology,t3_l9qz90,Do distributed semantic word embeddings such as word2vec have a theoretical foundation in linguistics? ,103
829,829,Exactly *how* is the new technology supposed to help improving search engines?,"Aside from the traditional inverted-index searches, and nearest-neighbor searches (with document/sentence embeddings), I mean.

I am having trouble mixing the two as well, because the ML models fail when it comes to proper nouns, I need an inverted-index search. Sometimes the nearest-neighbor searchs are all over the place too, with tangentially related sentences, and it's hard to adjust a similarity threshold.

Furthermore, I'd like to know how align (highlight) related parts of the text to the query (like Google does). I suspect this is done with expanded queries on inverted-index search, because it would be impractical to store embeddings for each word/wordpiece.

If that's the case, then how am I supposed to expand the searches?",https://www.reddit.com/r/LanguageTechnology/comments/la3hbs/exactly_how_is_the_new_technology_supposed_to/,LanguageTechnology,t3_la3hbs,"Exactly *how* is the new technology supposed to help improving search engines? Aside from the traditional inverted-index searches, and nearest-neighbor searches (with document/sentence embeddings), I mean.

I am having trouble mixing the two as well, because the ML models fail when it comes to proper nouns, I need an inverted-index search. Sometimes the nearest-neighbor searchs are all over the place too, with tangentially related sentences, and it's hard to adjust a similarity threshold.

Furthermore, I'd like to know how align (highlight) related parts of the text to the query (like Google does). I suspect this is done with expanded queries on inverted-index search, because it would be impractical to store embeddings for each word/wordpiece.

If that's the case, then how am I supposed to expand the searches?",821
830,830,Hierarchical Transformers for Long Document Classification (Research Paper Walkthrough),"This paper extends BERT for doing long document classification in nlp. They propose BERT variations RoBERT and ToBERT as hierarchical enchancements for the same. They obtained a significant improvement over the baseline models.

Paper Walkthrough: https://youtu.be/3IOl5d9PZeM

Paper Link: https://arxiv.org/abs/1910.10781",https://www.reddit.com/r/LanguageTechnology/comments/l9cylk/hierarchical_transformers_for_long_document/,LanguageTechnology,t3_l9cylk,"Hierarchical Transformers for Long Document Classification (Research Paper Walkthrough) This paper extends BERT for doing long document classification in nlp. They propose BERT variations RoBERT and ToBERT as hierarchical enchancements for the same. They obtained a significant improvement over the baseline models.

Paper Walkthrough: https://youtu.be/3IOl5d9PZeM

Paper Link: https://arxiv.org/abs/1910.10781",410
831,831,Metrics to analyze the quality of generated text?,"If I have a set of synthetic text/articles generated by language models, what metrics can I use to measure the text's quality, in terms of how coherent the context is and how close to human writing? Thank you!",https://www.reddit.com/r/LanguageTechnology/comments/l9w7du/metrics_to_analyze_the_quality_of_generated_text/,LanguageTechnology,t3_l9w7du,"Metrics to analyze the quality of generated text? If I have a set of synthetic text/articles generated by language models, what metrics can I use to measure the text's quality, in terms of how coherent the context is and how close to human writing? Thank you!",259
832,832,TriggerNER: Learning with Entity Triggers as Explanations | Research Papers Summary 006,,https://youtu.be/AyvOOeFP2i4,LanguageTechnology,t3_l9jdrb,TriggerNER: Learning with Entity Triggers as Explanations | Research Papers Summary 006 ,88
833,833,substitute for tokenizer in torchtext,"In the pytorch official tutorial for language translation ([https://pytorch.org/tutorials/beginner/torchtext\_translation\_tutorial.html](https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html)), tokenizer in torchtext is used. Parts of code are

    from torchtext.data.utils import get_tokenizer
    de_tokenizer = get_tokenizer('spacy', language='de')
    en_tokenizer = get_tokenizer('spacy', language='en')

However, I have difficulties in downloading and installing spacy package. Are there other substitutes for the tokenizer? Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/l9cd9g/substitute_for_tokenizer_in_torchtext/,LanguageTechnology,t3_l9cd9g,"substitute for tokenizer in torchtext In the pytorch official tutorial for language translation ([https://pytorch.org/tutorials/beginner/torchtext\_translation\_tutorial.html](https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html)), tokenizer in torchtext is used. Parts of code are

    from torchtext.data.utils import get_tokenizer
    de_tokenizer = get_tokenizer('spacy', language='de')
    en_tokenizer = get_tokenizer('spacy', language='en')

However, I have difficulties in downloading and installing spacy package. Are there other substitutes for the tokenizer? Thanks.",599
834,834,"[P] An interactive history of natural language processing, starting a long time ago",,https://www.nlphistory.com,LanguageTechnology,t3_l8so1a,"[P] An interactive history of natural language processing, starting a long time ago ",84
835,835,Research topics,"Hi all, I finished my master in nlp two years ago (worked on summarization) and I'm thinking of starting a PhD program.
The thing is, I'm not sure what topics I should work on. 

What I know is that I'd like to work on applicable topics, so nothing too theoretical. Also, leaderboard climbing using Bert in different ways is not that interesting imo.

So I'm basically asking what nlp domains you find interesting and you think should be great research topics.
Thanks!!",https://www.reddit.com/r/LanguageTechnology/comments/l8wlpr/research_topics/,LanguageTechnology,t3_l8wlpr,"Research topics Hi all, I finished my master in nlp two years ago (worked on summarization) and I'm thinking of starting a PhD program.
The thing is, I'm not sure what topics I should work on. 

What I know is that I'd like to work on applicable topics, so nothing too theoretical. Also, leaderboard climbing using Bert in different ways is not that interesting imo.

So I'm basically asking what nlp domains you find interesting and you think should be great research topics.
Thanks!!",485
836,836,Partner Up for Learning,"Hello everyone, hope you doing well. I just wanted share the discord server for the people who search for learning partners. You can join server to find a partner for learning different programming languages or any topics you are interested in.
Here is the link for the server:

https://discord.gg/ayeGrsaSG2",https://www.reddit.com/r/LanguageTechnology/comments/l8zkyl/partner_up_for_learning/,LanguageTechnology,t3_l8zkyl,"Partner Up for Learning Hello everyone, hope you doing well. I just wanted share the discord server for the people who search for learning partners. You can join server to find a partner for learning different programming languages or any topics you are interested in.
Here is the link for the server:

https://discord.gg/ayeGrsaSG2",332
837,837,How to break a word into syllables?,"I am new to ML and starting off with what I think is an easy project. My first foray into ML was to predict the number of syllables in a word given its pronunciation, or phonetic transcription. That was pretty straightforward using graph convolutional networks to solve a classification problem. Having succeeded at that, my next goal is to predict the the location of syllable breaks in a word. I have written code to enumerate all possible combinations of *N* syllables for a word, but I don't know which is correct. The core of my problem seems to me to be how to accurately break a graph into subgraphs. This is where I'm running up against my own ignorance about ML approaches. How would I go about doing that? My first thought was link prediction, but I'm open to other ideas. Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/l8p62a/how_to_break_a_word_into_syllables/,LanguageTechnology,t3_l8p62a,"How to break a word into syllables? I am new to ML and starting off with what I think is an easy project. My first foray into ML was to predict the number of syllables in a word given its pronunciation, or phonetic transcription. That was pretty straightforward using graph convolutional networks to solve a classification problem. Having succeeded at that, my next goal is to predict the the location of syllable breaks in a word. I have written code to enumerate all possible combinations of *N* syllables for a word, but I don't know which is correct. The core of my problem seems to me to be how to accurately break a graph into subgraphs. This is where I'm running up against my own ignorance about ML approaches. How would I go about doing that? My first thought was link prediction, but I'm open to other ideas. Thanks.",826
838,838,using self attention on Word embeddings improved context in only one direction,"I am trying to implement the explanation for attention in this video using pytorch (https://www.youtube.com/watch?v=yGTUuEx3GkA) . The main idea can be seen on the slide at 12:38

Focusing on just the word ""bank"":

The idea is to get glove embeddings for the words ""Bank of a river"", and then take a dot product of the word embedding of bank with itself and every other word, to get a tensor of 4 weights. Then normalize the weights and use them to get a new word embedding for the word ""bank"" which is now the sum of all the word embeddings scaled by their corresponding normalized weights.

Before, I tried to find the cosine similarity between the words ""bank"" and ""river"" and got 0.33 and after the reweighing I got 0.59 i.e it worked.

I also checked that the similarity between ""water"" and ""bank"" was 0.49 and became 0.57 with the new embeddings.

BUT, the similarity between ""money"" and ""bank"" was 0.57 and before and became 0.64 after! So the ""bank"" vector came closet to ""money"" after I provided context.

So while what I did to the original ""bank"" vector got it closer to things like ""water"" (which is what I was trying to do), it didn't get away from ""money"" as I was expecting.

Why is the change happening in only one direction?

You can have a look at the code and the outputs here https://github.com/VishakBharadwaj94/transformers/blob/master/transformers_tmp.ipynb",https://www.reddit.com/r/LanguageTechnology/comments/l8e57t/using_self_attention_on_word_embeddings_improved/,LanguageTechnology,t3_l8e57t,"using self attention on Word embeddings improved context in only one direction I am trying to implement the explanation for attention in this video using pytorch (https://www.youtube.com/watch?v=yGTUuEx3GkA) . The main idea can be seen on the slide at 12:38

Focusing on just the word ""bank"":

The idea is to get glove embeddings for the words ""Bank of a river"", and then take a dot product of the word embedding of bank with itself and every other word, to get a tensor of 4 weights. Then normalize the weights and use them to get a new word embedding for the word ""bank"" which is now the sum of all the word embeddings scaled by their corresponding normalized weights.

Before, I tried to find the cosine similarity between the words ""bank"" and ""river"" and got 0.33 and after the reweighing I got 0.59 i.e it worked.

I also checked that the similarity between ""water"" and ""bank"" was 0.49 and became 0.57 with the new embeddings.

BUT, the similarity between ""money"" and ""bank"" was 0.57 and before and became 0.64 after! So the ""bank"" vector came closet to ""money"" after I provided context.

So while what I did to the original ""bank"" vector got it closer to things like ""water"" (which is what I was trying to do), it didn't get away from ""money"" as I was expecting.

Why is the change happening in only one direction?

You can have a look at the code and the outputs here https://github.com/VishakBharadwaj94/transformers/blob/master/transformers_tmp.ipynb",1459
839,839,Which model should I use to pick the best answer for the TOEIC reading test?,"I want to build a question answering model that take the context (the reading paragraphs), the question and 4 choices as inputs and output the best answer for that question given that context. I’m new to NLP but willing to learn more so any recommendations will help a lot. Thanks",https://www.reddit.com/r/LanguageTechnology/comments/l8pfvl/which_model_should_i_use_to_pick_the_best_answer/,LanguageTechnology,t3_l8pfvl,"Which model should I use to pick the best answer for the TOEIC reading test? I want to build a question answering model that take the context (the reading paragraphs), the question and 4 choices as inputs and output the best answer for that question given that context. I’m new to NLP but willing to learn more so any recommendations will help a lot. Thanks",357
840,840,Rebuilding the spellchecker: Hunspell and the order of edits,,https://zverok.github.io/blog/2021-01-28-spellchecker-5.html,LanguageTechnology,t3_l7yz1s,Rebuilding the spellchecker: Hunspell and the order of edits ,61
841,841,Entity Resolution for Master Data Management,"Last year, we set out to create a master entity resolution tool. We wanted to identify and resolve multiple occurrences of a single entity to get a clearer picture of the information within data... but in a practical and scaleable way.

Our blog post, **Entity Resolution for Master Data Management** explains the why and how behind er², ThinkData's entity resolution tool.

If you're interested, check it out here: [https://blog.thinkdataworks.com/entity-resolution-for-master-data-management](https://blog.thinkdataworks.com/entity-resolution-for-master-data-management)",https://www.reddit.com/r/LanguageTechnology/comments/l85gyu/entity_resolution_for_master_data_management/,LanguageTechnology,t3_l85gyu,"Entity Resolution for Master Data Management Last year, we set out to create a master entity resolution tool. We wanted to identify and resolve multiple occurrences of a single entity to get a clearer picture of the information within data... but in a practical and scaleable way.

Our blog post, **Entity Resolution for Master Data Management** explains the why and how behind er², ThinkData's entity resolution tool.

If you're interested, check it out here: [https://blog.thinkdataworks.com/entity-resolution-for-master-data-management](https://blog.thinkdataworks.com/entity-resolution-for-master-data-management)",617
842,842,An unexpected use case of word embeddings,,https://paulbricman.com/docs/tools/semantica/,LanguageTechnology,t3_l7zu86,An unexpected use case of word embeddings ,42
843,843,"Which are top APIs for Indian languages mainly VR, OCR, Speech - Text - Speech?",,https://www.reddit.com/r/LanguageTechnology/comments/l7ufe9/which_are_top_apis_for_indian_languages_mainly_vr/,LanguageTechnology,t3_l7ufe9,"Which are top APIs for Indian languages mainly VR, OCR, Speech - Text - Speech? ",80
844,844,Chaining BERT multilabel classifiers.,"Say I have a two layers of labels with a label and sublabel:

    Fruit.Apple
    Fruit.Orange
    Fruit.Banana

    Vegetable:Cucumber
    Vegetable:Squash
    Vegetable:Cabbage

    Meat:Cow
    Meat:Chicken
    Meat:Fish

Then suppose I build a dataset of ""meals"" which are combinations of the above labels:

    [Vegetable:Squash,Meat:Cow]
    [Fruit.Apple,Fruit.Orange]
    [Meat:Fish,Fruit.Orange]

Really each ""meal"" is a document with a category and subcategory. If I were to train a bert classifier for guessing the ingredients in a given meal, would it be better to:

* train 1 classifier with 9 labels
* or build a classier with 3 labels (fruits, vegetables,meats) then build 3 additional classifier to sort the finer sublabels (fruits -&gt; (apple, orange, banana), vegetable -&gt;(cucumber, squash, cabbage), etc)

Now I'd imagine if you had a large enough database, the first would probably be fine. But if you had say 20 labels each with 10 sublabels, then the second option starts to make more sense.",https://www.reddit.com/r/LanguageTechnology/comments/l7hm0b/chaining_bert_multilabel_classifiers/,LanguageTechnology,t3_l7hm0b,"Chaining BERT multilabel classifiers. Say I have a two layers of labels with a label and sublabel:

    Fruit.Apple
    Fruit.Orange
    Fruit.Banana

    Vegetable:Cucumber
    Vegetable:Squash
    Vegetable:Cabbage

    Meat:Cow
    Meat:Chicken
    Meat:Fish

Then suppose I build a dataset of ""meals"" which are combinations of the above labels:

    [Vegetable:Squash,Meat:Cow]
    [Fruit.Apple,Fruit.Orange]
    [Meat:Fish,Fruit.Orange]

Really each ""meal"" is a document with a category and subcategory. If I were to train a bert classifier for guessing the ingredients in a given meal, would it be better to:

* train 1 classifier with 9 labels
* or build a classier with 3 labels (fruits, vegetables,meats) then build 3 additional classifier to sort the finer sublabels (fruits -&gt; (apple, orange, banana), vegetable -&gt;(cucumber, squash, cabbage), etc)

Now I'd imagine if you had a large enough database, the first would probably be fine. But if you had say 20 labels each with 10 sublabels, then the second option starts to make more sense.",1054
845,845,Sales Conversations Datasets,"Hey everybody,

I'm new to NLP and looking into training tensorflow using sales conversations, i.e. e-mail conversations. The problem of course is getting data... I have not been able to come up with a good possible source yet. Any ideas are appreciated :-)",https://www.reddit.com/r/LanguageTechnology/comments/l7b50r/sales_conversations_datasets/,LanguageTechnology,t3_l7b50r,"Sales Conversations Datasets Hey everybody,

I'm new to NLP and looking into training tensorflow using sales conversations, i.e. e-mail conversations. The problem of course is getting data... I have not been able to come up with a good possible source yet. Any ideas are appreciated :-)",286
846,846,Stylometry library in Python,"I've written a library for doing forensic stylometry (identifying who wrote an unknown text)

pip install faststylometry

Here's a tutorial [https://freelancedatascientist.net/fast-stylometry-tutorial/](https://freelancedatascientist.net/fast-stylometry-tutorial/)

And here's the library [https://pypi.org/project/faststylometry](https://pypi.org/project/faststylometry)

There are a few cool things I'd like to try with it, such as checking if it could identify Miles Taylor as the staffer who publicly criticised Trump's administration",https://www.reddit.com/r/LanguageTechnology/comments/l6ud6c/stylometry_library_in_python/,LanguageTechnology,t3_l6ud6c,"Stylometry library in Python I've written a library for doing forensic stylometry (identifying who wrote an unknown text)

pip install faststylometry

Here's a tutorial [https://freelancedatascientist.net/fast-stylometry-tutorial/](https://freelancedatascientist.net/fast-stylometry-tutorial/)

And here's the library [https://pypi.org/project/faststylometry](https://pypi.org/project/faststylometry)

There are a few cool things I'd like to try with it, such as checking if it could identify Miles Taylor as the staffer who publicly criticised Trump's administration",567
847,847,Has anyone seen work investigating the relationship between neural text summarization and relation extraction?,"Title is the question. I'm working on a relation extraction research project and had a shower thought of whether models that are good at summarization (although this expression is also highly controversial) are also good at extracting relationships between two entities.

Intuitively, it makes sense. However, if I think about the details making the transfer between two tasks seems very difficult (e.g., how to make the transition between structured to unstructured output spaces).

I'd appreciate it if anyone would let me know if they know anything. Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/l6vlqw/has_anyone_seen_work_investigating_the/,LanguageTechnology,t3_l6vlqw,"Has anyone seen work investigating the relationship between neural text summarization and relation extraction? Title is the question. I'm working on a relation extraction research project and had a shower thought of whether models that are good at summarization (although this expression is also highly controversial) are also good at extracting relationships between two entities.

Intuitively, it makes sense. However, if I think about the details making the transfer between two tasks seems very difficult (e.g., how to make the transition between structured to unstructured output spaces).

I'd appreciate it if anyone would let me know if they know anything. Thanks!",671
848,848,Towards Automated Fact-Checking,,https://www.youtube.com/watch?v=Wy2E9Bg8hxk,LanguageTechnology,t3_l6i4xa,Towards Automated Fact-Checking ,32
849,849,"Hi all! For my side project, I made an AI-based program that predicts what a user will search next for an Online Dictionary. Here is a short article that I wrote about the project. Any thoughts or feedback are greatly appreciate. Thank you!",,https://www.aiplusinfo.com/blog/ai-search-prediction-for-online-dictionaries/,LanguageTechnology,t3_l6unfh,"Hi all! For my side project, I made an AI-based program that predicts what a user will search next for an Online Dictionary. Here is a short article that I wrote about the project. Any thoughts or feedback are greatly appreciate. Thank you! ",241
850,850,Tool for Complex Data Labelling Tasks,"Hi r/LanguageTechnology readers!

We have created a [labelling tool](https://humanlambdas.com/solutions/data-labelling) that can be customized to display all sorts of data models and tasks. Here are a couple of [examples](https://www.humanlambdas.com/templates/nlp-news-article-annotation) of [types](https://www.humanlambdas.com/templates/sec-filing-data-extraction) of complex tasks one can set up.

I hope some of you will find this useful, and if you have any thoughts I would love to hear your feedback!",https://www.reddit.com/r/LanguageTechnology/comments/l6tbrp/tool_for_complex_data_labelling_tasks/,LanguageTechnology,t3_l6tbrp,"Tool for Complex Data Labelling Tasks Hi r/LanguageTechnology readers!

We have created a [labelling tool](https://humanlambdas.com/solutions/data-labelling) that can be customized to display all sorts of data models and tasks. Here are a couple of [examples](https://www.humanlambdas.com/templates/nlp-news-article-annotation) of [types](https://www.humanlambdas.com/templates/sec-filing-data-extraction) of complex tasks one can set up.

I hope some of you will find this useful, and if you have any thoughts I would love to hear your feedback!",546
851,851,[R] RECCON: A Dataset for Recognizing Emotion Cause in Conversations,"RECCON is a dataset for causal reasoning of emotions in conversations. It has subtasks of textual entailment aka Natural Language Inference (NLI) and QA.  


**Abstract.** Recognizing the cause behind emotions in text is a fundamental yet under-explored area of research in NLP. Advances in this area hold the potential to improve interpretability and performance in affect-based models. Identifying emotion causes at the utterance level in conversations is particularly challenging due to the intermingling dynamic among the interlocutors. To this end, we introduce the task of recognizing emotion cause in conversations with an accompanying dataset named RECCON. Furthermore, we define different cause types based on the source of the causes and establish strong transformer-based baselines to address two different sub-tasks of RECCON: 1) Causal Span Extraction and 2) Causal Emotion Entailment. The dataset is available at [https://github.com/declare-lab/RECCON](https://github.com/declare-lab/RECCON).

**Paper:** [**https://arxiv.org/pdf/2012.11820.pdf**](https://arxiv.org/pdf/2012.11820.pdf)

**Code:** [**https://github.com/declare-lab/RECCON**](https://github.com/declare-lab/RECCON)

**PwC:** [**https://paperswithcode.com/paper/recognizing-emotion-cause-in-conversations**](https://paperswithcode.com/paper/recognizing-emotion-cause-in-conversations)",https://www.reddit.com/r/LanguageTechnology/comments/l6o73d/r_reccon_a_dataset_for_recognizing_emotion_cause/,LanguageTechnology,t3_l6o73d,"[R] RECCON: A Dataset for Recognizing Emotion Cause in Conversations RECCON is a dataset for causal reasoning of emotions in conversations. It has subtasks of textual entailment aka Natural Language Inference (NLI) and QA.  


**Abstract.** Recognizing the cause behind emotions in text is a fundamental yet under-explored area of research in NLP. Advances in this area hold the potential to improve interpretability and performance in affect-based models. Identifying emotion causes at the utterance level in conversations is particularly challenging due to the intermingling dynamic among the interlocutors. To this end, we introduce the task of recognizing emotion cause in conversations with an accompanying dataset named RECCON. Furthermore, we define different cause types based on the source of the causes and establish strong transformer-based baselines to address two different sub-tasks of RECCON: 1) Causal Span Extraction and 2) Causal Emotion Entailment. The dataset is available at [https://github.com/declare-lab/RECCON](https://github.com/declare-lab/RECCON).

**Paper:** [**https://arxiv.org/pdf/2012.11820.pdf**](https://arxiv.org/pdf/2012.11820.pdf)

**Code:** [**https://github.com/declare-lab/RECCON**](https://github.com/declare-lab/RECCON)

**PwC:** [**https://paperswithcode.com/paper/recognizing-emotion-cause-in-conversations**](https://paperswithcode.com/paper/recognizing-emotion-cause-in-conversations)",1431
852,852,Does anyone have any experience in Japanese text classification? Or is there anyone who can help me with that? I’ll be really thankful!,,https://www.reddit.com/r/LanguageTechnology/comments/l6rjgs/does_anyone_have_any_experience_in_japanese_text/,LanguageTechnology,t3_l6rjgs,Does anyone have any experience in Japanese text classification? Or is there anyone who can help me with that? I’ll be really thankful! ,136
853,853,Match questions to similar questions?,"basically we want to help users find similar questions

I've been using https://github.com/hanxiao/bert-as-service#building-a-qa-semantic-search-engine-in-3-minutes but am not very happy with the result. 

Are there any low hanging fruits for it?


Why am I not so happy?

Given this input:
`Someone got stuck in the middle of a donation`


We received these matches:
```
18.805347 How the fiscal sponsorship works
18.803146 What fees are involved in running a campaign on MyApp?
18.800673 Do I have to provide contribution levels in my campaign?
18.682882 Someone could not donate, what is wrong?
```

well it found the match on position 4, but this is a suuuuper small example size to match again, we only had a total of 14 possible questions that it could match. So not very impressed. Are there any better easy approaches?",https://www.reddit.com/r/LanguageTechnology/comments/l68q6u/match_questions_to_similar_questions/,LanguageTechnology,t3_l68q6u,"Match questions to similar questions? basically we want to help users find similar questions

I've been using https://github.com/hanxiao/bert-as-service#building-a-qa-semantic-search-engine-in-3-minutes but am not very happy with the result. 

Are there any low hanging fruits for it?


Why am I not so happy?

Given this input:
`Someone got stuck in the middle of a donation`


We received these matches:
```
18.805347 How the fiscal sponsorship works
18.803146 What fees are involved in running a campaign on MyApp?
18.800673 Do I have to provide contribution levels in my campaign?
18.682882 Someone could not donate, what is wrong?
```

well it found the match on position 4, but this is a suuuuper small example size to match again, we only had a total of 14 possible questions that it could match. So not very impressed. Are there any better easy approaches?",864
854,854,Find sponsors from transcripts (yt/podcast),"Hi there!

For videos on YouTube or podcasts on other platforms, I want to find all the brand(s) that are sponsoring that video or that podcast. Right now we are using fuzzy queries on description and transcript texts. But that does not cover all the cases. 

Often content creators use terms like “this video is sponsored/brought to you by {brand name}” but not always. So we want to use nlp. 

Please suggest any approach/idea/library or any direction to further investigation. Any help is appreciated.",https://www.reddit.com/r/LanguageTechnology/comments/l6dmtx/find_sponsors_from_transcripts_ytpodcast/,LanguageTechnology,t3_l6dmtx,"Find sponsors from transcripts (yt/podcast) Hi there!

For videos on YouTube or podcasts on other platforms, I want to find all the brand(s) that are sponsoring that video or that podcast. Right now we are using fuzzy queries on description and transcript texts. But that does not cover all the cases. 

Often content creators use terms like “this video is sponsored/brought to you by {brand name}” but not always. So we want to use nlp. 

Please suggest any approach/idea/library or any direction to further investigation. Any help is appreciated.",548
855,855,Is there a way to analyze a sentence to calculate whether A is beneficial to B?,"For example we use a float value to represent whether Alice is helping Bob:

* In **Alice gives Bob $100**, Alice is helping Bob; (+0.5)
* In **Alice gives Bob a slap**, Bob is hurt by Alice; (-0.5)
* In **Alice gives Bob a slap to keep him from falling sleep in the snow**, Though Bob is hurt, Alice is saving Bob's life so it's still good for him; (+0.7)

So, my idea is to make a corpus based on [FrameNet](https://framenet.icsi.berkeley.edu/fndrupal/WhatIsFrameNet), giving *beneficial* value for frame elements. (Assuming my input is already in the frame data structure) 

Is there any better idea or existing solution for this problem?",https://www.reddit.com/r/LanguageTechnology/comments/l5xlvd/is_there_a_way_to_analyze_a_sentence_to_calculate/,LanguageTechnology,t3_l5xlvd,"Is there a way to analyze a sentence to calculate whether A is beneficial to B? For example we use a float value to represent whether Alice is helping Bob:

* In **Alice gives Bob $100**, Alice is helping Bob; (+0.5)
* In **Alice gives Bob a slap**, Bob is hurt by Alice; (-0.5)
* In **Alice gives Bob a slap to keep him from falling sleep in the snow**, Though Bob is hurt, Alice is saving Bob's life so it's still good for him; (+0.7)

So, my idea is to make a corpus based on [FrameNet](https://framenet.icsi.berkeley.edu/fndrupal/WhatIsFrameNet), giving *beneficial* value for frame elements. (Assuming my input is already in the frame data structure) 

Is there any better idea or existing solution for this problem?",721
856,856,Is it possible to train a decoder using monolingual data only?,"I’m working on enhancing low resource translation using cross lingual signals from related languages and I was wondering if it’s somehow possible to train a decoder stack in a seq2seq task using just monolingual data. For example if I have A -&gt; B translation with A having good monolingual data but little or no parallel data with B thus is low resource, my current methodology uses a monolingual embedding space of A to first encode the input sentence, then uses a cross lingual map to map this encoded sentence into a pivot language, and lastly I use a joint cross lingual map of pivot and B to decode the sentence. Now I’m think of employing this method is B -&gt; A direction. The issue is, it’s not possible to learn a joint cross lingual map between A and B (spaces are not isomorphic) so I was thinking of learning a decoder stack for A using monolingual data available. I can clarify more if needed! Apologies if the questions is a bit uninformed haha",https://www.reddit.com/r/LanguageTechnology/comments/l64huo/is_it_possible_to_train_a_decoder_using/,LanguageTechnology,t3_l64huo,"Is it possible to train a decoder using monolingual data only? I’m working on enhancing low resource translation using cross lingual signals from related languages and I was wondering if it’s somehow possible to train a decoder stack in a seq2seq task using just monolingual data. For example if I have A -&gt; B translation with A having good monolingual data but little or no parallel data with B thus is low resource, my current methodology uses a monolingual embedding space of A to first encode the input sentence, then uses a cross lingual map to map this encoded sentence into a pivot language, and lastly I use a joint cross lingual map of pivot and B to decode the sentence. Now I’m think of employing this method is B -&gt; A direction. The issue is, it’s not possible to learn a joint cross lingual map between A and B (spaces are not isomorphic) so I was thinking of learning a decoder stack for A using monolingual data available. I can clarify more if needed! Apologies if the questions is a bit uninformed haha",1025
857,857,Backprop through Time vs Normal for RNN language model,"Hello people, so I’m experimenting with an RNN language model and normal back-propagation appears to be performing better than bptt even when it’s been truncated to only look back two or five steps (we’ve tested both). Can anyone give me some intuition about why this might be going on? Does BPTT require more training data to perform better? I would have thought the truncation would mean that vanishing gradients shouldn’t be a problem. If anyone knows any articles or blogs I could read to try and understand this better it would be really useful :)",https://www.reddit.com/r/LanguageTechnology/comments/l624ej/backprop_through_time_vs_normal_for_rnn_language/,LanguageTechnology,t3_l624ej,"Backprop through Time vs Normal for RNN language model Hello people, so I’m experimenting with an RNN language model and normal back-propagation appears to be performing better than bptt even when it’s been truncated to only look back two or five steps (we’ve tested both). Can anyone give me some intuition about why this might be going on? Does BPTT require more training data to perform better? I would have thought the truncation would mean that vanishing gradients shouldn’t be a problem. If anyone knows any articles or blogs I could read to try and understand this better it would be really useful :)",607
858,858,Unbalanced document length &amp; topic modeling (lda) [help],"Hi all,

I can't seem to form an intuition for the following settings : I would like to perform a LDA on a group of text but some document are many, many time longer than others. 

The average is at 80 tokens, median 40 but there are document reaching up to 6000 tokens. 

My strategy was to discard document with too few words (lower than the 25% quantile ) as they are unlikely to satisfy the assumption that ""documents are a mixture of topics"". 

But I'm not sure how to deal with the outlier with too many words. Would the LDA be robust enough to deal with the imbalance? Or should I split large documents into smaller chunks and randomly select one chunk.

Thanks in advance.",https://www.reddit.com/r/LanguageTechnology/comments/l68ab8/unbalanced_document_length_topic_modeling_lda_help/,LanguageTechnology,t3_l68ab8,"Unbalanced document length &amp; topic modeling (lda) [help] Hi all,

I can't seem to form an intuition for the following settings : I would like to perform a LDA on a group of text but some document are many, many time longer than others. 

The average is at 80 tokens, median 40 but there are document reaching up to 6000 tokens. 

My strategy was to discard document with too few words (lower than the 25% quantile ) as they are unlikely to satisfy the assumption that ""documents are a mixture of topics"". 

But I'm not sure how to deal with the outlier with too many words. Would the LDA be robust enough to deal with the imbalance? Or should I split large documents into smaller chunks and randomly select one chunk.

Thanks in advance.",741
859,859,NLP Specialization course on coursera worth it?,"Dear Reddit-Fam

Can anyone tell me whether the NLP Specialization track on coursera is a good starting point for someone who is studying Data Science (Master's) and want's to go deeper into NLP?

Greeets",https://www.reddit.com/r/LanguageTechnology/comments/l5fodl/nlp_specialization_course_on_coursera_worth_it/,LanguageTechnology,t3_l5fodl,"NLP Specialization course on coursera worth it? Dear Reddit-Fam

Can anyone tell me whether the NLP Specialization track on coursera is a good starting point for someone who is studying Data Science (Master's) and want's to go deeper into NLP?

Greeets",252
860,860,Fine-Tune 11B T5 for Generation Task,"I'm trying to figure out how to fine-tune the largest version of T5 for a language generation task, but I can't seem to find any notebooks or resources to do so. Any great places to start?",https://www.reddit.com/r/LanguageTechnology/comments/l5u8mz/finetune_11b_t5_for_generation_task/,LanguageTechnology,t3_l5u8mz,"Fine-Tune 11B T5 for Generation Task I'm trying to figure out how to fine-tune the largest version of T5 for a language generation task, but I can't seem to find any notebooks or resources to do so. Any great places to start?",225
861,861,NLP for Interpretability,Can someone point me in the direction of any literature using NLP to understand why a neural network makes the choices it does? Like e.g. a chess bot which can explain why it made the move it did. Humans use natural language to communicate our beliefs and reasons: surely there's a way to make our models do the same.,https://www.reddit.com/r/LanguageTechnology/comments/l58u0h/nlp_for_interpretability/,LanguageTechnology,t3_l58u0h,NLP for Interpretability Can someone point me in the direction of any literature using NLP to understand why a neural network makes the choices it does? Like e.g. a chess bot which can explain why it made the move it did. Humans use natural language to communicate our beliefs and reasons: surely there's a way to make our models do the same.,342
862,862,Announcing UBIAI: Easy-to-Use Text Annotation Tool,"[UBIAI](https://ubiai.tools) was born out of frustration with existing solutions, which either have a low quality/price ratio or are expensive and geared towards large companies. We know that data labeling is the bottleneck for creating custom NLP models (NER, entity relations, classification, etc) and is here to stay. We wanted to create the most accessible, easy-to-use and automated solution at an affordable price.

If you are launching a new NLP project, please explore our [tool](https://ubiai.tools) (we offer free 14 day trial) and give us your feedback at [admin@ubiai.tools](mailto:admin@ubiai.tools)

Here are few blog links:

* [Introducing UBIAI](https://chatbotslife.com/introducing-ubiai-easy-to-use-text-annotation-for-nlp-applications-74a2401fa725?sk=cace5030af4ca42ad4fda0eff4f2a229)
* [Building Job Entity Recognizer using Amazon Comprehend](https://medium.com/swlh/building-a-job-entity-recognizer-using-amazon-comprehend-5dd2c33faa82?sk=e34060de1a9a5b9da6a5bfefc0bff7d4)",https://www.reddit.com/r/LanguageTechnology/comments/l5jr10/announcing_ubiai_easytouse_text_annotation_tool/,LanguageTechnology,t3_l5jr10,"Announcing UBIAI: Easy-to-Use Text Annotation Tool [UBIAI](https://ubiai.tools) was born out of frustration with existing solutions, which either have a low quality/price ratio or are expensive and geared towards large companies. We know that data labeling is the bottleneck for creating custom NLP models (NER, entity relations, classification, etc) and is here to stay. We wanted to create the most accessible, easy-to-use and automated solution at an affordable price.

If you are launching a new NLP project, please explore our [tool](https://ubiai.tools) (we offer free 14 day trial) and give us your feedback at [admin@ubiai.tools](mailto:admin@ubiai.tools)

Here are few blog links:

* [Introducing UBIAI](https://chatbotslife.com/introducing-ubiai-easy-to-use-text-annotation-for-nlp-applications-74a2401fa725?sk=cace5030af4ca42ad4fda0eff4f2a229)
* [Building Job Entity Recognizer using Amazon Comprehend](https://medium.com/swlh/building-a-job-entity-recognizer-using-amazon-comprehend-5dd2c33faa82?sk=e34060de1a9a5b9da6a5bfefc0bff7d4)",1044
863,863,"[Tutorial] Training, Visualizing, and Understanding Word Embeddings","In this post, we will look at different techniques you can use to better understand how well a language model captures the contextual relationship between words. We will do this by: 

1. Looking at the dataset we need to train these models to see if we can come up with a simple one that helps us visualize how these models “learn” the relationship between different words.
1. Looking at the tools and techniques you can use to track the progress of these models and monitor the results while they process our simplified dataset.
1. After that you should hopefully be able to re-use that template for more complex models with some real life datasets.

[understanding word embeddings](https://neptune.ai/blog/word-embeddings-deep-dive-into-custom-datasets?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-word-embeddings-deep-dive-into-custom-datasets&amp;utm_content=languagetechnology)",https://www.reddit.com/r/LanguageTechnology/comments/l5i5ph/tutorial_training_visualizing_and_understanding/,LanguageTechnology,t3_l5i5ph,"[Tutorial] Training, Visualizing, and Understanding Word Embeddings In this post, we will look at different techniques you can use to better understand how well a language model captures the contextual relationship between words. We will do this by: 

1. Looking at the dataset we need to train these models to see if we can come up with a simple one that helps us visualize how these models “learn” the relationship between different words.
1. Looking at the tools and techniques you can use to track the progress of these models and monitor the results while they process our simplified dataset.
1. After that you should hopefully be able to re-use that template for more complex models with some real life datasets.

[understanding word embeddings](https://neptune.ai/blog/word-embeddings-deep-dive-into-custom-datasets?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-word-embeddings-deep-dive-into-custom-datasets&amp;utm_content=languagetechnology)",965
864,864,What is the most accurate sentiment recognition open source code?,,https://www.reddit.com/r/LanguageTechnology/comments/l5fack/what_is_the_most_accurate_sentiment_recognition/,LanguageTechnology,t3_l5fack,What is the most accurate sentiment recognition open source code? ,66
865,865,What is the best summarisation open source code?,,https://www.reddit.com/r/LanguageTechnology/comments/l5f16m/what_is_the_best_summarisation_open_source_code/,LanguageTechnology,t3_l5f16m,What is the best summarisation open source code? ,49
866,866,Building a personal corpus based on digital conversation history,"Has anybody ever done work on this? Or does anybody know of papers/projects that have done this?

With the new personal data availability created by European Union and California laws, I am currently working on a personal project to unify all of my digital conversation history and data into a personal corpus of everything I've said.

I've come across a number of projects that work with Facebook Messenger, whatsapp, WeChat, etc., but all the projects that I have found only work at an individual app level, and almost all of them are limited to shallow linguistic analysis. I want to perform various types of analysis on my data (mostly for novelty, with some practical application in language learning)

While this is not something everyone would be interested in, and in fact, many privacy minded people would be very opposed to doing this, I think this would be very useful to computational linguists and enthusiasts for analyzing data at a level of intimacy that far overextends what you would get from an academic level.

I'll do this project regardless eventually, but I was just wondering if there is previous work or an open source project to contribute to so I don't have to reinvent the wheel.",https://www.reddit.com/r/LanguageTechnology/comments/l535jb/building_a_personal_corpus_based_on_digital/,LanguageTechnology,t3_l535jb,"Building a personal corpus based on digital conversation history Has anybody ever done work on this? Or does anybody know of papers/projects that have done this?

With the new personal data availability created by European Union and California laws, I am currently working on a personal project to unify all of my digital conversation history and data into a personal corpus of everything I've said.

I've come across a number of projects that work with Facebook Messenger, whatsapp, WeChat, etc., but all the projects that I have found only work at an individual app level, and almost all of them are limited to shallow linguistic analysis. I want to perform various types of analysis on my data (mostly for novelty, with some practical application in language learning)

While this is not something everyone would be interested in, and in fact, many privacy minded people would be very opposed to doing this, I think this would be very useful to computational linguists and enthusiasts for analyzing data at a level of intimacy that far overextends what you would get from an academic level.

I'll do this project regardless eventually, but I was just wondering if there is previous work or an open source project to contribute to so I don't have to reinvent the wheel.",1271
867,867,Demo colab for openAI's CLIP,"I decided to create a fun playground Colab, where you can dabble with CLIP!
https://colab.research.google.com/drive/1ePZiVXnINfJNTHB6T_qsNlbo8fFWDsk_?usp=sharing 

Upload your own pictures, choose silly captions, and find out which ones CLIP thinks are most likely. I was already impressed, but do test it yourself :wink:

Please share any funny results you might encounter! :nerd_face:",https://www.reddit.com/r/LanguageTechnology/comments/l59lrc/demo_colab_for_openais_clip/,LanguageTechnology,t3_l59lrc,"Demo colab for openAI's CLIP I decided to create a fun playground Colab, where you can dabble with CLIP!
https://colab.research.google.com/drive/1ePZiVXnINfJNTHB6T_qsNlbo8fFWDsk_?usp=sharing 

Upload your own pictures, choose silly captions, and find out which ones CLIP thinks are most likely. I was already impressed, but do test it yourself :wink:

Please share any funny results you might encounter! :nerd_face:",415
868,868,"Allen Institute launches GENIE, a leaderboard for human-in-the-loop language model benchmarking",,/r/MachineLearning/comments/l44ofg/rallen_institute_launches_genie_a_leaderboard_for/,LanguageTechnology,t3_l4r3zw,"Allen Institute launches GENIE, a leaderboard for human-in-the-loop language model benchmarking ",96
869,869,"ERNIE-M: Multilingual Model Learns 96 Languages from Monolingual Corpora, Tops Google’s XTREME Benchmark","[ERNIE-M](http://arxiv.org/abs/2012.15674) is a new multilingual model that understands 96 languages and tops [XTREME](https://arxiv.org/abs/2003.11080), a substantial multilingual multi-task benchmark proposed by Google, Carnegie Mellon University, and DeepMind. The novel pre-training method can learn semantic alignment across multiple languages on monolingual corpora.

Paper: [https://arxiv.org/abs/2012.15674](https://arxiv.org/abs/2012.15674)

Blog: [http://research.baidu.com/Blog/index-view?id=151](http://research.baidu.com/Blog/index-view?id=151)",https://www.reddit.com/r/LanguageTechnology/comments/l4vicp/erniem_multilingual_model_learns_96_languages/,LanguageTechnology,t3_l4vicp,"ERNIE-M: Multilingual Model Learns 96 Languages from Monolingual Corpora, Tops Google’s XTREME Benchmark [ERNIE-M](http://arxiv.org/abs/2012.15674) is a new multilingual model that understands 96 languages and tops [XTREME](https://arxiv.org/abs/2003.11080), a substantial multilingual multi-task benchmark proposed by Google, Carnegie Mellon University, and DeepMind. The novel pre-training method can learn semantic alignment across multiple languages on monolingual corpora.

Paper: [https://arxiv.org/abs/2012.15674](https://arxiv.org/abs/2012.15674)

Blog: [http://research.baidu.com/Blog/index-view?id=151](http://research.baidu.com/Blog/index-view?id=151)",662
870,870,"720+ new NLP models, 300+ supported languages, translation, summarization, question answering, and more with T5 and Marian models! - John Snow Labs NLU 1.1.0","
# 720+ new  NLP models, 300+ supported languages, translation, summarization, question answering and more with T5 and Marian models!  - John Snow Labs NLU 1.1.0

##  NLU 1.1.0 Release Notes

We are incredibly excited to release NLU 1.1.0!
This release integrates the 720+ new models from the latest [Spark-NLP 2.7.0 + releases](https://github.com/JohnSnowLabs/spark-nlp/releases)
You can now achieve state-of-the-art results with Sequence2Sequence transformers on problems like text summarization, question answering, translation between  192+ languages, and extract Named Entity in various Right to Left written languages like  Arabic, Persian, Urdu, and languages that require segmentation like Koreas, Japanese, Chinese, and many more in 1 line of code!     
These new features are possible because of the integration of the [Google's T5 models](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html) and [Microsoft's Marian models](https://marian-nmt.github.io/publications/)  transformers.

NLU 1.1.0 has over 720+ new pretrained models and pipelines while extending the support of multi-lingual models to 192+ languages such as Chinese, Japanese, Korean, Arabic, Persian, Urdu, and Hebrew.


In addition to this, NLU 1.1.0 comes with 9 new notebooks showcasing training classifiers for various review and sentiment datasets and 7 notebooks for the new features and models.


### NLU 1.1.0  New Features
* **720+** new models you can find an overview of all NLU models [here](https://nlu.johnsnowlabs.com/docs/en/namespace) and further documentation in the [models hub](https://nlp.johnsnowlabs.com/models)
* **NEW:** Introducing MarianTransformer annotator for machine translation based on MarianNMT models. Marian is an efficient, free Neural Machine Translation framework mainly being developed by the Microsoft Translator team (646+ pretrained models &amp; pipelines in 192+ languages)
* **NEW:** Introducing T5Transformer annotator for Text-To-Text Transfer Transformer (Google T5) models to achieve state-of-the-art results on multiple NLP tasks such as Translation, Summarization, Question Answering, Sentence Similarity, and so on
* **NEW:** Introducing brand new and refactored language detection and identification models. The new LanguageDetectorDL is faster, more accurate, and supports up to 375 languages
* **NEW:** Introducing WordSegmenter model for word segmentation of languages without any rule-based tokenization such as Chinese, Japanese, or Korean
* **NEW:** Introducing DocumentNormalizer component for cleaning content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters

## Translation
[Translation example](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/translation_demo.ipynb)       
You can translate between more than 192 Languages pairs with the [Marian Models](https://marian-nmt.github.io/publications/)
You need to specify the language your data is in as `start_language` and the language you want to translate to as `target_language`.    
The language references must be [ISO language codes](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)

`nlu.load('&lt;start_language&gt;.translate.&lt;target_language&gt;')`

**Translate English to French :**     
```
nlu.load('en.translate_to.fr').predict(""Hello from John Snow Labs"")
&gt;&gt;&gt; Output: Bonjour des laboratoires de neige de John!	 

```
**Translate English to Inukitut :**     
```
nlu.load('en.translate_to.lu').predict(""Hello from John Snow Labs"")
&gt;&gt;&gt; Output: kalunganyembo ka mashika makamankate 
```
**Translate English to Hungarian :**
```
nlu.load('en.translate_to.hu').predict(""Hello from John Snow Labs"")
&gt;&gt;&gt; Output: Helló John hó laborjából.
```
**Translate English to German :**
```
nlu.load('en.translate_to.de').predict(""Hello from John Snow Labs!"")
&gt;&gt;&gt; Output: Hallo aus John Schnee Labors 
```


```python
translate_pipe = nlu.load('en.translate_to.de')
df = translate_pipe.predict('Billy likes to go to the mall every sunday')
df
```

|	sentence|	translation|
|-----------|--------------|
|Billy likes to go to the mall every sunday	| Billy geht gerne jeden Sonntag ins Einkaufszentrum|






## T5
[Example of every T5 task](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_tasks_summarize_question_answering_and_more)
### Overview of every task available with T5
[The T5 model](https://arxiv.org/pdf/1910.10683.pdf) is trained on various datasets for 17 different tasks which fall into 8 categories.


1. Text summarization
2. Question answering
3. Translation
4. Sentiment analysis
5. Natural Language inference
6. Coreference resolution
7. Sentence Completion
8. Word sense disambiguation

### Every T5 Task with explanation:

|Task Name | Explanation | 
|----------|--------------|
|[1.CoLA](https://nyu-mll.github.io/CoLA/)                   | Classify if a sentence is gramaticaly correct|
|[2.RTE](https://dl.acm.org/doi/10.1007/11736790_9)                    | Classify whether if a statement can be deducted from a sentence|
|[3.MNLI](https://arxiv.org/abs/1704.05426)                   | Classify for a hypothesis and premise whether they contradict or contradict each other or neither of both (3 class).|
|[4.MRPC](https://www.aclweb.org/anthology/I05-5002.pdf)                   | Classify whether a pair of sentences is a re-phrasing of each other (semantically equivalent)|
|[5.QNLI](https://arxiv.org/pdf/1804.07461.pdf)                   | Classify whether the answer to a question can be deducted from an answer candidate.|
|[6.QQP](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)                    | Classify whether a pair of questions is a re-phrasing of each other (semantically equivalent)|
|[7.SST2](https://www.aclweb.org/anthology/D13-1170.pdf)                   | Classify the sentiment of a sentence as positive or negative|
|[8.STSB](https://www.aclweb.org/anthology/S17-2001/)                   | Classify the sentiment of a sentence on a scale from 1 to 5 (21 Sentiment classes)|
|[9.CB](https://ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/601)                     | Classify for a premise and a hypothesis whether they contradict each other or not (binary).|
|[10.COPA](https://www.aaai.org/ocs/index.php/SSS/SSS11/paper/view/2418/0)                   | Classify for a question, premise, and 2 choices which choice the correct choice is (binary).|
|[11.MultiRc](https://www.aclweb.org/anthology/N18-1023.pdf)                | Classify for a question, a paragraph of text, and an answer candidate, if the answer is correct (binary),|
|[12.WiC](https://arxiv.org/abs/1808.09121)                    | Classify for a pair of sentences and a disambigous word if the word has the same meaning in both sentences.|
|[13.WSC/DPR](https://www.aaai.org/ocs/index.php/KR/KR12/paper/view/4492/0)       | Predict for an ambiguous pronoun in a sentence what it is referring to.  |
|[14.Summarization](https://arxiv.org/abs/1506.03340)          | Summarize text into a shorter representation.|
|[15.SQuAD](https://arxiv.org/abs/1606.05250)                  | Answer a question for a given context.|
|[16.WMT1.](https://arxiv.org/abs/1706.03762)                  | Translate English to German|
|[17.WMT2.](https://arxiv.org/abs/1706.03762)                   | Translate English to French|
|[18.WMT3.](https://arxiv.org/abs/1706.03762)                   | Translate English to Romanian|

- [Every T5 Task example notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_tasks_summarize_question_answering_and_more) to see how to use every T5 Task.
- [T5 Open and Closed Book question answering  notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_question_answering.ipynb)

# `Open book` and `Closed book` question answering with Google's T5
[T5 Open and Closed Book question answering tutorial](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_question_answering.ipynb)

With the latest NLU release and Google's T5 you can answer **general knowledge based questions given no context** and in addition answer **questions on text databases**.      
These questions can be asked in natural human language and answerd in just 1 line with NLU!.




## What is a `open book question`?
You can imagine an `open book` question similar to an examen where you are allowed to bring in text documents or cheat sheets that help you answer questions in an examen. Kinda like bringing a history book to an history examen.

In `T5's` terms, this means the model is given a `question` and an **additional piece of textual information** or so called `context`.

This enables the `T5` model to answer questions on textual datasets like `medical records`,`newsarticles` , `wiki-databases` , `stories` and `movie scripts` , `product descriptions`, 'legal documents' and many more.

You can answer `open book question` in 1 line of code, leveraging the latest NLU release and Google's T5.     
All it takes is :



```python
nlu.load('answer_question').predict(""""""
Where did Jebe die?
context: Ghenkis Khan recalled Subtai back to Mongolia soon afterwards,
 and Jebe died on the road back to Samarkand"""""")
&gt;&gt;&gt; Output: Samarkand
```

Example for answering medical questions based on medical context
``` python
question ='''
What does increased oxygen concentrations in the patient’s lungs displace? 
context: Hyperbaric (high-pressure) medicine uses special oxygen chambers to increase the partial pressure of O 2 around the patient and, when needed, the medical staff. 
Carbon monoxide poisoning, gas gangrene, and decompression sickness (the ’bends’) are sometimes treated using these devices. Increased O 2 concentration in the lungs helps to displace carbon monoxide from the heme group of hemoglobin.
 Oxygen gas is poisonous to the anaerobic bacteria that cause gas gangrene, so increasing its partial pressure helps kill them. Decompression sickness occurs in divers who decompress too quickly after a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming in their blood. Increasing the pressure of O 2 as soon as possible is part of the treatment.
'''


#Predict on text data with T5
nlu.load('answer_question').predict(question)
&gt;&gt;&gt; Output: carbon monoxide	
```

Take a look at this example on a recent news article snippet :
```python
question1 = 'Who is Jack ma?'
question2 = 'Who is founder of Alibaba Group?'
question3 = 'When did Jack Ma re-appear?'
question4 = 'How did Alibaba stocks react?'
question5 = 'Whom did Jack Ma meet?'
question6 = 'Who did Jack Ma hide from?'

# from https://www.bbc.com/news/business-55728338 
news_article_snippet = """""" context:
Alibaba Group founder Jack Ma has made his first appearance since Chinese regulators cracked down on his business empire.
His absence had fuelled speculation over his whereabouts amid increasing official scrutiny of his businesses.
The billionaire met 100 rural teachers in China via a video meeting on Wednesday, according to local government media.
Alibaba shares surged 5% on Hong Kong's stock exchange on the news.
""""""
# join question with context, works with Pandas DF aswell!
questions = [
             question1+ news_article_snippet,
             question2+ news_article_snippet,
             question3+ news_article_snippet,
             question4+ news_article_snippet,
             question5+ news_article_snippet,
             question6+ news_article_snippet,]
nlu.load('answer_question').predict(questions)
```
This will output a Pandas Dataframe similar to this :

|Answer|Question|
|-----|---------|
Alibaba Group founder| 	Who is Jack ma? |        
|Jack Ma	|Who is founder of Alibaba Group? |  
Wednesday	| When did Jack Ma re-appear? | 
surged 5%	| How did Alibaba stocks react? | 
100 rural teachers	| Whom did Jack Ma meet? | 
Chinese regulators	|Who did Jack Ma hide from?|



## What is a `closed book question`?
A `closed book question` is the exact opposite of a `open book question`. In an examen scenario, you are only allowed to use what you have memorized in your brain and nothing else.      
In `T5's` terms this means that T5 can only use it's stored weights to answer a `question` and is given **no aditional context**.        
`T5` was pre-trained on the [C4 dataset](https://commoncrawl.org/) which contains **petabytes  of web crawling data**  collected over the last 8 years, including Wikipedia in every language.


This gives `T5` the broad knowledge of the internet stored in it's weights to answer various `closed book questions`

You can answer `closed book question` in 1 line of code, leveraging the latest NLU release and Google's T5.     
You need to pass one string to NLU, which starts which a `question` and is followed by  a `context:` tag and then the actual context contents.
All it takes is :


```python
nlu.load('en.t5').predict('Who is president of Nigeria?')
&gt;&gt;&gt; Muhammadu Buhari 
```


```python
nlu.load('en.t5').predict('What is the most spoken language in India?')
&gt;&gt;&gt; Hindi
```


```python
nlu.load('en.t5').predict('What is the capital of Germany?')
&gt;&gt;&gt; Berlin
```




## Text Summarization with T5
[Summarization example](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_tasks_summarize_question_answering_and_more)

`Summarizes` a paragraph into a shorter version with the same semantic meaning, based on [this paper](https://arxiv.org/abs/1506.03340)

```python
# Set the task on T5
pipe = nlu.load('summarize')

# define Data, add additional tags between sentences
data = [
'''
The belgian duo took to the dance floor on monday night with some friends . manchester united face newcastle in the premier league on wednesday . red devils will be looking for just their second league away win in seven . louis van gaal’s side currently sit two points clear of liverpool in fourth .
''',
'''  Calculus, originally called infinitesimal calculus or ""the calculus of infinitesimals"", is the mathematical study of continuous change, in the same way that geometry is the study of shape and algebra is the study of generalizations of arithmetic operations. It has two major branches, differential calculus and integral calculus; the former concerns instantaneous rates of change, and the slopes of curves, while integral calculus concerns accumulation of quantities, and areas under or between curves. These two branches are related to each other by the fundamental theorem of calculus, and they make use of the fundamental notions of convergence of infinite sequences and infinite series to a well-defined limit.[1] Infinitesimal calculus was developed independently in the late 17th century by Isaac Newton and Gottfried Wilhelm Leibniz.[2][3] Today, calculus has widespread uses in science, engineering, and economics.[4] In mathematics education, calculus denotes courses of elementary mathematical analysis, which are mainly devoted to the study of functions and limits. The word calculus (plural calculi) is a Latin word, meaning originally ""small pebble"" (this meaning is kept in medicine – see Calculus (medicine)). Because such pebbles were used for calculation, the meaning of the word has evolved and today usually means a method of computation. It is therefore used for naming specific methods of calculation and related theories, such as propositional calculus, Ricci calculus, calculus of variations, lambda calculus, and process calculus.'''
]


#Predict on text data with T5
pipe.predict(data)
```

| Predicted summary| Text | 
|------------------|-------|
| manchester united face newcastle in the premier league on wednesday . louis van gaal's side currently sit two points clear of liverpool in fourth . the belgian duo took to the dance floor on monday night with some friends .            | the belgian duo took to the dance floor on monday night with some friends . manchester united face newcastle in the premier league on wednesday . red devils will be looking for just their second league away win in seven . louis van gaal’s side currently sit two points clear of liverpool in fourth . | 


## Binary Sentence similarity/ Paraphrasing
[Binary sentence similarity example](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_tasks_summarize_question_answering_and_more)
Classify whether one sentence is a re-phrasing or similar to another sentence      
This is a sub-task of [GLUE](https://arxiv.org/pdf/1804.07461.pdf) and based on [MRPC - Binary Paraphrasing/ sentence similarity classification ](https://www.aclweb.org/anthology/I05-5002.pdf)

```
t5 = nlu.load('en.t5.base')
# Set the task on T5
t5['t5'].setTask('mrpc ')

# define Data, add additional tags between sentences
data = [
''' sentence1: We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , "" Rumsfeld said .
sentence2: Rather , the US acted because the administration saw "" existing evidence in a new light , through the prism of our experience on September 11 ""
'''
,
'''  
sentence1: I like to eat peanutbutter for breakfast
sentence2: 	I like to play football.
'''
]

#Predict on text data with T5
t5.predict(data)
```
| Sentence1 | Sentence2 | prediction|
|------------|------------|----------|
|We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , "" Rumsfeld said .| Rather , the US acted because the administration saw "" existing evidence in a new light , through the prism of our experience on September 11 "" . | equivalent | 
| I like to eat peanutbutter for breakfast| I like to play football | not_equivalent | 


### How to configure T5 task for MRPC and pre-process text
`.setTask('mrpc sentence1:)` and prefix second sentence with `sentence2:`

### Example pre-processed input for T5 MRPC - Binary Paraphrasing/ sentence similarity

```
mrpc 
sentence1: We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , "" Rumsfeld said . 
sentence2: Rather , the US acted because the administration saw "" existing evidence in a new light , through the prism of our experience on September 11"",
```



## Regressive Sentence similarity/ Paraphrasing

Measures how similar two sentences are on a scale from 0 to 5 with 21 classes representing a regressive label.     
This is a sub-task of [GLUE](https://arxiv.org/pdf/1804.07461.pdf) and based on[STSB - Regressive semantic sentence similarity](https://www.aclweb.org/anthology/S17-2001/) .

```python
t5 = nlu.load('en.t5.base')
# Set the task on T5
t5['t5'].setTask('stsb ') 

# define Data, add additional tags between sentences
data = [
             
              ''' sentence1:  What attributes would have made you highly desirable in ancient Rome?  
                  sentence2:  How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER?'
              '''
             ,
             '''  
              sentence1: What was it like in Ancient rome?
              sentence2: 	What was Ancient rome like?
              ''',
              '''  
              sentence1: What was live like as a King in Ancient Rome??
              sentence2: 	What was Ancient rome like?
              '''

             ]



#Predict on text data with T5
t5.predict(data)

```

| sentence1 | sentence2 | prediction|
|------------|------------|----------|
|What attributes would have made you highly desirable in ancient Rome?        | How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER? | 0 | 
|What was it like in Ancient rome?  | What was Ancient rome like?| 5.0 | 
|What was live like as a King in Ancient Rome??       | What is it like to live in Rome? | 3.2 | 


### How to configure T5 task for stsb and pre-process text
`.setTask('stsb sentence1:)` and prefix second sentence with `sentence2:`




### Example pre-processed input for T5 STSB - Regressive semantic sentence similarity

```
stsb
sentence1: What attributes would have made you highly desirable in ancient Rome?        
sentence2: How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER?',
```





## Grammar Checking
[Grammar checking with T5 example](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_tasks_summarize_question_answering_and_more)
Judges if a sentence is grammatically acceptable.    
Based on [CoLA - Binary Grammatical Sentence acceptability classification](https://nyu-mll.github.io/CoLA/)

```python
pipe = nlu.load('grammar_correctness')
# Set the task on T5
pipe['t5'].setTask('cola sentence: ')
# define Data
data = ['Anna and Mike is going skiing and they is liked is','Anna and Mike like to dance']
#Predict on text data with T5
pipe.predict(data)
```
|sentence  | prediction|
|------------|------------|
| Anna and Mike is going skiing and they is liked is | unacceptable |      
| Anna and Mike like to dance | acceptable | 


## Document Normalization
[Document Normalizer example](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/text_pre_processing_and_cleaning/document_normalizer_demo.ipynb)     
The DocumentNormalizer extracts content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters

```python
pipe = nlu.load('norm_document')
data = '&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is an example of a simple HTML page with one paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt;'
df = pipe.predict(data,output_level='document')
df
```
|text|normalized_text|
|------|-------------|
| `&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is an example of a simple HTML page with one paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt;`       |Example This is an example of a simple HTML page with one paragraph.|

## Word Segmenter
[Word Segmenter Example](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/multilingual/japanese_ner_pos_and_tokenization.ipynb)     
The WordSegmenter segments languages without any rule-based tokenization such as Chinese, Japanese, or Korean
```python
pipe = nlu.load('ja.segment_words')
# japanese for 'Donald Trump and Angela Merkel dont share many opinions'
ja_data = ['ドナルド・トランプとアンゲラ・メルケルは多くの意見を共有していません']
df = pipe.predict(ja_data, output_level='token')
df

```

|	token|
|--------|
|	ドナルド|
|	・|
|	トランプ|
|	と|
|	アンゲラ|
|	・|
|	メルケル|
|	は|
|	多く|
|	の|
|	意見|
|	を|
|	共有|
|	し|
|	て|
|	い|
|	ませ|
|	ん|


# Named Entity Extraction (NER) in Various Languages 
NLU now support NER for over 60 languages, including Korean, Japanese, Chinese and many more!   
```python

# Extract named chinese entities
pipe = nlu.load('zh.ner')
# Chinese for 'Donald Trump and Angela Merkel dont share many opinions'
zh_data = ['唐纳德特朗普和安吉拉·默克尔没有太多意见']
df = pipe.predict(zh_data, output_level='document')
df
&gt;&gt;&gt; Output : [唐纳德, 安吉拉]

# Now translate [唐纳德, 安吉拉] back to english with NLU!
translate_pipe = nlu.load('zh.translate_to.en')
en_entities = translate_pipe.predict(['唐纳德', '安吉拉'])
&gt;&gt;&gt; Output :
```
|Translation|	Chinese| 
|------|------|
|Donald | 唐纳德 |
|Angela | 	安吉拉|

# New NLU Notebooks


### NLU 1.1.0  New Notebooks for new features
- [Translate between 192+ languages with marian](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/translation_demo.ipynb)
- [Try out the 18 Tasks like Summarization Question Answering and more on T5](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_tasks_summarize_question_answering_and_more)
- [T5 Open and Closed Book question answering tutorial](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_question_answering.ipynb)
- [Tokenize, extract POS and NER in Chinese](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/multilingual/chinese_ner_pos_and_tokenization.ipynb)
- [Tokenize, extract POS and NER in Korean](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/multilingual/korean_ner_pos_and_tokenization.ipynb)
- [Tokenize, extract POS and NER in Japanese](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/multilingual/japanese_ner_pos_and_tokenization.ipynb)
- [Normalize documents](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/text_pre_processing_and_cleaning/document_normalizer_demo.ipynb)
- [Aspect based sentiment NER sentiment for restaurants](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/named_entity_recognition_(NER)/aspect_based_ner_sentiment_restaurants.ipynb)

### NLU 1.1.0 New Classifier Training Tutorials
#### Binary Classifier training Jupyter tutorials
- [2 class Finance News sentiment classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/binary_text_classification/NLU_training_sentiment_classifier_demo_apple_twitter.ipynb)
- [2 class Reddit comment sentiment classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/binary_text_classification/NLU_training_sentiment_classifier_demo_reddit.ipynb)
- [2 class Apple Tweets sentiment classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/binary_text_classification/NLU_training_sentiment_classifier_demo_IMDB.ipynb)
- [2 class IMDB Movie sentiment classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/binary_text_classification/NLU_training_sentiment_classifier_demo_IMDB.ipynb)
- [2 class twitter classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/binary_text_classification/NLU_training_sentiment_classifier_demo_twitter.ipynb)

#### Multi Class text Classifier training Jupyter tutorials
- [5 class WineEnthusiast Wine review classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/multi_class_text_classification/NLU_training_multi_class_text_classifier_demo_wine.ipynb)
- [3 class Amazon Phone review classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/multi_class_text_classification/NLU_training_multi_class_text_classifier_demo_amazon.ipynb)
- [5 class Amazon Musical Instruments review classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/multi_class_text_classification/NLU_training_multi_class_text_classifier_demo_musical_instruments.ipynb)
- [5 class Tripadvisor Hotel review classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/multi_class_text_classification/NLU_training_multi_class_text_classifier_demo_hotel_reviews.ipynb)



### NLU 1.1.0 New Medium Tutorials

- [1 line to Glove Word Embeddings with NLU     with t-SNE plots](https://medium.com/spark-nlp/1-line-to-glove-word-embeddings-with-nlu-in-python-baed152fff4d)
- [1 line to Xlnet Word Embeddings with NLU     with t-SNE plots](https://medium.com/spark-nlp/1-line-to-xlnet-word-embeddings-with-nlu-in-python-5efc57d7ac79)
- [1 line to AlBERT Word Embeddings with NLU    with t-SNE plots](https://medium.com/spark-nlp/1-line-to-albert-word-embeddings-with-nlu-in-python-1691bc048ed1)
- [1 line to CovidBERT Word Embeddings with NLU with t-SNE plots](https://medium.com/spark-nlp/1-line-to-covidbert-word-embeddings-with-nlu-in-python-e67396da2f78)
- [1 line to Electra Word Embeddings with NLU   with t-SNE plots](https://medium.com/spark-nlp/1-line-to-electra-word-embeddings-with-nlu-in-python-25f749bf3e92)
- [1 line to BioBERT Word Embeddings with NLU   with t-SNE plots](https://medium.com/spark-nlp/1-line-to-biobert-word-embeddings-with-nlu-in-python-7224ab52e131)



## Installation

```bash
# PyPi
!pip install nlu pyspark==2.4.7
#Conda
# Install NLU from Anaconda/Conda
conda install -c johnsnowlabs nlu
```


# Additional NLU ressources
- [NLU Website](https://nlu.johnsnowlabs.com/)
- [All NLU Tutorial Notebooks](https://nlu.johnsnowlabs.com/docs/en/notebooks)
- [NLU Videos and Blogposts on NLU](https://nlp.johnsnowlabs.com/learn#pythons-nlu-library)
- [NLU on Github](https://github.com/JohnSnowLabs/nlu)",https://www.reddit.com/r/LanguageTechnology/comments/l4c8t9/720_new_nlp_models_300_supported_languages/,LanguageTechnology,t3_l4c8t9,"720+ new NLP models, 300+ supported languages, translation, summarization, question answering, and more with T5 and Marian models! - John Snow Labs NLU 1.1.0 
# 720+ new  NLP models, 300+ supported languages, translation, summarization, question answering and more with T5 and Marian models!  - John Snow Labs NLU 1.1.0

##  NLU 1.1.0 Release Notes

We are incredibly excited to release NLU 1.1.0!
This release integrates the 720+ new models from the latest [Spark-NLP 2.7.0 + releases](https://github.com/JohnSnowLabs/spark-nlp/releases)
You can now achieve state-of-the-art results with Sequence2Sequence transformers on problems like text summarization, question answering, translation between  192+ languages, and extract Named Entity in various Right to Left written languages like  Arabic, Persian, Urdu, and languages that require segmentation like Koreas, Japanese, Chinese, and many more in 1 line of code!     
These new features are possible because of the integration of the [Google's T5 models](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html) and [Microsoft's Marian models](https://marian-nmt.github.io/publications/)  transformers.

NLU 1.1.0 has over 720+ new pretrained models and pipelines while extending the support of multi-lingual models to 192+ languages such as Chinese, Japanese, Korean, Arabic, Persian, Urdu, and Hebrew.


In addition to this, NLU 1.1.0 comes with 9 new notebooks showcasing training classifiers for various review and sentiment datasets and 7 notebooks for the new features and models.


### NLU 1.1.0  New Features
* **720+** new models you can find an overview of all NLU models [here](https://nlu.johnsnowlabs.com/docs/en/namespace) and further documentation in the [models hub](https://nlp.johnsnowlabs.com/models)
* **NEW:** Introducing MarianTransformer annotator for machine translation based on MarianNMT models. Marian is an efficient, free Neural Machine Translation framework mainly being developed by the Microsoft Translator team (646+ pretrained models &amp; pipelines in 192+ languages)
* **NEW:** Introducing T5Transformer annotator for Text-To-Text Transfer Transformer (Google T5) models to achieve state-of-the-art results on multiple NLP tasks such as Translation, Summarization, Question Answering, Sentence Similarity, and so on
* **NEW:** Introducing brand new and refactored language detection and identification models. The new LanguageDetectorDL is faster, more accurate, and supports up to 375 languages
* **NEW:** Introducing WordSegmenter model for word segmentation of languages without any rule-based tokenization such as Chinese, Japanese, or Korean
* **NEW:** Introducing DocumentNormalizer component for cleaning content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters

## Translation
[Translation example](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/translation_demo.ipynb)       
You can translate between more than 192 Languages pairs with the [Marian Models](https://marian-nmt.github.io/publications/)
You need to specify the language your data is in as `start_language` and the language you want to translate to as `target_language`.    
The language references must be [ISO language codes](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)

`nlu.load('&lt;start_language&gt;.translate.&lt;target_language&gt;')`

**Translate English to French :**     
```
nlu.load('en.translate_to.fr').predict(""Hello from John Snow Labs"")
&gt;&gt;&gt; Output: Bonjour des laboratoires de neige de John!	 

```
**Translate English to Inukitut :**     
```
nlu.load('en.translate_to.lu').predict(""Hello from John Snow Labs"")
&gt;&gt;&gt; Output: kalunganyembo ka mashika makamankate 
```
**Translate English to Hungarian :**
```
nlu.load('en.translate_to.hu').predict(""Hello from John Snow Labs"")
&gt;&gt;&gt; Output: Helló John hó laborjából.
```
**Translate English to German :**
```
nlu.load('en.translate_to.de').predict(""Hello from John Snow Labs!"")
&gt;&gt;&gt; Output: Hallo aus John Schnee Labors 
```


```python
translate_pipe = nlu.load('en.translate_to.de')
df = translate_pipe.predict('Billy likes to go to the mall every sunday')
df
```

|	sentence|	translation|
|-----------|--------------|
|Billy likes to go to the mall every sunday	| Billy geht gerne jeden Sonntag ins Einkaufszentrum|






## T5
[Example of every T5 task](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_tasks_summarize_question_answering_and_more)
### Overview of every task available with T5
[The T5 model](https://arxiv.org/pdf/1910.10683.pdf) is trained on various datasets for 17 different tasks which fall into 8 categories.


1. Text summarization
2. Question answering
3. Translation
4. Sentiment analysis
5. Natural Language inference
6. Coreference resolution
7. Sentence Completion
8. Word sense disambiguation

### Every T5 Task with explanation:

|Task Name | Explanation | 
|----------|--------------|
|[1.CoLA](https://nyu-mll.github.io/CoLA/)                   | Classify if a sentence is gramaticaly correct|
|[2.RTE](https://dl.acm.org/doi/10.1007/11736790_9)                    | Classify whether if a statement can be deducted from a sentence|
|[3.MNLI](https://arxiv.org/abs/1704.05426)                   | Classify for a hypothesis and premise whether they contradict or contradict each other or neither of both (3 class).|
|[4.MRPC](https://www.aclweb.org/anthology/I05-5002.pdf)                   | Classify whether a pair of sentences is a re-phrasing of each other (semantically equivalent)|
|[5.QNLI](https://arxiv.org/pdf/1804.07461.pdf)                   | Classify whether the answer to a question can be deducted from an answer candidate.|
|[6.QQP](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)                    | Classify whether a pair of questions is a re-phrasing of each other (semantically equivalent)|
|[7.SST2](https://www.aclweb.org/anthology/D13-1170.pdf)                   | Classify the sentiment of a sentence as positive or negative|
|[8.STSB](https://www.aclweb.org/anthology/S17-2001/)                   | Classify the sentiment of a sentence on a scale from 1 to 5 (21 Sentiment classes)|
|[9.CB](https://ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/601)                     | Classify for a premise and a hypothesis whether they contradict each other or not (binary).|
|[10.COPA](https://www.aaai.org/ocs/index.php/SSS/SSS11/paper/view/2418/0)                   | Classify for a question, premise, and 2 choices which choice the correct choice is (binary).|
|[11.MultiRc](https://www.aclweb.org/anthology/N18-1023.pdf)                | Classify for a question, a paragraph of text, and an answer candidate, if the answer is correct (binary),|
|[12.WiC](https://arxiv.org/abs/1808.09121)                    | Classify for a pair of sentences and a disambigous word if the word has the same meaning in both sentences.|
|[13.WSC/DPR](https://www.aaai.org/ocs/index.php/KR/KR12/paper/view/4492/0)       | Predict for an ambiguous pronoun in a sentence what it is referring to.  |
|[14.Summarization](https://arxiv.org/abs/1506.03340)          | Summarize text into a shorter representation.|
|[15.SQuAD](https://arxiv.org/abs/1606.05250)                  | Answer a question for a given context.|
|[16.WMT1.](https://arxiv.org/abs/1706.03762)                  | Translate English to German|
|[17.WMT2.](https://arxiv.org/abs/1706.03762)                   | Translate English to French|
|[18.WMT3.](https://arxiv.org/abs/1706.03762)                   | Translate English to Romanian|

- [Every T5 Task example notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_tasks_summarize_question_answering_and_more) to see how to use every T5 Task.
- [T5 Open and Closed Book question answering  notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_question_answering.ipynb)

# `Open book` and `Closed book` question answering with Google's T5
[T5 Open and Closed Book question answering tutorial](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_question_answering.ipynb)

With the latest NLU release and Google's T5 you can answer **general knowledge based questions given no context** and in addition answer **questions on text databases**.      
These questions can be asked in natural human language and answerd in just 1 line with NLU!.




## What is a `open book question`?
You can imagine an `open book` question similar to an examen where you are allowed to bring in text documents or cheat sheets that help you answer questions in an examen. Kinda like bringing a history book to an history examen.

In `T5's` terms, this means the model is given a `question` and an **additional piece of textual information** or so called `context`.

This enables the `T5` model to answer questions on textual datasets like `medical records`,`newsarticles` , `wiki-databases` , `stories` and `movie scripts` , `product descriptions`, 'legal documents' and many more.

You can answer `open book question` in 1 line of code, leveraging the latest NLU release and Google's T5.     
All it takes is :



```python
nlu.load('answer_question').predict(""""""
Where did Jebe die?
context: Ghenkis Khan recalled Subtai back to Mongolia soon afterwards,
 and Jebe died on the road back to Samarkand"""""")
&gt;&gt;&gt; Output: Samarkand
```

Example for answering medical questions based on medical context
``` python
question ='''
What does increased oxygen concentrations in the patient’s lungs displace? 
context: Hyperbaric (high-pressure) medicine uses special oxygen chambers to increase the partial pressure of O 2 around the patient and, when needed, the medical staff. 
Carbon monoxide poisoning, gas gangrene, and decompression sickness (the ’bends’) are sometimes treated using these devices. Increased O 2 concentration in the lungs helps to displace carbon monoxide from the heme group of hemoglobin.
 Oxygen gas is poisonous to the anaerobic bacteria that cause gas gangrene, so increasing its partial pressure helps kill them. Decompression sickness occurs in divers who decompress too quickly after a dive, resulting in bubbles of inert gas, mostly nitrogen and helium, forming in their blood. Increasing the pressure of O 2 as soon as possible is part of the treatment.
'''


#Predict on text data with T5
nlu.load('answer_question').predict(question)
&gt;&gt;&gt; Output: carbon monoxide	
```

Take a look at this example on a recent news article snippet :
```python
question1 = 'Who is Jack ma?'
question2 = 'Who is founder of Alibaba Group?'
question3 = 'When did Jack Ma re-appear?'
question4 = 'How did Alibaba stocks react?'
question5 = 'Whom did Jack Ma meet?'
question6 = 'Who did Jack Ma hide from?'

# from https://www.bbc.com/news/business-55728338 
news_article_snippet = """""" context:
Alibaba Group founder Jack Ma has made his first appearance since Chinese regulators cracked down on his business empire.
His absence had fuelled speculation over his whereabouts amid increasing official scrutiny of his businesses.
The billionaire met 100 rural teachers in China via a video meeting on Wednesday, according to local government media.
Alibaba shares surged 5% on Hong Kong's stock exchange on the news.
""""""
# join question with context, works with Pandas DF aswell!
questions = [
             question1+ news_article_snippet,
             question2+ news_article_snippet,
             question3+ news_article_snippet,
             question4+ news_article_snippet,
             question5+ news_article_snippet,
             question6+ news_article_snippet,]
nlu.load('answer_question').predict(questions)
```
This will output a Pandas Dataframe similar to this :

|Answer|Question|
|-----|---------|
Alibaba Group founder| 	Who is Jack ma? |        
|Jack Ma	|Who is founder of Alibaba Group? |  
Wednesday	| When did Jack Ma re-appear? | 
surged 5%	| How did Alibaba stocks react? | 
100 rural teachers	| Whom did Jack Ma meet? | 
Chinese regulators	|Who did Jack Ma hide from?|



## What is a `closed book question`?
A `closed book question` is the exact opposite of a `open book question`. In an examen scenario, you are only allowed to use what you have memorized in your brain and nothing else.      
In `T5's` terms this means that T5 can only use it's stored weights to answer a `question` and is given **no aditional context**.        
`T5` was pre-trained on the [C4 dataset](https://commoncrawl.org/) which contains **petabytes  of web crawling data**  collected over the last 8 years, including Wikipedia in every language.


This gives `T5` the broad knowledge of the internet stored in it's weights to answer various `closed book questions`

You can answer `closed book question` in 1 line of code, leveraging the latest NLU release and Google's T5.     
You need to pass one string to NLU, which starts which a `question` and is followed by  a `context:` tag and then the actual context contents.
All it takes is :


```python
nlu.load('en.t5').predict('Who is president of Nigeria?')
&gt;&gt;&gt; Muhammadu Buhari 
```


```python
nlu.load('en.t5').predict('What is the most spoken language in India?')
&gt;&gt;&gt; Hindi
```


```python
nlu.load('en.t5').predict('What is the capital of Germany?')
&gt;&gt;&gt; Berlin
```




## Text Summarization with T5
[Summarization example](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_tasks_summarize_question_answering_and_more)

`Summarizes` a paragraph into a shorter version with the same semantic meaning, based on [this paper](https://arxiv.org/abs/1506.03340)

```python
# Set the task on T5
pipe = nlu.load('summarize')

# define Data, add additional tags between sentences
data = [
'''
The belgian duo took to the dance floor on monday night with some friends . manchester united face newcastle in the premier league on wednesday . red devils will be looking for just their second league away win in seven . louis van gaal’s side currently sit two points clear of liverpool in fourth .
''',
'''  Calculus, originally called infinitesimal calculus or ""the calculus of infinitesimals"", is the mathematical study of continuous change, in the same way that geometry is the study of shape and algebra is the study of generalizations of arithmetic operations. It has two major branches, differential calculus and integral calculus; the former concerns instantaneous rates of change, and the slopes of curves, while integral calculus concerns accumulation of quantities, and areas under or between curves. These two branches are related to each other by the fundamental theorem of calculus, and they make use of the fundamental notions of convergence of infinite sequences and infinite series to a well-defined limit.[1] Infinitesimal calculus was developed independently in the late 17th century by Isaac Newton and Gottfried Wilhelm Leibniz.[2][3] Today, calculus has widespread uses in science, engineering, and economics.[4] In mathematics education, calculus denotes courses of elementary mathematical analysis, which are mainly devoted to the study of functions and limits. The word calculus (plural calculi) is a Latin word, meaning originally ""small pebble"" (this meaning is kept in medicine – see Calculus (medicine)). Because such pebbles were used for calculation, the meaning of the word has evolved and today usually means a method of computation. It is therefore used for naming specific methods of calculation and related theories, such as propositional calculus, Ricci calculus, calculus of variations, lambda calculus, and process calculus.'''
]


#Predict on text data with T5
pipe.predict(data)
```

| Predicted summary| Text | 
|------------------|-------|
| manchester united face newcastle in the premier league on wednesday . louis van gaal's side currently sit two points clear of liverpool in fourth . the belgian duo took to the dance floor on monday night with some friends .            | the belgian duo took to the dance floor on monday night with some friends . manchester united face newcastle in the premier league on wednesday . red devils will be looking for just their second league away win in seven . louis van gaal’s side currently sit two points clear of liverpool in fourth . | 


## Binary Sentence similarity/ Paraphrasing
[Binary sentence similarity example](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_tasks_summarize_question_answering_and_more)
Classify whether one sentence is a re-phrasing or similar to another sentence      
This is a sub-task of [GLUE](https://arxiv.org/pdf/1804.07461.pdf) and based on [MRPC - Binary Paraphrasing/ sentence similarity classification ](https://www.aclweb.org/anthology/I05-5002.pdf)

```
t5 = nlu.load('en.t5.base')
# Set the task on T5
t5['t5'].setTask('mrpc ')

# define Data, add additional tags between sentences
data = [
''' sentence1: We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , "" Rumsfeld said .
sentence2: Rather , the US acted because the administration saw "" existing evidence in a new light , through the prism of our experience on September 11 ""
'''
,
'''  
sentence1: I like to eat peanutbutter for breakfast
sentence2: 	I like to play football.
'''
]

#Predict on text data with T5
t5.predict(data)
```
| Sentence1 | Sentence2 | prediction|
|------------|------------|----------|
|We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , "" Rumsfeld said .| Rather , the US acted because the administration saw "" existing evidence in a new light , through the prism of our experience on September 11 "" . | equivalent | 
| I like to eat peanutbutter for breakfast| I like to play football | not_equivalent | 


### How to configure T5 task for MRPC and pre-process text
`.setTask('mrpc sentence1:)` and prefix second sentence with `sentence2:`

### Example pre-processed input for T5 MRPC - Binary Paraphrasing/ sentence similarity

```
mrpc 
sentence1: We acted because we saw the existing evidence in a new light , through the prism of our experience on 11 September , "" Rumsfeld said . 
sentence2: Rather , the US acted because the administration saw "" existing evidence in a new light , through the prism of our experience on September 11"",
```



## Regressive Sentence similarity/ Paraphrasing

Measures how similar two sentences are on a scale from 0 to 5 with 21 classes representing a regressive label.     
This is a sub-task of [GLUE](https://arxiv.org/pdf/1804.07461.pdf) and based on[STSB - Regressive semantic sentence similarity](https://www.aclweb.org/anthology/S17-2001/) .

```python
t5 = nlu.load('en.t5.base')
# Set the task on T5
t5['t5'].setTask('stsb ') 

# define Data, add additional tags between sentences
data = [
             
              ''' sentence1:  What attributes would have made you highly desirable in ancient Rome?  
                  sentence2:  How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER?'
              '''
             ,
             '''  
              sentence1: What was it like in Ancient rome?
              sentence2: 	What was Ancient rome like?
              ''',
              '''  
              sentence1: What was live like as a King in Ancient Rome??
              sentence2: 	What was Ancient rome like?
              '''

             ]



#Predict on text data with T5
t5.predict(data)

```

| sentence1 | sentence2 | prediction|
|------------|------------|----------|
|What attributes would have made you highly desirable in ancient Rome?        | How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER? | 0 | 
|What was it like in Ancient rome?  | What was Ancient rome like?| 5.0 | 
|What was live like as a King in Ancient Rome??       | What is it like to live in Rome? | 3.2 | 


### How to configure T5 task for stsb and pre-process text
`.setTask('stsb sentence1:)` and prefix second sentence with `sentence2:`




### Example pre-processed input for T5 STSB - Regressive semantic sentence similarity

```
stsb
sentence1: What attributes would have made you highly desirable in ancient Rome?        
sentence2: How I GET OPPERTINUTY TO JOIN IT COMPANY AS A FRESHER?',
```





## Grammar Checking
[Grammar checking with T5 example](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_tasks_summarize_question_answering_and_more)
Judges if a sentence is grammatically acceptable.    
Based on [CoLA - Binary Grammatical Sentence acceptability classification](https://nyu-mll.github.io/CoLA/)

```python
pipe = nlu.load('grammar_correctness')
# Set the task on T5
pipe['t5'].setTask('cola sentence: ')
# define Data
data = ['Anna and Mike is going skiing and they is liked is','Anna and Mike like to dance']
#Predict on text data with T5
pipe.predict(data)
```
|sentence  | prediction|
|------------|------------|
| Anna and Mike is going skiing and they is liked is | unacceptable |      
| Anna and Mike like to dance | acceptable | 


## Document Normalization
[Document Normalizer example](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/text_pre_processing_and_cleaning/document_normalizer_demo.ipynb)     
The DocumentNormalizer extracts content from HTML or XML documents, applying either data cleansing using an arbitrary number of custom regular expressions either data extraction following the different parameters

```python
pipe = nlu.load('norm_document')
data = '&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is an example of a simple HTML page with one paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt;'
df = pipe.predict(data,output_level='document')
df
```
|text|normalized_text|
|------|-------------|
| `&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Example&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;This is an example of a simple HTML page with one paragraph.&lt;/p&gt; &lt;/body&gt; &lt;/html&gt;`       |Example This is an example of a simple HTML page with one paragraph.|

## Word Segmenter
[Word Segmenter Example](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/multilingual/japanese_ner_pos_and_tokenization.ipynb)     
The WordSegmenter segments languages without any rule-based tokenization such as Chinese, Japanese, or Korean
```python
pipe = nlu.load('ja.segment_words')
# japanese for 'Donald Trump and Angela Merkel dont share many opinions'
ja_data = ['ドナルド・トランプとアンゲラ・メルケルは多くの意見を共有していません']
df = pipe.predict(ja_data, output_level='token')
df

```

|	token|
|--------|
|	ドナルド|
|	・|
|	トランプ|
|	と|
|	アンゲラ|
|	・|
|	メルケル|
|	は|
|	多く|
|	の|
|	意見|
|	を|
|	共有|
|	し|
|	て|
|	い|
|	ませ|
|	ん|


# Named Entity Extraction (NER) in Various Languages 
NLU now support NER for over 60 languages, including Korean, Japanese, Chinese and many more!   
```python

# Extract named chinese entities
pipe = nlu.load('zh.ner')
# Chinese for 'Donald Trump and Angela Merkel dont share many opinions'
zh_data = ['唐纳德特朗普和安吉拉·默克尔没有太多意见']
df = pipe.predict(zh_data, output_level='document')
df
&gt;&gt;&gt; Output : [唐纳德, 安吉拉]

# Now translate [唐纳德, 安吉拉] back to english with NLU!
translate_pipe = nlu.load('zh.translate_to.en')
en_entities = translate_pipe.predict(['唐纳德', '安吉拉'])
&gt;&gt;&gt; Output :
```
|Translation|	Chinese| 
|------|------|
|Donald | 唐纳德 |
|Angela | 	安吉拉|

# New NLU Notebooks


### NLU 1.1.0  New Notebooks for new features
- [Translate between 192+ languages with marian](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/translation_demo.ipynb)
- [Try out the 18 Tasks like Summarization Question Answering and more on T5](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_tasks_summarize_question_answering_and_more)
- [T5 Open and Closed Book question answering tutorial](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/sequence2sequence/T5_question_answering.ipynb)
- [Tokenize, extract POS and NER in Chinese](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/multilingual/chinese_ner_pos_and_tokenization.ipynb)
- [Tokenize, extract POS and NER in Korean](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/multilingual/korean_ner_pos_and_tokenization.ipynb)
- [Tokenize, extract POS and NER in Japanese](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/multilingual/japanese_ner_pos_and_tokenization.ipynb)
- [Normalize documents](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/text_pre_processing_and_cleaning/document_normalizer_demo.ipynb)
- [Aspect based sentiment NER sentiment for restaurants](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/named_entity_recognition_(NER)/aspect_based_ner_sentiment_restaurants.ipynb)

### NLU 1.1.0 New Classifier Training Tutorials
#### Binary Classifier training Jupyter tutorials
- [2 class Finance News sentiment classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/binary_text_classification/NLU_training_sentiment_classifier_demo_apple_twitter.ipynb)
- [2 class Reddit comment sentiment classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/binary_text_classification/NLU_training_sentiment_classifier_demo_reddit.ipynb)
- [2 class Apple Tweets sentiment classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/binary_text_classification/NLU_training_sentiment_classifier_demo_IMDB.ipynb)
- [2 class IMDB Movie sentiment classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/binary_text_classification/NLU_training_sentiment_classifier_demo_IMDB.ipynb)
- [2 class twitter classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/binary_text_classification/NLU_training_sentiment_classifier_demo_twitter.ipynb)

#### Multi Class text Classifier training Jupyter tutorials
- [5 class WineEnthusiast Wine review classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/multi_class_text_classification/NLU_training_multi_class_text_classifier_demo_wine.ipynb)
- [3 class Amazon Phone review classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/multi_class_text_classification/NLU_training_multi_class_text_classifier_demo_amazon.ipynb)
- [5 class Amazon Musical Instruments review classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/multi_class_text_classification/NLU_training_multi_class_text_classifier_demo_musical_instruments.ipynb)
- [5 class Tripadvisor Hotel review classifier training](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/Training/multi_class_text_classification/NLU_training_multi_class_text_classifier_demo_hotel_reviews.ipynb)



### NLU 1.1.0 New Medium Tutorials

- [1 line to Glove Word Embeddings with NLU     with t-SNE plots](https://medium.com/spark-nlp/1-line-to-glove-word-embeddings-with-nlu-in-python-baed152fff4d)
- [1 line to Xlnet Word Embeddings with NLU     with t-SNE plots](https://medium.com/spark-nlp/1-line-to-xlnet-word-embeddings-with-nlu-in-python-5efc57d7ac79)
- [1 line to AlBERT Word Embeddings with NLU    with t-SNE plots](https://medium.com/spark-nlp/1-line-to-albert-word-embeddings-with-nlu-in-python-1691bc048ed1)
- [1 line to CovidBERT Word Embeddings with NLU with t-SNE plots](https://medium.com/spark-nlp/1-line-to-covidbert-word-embeddings-with-nlu-in-python-e67396da2f78)
- [1 line to Electra Word Embeddings with NLU   with t-SNE plots](https://medium.com/spark-nlp/1-line-to-electra-word-embeddings-with-nlu-in-python-25f749bf3e92)
- [1 line to BioBERT Word Embeddings with NLU   with t-SNE plots](https://medium.com/spark-nlp/1-line-to-biobert-word-embeddings-with-nlu-in-python-7224ab52e131)



## Installation

```bash
# PyPi
!pip install nlu pyspark==2.4.7
#Conda
# Install NLU from Anaconda/Conda
conda install -c johnsnowlabs nlu
```


# Additional NLU ressources
- [NLU Website](https://nlu.johnsnowlabs.com/)
- [All NLU Tutorial Notebooks](https://nlu.johnsnowlabs.com/docs/en/notebooks)
- [NLU Videos and Blogposts on NLU](https://nlp.johnsnowlabs.com/learn#pythons-nlu-library)
- [NLU on Github](https://github.com/JohnSnowLabs/nlu)",28997
871,871,New to NLP; Seeking guidance on current project,"Hello, I am conducting research to identify ""improvisations"" within the healthcare system as a response to COVID (e.g scuba masks in place of normal face masks). I am doing this by analyzing text data of thousands articles taken from various news apis.

What I have done so far: 

1. familiarized myself with concepts (bag of words, word2vec, tfidf)
2. created a testing and training set (testing set I have created a binary field indicating whether or not the article is the type of article I am looking for)
3. familiarized myself with preprocessing (cleaning the data)

This is my first real exposure to NLP and I really fell in love with what I have seen so far. But as with every new thing, there is of course a lot of unknowns. 

I am looking to see if anyone can give me pointers on how to proceed. I thought about summarizing the articles (reduces dimensions of vector for BoW) then using Bag of words to train a model. Not sure if there is a different and better approach. All comments/critiques/criticisms are welcome and help would be most appreciated :)",https://www.reddit.com/r/LanguageTechnology/comments/l4g58w/new_to_nlp_seeking_guidance_on_current_project/,LanguageTechnology,t3_l4g58w,"New to NLP; Seeking guidance on current project Hello, I am conducting research to identify ""improvisations"" within the healthcare system as a response to COVID (e.g scuba masks in place of normal face masks). I am doing this by analyzing text data of thousands articles taken from various news apis.

What I have done so far: 

1. familiarized myself with concepts (bag of words, word2vec, tfidf)
2. created a testing and training set (testing set I have created a binary field indicating whether or not the article is the type of article I am looking for)
3. familiarized myself with preprocessing (cleaning the data)

This is my first real exposure to NLP and I really fell in love with what I have seen so far. But as with every new thing, there is of course a lot of unknowns. 

I am looking to see if anyone can give me pointers on how to proceed. I thought about summarizing the articles (reduces dimensions of vector for BoW) then using Bag of words to train a model. Not sure if there is a different and better approach. All comments/critiques/criticisms are welcome and help would be most appreciated :)",1113
872,872,PhD internship in NLP at industrial research venue,"Hi NLP community,

I am a second-year PhD student in Computer Science at a prestigious university in Europe (&lt;100 ranking). 
I would want to start planning for a PhD internship at a research institute/industry in 2022/3. However, I am not too sure how to proceed with the process and what are typical requirements. Specifically, I work on the intersection of Structured Prediction and Bayesian Deep Learning, think deriving uncertainty for Named Entity Recognition. In my first year, I published a workshop paper at ICML and a large journal paper at JMLR.

For example, imagine I target one of the FAANG companies, what would they at least expect me to have done, e.g., publish at top ML conferences (ACL, NeurIPS, ICML, ICLR,...)? How can I increase my chances? Can someone maybe share their experiences on this? 

I appreciate your time in replying, cheers!",https://www.reddit.com/r/LanguageTechnology/comments/l46o5j/phd_internship_in_nlp_at_industrial_research_venue/,LanguageTechnology,t3_l46o5j,"PhD internship in NLP at industrial research venue Hi NLP community,

I am a second-year PhD student in Computer Science at a prestigious university in Europe (&lt;100 ranking). 
I would want to start planning for a PhD internship at a research institute/industry in 2022/3. However, I am not too sure how to proceed with the process and what are typical requirements. Specifically, I work on the intersection of Structured Prediction and Bayesian Deep Learning, think deriving uncertainty for Named Entity Recognition. In my first year, I published a workshop paper at ICML and a large journal paper at JMLR.

For example, imagine I target one of the FAANG companies, what would they at least expect me to have done, e.g., publish at top ML conferences (ACL, NeurIPS, ICML, ICLR,...)? How can I increase my chances? Can someone maybe share their experiences on this? 

I appreciate your time in replying, cheers!",913
873,873,Is there a model for comparing the relevance a piece of text to the GPT-2 model's fine tuning data?,"I have a couple of GPT-2-backed reddit chatbots (on r/SubSimGPT2Interactive ) that reply to other humans and bots based on random probability. GPT-2 has a pretty broad corpus so it works quite well, generally, except for GPT-2 losing the context as it's well known to do. 

Perhaps choosing which comments to reply to more carefully would help maintain context and in turn keep the bots replying to replies that are closely related to their training material, or 'on-brand' if you want to call it that!

When there is a potential reply, I would like to compare the incoming comment (which is only a few hundred to a thousand characters at most) to the bot's fine tuning material (a 10-30Mb text file) and be able to get some kind of relevance value and if it is over a particular threshold, generate a reply.

Is there some way that I can use a second ML model, or the GPT-2 model itself, to calculate such a relevance value?

Any different ideas appreciated, too! 

Cheers",https://www.reddit.com/r/LanguageTechnology/comments/l4fq8y/is_there_a_model_for_comparing_the_relevance_a/,LanguageTechnology,t3_l4fq8y,"Is there a model for comparing the relevance a piece of text to the GPT-2 model's fine tuning data? I have a couple of GPT-2-backed reddit chatbots (on r/SubSimGPT2Interactive ) that reply to other humans and bots based on random probability. GPT-2 has a pretty broad corpus so it works quite well, generally, except for GPT-2 losing the context as it's well known to do. 

Perhaps choosing which comments to reply to more carefully would help maintain context and in turn keep the bots replying to replies that are closely related to their training material, or 'on-brand' if you want to call it that!

When there is a potential reply, I would like to compare the incoming comment (which is only a few hundred to a thousand characters at most) to the bot's fine tuning material (a 10-30Mb text file) and be able to get some kind of relevance value and if it is over a particular threshold, generate a reply.

Is there some way that I can use a second ML model, or the GPT-2 model itself, to calculate such a relevance value?

Any different ideas appreciated, too! 

Cheers",1073
874,874,Language Understanding with Knowledge-based Embeddings (LUKE) | Research Papers Summary 005,,https://youtu.be/oho-i5Ws07g,LanguageTechnology,t3_l455uw,Language Understanding with Knowledge-based Embeddings (LUKE) | Research Papers Summary 005 ,92
875,875,Erasmus Mundus MSc LCT Questions,"Hi, everyone!

I'm applying to the LCT MSc for Fall 2021, and I would really like your opinions on the best combination of universities to take. 

Background: I'm a Computer Science student with experience in NLP at a foundational level. I have done projects using ML and Deep Learning as well. My linguistics background is not very strong, but I would like to learn more about it.

Requirements: I have already settled on Saarland for one of the universities. I would probably choose it for Year 2. For Year 1, I am focusing on Lorraine, Groningen or Trento. I have some rudimentary knowledge of French. I would like to study at a uni that has good research opportunities, with connections to applying NLP to the humanities, if possible. I realize the LCT programme is a bit disconnected, but which of these three unis would have a better transitory experience? I would also prefer that the classes be taught by profs with a good level of competency in English. Since I aim to work in industry research or at a research institute post this masters, ideally a university with a good CS programme would help, hence the reason for Saarland. As for the other, I am open to a more linguistics focused background, but having relevant options that can tie in with my focus area.

&amp;#x200B;

I would also like a ranking based on living environment - things to do, how expensive it is, how complicated the document processes are, how likely it is to find English speakers in the area, conveniences, food, relative ease of finding accommodation. 

&amp;#x200B;

Your help would be greatly appreciated, Reddit community. I will be cross-posting this on r/CompLing too.",https://www.reddit.com/r/LanguageTechnology/comments/l3yfcv/erasmus_mundus_msc_lct_questions/,LanguageTechnology,t3_l3yfcv,"Erasmus Mundus MSc LCT Questions Hi, everyone!

I'm applying to the LCT MSc for Fall 2021, and I would really like your opinions on the best combination of universities to take. 

Background: I'm a Computer Science student with experience in NLP at a foundational level. I have done projects using ML and Deep Learning as well. My linguistics background is not very strong, but I would like to learn more about it.

Requirements: I have already settled on Saarland for one of the universities. I would probably choose it for Year 2. For Year 1, I am focusing on Lorraine, Groningen or Trento. I have some rudimentary knowledge of French. I would like to study at a uni that has good research opportunities, with connections to applying NLP to the humanities, if possible. I realize the LCT programme is a bit disconnected, but which of these three unis would have a better transitory experience? I would also prefer that the classes be taught by profs with a good level of competency in English. Since I aim to work in industry research or at a research institute post this masters, ideally a university with a good CS programme would help, hence the reason for Saarland. As for the other, I am open to a more linguistics focused background, but having relevant options that can tie in with my focus area.

&amp;#x200B;

I would also like a ranking based on living environment - things to do, how expensive it is, how complicated the document processes are, how likely it is to find English speakers in the area, conveniences, food, relative ease of finding accommodation. 

&amp;#x200B;

Your help would be greatly appreciated, Reddit community. I will be cross-posting this on r/CompLing too.",1694
876,876,The Language Interpretability Tool (LIT): Interactive Exploration and Analysis of NLP Models - Google AI,,http://ai.googleblog.com/2020/11/the-language-interpretability-tool-lit.html,LanguageTechnology,t3_l39nfv,The Language Interpretability Tool (LIT): Interactive Exploration and Analysis of NLP Models - Google AI ,105
877,877,DialoGPT Paper Walkthrough,"This paper from Microsoft presents a large, tunable neural conversational response generation model, DialoGPT (dialogue generative pre-trained transformer) model trained on 147M conversation-like exchanges extracted from Reddit comments. 

Researchers show that the conversational systems that leverage DialoGPT generate more relevant, contentful, and context-consistent responses than strong baseline systems.

Paper Walkthrough: https://youtu.be/Zo679MYoJns

Paper: ⏩ Paper: https://www.aclweb.org/anthology/2020.acl-demos.30.pdf",https://www.reddit.com/r/LanguageTechnology/comments/l3b856/dialogpt_paper_walkthrough/,LanguageTechnology,t3_l3b856,"DialoGPT Paper Walkthrough This paper from Microsoft presents a large, tunable neural conversational response generation model, DialoGPT (dialogue generative pre-trained transformer) model trained on 147M conversation-like exchanges extracted from Reddit comments. 

Researchers show that the conversational systems that leverage DialoGPT generate more relevant, contentful, and context-consistent responses than strong baseline systems.

Paper Walkthrough: https://youtu.be/Zo679MYoJns

Paper: ⏩ Paper: https://www.aclweb.org/anthology/2020.acl-demos.30.pdf",558
878,878,What We Found Analyzing 300 Yelp Reviews of a Michelin Reviewed Restaurant with Natural Language Processing,,https://blog.diffbot.com/what-we-found-analyzing-300-yelp-reviews-of-a-michelin-reviewed-restaurant-with-natural-language-processing/,LanguageTechnology,t3_l2y43q,What We Found Analyzing 300 Yelp Reviews of a Michelin Reviewed Restaurant with Natural Language Processing ,108
879,879,What exists in the way of open source machine translation?,"In particular, is there any rule-based system that does a deeper analysis than Apertium? I'm interested in making a translator that attempts to preserve the meter and rhyme scheme of verse.",https://www.reddit.com/r/LanguageTechnology/comments/l3133x/what_exists_in_the_way_of_open_source_machine/,LanguageTechnology,t3_l3133x,"What exists in the way of open source machine translation? In particular, is there any rule-based system that does a deeper analysis than Apertium? I'm interested in making a translator that attempts to preserve the meter and rhyme scheme of verse.",248
880,880,AI that generates rap lyrics (Open-Source + Live Demo),"I built an AI that generates rap music lyrics using TensorFlow and Keras actually posted this project a while ago but since then lots of improvements have done also at that time servers are not capable of running the tf model. you can check the website(live demo you can give it a seed and I generates rap based on the seed) and the GitHub repos all links down below if you star or fork the repo I would be so happy thanks.

Github: [https://github.com/YigitGunduc/Spectrum](https://github.com/YigitGunduc/Spectrum)

Website: [https://spectrumapp.herokuapp.com/](https://spectrumapp.herokuapp.com/)",https://www.reddit.com/r/LanguageTechnology/comments/l2qk95/ai_that_generates_rap_lyrics_opensource_live_demo/,LanguageTechnology,t3_l2qk95,"AI that generates rap lyrics (Open-Source + Live Demo) I built an AI that generates rap music lyrics using TensorFlow and Keras actually posted this project a while ago but since then lots of improvements have done also at that time servers are not capable of running the tf model. you can check the website(live demo you can give it a seed and I generates rap based on the seed) and the GitHub repos all links down below if you star or fork the repo I would be so happy thanks.

Github: [https://github.com/YigitGunduc/Spectrum](https://github.com/YigitGunduc/Spectrum)

Website: [https://spectrumapp.herokuapp.com/](https://spectrumapp.herokuapp.com/)",653
881,881,"Announcing DeepPavlov Community Call #5 - January 28, 8am PDT","Hi, I'm a CPO of DeepPavlov, an R&amp;D lab that builds a popular open-source NLP &amp; Conversational AI library also called DeepPavlov. It was born in February 2018, has lots of different state-of-the-art and demo NLP components. 

In addition to our dear users it has been battletested in our Socialbot in Amazon Alexa Prize 3, and it is now used in our Socialbot in Amazon Alexa Prize 4.

This January we've started work on refactoring the DeepPavlov Library on it's path to v1.0.  

I want to welcome you to join our DeepPavlov Community Call #5 to learn more next week on Jan 28 at 7pm MSK/8am PDT.  

Here's the link: [https://bit.ly/DPCommunityCall5](https://bit.ly/DPCommunityCall5) 

We are also interested in your feedback. Let us know what you want from DeepPavlov: 

[https://bit.ly/DPLibrary2021Survey](https://bit.ly/DPLibrary2021Survey)

See you next week!",https://www.reddit.com/r/LanguageTechnology/comments/l2nnaa/announcing_deeppavlov_community_call_5_january_28/,LanguageTechnology,t3_l2nnaa,"Announcing DeepPavlov Community Call #5 - January 28, 8am PDT Hi, I'm a CPO of DeepPavlov, an R&amp;D lab that builds a popular open-source NLP &amp; Conversational AI library also called DeepPavlov. It was born in February 2018, has lots of different state-of-the-art and demo NLP components. 

In addition to our dear users it has been battletested in our Socialbot in Amazon Alexa Prize 3, and it is now used in our Socialbot in Amazon Alexa Prize 4.

This January we've started work on refactoring the DeepPavlov Library on it's path to v1.0.  

I want to welcome you to join our DeepPavlov Community Call #5 to learn more next week on Jan 28 at 7pm MSK/8am PDT.  

Here's the link: [https://bit.ly/DPCommunityCall5](https://bit.ly/DPCommunityCall5) 

We are also interested in your feedback. Let us know what you want from DeepPavlov: 

[https://bit.ly/DPLibrary2021Survey](https://bit.ly/DPLibrary2021Survey)

See you next week!",934
882,882,Linguistics Reading List for NLP,"Hi all,

What reading in linguistics would you recommend to someone entering NLP without much of a linguistics background? 

My background: graduated with double BA in International Studies and Japanese a few years ago. Became interested in linguistics at the end of my BA and took a couple lower level courses. I’m currently finishing prerequisites in stats, math, and CS and am applying to data science MS programs with the hope of concentrating on NLP—I originally wanted to apply to computational linguistics programs but am opting for data science for a few reasons. 

I see people argue back and forth for days about whether linguistic knowledge is helpful at all for for NLP. For those of you who think it is worthwhile, what reading would you recommend?",https://www.reddit.com/r/LanguageTechnology/comments/l28pwj/linguistics_reading_list_for_nlp/,LanguageTechnology,t3_l28pwj,"Linguistics Reading List for NLP Hi all,

What reading in linguistics would you recommend to someone entering NLP without much of a linguistics background? 

My background: graduated with double BA in International Studies and Japanese a few years ago. Became interested in linguistics at the end of my BA and took a couple lower level courses. I’m currently finishing prerequisites in stats, math, and CS and am applying to data science MS programs with the hope of concentrating on NLP—I originally wanted to apply to computational linguistics programs but am opting for data science for a few reasons. 

I see people argue back and forth for days about whether linguistic knowledge is helpful at all for for NLP. For those of you who think it is worthwhile, what reading would you recommend?",794
883,883,How to cluster documents using Word2vec and K-means,,https://dylancastillo.co/nlp-snippets-cluster-documents-using-word2vec/,LanguageTechnology,t3_l2oeyk,How to cluster documents using Word2vec and K-means ,52
884,884,Does anyone know of a certificate program affiliated with a University that teaches NLP?,I want to learn from a live instructor instead of a coursera class. I am ok with it being online. I just want something where I can ask a instructor questions right away.,https://www.reddit.com/r/LanguageTechnology/comments/l2ggir/does_anyone_know_of_a_certificate_program/,LanguageTechnology,t3_l2ggir,Does anyone know of a certificate program affiliated with a University that teaches NLP? I want to learn from a live instructor instead of a coursera class. I am ok with it being online. I just want something where I can ask a instructor questions right away.,259
885,885,From document library to corpus for training BERT,"Hello. I would like to attempt extending BERT with my own small corpus of technical documents. They include lots of tables, figures, bulleted lists, mixed in footnotes, and other relics that aren’t always part of my domains natural language discourse. Some may even be riddled with errors from being generated from OCRing pdfs (let’s say about 2% of them)

What’s the optimal way to clean up a big pile of garbage like this to improve my attempt to train a language model?",https://www.reddit.com/r/LanguageTechnology/comments/l23e2v/from_document_library_to_corpus_for_training_bert/,LanguageTechnology,t3_l23e2v,"From document library to corpus for training BERT Hello. I would like to attempt extending BERT with my own small corpus of technical documents. They include lots of tables, figures, bulleted lists, mixed in footnotes, and other relics that aren’t always part of my domains natural language discourse. Some may even be riddled with errors from being generated from OCRing pdfs (let’s say about 2% of them)

What’s the optimal way to clean up a big pile of garbage like this to improve my attempt to train a language model?",522
886,886,withdraw from naacl submit to acl,"Is it okay to withdraw from naacl submit to acl, looks like my reviewers are being unprofessional, and my paper also has some changes. But I am submiting to the same venue. Would that be ok?",https://www.reddit.com/r/LanguageTechnology/comments/l20ggf/withdraw_from_naacl_submit_to_acl/,LanguageTechnology,t3_l20ggf,"withdraw from naacl submit to acl Is it okay to withdraw from naacl submit to acl, looks like my reviewers are being unprofessional, and my paper also has some changes. But I am submiting to the same venue. Would that be ok?",224
887,887,Which cloud storage provider for uploading scraped data and analyzing it later on using DL and ML.,"I have a project of multiple web scrapers running, all fetching text data from online. Once I've collected enough data to draw conclusions from it, I would like to analyse the text data (NLP, ML, DL). The scrapers are currently running on a VPS and storing the scraped text data in a local database.

Since the VPS is not strong enough for high performance NLP, I'm thinking about outsourcing the storing- and analysis-part to another provider. But I'm completely overwhelmed by the endless amounts of providers and their rather abstract descriptions of what they provide.

Are there good and cheap (free?) solutions that allow for uploading and storing data (approx. 1MB per upload) in regular intervals (1 upload per minute) and analyzing that data (preferably python; nltk, tensorflow, scikit etc.)? They can be different providers, but I prefer everything in one household.",https://www.reddit.com/r/LanguageTechnology/comments/l29131/which_cloud_storage_provider_for_uploading/,LanguageTechnology,t3_l29131,"Which cloud storage provider for uploading scraped data and analyzing it later on using DL and ML. I have a project of multiple web scrapers running, all fetching text data from online. Once I've collected enough data to draw conclusions from it, I would like to analyse the text data (NLP, ML, DL). The scrapers are currently running on a VPS and storing the scraped text data in a local database.

Since the VPS is not strong enough for high performance NLP, I'm thinking about outsourcing the storing- and analysis-part to another provider. But I'm completely overwhelmed by the endless amounts of providers and their rather abstract descriptions of what they provide.

Are there good and cheap (free?) solutions that allow for uploading and storing data (approx. 1MB per upload) in regular intervals (1 upload per minute) and analyzing that data (preferably python; nltk, tensorflow, scikit etc.)? They can be different providers, but I prefer everything in one household.",976
888,888,Meaning of Regex [^.]*+,"Hi, I found a document which uses the formula VerbRoot[^.]*+  , I think it's for finding all the forms in which the verb can appear. But I don't really understand how the formula works, or if It's OK

Hope someone can help me! Thanks in advance!",https://www.reddit.com/r/LanguageTechnology/comments/l1we2w/meaning_of_regex/,LanguageTechnology,t3_l1we2w,"Meaning of Regex [^.]*+ Hi, I found a document which uses the formula VerbRoot[^.]*+  , I think it's for finding all the forms in which the verb can appear. But I don't really understand how the formula works, or if It's OK

Hope someone can help me! Thanks in advance!",269
889,889,Composable Named Entities in Apache NLPCraft,,http://nlpcraft.apache.org/blogs/composable_named_entities.html,LanguageTechnology,t3_l1to78,Composable Named Entities in Apache NLPCraft ,45
890,890,Looking for an automatic text summarization method for academic papers,"Loads of works have been published on automatic summarization in general, and also for summarizing academic papers - it's quite easy to get lost in the literature and start implementing things that do not end up being the right methods. 

I am trying to implement an academic paper summarizer - so going from the full paper to abstract-like sized summary. I would be looking to use abstractive methods, or potentially hybrid solutions (extractive + abstractive). 

Does anyone have experience with a specific paper or method that they recommend for this task? ++ &lt;3 if the paper comes with code 

PS: Honestly, I hope that in the near future, all researchers publishing this kind of work will \*always\* publish code with it. I find it unacceptable that such works are most often without code linked to it.",https://www.reddit.com/r/LanguageTechnology/comments/l1g24c/looking_for_an_automatic_text_summarization/,LanguageTechnology,t3_l1g24c,"Looking for an automatic text summarization method for academic papers Loads of works have been published on automatic summarization in general, and also for summarizing academic papers - it's quite easy to get lost in the literature and start implementing things that do not end up being the right methods. 

I am trying to implement an academic paper summarizer - so going from the full paper to abstract-like sized summary. I would be looking to use abstractive methods, or potentially hybrid solutions (extractive + abstractive). 

Does anyone have experience with a specific paper or method that they recommend for this task? ++ &lt;3 if the paper comes with code 

PS: Honestly, I hope that in the near future, all researchers publishing this kind of work will \*always\* publish code with it. I find it unacceptable that such works are most often without code linked to it.",880
891,891,How to introduce named entities into clustering?,"Hello there.

If I get some embeddings (e.g. Bert based ones) for some article headlines corpus and run some clustering algorithm, the articles about e.g. crime get (understandably) clustered together, but I’d like to cluster by news story/event instead, so I think named entities are the key for this.

When using a more traditional TF-IDF approach I’ve seen people boosting the weight of the words representing named entities, but with sentence embeddings I don’t think that’s possible.

I found some approach in a paper that works reasonably well but I wonder what people are doing about this?",https://www.reddit.com/r/LanguageTechnology/comments/l14xga/how_to_introduce_named_entities_into_clustering/,LanguageTechnology,t3_l14xga,"How to introduce named entities into clustering? Hello there.

If I get some embeddings (e.g. Bert based ones) for some article headlines corpus and run some clustering algorithm, the articles about e.g. crime get (understandably) clustered together, but I’d like to cluster by news story/event instead, so I think named entities are the key for this.

When using a more traditional TF-IDF approach I’ve seen people boosting the weight of the words representing named entities, but with sentence embeddings I don’t think that’s possible.

I found some approach in a paper that works reasonably well but I wonder what people are doing about this?",645
892,892,The field of natural language processing is chasing the wrong goal,,https://www.technologyreview.com/2020/07/31/1005876/natural-language-processing-evaluation-ai-opinion/,LanguageTechnology,t3_l0wbu2,The field of natural language processing is chasing the wrong goal ,67
893,893,[R] Finding The Words To Say: Hidden State Visualizations For Language Models,,/r/MachineLearning/comments/l0jiy0/r_finding_the_words_to_say_hidden_state/,LanguageTechnology,t3_l0jjuj,[R] Finding The Words To Say: Hidden State Visualizations For Language Models ,78
894,894,GPT-2,How can I use GPT-2 to teach a model how to summarize a piece of random text?,https://www.reddit.com/r/LanguageTechnology/comments/l0q8gk/gpt2/,LanguageTechnology,t3_l0q8gk,GPT-2 How can I use GPT-2 to teach a model how to summarize a piece of random text?,83
895,895,Google AI Introduces ToTTo: A Controlled Table-to-Text Generation Dataset Using Novel Annotation Process,"**The rising field of natural-language generation**

Research in natural language generation (NLG), a subset of artificial intelligence, is rising. [NLG](https://en.wikipedia.org/wiki/Natural-language_generation) is a software process that changes structured data into natural language. Not to be confused with natural language processing (NLP), NLG synthesizes and writes new content, whereas NLP reads and derives analytic insights from content ([Gartner](https://www.gartner.com/en/documents/3388326)).  

* Natural language generation (NLG) creates (or generates) text. It is when computers write language, turning structured data into text.
* Natural language processing (NLP) reads (or processes) text. It is when computers read language and derive insights.

Read Full Summary: [https://www.marktechpost.com/2021/01/18/google-ai-introduces-totto-a-controlled-table-to-text-generation-dataset-using-novel-annotation-process/](https://www.marktechpost.com/2021/01/18/google-ai-introduces-totto-a-controlled-table-to-text-generation-dataset-using-novel-annotation-process/)

Paper: [https://arxiv.org/abs/2004.14373](https://arxiv.org/abs/2004.14373)

GitHub: [https://github.com/google-research-datasets/totto](https://github.com/google-research-datasets/totto)",https://www.reddit.com/r/LanguageTechnology/comments/l0djzb/google_ai_introduces_totto_a_controlled/,LanguageTechnology,t3_l0djzb,"Google AI Introduces ToTTo: A Controlled Table-to-Text Generation Dataset Using Novel Annotation Process **The rising field of natural-language generation**

Research in natural language generation (NLG), a subset of artificial intelligence, is rising. [NLG](https://en.wikipedia.org/wiki/Natural-language_generation) is a software process that changes structured data into natural language. Not to be confused with natural language processing (NLP), NLG synthesizes and writes new content, whereas NLP reads and derives analytic insights from content ([Gartner](https://www.gartner.com/en/documents/3388326)).  

* Natural language generation (NLG) creates (or generates) text. It is when computers write language, turning structured data into text.
* Natural language processing (NLP) reads (or processes) text. It is when computers read language and derive insights.

Read Full Summary: [https://www.marktechpost.com/2021/01/18/google-ai-introduces-totto-a-controlled-table-to-text-generation-dataset-using-novel-annotation-process/](https://www.marktechpost.com/2021/01/18/google-ai-introduces-totto-a-controlled-table-to-text-generation-dataset-using-novel-annotation-process/)

Paper: [https://arxiv.org/abs/2004.14373](https://arxiv.org/abs/2004.14373)

GitHub: [https://github.com/google-research-datasets/totto](https://github.com/google-research-datasets/totto)",1371
896,896,[Q] Tips/tricks for dataset synthesis?,"I imagine this is an incredibly common problem to other NLP practitioners, but I find that anytime I need to work on some sort of sequence-sequence model, there is always a shortage of cleaned, tagged data. (For classification tasks, this problem isn't nearly as much of an issue.) And so, my go to is typically using some combination of SpaCy POS tagging, HuggingFace  NER, regular expressions, and rule based logic. In particular, I like that SpaCy will not just tag the parts of speech but also use dynamic programming to find noun phrases that you can drill down on. This, in combination with rules and regex, usually allows me to find the tokens of interest, label them accordingly, save to disk/db, then model using Keras, PyTorch, etc. (which is much more streamlined for a single task.) 

One example: I was trying to extract ""excitors"" and ""aggravators"" for a marketing-related NLP project. The idea was to take""long wait time"" or ""friendly service"" from Yelp reviews. I found using the above pseudo method, I was able to piece together raw documents and an array of tokens for NER modeling. 

My employers have never seemed inclined to spend on a 3rd party data tagging service (overseas or otherwise), though I do understand such a service exists.

Curious, how do others approach the all-familiar, ""I don't have nearly enough data"" conundrum?",https://www.reddit.com/r/LanguageTechnology/comments/l0n285/q_tipstricks_for_dataset_synthesis/,LanguageTechnology,t3_l0n285,"[Q] Tips/tricks for dataset synthesis? I imagine this is an incredibly common problem to other NLP practitioners, but I find that anytime I need to work on some sort of sequence-sequence model, there is always a shortage of cleaned, tagged data. (For classification tasks, this problem isn't nearly as much of an issue.) And so, my go to is typically using some combination of SpaCy POS tagging, HuggingFace  NER, regular expressions, and rule based logic. In particular, I like that SpaCy will not just tag the parts of speech but also use dynamic programming to find noun phrases that you can drill down on. This, in combination with rules and regex, usually allows me to find the tokens of interest, label them accordingly, save to disk/db, then model using Keras, PyTorch, etc. (which is much more streamlined for a single task.) 

One example: I was trying to extract ""excitors"" and ""aggravators"" for a marketing-related NLP project. The idea was to take""long wait time"" or ""friendly service"" from Yelp reviews. I found using the above pseudo method, I was able to piece together raw documents and an array of tokens for NER modeling. 

My employers have never seemed inclined to spend on a 3rd party data tagging service (overseas or otherwise), though I do understand such a service exists.

Curious, how do others approach the all-familiar, ""I don't have nearly enough data"" conundrum?",1393
897,897,"[R]: NAACL, reviews are out",when will the reviews of NAACL be out?,https://www.reddit.com/r/LanguageTechnology/comments/l0px0t/r_naacl_reviews_are_out/,LanguageTechnology,t3_l0px0t,"[R]: NAACL, reviews are out when will the reviews of NAACL be out?",66
898,898,Best approach for content recommendation,"This is my problem:

I have a set of essays or articles I know have been ""enjoyed"" by a user, but only have data on one user's preferences. Now, based on this how can I assess whether a new piece of content will suit the user or not?

It's some sort of classification issue but the problem is that most things I have been finding online go about this by looking at what other ""similar"" (as in like the same content) users have liked, and I can't really go that route here.

I'm a beginner, so this might be a stupid question but I'd love to learn.

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/l0otz9/best_approach_for_content_recommendation/,LanguageTechnology,t3_l0otz9,"Best approach for content recommendation This is my problem:

I have a set of essays or articles I know have been ""enjoyed"" by a user, but only have data on one user's preferences. Now, based on this how can I assess whether a new piece of content will suit the user or not?

It's some sort of classification issue but the problem is that most things I have been finding online go about this by looking at what other ""similar"" (as in like the same content) users have liked, and I can't really go that route here.

I'm a beginner, so this might be a stupid question but I'd love to learn.

Thanks!",597
899,899,Are there any companies putting NLP into ethical issues?,My question is inspired by this list [here](https://ethical.net/resources/?resource-category=ethical-tech-orgs). Do you know about any tech company that is putting NLP into ethical applications or at least care about it?,https://www.reddit.com/r/LanguageTechnology/comments/l0kd07/are_there_any_companies_putting_nlp_into_ethical/,LanguageTechnology,t3_l0kd07,Are there any companies putting NLP into ethical issues? My question is inspired by this list [here](https://ethical.net/resources/?resource-category=ethical-tech-orgs). Do you know about any tech company that is putting NLP into ethical applications or at least care about it?,277
900,900,I made NLPRule: A library for fast grammatical error correction,"[*Also posted on /r/ML*](https://www.reddit.com/r/MachineLearning/comments/kzuaie/p_i_made_nlprule_a_library_for_fast_grammatical/) *but this subreddit is more fitting :)*

&amp;#x200B;

Hi /r/LanguageTechnology!

I made NLPRule, a library for fast grammatical error correction in English and German by  checking thousands of rules. It is written in Rust and has bindings for Python.

Repository: [https://github.com/bminixhofer/nlprule](https://github.com/bminixhofer/nlprule)

**Synopsis**

    from nlprule import Tokenizer, Rules, SplitOn
    
    tokenizer = Tokenizer.load(""en"")
    rules = Rules.load(""en"", tokenizer, SplitOn([""."", ""?"", ""!""]))
    
    rules.correct(""He wants that you send him an email."")
    # returns: 'He wants you to send him an email.'
    
    rules.correct(""I can due his homework."")
    # returns: 'I can do his homework.'
    
    rules.correct(""It is enough for all intensive purposes."")
    # returns: 'It is enough for all intents and purposes.'
    
    
    suggestions = rules.suggest(""She was not been here since Monday."")
    for s in suggestions:
      print(s.start, s.end, s.replacements, s.source, s.message)
    # prints:
    # 4 16 ['was not', 'has not been'] WAS_BEEN.1 Did you mean was not or has not been?

**Background**

I've been interested in grammatical error correction for a while and came across [LanguageTool](https://github.com/languagetool-org/languagetool) which is based on [thousands of rules for error correction in an XML file](https://raw.githubusercontent.com/languagetool-org/languagetool/master/languagetool-language-modules/en/src/main/resources/org/languagetool/rules/en/grammar.xml).  You can think of the rule syntax as a restricted form of Regex where  the atoms are words annotated with lemmas, part-of-speech tags, and  chunks.

I'm not a big fan of Java,  wanted to improve my Rust and was interested in how these rules are  parsed so I made a proof of concept reverse-engineering the LanguageTool  logic in Rust. I had this lying around for quite some time and decided  to finish it up and make it into a usable library now during the  holidays.

**Relation to more sophisticated GEC approaches**

There's lots of research in using Neural Networks for Grammatical Error Correction and [there are some exciting recent approaches](https://github.com/grammarly/gector) which capture many more errors than a rule-based approach could. Still, for me there are two reasons to use rules:

1. **Speed.** On my machine with an 8th Gen Intel CPU it takes less than 1ms to correct a sentence.
2. **Dealing with extreme data sparsity of some errors.** The above example ""It is enough for all intensive purposes."" contains a [well known error](https://www.merriam-webster.com/words-at-play/usage-for-all-intensive-purposes-intents).  Yet, I would be surprised if a current ML model corrects this error  unless specifically accounted for since it will almost never have  appeared in its training data. This is even more true for similarly rare  errors in other languages where there is less data available than for  English. So I believe rules are especially useful in conjunction with a  more powerful ML model.

I think of NLPRule as a kind of ""sanity-check"" for text.

**Rule-based postprocessing for NLG**

Two  areas where NLPRule might be interesting are preprocessing for NLP and  postprocessing for NLG. I've tried the latter with texts generated from  GPT2. Applying NLPRule yields a significant amount of suggestions:

    Generated 192300 tokens.
    misspelling:    35 suggestions  (0.18 per 1000 tokens)
    style:          53 suggestions  (0.28 per 1000 tokens)
    typographical:  112 suggestions (0.58 per 1000 tokens)
    grammar:        29 suggestions  (0.15 per 1000 tokens)
    none:           3 suggestions   (0.02 per 1000 tokens)
    inconsistency:  2 suggestions   (0.01 per 1000 tokens)

Not all of these are errors, some are just suggestions for improvement. More information [here](https://github.com/bminixhofer/nlprule/tree/master/examples).

I'm happy to discuss anything in the  comments!",https://www.reddit.com/r/LanguageTechnology/comments/kzui94/i_made_nlprule_a_library_for_fast_grammatical/,LanguageTechnology,t3_kzui94,"I made NLPRule: A library for fast grammatical error correction [*Also posted on /r/ML*](https://www.reddit.com/r/MachineLearning/comments/kzuaie/p_i_made_nlprule_a_library_for_fast_grammatical/) *but this subreddit is more fitting :)*

&amp;#x200B;

Hi /r/LanguageTechnology!

I made NLPRule, a library for fast grammatical error correction in English and German by  checking thousands of rules. It is written in Rust and has bindings for Python.

Repository: [https://github.com/bminixhofer/nlprule](https://github.com/bminixhofer/nlprule)

**Synopsis**

    from nlprule import Tokenizer, Rules, SplitOn
    
    tokenizer = Tokenizer.load(""en"")
    rules = Rules.load(""en"", tokenizer, SplitOn([""."", ""?"", ""!""]))
    
    rules.correct(""He wants that you send him an email."")
    # returns: 'He wants you to send him an email.'
    
    rules.correct(""I can due his homework."")
    # returns: 'I can do his homework.'
    
    rules.correct(""It is enough for all intensive purposes."")
    # returns: 'It is enough for all intents and purposes.'
    
    
    suggestions = rules.suggest(""She was not been here since Monday."")
    for s in suggestions:
      print(s.start, s.end, s.replacements, s.source, s.message)
    # prints:
    # 4 16 ['was not', 'has not been'] WAS_BEEN.1 Did you mean was not or has not been?

**Background**

I've been interested in grammatical error correction for a while and came across [LanguageTool](https://github.com/languagetool-org/languagetool) which is based on [thousands of rules for error correction in an XML file](https://raw.githubusercontent.com/languagetool-org/languagetool/master/languagetool-language-modules/en/src/main/resources/org/languagetool/rules/en/grammar.xml).  You can think of the rule syntax as a restricted form of Regex where  the atoms are words annotated with lemmas, part-of-speech tags, and  chunks.

I'm not a big fan of Java,  wanted to improve my Rust and was interested in how these rules are  parsed so I made a proof of concept reverse-engineering the LanguageTool  logic in Rust. I had this lying around for quite some time and decided  to finish it up and make it into a usable library now during the  holidays.

**Relation to more sophisticated GEC approaches**

There's lots of research in using Neural Networks for Grammatical Error Correction and [there are some exciting recent approaches](https://github.com/grammarly/gector) which capture many more errors than a rule-based approach could. Still, for me there are two reasons to use rules:

1. **Speed.** On my machine with an 8th Gen Intel CPU it takes less than 1ms to correct a sentence.
2. **Dealing with extreme data sparsity of some errors.** The above example ""It is enough for all intensive purposes."" contains a [well known error](https://www.merriam-webster.com/words-at-play/usage-for-all-intensive-purposes-intents).  Yet, I would be surprised if a current ML model corrects this error  unless specifically accounted for since it will almost never have  appeared in its training data. This is even more true for similarly rare  errors in other languages where there is less data available than for  English. So I believe rules are especially useful in conjunction with a  more powerful ML model.

I think of NLPRule as a kind of ""sanity-check"" for text.

**Rule-based postprocessing for NLG**

Two  areas where NLPRule might be interesting are preprocessing for NLP and  postprocessing for NLG. I've tried the latter with texts generated from  GPT2. Applying NLPRule yields a significant amount of suggestions:

    Generated 192300 tokens.
    misspelling:    35 suggestions  (0.18 per 1000 tokens)
    style:          53 suggestions  (0.28 per 1000 tokens)
    typographical:  112 suggestions (0.58 per 1000 tokens)
    grammar:        29 suggestions  (0.15 per 1000 tokens)
    none:           3 suggestions   (0.02 per 1000 tokens)
    inconsistency:  2 suggestions   (0.01 per 1000 tokens)

Not all of these are errors, some are just suggestions for improvement. More information [here](https://github.com/bminixhofer/nlprule/tree/master/examples).

I'm happy to discuss anything in the  comments!",4149
901,901,Confused about whether I can add special tokens to a pretrained GPT-2 tokenizer,"I am using transformers/simpletransformers.

I have sifted through the transformers source code, but the loose inheritance it uses (where parameters are all defined at the base and not validated when they are inherited) makes it really hard to decipher what is possible. Some Github issues suggest it's possible to add tokens, some not.

Trial-and-error setting has just run me into more errors of arguments not set properly in simpletransformers, so I'm at the stage of trying to call the base tokenizer functions directly like so:

    lmm = LanguageModelingModel(""gpt2"", ""gpt2"", args=args)
    ## special_tokens is a list of strings
    lmm.tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})
    lmm.model.resize_token_embeddings(len(lmm.tokenizer)) 
    lmm.train_tokenizer(train_files=[training_file, eval_file])
    lmm.train_model(train_file=training_file, eval_file=eval_file, args=args, verbose=True)

Which fails with an unclear cuda error, unfortunately.

I am using special tokens to segment parts of conversational text. The model is used by a reddit chatbot.

Am I wasting my time trying to add special tokens?

Update: I seem to have it working by re-setting the vocab\_size argument with the updated value when calling train\_model. I'll find out soon whether there is any kind of improvement.",https://www.reddit.com/r/LanguageTechnology/comments/kzpwao/confused_about_whether_i_can_add_special_tokens/,LanguageTechnology,t3_kzpwao,"Confused about whether I can add special tokens to a pretrained GPT-2 tokenizer I am using transformers/simpletransformers.

I have sifted through the transformers source code, but the loose inheritance it uses (where parameters are all defined at the base and not validated when they are inherited) makes it really hard to decipher what is possible. Some Github issues suggest it's possible to add tokens, some not.

Trial-and-error setting has just run me into more errors of arguments not set properly in simpletransformers, so I'm at the stage of trying to call the base tokenizer functions directly like so:

    lmm = LanguageModelingModel(""gpt2"", ""gpt2"", args=args)
    ## special_tokens is a list of strings
    lmm.tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})
    lmm.model.resize_token_embeddings(len(lmm.tokenizer)) 
    lmm.train_tokenizer(train_files=[training_file, eval_file])
    lmm.train_model(train_file=training_file, eval_file=eval_file, args=args, verbose=True)

Which fails with an unclear cuda error, unfortunately.

I am using special tokens to segment parts of conversational text. The model is used by a reddit chatbot.

Am I wasting my time trying to add special tokens?

Update: I seem to have it working by re-setting the vocab\_size argument with the updated value when calling train\_model. I'll find out soon whether there is any kind of improvement.",1414
902,902,How to validate a dataset?,"I asked a team of data creators to generate a dataset for me to be used in implementing a dialect classification in the Arabic language for specific domains.  
Anyone know a way to validate this data.  
I thought of making an EDA listing the most important features like the distribution of the terms, number of unique words and somethings like that.  
Anyone knows any other features to validate the dataset that it's valuable, or know another way to do so !?",https://www.reddit.com/r/LanguageTechnology/comments/kztqzi/how_to_validate_a_dataset/,LanguageTechnology,t3_kztqzi,"How to validate a dataset? I asked a team of data creators to generate a dataset for me to be used in implementing a dialect classification in the Arabic language for specific domains.  
Anyone know a way to validate this data.  
I thought of making an EDA listing the most important features like the distribution of the terms, number of unique words and somethings like that.  
Anyone knows any other features to validate the dataset that it's valuable, or know another way to do so !?",487
903,903,Temporally-Informed Analysis of Named Entity Recognition | Research Papers Summary 004,,https://youtu.be/eEkVYgWj2aE,LanguageTechnology,t3_kzbkxj,Temporally-Informed Analysis of Named Entity Recognition | Research Papers Summary 004 ,87
904,904,Recommendations for extracting data,"Dear Reddit,

I'm trying to extract/scrape the following data at scale and was looking for recommendations from the community on the best approach. 

1. News articles from the web (*I've found 'news-please' works well. Are there others?* )
2. e-mail Newsletters
3. Arxiv papers   
4. Financial earnings call transcripts. 
5. Twitter posts (*I think the Twitter API might be the best approach*)
6. Instagram posts and comments

Ideally I'd prefer python libraries but I'm open to any tool that does the job. 

Thank You for your help",https://www.reddit.com/r/LanguageTechnology/comments/kzla5l/recommendations_for_extracting_data/,LanguageTechnology,t3_kzla5l,"Recommendations for extracting data Dear Reddit,

I'm trying to extract/scrape the following data at scale and was looking for recommendations from the community on the best approach. 

1. News articles from the web (*I've found 'news-please' works well. Are there others?* )
2. e-mail Newsletters
3. Arxiv papers   
4. Financial earnings call transcripts. 
5. Twitter posts (*I think the Twitter API might be the best approach*)
6. Instagram posts and comments

Ideally I'd prefer python libraries but I'm open to any tool that does the job. 

Thank You for your help",568
905,905,How to learn (more about) GPT-2,"Dear Reddit-Fam

I'm looking for resources about GPT-2 (for natural language generation), especially for training, fine-tuning (maybe in another language also). It seems like documentations or courses that go in-depth are very scarce at the moment (maybe/hopefully i'm false).

Greeeets",https://www.reddit.com/r/LanguageTechnology/comments/kz4d03/how_to_learn_more_about_gpt2/,LanguageTechnology,t3_kz4d03,"How to learn (more about) GPT-2 Dear Reddit-Fam

I'm looking for resources about GPT-2 (for natural language generation), especially for training, fine-tuning (maybe in another language also). It seems like documentations or courses that go in-depth are very scarce at the moment (maybe/hopefully i'm false).

Greeeets",318
906,906,How to make your NLP system multilingual,"So you have an NLP system - a chat bot, a search engine, NER, a classifier... - working well for English.

And you want to make it work for other languages, or maybe for all languages.

We see 3 basic approaches:

1. machine-translating at inference (or query) time
2. machine-translating labelled training data (or search indices), and training a multilingual model
3. zero-shot approaches with a multilingual LM like BERT or LASER

When to use which approach?

Machine-translating at inference time [2] is easiest to start with, but it's usually a bad idea.  It's the default at major US tech enterprises, from what I've seen, and even at really smart ML startups like Aylien.  And it's often suggested in this sub.

In Europe, where building a multilingual system is super important, we've even seen researchers *human-labelling* for every language, and ML startups *human-translating* labelled training data, or doing rules-based transliteration with *human post-editing*.

As a guy who thinks around the clock about machine translation risk and automation, all this unscalableness pains me to see.

So we have shared some open guides based on the work of our clients who implemented [multilingual search](https://www.reddit.com/r/LanguageTechnology/comments/k9ui4b/how_to_build_multilingual_search_with_translation/).

Nerses Nersesyan from Polixis and I will give a workshop on this at Applied Machine Learning Days in March.

https://appliedmldays.org/events/amld-epfl-2021/workshops/how-to-make-your-nlp-system-multilingual",https://www.reddit.com/r/LanguageTechnology/comments/kyjgb7/how_to_make_your_nlp_system_multilingual/,LanguageTechnology,t3_kyjgb7,"How to make your NLP system multilingual So you have an NLP system - a chat bot, a search engine, NER, a classifier... - working well for English.

And you want to make it work for other languages, or maybe for all languages.

We see 3 basic approaches:

1. machine-translating at inference (or query) time
2. machine-translating labelled training data (or search indices), and training a multilingual model
3. zero-shot approaches with a multilingual LM like BERT or LASER

When to use which approach?

Machine-translating at inference time [2] is easiest to start with, but it's usually a bad idea.  It's the default at major US tech enterprises, from what I've seen, and even at really smart ML startups like Aylien.  And it's often suggested in this sub.

In Europe, where building a multilingual system is super important, we've even seen researchers *human-labelling* for every language, and ML startups *human-translating* labelled training data, or doing rules-based transliteration with *human post-editing*.

As a guy who thinks around the clock about machine translation risk and automation, all this unscalableness pains me to see.

So we have shared some open guides based on the work of our clients who implemented [multilingual search](https://www.reddit.com/r/LanguageTechnology/comments/k9ui4b/how_to_build_multilingual_search_with_translation/).

Nerses Nersesyan from Polixis and I will give a workshop on this at Applied Machine Learning Days in March.

https://appliedmldays.org/events/amld-epfl-2021/workshops/how-to-make-your-nlp-system-multilingual",1572
907,907,"How would you analyze text message history from Facebook, WhatsApp, Wechat, etc.? How would grouping work?","So, when you get a conversation history, it'll be in the form of messages obviously. But messages aren't interpreted by people in the same way that they're stored.  People will consciously or unconsciously send multiple messages in a row for an overarching message.

If you were to try to analyze conversation chains though, this would make it harder to do LDA topic modelling, because the occurrences of words in a message are split up.  Another problem too, time gaps mean that sometimes a conversation will die, and the messaging following it will be part of a completely separate conversation. Othertimes, it might just be a while before someone gets back to you, or the conversation may be asynchronous due to conflicting schedules or something.

Another issue is revisiions.  


\*revisions.

How do you interpret revisions or clarifications in text?

Personally, I think these problems are too heavily in the area of computational pragmatics to be solvable, but surely there is something more that can be done than simply pretending the problem doesn't exist.

&amp;#x200B;

What would your solution/suggestion be?

Due to the lack of solutions in this area, I think nearly every suggestion that attempts to address any of these problems has merit.

&amp;#x200B;

Another thing too, do you think that this topic is publishable?  This is mostly a personal project for me, but if it comes out as something worthwhile, maybe I would put forth more effort into it for publication.",https://www.reddit.com/r/LanguageTechnology/comments/kyoxhs/how_would_you_analyze_text_message_history_from/,LanguageTechnology,t3_kyoxhs,"How would you analyze text message history from Facebook, WhatsApp, Wechat, etc.? How would grouping work? So, when you get a conversation history, it'll be in the form of messages obviously. But messages aren't interpreted by people in the same way that they're stored.  People will consciously or unconsciously send multiple messages in a row for an overarching message.

If you were to try to analyze conversation chains though, this would make it harder to do LDA topic modelling, because the occurrences of words in a message are split up.  Another problem too, time gaps mean that sometimes a conversation will die, and the messaging following it will be part of a completely separate conversation. Othertimes, it might just be a while before someone gets back to you, or the conversation may be asynchronous due to conflicting schedules or something.

Another issue is revisiions.  


\*revisions.

How do you interpret revisions or clarifications in text?

Personally, I think these problems are too heavily in the area of computational pragmatics to be solvable, but surely there is something more that can be done than simply pretending the problem doesn't exist.

&amp;#x200B;

What would your solution/suggestion be?

Due to the lack of solutions in this area, I think nearly every suggestion that attempts to address any of these problems has merit.

&amp;#x200B;

Another thing too, do you think that this topic is publishable?  This is mostly a personal project for me, but if it comes out as something worthwhile, maybe I would put forth more effort into it for publication.",1590
908,908,[p] Ecco – See what your NLP language model is “thinking”,,/r/MachineLearning/comments/kt33dp/p_ecco_see_what_your_nlp_language_model_is/,LanguageTechnology,t3_kyfkb7,[p] Ecco – See what your NLP language model is “thinking” ,58
909,909,What are non-english language missing in order to reach english-like NLP performances?,"Hi all,
I am currently working on some NLP tasks on Italian corpuses. I am noticing that, in general, Italian language models perform worse than their english siblings on similar tasks. I Indeed found several articles online raising the problem of low performance in non english NLP models.

So my question is: is this only a problem of low quality /small sized training datasets? Or is it something else? How would you address this problem if you had infinite ?money?

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/ky4hci/what_are_nonenglish_language_missing_in_order_to/,LanguageTechnology,t3_ky4hci,"What are non-english language missing in order to reach english-like NLP performances? Hi all,
I am currently working on some NLP tasks on Italian corpuses. I am noticing that, in general, Italian language models perform worse than their english siblings on similar tasks. I Indeed found several articles online raising the problem of low performance in non english NLP models.

So my question is: is this only a problem of low quality /small sized training datasets? Or is it something else? How would you address this problem if you had infinite ?money?

Thanks!",564
910,910,How to perform cosine similarity when taking into account the importance of the words as well.,"I have two documents or text data. Document 1 contains information like keywords with its own numeric number (which is the importance of the word):

    *gre (300)    india(290)    art(278)   galleries(257) ...*  

And another document that i have is the tf\*idf matrix. its the extracted keywords from single document with its tf\*idf score. (again, can be interpreted as the importance of the word).

    function   0.6781 art        0.2463 galleries  0.15655 . . ...  

so How do i compute similarities between these two document considering that the similarity between ""**art""** from document 1 and 2 should have higher score (higher similarity) because they are more important keywords as compared to the word ""**galleries""** from document 1 and 2 since they are less important keywords comparatively. How do i do this?",https://www.reddit.com/r/LanguageTechnology/comments/kycu60/how_to_perform_cosine_similarity_when_taking_into/,LanguageTechnology,t3_kycu60,"How to perform cosine similarity when taking into account the importance of the words as well. I have two documents or text data. Document 1 contains information like keywords with its own numeric number (which is the importance of the word):

    *gre (300)    india(290)    art(278)   galleries(257) ...*  

And another document that i have is the tf\*idf matrix. its the extracted keywords from single document with its tf\*idf score. (again, can be interpreted as the importance of the word).

    function   0.6781 art        0.2463 galleries  0.15655 . . ...  

so How do i compute similarities between these two document considering that the similarity between ""**art""** from document 1 and 2 should have higher score (higher similarity) because they are more important keywords as compared to the word ""**galleries""** from document 1 and 2 since they are less important keywords comparatively. How do i do this?",919
911,911,First NLP course. Seeking ideas for fun/interesting term project. (Interesting data? Hottest research?),"The headline pretty much says it all:

I'm taking my first NLP course and need some inspiration coming up with ideas for my term project. Broad strokes of the project requirements are to find a research paper involving a particular method or somesuch, and then to implement said somesuch and report various metrics on efficiency/f1/etc.

It'll be a lot more fun if the method and or data are new/unique.

Show me what you got! :D",https://www.reddit.com/r/LanguageTechnology/comments/ky8bbk/first_nlp_course_seeking_ideas_for_funinteresting/,LanguageTechnology,t3_ky8bbk,"First NLP course. Seeking ideas for fun/interesting term project. (Interesting data? Hottest research?) The headline pretty much says it all:

I'm taking my first NLP course and need some inspiration coming up with ideas for my term project. Broad strokes of the project requirements are to find a research paper involving a particular method or somesuch, and then to implement said somesuch and report various metrics on efficiency/f1/etc.

It'll be a lot more fun if the method and or data are new/unique.

Show me what you got! :D",533
912,912,Knowledge of linguistics in NLP,"For those of you who have started out from a traditional ML/DL background, have you ever felt like knowledge of linguistics is necessary to excel in this field?

While I love NLP as a field of study, I've also started to increasingly wonder how non-linguists can break into NLP, when, after all, NLP is a study of the human language. This also makes me think that recent advances in NLP are being driven by hard-core engineering and resource-intensive computing (huge, billion-parameter models trained on terabytes of datasets) rather than refined linguistic approaches that could potentially yield more meaningful insight into how humans learn and understand language. 

But of course, this is coming from someone who has just started to study NLP, so I'm sure there are finer details that I'm missing from the bigger picture.

Thanks for sharing your opinions and experience!",https://www.reddit.com/r/LanguageTechnology/comments/kxnecz/knowledge_of_linguistics_in_nlp/,LanguageTechnology,t3_kxnecz,"Knowledge of linguistics in NLP For those of you who have started out from a traditional ML/DL background, have you ever felt like knowledge of linguistics is necessary to excel in this field?

While I love NLP as a field of study, I've also started to increasingly wonder how non-linguists can break into NLP, when, after all, NLP is a study of the human language. This also makes me think that recent advances in NLP are being driven by hard-core engineering and resource-intensive computing (huge, billion-parameter models trained on terabytes of datasets) rather than refined linguistic approaches that could potentially yield more meaningful insight into how humans learn and understand language. 

But of course, this is coming from someone who has just started to study NLP, so I'm sure there are finer details that I'm missing from the bigger picture.

Thanks for sharing your opinions and experience!",909
913,913,Any good model which can be used for fine-tuning,"I am doing a search NLP engine which takes short query of 6-7 tokens  of  type question or a statement which wants to find a answer from database. Can you guys give me a good starting point to have a good pretrained model for short queries and fine tune different tasks like NER, entity relationship, pos tagging. And also data must be created manually. How Fine-tuning can be done wtih  minimal training data.?",https://www.reddit.com/r/LanguageTechnology/comments/ky0u3p/any_good_model_which_can_be_used_for_finetuning/,LanguageTechnology,t3_ky0u3p,"Any good model which can be used for fine-tuning I am doing a search NLP engine which takes short query of 6-7 tokens  of  type question or a statement which wants to find a answer from database. Can you guys give me a good starting point to have a good pretrained model for short queries and fine tune different tasks like NER, entity relationship, pos tagging. And also data must be created manually. How Fine-tuning can be done wtih  minimal training data.?",460
914,914,Bullet point summarizers?,Can anyone point me to some literature that would be talking about models where you input a text and it returns bullet point summary? I found a very little number of such. Is this even a thing?,https://www.reddit.com/r/LanguageTechnology/comments/kxx9f0/bullet_point_summarizers/,LanguageTechnology,t3_kxx9f0,Bullet point summarizers? Can anyone point me to some literature that would be talking about models where you input a text and it returns bullet point summary? I found a very little number of such. Is this even a thing?,219
915,915,Are there any models to do fine-grained POS tagging for Nouns (Concrete noun and Abstract noun )?,"Can anyone point to NLP models/approaches to do fine-grained POS tagging of Nouns. I'm especially interested to distinguish if a Noun is Concrete or Abstract.

[https://www.grammarly.com/blog/concrete-vs-abstract-nouns/](https://www.grammarly.com/blog/concrete-vs-abstract-nouns/)

A concrete noun is a noun that can be identified through one of the five senses (taste, touch, sight, hearing, or smell).  

 An abstract noun is a noun that cannot be perceived using one of the five senses (i.e., taste, touch, sight, hearing, smelling).",https://www.reddit.com/r/LanguageTechnology/comments/ky0sxt/are_there_any_models_to_do_finegrained_pos/,LanguageTechnology,t3_ky0sxt,"Are there any models to do fine-grained POS tagging for Nouns (Concrete noun and Abstract noun )? Can anyone point to NLP models/approaches to do fine-grained POS tagging of Nouns. I'm especially interested to distinguish if a Noun is Concrete or Abstract.

[https://www.grammarly.com/blog/concrete-vs-abstract-nouns/](https://www.grammarly.com/blog/concrete-vs-abstract-nouns/)

A concrete noun is a noun that can be identified through one of the five senses (taste, touch, sight, hearing, or smell).  

 An abstract noun is a noun that cannot be perceived using one of the five senses (i.e., taste, touch, sight, hearing, smelling).",634
916,916,Upcoming shared tasks in NLP 2021,"Any shared tasks in the year 2021 for NLP happening soon. 

Anyone needs collaborator for shared task. ?",https://www.reddit.com/r/LanguageTechnology/comments/kxqwdn/upcoming_shared_tasks_in_nlp_2021/,LanguageTechnology,t3_kxqwdn,"Upcoming shared tasks in NLP 2021 Any shared tasks in the year 2021 for NLP happening soon. 

Anyone needs collaborator for shared task. ?",138
917,917,Is there any case ELMo can be a better choice than BERT/Transformer?,"Hi, here's one very simple question.

Can you guys think of any case where ELMo can be a clearly better design choice than BERT/Transformer family? I tried, but I couldn't think of any case.",https://www.reddit.com/r/LanguageTechnology/comments/kxnytw/is_there_any_case_elmo_can_be_a_better_choice/,LanguageTechnology,t3_kxnytw,"Is there any case ELMo can be a better choice than BERT/Transformer? Hi, here's one very simple question.

Can you guys think of any case where ELMo can be a clearly better design choice than BERT/Transformer family? I tried, but I couldn't think of any case.",259
918,918,Resource on Multi document summarisation,"Hey,
I was looking for some good papers on unsupervised multi-document summarisation ?
Any recommendations?

Thanks",https://www.reddit.com/r/LanguageTechnology/comments/kxsrcq/resource_on_multi_document_summarisation/,LanguageTechnology,t3_kxsrcq,"Resource on Multi document summarisation Hey,
I was looking for some good papers on unsupervised multi-document summarisation ?
Any recommendations?

Thanks",156
919,919,How can I extract the topic of a sentence and then the adjective related to it in spacy?,"Hello everyone! I've posted here a couple of times and you guys helped me a lot. The last time, I tried to extract NOUN and ADJECTIVE together, but the output had a lot of errors. Now I want to try a different approach, to first identify the topic of a sentence and then extract the adjective, like this: 

&amp;#x200B;

The teacher is calm and intelligent.

The material is bad.

I want an output that is like:

{teacher calm}, {teacher intelligent} and {material bad}

Can anyone help me? 

Also, if anyone has a different idea about how to solve this problem in a better way, I'll really appreciate your reply too!  


Thanks in advance!   
 

#",https://www.reddit.com/r/LanguageTechnology/comments/kxo2ga/how_can_i_extract_the_topic_of_a_sentence_and/,LanguageTechnology,t3_kxo2ga,"How can I extract the topic of a sentence and then the adjective related to it in spacy? Hello everyone! I've posted here a couple of times and you guys helped me a lot. The last time, I tried to extract NOUN and ADJECTIVE together, but the output had a lot of errors. Now I want to try a different approach, to first identify the topic of a sentence and then extract the adjective, like this: 

&amp;#x200B;

The teacher is calm and intelligent.

The material is bad.

I want an output that is like:

{teacher calm}, {teacher intelligent} and {material bad}

Can anyone help me? 

Also, if anyone has a different idea about how to solve this problem in a better way, I'll really appreciate your reply too!  


Thanks in advance!   
 

#",737
920,920,Why are language modeling pre-training objectives considered unsupervised?,"Maybe this is stemming from my not-so-great grasp of supervised vs. unsupervised learning, but my understanding is that if we have access to ground-truth labels then it's supervised learning and if not then it's unsupervised.

I'll take the masked language modeling (MLM) that BERT ([Devlin et al., 2019](https://www.aclweb.org/anthology/N19-1423/)) and many other subsequent language models use.

According to the original paper:

&gt; ...we simply mask some percentage of the input tokens at random, and then predict those masked tokens... In this case, the final hidden vectors corresponding to the mask tokens are fed into an output softmax over the vocabulary, as in a standard LM.

If we just replace a certain percentage of tokens with `[MASK]` randomly, don't we technically have access to the ground-truth labels (i.e., the original unmasked tokens)? Shouldn't this be considered supervised learning?

My argument is analogous for the next sentence prediction (NSP) task.",https://www.reddit.com/r/LanguageTechnology/comments/kxpmnn/why_are_language_modeling_pretraining_objectives/,LanguageTechnology,t3_kxpmnn,"Why are language modeling pre-training objectives considered unsupervised? Maybe this is stemming from my not-so-great grasp of supervised vs. unsupervised learning, but my understanding is that if we have access to ground-truth labels then it's supervised learning and if not then it's unsupervised.

I'll take the masked language modeling (MLM) that BERT ([Devlin et al., 2019](https://www.aclweb.org/anthology/N19-1423/)) and many other subsequent language models use.

According to the original paper:

&gt; ...we simply mask some percentage of the input tokens at random, and then predict those masked tokens... In this case, the final hidden vectors corresponding to the mask tokens are fed into an output softmax over the vocabulary, as in a standard LM.

If we just replace a certain percentage of tokens with `[MASK]` randomly, don't we technically have access to the ground-truth labels (i.e., the original unmasked tokens)? Shouldn't this be considered supervised learning?

My argument is analogous for the next sentence prediction (NSP) task.",1055
921,921,"Introduction to chatbots: what, why and how?[chatbot creation using dialogflow]",,https://shyambhu20.blogspot.com/2020/12/introduction-to-chatbots-what-why-and.html,LanguageTechnology,t3_kxphom,"Introduction to chatbots: what, why and how?[chatbot creation using dialogflow] ",80
922,922,Does anyone maybe know (or has an insight) into the things I could not understand from reading the NLP book?,"As I currently want to self-study NLP (and information retrieval) I have a few questions and I hope that someone can provide me some insight on them :) .

1) If I want to train a learning-to-rank model with imperfect labels, which loss would be better to choose: point-wise or pair-wise? If I choose a pair-wise loss, will it be computationally more expensive, but less prone to overfitting (and learning the exact non-machine learning) ranking function?

2) Does the term-at-a-time algorithm need to parse the entire posting list of at least one query term?

3) Can the Cranfield paradigm (about the testing datasets) be used for the evaluation of an e-mail search system?

4) Does stemming help or hurt the ranking algorithm for the retrieval system of the entity knowledge graph?

This is the things I could not understand from reading the book about it (and searching it later online), so thank you in advance :)",https://www.reddit.com/r/LanguageTechnology/comments/kxjizd/does_anyone_maybe_know_or_has_an_insight_into_the/,LanguageTechnology,t3_kxjizd,"Does anyone maybe know (or has an insight) into the things I could not understand from reading the NLP book? As I currently want to self-study NLP (and information retrieval) I have a few questions and I hope that someone can provide me some insight on them :) .

1) If I want to train a learning-to-rank model with imperfect labels, which loss would be better to choose: point-wise or pair-wise? If I choose a pair-wise loss, will it be computationally more expensive, but less prone to overfitting (and learning the exact non-machine learning) ranking function?

2) Does the term-at-a-time algorithm need to parse the entire posting list of at least one query term?

3) Can the Cranfield paradigm (about the testing datasets) be used for the evaluation of an e-mail search system?

4) Does stemming help or hurt the ranking algorithm for the retrieval system of the entity knowledge graph?

This is the things I could not understand from reading the book about it (and searching it later online), so thank you in advance :)",1025
923,923,"Article: ""Google’s new trillion-parameter AI language model is almost 6 times bigger than GPT-3""",,/r/GPT3/comments/kwud6k/article_googles_new_trillionparameter_ai_language/,LanguageTechnology,t3_kww3ne,"Article: ""Google’s new trillion-parameter AI language model is almost 6 times bigger than GPT-3"" ",97
924,924,Folks’Talks video game. Graphic Research Interface. Explanatory note for current temporary interface.,,/r/learnmachinelearning/comments/kx0nu1/folkstalks_video_game_graphic_research_interface/,LanguageTechnology,t3_kx19kw,Folks’Talks video game. Graphic Research Interface. Explanatory note for current temporary interface. ,102
925,925,Could you please advice if I am using this Marian MT transformer correctly? It runs way too slow.,"Hello, I am dabbing in NLP transformers, specifically the [Marian MT model released by HuggingFace](https://huggingface.co/transformers/model_doc/marian.html).

I adapted the tutorial example and it does work, but it is super slow. Could you please advise if I am using it correctly? Please note that I wish to use it to translate individual words from a list, not a whole text.


Here is the code:

    from transformers import MarianTokenizer, MarianMTModel
    from typing import List
    mt_model = MarianMTModel.from_pretrained('mt_model/opus-mt-en-es')
    mt_tok = MarianTokenizer.from_pretrained('mt_model/opus-mt-en-es')
    
    def translate(word, model, tok):
        batch = tok.prepare_seq2seq_batch(src_texts=[word], 
                                          return_tensors=""pt"")  
        gen = model.generate(**batch)
        translated_word: List[str] = tok.batch_decode(gen, skip_special_tokens=True)
        return ' '.join(translated_word)",https://www.reddit.com/r/LanguageTechnology/comments/kwuznq/could_you_please_advice_if_i_am_using_this_marian/,LanguageTechnology,t3_kwuznq,"Could you please advice if I am using this Marian MT transformer correctly? It runs way too slow. Hello, I am dabbing in NLP transformers, specifically the [Marian MT model released by HuggingFace](https://huggingface.co/transformers/model_doc/marian.html).

I adapted the tutorial example and it does work, but it is super slow. Could you please advise if I am using it correctly? Please note that I wish to use it to translate individual words from a list, not a whole text.


Here is the code:

    from transformers import MarianTokenizer, MarianMTModel
    from typing import List
    mt_model = MarianMTModel.from_pretrained('mt_model/opus-mt-en-es')
    mt_tok = MarianTokenizer.from_pretrained('mt_model/opus-mt-en-es')
    
    def translate(word, model, tok):
        batch = tok.prepare_seq2seq_batch(src_texts=[word], 
                                          return_tensors=""pt"")  
        gen = model.generate(**batch)
        translated_word: List[str] = tok.batch_decode(gen, skip_special_tokens=True)
        return ' '.join(translated_word)",1059
926,926,Commonsense Reasoning for Natural Language Processing - Vered Shwartz,,http://veredshwartz.blogspot.com/2021/01/commonsense-reasoning-for-natural.html,LanguageTechnology,t3_kwnd6u,Commonsense Reasoning for Natural Language Processing - Vered Shwartz ,70
927,927,Measuring Fullness of a Sentence,"Would love some help with a bit of an odd problem I’m trying to solve… How does one measure the “fullness” of a sentence?

Ex:
Thank you for reaching out about the issue at school
- will score higher than 
Thank you for reaching out

As the first sentence provides more detail, it should score higher. How can I measure the fullness/detail of a sentence?",https://www.reddit.com/r/LanguageTechnology/comments/kwj9np/measuring_fullness_of_a_sentence/,LanguageTechnology,t3_kwj9np,"Measuring Fullness of a Sentence Would love some help with a bit of an odd problem I’m trying to solve… How does one measure the “fullness” of a sentence?

Ex:
Thank you for reaching out about the issue at school
- will score higher than 
Thank you for reaching out

As the first sentence provides more detail, it should score higher. How can I measure the fullness/detail of a sentence?",387
928,928,Translation management systems,"For anyone into language tech, my colleague is hosting a free event, thought I would share here [https://us02web.zoom.us/webinar/register/1916105631007/WN\_ReYW3SRKRXeSQtuxiya1ng](https://us02web.zoom.us/webinar/register/1916105631007/WN_ReYW3SRKRXeSQtuxiya1ng)",https://www.reddit.com/r/LanguageTechnology/comments/kwmt5r/translation_management_systems/,LanguageTechnology,t3_kwmt5r,"Translation management systems For anyone into language tech, my colleague is hosting a free event, thought I would share here [https://us02web.zoom.us/webinar/register/1916105631007/WN\_ReYW3SRKRXeSQtuxiya1ng](https://us02web.zoom.us/webinar/register/1916105631007/WN_ReYW3SRKRXeSQtuxiya1ng)",292
929,929,Great papers for distantly supervised learning?,I have been searching for papers on distant supervision for named-entity extraction on Google scholar. Does anyone have some suggestions for high impact papers that worked on distant supervision in named-entity extraction?,https://www.reddit.com/r/LanguageTechnology/comments/kwgx1f/great_papers_for_distantly_supervised_learning/,LanguageTechnology,t3_kwgx1f,Great papers for distantly supervised learning? I have been searching for papers on distant supervision for named-entity extraction on Google scholar. Does anyone have some suggestions for high impact papers that worked on distant supervision in named-entity extraction?,270
930,930,Recommendations for Semantic Search,"I'm looking for recommendations for a semantic search system that can score thousands of text snippets based on their relevance to a user's question.

`INPUT:`  
`- A question, in natural language English.`  
`- A corpus of thousands of text snippets.`

`OUTPUT:`  
`A score for each of the text snippets based on how relevant it is to the question.`

It should not just be keyword based, but based on meaning / closeness of concept. For example...

`QUESTION: ""Why is LIDAR unneccesary for self driving cars?""`  
`SNIPPET: ""SpaceX uses LIDAR for docking to the ISS"".`

\-&gt; The snippet should get a lower relevance score, because the snippet is about the same subject (LIDAR), but in a different context (space vs. automotive).

It should also be smart enough to rank snippets that use different words for the same concept.

`QUESTION: ""Why is LIDAR unneccesary for self driving cars?""`  
`SNIPPET: ""Tesla's FSD uses cameras to create a 3D vector space representation of the surroundings, which makes costly sensors such as LIDAR unnecessary.""`

\-&gt; The snippet should get a higher relevance score, because the words ""Tesla"" and ""FSD"" in the snippet are semantically linked to the words ""self driving cars"" in the question.

What would you say is the best tool to accomplish this today?",https://www.reddit.com/r/LanguageTechnology/comments/kwcfip/recommendations_for_semantic_search/,LanguageTechnology,t3_kwcfip,"Recommendations for Semantic Search I'm looking for recommendations for a semantic search system that can score thousands of text snippets based on their relevance to a user's question.

`INPUT:`  
`- A question, in natural language English.`  
`- A corpus of thousands of text snippets.`

`OUTPUT:`  
`A score for each of the text snippets based on how relevant it is to the question.`

It should not just be keyword based, but based on meaning / closeness of concept. For example...

`QUESTION: ""Why is LIDAR unneccesary for self driving cars?""`  
`SNIPPET: ""SpaceX uses LIDAR for docking to the ISS"".`

\-&gt; The snippet should get a lower relevance score, because the snippet is about the same subject (LIDAR), but in a different context (space vs. automotive).

It should also be smart enough to rank snippets that use different words for the same concept.

`QUESTION: ""Why is LIDAR unneccesary for self driving cars?""`  
`SNIPPET: ""Tesla's FSD uses cameras to create a 3D vector space representation of the surroundings, which makes costly sensors such as LIDAR unnecessary.""`

\-&gt; The snippet should get a higher relevance score, because the words ""Tesla"" and ""FSD"" in the snippet are semantically linked to the words ""self driving cars"" in the question.

What would you say is the best tool to accomplish this today?",1328
931,931,Our new state-of-the-art multilingual NLP Toolkit - Trankit has been released,"Hi everyone,

We just released our lightweight transformer-based NLP toolkit named **Trankit.**

**Our toolkit outperforms the current state-of-the-art Stanford NLP (Stanza)** in many tasks such as sentence segmentation, part-of-speech tagging, and dependency parsing **over** **56 different languages**. Detailed comparison can be found [here](https://trankit.readthedocs.io/en/latest/performance.html#universal-dependencies-v2-5).

For example, for **English**, **Trankit is significantly better than Stanford NLP (Stanza)** on sentence segmentation (**+7.22%**) and dependency parsing (**+3.92%** for UAS and **+4.37%** for LAS). For **Arabic**, our toolkit substantially improves sentence segmentation performance by **16.16%** while **Chinese** observes **12.31%** and **12.72%** improvement of UAS and LAS for dependency parsing.

**Trankit is written in Python and can be easily installed via pip**. Our code and pretrained models are publicly available at: [https://github.com/nlp-uoregon/trankit](https://github.com/nlp-uoregon/trankit)

We also created a documentation page and a demo website for Trankit.Documentation page: [https://trankit.readthedocs.io/en/latest/index.html](https://trankit.readthedocs.io/en/latest/index.html)

Demo website: [http://nlp.uoregon.edu/trankit](http://nlp.uoregon.edu/trankit)

Technical details about Trankit can be found in our paper: [https://arxiv.org/pdf/2101.03289.pdf](https://arxiv.org/pdf/2101.03289.pdf)

Thank you!",https://www.reddit.com/r/LanguageTechnology/comments/kvyvfu/our_new_stateoftheart_multilingual_nlp_toolkit/,LanguageTechnology,t3_kvyvfu,"Our new state-of-the-art multilingual NLP Toolkit - Trankit has been released Hi everyone,

We just released our lightweight transformer-based NLP toolkit named **Trankit.**

**Our toolkit outperforms the current state-of-the-art Stanford NLP (Stanza)** in many tasks such as sentence segmentation, part-of-speech tagging, and dependency parsing **over** **56 different languages**. Detailed comparison can be found [here](https://trankit.readthedocs.io/en/latest/performance.html#universal-dependencies-v2-5).

For example, for **English**, **Trankit is significantly better than Stanford NLP (Stanza)** on sentence segmentation (**+7.22%**) and dependency parsing (**+3.92%** for UAS and **+4.37%** for LAS). For **Arabic**, our toolkit substantially improves sentence segmentation performance by **16.16%** while **Chinese** observes **12.31%** and **12.72%** improvement of UAS and LAS for dependency parsing.

**Trankit is written in Python and can be easily installed via pip**. Our code and pretrained models are publicly available at: [https://github.com/nlp-uoregon/trankit](https://github.com/nlp-uoregon/trankit)

We also created a documentation page and a demo website for Trankit.Documentation page: [https://trankit.readthedocs.io/en/latest/index.html](https://trankit.readthedocs.io/en/latest/index.html)

Demo website: [http://nlp.uoregon.edu/trankit](http://nlp.uoregon.edu/trankit)

Technical details about Trankit can be found in our paper: [https://arxiv.org/pdf/2101.03289.pdf](https://arxiv.org/pdf/2101.03289.pdf)

Thank you!",1548
932,932,"Is there any work in NLP where a neural summarization model is ""forced"" to contain a certain subject and object?","Hi guys. I'm wondering if there is any work done in the NLP field regarding neural summarization where the model is given the constraint to contain a certain subject and object.

For example, if we're given a document about Elon Musk and Tesla, I'm wondering if the model can be constrained to output a summarization in the form of, for example, ""Elon Musk is the founder of Tesla.""

Any tips are appreciated. Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/kwafut/is_there_any_work_in_nlp_where_a_neural/,LanguageTechnology,t3_kwafut,"Is there any work in NLP where a neural summarization model is ""forced"" to contain a certain subject and object? Hi guys. I'm wondering if there is any work done in the NLP field regarding neural summarization where the model is given the constraint to contain a certain subject and object.

For example, if we're given a document about Elon Musk and Tesla, I'm wondering if the model can be constrained to output a summarization in the form of, for example, ""Elon Musk is the founder of Tesla.""

Any tips are appreciated. Thanks.",530
933,933,Multiclass dataset for sentiment analysis?,"Hi all

I am looking to fine tune a deep learning model like BERT to classify news sentiment as either negative, neutral or positive. I can find many binary classification datasets used as performance measures by state of the art models, and even [papers where their scores are compared](https://arxiv.org/pdf/2004.03705.pdf),  but i can't seem to find a dataset that is used by  state of the art models to compare 3 class sentiment analysis of positive negative and neutral.

How should i approach this? Should i look at performance metrics for binary classification tasks and make an assumption that the ones that perform best at binary classification will also perform best at 3-class classification? Or should i look at model performances with multi-class labels (which often have 15-30 labels) and use that as a guideline?

Are there any leaderboards that contain rankings of the best models for 3-label negative, neutral and positive sentiment? i can't seem to find any.

My aim is to find good at this task in general, and then fine tune it classifying sentiment of financial news headlines",https://www.reddit.com/r/LanguageTechnology/comments/kwcay2/multiclass_dataset_for_sentiment_analysis/,LanguageTechnology,t3_kwcay2,"Multiclass dataset for sentiment analysis? Hi all

I am looking to fine tune a deep learning model like BERT to classify news sentiment as either negative, neutral or positive. I can find many binary classification datasets used as performance measures by state of the art models, and even [papers where their scores are compared](https://arxiv.org/pdf/2004.03705.pdf),  but i can't seem to find a dataset that is used by  state of the art models to compare 3 class sentiment analysis of positive negative and neutral.

How should i approach this? Should i look at performance metrics for binary classification tasks and make an assumption that the ones that perform best at binary classification will also perform best at 3-class classification? Or should i look at model performances with multi-class labels (which often have 15-30 labels) and use that as a guideline?

Are there any leaderboards that contain rankings of the best models for 3-label negative, neutral and positive sentiment? i can't seem to find any.

My aim is to find good at this task in general, and then fine tune it classifying sentiment of financial news headlines",1140
934,934,Information extraction and comparison,How to extract information from sentences which is present in one excel file and compare it with 700 standard sentences  with unique codes  which is present in another Excel sheet and assign the sentence with that particular unique code of the sentence to which it is almost similar ?,https://www.reddit.com/r/LanguageTechnology/comments/kwefqq/information_extraction_and_comparison/,LanguageTechnology,t3_kwefqq,Information extraction and comparison How to extract information from sentences which is present in one excel file and compare it with 700 standard sentences  with unique codes  which is present in another Excel sheet and assign the sentence with that particular unique code of the sentence to which it is almost similar ?,322
935,935,Pronunciation Attribution for Japanese Kanji,"Hello,

I am wondering if there are algorithms out there for attributing syllables of a romaji/furigana/pronunciation to the different Kanji within a word?

eg  東京 (トウキョウ) -&gt; 東 (トウ) 京 (キョウ)

Maybe a lattice-based approach? I implemented an algorithm using a form of A\* search but I was wondering if there were better algorithms that I could look at.

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/kwa7p2/pronunciation_attribution_for_japanese_kanji/,LanguageTechnology,t3_kwa7p2,"Pronunciation Attribution for Japanese Kanji Hello,

I am wondering if there are algorithms out there for attributing syllables of a romaji/furigana/pronunciation to the different Kanji within a word?

eg  東京 (トウキョウ) -&gt; 東 (トウ) 京 (キョウ)

Maybe a lattice-based approach? I implemented an algorithm using a form of A\* search but I was wondering if there were better algorithms that I could look at.

Thanks!",407
936,936,[D] Help Document Ordering,"Hi, I am currently working on a problem to order/rank help documents in the most useful way. The ranking criteria is a bit complex.   
The criteria should be based on :  
1. how useful it was in the past 

2. how popular (or trending) it is amongst the users 

3. also how much information(relative to other documents in the list) does the document have. 

 As of now I was thinking I could use some weighted window method to compute the popularity and trending aspect based on click through rate or likes/dislikes the documents get over the window of time.   
I wanted to understand how I could address the information aspect of the criteria i.e what methods would I use to compare the documents based on the amount of information they would have to rank accordingly.   
I would also appreciate ideas that would help me combine scores from both these aspects to get to a final score to rank the documents.",https://www.reddit.com/r/LanguageTechnology/comments/kw5wpy/d_help_document_ordering/,LanguageTechnology,t3_kw5wpy,"[D] Help Document Ordering Hi, I am currently working on a problem to order/rank help documents in the most useful way. The ranking criteria is a bit complex.   
The criteria should be based on :  
1. how useful it was in the past 

2. how popular (or trending) it is amongst the users 

3. also how much information(relative to other documents in the list) does the document have. 

 As of now I was thinking I could use some weighted window method to compute the popularity and trending aspect based on click through rate or likes/dislikes the documents get over the window of time.   
I wanted to understand how I could address the information aspect of the criteria i.e what methods would I use to compare the documents based on the amount of information they would have to rank accordingly.   
I would also appreciate ideas that would help me combine scores from both these aspects to get to a final score to rank the documents.",933
937,937,Is there any tool (preferably for python) that helps with extracting all entities and relationships in a path of a RDF graph?,"I know that property paths in SPARQL can aid you with that. However, you need to be really specific with your nodes and relationships in between two entity nodes that mark the start and the end of the path, if you want to extract them. I am searching for a arbitrary way to do this.

What i want is basically:

Input: start entity, amount of max hops for the path (f.e. 4), RDF knowledge graph

Extract all paths with hops &lt;= 4 beginning from the start entity. A hop is basically a jump between entities via SPO representation.

Output:

\[start entity - relationship 1.1 - entity 1.1 - relationship 2.1 - entity 2.1 - relationship 3.1 - entity 3.1 - relationship 4.1 - entity 4.1\],

\[start entity - relationship 1.2 - entity 1.2 - relationship 2.2 - entity 2.2 - relationship 3.2 - entity 3.2 - relationship 4.2 - entity 4.2\],

etc.

Does not need to be in array representation. All i want is to be able to analyze a path programmatically. Im am currently considering doing this manually via loops and multiple queries on a local RDF TTL-graph.",https://www.reddit.com/r/LanguageTechnology/comments/kvtng6/is_there_any_tool_preferably_for_python_that/,LanguageTechnology,t3_kvtng6,"Is there any tool (preferably for python) that helps with extracting all entities and relationships in a path of a RDF graph? I know that property paths in SPARQL can aid you with that. However, you need to be really specific with your nodes and relationships in between two entity nodes that mark the start and the end of the path, if you want to extract them. I am searching for a arbitrary way to do this.

What i want is basically:

Input: start entity, amount of max hops for the path (f.e. 4), RDF knowledge graph

Extract all paths with hops &lt;= 4 beginning from the start entity. A hop is basically a jump between entities via SPO representation.

Output:

\[start entity - relationship 1.1 - entity 1.1 - relationship 2.1 - entity 2.1 - relationship 3.1 - entity 3.1 - relationship 4.1 - entity 4.1\],

\[start entity - relationship 1.2 - entity 1.2 - relationship 2.2 - entity 2.2 - relationship 3.2 - entity 3.2 - relationship 4.2 - entity 4.2\],

etc.

Does not need to be in array representation. All i want is to be able to analyze a path programmatically. Im am currently considering doing this manually via loops and multiple queries on a local RDF TTL-graph.",1177
938,938,Create search bar NLP recommendation in Python," Like the title says, I would like to create an NLP project which consists of a search bar and when someone types something domain specific, it can start generating suggestions. The problem is, I want these suggestions to only be domain specific. Can someone guide me to tutorials or frameworks that can help me. Thank you.

Just as an example - I would create a bank and clients would type up specific processes in that bank. So if a client were to type ""I would like"" it would generate some suggestions like ""I would like to request a loan"" and ""I would like to speak to customer service"" and ""I would like to open a bank account""

Thanks again.",https://www.reddit.com/r/LanguageTechnology/comments/kw2oc4/create_search_bar_nlp_recommendation_in_python/,LanguageTechnology,t3_kw2oc4,"Create search bar NLP recommendation in Python  Like the title says, I would like to create an NLP project which consists of a search bar and when someone types something domain specific, it can start generating suggestions. The problem is, I want these suggestions to only be domain specific. Can someone guide me to tutorials or frameworks that can help me. Thank you.

Just as an example - I would create a bank and clients would type up specific processes in that bank. So if a client were to type ""I would like"" it would generate some suggestions like ""I would like to request a loan"" and ""I would like to speak to customer service"" and ""I would like to open a bank account""

Thanks again.",694
939,939,T5: Exploring Limits of Transfer Learning with Text-to-Text Transformer | Research Paper Walkthrough,,https://youtu.be/91iLu6OOrwk,LanguageTechnology,t3_kvlrxo,T5: Exploring Limits of Transfer Learning with Text-to-Text Transformer | Research Paper Walkthrough ,101
940,940,Is there a method for restyling a sentence given another sentence?,"I’m working on a problem where I need to take two sentences:

1. Input sentence (this needs to be restyled)
2. Reference sentence (we match the style of this sentence)

I need to rephrase the input sentence to be more similar to the reference sentence.

Very simple example — if the reference sentence is needlessly verbose, has misspellings and lots of commas, we rephrase the input sentence to have commas and misspellings, and add words to make it more verbose.

How should I approach this problem?",https://www.reddit.com/r/LanguageTechnology/comments/kvas7j/is_there_a_method_for_restyling_a_sentence_given/,LanguageTechnology,t3_kvas7j,"Is there a method for restyling a sentence given another sentence? I’m working on a problem where I need to take two sentences:

1. Input sentence (this needs to be restyled)
2. Reference sentence (we match the style of this sentence)

I need to rephrase the input sentence to be more similar to the reference sentence.

Very simple example — if the reference sentence is needlessly verbose, has misspellings and lots of commas, we rephrase the input sentence to have commas and misspellings, and add words to make it more verbose.

How should I approach this problem?",568
941,941,How to know if my language model saw a phrase during training,"Is there a way to know if there was a phrase in an LM’s training data w/o looking at the training data itself? It is not as trivial as looking at the vocab: for example if the vocab contains Donald and Trump, doesn’t mean that it the phrase “Donald Trump” was in the training data.",https://www.reddit.com/r/LanguageTechnology/comments/kuzi88/how_to_know_if_my_language_model_saw_a_phrase/,LanguageTechnology,t3_kuzi88,"How to know if my language model saw a phrase during training Is there a way to know if there was a phrase in an LM’s training data w/o looking at the training data itself? It is not as trivial as looking at the vocab: for example if the vocab contains Donald and Trump, doesn’t mean that it the phrase “Donald Trump” was in the training data.",343
942,942,[R]: Twitter Data crawling for research,"Hello All

I am looking to crawl data for academic research (most likely need to release/open-source the dataset).  Do you guys know the license? (I have already read their webpage, terms and condition), however, I don't find too many open source twitter data set, wondering if there is any hidden terms that I am not awared off?",https://www.reddit.com/r/LanguageTechnology/comments/kusrxx/r_twitter_data_crawling_for_research/,LanguageTechnology,t3_kusrxx,"[R]: Twitter Data crawling for research Hello All

I am looking to crawl data for academic research (most likely need to release/open-source the dataset).  Do you guys know the license? (I have already read their webpage, terms and condition), however, I don't find too many open source twitter data set, wondering if there is any hidden terms that I am not awared off?",369
943,943,Simple LSTM to Detect Passive and Active Voice in Your Writing,,https://www.bobbywlindsey.com/2021/01/09/how-to-detect-passive-and-active-voice-in-your-writing-using-an-lstm/,LanguageTechnology,t3_kui5yj,Simple LSTM to Detect Passive and Active Voice in Your Writing ,63
944,944,Is there an NLP technique for rephrasing question-answer pairs as a full sentence?,"Is there an NLP technique for rephrasing question-answer pairs as a full and grammatically correct sentence? For example:

Question: Where does Joe live?

Answer: Joe lives in Los Angeles.

I’ve looked into Answer Ellipsis, which is essentially the opposite of this issue and what most Machine Reading Comprehension or Question Answering systems already generate. For example, the answer to the above with answer ellipsis would be “Los Angeles”.

For the sake of reader comprehension, I want to turn question-answer pairs into something understandable. What techniques exist to do this?",https://www.reddit.com/r/LanguageTechnology/comments/kujpgj/is_there_an_nlp_technique_for_rephrasing/,LanguageTechnology,t3_kujpgj,"Is there an NLP technique for rephrasing question-answer pairs as a full sentence? Is there an NLP technique for rephrasing question-answer pairs as a full and grammatically correct sentence? For example:

Question: Where does Joe live?

Answer: Joe lives in Los Angeles.

I’ve looked into Answer Ellipsis, which is essentially the opposite of this issue and what most Machine Reading Comprehension or Question Answering systems already generate. For example, the answer to the above with answer ellipsis would be “Los Angeles”.

For the sake of reader comprehension, I want to turn question-answer pairs into something understandable. What techniques exist to do this?",669
945,945,GAP: Text2sql with Generation-Augmented Pre-Training,,https://arxiv.org/abs/2012.10309,LanguageTechnology,t3_ku5u1y,GAP: Text2sql with Generation-Augmented Pre-Training ,53
946,946,Spider: Yale Semantic Parsing and Text-to-SQL Challenge,,https://yale-lily.github.io/spider,LanguageTechnology,t3_kttt6h,Spider: Yale Semantic Parsing and Text-to-SQL Challenge ,56
947,947,Making a natural language bot.. that sounds like its having a stroke. What data sets to use?,"Got sent here from r/learnprogramming! 

&amp;#x200B;

Hi, for a long time I've ""collected"" and made up sentences that \*almost\* make sense, but don't. It's similar to the kinds of things you might see on [r/ihadastroke](https://www.reddit.com/r/ihadastroke/). Such as:

***Appreciate what you what, be are the make you appreciate what you dad.***

or

***Why do they call it oven when you of in the cold food of out hot eat the food?***

or

***Don't think that carrot big because carrot big leaf because small leaf carrot not big leaf sizes.***

As a fun quarantine side project, I wanted to train an AI to generate these almost-sensical sentences for my own amusement. Since I typically only program games, I wanted something simple and I'm currently using Max Woolfe's [GPT-2 simple](https://minimaxir.com/2019/09/howto-gpt2/) since its extremely easy to input data sets and quickly train a model right from a google collab project. I've considered that perhaps using a ""worse"" platform to create a model might be better for my goals though.

Anyway, I'm considering from where I should pull input sets to train the model. Some ideas I have right now are English as second language forums, mass-translating sentences through a bunch of different languages then back to english, bad sentences generated by other bots like on [r/SubredditSimulator](https://www.reddit.com/r/SubredditSimulator/), or mixing proper english sentences with a smattering of ones that are nonsensical. The nuance to this is that I'd want sentences that ***almost*** make sense, but don't. Oftentimes they'll have a proper grammatic opening or ending, but then will start to deviate or repeat verbs when the clause should end. It might also be possible to not use ML but just take fully formed sentences and start swapping around and subbing out words algorithmically. Any and all suggestions are welcome! This is my first time trying any type of model training so I appreciate any tips, but would probably need to keep it simple.",https://www.reddit.com/r/LanguageTechnology/comments/ku0d7b/making_a_natural_language_bot_that_sounds_like/,LanguageTechnology,t3_ku0d7b,"Making a natural language bot.. that sounds like its having a stroke. What data sets to use? Got sent here from r/learnprogramming! 

&amp;#x200B;

Hi, for a long time I've ""collected"" and made up sentences that \*almost\* make sense, but don't. It's similar to the kinds of things you might see on [r/ihadastroke](https://www.reddit.com/r/ihadastroke/). Such as:

***Appreciate what you what, be are the make you appreciate what you dad.***

or

***Why do they call it oven when you of in the cold food of out hot eat the food?***

or

***Don't think that carrot big because carrot big leaf because small leaf carrot not big leaf sizes.***

As a fun quarantine side project, I wanted to train an AI to generate these almost-sensical sentences for my own amusement. Since I typically only program games, I wanted something simple and I'm currently using Max Woolfe's [GPT-2 simple](https://minimaxir.com/2019/09/howto-gpt2/) since its extremely easy to input data sets and quickly train a model right from a google collab project. I've considered that perhaps using a ""worse"" platform to create a model might be better for my goals though.

Anyway, I'm considering from where I should pull input sets to train the model. Some ideas I have right now are English as second language forums, mass-translating sentences through a bunch of different languages then back to english, bad sentences generated by other bots like on [r/SubredditSimulator](https://www.reddit.com/r/SubredditSimulator/), or mixing proper english sentences with a smattering of ones that are nonsensical. The nuance to this is that I'd want sentences that ***almost*** make sense, but don't. Oftentimes they'll have a proper grammatic opening or ending, but then will start to deviate or repeat verbs when the clause should end. It might also be possible to not use ML but just take fully formed sentences and start swapping around and subbing out words algorithmically. Any and all suggestions are welcome! This is my first time trying any type of model training so I appreciate any tips, but would probably need to keep it simple.",2102
948,948,NLP School project,"Hello everyone !

I'm a beginner in NLP, and as part of a school project, I created a model allowing to automatically generate emails subjects based on the content of the email. I need to assess the quality of the generated objects, so I need the help of many people to fill a questionnaire :  
[https://forms.gle/8cnnNqtyd8Qv1wbU6](https://forms.gle/8cnnNqtyd8Qv1wbU6?fbclid=IwAR0rqHJOHBQ-jHFX8E522UiB3CUORtBqgpmGJ2hXw2HfUDdKR25NkjP1SU0)

In this questionnaire there are ten sentences, and for each sentence you can say, in your opinion, if this could or not be an email subject.

Thank you so much !",https://www.reddit.com/r/LanguageTechnology/comments/ku0c4w/nlp_school_project/,LanguageTechnology,t3_ku0c4w,"NLP School project Hello everyone !

I'm a beginner in NLP, and as part of a school project, I created a model allowing to automatically generate emails subjects based on the content of the email. I need to assess the quality of the generated objects, so I need the help of many people to fill a questionnaire :  
[https://forms.gle/8cnnNqtyd8Qv1wbU6](https://forms.gle/8cnnNqtyd8Qv1wbU6?fbclid=IwAR0rqHJOHBQ-jHFX8E522UiB3CUORtBqgpmGJ2hXw2HfUDdKR25NkjP1SU0)

In this questionnaire there are ten sentences, and for each sentence you can say, in your opinion, if this could or not be an email subject.

Thank you so much !",620
949,949,Any interest in a disk image for running GPT-2 on a Raspberry Pi4? How to make it available - it's 64GB,"I have created a clean(ish) image with a running implementation of GPT-2 and Tensorflow 1.13.1 that runs on the Pi 4B 8 gig (might also run on the 4G, but possibly slower.)  GitHub limits file uploads to 25MB.  The image is 64 GB......  does anybody have a suggestion of how best to make this available?  Maybe I should sell them for $ on Etsy??? :)

By clean-ish, I mean that I have cleaned up *files I have created* that pertain to other functions the robots have, but there are a LOT of things still *installed* that do not pertain specifically to GPT-2 or Tensorflow 1.13.1 (things like speech recognition, synthesis, zmq &amp; imagezmq, face and object detection &amp; recognition, etc., etc.......)  This image is highly customized, and folks seeking to experiment with GPT-2 on the Pi should be able to do quite a bit with this as a starting point.  Apparently others have had a very hard time (as did I) getting GPT-2 to run on the Pi.  All this needs you to do is burn the image, boot the Pi, open a terminal window, cd ~/Desktop/HOSTCORE/gpt-2 and then python src/speakGPT2.py

You'll get a boatload of tensorflow deprication warnings and memory allocation warnings, but it will eventually offer you the ""Model prompt &gt;&gt;&gt;"" and you can enter your prompt and you're off to the races.

Here's a sample I just ran to test that I didn't break anything when I cleaned up the ~100 files....  Everything after ""SAMPLE 1"" is generated by GPT-2 lol...  Anyway - please let me know if there is interest.

Dave


Model prompt &gt;&gt;&gt; I've worked hard to create this disk image for folks who want to experiment so they can get a working copy of GPT-2.  Now I hope to see some inspiring results, and I hope you'll all share 

============SAMPLE 1 =============

 with your own experience and how it goes for you! Enjoy!
I was fortunate enough to meet a guy at an airport this week who gave me a great introduction to his GPT-2 system. I had never been able to get a working copy of a GPT-2, but his system was working, and he had me work with it. I did a lot of research and spent hours trying to figure out how to get it to work. It was really nice to see someone with experience and knowledge of the system, and how to get it to work. When I went to see him I knew what to expect.

-----------------------------

Model prompt &gt;&gt;&gt;",https://www.reddit.com/r/LanguageTechnology/comments/ktx75b/any_interest_in_a_disk_image_for_running_gpt2_on/,LanguageTechnology,t3_ktx75b,"Any interest in a disk image for running GPT-2 on a Raspberry Pi4? How to make it available - it's 64GB I have created a clean(ish) image with a running implementation of GPT-2 and Tensorflow 1.13.1 that runs on the Pi 4B 8 gig (might also run on the 4G, but possibly slower.)  GitHub limits file uploads to 25MB.  The image is 64 GB......  does anybody have a suggestion of how best to make this available?  Maybe I should sell them for $ on Etsy??? :)

By clean-ish, I mean that I have cleaned up *files I have created* that pertain to other functions the robots have, but there are a LOT of things still *installed* that do not pertain specifically to GPT-2 or Tensorflow 1.13.1 (things like speech recognition, synthesis, zmq &amp; imagezmq, face and object detection &amp; recognition, etc., etc.......)  This image is highly customized, and folks seeking to experiment with GPT-2 on the Pi should be able to do quite a bit with this as a starting point.  Apparently others have had a very hard time (as did I) getting GPT-2 to run on the Pi.  All this needs you to do is burn the image, boot the Pi, open a terminal window, cd ~/Desktop/HOSTCORE/gpt-2 and then python src/speakGPT2.py

You'll get a boatload of tensorflow deprication warnings and memory allocation warnings, but it will eventually offer you the ""Model prompt &gt;&gt;&gt;"" and you can enter your prompt and you're off to the races.

Here's a sample I just ran to test that I didn't break anything when I cleaned up the ~100 files....  Everything after ""SAMPLE 1"" is generated by GPT-2 lol...  Anyway - please let me know if there is interest.

Dave


Model prompt &gt;&gt;&gt; I've worked hard to create this disk image for folks who want to experiment so they can get a working copy of GPT-2.  Now I hope to see some inspiring results, and I hope you'll all share 

============SAMPLE 1 =============

 with your own experience and how it goes for you! Enjoy!
I was fortunate enough to meet a guy at an airport this week who gave me a great introduction to his GPT-2 system. I had never been able to get a working copy of a GPT-2, but his system was working, and he had me work with it. I did a lot of research and spent hours trying to figure out how to get it to work. It was really nice to see someone with experience and knowledge of the system, and how to get it to work. When I went to see him I knew what to expect.

-----------------------------

Model prompt &gt;&gt;&gt;",2454
950,950,Probabilistic verbal subcategorisation frames research,"This is more so on the theoretical side of things but I'm curious to know if anybody is familiar with any research that deals with calculating the likelihood that a verb will take a particular set of arguments as it's complement, in particular the likelihood that a verb will take the overt complementiser *that* as in \[think + \[C\[that\]\]? 

There's a tonne of theoretical linguistic research into this but I'm curious to learn about any different approaches.",https://www.reddit.com/r/LanguageTechnology/comments/ktv513/probabilistic_verbal_subcategorisation_frames/,LanguageTechnology,t3_ktv513,"Probabilistic verbal subcategorisation frames research This is more so on the theoretical side of things but I'm curious to know if anybody is familiar with any research that deals with calculating the likelihood that a verb will take a particular set of arguments as it's complement, in particular the likelihood that a verb will take the overt complementiser *that* as in \[think + \[C\[that\]\]? 

There's a tonne of theoretical linguistic research into this but I'm curious to learn about any different approaches.",518
951,951,ICLR 2020 Workshop Paper on Distant Supervision for Low-Resource Named Entity Recognition | Research Papers Summary 003,,https://youtu.be/qcrkSZ4l1dk,LanguageTechnology,t3_ktqmbw,ICLR 2020 Workshop Paper on Distant Supervision for Low-Resource Named Entity Recognition | Research Papers Summary 003 ,120
952,952,ecco - Visualize &amp; Explain NLP Language Models in Python,,https://www.youtube.com/watch?v=gJPMXgvnX4Y,LanguageTechnology,t3_ktbyfj,ecco - Visualize &amp; Explain NLP Language Models in Python ,61
953,953,"If I am processing pdfs and are formatted incorrectly, what algorithm should I use?","Most of my pdfs are fine. However, some the text is not formatted correctly.",https://www.reddit.com/r/LanguageTechnology/comments/ktmhnu/if_i_am_processing_pdfs_and_are_formatted/,LanguageTechnology,t3_ktmhnu,"If I am processing pdfs and are formatted incorrectly, what algorithm should I use? Most of my pdfs are fine. However, some the text is not formatted correctly.",160
954,954,Universal Sentence Encoder large not working?,"The large universal sentence encoder was updated today and it seems to no longer be working, I'm trying to load it in colab and it doesn't ever stop loading.

&amp;#x200B;

Does anyone know anything about this?",https://www.reddit.com/r/LanguageTechnology/comments/ktal3s/universal_sentence_encoder_large_not_working/,LanguageTechnology,t3_ktal3s,"Universal Sentence Encoder large not working? The large universal sentence encoder was updated today and it seems to no longer be working, I'm trying to load it in colab and it doesn't ever stop loading.

&amp;#x200B;

Does anyone know anything about this?",256
955,955,How to go about building a word list (subset of english word).,"With the knowledge that we now have of language embedding like BERT I was wondering if there exist a better way to select for example the top 5000 must useful english word.  


This have traditionally been done by simply sorting by word frequency.  
But this have many problem:  
1- word like ""stick"" have multiple meaning which increase the frequency by grouping them under the same count. ex: a) Popsicle sticks b) ""just stick that sandwich on my desk"" c) up the stick (pregnant) ...  
2- word have synonyms that are not grouped together   
3- word at different tense are not grouped together (is vs has), (go vs going) (be vs been)  


I am curious if anyone have explored tagging word usage in a corpus with its meaning before taking a count the the usage frequency?  
Have anyone used some alternative approach to select a subset of word, for example if you wanted to produce a pocket english dictionary.",https://www.reddit.com/r/LanguageTechnology/comments/ktcz4r/how_to_go_about_building_a_word_list_subset_of/,LanguageTechnology,t3_ktcz4r,"How to go about building a word list (subset of english word). With the knowledge that we now have of language embedding like BERT I was wondering if there exist a better way to select for example the top 5000 must useful english word.  


This have traditionally been done by simply sorting by word frequency.  
But this have many problem:  
1- word like ""stick"" have multiple meaning which increase the frequency by grouping them under the same count. ex: a) Popsicle sticks b) ""just stick that sandwich on my desk"" c) up the stick (pregnant) ...  
2- word have synonyms that are not grouped together   
3- word at different tense are not grouped together (is vs has), (go vs going) (be vs been)  


I am curious if anyone have explored tagging word usage in a corpus with its meaning before taking a count the the usage frequency?  
Have anyone used some alternative approach to select a subset of word, for example if you wanted to produce a pocket english dictionary.",972
956,956,Extrapolating Materials Science domain knowledge through context-free embeddings.,"[https://www.sciencedirect.com/science/article/pii/S2589004220311196](https://www.sciencedirect.com/science/article/pii/S2589004220311196)

This paper talks about how context-free word embeddings can capture the domain knowledge in a corpus of papers and can be used to extrapolate the same by finding novel polymers for existing applications.

Let me know what you think!",https://www.reddit.com/r/LanguageTechnology/comments/kt83z6/extrapolating_materials_science_domain_knowledge/,LanguageTechnology,t3_kt83z6,"Extrapolating Materials Science domain knowledge through context-free embeddings. [https://www.sciencedirect.com/science/article/pii/S2589004220311196](https://www.sciencedirect.com/science/article/pii/S2589004220311196)

This paper talks about how context-free word embeddings can capture the domain knowledge in a corpus of papers and can be used to extrapolate the same by finding novel polymers for existing applications.

Let me know what you think!",454
957,957,Minimum number of samples for encoder-decoder models?,"Hi,

Is there any research or empirical rule of thumb for minimum number of text pairs needed to train an encoder-decoder style model (seq2seq LSTM, BART, T5, etc.)?",https://www.reddit.com/r/LanguageTechnology/comments/kt4xix/minimum_number_of_samples_for_encoderdecoder/,LanguageTechnology,t3_kt4xix,"Minimum number of samples for encoder-decoder models? Hi,

Is there any research or empirical rule of thumb for minimum number of text pairs needed to train an encoder-decoder style model (seq2seq LSTM, BART, T5, etc.)?",219
958,958,Masters in LT - Sweden - Any and all advice welcome,"Hello! 

I know this is a little late, but I was looking for some opinions/suggestions on this dilemma I'm facing: 

I'm applying for a masters in language technology and I currently have 2 Swedish programs that I'm confused about: the masters programs at Uppsala and Gothenburg. While the Gothenburg syllabus looks more interesting with fun profs and labs to be around, Uppsala offers more (2-3 as opposed to 1) options in terms of funding. Both require that they be my first choice if I am to be considered for funding, and I need some form of funding if I'm not to drown in student debt. 

My background: I'm from South Asia and currently finishing up a master's in English with an 8-pointer GPA. I've done half a dozen courses in linguistics and I know some C++ (only the basics - functions, data structures, loops, sorting, recursion that sort of thing). I also know some calculus, probability, and basic linear algebra. I do not have related research or internship experience.

I understand that this background is as such kinda poor and that the programs I'm applying to are very competitive, but any and all help is appreciated. Especially because Gothenburg says that only one applicant out of all fee paying applicants will be awarded the Axel Adler scholarship, I wanted to know if by opting for Uppsala as my first choice I might be losing out on much in terms of what Gothenburg has to offer. What I'm hoping to do if I get accepted is to pick up enough math and programming for an industrial career as opposed to an academic one, and I'm looking for a program that has good teachers and facilities as opposed to say, all repute but no teaching. 

Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/kswlx8/masters_in_lt_sweden_any_and_all_advice_welcome/,LanguageTechnology,t3_kswlx8,"Masters in LT - Sweden - Any and all advice welcome Hello! 

I know this is a little late, but I was looking for some opinions/suggestions on this dilemma I'm facing: 

I'm applying for a masters in language technology and I currently have 2 Swedish programs that I'm confused about: the masters programs at Uppsala and Gothenburg. While the Gothenburg syllabus looks more interesting with fun profs and labs to be around, Uppsala offers more (2-3 as opposed to 1) options in terms of funding. Both require that they be my first choice if I am to be considered for funding, and I need some form of funding if I'm not to drown in student debt. 

My background: I'm from South Asia and currently finishing up a master's in English with an 8-pointer GPA. I've done half a dozen courses in linguistics and I know some C++ (only the basics - functions, data structures, loops, sorting, recursion that sort of thing). I also know some calculus, probability, and basic linear algebra. I do not have related research or internship experience.

I understand that this background is as such kinda poor and that the programs I'm applying to are very competitive, but any and all help is appreciated. Especially because Gothenburg says that only one applicant out of all fee paying applicants will be awarded the Axel Adler scholarship, I wanted to know if by opting for Uppsala as my first choice I might be losing out on much in terms of what Gothenburg has to offer. What I'm hoping to do if I get accepted is to pick up enough math and programming for an industrial career as opposed to an academic one, and I'm looking for a program that has good teachers and facilities as opposed to say, all repute but no teaching. 

Thanks!",1720
959,959,How to construct a taxonomy from news articles?,I am trying to build a taxonomic representation of football related stuffs from football news articles.,https://www.reddit.com/r/LanguageTechnology/comments/ksx59h/how_to_construct_a_taxonomy_from_news_articles/,LanguageTechnology,t3_ksx59h,How to construct a taxonomy from news articles? I am trying to build a taxonomic representation of football related stuffs from football news articles.,151
960,960,Introduction to Rasa: the NLU chatbot framework,,https://shyambhu20.blogspot.com/2021/01/introduction-to-rasa-nlu-chatbot.html,LanguageTechnology,t3_ksporj,Introduction to Rasa: the NLU chatbot framework ,48
961,961,"500 AI, Machine learning, Deep learning, Computer vision, and NLP Projects with code",,https://github.com/ashishpatel26/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code,LanguageTechnology,t3_ksgusq,"500 AI, Machine learning, Deep learning, Computer vision, and NLP Projects with code ",85
962,962,VSCode NLP++ Language Extension Released,"A VSCode Language Extension for NLP++ has been released in the VisualStudio Marketplace.  NLP++ is a open source computer language specifically dedicated to creating text analyzers that mimic human readers and includes the NLP++ language and knowledge based system called the ""conceptual grammar"". NLP++ is used for any type of text processing from simple tagging or extraction, to full language parsing. There is a full English parser that is free an available for use. More information can be found at [http://visualtext.org](http://visualtext.org).",https://www.reddit.com/r/LanguageTechnology/comments/ksm3vc/vscode_nlp_language_extension_released/,LanguageTechnology,t3_ksm3vc,"VSCode NLP++ Language Extension Released A VSCode Language Extension for NLP++ has been released in the VisualStudio Marketplace.  NLP++ is a open source computer language specifically dedicated to creating text analyzers that mimic human readers and includes the NLP++ language and knowledge based system called the ""conceptual grammar"". NLP++ is used for any type of text processing from simple tagging or extraction, to full language parsing. There is a full English parser that is free an available for use. More information can be found at [http://visualtext.org](http://visualtext.org).",592
963,963,How to Fine-tune / Use GPT-3 Alternatives for Text Generation,"I'm new to NLP, and I'm trying to find an open-source alternative to GPT-3, which I've been using for text generation. I've been using prompt programming to give GPT-3 some examples of emails and have it generate one for me based on parameters I indicate. I'm looking for a way to do the same in the easiest and cheapest manner. I know that T5, Bert, and GPT-2 are all potential alternatives that require fine-tuning on my use case, but I don't exactly know what that entails (other than the fact I probably need a GPU). Can anyone shed some light?",https://www.reddit.com/r/LanguageTechnology/comments/ksjuo5/how_to_finetune_use_gpt3_alternatives_for_text/,LanguageTechnology,t3_ksjuo5,"How to Fine-tune / Use GPT-3 Alternatives for Text Generation I'm new to NLP, and I'm trying to find an open-source alternative to GPT-3, which I've been using for text generation. I've been using prompt programming to give GPT-3 some examples of emails and have it generate one for me based on parameters I indicate. I'm looking for a way to do the same in the easiest and cheapest manner. I know that T5, Bert, and GPT-2 are all potential alternatives that require fine-tuning on my use case, but I don't exactly know what that entails (other than the fact I probably need a GPU). Can anyone shed some light?",610
964,964,Rank text by structural similarity?,"I’m trying to solve a problem where I have 10 sentences that all mean the same thing (semantically very similar). 

Given a different, somewhat semantically similar sentence, how can I find the most structurally similar sentence out of the 10?

First thoughts are searching for occurrences of punctuation, words like “the”, etc., but is there a better way (or better yet, an API) to do this?",https://www.reddit.com/r/LanguageTechnology/comments/ksg1ey/rank_text_by_structural_similarity/,LanguageTechnology,t3_ksg1ey,"Rank text by structural similarity? I’m trying to solve a problem where I have 10 sentences that all mean the same thing (semantically very similar). 

Given a different, somewhat semantically similar sentence, how can I find the most structurally similar sentence out of the 10?

First thoughts are searching for occurrences of punctuation, words like “the”, etc., but is there a better way (or better yet, an API) to do this?",427
965,965,The Curious Case of Neural Text DeGeneration | Research Paper Walkthrough,"This ICLR 2020 paper introduces a novel text decoding strategy called Nucleus Sampling (Top-p sampling). This strategy overcomes the limitation of generating bland, repetitive and incoherent long text from other decoding strategies like Beam Search, Top-k sampling, etc. 🔥 

Watch Paper Walkthrough: https://youtu.be/dCORspO2yVY


⏩ Paper Title: The Curious Case of Neural Text Degeneration
⏩ Paper: https://arxiv.org/abs/1904.09751
⏩ Author: Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi
⏩ Organisation: Allen School of Computer Science &amp; Engineering, University of Washington, Allen Institute for Artificial Intelligence, University of Cape Town",https://www.reddit.com/r/LanguageTechnology/comments/ksflp5/the_curious_case_of_neural_text_degeneration/,LanguageTechnology,t3_ksflp5,"The Curious Case of Neural Text DeGeneration | Research Paper Walkthrough This ICLR 2020 paper introduces a novel text decoding strategy called Nucleus Sampling (Top-p sampling). This strategy overcomes the limitation of generating bland, repetitive and incoherent long text from other decoding strategies like Beam Search, Top-k sampling, etc. 🔥 

Watch Paper Walkthrough: https://youtu.be/dCORspO2yVY


⏩ Paper Title: The Curious Case of Neural Text Degeneration
⏩ Paper: https://arxiv.org/abs/1904.09751
⏩ Author: Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi
⏩ Organisation: Allen School of Computer Science &amp; Engineering, University of Washington, Allen Institute for Artificial Intelligence, University of Cape Town",737
966,966,"Has anyone deployed a BERT like model across multiple tasks (Multi-class, NER, outlier detection)? Seeking advice.","So I have a custom pre-trained RoBERTa model that I want to fine tune with NER, multi class classification, and outlier / new class detection.  Currently using Huggingface Transformers for pre-training and fine-tuning.

I’ve recently realized that naively fine tuning on each task separately would require loading in 3 instances of the pre trained model.  My understanding is that fine tuning makes small adjustments to the embedding layers.  Fine tuning separately but using the initial embedding may take a hit to performance.  

Any thoughts or experience on fine tuning across all 3 tasks simultaneously? Or maybe some hacky approach?  Also, if anyone has anyone insights on parameter tuning (specifically BPE vocab size), scheduling, or noising.  Any help would be much appreciated!",https://www.reddit.com/r/LanguageTechnology/comments/krumbu/has_anyone_deployed_a_bert_like_model_across/,LanguageTechnology,t3_krumbu,"Has anyone deployed a BERT like model across multiple tasks (Multi-class, NER, outlier detection)? Seeking advice. So I have a custom pre-trained RoBERTa model that I want to fine tune with NER, multi class classification, and outlier / new class detection.  Currently using Huggingface Transformers for pre-training and fine-tuning.

I’ve recently realized that naively fine tuning on each task separately would require loading in 3 instances of the pre trained model.  My understanding is that fine tuning makes small adjustments to the embedding layers.  Fine tuning separately but using the initial embedding may take a hit to performance.  

Any thoughts or experience on fine tuning across all 3 tasks simultaneously? Or maybe some hacky approach?  Also, if anyone has anyone insights on parameter tuning (specifically BPE vocab size), scheduling, or noising.  Any help would be much appreciated!",902
967,967,NLP in 2020: The Year In Review,,https://www.linkedin.com/pulse/natural-language-processing-2020-year-review-ivan-bilan,LanguageTechnology,t3_krkmif,NLP in 2020: The Year In Review ,32
968,968,Free NLP assignments,"NLP educators-- I made some free mastery-based assignments to reinforce learning in your NLP classes this semester. These assignments leverage cognitive neuroscience principles proven to optimize knowledge retention &amp; adapt to unique student needs:

[https://docs.google.com/document/d/1PJPc8mTdkm-QSwN4FCjjTxEup7npqE-uUNwz4uhdtzM/edit?usp=sharing](https://docs.google.com/document/d/1PJPc8mTdkm-QSwN4FCjjTxEup7npqE-uUNwz4uhdtzM/edit?usp=sharing)",https://www.reddit.com/r/LanguageTechnology/comments/krb5vq/free_nlp_assignments/,LanguageTechnology,t3_krb5vq,"Free NLP assignments NLP educators-- I made some free mastery-based assignments to reinforce learning in your NLP classes this semester. These assignments leverage cognitive neuroscience principles proven to optimize knowledge retention &amp; adapt to unique student needs:

[https://docs.google.com/document/d/1PJPc8mTdkm-QSwN4FCjjTxEup7npqE-uUNwz4uhdtzM/edit?usp=sharing](https://docs.google.com/document/d/1PJPc8mTdkm-QSwN4FCjjTxEup7npqE-uUNwz4uhdtzM/edit?usp=sharing)",471
969,969,OpenAI's DALL·E: Creating Images from Text - Explained,,https://youtu.be/UfAE-1vdj_E,LanguageTechnology,t3_kri32o,OpenAI's DALL·E: Creating Images from Text - Explained ,55
970,970,Best way to work into an NLP/Computational Linguist career?,"Hi all, I hope I’ve posted this in the right place! I’ve just graduated with an undergraduate degree in linguistics with hopes to do my masters in computational linguistics, but was ultimately unsuccessful with getting into a graduate program. I have basic experience with python, R, foma, and took computational ling courses during my degree so I’m a bit familiar with CYK, FSTs, etc. I’m just wondering if there’s any entry level job I could do with little experience/no masters that would keep me in the area of computational lingusitics/NLP, or if anyone else has had any success or advice about this sort of situation? Thanks so much :)",https://www.reddit.com/r/LanguageTechnology/comments/o0ut84/best_way_to_work_into_an_nlpcomputational/,LanguageTechnology,t3_o0ut84,"Best way to work into an NLP/Computational Linguist career? Hi all, I hope I’ve posted this in the right place! I’ve just graduated with an undergraduate degree in linguistics with hopes to do my masters in computational linguistics, but was ultimately unsuccessful with getting into a graduate program. I have basic experience with python, R, foma, and took computational ling courses during my degree so I’m a bit familiar with CYK, FSTs, etc. I’m just wondering if there’s any entry level job I could do with little experience/no masters that would keep me in the area of computational lingusitics/NLP, or if anyone else has had any success or advice about this sort of situation? Thanks so much :)",701
971,971,Big tech fails to recognize African languages | DW News,,https://www.youtube.com/watch?v=iU0Lj-mR9DQ,LanguageTechnology,t3_o0dsly,Big tech fails to recognize African languages | DW News ,56
972,972,"As a part of Pincone, a bookmark manager, we added auto-labeling of websites and wrote a bit about how we did it.",,https://pincone.com/blog/unsupervised-auto-labeling-of-websites,LanguageTechnology,t3_o0ehx9,"As a part of Pincone, a bookmark manager, we added auto-labeling of websites and wrote a bit about how we did it. ",114
973,973,[D] Hugging Face has released an official course,,/r/MachineLearning/comments/o04ort/d_hugging_face_has_released_an_official_course/,LanguageTechnology,t3_o0f54a,[D] Hugging Face has released an official course ,49
974,974,"HemingwAI, the API writing text with you is looking for feedback","Hey fellow NLPlers,

I'd love to ask you for some feedback on our NLG project, as we have just released our documentation to our AI copywriter API!

Now we are inviting developers to test out the current platform. Feedback from you is gold for us as we are trying to better understand where we can generate value in your daily needs! And please do share it with people which would enjoy our work!

**How we got started?**

We are two NLG Enthusiasts in Berlin who wanted to take away the complexity till somebody could leverage some of the newest GPT models. Hence, we built an infrastructure to get your AI copywriter ready in a matter of minutes!

What started as a GUI to validate that individuals and businesses show interest in natural language generation is now also just one API request away.

Please ask me any question in the chat below or on twitter via dom\_does.

Links for accessing HemingwAI API.

Documentation: [https://textcortex.com/documentation/api](https://textcortex.com/documentation/api)

Github: [https://github.com/textcortex/hemingwai](https://github.com/textcortex/hemingwai)",https://www.reddit.com/r/LanguageTechnology/comments/o0bpf6/hemingwai_the_api_writing_text_with_you_is/,LanguageTechnology,t3_o0bpf6,"HemingwAI, the API writing text with you is looking for feedback Hey fellow NLPlers,

I'd love to ask you for some feedback on our NLG project, as we have just released our documentation to our AI copywriter API!

Now we are inviting developers to test out the current platform. Feedback from you is gold for us as we are trying to better understand where we can generate value in your daily needs! And please do share it with people which would enjoy our work!

**How we got started?**

We are two NLG Enthusiasts in Berlin who wanted to take away the complexity till somebody could leverage some of the newest GPT models. Hence, we built an infrastructure to get your AI copywriter ready in a matter of minutes!

What started as a GUI to validate that individuals and businesses show interest in natural language generation is now also just one API request away.

Please ask me any question in the chat below or on twitter via dom\_does.

Links for accessing HemingwAI API.

Documentation: [https://textcortex.com/documentation/api](https://textcortex.com/documentation/api)

Github: [https://github.com/textcortex/hemingwai](https://github.com/textcortex/hemingwai)",1168
975,975,How to fine-tune with BertForPretraining,,https://youtube.com/watch?v=IC9FaVPKlYc&amp;feature=share,LanguageTechnology,t3_o0hr4a,How to fine-tune with BertForPretraining ,41
976,976,Research project: Free text to excel output,"Hi all,

I'm new to machine learning so please bear with me and forgive me for my ignorance.

I am working with medical data, specifically radiology reports. One of my potential projects hopes to take free text and be able to capture specific anatomy and their measurements, and output it into an excel in an organized fashion. For instance, would it be possible to identify the thoracic and abdominal aorta within free text, see their maximum measurements, and to output it into an excel report? 

I have already annotated all the free text reports with the anatomy and measurements of interest. How would I go about finding the correct machine learning algorithm and start training it to properly identify what I am looking for? If anyone could help point me in the right direction to get started, I would be so very grateful. Thank you",https://www.reddit.com/r/LanguageTechnology/comments/o0eski/research_project_free_text_to_excel_output/,LanguageTechnology,t3_o0eski,"Research project: Free text to excel output Hi all,

I'm new to machine learning so please bear with me and forgive me for my ignorance.

I am working with medical data, specifically radiology reports. One of my potential projects hopes to take free text and be able to capture specific anatomy and their measurements, and output it into an excel in an organized fashion. For instance, would it be possible to identify the thoracic and abdominal aorta within free text, see their maximum measurements, and to output it into an excel report? 

I have already annotated all the free text reports with the anatomy and measurements of interest. How would I go about finding the correct machine learning algorithm and start training it to properly identify what I am looking for? If anyone could help point me in the right direction to get started, I would be so very grateful. Thank you",882
977,977,Can't run 124M using transformers,"I have downloaded gpt 124M on my local machine and i was able to run the [interactivesample.py](https://interactivesample.py) that was provided by them

&amp;#x200B;

But when i try to load 124M using transformers, i get following error:

*\_OSError: Can't load config for 'models\\124M'. Make sure that:*



*- 'models\\124M' is a correct model identifier listed on '*[*https://huggingface.co/models*](https://huggingface.co/models)*'*



*- or 'models\\124M' is the correct path to a directory containing a config.json file\_*

&amp;#x200B;

**\*\*My code:\*\***

tokenizer = AutoTokenizer.from\_pretrained(""models\\\\124M"")

&amp;#x200B;

124M contains following json file : encoder",https://www.reddit.com/r/LanguageTechnology/comments/o0iccg/cant_run_124m_using_transformers/,LanguageTechnology,t3_o0iccg,"Can't run 124M using transformers I have downloaded gpt 124M on my local machine and i was able to run the [interactivesample.py](https://interactivesample.py) that was provided by them

&amp;#x200B;

But when i try to load 124M using transformers, i get following error:

*\_OSError: Can't load config for 'models\\124M'. Make sure that:*



*- 'models\\124M' is a correct model identifier listed on '*[*https://huggingface.co/models*](https://huggingface.co/models)*'*



*- or 'models\\124M' is the correct path to a directory containing a config.json file\_*

&amp;#x200B;

**\*\*My code:\*\***

tokenizer = AutoTokenizer.from\_pretrained(""models\\\\124M"")

&amp;#x200B;

124M contains following json file : encoder",719
978,978,Best learning resources,"Hi all, I am currently working through a “Build ChatBots with Python” course on Codecademy which obviously spends some time on NLP. However, as a Python beginner, I feel like their explanations on a lot of topics are glazed over leaving me confused. Thus I am looking for some beginner-friendly resources I can use to supplement my course. Ultimately I want to be able to program my own chatbots with Python, and am fascinated by NLP, linguistics, and machine learning. I am open to online courses, projects to work through, YouTube videos, books, etc. Thanks in advance!",https://www.reddit.com/r/LanguageTechnology/comments/o0hco1/best_learning_resources/,LanguageTechnology,t3_o0hco1,"Best learning resources Hi all, I am currently working through a “Build ChatBots with Python” course on Codecademy which obviously spends some time on NLP. However, as a Python beginner, I feel like their explanations on a lot of topics are glazed over leaving me confused. Thus I am looking for some beginner-friendly resources I can use to supplement my course. Ultimately I want to be able to program my own chatbots with Python, and am fascinated by NLP, linguistics, and machine learning. I am open to online courses, projects to work through, YouTube videos, books, etc. Thanks in advance!",595
979,979,"Open Source Grammar Correction Service with Gramformer- Google Collab, fastapi,pyngrok -Python demo",,https://youtu.be/3rKmeAf2p0A,LanguageTechnology,t3_o0ggfs,"Open Source Grammar Correction Service with Gramformer- Google Collab, fastapi,pyngrok -Python demo ",100
980,980,My first contribution into hugging face,"I have finetune wav2vec2 large xlsr53 on WOLOF audio data set, for more info visit the [here](https://huggingface.co/kingabzpro/wav2vec2-large-xlsr-53-wolof). You can also check my [Github](https://github.com/kingabzpro/WOLOF-ASR-Wav2Vec2) repo. You can also look at my [Kaggle](https://www.kaggle.com/kingabzpro/fine-tuning-xlsr-wav2vec2-for-wolof-asr-with) notebook.",https://www.reddit.com/r/LanguageTechnology/comments/nzwin4/my_first_contribution_into_hugging_face/,LanguageTechnology,t3_nzwin4,"My first contribution into hugging face I have finetune wav2vec2 large xlsr53 on WOLOF audio data set, for more info visit the [here](https://huggingface.co/kingabzpro/wav2vec2-large-xlsr-53-wolof). You can also check my [Github](https://github.com/kingabzpro/WOLOF-ASR-Wav2Vec2) repo. You can also look at my [Kaggle](https://www.kaggle.com/kingabzpro/fine-tuning-xlsr-wav2vec2-for-wolof-asr-with) notebook.",408
981,981,Edinburgh or U Washington NLP Masters? accepted and need help deciding.,"Hi, I'm into both U of Washington and U of Edinburgh for NLP Master's and Master's of Speech and Language Processing, respectively. Washington is remote and tuition is 40k (and 1 year in duration if full-time) and Edinburgh seems to be 1 year + dissertation at 60k for tuition. I was hoping to get some insight on which path would be more lucrative considering the costs, as well as U wash having an internship option. I am certain I want to continue onwards to industry as opposed to PHD if that helps. My concerns are getting a degree from an overseas uni, as well as slight concern about the tuition. I am a new grad (May 2021) and realized I need further education for most NLP positions in the US. 

Thank you everyone in this community for your help!",https://www.reddit.com/r/LanguageTechnology/comments/nzurca/edinburgh_or_u_washington_nlp_masters_accepted/,LanguageTechnology,t3_nzurca,"Edinburgh or U Washington NLP Masters? accepted and need help deciding. Hi, I'm into both U of Washington and U of Edinburgh for NLP Master's and Master's of Speech and Language Processing, respectively. Washington is remote and tuition is 40k (and 1 year in duration if full-time) and Edinburgh seems to be 1 year + dissertation at 60k for tuition. I was hoping to get some insight on which path would be more lucrative considering the costs, as well as U wash having an internship option. I am certain I want to continue onwards to industry as opposed to PHD if that helps. My concerns are getting a degree from an overseas uni, as well as slight concern about the tuition. I am a new grad (May 2021) and realized I need further education for most NLP positions in the US. 

Thank you everyone in this community for your help!",828
982,982,Fine-tuning the larger GPT Neo models(1.3B and 2.7B) with a Jupyter notebook,"Normally, only fine-tuning the 125M GPT Neo model is possible due to the fact that even that model uses over 10GB of VRAM, and the 1.3B and 2.7B taking much more. By following this video and the provided Jupyter notebook, it is possible to fine-tune the larger GPT Neo models on high-end consumer hardware or on cheap cloud options

[https://www.youtube.com/watch?v=Igr1tP8WaRc](https://www.youtube.com/watch?v=Igr1tP8WaRc)",https://www.reddit.com/r/LanguageTechnology/comments/nzzfjl/finetuning_the_larger_gpt_neo_models13b_and_27b/,LanguageTechnology,t3_nzzfjl,"Fine-tuning the larger GPT Neo models(1.3B and 2.7B) with a Jupyter notebook Normally, only fine-tuning the 125M GPT Neo model is possible due to the fact that even that model uses over 10GB of VRAM, and the 1.3B and 2.7B taking much more. By following this video and the provided Jupyter notebook, it is possible to fine-tune the larger GPT Neo models on high-end consumer hardware or on cheap cloud options

[https://www.youtube.com/watch?v=Igr1tP8WaRc](https://www.youtube.com/watch?v=Igr1tP8WaRc)",500
983,983,Should you use MT5 instead of T5 for every non-english task?,"I was looking at the T5 transformer model and was thinking about using it for a german generation task. This model seems really powerful but it is only trained for English. Then I found the multilingual T5 model which supports many languages. Is this way better for the non-english tasks (for example paraphrase generation in my case)? I am confused because the T5 model is able to translate from English to German, it can be trained on other languages etc.",https://www.reddit.com/r/LanguageTechnology/comments/o06vpi/should_you_use_mt5_instead_of_t5_for_every/,LanguageTechnology,t3_o06vpi,"Should you use MT5 instead of T5 for every non-english task? I was looking at the T5 transformer model and was thinking about using it for a german generation task. This model seems really powerful but it is only trained for English. Then I found the multilingual T5 model which supports many languages. Is this way better for the non-english tasks (for example paraphrase generation in my case)? I am confused because the T5 model is able to translate from English to German, it can be trained on other languages etc.",518
984,984,Researchers From Bangladesh University And UCLA Use AI To Develop A Framework (Text2App) To Create Android Apps From Text Descriptions,"A team of Researchers at BUET (Bangladesh University of Engineering and Technology) and UCLA (University of California- Los Angeles) has created a [framework that can be used to develop Android applications from text descriptions.](https://arxiv.org/pdf/2104.08301.pdf)

According to Masum Hasan, a researcher who carried out the study, their team wondered whether a full-fledged software could be built from natural language specification. Almost all the existing models for creating software based on text descriptions are based on end-to-end neural machine translation (NMT) models, which are similar to the one behind Google Translate. Usually, these models use NMT frameworks to translate human language into a source code.

Summary: https://www.marktechpost.com/2021/06/14/researchers-from-bangladesh-university-and-ucla-use-ai-to-develop-a-framework-text2app-to-create-android-apps-from-text-descriptions/

Paper: https://arxiv.org/pdf/2104.08301.pdf

Github: https://text2app.github.io/",https://www.reddit.com/r/LanguageTechnology/comments/o06asl/researchers_from_bangladesh_university_and_ucla/,LanguageTechnology,t3_o06asl,"Researchers From Bangladesh University And UCLA Use AI To Develop A Framework (Text2App) To Create Android Apps From Text Descriptions A team of Researchers at BUET (Bangladesh University of Engineering and Technology) and UCLA (University of California- Los Angeles) has created a [framework that can be used to develop Android applications from text descriptions.](https://arxiv.org/pdf/2104.08301.pdf)

According to Masum Hasan, a researcher who carried out the study, their team wondered whether a full-fledged software could be built from natural language specification. Almost all the existing models for creating software based on text descriptions are based on end-to-end neural machine translation (NMT) models, which are similar to the one behind Google Translate. Usually, these models use NMT frameworks to translate human language into a source code.

Summary: https://www.marktechpost.com/2021/06/14/researchers-from-bangladesh-university-and-ucla-use-ai-to-develop-a-framework-text2app-to-create-android-apps-from-text-descriptions/

Paper: https://arxiv.org/pdf/2104.08301.pdf

Github: https://text2app.github.io/",1129
985,985,"I want to learn about Language, Linguistics, Etymology, and everything in between in one book. Any recommendations. Bonus points if it's computationally relevant.","I hate ending up going in google spirals , forgetting terms, confusing terms. I am only talking about books for English and maybe any Arabic letter languages although only Eng is necessary.

Research papers and articles are welcome as well.",https://www.reddit.com/r/LanguageTechnology/comments/nzinae/i_want_to_learn_about_language_linguistics/,LanguageTechnology,t3_nzinae,"I want to learn about Language, Linguistics, Etymology, and everything in between in one book. Any recommendations. Bonus points if it's computationally relevant. I hate ending up going in google spirals , forgetting terms, confusing terms. I am only talking about books for English and maybe any Arabic letter languages although only Eng is necessary.

Research papers and articles are welcome as well.",403
986,986,BERT: How to do sentiment analysis on a custom dataset?,"Hello,

I have seen his sentiment analysis tutorial here: [https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment?text=I+like+you.+I+love+you](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment?text=I+like+you.+I+love+you)

Now, I was wondering, how do I do such a task using my own dataset? I have list of different sentences and I want to find out the sentiment of each sentence, which can be either ""happy"", ""sad"" or ""angry"". 

Do I need to fine tune BERT with my own data? If  so, how?

Thanks.",https://www.reddit.com/r/LanguageTechnology/comments/nznn4m/bert_how_to_do_sentiment_analysis_on_a_custom/,LanguageTechnology,t3_nznn4m,"BERT: How to do sentiment analysis on a custom dataset? Hello,

I have seen his sentiment analysis tutorial here: [https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment?text=I+like+you.+I+love+you](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment?text=I+like+you.+I+love+you)

Now, I was wondering, how do I do such a task using my own dataset? I have list of different sentences and I want to find out the sentiment of each sentence, which can be either ""happy"", ""sad"" or ""angry"". 

Do I need to fine tune BERT with my own data? If  so, how?

Thanks.",592
987,987,Gpt 2 124m using transformers,"I downloaded gpt 124 M and i was able to run the interactive sample file.
How can I run 124M using transformers.
While running:
Auto tokenizer. Frompretrained(""c:\\path\\124M"")

I get an error :configuration not found.

Note:124 M contains encoder. Json, hoarams. Json,... Etc.",https://www.reddit.com/r/LanguageTechnology/comments/nzudh7/gpt_2_124m_using_transformers/,LanguageTechnology,t3_nzudh7,"Gpt 2 124m using transformers I downloaded gpt 124 M and i was able to run the interactive sample file.
How can I run 124M using transformers.
While running:
Auto tokenizer. Frompretrained(""c:\\path\\124M"")

I get an error :configuration not found.

Note:124 M contains encoder. Json, hoarams. Json,... Etc.",307
988,988,Energy-Based Models for Code Generation under Compilability Constraints,,https://arxiv.org/pdf/2106.04985.pdf,LanguageTechnology,t3_nzyir7,Energy-Based Models for Code Generation under Compilability Constraints ,72
989,989,Looking for medical audio/transcription dataset for training STT model with DeepSpeech.,"I’m working on training a STT model with DeepSpeech that is based on a pre-trained model but will specialize in transcribing medical conversation (diseases, medications, etc). The most frustrating part so far has been a lack of medical audio data for training. I’m looking for high quality audio on the scale of thousands of hours with accurate transcriptions. Does anyone know if such a dataset exists?",https://www.reddit.com/r/LanguageTechnology/comments/nzp9s4/looking_for_medical_audiotranscription_dataset/,LanguageTechnology,t3_nzp9s4,"Looking for medical audio/transcription dataset for training STT model with DeepSpeech. I’m working on training a STT model with DeepSpeech that is based on a pre-trained model but will specialize in transcribing medical conversation (diseases, medications, etc). The most frustrating part so far has been a lack of medical audio data for training. I’m looking for high quality audio on the scale of thousands of hours with accurate transcriptions. Does anyone know if such a dataset exists?",491
990,990,How To Build and Deploy an NLP Model with FastAPI: Part 1,,https://hackernoon.com/how-to-build-and-deploy-an-nlp-model-with-fastapi-part-1-n5w35cj,LanguageTechnology,t3_nzglu3,How To Build and Deploy an NLP Model with FastAPI: Part 1 ,58
991,991,"This Chinese Super Scale Intelligence Model, ‘Wu Dao 2.0’, Claims To Be Trained Using 1.75 Trillion Parameters, Surpassing All Prior Models to Achieve a New Breakthrough in Deep Learning","Deep learning is one area of technology where ambitiousness has no barriers. According to a recent announcement by [The Beijing Academy of Artificial Intelligence (BAAI)](https://www.baai.ac.cn/), in China, yet another milestone has been achieved in the field with its “Wu Dao” AI system. The [GPT 3](https://www.marktechpost.com/2020/08/02/gpt-3-a-new-breakthrough-in-language-generator/) brought in new interest for all the AI researchers, the super scale pre training models. By this approach and making use of 175 billion parameters, it managed to achieve exceptional performance results across the natural language processing tasks (NLP). However, the lacking component is its inability to have any form of cognitive abilities or common sense. Therefore, despite the size, even these models cannot indulge in tasks such as open dialogues, visual reasoning, and so on. With Wu Dao, the researchers plan to address this issue. This is China’s first attempt at a home-grown super-scale intelligent model system. 

Article: [https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/](https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/?_ga=2.13897584.636390090.1623335762-488125022.1618729090)

Reference: [https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/](https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/)",https://www.reddit.com/r/LanguageTechnology/comments/nzgkbn/this_chinese_super_scale_intelligence_model_wu/,LanguageTechnology,t3_nzgkbn,"This Chinese Super Scale Intelligence Model, ‘Wu Dao 2.0’, Claims To Be Trained Using 1.75 Trillion Parameters, Surpassing All Prior Models to Achieve a New Breakthrough in Deep Learning Deep learning is one area of technology where ambitiousness has no barriers. According to a recent announcement by [The Beijing Academy of Artificial Intelligence (BAAI)](https://www.baai.ac.cn/), in China, yet another milestone has been achieved in the field with its “Wu Dao” AI system. The [GPT 3](https://www.marktechpost.com/2020/08/02/gpt-3-a-new-breakthrough-in-language-generator/) brought in new interest for all the AI researchers, the super scale pre training models. By this approach and making use of 175 billion parameters, it managed to achieve exceptional performance results across the natural language processing tasks (NLP). However, the lacking component is its inability to have any form of cognitive abilities or common sense. Therefore, despite the size, even these models cannot indulge in tasks such as open dialogues, visual reasoning, and so on. With Wu Dao, the researchers plan to address this issue. This is China’s first attempt at a home-grown super-scale intelligent model system. 

Article: [https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/](https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/?_ga=2.13897584.636390090.1623335762-488125022.1618729090)

Reference: [https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/](https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/)",1946
992,992,The NLP challenge: 5 Puzzles in 2 Weeks,"Anybody participating?   


https://www.aicrowd.com/challenges/ai-blitz-9?utm\_source=reddit&amp;utm\_medium=languagetechnology&amp;utm\_campaign=blitz9",https://www.reddit.com/r/LanguageTechnology/comments/nzfnll/the_nlp_challenge_5_puzzles_in_2_weeks/,LanguageTechnology,t3_nzfnll,"The NLP challenge: 5 Puzzles in 2 Weeks Anybody participating?   


https://www.aicrowd.com/challenges/ai-blitz-9?utm\_source=reddit&amp;utm\_medium=languagetechnology&amp;utm\_campaign=blitz9",192
993,993,Can the task of question answering ever be formulated as classification?,"Hi. I'm currently wondering if the NLP task of question answering (QA) can be formulated as classification as opposed to span extraction. For example, if I feed a model `[CLS] Where does President Roosevelt live? [SEP] CONTEXT` it seems that almost all (if not all) QA models formulate the task as span extraction and return the correct answer that's contained within the document. However, I'm curious whether we could have labels and formulate it as classification instead.

If anybody knows any papers or resources I could look into, that'd be great. Thanks!",https://www.reddit.com/r/LanguageTechnology/comments/nzb0jq/can_the_task_of_question_answering_ever_be/,LanguageTechnology,t3_nzb0jq,"Can the task of question answering ever be formulated as classification? Hi. I'm currently wondering if the NLP task of question answering (QA) can be formulated as classification as opposed to span extraction. For example, if I feed a model `[CLS] Where does President Roosevelt live? [SEP] CONTEXT` it seems that almost all (if not all) QA models formulate the task as span extraction and return the correct answer that's contained within the document. However, I'm curious whether we could have labels and formulate it as classification instead.

If anybody knows any papers or resources I could look into, that'd be great. Thanks!",634
994,994,Knowledge Graph,"Hi , i’m working on a project to build knowledge graph , so that the relationships within the document will help us to query documents with those attributes from the entire corpus.
Would like some help what methods can be used to mine relationships from the document.",https://www.reddit.com/r/LanguageTechnology/comments/nyzdmz/knowledge_graph/,LanguageTechnology,t3_nyzdmz,"Knowledge Graph Hi , i’m working on a project to build knowledge graph , so that the relationships within the document will help us to query documents with those attributes from the entire corpus.
Would like some help what methods can be used to mine relationships from the document.",283
