approved_at_utc,subreddit,selftext,author_fullname,saved,mod_reason_title,gilded,clicked,title,link_flair_richtext,subreddit_name_prefixed,hidden,pwls,link_flair_css_class,downs,top_awarded_type,hide_score,name,quarantine,link_flair_text_color,upvote_ratio,author_flair_background_color,subreddit_type,ups,total_awards_received,media_embed,author_flair_template_id,is_original_content,user_reports,secure_media,is_reddit_media_domain,is_meta,category,secure_media_embed,link_flair_text,can_mod_post,score,approved_by,is_created_from_ads_ui,author_premium,thumbnail,edited,author_flair_css_class,author_flair_richtext,gildings,content_categories,is_self,mod_note,created,link_flair_type,wls,removed_by_category,banned_by,author_flair_type,domain,allow_live_comments,selftext_html,likes,suggested_sort,banned_at_utc,url_overridden_by_dest,view_count,archived,no_follow,is_crosspostable,pinned,over_18,all_awardings,awarders,media_only,can_gild,spoiler,locked,author_flair_text,treatment_tags,visited,removed_by,num_reports,distinguished,subreddit_id,mod_reason_by,removal_reason,link_flair_background_color,id,is_robot_indexable,report_reasons,author,discussion_type,num_comments,send_replies,whitelist_status,contest_mode,mod_reports,author_patreon_flair,author_flair_text_color,permalink,parent_whitelist_status,stickied,url,subreddit_subscribers,created_utc,num_crossposts,media,is_video,crosspost_parent_list,crosspost_parent,media_metadata,author_cakeday,poll_data,is_gallery,gallery_data
,deeplearning,,t2_ap2kjhxj,False,,0,False,(Data Science Humour) I've found this to be really accurate. Making something from scratch and then moving on to libraries is the best way to learn.,[],r/deeplearning,False,6,,0,,False,t3_o0m0lk,False,dark,0.91,,public,150,0,{},,False,[],,True,False,,{},,False,150,,False,False,,False,,[],{},,False,,1623812858.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/adgnnwvx9h571.jpg,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0m0lk,True,,alan_turing8,,24,True,all_ads,False,[],False,,/r/deeplearning/comments/o0m0lk/data_science_humour_ive_found_this_to_be_really/,all_ads,False,https://i.redd.it/adgnnwvx9h571.jpg,66147,1623784058.0,0,,False,,,,,,,
,deeplearning,,t2_hmbd5,False,,0,False,Tutorial for novice: How do we make the machine automatically classify crocodiles and snakes?,[],r/deeplearning,False,6,,0,,True,t3_o15nqp,False,dark,0.43,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/EEZ_PrvqHXk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': '2. How do we make the machine automatically classify crocodiles and snakes?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/EEZ_PrvqHXk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Chier Hu', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/EEZ_PrvqHXk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ChierHu'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/EEZ_PrvqHXk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/o15nqp', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1623881060.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/EEZ_PrvqHXk,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o15nqp,True,,RossJD,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o15nqp/tutorial_for_novice_how_do_we_make_the_machine/,all_ads,False,https://youtu.be/EEZ_PrvqHXk,66147,1623852260.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': '2. How do we make the machine automatically classify crocodiles and snakes?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/EEZ_PrvqHXk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Chier Hu', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/EEZ_PrvqHXk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ChierHu'}}",False,,,,,,,
,deeplearning,"I have trained a posture analysis network to classify in a video of humans recorded in public places if there is a) shake-hand between two humans, b) Standing close together that their hands touch each other but not shake hand and c) No interaction at all. There are multiple labels to identify different parts of a human. The labels are done to train the network to spot hand-shaking in a large dataset of videos of humans recorded in public. As you can guess, this leads to an imbalanced dataset. To train, I sampled data such that 60% of my input contained handshaking images and the rest contained different images than hand-shaking. In this network, we are not looking at just labels but also the relative position of individual labels wrt to one another. We have an algorithm that can then classify them into the three classes.

&amp;#x200B;

I am stuck on how to evaluate the performance of this network. I have a large dataset and it is not labeled. So I have decided to pick 25 from class A) and B) and 50 from class (C) to create a small test dataset(with labels) to show the performance of the network. And to run the network on the large dataset without labels, but because classes A and B are quite rare events, I would be able to individually access the accuracy of the network prediction of True positive and false-positive cases.

&amp;#x200B;

Is this a sound way to evaluate ? Can anyone having experience or opinion share their input on this? How else can I evaluate this?",t2_c5febi8b,False,,0,False,Evaluating a convolutional neural network on an imbalanced (academic) dataset,[],r/deeplearning,False,6,,0,,False,t3_o14as5,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623877215.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have trained a posture analysis network to classify in a video of humans recorded in public places if there is a) shake-hand between two humans, b) Standing close together that their hands touch each other but not shake hand and c) No interaction at all. There are multiple labels to identify different parts of a human. The labels are done to train the network to spot hand-shaking in a large dataset of videos of humans recorded in public. As you can guess, this leads to an imbalanced dataset. To train, I sampled data such that 60% of my input contained handshaking images and the rest contained different images than hand-shaking. In this network, we are not looking at just labels but also the relative position of individual labels wrt to one another. We have an algorithm that can then classify them into the three classes.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am stuck on how to evaluate the performance of this network. I have a large dataset and it is not labeled. So I have decided to pick 25 from class A) and B) and 50 from class (C) to create a small test dataset(with labels) to show the performance of the network. And to run the network on the large dataset without labels, but because classes A and B are quite rare events, I would be able to individually access the accuracy of the network prediction of True positive and false-positive cases.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Is this a sound way to evaluate ? Can anyone having experience or opinion share their input on this? How else can I evaluate this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o14as5,True,,popkept09,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o14as5/evaluating_a_convolutional_neural_network_on_an/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o14as5/evaluating_a_convolutional_neural_network_on_an/,66147,1623848415.0,0,,False,,,,,,,
,deeplearning,"Hello to everyone, I have a Dockerfile with my Neural Network and a Flask API to make calls.

Do you have a tutorial on deploying this Dockerfile on a google cloud machine with GPU, with the possibility to scale it depending on the number of requests (like it happens with Cloud Run).

I know the existence of GKE, I am just wondering if there's a tutorial that goes straight to the point.

Thanks",t2_b79ww8lt,False,,0,False,deploy on google cloud GPU,[],r/deeplearning,False,6,,0,,False,t3_o134ag,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623873346.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello to everyone, I have a Dockerfile with my Neural Network and a Flask API to make calls.&lt;/p&gt;

&lt;p&gt;Do you have a tutorial on deploying this Dockerfile on a google cloud machine with GPU, with the possibility to scale it depending on the number of requests (like it happens with Cloud Run).&lt;/p&gt;

&lt;p&gt;I know the existence of GKE, I am just wondering if there&amp;#39;s a tutorial that goes straight to the point.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o134ag,True,,pemstr,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o134ag/deploy_on_google_cloud_gpu/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o134ag/deploy_on_google_cloud_gpu/,66147,1623844546.0,0,,False,,,,,,,
,deeplearning,"[Self Organizing Map](https://pythoncodingai.com/self-organizing-map/) (or Kohonen Map or SOM) is a order of [Artificial Neural](https://pythoncodingai.com/self-organizing-map/) net which is likewise heartened by consanguineous miniatures of neural complexes crystallize the 1970 ’s . It follows an unsupervised earnestness path and conditioned its net through a competitive clearness algorithm . SOM is harnessed for clustering and mapping (or measurement deduction) styles to conspire multidimensional data onto minor - dimensional which allows people to demote knotty matters for royal exposition . SOM has two layers, one is the Intake stratum and the distant one is the handiwork stratum .",t2_cr5c9b0q,False,,0,False,What is Self Organizing Map ? Meaning and Explained | Python Coding AI,[],r/deeplearning,False,6,,0,,False,t3_o10kj5,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623863294.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://pythoncodingai.com/self-organizing-map/""&gt;Self Organizing Map&lt;/a&gt; (or Kohonen Map or SOM) is a order of &lt;a href=""https://pythoncodingai.com/self-organizing-map/""&gt;Artificial Neural&lt;/a&gt; net which is likewise heartened by consanguineous miniatures of neural complexes crystallize the 1970 ’s . It follows an unsupervised earnestness path and conditioned its net through a competitive clearness algorithm . SOM is harnessed for clustering and mapping (or measurement deduction) styles to conspire multidimensional data onto minor - dimensional which allows people to demote knotty matters for royal exposition . SOM has two layers, one is the Intake stratum and the distant one is the handiwork stratum .&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o10kj5,True,,codingainp,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o10kj5/what_is_self_organizing_map_meaning_and_explained/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o10kj5/what_is_self_organizing_map_meaning_and_explained/,66147,1623834494.0,0,,False,,,,,,,
,deeplearning,,t2_c7lfuw9x,False,,0,False,Top 10 Deep Learning Algorithms One Should Know in 2021,[],r/deeplearning,False,6,,0,,False,t3_o102h2,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623861077.0,text,6,,,text,analyticsinsight.net,False,,,,,https://www.analyticsinsight.net/top-10-deep-learning-algorithms-one-should-know-in-2021/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o102h2,True,,Analyticsinsight01,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o102h2/top_10_deep_learning_algorithms_one_should_know/,all_ads,False,https://www.analyticsinsight.net/top-10-deep-learning-algorithms-one-should-know-in-2021/,66147,1623832277.0,0,,False,,,,,,,
,deeplearning,"Do you think about how Google Assistant or Apple’s Siri adhere to your guidelines? Do you see promotions for items you prior looked for on online business sites? What is Neural Network In the event that you have thought about how this all meets up, it is a result of . . . [Read more](https://pythoncodingai.com/what-is-neural-network/)",t2_cr5c9b0q,False,,0,False,"What is Neural Network: Overview, Applications, and Advantages 2021 | Python Coding AI",[],r/deeplearning,False,6,,0,,False,t3_o0zyee,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623860531.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Do you think about how Google Assistant or Apple’s Siri adhere to your guidelines? Do you see promotions for items you prior looked for on online business sites? What is Neural Network In the event that you have thought about how this all meets up, it is a result of . . . &lt;a href=""https://pythoncodingai.com/what-is-neural-network/""&gt;Read more&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0zyee,True,,codingainp,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0zyee/what_is_neural_network_overview_applications_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0zyee/what_is_neural_network_overview_applications_and/,66147,1623831731.0,0,,False,,,,,,,
,deeplearning,"TensorFlow is an open-source start to finish stage for making Machine Learning applications. It is an emblematic number related library that utilizations dataflow and differentiable programming to perform different undertakings zeroed in on preparing and surmising of profound neural organizations. It permits engineers to make AI applications utilizing different apparatuses, . . . [Read more](https://pythoncodingai.com/what-is-tensorflow-2021/)",t2_cr5c9b0q,False,,0,False,What is TensorFlow? 2021 | Python Coding AI,[],r/deeplearning,False,6,,0,,False,t3_o0zxrk,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623860444.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TensorFlow is an open-source start to finish stage for making Machine Learning applications. It is an emblematic number related library that utilizations dataflow and differentiable programming to perform different undertakings zeroed in on preparing and surmising of profound neural organizations. It permits engineers to make AI applications utilizing different apparatuses, . . . &lt;a href=""https://pythoncodingai.com/what-is-tensorflow-2021/""&gt;Read more&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0zxrk,True,,codingainp,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/o0zxrk/what_is_tensorflow_2021_python_coding_ai/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0zxrk/what_is_tensorflow_2021_python_coding_ai/,66147,1623831644.0,0,,False,,,,,,,
,deeplearning,"We don’t make another dialect each time we talk – each human language has a constant arrangement of punctuation rules and an assortment of words that we depend on to decipher it. Long Short Term Memory Networks. As you read this article, you see each word dependent on your insight . . . [Read more](https://pythoncodingai.com/long-short-term-memory-networks/)",t2_cr5c9b0q,False,,0,False,Long Short Term Memory Networks,[],r/deeplearning,False,6,,0,,False,t3_o0za4t,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623857415.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We don’t make another dialect each time we talk – each human language has a constant arrangement of punctuation rules and an assortment of words that we depend on to decipher it. Long Short Term Memory Networks. As you read this article, you see each word dependent on your insight . . . &lt;a href=""https://pythoncodingai.com/long-short-term-memory-networks/""&gt;Read more&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0za4t,True,,codingainp,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0za4t/long_short_term_memory_networks/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0za4t/long_short_term_memory_networks/,66147,1623828615.0,0,,False,,,,,,,
,deeplearning,"Almost 80% of leading small-medium IT companies consider automation tools to be the key to their business success. 92% of AI startup companies think they should rely on AI to [improve their decision-making processes](https://techcrunch.com/2021/06/09/ai-startup-investment-is-on-pace-for-a-record-year/), and 79% of these respondents said they are [already doing so](https://techcrunch.com/2021/06/09/ai-startup-investment-is-on-pace-for-a-record-year/).

And more than that, today, you can fully automate marketing. We’ll tell you what you’ll get out of it and, most importantly, how to implement it — literally, the right steps and with the right tools.

What do you think of AI-powered marketing automation? I tried to put my thoughts in a [detailed guide](https://signum.ai/blog/marketing-automation-from-a-to-z/), and I sincerely want to hear your opinion.",t2_pur71,False,,0,False,Businesses are crazy about implementing AI to accelerate their marketing performance,[],r/deeplearning,False,6,,0,,False,t3_o116dy,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623865891.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Almost 80% of leading small-medium IT companies consider automation tools to be the key to their business success. 92% of AI startup companies think they should rely on AI to &lt;a href=""https://techcrunch.com/2021/06/09/ai-startup-investment-is-on-pace-for-a-record-year/""&gt;improve their decision-making processes&lt;/a&gt;, and 79% of these respondents said they are &lt;a href=""https://techcrunch.com/2021/06/09/ai-startup-investment-is-on-pace-for-a-record-year/""&gt;already doing so&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;And more than that, today, you can fully automate marketing. We’ll tell you what you’ll get out of it and, most importantly, how to implement it — literally, the right steps and with the right tools.&lt;/p&gt;

&lt;p&gt;What do you think of AI-powered marketing automation? I tried to put my thoughts in a &lt;a href=""https://signum.ai/blog/marketing-automation-from-a-to-z/""&gt;detailed guide&lt;/a&gt;, and I sincerely want to hear your opinion.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o116dy,True,,kotik007,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o116dy/businesses_are_crazy_about_implementing_ai_to/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o116dy/businesses_are_crazy_about_implementing_ai_to/,66147,1623837091.0,0,,False,,,,,,,
,deeplearning,,t2_auwgbh53,False,,0,False,Game search engine using Neural Networks - A demo built with 17k mobile strategy game dataset,[],r/deeplearning,False,6,,0,,False,t3_o0cjxa,False,dark,0.91,,public,26,2,{},,False,[],,True,False,,{},,False,26,,False,True,,False,,[],{},,False,,1623786769.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/aixbz2d14f571.gif,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 300, 'id': 'award_28e8196b-d4e9-45bc-b612-cd4c7d3ed4b3', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=16&amp;height=16&amp;auto=webp&amp;s=9d714b25ca25d05e3310bc60bc1714ddf7951331', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=32&amp;height=32&amp;auto=webp&amp;s=d584b15c8e17d61fa8ae319a91d351c8fe35b918', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=48&amp;height=48&amp;auto=webp&amp;s=d9fb2c025611a15e6bb4437734f92db99b93fd12', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=64&amp;height=64&amp;auto=webp&amp;s=744fb200d76bf21f6e023ba98d3b4189b34973e3', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=128&amp;height=128&amp;auto=webp&amp;s=c180572afbc080622a8ac8441c3bc5214597d05a', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""When an upvote just isn't enough, smash the Rocket Like."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Rocket Like', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=16&amp;height=16&amp;auto=webp&amp;s=24fc4d912e595c3fed2ce0deef1c13f70df56056', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=32&amp;height=32&amp;auto=webp&amp;s=f9d869602e0d8b719186cc603864a42699e5c96e', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=48&amp;height=48&amp;auto=webp&amp;s=b223ac8fdd206b683b840c2782307c3f01b04fb7', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=64&amp;height=64&amp;auto=webp&amp;s=a0b840c6ecdee904012a6c53c40194733b72bca8', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=128&amp;height=128&amp;auto=webp&amp;s=b2e2ca67e067f82ff9b4ea1fe1b39395ca622894', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png'}, {'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0cjxa,True,,opensourcecolumbus,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/o0cjxa/game_search_engine_using_neural_networks_a_demo/,all_ads,False,https://i.redd.it/aixbz2d14f571.gif,66147,1623757969.0,0,,False,,,,,,,
,deeplearning,"Not that surprising - XGBoost still rocks when the underlying data is in a tabular form.

Original article here: [https://arxiv.org/pdf/2106.03253.pdf](https://arxiv.org/pdf/2106.03253.pdf)

More hard-to-find, independent stuff related to AI &amp; Data Science [here](https://thereshape.co/?utm_source=reddit).",t2_4gl6xq75,False,,0,False,Tabular Data: Deep Learning is Not All You Need,[],r/deeplearning,False,6,,0,,False,t3_o0l92k,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623810852.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Not that surprising - XGBoost still rocks when the underlying data is in a tabular form.&lt;/p&gt;

&lt;p&gt;Original article here: &lt;a href=""https://arxiv.org/pdf/2106.03253.pdf""&gt;https://arxiv.org/pdf/2106.03253.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;More hard-to-find, independent stuff related to AI &amp;amp; Data Science &lt;a href=""https://thereshape.co/?utm_source=reddit""&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0l92k,True,,rshpkamil,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0l92k/tabular_data_deep_learning_is_not_all_you_need/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0l92k/tabular_data_deep_learning_is_not_all_you_need/,66147,1623782052.0,0,,False,,,,,,,
,deeplearning,"65% of respondents don't know what their models are doing... Only 20% monitor them for fairness and ethics.

Original article here: [https://www.fico.com/blogs/its-2021-do-you-know-what-your-ai-doing](https://www.fico.com/blogs/its-2021-do-you-know-what-your-ai-doing)

More hard-to-find, independent stuff related to AI &amp; Data Science [here](https://thereshape.co/?utm_source=reddit).",t2_4gl6xq75,False,,0,False,It’s 2021. Do You Know What Your AI Is Doing?,[],r/deeplearning,False,6,,0,,False,t3_o0izhm,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623804946.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;65% of respondents don&amp;#39;t know what their models are doing... Only 20% monitor them for fairness and ethics.&lt;/p&gt;

&lt;p&gt;Original article here: &lt;a href=""https://www.fico.com/blogs/its-2021-do-you-know-what-your-ai-doing""&gt;https://www.fico.com/blogs/its-2021-do-you-know-what-your-ai-doing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;More hard-to-find, independent stuff related to AI &amp;amp; Data Science &lt;a href=""https://thereshape.co/?utm_source=reddit""&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0izhm,True,,rshpkamil,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/o0izhm/its_2021_do_you_know_what_your_ai_is_doing/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0izhm/its_2021_do_you_know_what_your_ai_is_doing/,66147,1623776146.0,0,,False,,,,,,,
,deeplearning,,t2_hkv9s,False,,0,False,Detecting Hallucinated Content in Conditional Neural Sequence Generation (NLP Paper Walkthrough),[],r/deeplearning,False,6,,0,,False,t3_o0dr7e,False,dark,0.75,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fD2g9s1Isi4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Detecting Hallucinated Content in Conditional Neural Sequence Generation (NLP Paper Walkthrough)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fD2g9s1Isi4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/fD2g9s1Isi4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fD2g9s1Isi4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/o0dr7e', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1623790706.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/fD2g9s1Isi4,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0dr7e,True,,prakhar21,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0dr7e/detecting_hallucinated_content_in_conditional/,all_ads,False,https://youtu.be/fD2g9s1Isi4,66147,1623761906.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Detecting Hallucinated Content in Conditional Neural Sequence Generation (NLP Paper Walkthrough)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fD2g9s1Isi4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/fD2g9s1Isi4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}}",False,,,,,,,
,deeplearning,"In other words, I just want to use a part of my model as an encoder somewhere else. Is there any format constraint that I must obey or is it even possible? I am assuming I have to use local model save because the two project are not related. Any help or advice would be much appreciated. thanks in advance",t2_5xf5u3ie,False,,0,False,I want to use a part of my keras model in another project,[],r/deeplearning,False,6,,0,,False,t3_o0hxhe,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623802139.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In other words, I just want to use a part of my model as an encoder somewhere else. Is there any format constraint that I must obey or is it even possible? I am assuming I have to use local model save because the two project are not related. Any help or advice would be much appreciated. thanks in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0hxhe,True,,mortuish,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0hxhe/i_want_to_use_a_part_of_my_keras_model_in_another/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0hxhe/i_want_to_use_a_part_of_my_keras_model_in_another/,66147,1623773339.0,0,,False,,,,,,,
,deeplearning,"A research team from DeepMind and Google Brain proposes Launchpad, a programming model that simplifies the process of defining and launching instances of distributed computation.   

Here is a quick read: [Google's Launchpad Programming Framework Simplifies the Distributed Computation Learning Process.](https://syncedreview.com/2021/06/15/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-41/)

The paper *Launchpad: A Programming Model for Distributed Machine Learning Research* is on [arXiv](https://arxiv.org/abs/2106.04516).",t2_2fv4yodo,False,,0,False,[R] Google's Launchpad Programming Framework Simplifies the Distributed Computation Learning Process,[],r/deeplearning,False,6,,0,,False,t3_o0hf7c,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623800789.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from DeepMind and Google Brain proposes Launchpad, a programming model that simplifies the process of defining and launching instances of distributed computation.   &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/15/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-41/""&gt;Google&amp;#39;s Launchpad Programming Framework Simplifies the Distributed Computation Learning Process.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Launchpad: A Programming Model for Distributed Machine Learning Research&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2106.04516""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0hf7c,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0hf7c/r_googles_launchpad_programming_framework/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0hf7c/r_googles_launchpad_programming_framework/,66147,1623771989.0,0,,False,,,,,,,
,deeplearning,"model.fit is too rigid to this one's tastes so he runs a tensorflow train op, but the layers have been declared using keras. The declaration includes regularizers and they don't seem to be run automatically, he has looked at keras code on github a bit but hasn't found at which point they are called. Maybe anybody knows how to do it? Probably not but why not ask =)",t2_bukbhrzs,False,,0,False,"question, how to make keras layers run regularizers without model.fit",[],r/deeplearning,False,6,,0,,False,t3_o09lt0,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623775323.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;model.fit is too rigid to this one&amp;#39;s tastes so he runs a tensorflow train op, but the layers have been declared using keras. The declaration includes regularizers and they don&amp;#39;t seem to be run automatically, he has looked at keras code on github a bit but hasn&amp;#39;t found at which point they are called. Maybe anybody knows how to do it? Probably not but why not ask =)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o09lt0,True,,ne-skwai,,5,False,all_ads,False,[],False,,/r/deeplearning/comments/o09lt0/question_how_to_make_keras_layers_run/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o09lt0/question_how_to_make_keras_layers_run/,66147,1623746523.0,0,,False,,,,,,,
,deeplearning,"Can GAN learn to increase the resolution of image ? For reference, suppose a MNIST - handwritten digits dataset (28 x 28) is fed into just an encoder and have been turned into low resolution image (around 15 x 15 maybe ). Can a GAN now be trained with the low resolution image as input and original ""high-res"" MNIST image as output so that it can recreate the high-res image for encoder generated low resolution test data ?? Help a Deep-Learning Newbie.",t2_55tkmq8g,False,,0,False,Is it possible to have different input and output sizes in GAN ?,[],r/deeplearning,False,6,,0,,False,t3_o09fx1,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1623774564.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can GAN learn to increase the resolution of image ? For reference, suppose a MNIST - handwritten digits dataset (28 x 28) is fed into just an encoder and have been turned into low resolution image (around 15 x 15 maybe ). Can a GAN now be trained with the low resolution image as input and original &amp;quot;high-res&amp;quot; MNIST image as output so that it can recreate the high-res image for encoder generated low resolution test data ?? Help a Deep-Learning Newbie.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o09fx1,True,,BakedTiger,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/o09fx1/is_it_possible_to_have_different_input_and_output/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o09fx1/is_it_possible_to_have_different_input_and_output/,66147,1623745764.0,0,,False,,,,,,,
,deeplearning,I'm looking for topics on which I can read multiple research papers and write a survey paper on. Any suggestions,t2_5id0e0q7,False,,0,False,Topics on which I can read research papers?,[],r/deeplearning,False,6,,0,,False,t3_o0assy,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623780421.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking for topics on which I can read multiple research papers and write a survey paper on. Any suggestions&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0assy,True,,rshells,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/o0assy/topics_on_which_i_can_read_research_papers/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0assy/topics_on_which_i_can_read_research_papers/,66147,1623751621.0,0,,False,,,,,,,
,deeplearning,,t2_cccdvf8f,False,,0,False,Speech AI – how to improve call center sales performance,[],r/deeplearning,False,6,,0,,False,t3_o0d4e5,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1623788664.0,text,6,,,text,addepto.com,False,,,,,https://addepto.com/how-to-improve-call-center-sales-performance-with-ai-in-speech/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0d4e5,True,,AddeptoAnalytics,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0d4e5/speech_ai_how_to_improve_call_center_sales/,all_ads,False,https://addepto.com/how-to-improve-call-center-sales-performance-with-ai-in-speech/,66147,1623759864.0,0,,False,,,,,,,
,deeplearning,"Hey fellow deep learners,

I'd love to ask you for some feedback on our NLG project, as we have just released our documentation to our AI copywriter API!

Now we are inviting developers to test out the current platform. Feedback from you is gold for us as we are trying to better understand where we can generate value in your daily needs! And please do share it with people which would enjoy our work!

**How we got started?**

We are two NLG Enthusiasts in Berlin who wanted to take away the complexity till somebody could leverage some of the newest GPT models. Hence, we built an infrastructure to get your AI copywriter ready in a matter of minutes!

What started as a GUI to validate that individuals and businesses show interest in natural language generation is now also just one API request away.

Please ask me any question in the chat below or on twitter via dom\_does.

Links for accessing HemingwAI API.

Documentation: [https://textcortex.com/documentation/api](https://textcortex.com/documentation/api)

Github: [https://github.com/textcortex/hemingwai](https://github.com/textcortex/hemingwai)

Discuss within our [Slack community](https://join.slack.com/t/textcortexaicommunity/shared_invite/zt-rmaw7j10-Lz9vf86aF5I_fYZAS7JafQ)",t2_p8q7k,False,,0,False,"HemingwAI, the API writing text with you is looking for feedback",[],r/deeplearning,False,6,,0,,False,t3_o0byh1,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1623760949.0,,[],{},,True,,1623784705.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey fellow deep learners,&lt;/p&gt;

&lt;p&gt;I&amp;#39;d love to ask you for some feedback on our NLG project, as we have just released our documentation to our AI copywriter API!&lt;/p&gt;

&lt;p&gt;Now we are inviting developers to test out the current platform. Feedback from you is gold for us as we are trying to better understand where we can generate value in your daily needs! And please do share it with people which would enjoy our work!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How we got started?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We are two NLG Enthusiasts in Berlin who wanted to take away the complexity till somebody could leverage some of the newest GPT models. Hence, we built an infrastructure to get your AI copywriter ready in a matter of minutes!&lt;/p&gt;

&lt;p&gt;What started as a GUI to validate that individuals and businesses show interest in natural language generation is now also just one API request away.&lt;/p&gt;

&lt;p&gt;Please ask me any question in the chat below or on twitter via dom_does.&lt;/p&gt;

&lt;p&gt;Links for accessing HemingwAI API.&lt;/p&gt;

&lt;p&gt;Documentation: &lt;a href=""https://textcortex.com/documentation/api""&gt;https://textcortex.com/documentation/api&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Github: &lt;a href=""https://github.com/textcortex/hemingwai""&gt;https://github.com/textcortex/hemingwai&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Discuss within our &lt;a href=""https://join.slack.com/t/textcortexaicommunity/shared_invite/zt-rmaw7j10-Lz9vf86aF5I_fYZAS7JafQ""&gt;Slack community&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0byh1,True,,kotanasu,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0byh1/hemingwai_the_api_writing_text_with_you_is/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0byh1/hemingwai_the_api_writing_text_with_you_is/,66147,1623755905.0,0,,False,,,,,,,
,deeplearning,"That's a good field of application.

I've asked in Bitcoin subreddit but they said it'd be guaranteed to fail because of external factors..",t2_93zr2qdu,False,,0,False,Any research about crypto price prediction with deep learning?,[],r/deeplearning,False,6,,0,,False,t3_o09b7o,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623773972.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;That&amp;#39;s a good field of application.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve asked in Bitcoin subreddit but they said it&amp;#39;d be guaranteed to fail because of external factors..&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o09b7o,True,,depaul9,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/o09b7o/any_research_about_crypto_price_prediction_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o09b7o/any_research_about_crypto_price_prediction_with/,66147,1623745172.0,0,,False,,,,,,,
,deeplearning,"Hello Everyone. 

I am really scratching my head to get this topic inside my brain, It's obvious that even stackoverflow and google can't give me something satisfactory on this.
So I could use your help guys. 

I know about NN, CNN, RNN , LSTM, HMM and other heavy terms used in deep learning, but still can't connect how exactly this works (Phonemes Alignment).

It will be so helpful if you could provide me something on this. 
Thanks in advance.",t2_5mworz81,False,,0,False,Phonemes Alignment is Automatic Speech Recognition (ASR)?,[],r/deeplearning,False,6,,0,,False,t3_nzr1ae,False,dark,0.94,,public,12,0,{},,False,[],,False,False,,{},,False,12,,False,False,,False,,[],{},,True,,1623717776.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello Everyone. &lt;/p&gt;

&lt;p&gt;I am really scratching my head to get this topic inside my brain, It&amp;#39;s obvious that even stackoverflow and google can&amp;#39;t give me something satisfactory on this.
So I could use your help guys. &lt;/p&gt;

&lt;p&gt;I know about NN, CNN, RNN , LSTM, HMM and other heavy terms used in deep learning, but still can&amp;#39;t connect how exactly this works (Phonemes Alignment).&lt;/p&gt;

&lt;p&gt;It will be so helpful if you could provide me something on this. 
Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzr1ae,True,,bugboy404,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nzr1ae/phonemes_alignment_is_automatic_speech/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzr1ae/phonemes_alignment_is_automatic_speech/,66147,1623688976.0,0,,False,,,,,,,
,deeplearning,"Hi everyone,

I am entering my last quarter of school and am planning on doing a Capstone project related to neural networks. I have taken an introductory course and learned about perceptrons, backprop, gradient descent, etc. The course ended right when we started talking about deep learning, unsupervised learning, and convolutions neural networks. I would like to do a project related to deep unsupervised learning and building a neural network from scratch in order to solve a certain meaningful problem. One thing that has always interested me is neural networks playing and learning video games but I would love to get some more ideas. Please link or comment some good ideas and/or any great resources regarding unsupervised learning and deep neural networks.",t2_beo5jpj9,False,,0,False,Capstone Project Ideas,[],r/deeplearning,False,6,,0,,False,t3_nzyntv,False,dark,0.67,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1623737998.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I am entering my last quarter of school and am planning on doing a Capstone project related to neural networks. I have taken an introductory course and learned about perceptrons, backprop, gradient descent, etc. The course ended right when we started talking about deep learning, unsupervised learning, and convolutions neural networks. I would like to do a project related to deep unsupervised learning and building a neural network from scratch in order to solve a certain meaningful problem. One thing that has always interested me is neural networks playing and learning video games but I would love to get some more ideas. Please link or comment some good ideas and/or any great resources regarding unsupervised learning and deep neural networks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzyntv,True,,I_love_Jesus_1,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/nzyntv/capstone_project_ideas/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzyntv/capstone_project_ideas/,66147,1623709198.0,0,,False,,,,,,,
,deeplearning,,t2_44mbtmjy,False,,0,False,State of the art in Face Swapping! (Thank you TenCent),[],r/deeplearning,False,6,,0,,False,t3_nzyaxp,False,dark,0.67,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1623737006.0,text,6,,,text,self.LatestInML,False,,,,,/r/LatestInML/comments/nzxqyj/state_of_the_art_in_face_swapping_thank_you/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzyaxp,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nzyaxp/state_of_the_art_in_face_swapping_thank_you/,all_ads,False,/r/LatestInML/comments/nzxqyj/state_of_the_art_in_face_swapping_thank_you/,66147,1623708206.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper](https://www.catalyzex.com/paper/arxiv:2106.06340)\n\nhttps://reddit.com/link/nzxqyj/video/q6cp5pf0wa571/player\n\n👇 Free extension to get code for ML papers (❤️'d by Andrew Ng) Chrome: https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil\n\nFirefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'State of the art in Face Swapping! (Thank you TenCent)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'q6cp5pf0wa571': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/nzxqyj/asset/q6cp5pf0wa571/DASHPlaylist.mpd?a=1626449039%2CODU4YWFiN2JjZjY4NzNiNWM2ZGY3MzU2NjEwMmU0OWJhMjVhZDFjMDgzMjMyNTQ4MzEzOWIzNzc5MzFiMGJkZA%3D%3D&amp;v=1&amp;f=sd', 'x': 638, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/nzxqyj/asset/q6cp5pf0wa571/HLSPlaylist.m3u8?a=1626449039%2CYjU1YTZhNDlhN2RlMDEwMThhOWUxMDhiMTQ4NWNlMTkxNzRiNDk0MmQ0ZmE2MGE3ZGZmODY0MTc5Nzg4NDc0MA%3D%3D&amp;v=1&amp;f=sd', 'id': 'q6cp5pf0wa571', 'isGif': False}}, 'name': 't3_nzxqyj', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.73, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 7, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1623735496.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2106.06340""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/nzxqyj/video/q6cp5pf0wa571/player""&gt;https://reddit.com/link/nzxqyj/video/q6cp5pf0wa571/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39;d by Andrew Ng) Chrome: &lt;a href=""https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nzxqyj', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/nzxqyj/state_of_the_art_in_face_swapping_thank_you/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/nzxqyj/state_of_the_art_in_face_swapping_thank_you/', 'subreddit_subscribers': 7049, 'created_utc': 1623706696.0, 'num_crossposts': 6, 'media': None, 'is_video': False}]",t3_nzxqyj,,,,,
,deeplearning,"I can't really tell if the OpenCV LBPH facial recognition algorithm is based on deep learning and neural networks. From what I've found I don't think it is, but if someone more knowledgeable could confirm I would rly appreciate it 🙏",t2_4c0ol738,False,,0,False,Is the OpenCV LBPH algorithm based on deep learning?,[],r/deeplearning,False,6,,0,,False,t3_nzxq00,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1623735421.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I can&amp;#39;t really tell if the OpenCV LBPH facial recognition algorithm is based on deep learning and neural networks. From what I&amp;#39;ve found I don&amp;#39;t think it is, but if someone more knowledgeable could confirm I would rly appreciate it 🙏&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzxq00,True,,fluffsnake_,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nzxq00/is_the_opencv_lbph_algorithm_based_on_deep/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzxq00/is_the_opencv_lbph_algorithm_based_on_deep/,66147,1623706621.0,0,,False,,,,,,,
,deeplearning,"Deep learning is one area of technology where ambitiousness has no barriers. According to a recent announcement by [The Beijing Academy of Artificial Intelligence (BAAI)](https://www.baai.ac.cn/), in China, yet another milestone has been achieved in the field with its “Wu Dao” AI system. The [GPT 3](https://www.marktechpost.com/2020/08/02/gpt-3-a-new-breakthrough-in-language-generator/) brought in new interest for all the AI researchers, the super scale pre training models. By this approach and making use of 175 billion parameters, it managed to achieve exceptional performance results across the natural language processing tasks (NLP). However, the lacking component is its inability to have any form of cognitive abilities or common sense. Therefore, despite the size, even these models cannot indulge in tasks such as open dialogues, visual reasoning, and so on. With Wu Dao, the researchers plan to address this issue. This is China’s first attempt at a home-grown super-scale intelligent model system. 

Article: [https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/](https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/?_ga=2.13897584.636390090.1623335762-488125022.1618729090)

Reference: [https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/](https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/)",t2_2wsvqwhg,False,,0,False,"This Chinese Super Scale Intelligence Model, ‘Wu Dao 2.0’, Claims To Be Trained Using 1.75 Trillion Parameters, Surpassing All Prior Models to Achieve a New Breakthrough in Deep Learning",[],r/deeplearning,False,6,,0,,False,t3_nzgkj3,False,dark,0.89,,public,37,0,{},,False,[],,False,False,,{},,False,37,,False,False,,False,,[],{},,True,,1623681273.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Deep learning is one area of technology where ambitiousness has no barriers. According to a recent announcement by &lt;a href=""https://www.baai.ac.cn/""&gt;The Beijing Academy of Artificial Intelligence (BAAI)&lt;/a&gt;, in China, yet another milestone has been achieved in the field with its “Wu Dao” AI system. The &lt;a href=""https://www.marktechpost.com/2020/08/02/gpt-3-a-new-breakthrough-in-language-generator/""&gt;GPT 3&lt;/a&gt; brought in new interest for all the AI researchers, the super scale pre training models. By this approach and making use of 175 billion parameters, it managed to achieve exceptional performance results across the natural language processing tasks (NLP). However, the lacking component is its inability to have any form of cognitive abilities or common sense. Therefore, despite the size, even these models cannot indulge in tasks such as open dialogues, visual reasoning, and so on. With Wu Dao, the researchers plan to address this issue. This is China’s first attempt at a home-grown super-scale intelligent model system. &lt;/p&gt;

&lt;p&gt;Article: &lt;a href=""https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/?_ga=2.13897584.636390090.1623335762-488125022.1618729090""&gt;https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Reference: &lt;a href=""https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/""&gt;https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzgkj3,True,,ai-lover,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/nzgkj3/this_chinese_super_scale_intelligence_model_wu/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzgkj3/this_chinese_super_scale_intelligence_model_wu/,66147,1623652473.0,0,,False,,,,,,,
,deeplearning,,t2_5hxzzmvk,False,,0,False,"[JOB POST] PhD in Fusion of quantitative multi modal imaging and parametric mapping of lung structure and function and applications to COPD, asthma and long term effects of COVID-19 disease",[],r/deeplearning,False,6,,0,,False,t3_o01mdt,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623747077.0,text,6,,,text,sano.science,False,,,,,https://sano.science/job-offers/fusion-of-quantitative-multi-modal-imaging-and-parametric-mapping-of-lung-structure-and-function-and-applications-to-copd-asthma-and-long-term-effects-of-covid-19-disease/?fbclid=IwAR0BRFXbCFCOvn9FycWR24C_oQGkRQ1_c3BayCITnubdqUMPqHmdq8uuqdk,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o01mdt,True,,alecrimi,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o01mdt/job_post_phd_in_fusion_of_quantitative_multi/,all_ads,False,https://sano.science/job-offers/fusion-of-quantitative-multi-modal-imaging-and-parametric-mapping-of-lung-structure-and-function-and-applications-to-copd-asthma-and-long-term-effects-of-covid-19-disease/?fbclid=IwAR0BRFXbCFCOvn9FycWR24C_oQGkRQ1_c3BayCITnubdqUMPqHmdq8uuqdk,66147,1623718277.0,0,,False,,,,,,,
,deeplearning,"Im using Ubuntu 21.04 and I have a dedicated Radeon AMD  gpu .I was just searching about it and I think my new gpu is usless :( I just bought it for Deep Learning purposes , I just tried to install Rocm but unfortunately it wont install since its not supported by Ubuntu 21.04 I don’t know what to do 
Help please to overcome this problem",t2_50ckme9a,False,,0,False,HELP: AMD Radeon and tensorflow,[],r/deeplearning,False,6,,0,,False,t3_nzxums,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623735783.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im using Ubuntu 21.04 and I have a dedicated Radeon AMD  gpu .I was just searching about it and I think my new gpu is usless :( I just bought it for Deep Learning purposes , I just tried to install Rocm but unfortunately it wont install since its not supported by Ubuntu 21.04 I don’t know what to do 
Help please to overcome this problem&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzxums,True,,rayudy,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nzxums/help_amd_radeon_and_tensorflow/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzxums/help_amd_radeon_and_tensorflow/,66147,1623706983.0,0,,False,,,,,,,
,deeplearning,"I’ve been searching forever on deep learning benchmarks of the i7 11700k. I’m not sure whether to get it or the Ryzen 7 5800X. Will I actually use the AVX-512 technology, I presume it’ll still be far from a GPU in performance? Currently leaning to the AMD for less heat and less power consumption. Thoughts?",t2_7eip8,False,,0,False,Getting an Intel CPU for the AVX-512?,[],r/deeplearning,False,6,,0,,False,t3_nzxf5q,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623734604.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve been searching forever on deep learning benchmarks of the i7 11700k. I’m not sure whether to get it or the Ryzen 7 5800X. Will I actually use the AVX-512 technology, I presume it’ll still be far from a GPU in performance? Currently leaning to the AMD for less heat and less power consumption. Thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzxf5q,True,,jakkes12,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nzxf5q/getting_an_intel_cpu_for_the_avx512/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzxf5q/getting_an_intel_cpu_for_the_avx512/,66147,1623705804.0,0,,False,,,,,,,
,deeplearning,I'd like to know if there's any research paper reading group I can join. Thank you,t2_5id0e0q7,False,,0,False,Research Paper reading group?,[],r/deeplearning,False,6,,0,,False,t3_nzhwf6,False,dark,0.76,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1623687309.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;d like to know if there&amp;#39;s any research paper reading group I can join. Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzhwf6,True,,rshells,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/nzhwf6/research_paper_reading_group/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzhwf6/research_paper_reading_group/,66147,1623658509.0,0,,False,,,,,,,
,deeplearning,,t2_2op3d34c,False,,0,False,"Advanced AI eBooks Bundle by Morgan Claypool, 15 books",[],r/deeplearning,False,6,,0,,False,t3_nzv5g0,False,dark,0.55,,public,1,1,{},,False,[],,False,False,,{},,False,1,,False,True,,False,,[],{},,False,,1623728656.0,text,6,,,text,medium.com,False,,,,,https://medium.com/@Humble_Bundle/advanced-ai-ebooks-bundle-by-morgan-claypool-47510754139f?58712581,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzv5g0,True,,reps_up,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nzv5g0/advanced_ai_ebooks_bundle_by_morgan_claypool_15/,all_ads,False,https://medium.com/@Humble_Bundle/advanced-ai-ebooks-bundle-by-morgan-claypool-47510754139f?58712581,66147,1623699856.0,1,,False,,,,,,,
,deeplearning,"So Im currently working on my thesis , and I have read many publications on that , most of them are focusing on the GPU while in my case (im using spyder with anaconda installed in ubuntu) is consuming 90% of my CPU is there any way to make my algorithm run with the GPU rather than CPU 
Im a but lost guys",t2_50ckme9a,False,,0,False,What resources does Deep Learning consumes?,[],r/deeplearning,False,6,,0,,False,t3_nzuxju,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623728067.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So Im currently working on my thesis , and I have read many publications on that , most of them are focusing on the GPU while in my case (im using spyder with anaconda installed in ubuntu) is consuming 90% of my CPU is there any way to make my algorithm run with the GPU rather than CPU 
Im a but lost guys&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzuxju,True,,rayudy,,10,True,all_ads,False,[],False,,/r/deeplearning/comments/nzuxju/what_resources_does_deep_learning_consumes/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzuxju/what_resources_does_deep_learning_consumes/,66147,1623699267.0,0,,False,,,,,,,
,deeplearning,"I want to create a reinforcement learning environment, designed for wind tunnel simulations, where for each iteration a deep convolutional model could receive the 3D vector/scalar fields from the past simulation and output a better shape that maximizes the reward function (e.g. minimize drag, maximize lift, etc.).

 The observation and action space for the neural network is the same, the inputs of the model will be 3D arrays representing velocity field, pressure field, etc. and the output will be a 3D array (created using Conv3DTranspose) with values \[0, 1\] which represents the mesh. I'm thinking that the architecture of the model could be something similar to an auto-encoder. My plan is to use the algorithm of Marching Cubes in order to create the mesh from those points and openFoam for the CFD simulations. 

The goal will be to have multiple trained models specialized in optimizing a particular reward function, like minimizing drag or maximizing lift, for any object/shape given as input. What are your thoughts on this? Do you think it makes sense?

PS: I recently discover Growing Neural Cellular Automata that could be a better fit for this type of iterative process.",t2_1n4w9qid,False,,0,False,CFD Reinforcement Learning for Topology optimization in wind tunnel,[],r/deeplearning,False,6,,0,,False,t3_nzizby,False,dark,1.0,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1623692129.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to create a reinforcement learning environment, designed for wind tunnel simulations, where for each iteration a deep convolutional model could receive the 3D vector/scalar fields from the past simulation and output a better shape that maximizes the reward function (e.g. minimize drag, maximize lift, etc.).&lt;/p&gt;

&lt;p&gt;The observation and action space for the neural network is the same, the inputs of the model will be 3D arrays representing velocity field, pressure field, etc. and the output will be a 3D array (created using Conv3DTranspose) with values [0, 1] which represents the mesh. I&amp;#39;m thinking that the architecture of the model could be something similar to an auto-encoder. My plan is to use the algorithm of Marching Cubes in order to create the mesh from those points and openFoam for the CFD simulations. &lt;/p&gt;

&lt;p&gt;The goal will be to have multiple trained models specialized in optimizing a particular reward function, like minimizing drag or maximizing lift, for any object/shape given as input. What are your thoughts on this? Do you think it makes sense?&lt;/p&gt;

&lt;p&gt;PS: I recently discover Growing Neural Cellular Automata that could be a better fit for this type of iterative process.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzizby,True,,cTatu,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nzizby/cfd_reinforcement_learning_for_topology/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzizby/cfd_reinforcement_learning_for_topology/,66147,1623663329.0,2,,False,,,,,,,
,deeplearning,"Hi, I'm looking for an algorithm or model that removes the sky from an input image. Specifically, I'm trying to acquire a mask of the sky, so I can filter the sky pixels out of my model's prediction. The scenery I'm working with is through the front view of a car like a dashcam during morning.

Does anyone know a model or algorithm that I can use to perform this task in a computationally inexpensive way?",t2_tvxmr,False,,0,False,Sky removal model or algorithm?,[],r/deeplearning,False,6,,0,,False,t3_nzsz16,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623722908.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I&amp;#39;m looking for an algorithm or model that removes the sky from an input image. Specifically, I&amp;#39;m trying to acquire a mask of the sky, so I can filter the sky pixels out of my model&amp;#39;s prediction. The scenery I&amp;#39;m working with is through the front view of a car like a dashcam during morning.&lt;/p&gt;

&lt;p&gt;Does anyone know a model or algorithm that I can use to perform this task in a computationally inexpensive way?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzsz16,True,,AbdrahmanDiab,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/nzsz16/sky_removal_model_or_algorithm/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzsz16/sky_removal_model_or_algorithm/,66147,1623694108.0,0,,False,,,,,,,
,deeplearning,,t2_30jgxa2x,False,,0,False,How to Do Face Detection and Tagging in Video With Deep Learning,[],r/deeplearning,False,6,,0,,False,t3_nzrgi1,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623718879.0,text,6,,,text,education-ecosystem.com,False,,,,,https://www.education-ecosystem.com/sebagam/R8QqW-face-recognition-and-grouping-using-deep-learning/Ba1K9-outline-faces/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzrgi1,True,,NaturalWildFishOil,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nzrgi1/how_to_do_face_detection_and_tagging_in_video/,all_ads,False,https://www.education-ecosystem.com/sebagam/R8QqW-face-recognition-and-grouping-using-deep-learning/Ba1K9-outline-faces/,66147,1623690079.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'EducationEcosystem1', 'selftext': '', 'author_fullname': 't2_9vz6ic5r', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How to Do Face Detection and Tagging in Video With Deep Learning', 'link_flair_richtext': [{'e': 'text', 't': 'Artificial Intelligence'}], 'subreddit_name_prefixed': 'r/EducationEcosystem1', 'hidden': False, 'pwls': None, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nzmkof', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'restricted', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Artificial Intelligence', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1623705430.0, 'link_flair_type': 'richtext', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'education-ecosystem.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.education-ecosystem.com/sebagam/R8QqW-face-recognition-and-grouping-using-deep-learning/Ba1K9-outline-faces/', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '7bde20ac-a465-11eb-b9e0-0e44616a98ed', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_4av7i3', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#5a74cc', 'id': 'nzmkof', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Makeyourpuppyproud', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/EducationEcosystem1/comments/nzmkof/how_to_do_face_detection_and_tagging_in_video/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://www.education-ecosystem.com/sebagam/R8QqW-face-recognition-and-grouping-using-deep-learning/Ba1K9-outline-faces/', 'subreddit_subscribers': 82, 'created_utc': 1623676630.0, 'num_crossposts': 4, 'media': None, 'is_video': False}]",t3_nzmkof,,,,,
,deeplearning,"How are models trained on new set of data post production deployment ?

Suppose your Deep learning model was trained on 1 million labelled images. After 1year of deployment into production, your team has gathered  100,000 more labelled images. How will the training process look like? Will it be:

 1. Training on top of the existing weights using just the new images? (Similar to Transfer learning)

2. Training the whole 1.1 million datasets from scratch ?",t2_5c8umwtu,False,,0,False,Training of models post Production deployment,[],r/deeplearning,False,6,,0,,False,t3_nzhm31,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1623686045.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How are models trained on new set of data post production deployment ?&lt;/p&gt;

&lt;p&gt;Suppose your Deep learning model was trained on 1 million labelled images. After 1year of deployment into production, your team has gathered  100,000 more labelled images. How will the training process look like? Will it be:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Training on top of the existing weights using just the new images? (Similar to Transfer learning)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Training the whole 1.1 million datasets from scratch ?&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzhm31,True,,7pointsome1,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nzhm31/training_of_models_post_production_deployment/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzhm31/training_of_models_post_production_deployment/,66147,1623657245.0,0,,False,,,,,,,
,deeplearning,"A Google Research team proposes MergeDistill, a framework for merging pretrained teacher LMs from multiple monolingual/multilingual LMs into a single multilingual task-agnostic student LM to leverage the capabilities of the powerful language-specific LMs while still being multilingual and enabling positive language transfer.  

Here is a quick read: [Google Researchers Merge Pretrained Teacher LMs Into a Single Multilingual Student LM Via Knowledge Distillation.](https://syncedreview.com/2021/06/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-40/)

The paper *MergeDistill: Merging Pre-trained Language Models using Distillation* is on [arXiv](https://arxiv.org/pdf/2106.02834).",t2_2fv4yodo,False,,0,False,[R] Google Researchers Merge Pretrained Teacher LMs Into a Single Multilingual Student LM Via Knowledge Distillation,[],r/deeplearning,False,6,,0,,False,t3_nzohha,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623710925.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A Google Research team proposes MergeDistill, a framework for merging pretrained teacher LMs from multiple monolingual/multilingual LMs into a single multilingual task-agnostic student LM to leverage the capabilities of the powerful language-specific LMs while still being multilingual and enabling positive language transfer.  &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-40/""&gt;Google Researchers Merge Pretrained Teacher LMs Into a Single Multilingual Student LM Via Knowledge Distillation.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;MergeDistill: Merging Pre-trained Language Models using Distillation&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2106.02834""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzohha,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nzohha/r_google_researchers_merge_pretrained_teacher_lms/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzohha/r_google_researchers_merge_pretrained_teacher_lms/,66147,1623682125.0,0,,False,,,,,,,
,deeplearning,"I heard someone saying that tensorflow and keras is much faster then pytorch in terms of production inference. If i wish to deoply some trained model to production then should i code in keras?

As of my research pytorch is faster.",t2_3f4tbfwj,False,,0,False,Keras/tf is much faster then pytorch in production inference.,[],r/deeplearning,False,6,,0,,False,t3_nzjjy0,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623694505.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I heard someone saying that tensorflow and keras is much faster then pytorch in terms of production inference. If i wish to deoply some trained model to production then should i code in keras?&lt;/p&gt;

&lt;p&gt;As of my research pytorch is faster.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzjjy0,True,,ashishgupta2598,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nzjjy0/kerastf_is_much_faster_then_pytorch_in_production/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzjjy0/kerastf_is_much_faster_then_pytorch_in_production/,66147,1623665705.0,0,,False,,,,,,,
,deeplearning,"It seems like defining the model is just random coding, except for making the shapes match so you won't have an exception.    
I'm at a point in my project where I'm just adding and removing different blocks (Conv block, sigmoid, PReLU) to the model and hoping for the best.

How does anyone know which block to use in a net?

Here is [my project](https://github.com/unimonkiez/final_engineering_project) and the [task](https://arxiv.org/pdf/2006.05712.pdf) I'm trying to implement, don't need to enter though as this post is more about seeking advice than help (but is welcomed).",t2_sgea0,False,,0,False,Frustrated with deep-learning development,[],r/deeplearning,False,6,,0,,False,t3_nyzrfh,False,dark,0.8,,public,22,0,{},,False,[],,False,False,,{},,False,22,,False,False,,False,,[],{},,True,,1623629655.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It seems like defining the model is just random coding, except for making the shapes match so you won&amp;#39;t have an exception.&lt;br/&gt;
I&amp;#39;m at a point in my project where I&amp;#39;m just adding and removing different blocks (Conv block, sigmoid, PReLU) to the model and hoping for the best.&lt;/p&gt;

&lt;p&gt;How does anyone know which block to use in a net?&lt;/p&gt;

&lt;p&gt;Here is &lt;a href=""https://github.com/unimonkiez/final_engineering_project""&gt;my project&lt;/a&gt; and the &lt;a href=""https://arxiv.org/pdf/2006.05712.pdf""&gt;task&lt;/a&gt; I&amp;#39;m trying to implement, don&amp;#39;t need to enter though as this post is more about seeking advice than help (but is welcomed).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyzrfh,True,,unimonkiez,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/nyzrfh/frustrated_with_deeplearning_development/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nyzrfh/frustrated_with_deeplearning_development/,66147,1623600855.0,0,,False,,,,,,,
,deeplearning,,t2_159buvym,False,,0,False,Can anyone please guide me to a video based Automatic speech recognition (ASR) course ?,[],r/deeplearning,False,6,,0,,False,t3_nyw2z2,False,dark,0.78,,public,11,0,{},,False,[],,False,False,,{},,False,11,,False,False,,False,,[],{},,True,,1623618892.0,text,6,,,text,self.deeplearning,False,,,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyw2z2,True,,rakshith291,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nyw2z2/can_anyone_please_guide_me_to_a_video_based/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nyw2z2/can_anyone_please_guide_me_to_a_video_based/,66147,1623590092.0,0,,False,,,,,,,
,deeplearning,"At the beginning of training the model clearly will predict the wrong number of object bboxes in the image, which leads to have the predicted bboxes size different than the target bboxes size. 

So how does it still be able compute loss between these, when the dim is unmatched?",t2_abbcm4w8,False,,0,False,Mask RCNN loss,[],r/deeplearning,False,6,,0,,False,t3_nz7hfp,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623651357.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;At the beginning of training the model clearly will predict the wrong number of object bboxes in the image, which leads to have the predicted bboxes size different than the target bboxes size. &lt;/p&gt;

&lt;p&gt;So how does it still be able compute loss between these, when the dim is unmatched?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nz7hfp,True,,I_am_not_doing_this,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nz7hfp/mask_rcnn_loss/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nz7hfp/mask_rcnn_loss/,66147,1623622557.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,AI will fake your handwriting using just a single word,[],r/deeplearning,False,6,,0,,False,t3_nyed8t,False,dark,0.94,,public,68,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Hc5_M7ziy-Q?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI will fake your handwriting using just a single word', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Hc5_M7ziy-Q?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Hc5_M7ziy-Q/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Hc5_M7ziy-Q?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nyed8t', 'height': 200}",,False,68,,False,False,,False,,[],{},,False,,1623554911.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/Hc5_M7ziy-Q,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyed8t,True,,cmillionaire9,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nyed8t/ai_will_fake_your_handwriting_using_just_a_single/,all_ads,False,https://youtu.be/Hc5_M7ziy-Q,66147,1623526111.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI will fake your handwriting using just a single word', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Hc5_M7ziy-Q?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Hc5_M7ziy-Q/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,"Does anyone knows of a program/app to draw pretty neural network architectures? Not the actual code, just an schematic of the NN.",t2_cdlnd,False,,0,False,App or website to draw NNs?,[],r/deeplearning,False,6,,0,,False,t3_nyzzq9,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623630289.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone knows of a program/app to draw pretty neural network architectures? Not the actual code, just an schematic of the NN.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyzzq9,True,,donpepep,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nyzzq9/app_or_website_to_draw_nns/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nyzzq9/app_or_website_to_draw_nns/,66147,1623601489.0,0,,False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,Text Style Brush by Facebook AI - amazing single-shot text style transfer results (deepfakes just got ++),[],r/deeplearning,False,6,,0,,False,t3_nyxb8f,False,dark,0.6,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/OC0oe1EzQxo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Text Style Brush - Transfer of text aesthetics from a single example | Paper Explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/OC0oe1EzQxo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/OC0oe1EzQxo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/OC0oe1EzQxo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nyxb8f', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1623622766.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/OC0oe1EzQxo,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyxb8f,True,,gordicaleksa,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nyxb8f/text_style_brush_by_facebook_ai_amazing/,all_ads,False,https://youtu.be/OC0oe1EzQxo,66147,1623593966.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Text Style Brush - Transfer of text aesthetics from a single example | Paper Explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/OC0oe1EzQxo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/OC0oe1EzQxo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,Hi there! Let us know your nationality and practice your Arabic with us!,[],r/deeplearning,False,6,,0,,False,t3_nz4qji,False,dark,0.14,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623643656.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/e1iy1bw2a3571.jpg,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nz4qji,True,,Community-Of-Babel,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nz4qji/hi_there_let_us_know_your_nationality_and/,all_ads,False,https://i.redd.it/e1iy1bw2a3571.jpg,66147,1623614856.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Hi there! Let us know your nationality and practice your Arabic with us!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nz4mb6', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1623643343.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/e1iy1bw2a3571.jpg', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nz4mb6', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/nz4mb6/hi_there_let_us_know_your_nationality_and/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://i.redd.it/e1iy1bw2a3571.jpg', 'subreddit_subscribers': 0, 'created_utc': 1623614543.0, 'num_crossposts': 6, 'media': None, 'is_video': False}]",t3_nz4mb6,,,,,
,deeplearning,,t2_b35fb5yn,False,,0,False,"Learn Machine Learning, Data Science and Deep Learning with Python",[],r/deeplearning,False,6,,0,,False,t3_nywnw2,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623620745.0,text,6,,,text,medium.com,False,,,,,https://medium.com/@devexpert/20-best-machine-learning-courses-online-4a7863c4326a,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nywnw2,True,,hngkng21,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nywnw2/learn_machine_learning_data_science_and_deep/,all_ads,False,https://medium.com/@devexpert/20-best-machine-learning-courses-online-4a7863c4326a,66147,1623591945.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,Real-time Writing with fingers on Web Camera Screen,[],r/deeplearning,False,6,,0,,False,t3_nyev2d,False,dark,0.93,,public,12,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Qv82F4qe0CE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Real-time Writing with fingers on Web Camera Screen', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Qv82F4qe0CE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Qv82F4qe0CE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Qv82F4qe0CE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nyev2d', 'height': 200}",,False,12,,False,False,,False,,[],{},,False,,1623556293.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/Qv82F4qe0CE,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyev2d,True,,cmillionaire9,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nyev2d/realtime_writing_with_fingers_on_web_camera_screen/,all_ads,False,https://youtu.be/Qv82F4qe0CE,66147,1623527493.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Real-time Writing with fingers on Web Camera Screen', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Qv82F4qe0CE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Qv82F4qe0CE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,Can I learn deep learning without machine learning?,t2_7f6u7n1z,False,,0,False,Confused,[],r/deeplearning,False,6,,0,,False,t3_nz1vhk,False,dark,0.3,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623635544.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can I learn deep learning without machine learning?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nz1vhk,True,,satvs,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/nz1vhk/confused/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nz1vhk/confused/,66147,1623606744.0,0,,False,,,,,,,
,deeplearning,"Hello everyone,

Is there the source code and pre-trained models of Google Switch Transformers available for download?",t2_sm171,False,,0,False,Google Switch Transformers available?,[],r/deeplearning,False,6,,0,,False,t3_nys0ui,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623602216.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;Is there the source code and pre-trained models of Google Switch Transformers available for download?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nys0ui,True,,notooth1,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nys0ui/google_switch_transformers_available/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nys0ui/google_switch_transformers_available/,66147,1623573416.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,Barbershop: Try Different Hairstyles and Hair Colors from Pictures (GANs+),[],r/deeplearning,False,6,,0,,False,t3_ny99f3,False,dark,0.78,,public,10,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HtqYMvBVJD8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Barbershop: Try Different Hairstyles and Hair Colors from Pictures (GANs)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HtqYMvBVJD8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/HtqYMvBVJD8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HtqYMvBVJD8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ny99f3', 'height': 200}",,False,10,,False,False,,False,,[],{},,False,,1623540508.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/HtqYMvBVJD8,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny99f3,True,,OnlyProggingForFun,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/ny99f3/barbershop_try_different_hairstyles_and_hair/,all_ads,False,https://youtu.be/HtqYMvBVJD8,66147,1623511708.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Barbershop: Try Different Hairstyles and Hair Colors from Pictures (GANs)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HtqYMvBVJD8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/HtqYMvBVJD8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,,,,,,,
,deeplearning,,t2_bgz5v,False,,0,False,"Audiovisual Project ""Incomplete"" (2021) made with GANs, Segmentation, &amp; 3D Animation",[],r/deeplearning,False,6,,0,,False,t3_nyjy94,False,dark,0.76,,public,2,0,"{'content': '&lt;iframe class=""embedly-embed"" src=""https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fplayer.vimeo.com%2Fvideo%2F537999129%3Fapp_id%3D122963&amp;dntp=1&amp;display_name=Vimeo&amp;url=https%3A%2F%2Fvimeo.com%2F537999129&amp;image=http%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1147179301_1280&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=vimeo"" width=""600"" height=""338"" scrolling=""no"" title=""Vimeo embed"" frameborder=""0"" allow=""autoplay; fullscreen"" allowfullscreen=""true""&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",,False,[],"{'type': 'vimeo.com', 'oembed': {'provider_url': 'https://vimeo.com/', 'description': 'The year is 2021. The future has already happened. Composed of a single take, ""Incomplete"" invites us to traverse an endless choreography of bodies in perpetual free-fall and updating images that reflect a world in constant change.', 'title': 'Incomplete (2021)', 'type': 'video', 'author_name': 'Dalena Tran', 'height': 338, 'width': 600, 'html': '&lt;iframe class=""embedly-embed"" src=""https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fplayer.vimeo.com%2Fvideo%2F537999129%3Fapp_id%3D122963&amp;dntp=1&amp;display_name=Vimeo&amp;url=https%3A%2F%2Fvimeo.com%2F537999129&amp;image=http%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1147179301_1280&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=vimeo"" width=""600"" height=""338"" scrolling=""no"" title=""Vimeo embed"" frameborder=""0"" allow=""autoplay; fullscreen"" allowfullscreen=""true""&gt;&lt;/iframe&gt;', 'thumbnail_width': 1280, 'version': '1.0', 'provider_name': 'Vimeo', 'thumbnail_url': 'https://i.embed.ly/1/image?url=http%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1147179301_1280&amp;key=b1e305db91cf4aa5a86b732cc9fffceb', 'thumbnail_height': 720, 'author_url': 'https://vimeo.com/dalenatran'}}",False,False,,"{'content': '&lt;iframe class=""embedly-embed"" src=""https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fplayer.vimeo.com%2Fvideo%2F537999129%3Fapp_id%3D122963&amp;dntp=1&amp;display_name=Vimeo&amp;url=https%3A%2F%2Fvimeo.com%2F537999129&amp;image=http%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1147179301_1280&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=vimeo"" width=""600"" height=""338"" scrolling=""no"" title=""Vimeo embed"" frameborder=""0"" allow=""autoplay; fullscreen"" allowfullscreen=""true""&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nyjy94', 'height': 338}",,False,2,,False,False,,False,,[],{},,False,,1623570534.0,text,6,,,text,vimeo.com,False,,,,,https://vimeo.com/537999129,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyjy94,True,,dalenatran,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nyjy94/audiovisual_project_incomplete_2021_made_with/,all_ads,False,https://vimeo.com/537999129,66147,1623541734.0,0,"{'type': 'vimeo.com', 'oembed': {'provider_url': 'https://vimeo.com/', 'description': 'The year is 2021. The future has already happened. Composed of a single take, ""Incomplete"" invites us to traverse an endless choreography of bodies in perpetual free-fall and updating images that reflect a world in constant change.', 'title': 'Incomplete (2021)', 'type': 'video', 'author_name': 'Dalena Tran', 'height': 338, 'width': 600, 'html': '&lt;iframe class=""embedly-embed"" src=""https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fplayer.vimeo.com%2Fvideo%2F537999129%3Fapp_id%3D122963&amp;dntp=1&amp;display_name=Vimeo&amp;url=https%3A%2F%2Fvimeo.com%2F537999129&amp;image=http%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1147179301_1280&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=vimeo"" width=""600"" height=""338"" scrolling=""no"" title=""Vimeo embed"" frameborder=""0"" allow=""autoplay; fullscreen"" allowfullscreen=""true""&gt;&lt;/iframe&gt;', 'thumbnail_width': 1280, 'version': '1.0', 'provider_name': 'Vimeo', 'thumbnail_url': 'https://i.embed.ly/1/image?url=http%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1147179301_1280&amp;key=b1e305db91cf4aa5a86b732cc9fffceb', 'thumbnail_height': 720, 'author_url': 'https://vimeo.com/dalenatran'}}",False,,,,,,,
,deeplearning,,t2_83s7wqlw,False,,0,False,I'm trying to recreate this CNN in order to predict bounding boxes coordinates (I'm not doing any object classification...just bounding boxes). I can't seem to understand well the numbers on the rectangles (layers). Can someone enlighten me on how to translate this image to tensorflow/py. Thankieees,[],r/deeplearning,False,6,,0,,False,t3_ny3qjy,False,dark,0.86,,public,20,0,{},,False,[],,True,False,,{},,False,20,,False,False,,False,,[],{},,False,,1623522449.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/u9lfco036t471.png,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny3qjy,True,,Moroccanmuslim,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/ny3qjy/im_trying_to_recreate_this_cnn_in_order_to/,all_ads,False,https://i.redd.it/u9lfco036t471.png,66147,1623493649.0,0,,False,,,,,,,
,deeplearning,"Generative models have become synonymous with convolutions and more recently with self-attention, yet we (yes, I am the second author of this paper, yay 🙌) ask the question: are convolutions REALLY necessary to generate state-of-the-art quality images? Perhaps surprisingly a simple multilayer perceptron (MLP) with a couple of clever tricks does just as good (if not better) as specialized convolutional architectures (StyleGAN-2) on 256x256 resolution.

Check out the [full paper digest](https://t.me/casual_gan/51) (reading time \~5 minutes) to learn about the architecture of our MLP-based generator, the two types of positional encoding used to increase the fidelity of generated images, and how CIPS can be used to generate seamless cyclical panoramas without ever training on full panoramic images.

Meanwhile, check out the paper summary poster by [Casual GAN Papers](https://t.me/casual_gan)!

[CIPS: Conditionally Independent Pixel Synthesis](https://preview.redd.it/zmprpyqtzt471.png?width=680&amp;format=png&amp;auto=webp&amp;s=8a86c73bb7a5d535fb18f16d0b155b4765d00f36)

\[[Full Explanation Post](https://t.me/casual_gan/51)\] \[[Arxiv](https://arxiv.org/abs/2011.13775)\] \[[Project page](https://github.com/saic-mdal/CIPS)\]

More recent popular computer vision paper breakdowns:

&gt;[DALL-E](https://t.me/casual_gan/48)  
[VQGAN](https://t.me/casual_gan/46)  
[Decision Transformer](https://t.me/casual_gan/50)",t2_hhio3,False,,0,False,Image Generators with Conditionally-Independent Pixel Synthesis (CIPS) by Anokhin et al.,[],r/deeplearning,False,6,,0,,False,t3_ny60md,False,dark,0.85,,public,9,0,{},,False,[],,False,False,,{},,False,9,,False,False,,False,,[],{},,True,,1623530962.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Generative models have become synonymous with convolutions and more recently with self-attention, yet we (yes, I am the second author of this paper, yay 🙌) ask the question: are convolutions REALLY necessary to generate state-of-the-art quality images? Perhaps surprisingly a simple multilayer perceptron (MLP) with a couple of clever tricks does just as good (if not better) as specialized convolutional architectures (StyleGAN-2) on 256x256 resolution.&lt;/p&gt;

&lt;p&gt;Check out the &lt;a href=""https://t.me/casual_gan/51""&gt;full paper digest&lt;/a&gt; (reading time ~5 minutes) to learn about the architecture of our MLP-based generator, the two types of positional encoding used to increase the fidelity of generated images, and how CIPS can be used to generate seamless cyclical panoramas without ever training on full panoramic images.&lt;/p&gt;

&lt;p&gt;Meanwhile, check out the paper summary poster by &lt;a href=""https://t.me/casual_gan""&gt;Casual GAN Papers&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/zmprpyqtzt471.png?width=680&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8a86c73bb7a5d535fb18f16d0b155b4765d00f36""&gt;CIPS: Conditionally Independent Pixel Synthesis&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/51""&gt;Full Explanation Post&lt;/a&gt;] [&lt;a href=""https://arxiv.org/abs/2011.13775""&gt;Arxiv&lt;/a&gt;] [&lt;a href=""https://github.com/saic-mdal/CIPS""&gt;Project page&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;More recent popular computer vision paper breakdowns:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=""https://t.me/casual_gan/48""&gt;DALL-E&lt;/a&gt;&lt;br/&gt;
&lt;a href=""https://t.me/casual_gan/46""&gt;VQGAN&lt;/a&gt;&lt;br/&gt;
&lt;a href=""https://t.me/casual_gan/50""&gt;Decision Transformer&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny60md,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ny60md/image_generators_with_conditionallyindependent/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ny60md/image_generators_with_conditionallyindependent/,66147,1623502162.0,0,,False,,,"{'zmprpyqtzt471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 203, 'x': 108, 'u': 'https://preview.redd.it/zmprpyqtzt471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=49197c138222ca877021bd04c281025723d09014'}, {'y': 406, 'x': 216, 'u': 'https://preview.redd.it/zmprpyqtzt471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e825bac5feab62b3bef2cb8186236d210de8431'}, {'y': 602, 'x': 320, 'u': 'https://preview.redd.it/zmprpyqtzt471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=435de8508de4ff56d38a4107b65c478a6dcefbac'}, {'y': 1204, 'x': 640, 'u': 'https://preview.redd.it/zmprpyqtzt471.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=33e209b32154e372d20230226d62890936943285'}], 's': {'y': 1280, 'x': 680, 'u': 'https://preview.redd.it/zmprpyqtzt471.png?width=680&amp;format=png&amp;auto=webp&amp;s=8a86c73bb7a5d535fb18f16d0b155b4765d00f36'}, 'id': 'zmprpyqtzt471'}}",,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,State of the art in Video Object Segmentation,[],r/deeplearning,False,6,,0,,False,t3_nyhpp4,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FVzZubDj3AA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'State of the art in Video Object Segmentation', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FVzZubDj3AA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/FVzZubDj3AA/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FVzZubDj3AA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nyhpp4', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1623563823.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=FVzZubDj3AA,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyhpp4,True,,cmillionaire9,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nyhpp4/state_of_the_art_in_video_object_segmentation/,all_ads,False,https://www.youtube.com/watch?v=FVzZubDj3AA,66147,1623535023.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'State of the art in Video Object Segmentation', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FVzZubDj3AA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/FVzZubDj3AA/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,"My training with SAEHD isn’t starting when selecting Nvidia T500 (it does work with CPU, but only does about 30 iterations every 15min)

I have received this error message: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize

I saw another solution on github to this was to add the following code:

“OK, I was able to execute my CNN. I'm using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:

from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

I’m unsure exactly where to input this, as putting it in the notebook.py file located in the tensorboard folder hasn’t yielded any success

I have a HP Zbook, Inter Core i7, 32Gb RAM, Nvidia t500 graphics card.

Forever grateful if anyone can point me in the right direction. Thanks in advance",t2_2f5xu7mz,False,,0,False,DFL - SAEHD training not starting,[],r/deeplearning,False,6,,0,,False,t3_nyh5fx,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623562281.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My training with SAEHD isn’t starting when selecting Nvidia T500 (it does work with CPU, but only does about 30 iterations every 15min)&lt;/p&gt;

&lt;p&gt;I have received this error message: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize&lt;/p&gt;

&lt;p&gt;I saw another solution on github to this was to add the following code:&lt;/p&gt;

&lt;p&gt;“OK, I was able to execute my CNN. I&amp;#39;m using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:&lt;/p&gt;

&lt;p&gt;from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession&lt;/p&gt;

&lt;p&gt;config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)&lt;/p&gt;

&lt;p&gt;I’m unsure exactly where to input this, as putting it in the notebook.py file located in the tensorboard folder hasn’t yielded any success&lt;/p&gt;

&lt;p&gt;I have a HP Zbook, Inter Core i7, 32Gb RAM, Nvidia t500 graphics card.&lt;/p&gt;

&lt;p&gt;Forever grateful if anyone can point me in the right direction. Thanks in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyh5fx,True,,Kirchart007,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nyh5fx/dfl_saehd_training_not_starting/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nyh5fx/dfl_saehd_training_not_starting/,66147,1623533481.0,0,,False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,"Chip Placement with Deep RL paper explained! (recently published in Nature, used to develop Google's TPU v5)",[],r/deeplearning,False,6,,0,,False,t3_ny86od,False,dark,0.67,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Z3XtWuuTHz4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Chip Placement with Deep Reinforcement Learning | Paper Explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Z3XtWuuTHz4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Z3XtWuuTHz4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Z3XtWuuTHz4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ny86od', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1623537479.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/Z3XtWuuTHz4,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny86od,True,,gordicaleksa,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ny86od/chip_placement_with_deep_rl_paper_explained/,all_ads,False,https://youtu.be/Z3XtWuuTHz4,66147,1623508679.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Chip Placement with Deep Reinforcement Learning | Paper Explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Z3XtWuuTHz4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Z3XtWuuTHz4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,,t2_hmbd5,False,,0,False,Tutorial for novice: How does the machine recognize numbers and black-and-white images?,[],r/deeplearning,False,6,,0,,False,t3_ny1g4t,False,dark,0.71,,public,7,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/kiua6bTqy0Y?start=773&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How does the machine recognize numbers and black-and-white images?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/kiua6bTqy0Y?start=773&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Chier Hu', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/kiua6bTqy0Y/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ChierHu'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/kiua6bTqy0Y?start=773&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ny1g4t', 'height': 200}",,False,7,,False,False,,False,,[],{},,False,,1623512855.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/kiua6bTqy0Y?t=773,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny1g4t,True,,RossJD,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ny1g4t/tutorial_for_novice_how_does_the_machine/,all_ads,False,https://youtu.be/kiua6bTqy0Y?t=773,66147,1623484055.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How does the machine recognize numbers and black-and-white images?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/kiua6bTqy0Y?start=773&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Chier Hu', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/kiua6bTqy0Y/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ChierHu'}}",False,,,,,,,
,deeplearning,"&amp;#x200B;

https://preview.redd.it/b0b8fzoxau471.png?width=1121&amp;format=png&amp;auto=webp&amp;s=4d94b1ed901dcc33720d1b0455a3cd4fe1738a61",t2_3f66wv8f,False,,0,False,Pytorch Implementation Translating Real Images to cartoon images using PIX2PIX - Image-to-Image Translation with Conditional Adversarial Networks Code : https://lnkd.in/etv3Kws paper : https://lnkd.in/exdgeBB,[],r/deeplearning,False,6,,0,,False,t3_ny77uw,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623534706.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/b0b8fzoxau471.png?width=1121&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4d94b1ed901dcc33720d1b0455a3cd4fe1738a61""&gt;https://preview.redd.it/b0b8fzoxau471.png?width=1121&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4d94b1ed901dcc33720d1b0455a3cd4fe1738a61&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny77uw,True,,rohitkuk,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ny77uw/pytorch_implementation_translating_real_images_to/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ny77uw/pytorch_implementation_translating_real_images_to/,66147,1623505906.0,3,,False,,,"{'b0b8fzoxau471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 107, 'x': 108, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7379800dd42804c0d14c3c0e5a68151e228dbbcb'}, {'y': 215, 'x': 216, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=40410fcb901321c77cb836e8df5cb3bc97ef9827'}, {'y': 318, 'x': 320, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1adb964573d7d925cb322f4c40ae476251c4008'}, {'y': 637, 'x': 640, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8bf9501bcd036cf3236e4088a11ec1466bae1df5'}, {'y': 956, 'x': 960, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=012cc053ee761df7cd89af526eb5c6f164bb3591'}, {'y': 1076, 'x': 1080, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b9f15d63770af01885bcb4124890629ee6bf70d4'}], 's': {'y': 1117, 'x': 1121, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=1121&amp;format=png&amp;auto=webp&amp;s=4d94b1ed901dcc33720d1b0455a3cd4fe1738a61'}, 'id': 'b0b8fzoxau471'}}",,,,
,deeplearning,"Using tensor flow and 30,000 samples from celebA dataset i trained a DCGan to produce 128x128x3 images of faces. Check out the github and images produced.  [GitHub](https://github.com/giovannidmilana/Deep_conv_gen_gan)

https://preview.redd.it/x4vmrhk6ev471.png?width=432&amp;format=png&amp;auto=webp&amp;s=923e01f1fdc4f43564ca9bcd43c51025b49313d8",t2_2elywrfx,False,,0,False,Deep convolutional generative Adversarial neural net to produce images of faces,[],r/deeplearning,False,6,,0,,False,t3_nybxtg,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623548094.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Using tensor flow and 30,000 samples from celebA dataset i trained a DCGan to produce 128x128x3 images of faces. Check out the github and images produced.  &lt;a href=""https://github.com/giovannidmilana/Deep_conv_gen_gan""&gt;GitHub&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/x4vmrhk6ev471.png?width=432&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=923e01f1fdc4f43564ca9bcd43c51025b49313d8""&gt;https://preview.redd.it/x4vmrhk6ev471.png?width=432&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=923e01f1fdc4f43564ca9bcd43c51025b49313d8&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nybxtg,True,,Extra-most-best,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nybxtg/deep_convolutional_generative_adversarial_neural/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nybxtg/deep_convolutional_generative_adversarial_neural/,66147,1623519294.0,1,,False,,,"{'x4vmrhk6ev471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 72, 'x': 108, 'u': 'https://preview.redd.it/x4vmrhk6ev471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=46aa40b046e321d93f7dc16c47c940adfe22fb9b'}, {'y': 144, 'x': 216, 'u': 'https://preview.redd.it/x4vmrhk6ev471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ed5e7cf1e769ca1850f99664ac02fac88b692ae5'}, {'y': 213, 'x': 320, 'u': 'https://preview.redd.it/x4vmrhk6ev471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f0d0043489aae4f22452e92d9fc0186770ac817e'}], 's': {'y': 288, 'x': 432, 'u': 'https://preview.redd.it/x4vmrhk6ev471.png?width=432&amp;format=png&amp;auto=webp&amp;s=923e01f1fdc4f43564ca9bcd43c51025b49313d8'}, 'id': 'x4vmrhk6ev471'}}",,,,
,deeplearning,"Recently, I have been studying NLP transformer based language models like GPT-2, T5. From the research papers, I came to know that just changing the input format gives required task-specific output. But a lot of articles show fine-tuning them. I am really amused how models with 1.5 billion parameters can be fine-tuned. Can someone explain how is it possible? What is happening during fine-tuning?",t2_4ezy6j81,False,,0,False,"Fine-tuning GPT-2, T5",[],r/deeplearning,False,6,,0,,False,t3_nxz5se,False,dark,0.78,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1623503370.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Recently, I have been studying NLP transformer based language models like GPT-2, T5. From the research papers, I came to know that just changing the input format gives required task-specific output. But a lot of articles show fine-tuning them. I am really amused how models with 1.5 billion parameters can be fine-tuned. Can someone explain how is it possible? What is happening during fine-tuning?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxz5se,True,,Sunee_,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nxz5se/finetuning_gpt2_t5/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxz5se/finetuning_gpt2_t5/,66147,1623474570.0,0,,False,,,,,,,
,deeplearning,"A research team from McGill University, Université de Montréal, DeepMind and Mila presents an end-to-end, model-based deep reinforcement learning (RL) agent that dynamically attends to relevant parts of its environments to facilitate out-of-distribution (OOD) and systematic generalization.

Here is a quick read: [Yoshua Bengio Team Designs Consciousness-Inspired Planning Agent for Model-Based RL.](https://syncedreview.com/2021/06/11/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-39/)

The paper *A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning* is on [arXiv](https://arxiv.org/abs/2106.02097).",t2_2fv4yodo,False,,0,False,[R] Yoshua Bengio Team Designs Consciousness-Inspired Planning Agent for Model-Based RL,[],r/deeplearning,False,6,,0,,False,t3_nxikzm,False,dark,0.92,,public,34,0,{},,False,[],,False,False,,{},,False,34,,False,False,,False,,[],{},,True,,1623453910.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from McGill University, Université de Montréal, DeepMind and Mila presents an end-to-end, model-based deep reinforcement learning (RL) agent that dynamically attends to relevant parts of its environments to facilitate out-of-distribution (OOD) and systematic generalization.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/11/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-39/""&gt;Yoshua Bengio Team Designs Consciousness-Inspired Planning Agent for Model-Based RL.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2106.02097""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxikzm,True,,Yuqing7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nxikzm/r_yoshua_bengio_team_designs/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxikzm/r_yoshua_bengio_team_designs/,66147,1623425110.0,0,,False,,,,,,,
,deeplearning,"Hello folks,

I have a Asus G15 with a RTX 3080 mobile and I tried to install and use my GPU for training my NN with tensorflow.

I used [this video](https://www.youtube.com/watch?v=hHWkvEcDBO0&amp;t=2s) as a set-up guide but it did not work.

Tensorflow says it can't find a certain dll-file.

Just to make sure that it can be done: Does anyone know of someone with a RTX 3080 mobile who got the GPU acceleration working?",t2_gdgf6,False,,0,False,CUDA with RTX3080 mobile,[],r/deeplearning,False,6,,0,,False,t3_ny3zwx,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623523531.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello folks,&lt;/p&gt;

&lt;p&gt;I have a Asus G15 with a RTX 3080 mobile and I tried to install and use my GPU for training my NN with tensorflow.&lt;/p&gt;

&lt;p&gt;I used &lt;a href=""https://www.youtube.com/watch?v=hHWkvEcDBO0&amp;amp;t=2s""&gt;this video&lt;/a&gt; as a set-up guide but it did not work.&lt;/p&gt;

&lt;p&gt;Tensorflow says it can&amp;#39;t find a certain dll-file.&lt;/p&gt;

&lt;p&gt;Just to make sure that it can be done: Does anyone know of someone with a RTX 3080 mobile who got the GPU acceleration working?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny3zwx,True,,TheHupfdole,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/ny3zwx/cuda_with_rtx3080_mobile/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ny3zwx/cuda_with_rtx3080_mobile/,66147,1623494731.0,0,,False,,,,,,,
,deeplearning,"Many deep learning models created using TensorFlow require high processing capabilities to perform inference. Fortunately, there is a lite version of TensorFlow called TensorFlow Lite (TFLite for short) which allows these models to run on devices with limited capabilities. Inference is performed in less than a second.

This tutorial will go through how to prepare Raspberry Pi (RPi) to run a TFLite model for classifying images. After that, the TFLite version of the MobileNet model will be downloaded and used for making predictions on-device.

Tutorial video link: [https://youtu.be/FdfxizUUQJI](https://youtu.be/FdfxizUUQJI)

Run the code on a free GPU: [https://console.paperspace.com/ml-showcase/notebook/rljtgo7aadmiq7q?file=Raspberry%20Pi%20TF%20Lite%20Models.ipynb](https://console.paperspace.com/ml-showcase/notebook/rljtgo7aadmiq7q?file=Raspberry%20Pi%20TF%20Lite%20Models.ipynb)",t2_15en0l,False,,0,False,[Video] Running TensorFlow Lite Models on Raspberry Pi,[],r/deeplearning,False,6,,0,,False,t3_nxq771,False,dark,0.69,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1623474250.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Many deep learning models created using TensorFlow require high processing capabilities to perform inference. Fortunately, there is a lite version of TensorFlow called TensorFlow Lite (TFLite for short) which allows these models to run on devices with limited capabilities. Inference is performed in less than a second.&lt;/p&gt;

&lt;p&gt;This tutorial will go through how to prepare Raspberry Pi (RPi) to run a TFLite model for classifying images. After that, the TFLite version of the MobileNet model will be downloaded and used for making predictions on-device.&lt;/p&gt;

&lt;p&gt;Tutorial video link: &lt;a href=""https://youtu.be/FdfxizUUQJI""&gt;https://youtu.be/FdfxizUUQJI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Run the code on a free GPU: &lt;a href=""https://console.paperspace.com/ml-showcase/notebook/rljtgo7aadmiq7q?file=Raspberry%20Pi%20TF%20Lite%20Models.ipynb""&gt;https://console.paperspace.com/ml-showcase/notebook/rljtgo7aadmiq7q?file=Raspberry%20Pi%20TF%20Lite%20Models.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxq771,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nxq771/video_running_tensorflow_lite_models_on_raspberry/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxq771/video_running_tensorflow_lite_models_on_raspberry/,66147,1623445450.0,0,,False,,,,,,,
,deeplearning,"Transformers are everywhere, so why not add them to reinforcement learning (RL) as well? Yeah, that's right, the researchers at UC Berkeley just did that. They approach RL as a sequence modeling problem and use an autoregressive transformer to predict the next optimal action given the previous states, actions, and rewards so that it maximizes some reward function. Perhaps surprisingly, this simple Decision Transformer approach achieves state-of-the-art performance on Atari, OpenAI Gym, Key-to-Door tasks.

Check out the [full paper digest](https://t.me/casual_gan/50) to learn about how offline RL can be turned into a sequence modeling problem, represent simulation trajectories for the Transformer to learn from, and, most importantly, apply Transformers to ace offline RL tasks!

Meanwhile, check out this paper poster presented by [Casual GAN Papers](https://t.me/casual_gan):

[Decision Transformer](https://preview.redd.it/yfuy5n7x0n471.png?width=759&amp;format=png&amp;auto=webp&amp;s=faffb3478b73a3f694de28733306421b84b94a24)

\[[Full Explanation Post](https://t.me/casual_gan/50)\] \[[Arxiv](https://arxiv.org/pdf/2106.01345.pdf)\] \[[Project page](https://github.com/kzl/decision-transformer)\]

More recent popular computer vision paper breakdowns:

&gt;[DALL-E](https://t.me/casual_gan/48)  
[VQGAN](https://t.me/casual_gan/46)  
[DINO](https://t.me/casual_gan/40)",t2_hhio3,False,,0,False,Paper explained - Decision Transformer: Reinforcement Learning via Sequence Modeling (DecisionTransformer) by Lili Chen et al.,[],r/deeplearning,False,6,,0,,False,t3_nxfvgo,False,dark,0.86,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,1623463680.0,,[],{},,True,,1623446558.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Transformers are everywhere, so why not add them to reinforcement learning (RL) as well? Yeah, that&amp;#39;s right, the researchers at UC Berkeley just did that. They approach RL as a sequence modeling problem and use an autoregressive transformer to predict the next optimal action given the previous states, actions, and rewards so that it maximizes some reward function. Perhaps surprisingly, this simple Decision Transformer approach achieves state-of-the-art performance on Atari, OpenAI Gym, Key-to-Door tasks.&lt;/p&gt;

&lt;p&gt;Check out the &lt;a href=""https://t.me/casual_gan/50""&gt;full paper digest&lt;/a&gt; to learn about how offline RL can be turned into a sequence modeling problem, represent simulation trajectories for the Transformer to learn from, and, most importantly, apply Transformers to ace offline RL tasks!&lt;/p&gt;

&lt;p&gt;Meanwhile, check out this paper poster presented by &lt;a href=""https://t.me/casual_gan""&gt;Casual GAN Papers&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/yfuy5n7x0n471.png?width=759&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=faffb3478b73a3f694de28733306421b84b94a24""&gt;Decision Transformer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/50""&gt;Full Explanation Post&lt;/a&gt;] [&lt;a href=""https://arxiv.org/pdf/2106.01345.pdf""&gt;Arxiv&lt;/a&gt;] [&lt;a href=""https://github.com/kzl/decision-transformer""&gt;Project page&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;More recent popular computer vision paper breakdowns:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=""https://t.me/casual_gan/48""&gt;DALL-E&lt;/a&gt;&lt;br/&gt;
&lt;a href=""https://t.me/casual_gan/46""&gt;VQGAN&lt;/a&gt;&lt;br/&gt;
&lt;a href=""https://t.me/casual_gan/40""&gt;DINO&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxfvgo,True,,KirillTheMunchKing,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nxfvgo/paper_explained_decision_transformer/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxfvgo/paper_explained_decision_transformer/,66147,1623417758.0,0,,False,,,"{'yfuy5n7x0n471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 182, 'x': 108, 'u': 'https://preview.redd.it/yfuy5n7x0n471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=22ad6d1ff315884f546d89b700e29b9c94119f9e'}, {'y': 364, 'x': 216, 'u': 'https://preview.redd.it/yfuy5n7x0n471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=67d9a26f88a2f7cc6f8feadc358e5c14d3332686'}, {'y': 539, 'x': 320, 'u': 'https://preview.redd.it/yfuy5n7x0n471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=78168e3f4a71b62ebc99a4f7ec885fbe2cccbf21'}, {'y': 1079, 'x': 640, 'u': 'https://preview.redd.it/yfuy5n7x0n471.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=60680f5558f3ca8321faf1566e902903c734a489'}], 's': {'y': 1280, 'x': 759, 'u': 'https://preview.redd.it/yfuy5n7x0n471.png?width=759&amp;format=png&amp;auto=webp&amp;s=faffb3478b73a3f694de28733306421b84b94a24'}, 'id': 'yfuy5n7x0n471'}}",,,,
,deeplearning,Looking for action recognition references that perform post processing to detect start and end time for actions?,t2_bwsrpjo6,False,,0,False,Action recognition papers references,[],r/deeplearning,False,6,,0,,False,t3_nxgu9w,False,dark,0.73,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1623449311.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Looking for action recognition references that perform post processing to detect start and end time for actions?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxgu9w,True,,AbjectDrink3276,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nxgu9w/action_recognition_papers_references/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxgu9w/action_recognition_papers_references/,66147,1623420511.0,0,,False,,,,,,,
,deeplearning,"Hi everyone,

I've heard about deep learning and I find the concept really interesting, but i dont have any idea about how to do it or how it works in detail so do you know what are the prerequisite to learn this science and where i could learn it. My final objective (maybe is it too big?) is to create a bot that could learn from the cryptocurrencies market and be able to make ""predictions"" do you think it could be realisable at my scale? 

&amp;#x200B;

Thank you for reading !",t2_ad6d4twn,False,,0,False,How can I learn deeplearning?,[],r/deeplearning,False,6,,0,,False,t3_nxshw7,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623480758.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve heard about deep learning and I find the concept really interesting, but i dont have any idea about how to do it or how it works in detail so do you know what are the prerequisite to learn this science and where i could learn it. My final objective (maybe is it too big?) is to create a bot that could learn from the cryptocurrencies market and be able to make &amp;quot;predictions&amp;quot; do you think it could be realisable at my scale? &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you for reading !&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxshw7,True,,Idunnos0rry,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nxshw7/how_can_i_learn_deeplearning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxshw7/how_can_i_learn_deeplearning/,66147,1623451958.0,0,,False,,,,,,,
,deeplearning,,t2_ibqd1,False,,0,False,Facebook's Grand AI Challenge,[],r/deeplearning,False,6,,0,,False,t3_nx9i7x,False,dark,0.74,,public,15,0,{},,False,[],,False,False,,{},,False,15,,False,False,,False,,[],{},,False,,1623422935.0,text,6,,,text,aicrowd.com,False,,,,,https://www.aicrowd.com/challenges/neurips-2021-the-nethack-challenge?utm_source=reddit&amp;utm_medium=programming&amp;utm_campaign=nethack,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx9i7x,True,,EscapedLaughter,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nx9i7x/facebooks_grand_ai_challenge/,all_ads,False,https://www.aicrowd.com/challenges/neurips-2021-the-nethack-challenge?utm_source=reddit&amp;utm_medium=programming&amp;utm_campaign=nethack,66147,1623394135.0,0,,False,,,,,,,
,deeplearning,,t2_2htwi6,False,,0,False,MusicBERT: Symbolic Music Understanding with Large-Scale Pre-Training,[],r/deeplearning,False,6,,0,,False,t3_nx9xkp,False,dark,0.92,,public,11,0,{},,False,[],,False,False,,{},,False,11,,False,False,,False,,[],{},,False,,1623424709.0,text,6,,,text,arxiv.org,False,,,,,https://arxiv.org/pdf/2106.05630.pdf,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx9xkp,True,,tobyoup,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nx9xkp/musicbert_symbolic_music_understanding_with/,all_ads,False,https://arxiv.org/pdf/2106.05630.pdf,66147,1623395909.0,0,,False,,,,,,,
,deeplearning,"It’ an elegant way to perform matrix or vector manipulation.  
I  find it’s extremely useful if I have to perform matrix multiplication  of matrices which is of higher dimension, it gives a great flexibility  to sum and multiply among certain axis.  
Ex : if you have to multiply  matrix A of shape (1,200,2,32) &amp; matrix B of shape (2,32,32) and  results in a matrix C of shape (1,200,32).  
This can be implemented as follows:  
np.einsum(‘abcd,cde-&gt;abe’,A,B)  
That’s it ! 

&amp;#x200B;

[https://rakshithv.medium.com/einsum-equation-bb5f6292a98c](https://rakshithv.medium.com/einsum-equation-bb5f6292a98c)",t2_159buvym,False,,0,False,"What is ""Einsum"" equation ?",[],r/deeplearning,False,6,,0,,False,t3_nxlp27,False,dark,0.38,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623461976.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It’ an elegant way to perform matrix or vector manipulation.&lt;br/&gt;
I  find it’s extremely useful if I have to perform matrix multiplication  of matrices which is of higher dimension, it gives a great flexibility  to sum and multiply among certain axis.&lt;br/&gt;
Ex : if you have to multiply  matrix A of shape (1,200,2,32) &amp;amp; matrix B of shape (2,32,32) and  results in a matrix C of shape (1,200,32).&lt;br/&gt;
This can be implemented as follows:&lt;br/&gt;
np.einsum(‘abcd,cde-&amp;gt;abe’,A,B)&lt;br/&gt;
That’s it ! &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://rakshithv.medium.com/einsum-equation-bb5f6292a98c""&gt;https://rakshithv.medium.com/einsum-equation-bb5f6292a98c&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxlp27,True,,rakshith291,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nxlp27/what_is_einsum_equation/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxlp27/what_is_einsum_equation/,66147,1623433176.0,0,,False,,,,,,,
,deeplearning,,t2_159buvym,False,,0,False,"What is ""Einsum"" equation ?",[],r/deeplearning,False,6,,0,,False,t3_nxlm94,False,dark,0.17,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623461769.0,text,6,,,text,rakshithv.medium.com,False,,,,,https://rakshithv.medium.com/einsum-equation-bb5f6292a98c,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxlm94,True,,rakshith291,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nxlm94/what_is_einsum_equation/,all_ads,False,https://rakshithv.medium.com/einsum-equation-bb5f6292a98c,66147,1623432969.0,0,,False,,,,,,,
,deeplearning,"An IEEE team provides a comprehensive overview of the bottom-up and top-down design approaches toward neuromorphic intelligence, highlighting the different levels of granularity present in existing silicon implementations and assessing the benefits of the different circuit design styles in neural processing systems. 

Here is a quick read: [IEEE Publishes Comprehensive Survey of Bottom-Up and Top-Down Neural Processing System Design.](https://syncedreview.com/2021/06/10/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-38/)

The paper *Bottom-Up and Top-Down Neural Processing Systems Design: Neuromorphic Intelligence as the Convergence of Natural and Artificial Intelligence* is on [arXiv](https://arxiv.org/abs/2106.01288).",t2_2fv4yodo,False,,0,False,[R] IEEE Publishes Comprehensive Survey of Bottom-Up and Top-Down Neural Processing System Design,[],r/deeplearning,False,6,,0,,False,t3_nwqnxp,False,dark,0.96,,public,26,0,{},,False,[],,False,False,,{},,False,26,,False,False,,False,,[],{},,True,,1623368296.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;An IEEE team provides a comprehensive overview of the bottom-up and top-down design approaches toward neuromorphic intelligence, highlighting the different levels of granularity present in existing silicon implementations and assessing the benefits of the different circuit design styles in neural processing systems. &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/10/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-38/""&gt;IEEE Publishes Comprehensive Survey of Bottom-Up and Top-Down Neural Processing System Design.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Bottom-Up and Top-Down Neural Processing Systems Design: Neuromorphic Intelligence as the Convergence of Natural and Artificial Intelligence&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2106.01288""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwqnxp,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nwqnxp/r_ieee_publishes_comprehensive_survey_of_bottomup/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nwqnxp/r_ieee_publishes_comprehensive_survey_of_bottomup/,66147,1623339496.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,AI Sign Language Translator,[],r/deeplearning,False,6,,0,,False,t3_nxas4p,False,dark,0.57,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/cTwKP796PPw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI Sign Language Translator', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/cTwKP796PPw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/cTwKP796PPw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/cTwKP796PPw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nxas4p', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1623428207.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/cTwKP796PPw,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxas4p,True,,cmillionaire9,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nxas4p/ai_sign_language_translator/,all_ads,False,https://youtu.be/cTwKP796PPw,66147,1623399407.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI Sign Language Translator', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/cTwKP796PPw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/cTwKP796PPw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,"I have the following problem statement in which I only need to predict whether a given image is an apple or not. For training only 8 images are provided with the following details:

1. apple\_1 image - 2400x1889 PNG
2. apple\_2 image - 641x618 PNG
3. apple\_3 image - 1000x1001 PNG
4. apple\_4 image - 500x500 PNG		contains a sticker on top of fruit
5. apple\_5 image - 2400x1889 PNG
6. apple\_6 image - 1000x1000 PNG
7. apple\_7 image - 253x199 JPG
8. apple\_8 image - 253x199 JPG

&amp;#x200B;

I am thinking about using Transfer learning: either VGG or ResNet-18/34/50. Maybe ResNet is an overkill for this problem statement? How do I deal with such varying image sizes and of different file extensions (PNG, JPG)?

Any online code tutorial will be helpful.

Thanks!",t2_2mmql89p,False,,0,False,CNN - Apple Classification,[],r/deeplearning,False,6,,0,,False,t3_nx882t,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623417937.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have the following problem statement in which I only need to predict whether a given image is an apple or not. For training only 8 images are provided with the following details:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;apple_1 image - 2400x1889 PNG&lt;/li&gt;
&lt;li&gt;apple_2 image - 641x618 PNG&lt;/li&gt;
&lt;li&gt;apple_3 image - 1000x1001 PNG&lt;/li&gt;
&lt;li&gt;apple_4 image - 500x500 PNG     contains a sticker on top of fruit&lt;/li&gt;
&lt;li&gt;apple_5 image - 2400x1889 PNG&lt;/li&gt;
&lt;li&gt;apple_6 image - 1000x1000 PNG&lt;/li&gt;
&lt;li&gt;apple_7 image - 253x199 JPG&lt;/li&gt;
&lt;li&gt;apple_8 image - 253x199 JPG&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am thinking about using Transfer learning: either VGG or ResNet-18/34/50. Maybe ResNet is an overkill for this problem statement? How do I deal with such varying image sizes and of different file extensions (PNG, JPG)?&lt;/p&gt;

&lt;p&gt;Any online code tutorial will be helpful.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx882t,True,,grid_world,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/nx882t/cnn_apple_classification/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nx882t/cnn_apple_classification/,66147,1623389137.0,0,,False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,Non-Parametric Transformers | Paper explained!,[],r/deeplearning,False,6,,0,,False,t3_nwk1zy,False,dark,0.91,,public,27,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6ekOVosCQN8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Non-Parametric Transformers | Paper explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6ekOVosCQN8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6ekOVosCQN8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6ekOVosCQN8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nwk1zy', 'height': 200}",,False,27,,False,False,,False,,[],{},,False,,1623348904.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/6ekOVosCQN8,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwk1zy,True,,gordicaleksa,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nwk1zy/nonparametric_transformers_paper_explained/,all_ads,False,https://youtu.be/6ekOVosCQN8,66147,1623320104.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Non-Parametric Transformers | Paper explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6ekOVosCQN8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6ekOVosCQN8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,Can someone suggest me some good course /platform to learn NLP with hands-on experience such as chatboat and all ?,t2_4839qzd1,False,,0,False,Suggestions for NLP tutorials,[],r/deeplearning,False,6,,0,,False,t3_nx6l0k,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623412142.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can someone suggest me some good course /platform to learn NLP with hands-on experience such as chatboat and all ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx6l0k,True,,Vivek_Murali,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nx6l0k/suggestions_for_nlp_tutorials/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nx6l0k/suggestions_for_nlp_tutorials/,66147,1623383342.0,0,,False,,,,,,,
,deeplearning,Hello wonderful people. First a little background about me. I am currently in my second year of MTech Signal Processing. I specifically chose this brach because of its wide ranging applications in AI and deep learning. So I want a little help from you guys on what sort of research area I can chose so that my dissertation stands out a little from the crowd and which can actually help me in landing a job. I am also thinking of publishing a paper that would add to the project I want to work on. I am very inclined towards deep learning applications in medical field as well as in field the sound processing if that makes sense. Any sort of help would be appreciated.,t2_22fn1krt,False,,0,False,Some help regarding my upcoming dissertation next semester,[],r/deeplearning,False,6,,0,,False,t3_nx5vyl,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623409799.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello wonderful people. First a little background about me. I am currently in my second year of MTech Signal Processing. I specifically chose this brach because of its wide ranging applications in AI and deep learning. So I want a little help from you guys on what sort of research area I can chose so that my dissertation stands out a little from the crowd and which can actually help me in landing a job. I am also thinking of publishing a paper that would add to the project I want to work on. I am very inclined towards deep learning applications in medical field as well as in field the sound processing if that makes sense. Any sort of help would be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx5vyl,True,,AltruisticEmphasis,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nx5vyl/some_help_regarding_my_upcoming_dissertation_next/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nx5vyl/some_help_regarding_my_upcoming_dissertation_next/,66147,1623380999.0,2,,False,,,,,,,
,deeplearning,"Guys, I am college student in last semester and would like to prepare myself for the work after graduating. I would appreciate if you guy can share tools/libs or your experience working in the field. (which area? Which tool? Which sector? Firm? Research? Etc. )

P/s If here is the wrong place for the question, mods please remove it.",t2_aajz5dw6,False,,0,False,Tools you are using...,[],r/deeplearning,False,6,,0,,False,t3_nx0n1s,False,dark,0.44,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623393542.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Guys, I am college student in last semester and would like to prepare myself for the work after graduating. I would appreciate if you guy can share tools/libs or your experience working in the field. (which area? Which tool? Which sector? Firm? Research? Etc. )&lt;/p&gt;

&lt;p&gt;P/s If here is the wrong place for the question, mods please remove it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx0n1s,True,,PlutoMother,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nx0n1s/tools_you_are_using/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nx0n1s/tools_you_are_using/,66147,1623364742.0,0,,False,,,,,,,
,deeplearning,"Hi everyone, I am 36 yrs old. My major is computer science.  I am desperatley  in a need for a job to have a roof and a loaf. 

Recently I have applied for many jobs, I got 1000 plus rejections. What I see in the job market nowadays is video and image processing jobs. 
I set this goal: I want them to look for me in a year or less. I want them to ask for my service,  not me looking for companies  anymore.   
I want your help , guide me , order me, tell me what to do to become an expert in video processing. I promise, I will follow your steps and post my results here after months.

Edit: language mistakes",t2_zj4u90g,False,,0,False,Just give your orders !,[],r/deeplearning,False,6,,0,,False,t3_nwosn8,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623363592.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, I am 36 yrs old. My major is computer science.  I am desperatley  in a need for a job to have a roof and a loaf. &lt;/p&gt;

&lt;p&gt;Recently I have applied for many jobs, I got 1000 plus rejections. What I see in the job market nowadays is video and image processing jobs. 
I set this goal: I want them to look for me in a year or less. I want them to ask for my service,  not me looking for companies  anymore.&lt;br/&gt;
I want your help , guide me , order me, tell me what to do to become an expert in video processing. I promise, I will follow your steps and post my results here after months.&lt;/p&gt;

&lt;p&gt;Edit: language mistakes&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwosn8,True,,Beginner4ever,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/nwosn8/just_give_your_orders/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nwosn8/just_give_your_orders/,66147,1623334792.0,0,,False,,,,,,,
,deeplearning," Hi! I would like to cluster news articles with their similarity, I want to create and classifier with respect to their clusters.

I have 4 million of news articles text data and it's completely unsupervised, Now I am stuck on which is the best technique that I should use and how do I validate that the cluster perfect and having similarity. 

Thanks for any input!",t2_a8k0v7v0,False,,0,False,Best clustering approach on unsupervised news articles?,[],r/deeplearning,False,6,,0,,False,t3_nwhfgv,False,dark,0.73,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,True,,1623337780.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! I would like to cluster news articles with their similarity, I want to create and classifier with respect to their clusters.&lt;/p&gt;

&lt;p&gt;I have 4 million of news articles text data and it&amp;#39;s completely unsupervised, Now I am stuck on which is the best technique that I should use and how do I validate that the cluster perfect and having similarity. &lt;/p&gt;

&lt;p&gt;Thanks for any input!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwhfgv,True,,Alan491,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/nwhfgv/best_clustering_approach_on_unsupervised_news/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nwhfgv/best_clustering_approach_on_unsupervised_news/,66147,1623308980.0,0,,False,,,,,,,
,deeplearning,"Hi guys, i'm data science student and i'm traying to build a mask r cnn model for 13 classes for instances segmentation task .

My datasets have the following distribution:

train set:

* n images =  1296

&amp;#8203;

    # class:n_annotations
    CLASS_WEIGHTS = {1:1559, 2:835, 3:1112, 4:1205,
                 5:997, 6:31, 7:120, 8:37,
                 9:48, 10:28, 11:37, 12:1992, 13:1907}

val set:

* n images = 154

&amp;#8203;

    # class:n_annotations
    CLASS_WEIGHTS = {1:130, 2:79, 3:93, 4:152,
                     5:144, 6:2, 7:18, 8:0,
                     9:0, 10:0, 11:1, 12:235, 13:241}

I tried this:

    class CustomConfig(Config):
        """"""Configuration for training on the custom  dataset.
        Derives from the base Config class and overrides some values.
        """"""
        # Give the configuration a recognizable name
        NAME = ""object""
    
        # We use a GPU with 12GB memory, which can fit two images.
        # Adjust down if you use a smaller GPU.
        IMAGES_PER_GPU = 2
    
        # Number of classes (including background)
        NUM_CLASSES = 1 + 13
        # Number of training steps per epoch
        STEPS_PER_EPOCH = 120
        VALIDATION_STEPS = 30
    
        # Skip detections with &lt; 85% confidence
        DETECTION_MIN_CONFIDENCE = 0.5
        BACKBONE_STRIDES = [8,16,32,64,128]
        DETECTION_NMS_THRESHOLD=0.1
    
    ####################################################################
    
    
    augmentation = iaa.Sequential([
        iaa.Fliplr(0.8), # only horizontal flip here
        iaa.Flipud(0.8), # only vertical flip here
    ])
    
    ####################################################################
    
    CLASS_WEIGHTS = {1:1559, 2:835, 3:1112, 4:1205,
                     5:997, 6:31, 7:120, 8:37,
                     9:48, 10:28, 11:37, 12:1992, 13:1907}
    
    def compute_class_weights(CLASS_WEIGHTS=CLASS_WEIGHTS):
    
      mean = np.array(list(CLASS_WEIGHTS.values())).mean() # sum_class_occurence / nb_classes
      max_weight = np.array(list(CLASS_WEIGHTS.values())).max()
      CLASS_WEIGHTS.update((x, float(max_weight/(y))) for x, y in CLASS_WEIGHTS.items())
      CLASS_WEIGHTS=dict(sorted(CLASS_WEIGHTS.items()))
    
      return CLASS_WEIGHTS
    
    class_weights = compute_class_weights(CLASS_WEIGHTS)
    
    ########################################################################
    print(""Training mask r cnn"")
    model.train(dataset_train, dataset_val,
                learning_rate=0.0001*2,
                class_weight= class_weights,
                epochs=2,          # i tried diffferent number of epochs (2-20-30-50)
                augmentation= augmentation,
                layers='heads', custom_callbacks=[tensorboard])
    
    history = model.keras_model.history.history	

* Loss: values between range (0.6-1.8, based on number of epochs)
*  val\_loss : values between range (0.4 - 1)

both values are however fluctuating. 

I WANT fix this because i get this error : NO ISTANCES TO DISPLAY.  With only the 2 largest classes, it works very well.

&amp;#x200B;

Thanks for the attention.",t2_3zwz9769,False,,0,False,Fix Class imbalance in Mask r cnn,[],r/deeplearning,False,6,,0,,False,t3_nwt13h,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623374231.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, i&amp;#39;m data science student and i&amp;#39;m traying to build a mask r cnn model for 13 classes for instances segmentation task .&lt;/p&gt;

&lt;p&gt;My datasets have the following distribution:&lt;/p&gt;

&lt;p&gt;train set:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;n images =  1296&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#8203;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# class:n_annotations
CLASS_WEIGHTS = {1:1559, 2:835, 3:1112, 4:1205,
             5:997, 6:31, 7:120, 8:37,
             9:48, 10:28, 11:37, 12:1992, 13:1907}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;val set:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;n images = 154&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#8203;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# class:n_annotations
CLASS_WEIGHTS = {1:130, 2:79, 3:93, 4:152,
                 5:144, 6:2, 7:18, 8:0,
                 9:0, 10:0, 11:1, 12:235, 13:241}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I tried this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class CustomConfig(Config):
    &amp;quot;&amp;quot;&amp;quot;Configuration for training on the custom  dataset.
    Derives from the base Config class and overrides some values.
    &amp;quot;&amp;quot;&amp;quot;
    # Give the configuration a recognizable name
    NAME = &amp;quot;object&amp;quot;

    # We use a GPU with 12GB memory, which can fit two images.
    # Adjust down if you use a smaller GPU.
    IMAGES_PER_GPU = 2

    # Number of classes (including background)
    NUM_CLASSES = 1 + 13
    # Number of training steps per epoch
    STEPS_PER_EPOCH = 120
    VALIDATION_STEPS = 30

    # Skip detections with &amp;lt; 85% confidence
    DETECTION_MIN_CONFIDENCE = 0.5
    BACKBONE_STRIDES = [8,16,32,64,128]
    DETECTION_NMS_THRESHOLD=0.1

####################################################################


augmentation = iaa.Sequential([
    iaa.Fliplr(0.8), # only horizontal flip here
    iaa.Flipud(0.8), # only vertical flip here
])

####################################################################

CLASS_WEIGHTS = {1:1559, 2:835, 3:1112, 4:1205,
                 5:997, 6:31, 7:120, 8:37,
                 9:48, 10:28, 11:37, 12:1992, 13:1907}

def compute_class_weights(CLASS_WEIGHTS=CLASS_WEIGHTS):

  mean = np.array(list(CLASS_WEIGHTS.values())).mean() # sum_class_occurence / nb_classes
  max_weight = np.array(list(CLASS_WEIGHTS.values())).max()
  CLASS_WEIGHTS.update((x, float(max_weight/(y))) for x, y in CLASS_WEIGHTS.items())
  CLASS_WEIGHTS=dict(sorted(CLASS_WEIGHTS.items()))

  return CLASS_WEIGHTS

class_weights = compute_class_weights(CLASS_WEIGHTS)

########################################################################
print(&amp;quot;Training mask r cnn&amp;quot;)
model.train(dataset_train, dataset_val,
            learning_rate=0.0001*2,
            class_weight= class_weights,
            epochs=2,          # i tried diffferent number of epochs (2-20-30-50)
            augmentation= augmentation,
            layers=&amp;#39;heads&amp;#39;, custom_callbacks=[tensorboard])

history = model.keras_model.history.history 
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Loss: values between range (0.6-1.8, based on number of epochs)&lt;/li&gt;
&lt;li&gt; val_loss : values between range (0.4 - 1)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;both values are however fluctuating. &lt;/p&gt;

&lt;p&gt;I WANT fix this because i get this error : NO ISTANCES TO DISPLAY.  With only the 2 largest classes, it works very well.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks for the attention.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwt13h,True,,Dario_Della,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nwt13h/fix_class_imbalance_in_mask_r_cnn/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nwt13h/fix_class_imbalance_in_mask_r_cnn/,66147,1623345431.0,0,,False,,,,,,,
,deeplearning,"Hi, I used a neural network on Keras to approximate a concave one dimensional function , I would like to find the argmax and the max of my neural network, what would be the easiest way to solve this ? Should I implement something myself or does Keras already have some buil in function for that ?

Thanks!",t2_64rkugj2,False,,0,False,maximize a neural network,[],r/deeplearning,False,6,,0,,False,t3_nx0wb4,False,dark,0.2,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623394275.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I used a neural network on Keras to approximate a concave one dimensional function , I would like to find the argmax and the max of my neural network, what would be the easiest way to solve this ? Should I implement something myself or does Keras already have some buil in function for that ?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx0wb4,True,,draleo183013,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nx0wb4/maximize_a_neural_network/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nx0wb4/maximize_a_neural_network/,66147,1623365475.0,0,,False,,,,,,,
,deeplearning,,t2_154ll80i,False,,0,False,The 10 Emerging Deep Learning Trends To Watch in The Near Future,[],r/deeplearning,False,6,,0,,False,t3_nwru4j,False,dark,0.43,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623371253.0,text,6,,,text,ubuntupit.com,False,,,,,https://www.ubuntupit.com/emerging-deep-learning-trends/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwru4j,True,,UbuntuPIT,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nwru4j/the_10_emerging_deep_learning_trends_to_watch_in/,all_ads,False,https://www.ubuntupit.com/emerging-deep-learning-trends/,66147,1623342453.0,0,,False,,,,,,,
,deeplearning,,t2_5v1ni8yq,False,,0,False,"Using deep learning to decipher the regulatory code of gene expression, a review",[],r/deeplearning,False,6,,0,,False,t3_nwkop6,False,dark,0.62,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1623351352.0,text,6,,,text,frontiersin.org,False,,,,,https://www.frontiersin.org/articles/10.3389/fmolb.2021.673363,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwkop6,True,,janimezzz,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nwkop6/using_deep_learning_to_decipher_the_regulatory/,all_ads,False,https://www.frontiersin.org/articles/10.3389/fmolb.2021.673363,66147,1623322552.0,0,,False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,😂😂😂,[],r/deeplearning,False,6,,0,,False,t3_nwtous,False,dark,0.17,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623375888.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/utv9m9h06h471.png,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwtous,True,,Community-Of-Babel,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nwtous/_/,all_ads,False,https://i.redd.it/utv9m9h06h471.png,66147,1623347088.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '😂😂😂', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nwtl5k', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 10, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 10, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1623375625.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/utv9m9h06h471.png', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nwtl5k', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/nwtl5k/_/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://i.redd.it/utv9m9h06h471.png', 'subreddit_subscribers': 0, 'created_utc': 1623346825.0, 'num_crossposts': 7, 'media': None, 'is_video': False}]",t3_nwtl5k,,,,,
,deeplearning,"Programming is way more fun when you learn/work with someone. Help each other, ask questions, brainstorm, etc. There is just so much benefit to joining a community when you are in this field, especially when you cannot find the question you are looking for on stack overflow! 😉  
This is the same thing with AI, and it is why a little less than a year ago, I created a discord server where anyone learning or working in the field could come and share their projects, learn together, work together, and much more. As a result, the community is now close to 13'000 members, which is unbelievable! So glad to see it growing and see everyone so active.  


Join us if you are in the field of AI!  
[https://discord.gg/learnaitogether](https://discord.gg/learnaitogether)",t2_c14wpji,False,,0,False,"Are you currently learning or working with AI? Well, 12'000+ of us are, too! So join our Discord servers, ask questions, find teammates, share your projects, help others, and much more!",[],r/deeplearning,False,6,,0,,False,t3_nvt9fs,False,dark,0.84,,public,42,1,{},,False,[],,False,False,,{},,False,42,,False,False,,False,,[],{},,True,,1623266002.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Programming is way more fun when you learn/work with someone. Help each other, ask questions, brainstorm, etc. There is just so much benefit to joining a community when you are in this field, especially when you cannot find the question you are looking for on stack overflow! 😉&lt;br/&gt;
This is the same thing with AI, and it is why a little less than a year ago, I created a discord server where anyone learning or working in the field could come and share their projects, learn together, work together, and much more. As a result, the community is now close to 13&amp;#39;000 members, which is unbelievable! So glad to see it growing and see everyone so active.  &lt;/p&gt;

&lt;p&gt;Join us if you are in the field of AI!&lt;br/&gt;
&lt;a href=""https://discord.gg/learnaitogether""&gt;https://discord.gg/learnaitogether&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvt9fs,True,,OnlyProggingForFun,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvt9fs/are_you_currently_learning_or_working_with_ai/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvt9fs/are_you_currently_learning_or_working_with_ai/,66147,1623237202.0,0,,False,,,,,,,
,deeplearning,"A research team from UC Berkeley, Facebook AI Research and Google Brain abstracts Reinforcement Learning (RL) as a sequence modelling problem. Their proposed Decision Transformer simply outputs optimal actions by leveraging a causally masked transformer, yet matches or exceeds state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.

Here is a quick read: [Pieter Abbeel Team’s Decision Transformer Abstracts RL as Sequence Modelling.](https://syncedreview.com/2021/06/09/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-37/)

The paper *Decision Transformer: Reinforcement Learning via Sequence Modeling* is on [arXiv](https://arxiv.org/abs/2106.01345).",t2_2fv4yodo,False,,0,False,[R] Pieter Abbeel Team’s Decision Transformer Abstracts RL as Sequence Modelling,[],r/deeplearning,False,6,,0,,False,t3_nvxwi7,False,dark,0.82,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,True,,1623279460.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from UC Berkeley, Facebook AI Research and Google Brain abstracts Reinforcement Learning (RL) as a sequence modelling problem. Their proposed Decision Transformer simply outputs optimal actions by leveraging a causally masked transformer, yet matches or exceeds state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/09/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-37/""&gt;Pieter Abbeel Team’s Decision Transformer Abstracts RL as Sequence Modelling.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Decision Transformer: Reinforcement Learning via Sequence Modeling&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2106.01345""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvxwi7,True,,Yuqing7,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nvxwi7/r_pieter_abbeel_teams_decision_transformer/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvxwi7/r_pieter_abbeel_teams_decision_transformer/,66147,1623250660.0,0,,False,,,,,,,
,deeplearning,EDIT: CURSOR'S MOVEMENT. I am sorry guy's I thought I typed this.smh,t2_34qgdyb6,False,,0,False,Can NN be trained to predict the attention of the user based on its movement?,[],r/deeplearning,False,6,,0,,False,t3_nw2qxo,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1623299340.0,,[],{},,True,,1623292096.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;EDIT: CURSOR&amp;#39;S MOVEMENT. I am sorry guy&amp;#39;s I thought I typed this.smh&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nw2qxo,True,,yaakarsh1011,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nw2qxo/can_nn_be_trained_to_predict_the_attention_of_the/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nw2qxo/can_nn_be_trained_to_predict_the_attention_of_the/,66147,1623263296.0,0,,False,,,,,,,
,deeplearning,"I am working on identifying product placements in Youtube Videos and currently, I am looking at kids' toys being endorsed. When I was collecting training data for the toys, I noticed that most of the product images have just the object in the image and nothing else. There is no other pictorial significance other than the object in the image. 

For example, this is one of the training images: 
[Training Image](https://drive.google.com/file/d/1Jc04W5-Y1HLAbyoH8x-06Zg9dZf8inY4/view?usp=sharing)

And this is one of the images, that I'll be testing my object detector on after training my model:
[Inference Image](https://drive.google.com/file/d/1mHDerDcCd5UPykUB-DXjgrxhFl7slIvM/view?usp=sharing)

I just wanted to know how will this affect the performance of the model. I'll be annotating these images and use Few-Shot Learning for this task but I never encountered this situation where the training sample had images that contained only the object and nothing else. Also, since the image itself contains the object, fit to the image dimensions, and has nothing else in the image, should I actually annotate these images or is there any other approach that I can adopt that would help me train this kind of images faster? (on top of my mind, resize all the images to one size and since all the objects are fit to image dimensions, automate the process of drawing bounding boxes at coordinates close to the borders of the image)",t2_2y8jn07i,False,,0,False,"How well will an objector work if in the training images, there is no other spatial information other than the object itself?",[],r/deeplearning,False,6,,0,,False,t3_nw744v,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623303613.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am working on identifying product placements in Youtube Videos and currently, I am looking at kids&amp;#39; toys being endorsed. When I was collecting training data for the toys, I noticed that most of the product images have just the object in the image and nothing else. There is no other pictorial significance other than the object in the image. &lt;/p&gt;

&lt;p&gt;For example, this is one of the training images: 
&lt;a href=""https://drive.google.com/file/d/1Jc04W5-Y1HLAbyoH8x-06Zg9dZf8inY4/view?usp=sharing""&gt;Training Image&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And this is one of the images, that I&amp;#39;ll be testing my object detector on after training my model:
&lt;a href=""https://drive.google.com/file/d/1mHDerDcCd5UPykUB-DXjgrxhFl7slIvM/view?usp=sharing""&gt;Inference Image&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I just wanted to know how will this affect the performance of the model. I&amp;#39;ll be annotating these images and use Few-Shot Learning for this task but I never encountered this situation where the training sample had images that contained only the object and nothing else. Also, since the image itself contains the object, fit to the image dimensions, and has nothing else in the image, should I actually annotate these images or is there any other approach that I can adopt that would help me train this kind of images faster? (on top of my mind, resize all the images to one size and since all the objects are fit to image dimensions, automate the process of drawing bounding boxes at coordinates close to the borders of the image)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nw744v,True,,pranay-ar,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nw744v/how_well_will_an_objector_work_if_in_the_training/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nw744v/how_well_will_an_objector_work_if_in_the_training/,66147,1623274813.0,0,,False,,,,,,,
,deeplearning,,t2_clegqv8z,False,,0,False,GAN trained on instagram models,[],r/deeplearning,False,6,,0,,False,t3_nv6mzi,False,dark,0.93,,public,158,1,{},,False,[],"{'reddit_video': {'bitrate_kbps': 1200, 'fallback_url': 'https://v.redd.it/50i9nxgv72471/DASH_480.mp4?source=fallback', 'height': 480, 'width': 480, 'scrubber_media_url': 'https://v.redd.it/50i9nxgv72471/DASH_96.mp4', 'dash_url': 'https://v.redd.it/50i9nxgv72471/DASHPlaylist.mpd?a=1626449472%2CYTVjYmNlY2JkNTk1ODk3MmRlNTQ5ZjRhMzAwMGQyNzEzMjYzYzE0ZjJiODE3YzY4NDFhYTI1MDdmM2MyZGY3Nw%3D%3D&amp;v=1&amp;f=sd', 'duration': 19, 'hls_url': 'https://v.redd.it/50i9nxgv72471/HLSPlaylist.m3u8?a=1626449472%2CODNjMWRkNTFiOGM0ODRkMjc3OWE3ZTFlZmQ5MDBmYTY3NmMwYTY2MDQwYWRkODMzNjUwYTZkM2FjY2IxYjgyNA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,158,,False,False,,False,,[],{},,False,,1623195240.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/50i9nxgv72471,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv6mzi,True,,ThisModelDoesNotExis,,42,True,all_ads,False,[],False,,/r/deeplearning/comments/nv6mzi/gan_trained_on_instagram_models/,all_ads,False,https://v.redd.it/50i9nxgv72471,66147,1623166440.0,0,"{'reddit_video': {'bitrate_kbps': 1200, 'fallback_url': 'https://v.redd.it/50i9nxgv72471/DASH_480.mp4?source=fallback', 'height': 480, 'width': 480, 'scrubber_media_url': 'https://v.redd.it/50i9nxgv72471/DASH_96.mp4', 'dash_url': 'https://v.redd.it/50i9nxgv72471/DASHPlaylist.mpd?a=1626449472%2CYTVjYmNlY2JkNTk1ODk3MmRlNTQ5ZjRhMzAwMGQyNzEzMjYzYzE0ZjJiODE3YzY4NDFhYTI1MDdmM2MyZGY3Nw%3D%3D&amp;v=1&amp;f=sd', 'duration': 19, 'hls_url': 'https://v.redd.it/50i9nxgv72471/HLSPlaylist.m3u8?a=1626449472%2CODNjMWRkNTFiOGM0ODRkMjc3OWE3ZTFlZmQ5MDBmYTY3NmMwYTY2MDQwYWRkODMzNjUwYTZkM2FjY2IxYjgyNA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,https://youtu.be/z9mDGLKKqo0,t2_357rx0k0,False,,0,False,"AI Weekly Update - June 9th, 2021",[],r/deeplearning,False,6,,0,,False,t3_nw12t4,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623287763.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://youtu.be/z9mDGLKKqo0""&gt;https://youtu.be/z9mDGLKKqo0&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nw12t4,True,,HenryAILabs,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nw12t4/ai_weekly_update_june_9th_2021/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nw12t4/ai_weekly_update_june_9th_2021/,66147,1623258963.0,0,,False,,,,,,,
,deeplearning,"This is the autoencoder I am building.

https://preview.redd.it/gdu3p9hrv9471.png?width=739&amp;format=png&amp;auto=webp&amp;s=e1b914f6433b2a3bbd962bb265a18278efa89f1d",t2_39dnc90e,False,,0,False,Does anyone know why my val_loss is nan?,[],r/deeplearning,False,6,,0,,False,t3_nw0y6t,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623287434.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is the autoencoder I am building.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/gdu3p9hrv9471.png?width=739&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e1b914f6433b2a3bbd962bb265a18278efa89f1d""&gt;https://preview.redd.it/gdu3p9hrv9471.png?width=739&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e1b914f6433b2a3bbd962bb265a18278efa89f1d&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nw0y6t,True,,HVACCalculations,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/nw0y6t/does_anyone_know_why_my_val_loss_is_nan/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nw0y6t/does_anyone_know_why_my_val_loss_is_nan/,66147,1623258634.0,0,,False,,,"{'gdu3p9hrv9471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 123, 'x': 108, 'u': 'https://preview.redd.it/gdu3p9hrv9471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6dd0ffa8d94472e4f7ef2113b06e6a806672cdcd'}, {'y': 246, 'x': 216, 'u': 'https://preview.redd.it/gdu3p9hrv9471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d5c3e68890b087d38aa9573e7954897d67893f6'}, {'y': 365, 'x': 320, 'u': 'https://preview.redd.it/gdu3p9hrv9471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d93e2d3fcd2b52dfb7d236701a98e16b61ef337d'}, {'y': 731, 'x': 640, 'u': 'https://preview.redd.it/gdu3p9hrv9471.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2d05bdeacfc20c989359ebe916ee4fc73d2210f4'}], 's': {'y': 845, 'x': 739, 'u': 'https://preview.redd.it/gdu3p9hrv9471.png?width=739&amp;format=png&amp;auto=webp&amp;s=e1b914f6433b2a3bbd962bb265a18278efa89f1d'}, 'id': 'gdu3p9hrv9471'}}",,,,
,deeplearning,,t2_3r02kqm0,False,,0,False,"Pianist AI&gt; Level 4, Try 10 &gt; Getting better day by day :)!",[],r/deeplearning,False,6,,0,,False,t3_nvvjd1,False,dark,0.6,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/POVyCBcPj2s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Level 4: Try 10', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/POVyCBcPj2s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '[ The Pianist AI ]', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/POVyCBcPj2s/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ThePianistAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/POVyCBcPj2s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nvvjd1', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1623272896.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/POVyCBcPj2s,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvvjd1,True,,amin_mlm,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nvvjd1/pianist_ai_level_4_try_10_getting_better_day_by/,all_ads,False,https://youtu.be/POVyCBcPj2s,66147,1623244096.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Level 4: Try 10', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/POVyCBcPj2s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '[ The Pianist AI ]', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/POVyCBcPj2s/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ThePianistAI'}}",False,,,,,,,
,deeplearning,"Hi, I'm trying to construct a model that takes in the first two/three input values from the user and based on those values, decides the best 4th independent variable to ask the user to optimize the time needed to bucket the user into one of the 5-6 different buckets (supervised clusters). The initial approaches that I was considering were bidirectional LSTM/RNN's.. but after reading up on these two, I'm now thinking there may be more suitable/clever approaches to tackles this. Thank you, deep learning gods of Reddit xx",t2_4okx2lwr,False,,0,False,Dynamic model that predicts the best next input variable to ask based on the first two/three inputs,[],r/deeplearning,False,6,,0,,False,t3_nvza2w,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623283154.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I&amp;#39;m trying to construct a model that takes in the first two/three input values from the user and based on those values, decides the best 4th independent variable to ask the user to optimize the time needed to bucket the user into one of the 5-6 different buckets (supervised clusters). The initial approaches that I was considering were bidirectional LSTM/RNN&amp;#39;s.. but after reading up on these two, I&amp;#39;m now thinking there may be more suitable/clever approaches to tackles this. Thank you, deep learning gods of Reddit xx&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvza2w,True,,lalopark,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvza2w/dynamic_model_that_predicts_the_best_next_input/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvza2w/dynamic_model_that_predicts_the_best_next_input/,66147,1623254354.0,0,,False,,,,,,,
,deeplearning,"I came across Thinc library because I am a spacy user.

&amp;#x200B;

I am very confused about how Thinc implement the back-propagation. Did someone get into that?",t2_a1citpn9,False,,0,False,Thinc library for deep learning.,[],r/deeplearning,False,6,,0,,False,t3_nvuxf0,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623271107.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I came across Thinc library because I am a spacy user.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am very confused about how Thinc implement the back-propagation. Did someone get into that?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvuxf0,True,,MMOigres,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nvuxf0/thinc_library_for_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvuxf0/thinc_library_for_deep_learning/,66147,1623242307.0,0,,False,,,,,,,
,deeplearning,"I have a custom dataset with annotations in .json format. HI was watching various tutorials for custom tfod, and all were using .XML files as annotations. Is there anyway to use .json fornat as it is? 
P.S I'm a newbie in this field .",t2_7oqb9etn,False,,0,False,Custom TFOD,[],r/deeplearning,False,6,,0,,False,t3_nvs5ki,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623261846.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a custom dataset with annotations in .json format. HI was watching various tutorials for custom tfod, and all were using .XML files as annotations. Is there anyway to use .json fornat as it is? 
P.S I&amp;#39;m a newbie in this field .&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvs5ki,True,,Lonely_Soul97,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvs5ki/custom_tfod/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvs5ki/custom_tfod/,66147,1623233046.0,0,,False,,,,,,,
,deeplearning,"In the field of AI, the adaptability of imaginary numbers is sometimes overlooked. When contrasted to their real-valued equivalents, the added domain information contained in these numbers can enable substantially richer representations.
I'm here to announce the release of the first of two reports featured on Weights and Biases, which delves deep into the math underpinning complex variable optimization and includes a regressive example in Tensorflow to demonstrate its utility. You can find it here: 

https://wandb.ai/darshandeshpande/complex-optimization/reports/The-Reality-Behind-the-Optimization-of-Imaginary-Variables--Vmlldzo2OTk3MDM

The goal of this series is to encourage ML researchers and practitioners to indulge in complex numbers and representations in their research. Any feedback or suggestions are most welcome :)",t2_5yyol1fn,False,,0,False,A Mathematical Guide to Complex Variable Optimization,[],r/deeplearning,False,6,,0,,False,t3_nvmhfl,False,dark,0.71,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1623239257.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In the field of AI, the adaptability of imaginary numbers is sometimes overlooked. When contrasted to their real-valued equivalents, the added domain information contained in these numbers can enable substantially richer representations.
I&amp;#39;m here to announce the release of the first of two reports featured on Weights and Biases, which delves deep into the math underpinning complex variable optimization and includes a regressive example in Tensorflow to demonstrate its utility. You can find it here: &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://wandb.ai/darshandeshpande/complex-optimization/reports/The-Reality-Behind-the-Optimization-of-Imaginary-Variables--Vmlldzo2OTk3MDM""&gt;https://wandb.ai/darshandeshpande/complex-optimization/reports/The-Reality-Behind-the-Optimization-of-Imaginary-Variables--Vmlldzo2OTk3MDM&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The goal of this series is to encourage ML researchers and practitioners to indulge in complex numbers and representations in their research. Any feedback or suggestions are most welcome :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvmhfl,True,,Megixist,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvmhfl/a_mathematical_guide_to_complex_variable/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvmhfl/a_mathematical_guide_to_complex_variable/,66147,1623210457.0,0,,False,,,,,,,
,deeplearning,,t2_1568ks,False,,0,False,DeepMind scientists: Reinforcement learning is enough for general AI,[],r/deeplearning,False,6,,0,,False,t3_nv1kbv,False,dark,0.77,,public,16,0,{},,False,[],,False,False,,{},,False,16,,False,False,,False,,[],{},,False,,1623179485.0,text,6,,,text,bdtechtalks.com,False,,,,,https://bdtechtalks.com/2021/06/07/deepmind-artificial-intelligence-reward-maximization/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv1kbv,True,,bendee983,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nv1kbv/deepmind_scientists_reinforcement_learning_is/,all_ads,False,https://bdtechtalks.com/2021/06/07/deepmind-artificial-intelligence-reward-maximization/,66147,1623150685.0,0,,False,,,,,,,
,deeplearning,,t2_ebf9d,False,,0,False,"A model that detects filler words and shouts them back at you would be quite useful, be wary of false positives with like/so/etc.",[],r/deeplearning,False,6,,0,,False,t3_nvg372,False,dark,0.75,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6bvPECCshIo?start=57&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Community S1 E10 Public Speaking', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6bvPECCshIo?start=57&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'SmokeAndMirrorsBaby', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6bvPECCshIo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/SmokeAndMirrorsBaby'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6bvPECCshIo?start=57&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nvg372', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1623219140.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/6bvPECCshIo?t=57,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvg372,True,,JoelMahon,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvg372/a_model_that_detects_filler_words_and_shouts_them/,all_ads,False,https://youtu.be/6bvPECCshIo?t=57,66147,1623190340.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Community S1 E10 Public Speaking', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6bvPECCshIo?start=57&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'SmokeAndMirrorsBaby', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6bvPECCshIo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/SmokeAndMirrorsBaby'}}",False,,,,,,,
,deeplearning,,t2_11pdrgca,False,,0,False,Character animation layering using AI is here! [https://youtu.be/SkJNxLYNwN0],[],r/deeplearning,False,6,,0,,False,t3_nurkp4,False,dark,0.98,,public,75,0,{},,False,[],"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/z6jxfr71px371/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/z6jxfr71px371/DASH_96.mp4', 'dash_url': 'https://v.redd.it/z6jxfr71px371/DASHPlaylist.mpd?a=1626449472%2COGRlYzEyY2Y1YmYzYWJmNDlkNzlmM2M4ODUyZGEyNjc0ZTI4MTRhY2UyNWNhNTYyYTY1YjI0ZjM3NDc2ZWNlNw%3D%3D&amp;v=1&amp;f=sd', 'duration': 30, 'hls_url': 'https://v.redd.it/z6jxfr71px371/HLSPlaylist.m3u8?a=1626449472%2CNDA4ZTNlODE3ZDI1YTdkMWMyNjViOTAxMDNjYjE3NTYxODk5M2Q0OWFmMWE5NjJkOWE4NTUxYWY1N2I2MDc3Mg%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,75,,False,False,,False,,[],{},,False,,1623139951.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/z6jxfr71px371,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nurkp4,True,,-BlackSquirrel-,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nurkp4/character_animation_layering_using_ai_is_here/,all_ads,False,https://v.redd.it/z6jxfr71px371,66147,1623111151.0,0,"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/z6jxfr71px371/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/z6jxfr71px371/DASH_96.mp4', 'dash_url': 'https://v.redd.it/z6jxfr71px371/DASHPlaylist.mpd?a=1626449472%2COGRlYzEyY2Y1YmYzYWJmNDlkNzlmM2M4ODUyZGEyNjc0ZTI4MTRhY2UyNWNhNTYyYTY1YjI0ZjM3NDc2ZWNlNw%3D%3D&amp;v=1&amp;f=sd', 'duration': 30, 'hls_url': 'https://v.redd.it/z6jxfr71px371/HLSPlaylist.m3u8?a=1626449472%2CNDA4ZTNlODE3ZDI1YTdkMWMyNjViOTAxMDNjYjE3NTYxODk5M2Q0OWFmMWE5NjJkOWE4NTUxYWY1N2I2MDc3Mg%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,"Wouldn't it be amazing if you could simply type a text prompt describing the image in as much or as little detail as you want and a bunch of images fitting the description was generated on the fly? Well, thanks to the good folks at OpenAI it is possible! Introducing their DALL-E model that uses a discrete visual codebook obtained by training a discrete VAE, and a transformer to model the joint probability of text prompts and their corresponding images. And if that was not cool enough, they also make it possible to use an input image alongside a special text prompt as an additional condition to perform zero-shot image-to-image translation.

To learn how the authors managed to create an effective discrete visual codebook for text-to-image tasks, and how they cleverly applied an autoregressive transformer to generate high-resolution images from a combination of text and image tokens check out [the full explanation post](https://t.me/casual_gan/48)!

Meanwhile, check out some really awesome samples from the paper:

[DALL-E samples](https://preview.redd.it/dh0e2nbp34471.png?width=1280&amp;format=png&amp;auto=webp&amp;s=9d1d32fe1a81ee339d0bdbc4a26617087ed3395d)

\[[Full Explanation Post](https://t.me/casual_gan/48)\] \[[Arxiv](https://arxiv.org/abs/2102.12092)\] \[[Project page](https://github.com/openai/DALL-E)\]

More recent popular computer vision paper explanations:

&gt;\[[CoModGAN](https://t.me/casual_gan/43)\]\[[VQGAN](https://t.me/casual_gan/46)\]\[[DINO](https://t.me/casual_gan/40)\]",t2_hhio3,False,,0,False,Paper explаined - DALL-E: Zero-Shot Text-to-Image Generation,[],r/deeplearning,False,6,,0,,False,t3_nvfena,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623217463.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Wouldn&amp;#39;t it be amazing if you could simply type a text prompt describing the image in as much or as little detail as you want and a bunch of images fitting the description was generated on the fly? Well, thanks to the good folks at OpenAI it is possible! Introducing their DALL-E model that uses a discrete visual codebook obtained by training a discrete VAE, and a transformer to model the joint probability of text prompts and their corresponding images. And if that was not cool enough, they also make it possible to use an input image alongside a special text prompt as an additional condition to perform zero-shot image-to-image translation.&lt;/p&gt;

&lt;p&gt;To learn how the authors managed to create an effective discrete visual codebook for text-to-image tasks, and how they cleverly applied an autoregressive transformer to generate high-resolution images from a combination of text and image tokens check out &lt;a href=""https://t.me/casual_gan/48""&gt;the full explanation post&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;Meanwhile, check out some really awesome samples from the paper:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/dh0e2nbp34471.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9d1d32fe1a81ee339d0bdbc4a26617087ed3395d""&gt;DALL-E samples&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/48""&gt;Full Explanation Post&lt;/a&gt;] [&lt;a href=""https://arxiv.org/abs/2102.12092""&gt;Arxiv&lt;/a&gt;] [&lt;a href=""https://github.com/openai/DALL-E""&gt;Project page&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;More recent popular computer vision paper explanations:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/43""&gt;CoModGAN&lt;/a&gt;][&lt;a href=""https://t.me/casual_gan/46""&gt;VQGAN&lt;/a&gt;][&lt;a href=""https://t.me/casual_gan/40""&gt;DINO&lt;/a&gt;]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvfena,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvfena/paper_explаined_dalle_zeroshot_texttoimage/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvfena/paper_explаined_dalle_zeroshot_texttoimage/,66147,1623188663.0,0,,False,,,"{'dh0e2nbp34471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 81, 'x': 108, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc75eb55a32072273025d8e1b9974efa29eff591'}, {'y': 163, 'x': 216, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7cbf2f53f5fcfe0953b4b0339b6da8d416d53acb'}, {'y': 241, 'x': 320, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=abdb78b624eff549a8729e22aa7ab82df848f021'}, {'y': 483, 'x': 640, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=57a365d57e133f104f4d5f01d5f83b110455b569'}, {'y': 724, 'x': 960, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=19e08fd8162a0f897c7c0d2410ec8014aa53f3d2'}, {'y': 815, 'x': 1080, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f11ce3ddf29a95d0d0dc48e052736333af2cc8de'}], 's': {'y': 966, 'x': 1280, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=1280&amp;format=png&amp;auto=webp&amp;s=9d1d32fe1a81ee339d0bdbc4a26617087ed3395d'}, 'id': 'dh0e2nbp34471'}}",,,,
,deeplearning,,t2_87yl1fq2,False,,0,False,Some Maths Resources to Help You in Your ML Journey,[],r/deeplearning,False,6,,0,,False,t3_nvfe26,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623217417.0,text,6,,,text,self.learnmachinelearning,False,,,,,/r/learnmachinelearning/comments/nun6qb/some_maths_resources_to_help_you_in_your_ml/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvfe26,True,,axetobe_ML,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvfe26/some_maths_resources_to_help_you_in_your_ml/,all_ads,False,/r/learnmachinelearning/comments/nun6qb/some_maths_resources_to_help_you_in_your_ml/,66147,1623188617.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': 'I have been looking for content to improve my maths skills for ML. I have also noticed when scrolling a few threads many people did not find content that explains maths in an intuitive manner. Leading to a lack of belief in learning ML. But this does not have to be.\n\nI’m with you, odd-looking characters and Greek letters don’t look welcoming. But they are some good teachers online that can demystify that experience.\n\nSome of those materials are below:\n\n3blue1brown [Calculus](https://youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr) and [Linear Algebra](https://youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) series\n\nI remember watching both of these series a while. And I will be watching them again. The narrator explores the topic without getting bogged down in the details. Feels like your discovering the maths with the original people who made calculus. In the linear algebra series, he does such a great job visualising vector space. You can see the various operations done to vectors and matrices in picture form.\n\n[3blue1brown Deep Learning series](https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n\nTaking the concepts from the previous series and applying them to deep learning.\n\n[Khan Academy](https://khanacademy.org/)\n\nI’m sure you know about Sal Kahn by now. As you watched a couple of his videos. His video intuitively explains various topics. Also, show you the various hand by hand actions you need to take to do various calculations. Like matrix multiplication and calculating derivatives.\n\n[Mathematics for Machine Learning book](https://mml-book.github.io/)\n\nI tend to use this book as a reference guide if it’s a concept I want to check out. This book goes through the most important subjects relevant to machine learning and goes in-depth.\n\n[Mathematics for Machine Learning - Multivariate Calculus – Imperial College London](https://www.youtube.com/watch?v=QpwTEsO51tU)\n\nA multi-hour series explaining how calculus is used in deep learning. The material comes at the subject with a high-level view. But goes into sufficient enough detail to help you learn a lot.\n\n[Understand Calculus in 35 Minutes - The Organic Chemistry Tutor](https://www.youtube.com/watch?v=WsQQvHm4lSw)\n\nA general overview of the subject. So you can be familiar with the concepts for deep learning later on.\n\nNOTE: you won’t learn all of calculus in 30 minutes. But the video will help you get accustomed to the main ideas of the subject.\n\n&amp;#x200B;\n\nNow, these are resources that I have not used or have used very lightly but gotten good recommendations from various people.\n\nSo check them out:\n\n[Computational Linear Algebra](https://www.fast.ai/2017/07/17/num-lin-alg/):\n\nThis course talks about the linear algebra used in real computation. Not just Linear algebra done by hand.\n\n[Deep Learning book by Ian Goodfellow and Yoshua Bengio and Aaron Courville](https://www.deeplearningbook.org/)\n\nFrom their website:\n\n&gt;The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular.\n\nI have not thoroughly read all of the book. But I have used the notation page to understand maths symbols in various deep learning work.\n\n[An Introduction to Statistical Learning](https://www.statlearning.com/)\n\nA few people in this subreddit and the main subreddit have recommended this book. But I have never read it.\n\nInteresting book series which explains the maths used in high-performance code. Starting from the ground up.\n\n[Deep Learning for Programmers](https://aiprobook.com/numerical-linear-algebra-for-programmers/)\n\n[Numerical Linear Algebra for Programmers](https://aiprobook.com/deep-learning-for-programmers/)\n\n\\-\n\n*If you found this article interesting,* [*then check out my mailing list.*](https://www.tobiolabode.com/subscribe) *Where I write more stuff like this*', 'author_fullname': 't2_87yl1fq2', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Some Maths Resources to Help You in Your ML Journey', 'link_flair_richtext': [{'e': 'text', 't': 'Tutorial'}], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nun6qb', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 64, 'total_awards_received': 1, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Tutorial', 'can_mod_post': False, 'score': 64, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': 1623187067.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {'gid_1': 1}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1623127747.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnmachinelearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been looking for content to improve my maths skills for ML. I have also noticed when scrolling a few threads many people did not find content that explains maths in an intuitive manner. Leading to a lack of belief in learning ML. But this does not have to be.&lt;/p&gt;\n\n&lt;p&gt;I’m with you, odd-looking characters and Greek letters don’t look welcoming. But they are some good teachers online that can demystify that experience.&lt;/p&gt;\n\n&lt;p&gt;Some of those materials are below:&lt;/p&gt;\n\n&lt;p&gt;3blue1brown &lt;a href=""https://youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr""&gt;Calculus&lt;/a&gt; and &lt;a href=""https://youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab""&gt;Linear Algebra&lt;/a&gt; series&lt;/p&gt;\n\n&lt;p&gt;I remember watching both of these series a while. And I will be watching them again. The narrator explores the topic without getting bogged down in the details. Feels like your discovering the maths with the original people who made calculus. In the linear algebra series, he does such a great job visualising vector space. You can see the various operations done to vectors and matrices in picture form.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi""&gt;3blue1brown Deep Learning series&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Taking the concepts from the previous series and applying them to deep learning.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://khanacademy.org/""&gt;Khan Academy&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I’m sure you know about Sal Kahn by now. As you watched a couple of his videos. His video intuitively explains various topics. Also, show you the various hand by hand actions you need to take to do various calculations. Like matrix multiplication and calculating derivatives.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://mml-book.github.io/""&gt;Mathematics for Machine Learning book&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I tend to use this book as a reference guide if it’s a concept I want to check out. This book goes through the most important subjects relevant to machine learning and goes in-depth.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=QpwTEsO51tU""&gt;Mathematics for Machine Learning - Multivariate Calculus – Imperial College London&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A multi-hour series explaining how calculus is used in deep learning. The material comes at the subject with a high-level view. But goes into sufficient enough detail to help you learn a lot.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=WsQQvHm4lSw""&gt;Understand Calculus in 35 Minutes - The Organic Chemistry Tutor&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A general overview of the subject. So you can be familiar with the concepts for deep learning later on.&lt;/p&gt;\n\n&lt;p&gt;NOTE: you won’t learn all of calculus in 30 minutes. But the video will help you get accustomed to the main ideas of the subject.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now, these are resources that I have not used or have used very lightly but gotten good recommendations from various people.&lt;/p&gt;\n\n&lt;p&gt;So check them out:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://www.fast.ai/2017/07/17/num-lin-alg/""&gt;Computational Linear Algebra&lt;/a&gt;:&lt;/p&gt;\n\n&lt;p&gt;This course talks about the linear algebra used in real computation. Not just Linear algebra done by hand.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://www.deeplearningbook.org/""&gt;Deep Learning book by Ian Goodfellow and Yoshua Bengio and Aaron Courville&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;From their website:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I have not thoroughly read all of the book. But I have used the notation page to understand maths symbols in various deep learning work.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://www.statlearning.com/""&gt;An Introduction to Statistical Learning&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A few people in this subreddit and the main subreddit have recommended this book. But I have never read it.&lt;/p&gt;\n\n&lt;p&gt;Interesting book series which explains the maths used in high-performance code. Starting from the ground up.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://aiprobook.com/numerical-linear-algebra-for-programmers/""&gt;Deep Learning for Programmers&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://aiprobook.com/deep-learning-for-programmers/""&gt;Numerical Linear Algebra for Programmers&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;-&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;If you found this article interesting,&lt;/em&gt; &lt;a href=""https://www.tobiolabode.com/subscribe""&gt;&lt;em&gt;then check out my mailing list.&lt;/em&gt;&lt;/a&gt; &lt;em&gt;Where I write more stuff like this&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}], 'awarders': [], 'media_only': False, 'link_flair_template_id': '8aeee882-d289-11ea-b4f0-0ed750cbd99b', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#dadada', 'id': 'nun6qb', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'axetobe_ML', 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/nun6qb/some_maths_resources_to_help_you_in_your_ml/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnmachinelearning/comments/nun6qb/some_maths_resources_to_help_you_in_your_ml/', 'subreddit_subscribers': 232336, 'created_utc': 1623098947.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_nun6qb,,,,,
,deeplearning,,t2_19qv49zm,False,,0,False,A Theoretical and Practical Guide to Probabilistic Graphical Models with Tensorflow,[],r/deeplearning,False,6,,0,,False,t3_nv8rxp,False,dark,0.75,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Directed Graphical Models | Intro | Implementation in TensorFlow Probability | [english]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Machine Learning &amp; Simulation', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yBc01ZeaFxw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCh0P7KwJhuQ4vrzc3IRuw4Q'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nv8rxp', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1623200166.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=yBc01ZeaFxw&amp;list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv8rxp,True,,OB_two,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nv8rxp/a_theoretical_and_practical_guide_to/,all_ads,False,https://www.youtube.com/watch?v=yBc01ZeaFxw&amp;list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ,66147,1623171366.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Directed Graphical Models | Intro | Implementation in TensorFlow Probability | [english]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Machine Learning &amp; Simulation', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yBc01ZeaFxw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCh0P7KwJhuQ4vrzc3IRuw4Q'}}",False,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': '', 'author_fullname': 't2_19qv49zm', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'A Theoretical and Practical Guide to Probabilistic Graphical Models with Tensorflow', 'link_flair_richtext': [{'e': 'text', 't': 'Tutorial'}], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nv8kzp', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.87, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 18, 'total_awards_received': 0, 'media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Directed Graphical Models | Intro | Implementation in TensorFlow Probability | [english]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Machine Learning &amp; Simulation', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yBc01ZeaFxw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCh0P7KwJhuQ4vrzc3IRuw4Q'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nv8kzp', 'height': 200}, 'link_flair_text': 'Tutorial', 'can_mod_post': False, 'score': 18, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1623199656.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtube.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.youtube.com/watch?v=yBc01ZeaFxw&amp;list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '8aeee882-d289-11ea-b4f0-0ed750cbd99b', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#dadada', 'id': 'nv8kzp', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'OB_two', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/nv8kzp/a_theoretical_and_practical_guide_to/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.youtube.com/watch?v=yBc01ZeaFxw&amp;list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ', 'subreddit_subscribers': 232336, 'created_utc': 1623170856.0, 'num_crossposts': 4, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Directed Graphical Models | Intro | Implementation in TensorFlow Probability | [english]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Machine Learning &amp; Simulation', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yBc01ZeaFxw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCh0P7KwJhuQ4vrzc3IRuw4Q'}}, 'is_video': False}]",t3_nv8kzp,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,Differentiable Self-organizing Systems,[],r/deeplearning,False,6,,0,,False,t3_nvaz4a,False,dark,1.0,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Pn2QL_5LmJE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Differentiable Self-organizing Systems', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Pn2QL_5LmJE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Pn2QL_5LmJE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Pn2QL_5LmJE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nvaz4a', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1623206039.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/Pn2QL_5LmJE,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvaz4a,True,,cmillionaire9,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvaz4a/differentiable_selforganizing_systems/,all_ads,False,https://youtu.be/Pn2QL_5LmJE,66147,1623177239.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Differentiable Self-organizing Systems', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Pn2QL_5LmJE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Pn2QL_5LmJE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning," Is it possible to create a program that automatically finds similarities between disciplines in different fields?  For example, is it possible to have a machine learning or deep learning program that finds the laws of biology with a structure and number of variables similar to the equation of force such as f=ma in physics?",t2_68sl7hms,False,,0,False,Is it possible to write code that automatically retrieves insights by finding homogeneity between different disciplines?(This is a fairly abstract question),[],r/deeplearning,False,6,,0,,False,t3_nuyujx,False,dark,1.0,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1623165271.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is it possible to create a program that automatically finds similarities between disciplines in different fields?  For example, is it possible to have a machine learning or deep learning program that finds the laws of biology with a structure and number of variables similar to the equation of force such as f=ma in physics?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuyujx,True,,Plus-Ad1156,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nuyujx/is_it_possible_to_write_code_that_automatically/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nuyujx/is_it_possible_to_write_code_that_automatically/,66147,1623136471.0,0,,False,,,,,,,
,deeplearning,,t2_39dnc90e,False,,0,False,Can anyone help me figure out what im doing wrong with my input? I keep getting an error. I am new to coding and D.L. This is part of a autoencoder model i got off Keras. I am using sensor data not images.,[],r/deeplearning,False,6,,0,,False,t3_nv75zc,False,dark,0.5,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623196194.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/3xuo1o6na2471.png,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv75zc,True,,HVACCalculations,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nv75zc/can_anyone_help_me_figure_out_what_im_doing_wrong/,all_ads,False,https://i.redd.it/3xuo1o6na2471.png,66147,1623167394.0,0,,False,,,,,,,
,deeplearning,"\#This is the code I am using

input = layers.Input(shape=(sensor.shape\[1\]))

&amp;#x200B;

\# Encoder

x = layers.Conv2D(64, (3, 3), activation=""relu"", padding=""same"")(input)

x = layers.MaxPooling2D((2, 2), padding=""same"")(x)

x = layers.Conv2D(32, (3, 3), activation=""relu"", padding=""same"")(x)

x = layers.MaxPooling2D((2, 2), padding=""same"")(x)

&amp;#x200B;

\# Decoder

x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=""relu"", padding=""same"")(x)

x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation=""relu"", padding=""same"")(x)

x = layers.Conv2D(128, (3, 3), activation=""sigmoid"", padding=""same"")(x)

&amp;#x200B;

\# Autoencoder

autoencoder = Model(input, x)

autoencoder.compile(optimizer=""adam"", loss=""binary\_crossentropy"")

autoencoder.summary()

&amp;#x200B;

\#This is the error message

 **---------------------------------------------------------------------------** 

**ValueError**                                Traceback (most recent call last)

 **&lt;ipython-input-17-bdd3a2559477&gt;** in &lt;module&gt;       

2       

3 **# Encoder**

 **----&gt; 4** x **=** layers**.**Conv2D**(64,** **(3,** **3),** activation**=""relu"",** padding**=""same"")(**input**)**      

 5 x **=** layers**.**MaxPooling2D**((2,** **2),** padding**=""same"")(**x**)**       

6 x **=** layers**.**Conv2D**(32,** **(3,** **3),** activation**=""relu"",** padding**=""same"")(**x**)** **\~\\anaconda3\\envs\\Mytfenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base\_layer.py** in \_\_call\_\_**(self, \*args, \*\*kwargs)**    

 923 **# &gt;&gt; model = tf.keras.Model(inputs, outputs)**   

  924 **if** \_in\_functional\_construction\_mode**(**self**,** inputs**,** args**,** kwargs**,** input\_list**):**

 **--&gt; 925       return self.\_functional\_construction\_call(inputs, args, kwargs,**    

 926                                                 input\_list)    

 927 **\~\\anaconda3\\envs\\Mytfenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base\_layer.py** in \_functional\_construction\_call**(self, inputs, args, kwargs, input\_list)**    

1090 **# TODO(reedwm): We should assert input compatibility after the inputs**    

1091 **# are casted, not before.** **-&gt; 1092** input\_spec**.**assert\_input\_compatibility**(**self**.**input\_spec**,** inputs**,** self**.**name**)**    

1093       graph **=** backend**.**get\_graph**()**  

  1094 **# Use \`self.\_name\_scope()\` to avoid auto-incrementing the name.** **\~\\anaconda3\\envs\\Mytfenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input\_spec.py** in assert\_input\_compatibility**(input\_spec, inputs, layer\_name)**   

  189       ndim **=** x**.**shape**.**ndims     190 **if** ndim **is** **not** **None** **and** ndim **&lt;** spec**.**min\_ndim**:**

 **--&gt; 191         raise ValueError('Input ' + str(input\_index) + ' of layer ' +**     

192                          layer\_name **+** **' is incompatible with the layer: '**     

193 **': expected min\_ndim='** **+** str**(**spec**.**min\_ndim**)** **+** 

**ValueError**: Input 0 of layer conv2d\_3 is incompatible with the layer: : expected min\_ndim=4, found ndim=2. Full shape received: \[None, 8\]   
 ",t2_39dnc90e,False,,0,False,Can anyone help me figure out my why im getting this error? I found a autoencoder model off of keras and im trying to input some sensor data to train the model. Please let me know if you need any additional information (Sorry for the noob question),[],r/deeplearning,False,6,,0,,False,t3_nv74mw,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1623167623.0,,[],{},,True,,1623196130.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;#This is the code I am using&lt;/p&gt;

&lt;p&gt;input = layers.Input(shape=(sensor.shape[1]))&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;# Encoder&lt;/p&gt;

&lt;p&gt;x = layers.Conv2D(64, (3, 3), activation=&amp;quot;relu&amp;quot;, padding=&amp;quot;same&amp;quot;)(input)&lt;/p&gt;

&lt;p&gt;x = layers.MaxPooling2D((2, 2), padding=&amp;quot;same&amp;quot;)(x)&lt;/p&gt;

&lt;p&gt;x = layers.Conv2D(32, (3, 3), activation=&amp;quot;relu&amp;quot;, padding=&amp;quot;same&amp;quot;)(x)&lt;/p&gt;

&lt;p&gt;x = layers.MaxPooling2D((2, 2), padding=&amp;quot;same&amp;quot;)(x)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;# Decoder&lt;/p&gt;

&lt;p&gt;x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=&amp;quot;relu&amp;quot;, padding=&amp;quot;same&amp;quot;)(x)&lt;/p&gt;

&lt;p&gt;x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation=&amp;quot;relu&amp;quot;, padding=&amp;quot;same&amp;quot;)(x)&lt;/p&gt;

&lt;p&gt;x = layers.Conv2D(128, (3, 3), activation=&amp;quot;sigmoid&amp;quot;, padding=&amp;quot;same&amp;quot;)(x)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;# Autoencoder&lt;/p&gt;

&lt;p&gt;autoencoder = Model(input, x)&lt;/p&gt;

&lt;p&gt;autoencoder.compile(optimizer=&amp;quot;adam&amp;quot;, loss=&amp;quot;binary_crossentropy&amp;quot;)&lt;/p&gt;

&lt;p&gt;autoencoder.summary()&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;#This is the error message&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;---------------------------------------------------------------------------&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ValueError&lt;/strong&gt;                                Traceback (most recent call last)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&amp;lt;ipython-input-17-bdd3a2559477&amp;gt;&lt;/strong&gt; in &amp;lt;module&amp;gt;       &lt;/p&gt;

&lt;p&gt;2       &lt;/p&gt;

&lt;p&gt;3 &lt;strong&gt;# Encoder&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;----&amp;gt; 4&lt;/strong&gt; x &lt;strong&gt;=&lt;/strong&gt; layers&lt;strong&gt;.&lt;/strong&gt;Conv2D&lt;strong&gt;(64,&lt;/strong&gt; &lt;strong&gt;(3,&lt;/strong&gt; &lt;strong&gt;3),&lt;/strong&gt; activation&lt;strong&gt;=&amp;quot;relu&amp;quot;,&lt;/strong&gt; padding&lt;strong&gt;=&amp;quot;same&amp;quot;)(&lt;/strong&gt;input&lt;strong&gt;)&lt;/strong&gt;      &lt;/p&gt;

&lt;p&gt;5 x &lt;strong&gt;=&lt;/strong&gt; layers&lt;strong&gt;.&lt;/strong&gt;MaxPooling2D&lt;strong&gt;((2,&lt;/strong&gt; &lt;strong&gt;2),&lt;/strong&gt; padding&lt;strong&gt;=&amp;quot;same&amp;quot;)(&lt;/strong&gt;x&lt;strong&gt;)&lt;/strong&gt;       &lt;/p&gt;

&lt;p&gt;6 x &lt;strong&gt;=&lt;/strong&gt; layers&lt;strong&gt;.&lt;/strong&gt;Conv2D&lt;strong&gt;(32,&lt;/strong&gt; &lt;strong&gt;(3,&lt;/strong&gt; &lt;strong&gt;3),&lt;/strong&gt; activation&lt;strong&gt;=&amp;quot;relu&amp;quot;,&lt;/strong&gt; padding&lt;strong&gt;=&amp;quot;same&amp;quot;)(&lt;/strong&gt;x&lt;strong&gt;)&lt;/strong&gt; &lt;strong&gt;~\anaconda3\envs\Mytfenv\lib\site-packages\tensorflow\python\keras\engine\base_layer.py&lt;/strong&gt; in __call__&lt;strong&gt;(self, *args, **kwargs)&lt;/strong&gt;    &lt;/p&gt;

&lt;p&gt;923 &lt;strong&gt;# &amp;gt;&amp;gt; model = tf.keras.Model(inputs, outputs)&lt;/strong&gt;   &lt;/p&gt;

&lt;p&gt;924 &lt;strong&gt;if&lt;/strong&gt; _in_functional_construction_mode&lt;strong&gt;(&lt;/strong&gt;self&lt;strong&gt;,&lt;/strong&gt; inputs&lt;strong&gt;,&lt;/strong&gt; args&lt;strong&gt;,&lt;/strong&gt; kwargs&lt;strong&gt;,&lt;/strong&gt; input_list&lt;strong&gt;):&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;--&amp;gt; 925       return self._functional_construction_call(inputs, args, kwargs,&lt;/strong&gt;    &lt;/p&gt;

&lt;p&gt;926                                                 input_list)    &lt;/p&gt;

&lt;p&gt;927 &lt;strong&gt;~\anaconda3\envs\Mytfenv\lib\site-packages\tensorflow\python\keras\engine\base_layer.py&lt;/strong&gt; in _functional_construction_call&lt;strong&gt;(self, inputs, args, kwargs, input_list)&lt;/strong&gt;    &lt;/p&gt;

&lt;p&gt;1090 &lt;strong&gt;# TODO(reedwm): We should assert input compatibility after the inputs&lt;/strong&gt;    &lt;/p&gt;

&lt;p&gt;1091 &lt;strong&gt;# are casted, not before.&lt;/strong&gt; &lt;strong&gt;-&amp;gt; 1092&lt;/strong&gt; input_spec&lt;strong&gt;.&lt;/strong&gt;assert_input_compatibility&lt;strong&gt;(&lt;/strong&gt;self&lt;strong&gt;.&lt;/strong&gt;input_spec&lt;strong&gt;,&lt;/strong&gt; inputs&lt;strong&gt;,&lt;/strong&gt; self&lt;strong&gt;.&lt;/strong&gt;name&lt;strong&gt;)&lt;/strong&gt;    &lt;/p&gt;

&lt;p&gt;1093       graph &lt;strong&gt;=&lt;/strong&gt; backend&lt;strong&gt;.&lt;/strong&gt;get_graph&lt;strong&gt;()&lt;/strong&gt;  &lt;/p&gt;

&lt;p&gt;1094 &lt;strong&gt;# Use `self._name_scope()` to avoid auto-incrementing the name.&lt;/strong&gt; &lt;strong&gt;~\anaconda3\envs\Mytfenv\lib\site-packages\tensorflow\python\keras\engine\input_spec.py&lt;/strong&gt; in assert_input_compatibility&lt;strong&gt;(input_spec, inputs, layer_name)&lt;/strong&gt;   &lt;/p&gt;

&lt;p&gt;189       ndim &lt;strong&gt;=&lt;/strong&gt; x&lt;strong&gt;.&lt;/strong&gt;shape&lt;strong&gt;.&lt;/strong&gt;ndims     190 &lt;strong&gt;if&lt;/strong&gt; ndim &lt;strong&gt;is&lt;/strong&gt; &lt;strong&gt;not&lt;/strong&gt; &lt;strong&gt;None&lt;/strong&gt; &lt;strong&gt;and&lt;/strong&gt; ndim &lt;strong&gt;&amp;lt;&lt;/strong&gt; spec&lt;strong&gt;.&lt;/strong&gt;min_ndim&lt;strong&gt;:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;--&amp;gt; 191         raise ValueError(&amp;#39;Input &amp;#39; + str(input_index) + &amp;#39; of layer &amp;#39; +&lt;/strong&gt;     &lt;/p&gt;

&lt;p&gt;192                          layer_name &lt;strong&gt;+&lt;/strong&gt; &lt;strong&gt;&amp;#39; is incompatible with the layer: &amp;#39;&lt;/strong&gt;     &lt;/p&gt;

&lt;p&gt;193 &lt;strong&gt;&amp;#39;: expected min_ndim=&amp;#39;&lt;/strong&gt; &lt;strong&gt;+&lt;/strong&gt; str&lt;strong&gt;(&lt;/strong&gt;spec&lt;strong&gt;.&lt;/strong&gt;min_ndim&lt;strong&gt;)&lt;/strong&gt; &lt;strong&gt;+&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ValueError&lt;/strong&gt;: Input 0 of layer conv2d_3 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [None, 8]   &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv74mw,True,,HVACCalculations,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nv74mw/can_anyone_help_me_figure_out_my_why_im_getting/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nv74mw/can_anyone_help_me_figure_out_my_why_im_getting/,66147,1623167330.0,0,,False,,,"{'xs3cu31kc2471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 93, 'x': 108, 'u': 'https://preview.redd.it/xs3cu31kc2471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fe5f4155e2816d1fc70da835b811edc36feb607d'}, {'y': 186, 'x': 216, 'u': 'https://preview.redd.it/xs3cu31kc2471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cfc7efbc0cdf7ad2f1d2ddee23aadf12190ecf6e'}, {'y': 276, 'x': 320, 'u': 'https://preview.redd.it/xs3cu31kc2471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b111a4eae079a20cd0aa76badcc82c686c1ae651'}, {'y': 553, 'x': 640, 'u': 'https://preview.redd.it/xs3cu31kc2471.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8a4c63759774e485fd7a2b50a5e10141389e52e6'}], 's': {'y': 786, 'x': 909, 'u': 'https://preview.redd.it/xs3cu31kc2471.png?width=909&amp;format=png&amp;auto=webp&amp;s=208e54940a1e5efa2052fb0f38e036dfaca3f0f2'}, 'id': 'xs3cu31kc2471'}}",,,,
,deeplearning,"A research team from Google Brain conducts a comprehensive empirical study on more than fifty choices in a generic adversarial imitation learning framework and explores their impacts on large-scale (&gt;500k trained agents) continuous-control tasks to provide practical insights and recommendations for designing novel and effective AIL algorithms.

Here is a quick read: [What Matters in Adversarial Imitation Learning? Google Brain Study Reveals Valuable Insights.](https://syncedreview.com/2021/06/08/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-36/)

The paper *What Matters for Adversarial Imitation Learning?* is on [arXiv](https://arxiv.org/abs/2106.00672).",t2_2fv4yodo,False,,0,False,[R] What Matters in Adversarial Imitation Learning? Google Brain Study Reveals Valuable Insights,[],r/deeplearning,False,6,,0,,False,t3_nv5lqm,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623192085.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Google Brain conducts a comprehensive empirical study on more than fifty choices in a generic adversarial imitation learning framework and explores their impacts on large-scale (&amp;gt;500k trained agents) continuous-control tasks to provide practical insights and recommendations for designing novel and effective AIL algorithms.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/08/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-36/""&gt;What Matters in Adversarial Imitation Learning? Google Brain Study Reveals Valuable Insights.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;What Matters for Adversarial Imitation Learning?&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2106.00672""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv5lqm,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nv5lqm/r_what_matters_in_adversarial_imitation_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nv5lqm/r_what_matters_in_adversarial_imitation_learning/,66147,1623163285.0,0,,False,,,,,,,
,deeplearning,"Hey Guys! I recently am inspired by the paper mixup on network classification, and decided to write a PyTorch implementation of the mixup on image classification. Feel free to check it out:

[https://taying-cheng.medium.com/enhancing-neural-networks-with-mixup-in-pytorch-5129d261bc4a](https://taying-cheng.medium.com/enhancing-neural-networks-with-mixup-in-pytorch-5129d261bc4a)",t2_jn2eq6v,False,,0,False,Mixup - Enhancing Image Classification Results of Networks in PyTorch,[],r/deeplearning,False,6,,0,,False,t3_nuzkzj,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623168301.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey Guys! I recently am inspired by the paper mixup on network classification, and decided to write a PyTorch implementation of the mixup on image classification. Feel free to check it out:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://taying-cheng.medium.com/enhancing-neural-networks-with-mixup-in-pytorch-5129d261bc4a""&gt;https://taying-cheng.medium.com/enhancing-neural-networks-with-mixup-in-pytorch-5129d261bc4a&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuzkzj,True,,tt12343,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nuzkzj/mixup_enhancing_image_classification_results_of/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nuzkzj/mixup_enhancing_image_classification_results_of/,66147,1623139501.0,0,,False,,,,,,,
,deeplearning,,t2_r68sd3,False,,0,False,Data Structures in Python,[],r/deeplearning,False,6,,0,,False,t3_nv3co8,False,dark,0.33,,public,0,0,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/6TJERSlqQIk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Data Structures in Python #5', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/6TJERSlqQIk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Amine M. Boulouma', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6TJERSlqQIk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/AmineMBoulouma'}}",False,False,,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/6TJERSlqQIk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nv3co8', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1623185599.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/6TJERSlqQIk,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv3co8,True,,flambok,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nv3co8/data_structures_in_python/,all_ads,False,https://youtu.be/6TJERSlqQIk,66147,1623156799.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Data Structures in Python #5', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/6TJERSlqQIk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Amine M. Boulouma', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6TJERSlqQIk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/AmineMBoulouma'}}",False,,,,,,,
,deeplearning,,t2_c74s9tl6,False,,0,False,How Convolutional Neural Networks Work (CNNs Explained &amp; Visualized),[],r/deeplearning,False,6,,0,,False,t3_nuhkfv,False,dark,0.76,,public,13,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pj9-rr1wDhM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How Convolutional Neural Networks Work (CNNs Explained &amp; Visualized)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pj9-rr1wDhM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Futurology — An Optimistic Future', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/pj9-rr1wDhM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/FuturologyTV'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pj9-rr1wDhM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nuhkfv', 'height': 200}",,False,13,,False,False,,False,,[],{},,False,,1623114071.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=pj9-rr1wDhM,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuhkfv,True,,SpaghettiFagetti,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nuhkfv/how_convolutional_neural_networks_work_cnns/,all_ads,False,https://www.youtube.com/watch?v=pj9-rr1wDhM,66147,1623085271.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How Convolutional Neural Networks Work (CNNs Explained &amp; Visualized)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pj9-rr1wDhM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Futurology — An Optimistic Future', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/pj9-rr1wDhM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/FuturologyTV'}}",False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,When Vision Transformers Outperform ResNets without Pretraining! (Paper Explained),[],r/deeplearning,False,6,,0,,False,t3_nu92k1,False,dark,0.95,,public,38,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oDtcobGQ7xU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'When Vision Transformers Outperform ResNets without Pretraining | Paper Explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oDtcobGQ7xU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/oDtcobGQ7xU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oDtcobGQ7xU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nu92k1', 'height': 200}",,False,38,,False,False,,False,,[],{},,False,,1623090382.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/oDtcobGQ7xU,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nu92k1,True,,gordicaleksa,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nu92k1/when_vision_transformers_outperform_resnets/,all_ads,False,https://youtu.be/oDtcobGQ7xU,66147,1623061582.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'When Vision Transformers Outperform ResNets without Pretraining | Paper Explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oDtcobGQ7xU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/oDtcobGQ7xU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,"Are there any issues that come about with this? How does one test the network properly? I have a few separate programs that function semi-properly but my advisor has some doubts, as do I, so I'd like some assistance if possible. I simply want to train the network to give me an output value that is an estimate of the function of the input values. One input node, one output node, and as many or as few hidden layers/nodes as is necessary. So, if I input .4, the output the neural network should give me should be pretty close to .8. 

For the program Ill focus on, my network seems to get a very acceptably low MSE (1e-4 or 1e-5) when I train it, but there are a few caveats:

1) The network has 250 inputs. It takes the whole input as one batch and then backpropagates it all, and then updates the weights accordingly. It then uses the same input values again during the next iteration. I can change it to 2500 and 25000 inputs as well, and it still seems to train properly. Should I not train over the same inputs over and over again? My other program isn't like this, but I think this one works better. Im training over a fairly large set of input values.

2) My input data is between the range of .1 and 1. These are the values of the 250 inputs I mentioned in the above point. Is this bad? Is it good? What should my input ""range"" be? Are there any range of values that there are examples of that ""wouldn't be good"" in this case?

3) This point is just a series of related questions. How should I test my neural network? Should I just send random values through the network once it is finished and see if it outputs what I need it to, or is that not good? Does my input data being between .1 and 1 mean that I can't really input values too much larger than 1, or too much less than .1? Should my input data be *completely* random and be *any* real valued number? Or should there be bounds?

Thanks!",t2_i5dbu,False,,0,False,Deep Learning Regression Neural Network utilizing MATLAB (without using the toolbox),[],r/deeplearning,False,6,,0,,False,t3_nuul19,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1623125204.0,,[],{},,True,,1623149544.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Are there any issues that come about with this? How does one test the network properly? I have a few separate programs that function semi-properly but my advisor has some doubts, as do I, so I&amp;#39;d like some assistance if possible. I simply want to train the network to give me an output value that is an estimate of the function of the input values. One input node, one output node, and as many or as few hidden layers/nodes as is necessary. So, if I input .4, the output the neural network should give me should be pretty close to .8. &lt;/p&gt;

&lt;p&gt;For the program Ill focus on, my network seems to get a very acceptably low MSE (1e-4 or 1e-5) when I train it, but there are a few caveats:&lt;/p&gt;

&lt;p&gt;1) The network has 250 inputs. It takes the whole input as one batch and then backpropagates it all, and then updates the weights accordingly. It then uses the same input values again during the next iteration. I can change it to 2500 and 25000 inputs as well, and it still seems to train properly. Should I not train over the same inputs over and over again? My other program isn&amp;#39;t like this, but I think this one works better. Im training over a fairly large set of input values.&lt;/p&gt;

&lt;p&gt;2) My input data is between the range of .1 and 1. These are the values of the 250 inputs I mentioned in the above point. Is this bad? Is it good? What should my input &amp;quot;range&amp;quot; be? Are there any range of values that there are examples of that &amp;quot;wouldn&amp;#39;t be good&amp;quot; in this case?&lt;/p&gt;

&lt;p&gt;3) This point is just a series of related questions. How should I test my neural network? Should I just send random values through the network once it is finished and see if it outputs what I need it to, or is that not good? Does my input data being between .1 and 1 mean that I can&amp;#39;t really input values too much larger than 1, or too much less than .1? Should my input data be &lt;em&gt;completely&lt;/em&gt; random and be &lt;em&gt;any&lt;/em&gt; real valued number? Or should there be bounds?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuul19,True,,Kanep96,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/nuul19/deep_learning_regression_neural_network_utilizing/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nuul19/deep_learning_regression_neural_network_utilizing/,66147,1623120744.0,0,,False,,,,,,,
,deeplearning," The performance of deep neural networks (DNNs) relies heavily on their structures, and designing a good structure (aka architecture) tends to require extensive effort from human experts. The idea of an automatic structure-learning algorithm that can achieve performance on par with the best human-designed structures is thus increasingly appealing to machine learning researchers. 

[https://medium.com/syncedreview/microsoft-oneflow-leverage-the-efficient-coding-principle-to-design-unsupervised-dnn-9d2d258bdc3c](https://medium.com/syncedreview/microsoft-oneflow-leverage-the-efficient-coding-principle-to-design-unsupervised-dnn-9d2d258bdc3c)

&amp;#x200B;

https://preview.redd.it/2jqq3p4h5y371.png?width=790&amp;format=png&amp;auto=webp&amp;s=b78f0a397b65d7f473cf1dcc79153624468f8004",t2_c3oqcv1s,False,,0,False,Microsoft &amp; OneFlow Leverage the Efficient Coding Principle to Design Unsupervised DNN Structure-Learning That Outperforms Human-Designed Structures,[],r/deeplearning,False,6,,0,,False,t3_nutayl,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623145411.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The performance of deep neural networks (DNNs) relies heavily on their structures, and designing a good structure (aka architecture) tends to require extensive effort from human experts. The idea of an automatic structure-learning algorithm that can achieve performance on par with the best human-designed structures is thus increasingly appealing to machine learning researchers. &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://medium.com/syncedreview/microsoft-oneflow-leverage-the-efficient-coding-principle-to-design-unsupervised-dnn-9d2d258bdc3c""&gt;https://medium.com/syncedreview/microsoft-oneflow-leverage-the-efficient-coding-principle-to-design-unsupervised-dnn-9d2d258bdc3c&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/2jqq3p4h5y371.png?width=790&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b78f0a397b65d7f473cf1dcc79153624468f8004""&gt;https://preview.redd.it/2jqq3p4h5y371.png?width=790&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b78f0a397b65d7f473cf1dcc79153624468f8004&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nutayl,True,,xuchanghua,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nutayl/microsoft_oneflow_leverage_the_efficient_coding/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nutayl/microsoft_oneflow_leverage_the_efficient_coding/,66147,1623116611.0,0,,False,,,"{'2jqq3p4h5y371': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 43, 'x': 108, 'u': 'https://preview.redd.it/2jqq3p4h5y371.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ee299299aa1d047c1a20e5e3c7e82fc6f1965ff9'}, {'y': 87, 'x': 216, 'u': 'https://preview.redd.it/2jqq3p4h5y371.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a1a42a275b2c19aba4b1b8626693a9b784320b3'}, {'y': 129, 'x': 320, 'u': 'https://preview.redd.it/2jqq3p4h5y371.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=04d0a70bebaad34e0bb2c372709a493cb27cf843'}, {'y': 259, 'x': 640, 'u': 'https://preview.redd.it/2jqq3p4h5y371.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce6d24cf4ffb0ad4ce74c0efc541395126461abb'}], 's': {'y': 320, 'x': 790, 'u': 'https://preview.redd.it/2jqq3p4h5y371.png?width=790&amp;format=png&amp;auto=webp&amp;s=b78f0a397b65d7f473cf1dcc79153624468f8004'}, 'id': '2jqq3p4h5y371'}}",,,,
,deeplearning,"Hi all, I've been waiting since the beginning of this year for the availability of the RTX 3090 for building my research workstation and now I've just given up and I am currently looking for something else.  


I've found some refurbished ""HP Z840 Workstation"" with a Nvidia Quadro P6000 (or M6000) with 24gb. I plan to put another one to have 48gb. I need mostly Memory (Contrastive Learning needs bigger batch sizes) instead of speed - so they kind of look to fit well. However, I have not found any official benchmark and some very old forum like [this](https://www.kaggle.com/general/11332) speak badly about Quadros.   


So, what do you guys think? Any experience with Quadros for DL out there? Thx !!",t2_q9paa,False,,0,False,Quadro M6000 for Deep Learning?,[],r/deeplearning,False,6,,0,,False,t3_nugkzi,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1623111664.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I&amp;#39;ve been waiting since the beginning of this year for the availability of the RTX 3090 for building my research workstation and now I&amp;#39;ve just given up and I am currently looking for something else.  &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve found some refurbished &amp;quot;HP Z840 Workstation&amp;quot; with a Nvidia Quadro P6000 (or M6000) with 24gb. I plan to put another one to have 48gb. I need mostly Memory (Contrastive Learning needs bigger batch sizes) instead of speed - so they kind of look to fit well. However, I have not found any official benchmark and some very old forum like &lt;a href=""https://www.kaggle.com/general/11332""&gt;this&lt;/a&gt; speak badly about Quadros.   &lt;/p&gt;

&lt;p&gt;So, what do you guys think? Any experience with Quadros for DL out there? Thx !!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nugkzi,True,,mortadelass,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nugkzi/quadro_m6000_for_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nugkzi/quadro_m6000_for_deep_learning/,66147,1623082864.0,0,,False,,,,,,,
,deeplearning,,t2_50i7d,False,,0,False,Lucy says hi: real time visualization of the changes in the parameters of neural networks,[],r/deeplearning,False,6,,0,,False,t3_nucccs,False,dark,0.85,,public,5,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yB-quDmIR2w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Lucy | real time deep learning visualization | neural network parameters visualization in real time', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yB-quDmIR2w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Javier ideami', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yB-quDmIR2w/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ideami'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yB-quDmIR2w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nucccs', 'height': 200}",,False,5,,False,False,,False,,[],{},,False,,1623100721.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=yB-quDmIR2w,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nucccs,True,,javismiles,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nucccs/lucy_says_hi_real_time_visualization_of_the/,all_ads,False,https://www.youtube.com/watch?v=yB-quDmIR2w,66147,1623071921.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Lucy | real time deep learning visualization | neural network parameters visualization in real time', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yB-quDmIR2w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Javier ideami', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yB-quDmIR2w/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ideami'}}",False,,,,,,,
,deeplearning,"[https://nn.labml.ai/transformers/gmlp/index.html](https://nn.labml.ai/transformers/gmlp/index.html)

gMLP uses Multilayer Perceptrons (MLP) with gating instead of attention. It does pretty well compared to BERT on NLP and achieves same accuracy as ViT in vision tasks.

* [Github](https://github.com/labmlai/annotated_deep_learning_paper_implementations/tree/master/labml_nn/transformers/gmlp)
* [Paper](https://arxiv.org/abs/2105.08050)",t2_1jyhaoq,False,,0,False,Pay Attention to MLPs - Annotated PyTorch implementation,[],r/deeplearning,False,6,,0,,False,t3_nud3xn,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1623102864.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://nn.labml.ai/transformers/gmlp/index.html""&gt;https://nn.labml.ai/transformers/gmlp/index.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;gMLP uses Multilayer Perceptrons (MLP) with gating instead of attention. It does pretty well compared to BERT on NLP and achieves same accuracy as ViT in vision tasks.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://github.com/labmlai/annotated_deep_learning_paper_implementations/tree/master/labml_nn/transformers/gmlp""&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://arxiv.org/abs/2105.08050""&gt;Paper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nud3xn,True,,mlvpj,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nud3xn/pay_attention_to_mlps_annotated_pytorch/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nud3xn/pay_attention_to_mlps_annotated_pytorch/,66147,1623074064.0,0,,False,,,,,,,
,deeplearning,"A research team from Google Research combines the benefits of implicit differentiation and autodiff and proposes a unified, efficient and modular approach for implicit differentiation of optimization problems. 

Here is a quick read: [Google Proposes Efficient and Modular Implicit Differentiation for Optimization Problems.](https://syncedreview.com/2021/06/07/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-35/)

The paper *Efficient and Modular Implicit Differentiation* is on [arXiv](https://arxiv.org/abs/2105.15183).",t2_2fv4yodo,False,,0,False,[R] Google Proposes Efficient and Modular Implicit Differentiation for Optimization Problems,[],r/deeplearning,False,6,,0,,False,t3_nufqin,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623109618.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Google Research combines the benefits of implicit differentiation and autodiff and proposes a unified, efficient and modular approach for implicit differentiation of optimization problems. &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/07/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-35/""&gt;Google Proposes Efficient and Modular Implicit Differentiation for Optimization Problems.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Efficient and Modular Implicit Differentiation&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.15183""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nufqin,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nufqin/r_google_proposes_efficient_and_modular_implicit/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nufqin/r_google_proposes_efficient_and_modular_implicit/,66147,1623080818.0,0,,False,,,,,,,
,deeplearning,"Hi,   
I am working as a Senior Machine Learning Engineer with 3 years of experience in DL. Being self-taught in ML, I want to give back to the community and make ML more accessible for everyone, especially the more recent topics as there are already a plethora of resources covering just the basics.  
Here is a small tutorial on Fine Tuning BERT and using it for text classification using TensorFlow 2  
[https://www.kaggle.com/au1206/fine-tuning-bert-text-classification](https://www.kaggle.com/au1206/fine-tuning-bert-text-classification)  


I will also often post annotated papers, where I will try to annotate a recent paper and try to make it more readable for a better understanding for the people just starting out. You can find some at  
[https://au1206.github.io/](https://au1206.github.io/) and will now consciously try to make it easier to understand.",t2_qxkg2,False,,0,False,Fine-Tune BERT for Text Classification with TensorFlow Tutorial,[],r/deeplearning,False,6,,0,,False,t3_nuc3j1,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1623100015.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;br/&gt;
I am working as a Senior Machine Learning Engineer with 3 years of experience in DL. Being self-taught in ML, I want to give back to the community and make ML more accessible for everyone, especially the more recent topics as there are already a plethora of resources covering just the basics.&lt;br/&gt;
Here is a small tutorial on Fine Tuning BERT and using it for text classification using TensorFlow 2&lt;br/&gt;
&lt;a href=""https://www.kaggle.com/au1206/fine-tuning-bert-text-classification""&gt;https://www.kaggle.com/au1206/fine-tuning-bert-text-classification&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;I will also often post annotated papers, where I will try to annotate a recent paper and try to make it more readable for a better understanding for the people just starting out. You can find some at&lt;br/&gt;
&lt;a href=""https://au1206.github.io/""&gt;https://au1206.github.io/&lt;/a&gt; and will now consciously try to make it easier to understand.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuc3j1,True,,au1206,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nuc3j1/finetune_bert_for_text_classification_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nuc3j1/finetune_bert_for_text_classification_with/,66147,1623071215.0,0,,False,,,,,,,
,deeplearning,,t2_6l105jav,False,,0,False,2021 Python for Data Science &amp; Machine Learning from A-Z - free course from udemy,[],r/deeplearning,False,6,,0,,False,t3_nuhazo,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623113424.0,text,6,,,text,myfreeonlinecourses.com,False,,,,,https://www.myfreeonlinecourses.com/2021/04/100-off-2021-python-for-data-science.html,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuhazo,True,,Ordinary_Craft,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nuhazo/2021_python_for_data_science_machine_learning/,all_ads,False,https://www.myfreeonlinecourses.com/2021/04/100-off-2021-python-for-data-science.html,66147,1623084624.0,0,,False,,,,,,,
,deeplearning,"I have done countless research, but i am a first timer in Artificial Intelligence.  


My final implementation needs to be with openCV and c++

Noob question regarding the above statement:  
If i train a model that requires Tensorflow, keras, etc, like CNN, after training it, can i implement it using openCV only?  


If anyone has any recommendations on what i should use for this goal, i would really appreciate it!",t2_6y5y4bqx,False,,0,False,"Help, I am trying to detect and count some insect species in a glue trap! What should my aproach be?",[],r/deeplearning,False,6,,0,,False,t3_nu7ynb,False,dark,0.87,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1623085698.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have done countless research, but i am a first timer in Artificial Intelligence.  &lt;/p&gt;

&lt;p&gt;My final implementation needs to be with openCV and c++&lt;/p&gt;

&lt;p&gt;Noob question regarding the above statement:&lt;br/&gt;
If i train a model that requires Tensorflow, keras, etc, like CNN, after training it, can i implement it using openCV only?  &lt;/p&gt;

&lt;p&gt;If anyone has any recommendations on what i should use for this goal, i would really appreciate it!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nu7ynb,True,,Tyrian_Callows,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nu7ynb/help_i_am_trying_to_detect_and_count_some_insect/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nu7ynb/help_i_am_trying_to_detect_and_count_some_insect/,66147,1623056898.0,0,,False,,,,,,,
,deeplearning,"NFNets - A network that achieves state-of-the-art performance without Batch Norm.

A few baks back DeepMind published a very interesting [paper](https://arxiv.org/abs/2102.06171) in which they claimed to beat the EfficientNet-B7 which was SOTA on ImageNet.

They introduced a family of nets i.e. NfNets which tried to reproduce the batch norm benefits without using it.

Here is the blog which discussed it so that we can explore the topic in this thread.

https://highontechs.com/deep-learning/nfnets-networks-without-batch-norm/",t2_730sjlh9,False,,0,False,NFNets - A network that achieves state-of-the-art performance without Batch Norm.,[],r/deeplearning,False,6,,0,,False,t3_nu6ewu,False,dark,0.73,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1623078714.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;NFNets - A network that achieves state-of-the-art performance without Batch Norm.&lt;/p&gt;

&lt;p&gt;A few baks back DeepMind published a very interesting &lt;a href=""https://arxiv.org/abs/2102.06171""&gt;paper&lt;/a&gt; in which they claimed to beat the EfficientNet-B7 which was SOTA on ImageNet.&lt;/p&gt;

&lt;p&gt;They introduced a family of nets i.e. NfNets which tried to reproduce the batch norm benefits without using it.&lt;/p&gt;

&lt;p&gt;Here is the blog which discussed it so that we can explore the topic in this thread.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://highontechs.com/deep-learning/nfnets-networks-without-batch-norm/""&gt;https://highontechs.com/deep-learning/nfnets-networks-without-batch-norm/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nu6ewu,True,,Vivekvpawar,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nu6ewu/nfnets_a_network_that_achieves_stateoftheart/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nu6ewu/nfnets_a_network_that_achieves_stateoftheart/,66147,1623049914.0,0,,False,,,,,,,
,deeplearning,,t2_6zmd7l7y,False,,0,False,Do you guys have any idea on completing Andrew Ng’s deep learning course with companion books?,[],r/deeplearning,False,6,,0,,False,t3_nufd4t,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623108677.0,text,3,,,text,self.deeplearning,False,,,,,,,False,True,False,False,True,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nufd4t,True,,Super_AI_1086,,2,True,promo_adult_nsfw,False,[],False,,/r/deeplearning/comments/nufd4t/do_you_guys_have_any_idea_on_completing_andrew/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nufd4t/do_you_guys_have_any_idea_on_completing_andrew/,66147,1623079877.0,0,,False,,,,,,,
,deeplearning,"I searched the subreddit for this, but I think I am not using the right terms. 

&amp;#x200B;

I want to take a bunch of my art and have it morph into each other. I dont want to use Art Breeder, I want an app/program on my computer that will do it.

&amp;#x200B;

Can anyone point me in the right direction? 

&amp;#x200B;

Example: [https://www.youtube.com/watch?v=xp1MLeLbFvE](https://www.youtube.com/watch?v=xp1MLeLbFvE)

&amp;#x200B;

Thanks!",t2_5bihi,False,,0,False,Deep Learning generated art.,[],r/deeplearning,False,6,,0,,False,t3_nuex9z,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623107581.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I searched the subreddit for this, but I think I am not using the right terms. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I want to take a bunch of my art and have it morph into each other. I dont want to use Art Breeder, I want an app/program on my computer that will do it.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Can anyone point me in the right direction? &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Example: &lt;a href=""https://www.youtube.com/watch?v=xp1MLeLbFvE""&gt;https://www.youtube.com/watch?v=xp1MLeLbFvE&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuex9z,True,,murrray,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nuex9z/deep_learning_generated_art/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nuex9z/deep_learning_generated_art/,66147,1623078781.0,0,,False,,,,,,,
,deeplearning,"We have recently launched our new product [LabelMonkey](https://digit7.io/products/labelmonkey/) which is an AI-powered Auto Annotation Machine. With Label Monkey, you can now develop superior datasets at speed, scale and focus your undivided attention on innovation.",t2_ckyhamfs,False,,0,False,Image Annotation Simplified!,[],r/deeplearning,False,6,,0,,False,t3_nuer1a,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623107149.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We have recently launched our new product &lt;a href=""https://digit7.io/products/labelmonkey/""&gt;LabelMonkey&lt;/a&gt; which is an AI-powered Auto Annotation Machine. With Label Monkey, you can now develop superior datasets at speed, scale and focus your undivided attention on innovation.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuer1a,True,,Digit7labs,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nuer1a/image_annotation_simplified/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nuer1a/image_annotation_simplified/,66147,1623078349.0,0,,False,,,,,,,
,deeplearning,,t2_4xhrybaz,False,,0,False,Dummy question: what does E mean in a loss function? I see this notation being used in many papers. This one below is the Wasserstein Distance used in WGANs.,[],r/deeplearning,False,6,,0,,False,t3_ntu6ea,False,dark,0.85,,public,31,0,{},,False,[],,True,False,,{},,False,31,,False,False,,False,,[],{},,False,,1623038391.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/lc2mbel9bp371.jpg,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ntu6ea,True,,banenvy,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/ntu6ea/dummy_question_what_does_e_mean_in_a_loss/,all_ads,False,https://i.redd.it/lc2mbel9bp371.jpg,66147,1623009591.0,0,,False,,,,,,,
,deeplearning,,t2_66dqvlke,False,,0,False,Putting visual recognition in context - Link to free zoom lecture by the authors in comments,[],r/deeplearning,False,6,,0,,False,t3_nud4pk,False,dark,0.57,,public,1,0,{},,False,[],,True,False,,{},,False,1,,False,False,,False,,[],{},,False,,1623102923.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/anz9jib2nu371.png,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nud4pk,True,,dataskml,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nud4pk/putting_visual_recognition_in_context_link_to/,all_ads,False,https://i.redd.it/anz9jib2nu371.png,66147,1623074123.0,0,,False,,,,,,,
,deeplearning,,t2_hkv9s,False,,0,False,REALM: Retrieval-Augmented Language Model Pre-Training (Research Paper Walkthrough),[],r/deeplearning,False,6,,0,,False,t3_nu5g8i,False,dark,0.75,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/F1naDPJpdY4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'REALM: Retrieval-Augmented Language Model Pre-Training (Research Paper Walkthrough)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/F1naDPJpdY4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/F1naDPJpdY4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/F1naDPJpdY4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nu5g8i', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1623074811.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/F1naDPJpdY4,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nu5g8i,True,,prakhar21,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nu5g8i/realm_retrievalaugmented_language_model/,all_ads,False,https://youtu.be/F1naDPJpdY4,66147,1623046011.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'REALM: Retrieval-Augmented Language Model Pre-Training (Research Paper Walkthrough)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/F1naDPJpdY4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/F1naDPJpdY4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}}",False,,,,,,,
,deeplearning,"It is a lucrative idea to combine the effectiveness of the inductive bias of CNNs with the expressiveness of transformers, yet only recently such an approach was proven to be not only possible but extremely powerful as well. I am of course talking about ""Taming Transformers"" - a paper from 2020 that proposes a novel generator architecture where a CNN learns a context-rich vocabulary of discrete codes and a transformer learns to model their composition as high-resolution images in both conditional and unconditional generation settings.

To learn how the authors managed to create an effective codebook of perceptually rich discrete image components, and how they cleverly applied latent transformers to generate high-resolution images despite severe memory constraints check out [the full explanation post](https://t.me/casual_gan/46)!

Meanwhile, check out this paper poster provided by [Casual GAN Papers](https://t.me/casual_gan):

[Paper poster](https://preview.redd.it/pcbn3rq7bq371.png?width=2064&amp;format=png&amp;auto=webp&amp;s=ff7635ad7a3e742c7fb01e4e26b2370aa7fe9d08)

\[[Full Explanation Post](https://t.me/casual_gan/46)\] \[[Arxiv](https://arxiv.org/abs/2012.09841)\] \[[Project page](https://github.com/CompVis/taming-transformers)\]

More recent popular computer vision paper explanations:

&gt;\[[CoModGAN](https://t.me/casual_gan/43)\]\[[GANCraft](https://t.me/casual_gan/41)\]\[[DINO](https://t.me/casual_gan/40)\]",t2_hhio3,False,,0,False,Paper Explained: VQGAN - Taming Transformers for High-Resolution Image Synthesis,[],r/deeplearning,False,6,,0,,False,t3_ntygz5,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623050521.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It is a lucrative idea to combine the effectiveness of the inductive bias of CNNs with the expressiveness of transformers, yet only recently such an approach was proven to be not only possible but extremely powerful as well. I am of course talking about &amp;quot;Taming Transformers&amp;quot; - a paper from 2020 that proposes a novel generator architecture where a CNN learns a context-rich vocabulary of discrete codes and a transformer learns to model their composition as high-resolution images in both conditional and unconditional generation settings.&lt;/p&gt;

&lt;p&gt;To learn how the authors managed to create an effective codebook of perceptually rich discrete image components, and how they cleverly applied latent transformers to generate high-resolution images despite severe memory constraints check out &lt;a href=""https://t.me/casual_gan/46""&gt;the full explanation post&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;Meanwhile, check out this paper poster provided by &lt;a href=""https://t.me/casual_gan""&gt;Casual GAN Papers&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/pcbn3rq7bq371.png?width=2064&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ff7635ad7a3e742c7fb01e4e26b2370aa7fe9d08""&gt;Paper poster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/46""&gt;Full Explanation Post&lt;/a&gt;] [&lt;a href=""https://arxiv.org/abs/2012.09841""&gt;Arxiv&lt;/a&gt;] [&lt;a href=""https://github.com/CompVis/taming-transformers""&gt;Project page&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;More recent popular computer vision paper explanations:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/43""&gt;CoModGAN&lt;/a&gt;][&lt;a href=""https://t.me/casual_gan/41""&gt;GANCraft&lt;/a&gt;][&lt;a href=""https://t.me/casual_gan/40""&gt;DINO&lt;/a&gt;]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ntygz5,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ntygz5/paper_explained_vqgan_taming_transformers_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ntygz5/paper_explained_vqgan_taming_transformers_for/,66147,1623021721.0,0,,False,,,"{'pcbn3rq7bq371': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 209, 'x': 108, 'u': 'https://preview.redd.it/pcbn3rq7bq371.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ae75645fd16f8e643363163314dd87ba55dc4ebd'}, {'y': 418, 'x': 216, 'u': 'https://preview.redd.it/pcbn3rq7bq371.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1c479825749c85087174e120a3e3d83876d28069'}, {'y': 620, 'x': 320, 'u': 'https://preview.redd.it/pcbn3rq7bq371.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=eec8f1be9e60810d08a45f71195a8b4535c21b16'}, {'y': 1240, 'x': 640, 'u': 'https://preview.redd.it/pcbn3rq7bq371.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=539b7846b7c0ae1473ccae318a9700b9685535b2'}, {'y': 1860, 'x': 960, 'u': 'https://preview.redd.it/pcbn3rq7bq371.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=08eac6f87f9b4928acdbcf4d2dd6c9cad4b43129'}, {'y': 2093, 'x': 1080, 'u': 'https://preview.redd.it/pcbn3rq7bq371.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2e6f925fa863c99fc0e118ec7877e55062c8419e'}], 's': {'y': 4000, 'x': 2064, 'u': 'https://preview.redd.it/pcbn3rq7bq371.png?width=2064&amp;format=png&amp;auto=webp&amp;s=ff7635ad7a3e742c7fb01e4e26b2370aa7fe9d08'}, 'id': 'pcbn3rq7bq371'}}",,,,
,deeplearning,"Three days ago I made a video explaining how my NLP transformers course would be entirely free as part of a limited-time promo. I shared that video here and in a couple of other subreddits too, r/learnmachinglearning and r/Python being two.

Three days and 10823 downloads later, here we are! I thought we'd be lucky to hit 1K!

Incredible response, and very happy to be able to have been able to give so many of you an opportunity to access the course where some of you may not have been able to otherwise. I'm looking forward to working with all the students and helping you guys out, just please don't all ask me questions at once! 😬

Thanks all, truly humbled by the response - it's really *really* cool, it has blown my mind.

For any of you that are still interested, I will leave a final discount link [here](https://www.udemy.com/course/nlp-with-transformers/?couponCode=MEDIUM), thanks all!",t2_oupz3m9,False,,0,False,More than 10K of you downloaded the free NLP transformers course... Wow!,[],r/deeplearning,False,6,,0,,False,t3_ntpdi1,False,dark,0.89,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,True,,False,,[],{},,True,,1623025243.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Three days ago I made a video explaining how my NLP transformers course would be entirely free as part of a limited-time promo. I shared that video here and in a couple of other subreddits too, &lt;a href=""/r/learnmachinglearning""&gt;r/learnmachinglearning&lt;/a&gt; and &lt;a href=""/r/Python""&gt;r/Python&lt;/a&gt; being two.&lt;/p&gt;

&lt;p&gt;Three days and 10823 downloads later, here we are! I thought we&amp;#39;d be lucky to hit 1K!&lt;/p&gt;

&lt;p&gt;Incredible response, and very happy to be able to have been able to give so many of you an opportunity to access the course where some of you may not have been able to otherwise. I&amp;#39;m looking forward to working with all the students and helping you guys out, just please don&amp;#39;t all ask me questions at once! 😬&lt;/p&gt;

&lt;p&gt;Thanks all, truly humbled by the response - it&amp;#39;s really &lt;em&gt;really&lt;/em&gt; cool, it has blown my mind.&lt;/p&gt;

&lt;p&gt;For any of you that are still interested, I will leave a final discount link &lt;a href=""https://www.udemy.com/course/nlp-with-transformers/?couponCode=MEDIUM""&gt;here&lt;/a&gt;, thanks all!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ntpdi1,True,,jamescalam,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ntpdi1/more_than_10k_of_you_downloaded_the_free_nlp/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ntpdi1/more_than_10k_of_you_downloaded_the_free_nlp/,66147,1622996443.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,Hair styling just got easier with AI,[],r/deeplearning,False,6,,0,,False,t3_nth2sj,False,dark,0.88,,public,26,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/_BVzWAUcKzc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Hair styling just got easier with AI', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/_BVzWAUcKzc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/_BVzWAUcKzc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/_BVzWAUcKzc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nth2sj', 'height': 200}",,False,26,,False,False,,False,,[],{},,False,,1622996882.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/_BVzWAUcKzc,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nth2sj,True,,cmillionaire9,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nth2sj/hair_styling_just_got_easier_with_ai/,all_ads,False,https://youtu.be/_BVzWAUcKzc,66147,1622968082.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Hair styling just got easier with AI', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/_BVzWAUcKzc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/_BVzWAUcKzc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,,t2_45mbqpjy,False,,0,False,Audio-driven Neural Rendering of Portrait Videos.,[],r/deeplearning,False,6,,0,,False,t3_nti288,False,dark,0.78,,public,10,0,{},,False,[],,True,False,,{},,False,10,,False,False,,False,,[],{},,False,,1623001065.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/t94ei60e7m371,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nti288,True,,wojti_zielon,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nti288/audiodriven_neural_rendering_of_portrait_videos/,all_ads,False,https://v.redd.it/t94ei60e7m371,66147,1622972265.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'computervision', 'selftext': '', 'author_fullname': 't2_45mbqpjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Audio-driven Neural Rendering of Portrait Videos. In this project, we use neural rendering to manipulate the left video using only the voice from the right video. The videos belong to their respective owners and I do not claim any right over them. https://zielon.github.io/face-neural-rendering/', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/computervision', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nti0ky', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.8, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'reddit_video': {'bitrate_kbps': 1200, 'fallback_url': 'https://v.redd.it/t94ei60e7m371/DASH_480.mp4?source=fallback', 'height': 427, 'width': 854, 'scrubber_media_url': 'https://v.redd.it/t94ei60e7m371/DASH_96.mp4', 'dash_url': 'https://v.redd.it/t94ei60e7m371/DASHPlaylist.mpd?a=1626449497%2CMzRmOWQ1YWFiM2Q0ZGQyMWEyNjEwMDNkMzc3ZDQ5ZTVjYmNkZGRmNjhkNDQwMThhZThjZTQ4MmU3MDBhODI5Nw%3D%3D&amp;v=1&amp;f=sd', 'duration': 14, 'hls_url': 'https://v.redd.it/t94ei60e7m371/HLSPlaylist.m3u8?a=1626449497%2CZGEwMjRhZmY0NjEzOTgzMTQyZjY4NTZlOGFhMGUzMmNlZDFiOGM5MGVhZDUzNDgwM2VhYWNjZTRhZTI1ODdhMA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Showcase', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1623000869.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'v.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://v.redd.it/t94ei60e7m371', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '548b6866-850c-11eb-98a7-0e2238bc8f5f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2rfzn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#fdaad0', 'id': 'nti0ky', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'wojti_zielon', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/computervision/comments/nti0ky/audiodriven_neural_rendering_of_portrait_videos/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://v.redd.it/t94ei60e7m371', 'subreddit_subscribers': 48822, 'created_utc': 1622972069.0, 'num_crossposts': 1, 'media': {'reddit_video': {'bitrate_kbps': 1200, 'fallback_url': 'https://v.redd.it/t94ei60e7m371/DASH_480.mp4?source=fallback', 'height': 427, 'width': 854, 'scrubber_media_url': 'https://v.redd.it/t94ei60e7m371/DASH_96.mp4', 'dash_url': 'https://v.redd.it/t94ei60e7m371/DASHPlaylist.mpd?a=1626449497%2CMzRmOWQ1YWFiM2Q0ZGQyMWEyNjEwMDNkMzc3ZDQ5ZTVjYmNkZGRmNjhkNDQwMThhZThjZTQ4MmU3MDBhODI5Nw%3D%3D&amp;v=1&amp;f=sd', 'duration': 14, 'hls_url': 'https://v.redd.it/t94ei60e7m371/HLSPlaylist.m3u8?a=1626449497%2CZGEwMjRhZmY0NjEzOTgzMTQyZjY4NTZlOGFhMGUzMmNlZDFiOGM5MGVhZDUzNDgwM2VhYWNjZTRhZTI1ODdhMA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}, 'is_video': True}]",t3_nti0ky,,,,,
,deeplearning,,t2_gp3kfk8,False,,0,False,Had some fun with YOLOR detector and Magvii tracker with pretty simple counting algorithm,[],r/deeplearning,False,6,,0,,False,t3_nthv6q,False,dark,0.84,,public,8,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/3-0LhiDghls?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'OTFF: Object Tracking For Fun v0.1', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/3-0LhiDghls?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'JC Huynh', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/3-0LhiDghls/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/JCHuynh3011'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/3-0LhiDghls?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nthv6q', 'height': 200}",,False,8,,False,False,,False,,[],{},,False,,1623000227.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/3-0LhiDghls,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nthv6q,True,,JC1DA,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nthv6q/had_some_fun_with_yolor_detector_and_magvii/,all_ads,False,https://youtu.be/3-0LhiDghls,66147,1622971427.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'OTFF: Object Tracking For Fun v0.1', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/3-0LhiDghls?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'JC Huynh', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/3-0LhiDghls/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/JCHuynh3011'}}",False,,,,,,,
,deeplearning,,t2_3f66wv8f,False,,0,False,Generating Anime Images using PyTorch implementation of DCGAN,[],r/deeplearning,False,6,,0,,False,t3_nt2hiy,False,dark,0.94,,public,109,0,{},,False,[],,True,False,,{},,False,109,,False,False,,False,,[],{},,False,,1622947630.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/b0qal9b6th371.gif,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nt2hiy,True,,rohitkuk,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/nt2hiy/generating_anime_images_using_pytorch/,all_ads,False,https://i.redd.it/b0qal9b6th371.gif,66147,1622918830.0,5,,False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,"Egyptian Arabic Podcast: Introduction (Intermediate B1) SUBS (AR, EN, FR)",[],r/deeplearning,False,6,,0,,False,t3_ntsvfp,False,dark,0.33,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/o9eV2J_atlg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Egyptian Arabic Podcast: Introduction (Intermediate B1) SUBS (AR, EN, FR)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/o9eV2J_atlg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/o9eV2J_atlg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/o9eV2J_atlg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ntsvfp', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1623034887.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=o9eV2J_atlg,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ntsvfp,True,,Community-Of-Babel,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ntsvfp/egyptian_arabic_podcast_introduction_intermediate/,all_ads,False,https://www.youtube.com/watch?v=o9eV2J_atlg,66147,1623006087.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Egyptian Arabic Podcast: Introduction (Intermediate B1) SUBS (AR, EN, FR)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/o9eV2J_atlg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/o9eV2J_atlg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}",False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Egyptian Arabic Podcast: Introduction (Intermediate B1) SUBS (AR, EN, FR)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_ntstim', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 0, 'total_awards_received': 0, 'media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/o9eV2J_atlg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Egyptian Arabic Podcast: Introduction (Intermediate B1) SUBS (AR, EN, FR)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/o9eV2J_atlg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/o9eV2J_atlg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/o9eV2J_atlg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ntstim', 'height': 200}, 'link_flair_text': None, 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1623034749.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtube.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.youtube.com/watch?v=o9eV2J_atlg', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'ntstim', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/ntstim/egyptian_arabic_podcast_introduction_intermediate/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://www.youtube.com/watch?v=o9eV2J_atlg', 'subreddit_subscribers': 0, 'created_utc': 1623005949.0, 'num_crossposts': 3, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Egyptian Arabic Podcast: Introduction (Intermediate B1) SUBS (AR, EN, FR)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/o9eV2J_atlg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/o9eV2J_atlg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}, 'is_video': False}]",t3_ntstim,,,,,
,deeplearning,"hey guys i wanted to build a chatbot from scratch using the pretrained transformer model, 

can anyone suggests the basic steps for the development",t2_aogba58q,False,,0,False,build chatbot,[],r/deeplearning,False,6,,0,,False,t3_ntlmdv,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623014470.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;hey guys i wanted to build a chatbot from scratch using the pretrained transformer model, &lt;/p&gt;

&lt;p&gt;can anyone suggests the basic steps for the development&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ntlmdv,True,,ml_enthusiast09,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ntlmdv/build_chatbot/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ntlmdv/build_chatbot/,66147,1622985670.0,0,,False,,,,,,,
,deeplearning," If you are working in DataScience/MachineLearning/DeepLearning, sooner or later you'll have to encounter underfitting and overfitting. In today's post, I discuss techniques that can be used to handle them.

[https://towardsdatascience.com/techniques-for-handling-underfitting-and-overfitting-in-machine-learning-348daa2380b9?sk=1280d18bea711daa501bf536355bed4a](https://towardsdatascience.com/techniques-for-handling-underfitting-and-overfitting-in-machine-learning-348daa2380b9?sk=1280d18bea711daa501bf536355bed4a)  


\#machinelearning #datascience #deeplearning #ai #biasvariancetradeoff #overfitting #underfitting #artificialintelligence #ml #towardsdatascience",t2_dem70,False,,0,False,Techniques for handling underfitting and overfitting in Machine Learning,[],r/deeplearning,False,6,,0,,False,t3_ntm05e,False,dark,0.25,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623015665.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If you are working in DataScience/MachineLearning/DeepLearning, sooner or later you&amp;#39;ll have to encounter underfitting and overfitting. In today&amp;#39;s post, I discuss techniques that can be used to handle them.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://towardsdatascience.com/techniques-for-handling-underfitting-and-overfitting-in-machine-learning-348daa2380b9?sk=1280d18bea711daa501bf536355bed4a""&gt;https://towardsdatascience.com/techniques-for-handling-underfitting-and-overfitting-in-machine-learning-348daa2380b9?sk=1280d18bea711daa501bf536355bed4a&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;#machinelearning #datascience #deeplearning #ai #biasvariancetradeoff #overfitting #underfitting #artificialintelligence #ml #towardsdatascience&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ntm05e,True,,msminhas93,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ntm05e/techniques_for_handling_underfitting_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ntm05e/techniques_for_handling_underfitting_and/,66147,1622986865.0,0,,False,,,,,,,
,deeplearning,"Hello Everyone :)

Hi, so i have been building a Django project in python for the last two months and have got everything ready from user registration to file upload. Now my LAST part left is the following.

A User clicks an image on site which then drops down and shows similar results of that image.

How can i achieve that ? I want to fetch the results from the Database back-end of python (Will use the async Fetch function for that ) and the add Event listener for clicking an Image.

Will Really Need  Your Help. Thanks :)",t2_cprwzva,False,,0,False,Click an Image and Display Similar Results,[],r/deeplearning,False,6,,0,,False,t3_ntd80k,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1622981445.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello Everyone :)&lt;/p&gt;

&lt;p&gt;Hi, so i have been building a Django project in python for the last two months and have got everything ready from user registration to file upload. Now my LAST part left is the following.&lt;/p&gt;

&lt;p&gt;A User clicks an image on site which then drops down and shows similar results of that image.&lt;/p&gt;

&lt;p&gt;How can i achieve that ? I want to fetch the results from the Database back-end of python (Will use the async Fetch function for that ) and the add Event listener for clicking an Image.&lt;/p&gt;

&lt;p&gt;Will Really Need  Your Help. Thanks :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ntd80k,True,,Edulad,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/ntd80k/click_an_image_and_display_similar_results/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ntd80k/click_an_image_and_display_similar_results/,66147,1622952645.0,0,,False,,,,,,,
,deeplearning,I think DL models are pretty good for both the tasks but I was wondering which one is tougher. I feel classification is easier than regression using DL models. I want to know if the classification is easy as a task itself independent of any model? Or is there any catch in the behaviour of DL models?  Or this question itself makes no sense? Just curious,t2_5d883har,False,,0,False,Just curious: Classification Vs Regression task which is easier to accomplish using DL models?,[],r/deeplearning,False,6,,0,,False,t3_ntdkb6,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622982708.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I think DL models are pretty good for both the tasks but I was wondering which one is tougher. I feel classification is easier than regression using DL models. I want to know if the classification is easy as a task itself independent of any model? Or is there any catch in the behaviour of DL models?  Or this question itself makes no sense? Just curious&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ntdkb6,True,,SnooDoggos3844,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/ntdkb6/just_curious_classification_vs_regression_task/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ntdkb6/just_curious_classification_vs_regression_task/,66147,1622953908.0,0,,False,,,,,,,
,deeplearning,"Hey guys, title really. Have been through the top posts by but is mainly memes, not necessarily looking for someone to hold my hand, but just some rough information so I can research myself. 

I currently use NiceHash and I'm assuming this is the same in principle - rent out GPU/s? Currently have a 1080ti, (would have more if it wasn't for damn scalpers) 32GB of DDR4, an 8700K @ 5.2, and 1TB NVME SATA and a 2TB SSD. Aiming to get more cards when people start panic selling their mining cards (3080s have dropped £500 already on my local pages).

So yeah, can I do anything with what I've got, and where's a good resource to properly dig in to the ins and outs?

Cheers in advance.",t2_13mizr,False,,0,False,Considering joining the AI train.,[],r/deeplearning,False,6,,0,,False,t3_ntf8t9,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622989049.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, title really. Have been through the top posts by but is mainly memes, not necessarily looking for someone to hold my hand, but just some rough information so I can research myself. &lt;/p&gt;

&lt;p&gt;I currently use NiceHash and I&amp;#39;m assuming this is the same in principle - rent out GPU/s? Currently have a 1080ti, (would have more if it wasn&amp;#39;t for damn scalpers) 32GB of DDR4, an 8700K @ 5.2, and 1TB NVME SATA and a 2TB SSD. Aiming to get more cards when people start panic selling their mining cards (3080s have dropped £500 already on my local pages).&lt;/p&gt;

&lt;p&gt;So yeah, can I do anything with what I&amp;#39;ve got, and where&amp;#39;s a good resource to properly dig in to the ins and outs?&lt;/p&gt;

&lt;p&gt;Cheers in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ntf8t9,True,,unorthadoxparadox,,17,True,all_ads,False,[],False,,/r/deeplearning/comments/ntf8t9/considering_joining_the_ai_train/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ntf8t9/considering_joining_the_ai_train/,66147,1622960249.0,0,,False,,,,,,,
,deeplearning,,t2_e16u3,False,,0,False,The Energy-Based Learning Model — Yann LeCun,[],r/deeplearning,False,6,,0,,False,t3_nt0jrb,False,dark,0.79,,public,6,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/4lthJd3DNTM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Yann LeCun | May 18, 2021 | The Energy-Based Learning Model', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/4lthJd3DNTM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Mathematical Picture Language', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/4lthJd3DNTM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCrlS3CuPlahBp_M46fDaWVw'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/4lthJd3DNTM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nt0jrb', 'height': 200}",,False,6,,False,False,,False,,[],{},,False,,1622942195.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=4lthJd3DNTM,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nt0jrb,True,,Yaoel,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nt0jrb/the_energybased_learning_model_yann_lecun/,all_ads,False,https://www.youtube.com/watch?v=4lthJd3DNTM,66147,1622913395.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Yann LeCun | May 18, 2021 | The Energy-Based Learning Model', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/4lthJd3DNTM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Mathematical Picture Language', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/4lthJd3DNTM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCrlS3CuPlahBp_M46fDaWVw'}}",False,,,,,,,
,deeplearning,"What if you want to measure translation on an image?  Is CNN the best tool for the job still, even though its qualities are a bit adversarial to the task?",t2_6xu7knfy,False,,0,False,Translation invariance.. I don't like this quality,[],r/deeplearning,False,6,,0,,False,t3_nt9os1,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622969113.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What if you want to measure translation on an image?  Is CNN the best tool for the job still, even though its qualities are a bit adversarial to the task?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nt9os1,True,,v4pe2,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nt9os1/translation_invariance_i_dont_like_this_quality/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nt9os1/translation_invariance_i_dont_like_this_quality/,66147,1622940313.0,0,,False,,,,True,,,
,deeplearning,"Hey guys, so I have a very short time to make a final project from Natural Language and Speech Processing. Any ideas for a simple and short project? I have to learn the basics quickly so I have no idea what to pick and I'll appreciate any piece of advice.

Do you know any guides for such projects?

Thanks in advance)

P.S. Maybe it's not very suitable to post here but I hope you'll help me",t2_bwh6yhpr,False,,0,False,Help on choosing a topic for a short project from NLP,[],r/deeplearning,False,6,,0,,False,t3_nswr0k,False,dark,0.8,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1622931582.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, so I have a very short time to make a final project from Natural Language and Speech Processing. Any ideas for a simple and short project? I have to learn the basics quickly so I have no idea what to pick and I&amp;#39;ll appreciate any piece of advice.&lt;/p&gt;

&lt;p&gt;Do you know any guides for such projects?&lt;/p&gt;

&lt;p&gt;Thanks in advance)&lt;/p&gt;

&lt;p&gt;P.S. Maybe it&amp;#39;s not very suitable to post here but I hope you&amp;#39;ll help me&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nswr0k,True,,freckles_____,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nswr0k/help_on_choosing_a_topic_for_a_short_project_from/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nswr0k/help_on_choosing_a_topic_for_a_short_project_from/,66147,1622902782.0,0,,False,,,,,,,
,deeplearning,"We have an informative new post on Non Maximum Suppression with PyTorch today.  


Imagine you have trained a car detector. If trained properly it will create a bounding box around all cars in an image. Now, if you move the detected bounding box by one pixel in any direction, it is still a valid picture of a car. The detector may also select bounding boxes that do not cover the entire car. So, it will end up producing more than one bounding box for the same object unless we do some post-processing to filter out these multiple detections for the same object.  


The class of algorithms for achieving this filtering is called Non Maximum Suppression. In today's post, we go over the nuances of the problem and share an implementation. 

[https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/](https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/)",t2_cvc9f,False,,0,False,Non Maximum Suppression: Theory and Implementation in PyTorch,[],r/deeplearning,False,6,,0,,False,t3_nt3a3g,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622949873.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We have an informative new post on Non Maximum Suppression with PyTorch today.  &lt;/p&gt;

&lt;p&gt;Imagine you have trained a car detector. If trained properly it will create a bounding box around all cars in an image. Now, if you move the detected bounding box by one pixel in any direction, it is still a valid picture of a car. The detector may also select bounding boxes that do not cover the entire car. So, it will end up producing more than one bounding box for the same object unless we do some post-processing to filter out these multiple detections for the same object.  &lt;/p&gt;

&lt;p&gt;The class of algorithms for achieving this filtering is called Non Maximum Suppression. In today&amp;#39;s post, we go over the nuances of the problem and share an implementation. &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/""&gt;https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nt3a3g,True,,spmallick,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nt3a3g/non_maximum_suppression_theory_and_implementation/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nt3a3g/non_maximum_suppression_theory_and_implementation/,66147,1622921073.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,High-resolution depth estimation from a single image,[],r/deeplearning,False,6,,0,,False,t3_nsggai,False,dark,0.96,,public,52,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QSxfb-GC0U4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'High-resolution depth estimation from a single image', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QSxfb-GC0U4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/QSxfb-GC0U4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QSxfb-GC0U4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nsggai', 'height': 200}",,False,52,,False,False,,False,,[],{},,False,,1622872168.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/QSxfb-GC0U4,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nsggai,True,,cmillionaire9,,13,True,all_ads,False,[],False,,/r/deeplearning/comments/nsggai/highresolution_depth_estimation_from_a_single/,all_ads,False,https://youtu.be/QSxfb-GC0U4,66147,1622843368.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'High-resolution depth estimation from a single image', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QSxfb-GC0U4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/QSxfb-GC0U4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,"Hey guys, i have to present the topic context-aware poi recommendation (geo &amp; time) incorporating visual content. I have to read papers in that area but i don't know if it is possible to combine algorithms from two different paper. It is easy to find image feature processing solely and context-aware recommendation solely. But is it easy to combine them later?",t2_a8zq9blj,False,,0,False,Need your help for poi recommendation,[],r/deeplearning,False,6,,0,,False,t3_nt2t7a,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622948541.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, i have to present the topic context-aware poi recommendation (geo &amp;amp; time) incorporating visual content. I have to read papers in that area but i don&amp;#39;t know if it is possible to combine algorithms from two different paper. It is easy to find image feature processing solely and context-aware recommendation solely. But is it easy to combine them later?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nt2t7a,True,,stockhaunter,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nt2t7a/need_your_help_for_poi_recommendation/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nt2t7a/need_your_help_for_poi_recommendation/,66147,1622919741.0,0,,False,,,,,,,
,deeplearning,"I'm trying an experiment where I take pictures myself, and have a neural network both count the number of objects in the image and classify what objects are there. For example, a picture of animals could return ""2 cats 1 dog"", but the location of the object does not necessarily have to be pointed to. What is the best way to label the dataset? I have a lot of images that I took myself, but I was wondering if I could label the dataset [image][vector] (for example, [vector] could be [cat, dog] and it would indicate the count of each), or do I have to resort to bounding box annotations? 

Thanks in advance!",t2_5z438cm7,False,,0,False,How would you structure a dataset for both image counting and classification? And what would be the best approach for this task?,[],r/deeplearning,False,6,,0,,False,t3_nssug6,False,dark,1.0,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1622917827.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying an experiment where I take pictures myself, and have a neural network both count the number of objects in the image and classify what objects are there. For example, a picture of animals could return &amp;quot;2 cats 1 dog&amp;quot;, but the location of the object does not necessarily have to be pointed to. What is the best way to label the dataset? I have a lot of images that I took myself, but I was wondering if I could label the dataset [image][vector] (for example, [vector] could be [cat, dog] and it would indicate the count of each), or do I have to resort to bounding box annotations? &lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nssug6,True,,quaranprove,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/nssug6/how_would_you_structure_a_dataset_for_both_image/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nssug6/how_would_you_structure_a_dataset_for_both_image/,66147,1622889027.0,0,,False,,,,,,,
,deeplearning,,t2_m98ku,False,,0,False,Fish schools as ensemble learning algorithms,[],r/deeplearning,False,6,,0,,False,t3_nso0s1,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1622897698.0,text,6,,,text,link.medium.com,False,,,,,https://link.medium.com/vzIFQK4FPgb,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nso0s1,True,,cmosguy1,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nso0s1/fish_schools_as_ensemble_learning_algorithms/,all_ads,False,https://link.medium.com/vzIFQK4FPgb,66147,1622868898.0,0,,False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,"how to say ""i don't know"" in Egyptian Arabic🙄🤔",[],r/deeplearning,False,6,,0,,False,t3_nt33u2,False,dark,0.14,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1622949389.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/9bv2xky6yh371.png,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nt33u2,True,,Community-Of-Babel,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nt33u2/how_to_say_i_dont_know_in_egyptian_arabic/,all_ads,False,https://i.redd.it/9bv2xky6yh371.png,66147,1622920589.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'how to say ""i don\'t know"" in Egyptian Arabic🙄🤔', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nt323t', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1622949256.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/9bv2xky6yh371.png', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nt323t', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/nt323t/how_to_say_i_dont_know_in_egyptian_arabic/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://i.redd.it/9bv2xky6yh371.png', 'subreddit_subscribers': 0, 'created_utc': 1622920456.0, 'num_crossposts': 3, 'media': None, 'is_video': False}]",t3_nt323t,,,,,
,deeplearning,"I have a project wherein the inputs are a high school student's grades and the output will be a recommended college program based from their grades on their Senior high school subjects, we plan to train high school grades of college students who picked their specific college program for classification, what will be the ideal algorithm to use?",t2_cjdpiv53,False,,0,False,Need Machine learning algorithm,[],r/deeplearning,False,6,,0,,False,t3_nspjsk,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622903758.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a project wherein the inputs are a high school student&amp;#39;s grades and the output will be a recommended college program based from their grades on their Senior high school subjects, we plan to train high school grades of college students who picked their specific college program for classification, what will be the ideal algorithm to use?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nspjsk,True,,rektum4,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nspjsk/need_machine_learning_algorithm/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nspjsk/need_machine_learning_algorithm/,66147,1622874958.0,0,,False,,,,,,,
,deeplearning,"I am curious about how  depth estimation using deep learning is applied in real world scenario. I have seen in internet these violetish-orangesish images created after depth estimation of an image and its said their main application is in augmented reality. 

I am guessing the end result of depth estimation is an image with single channel (violetish-orangesish image) with 0 representing near object pixel and some higher value for the farthest object pixel. Using this how we are controlling AR objects? Or can you please give an overview of this?",t2_es9xwhl,False,,0,False,How is deep learning depth estimation is applied in real world.problems?,[],r/deeplearning,False,6,,0,,False,t3_nsokdc,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1622871237.0,,[],{},,True,,1622899773.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am curious about how  depth estimation using deep learning is applied in real world scenario. I have seen in internet these violetish-orangesish images created after depth estimation of an image and its said their main application is in augmented reality. &lt;/p&gt;

&lt;p&gt;I am guessing the end result of depth estimation is an image with single channel (violetish-orangesish image) with 0 representing near object pixel and some higher value for the farthest object pixel. Using this how we are controlling AR objects? Or can you please give an overview of this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nsokdc,True,,begooboi,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nsokdc/how_is_deep_learning_depth_estimation_is_applied/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nsokdc/how_is_deep_learning_depth_estimation_is_applied/,66147,1622870973.0,0,,False,,,,,,,
,deeplearning,"The a30 cost almost 3 times the price of the 3090 AT MSRP. What makes cards like the quadro rtx, a8000, a6000, a30 more suitable and better than the 3090 for deep learning? What warrants that huge price?",t2_8qp7rsco,False,,0,False,Difference between rtx 3090 and a30 for deep learning and AI?,[],r/deeplearning,False,6,,0,,False,t3_ns0zc0,False,dark,0.89,,public,27,0,{},,False,[],,False,False,,{},,False,27,,False,False,,False,,[],{},,True,,1622827721.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The a30 cost almost 3 times the price of the 3090 AT MSRP. What makes cards like the quadro rtx, a8000, a6000, a30 more suitable and better than the 3090 for deep learning? What warrants that huge price?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ns0zc0,True,,Hot-Vermicelli9242,,25,True,all_ads,False,[],False,,/r/deeplearning/comments/ns0zc0/difference_between_rtx_3090_and_a30_for_deep/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ns0zc0/difference_between_rtx_3090_and_a30_for_deep/,66147,1622798921.0,0,,False,,,,,,,
,deeplearning,,t2_1j5kuigl,False,,0,False,[R] CVPR 2021-Progressive Self Label Correction (ProSelfLC) for Training Robust Deep Neural Networks,[],r/deeplearning,False,6,,0,,False,t3_nsha6z,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1622874564.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/nsh6uu/r_cvpr_2021progressive_self_label_correction/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nsha6z,True,,XinshaoWang,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nsha6z/r_cvpr_2021progressive_self_label_correction/,all_ads,False,/r/MachineLearning/comments/nsh6uu/r_cvpr_2021progressive_self_label_correction/,66147,1622845764.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '[https://arxiv.org/abs/2005.03788](https://arxiv.org/abs/2005.03788)\n\n[https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021](https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021)\n\n[https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021/issues/2](https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021/issues/2)\n\n**Keywords**: entropy minimisation, maximum entropy, confidence penalty, self knowledge distillation, label correction, label noise, semi-supervised learning, output regularisation\n\n&amp;#x200B;\n\nProSelfLC is the first method to trust self knowledge progressively and adaptively. ProSelfLC redirects and promotes entropy minimisation, which is in marked contrast to recent practices of confidence penalty \\[42, 33, 6\\]', 'author_fullname': 't2_1j5kuigl', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R] CVPR 2021-Progressive Self Label Correction (ProSelfLC) for Training Robust Deep Neural Networks', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nsh6uu', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': 1622845673.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1622874281.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://arxiv.org/abs/2005.03788""&gt;https://arxiv.org/abs/2005.03788&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021""&gt;https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021/issues/2""&gt;https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021/issues/2&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Keywords&lt;/strong&gt;: entropy minimisation, maximum entropy, confidence penalty, self knowledge distillation, label correction, label noise, semi-supervised learning, output regularisation&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;ProSelfLC is the first method to trust self knowledge progressively and adaptively. ProSelfLC redirects and promotes entropy minimisation, which is in marked contrast to recent practices of confidence penalty [42, 33, 6]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nsh6uu', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'XinshaoWang', 'discussion_type': None, 'num_comments': 15, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/nsh6uu/r_cvpr_2021progressive_self_label_correction/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/nsh6uu/r_cvpr_2021progressive_self_label_correction/', 'subreddit_subscribers': 1931369, 'created_utc': 1622845481.0, 'num_crossposts': 7, 'media': None, 'is_video': False}]",t3_nsh6uu,,,,,
,deeplearning,"Activation functions might seem to be a very small component in the grand scheme of hundreds of layers and millions of parameters in deep neural networks, yet their importance is paramount. Activation functions not only help with training by introducing non-linearity, but they also help with network optimization. 

In this article we'll explore the 2018 paper by Google Brain titled ""[Searching for activation functions](https://arxiv.org/pdf/1710.05941.pdf)"". The paper proposes a novel activation function called Swish, which was discovered using a Neural Architecture Search (NAS) approach and showed significant improvement in performance compared to standard activation functions like ReLU or Leaky ReLU.

We will first take a look at the motivation behind the paper, followed by a dissection of the structure of Swish and its similarities to SILU (Sigmoid Weighted Linear Unit). We will then go through the results when Swish is applied to several NLP tasks, along with the PyTorch code to train your own deep neural networks with Swish.

Topics covered include:

1. Motivation
2. Swish Explained 
3. PyTorch Code
4. Notable Results
5. Conclusion
6. Reference

Article link: [https://blog.paperspace.com/swish-activation-function/](https://blog.paperspace.com/swish-activation-function/)",t2_15en0l,False,,0,False,[Article] The Swish Activation Function,[],r/deeplearning,False,6,,0,,False,t3_nsgg9h,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622872166.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Activation functions might seem to be a very small component in the grand scheme of hundreds of layers and millions of parameters in deep neural networks, yet their importance is paramount. Activation functions not only help with training by introducing non-linearity, but they also help with network optimization. &lt;/p&gt;

&lt;p&gt;In this article we&amp;#39;ll explore the 2018 paper by Google Brain titled &amp;quot;&lt;a href=""https://arxiv.org/pdf/1710.05941.pdf""&gt;Searching for activation functions&lt;/a&gt;&amp;quot;. The paper proposes a novel activation function called Swish, which was discovered using a Neural Architecture Search (NAS) approach and showed significant improvement in performance compared to standard activation functions like ReLU or Leaky ReLU.&lt;/p&gt;

&lt;p&gt;We will first take a look at the motivation behind the paper, followed by a dissection of the structure of Swish and its similarities to SILU (Sigmoid Weighted Linear Unit). We will then go through the results when Swish is applied to several NLP tasks, along with the PyTorch code to train your own deep neural networks with Swish.&lt;/p&gt;

&lt;p&gt;Topics covered include:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Motivation&lt;/li&gt;
&lt;li&gt;Swish Explained &lt;/li&gt;
&lt;li&gt;PyTorch Code&lt;/li&gt;
&lt;li&gt;Notable Results&lt;/li&gt;
&lt;li&gt;Conclusion&lt;/li&gt;
&lt;li&gt;Reference&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Article link: &lt;a href=""https://blog.paperspace.com/swish-activation-function/""&gt;https://blog.paperspace.com/swish-activation-function/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nsgg9h,True,,hellopaperspace,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nsgg9h/article_the_swish_activation_function/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nsgg9h/article_the_swish_activation_function/,66147,1622843366.0,0,,False,,,,,,,
,deeplearning,"I'm looking for 4 people who are experienced and interested in deep learning. I'd like to organize a study group for reading 2019-2021 top conference (ICML/ICLR/NIPS/AAAI/EMNLP/COLT/..) paper together. This will be a 3 months study group. Details:

Everyone picks 5 papers from top conference --&gt; we take turns to share the content/idea/points of the paper --&gt;  once a week, 2 people per week, 30-60 mins for one person --&gt; use slack as communication tool and use google meet for the meeting

Rules: every week attendance !! prepare slides before presentation!!",t2_c6tk2z5h,False,,0,False,Looking for study partners,[],r/deeplearning,False,6,,0,,False,t3_nrvxgq,False,dark,0.95,,public,28,0,{},,False,[],,False,False,,{},,False,28,,False,False,,1622788949.0,,[],{},,True,,1622807580.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking for 4 people who are experienced and interested in deep learning. I&amp;#39;d like to organize a study group for reading 2019-2021 top conference (ICML/ICLR/NIPS/AAAI/EMNLP/COLT/..) paper together. This will be a 3 months study group. Details:&lt;/p&gt;

&lt;p&gt;Everyone picks 5 papers from top conference --&amp;gt; we take turns to share the content/idea/points of the paper --&amp;gt;  once a week, 2 people per week, 30-60 mins for one person --&amp;gt; use slack as communication tool and use google meet for the meeting&lt;/p&gt;

&lt;p&gt;Rules: every week attendance !! prepare slides before presentation!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nrvxgq,True,,Environment_123,,13,True,all_ads,False,[],False,,/r/deeplearning/comments/nrvxgq/looking_for_study_partners/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nrvxgq/looking_for_study_partners/,66147,1622778780.0,0,,False,,,,,,,
,deeplearning,"I trained a model with five self-attention layers using the TransformerEncoderLayer from PyTorch. To get a better understanding, I extracted the attention weights for a forward pass from each layer. Does anybody have an idea how to compute the overall weights? Just add them up?",t2_8mz26qer,False,,0,False,Transformer: Interprete attention weights from multiple self attention layers,[],r/deeplearning,False,6,,0,,False,t3_ns44ql,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1622839030.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I trained a model with five self-attention layers using the TransformerEncoderLayer from PyTorch. To get a better understanding, I extracted the attention weights for a forward pass from each layer. Does anybody have an idea how to compute the overall weights? Just add them up?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ns44ql,True,,lsov2,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ns44ql/transformer_interprete_attention_weights_from/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ns44ql/transformer_interprete_attention_weights_from/,66147,1622810230.0,0,,False,,,,,,,
,deeplearning,"A research team from OneFlow and Microsoft takes a step toward automatic deep neural network structure design, exploring unsupervised structure-learning and leveraging the efficient coding principle, information theory and computational neuroscience to design structure learning without label information. 

Here is a quick read: [Microsoft &amp; OneFlow Leverage the Efficient Coding Principle to Design Unsupervised DNN Structure-Learning That Outperforms Human-Designed Structures.](https://syncedreview.com/2021/06/04/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-34/)

The paper *Learning Structures for Deep Neural Networks* is on [arXiv](https://arxiv.org/abs/2105.13905).",t2_2fv4yodo,False,,0,False,[R] Microsoft &amp; OneFlow Leverage the Efficient Coding Principle to Design Unsupervised DNN Structure-Learning That Outperforms Human-Designed Structures,[],r/deeplearning,False,6,,0,,False,t3_ns8yc6,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622852310.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from OneFlow and Microsoft takes a step toward automatic deep neural network structure design, exploring unsupervised structure-learning and leveraging the efficient coding principle, information theory and computational neuroscience to design structure learning without label information. &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/04/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-34/""&gt;Microsoft &amp;amp; OneFlow Leverage the Efficient Coding Principle to Design Unsupervised DNN Structure-Learning That Outperforms Human-Designed Structures.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Learning Structures for Deep Neural Networks&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.13905""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ns8yc6,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ns8yc6/r_microsoft_oneflow_leverage_the_efficient_coding/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ns8yc6/r_microsoft_oneflow_leverage_the_efficient_coding/,66147,1622823510.0,0,,False,,,,,,,
,deeplearning,I want to crop the detected objects (in video)to input them into a model to classify whether or not they are real or fake. How can i do it? Thanks,t2_5tjqypkb,False,,0,False,How can i crop the detected objects in darknet-yolov4?,[],r/deeplearning,False,6,,0,,False,t3_ns70h0,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622847228.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to crop the detected objects (in video)to input them into a model to classify whether or not they are real or fake. How can i do it? Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ns70h0,True,,Just-A-abnormal-Guy,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/ns70h0/how_can_i_crop_the_detected_objects_in/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ns70h0/how_can_i_crop_the_detected_objects_in/,66147,1622818428.0,0,,False,,,,,,,
,deeplearning,"**Context**

I have a DAG representing an ontology of skills (ESCO), each node in this DAG has one to n skill-labels. I want to classify a skill-label to know to which node it belongs. The idea is that a skill-label is classified on its node and each of its node's parents recursively up to the top of the DAG. Doing so should ensure a higher accuracy for the nodes at the top of the hierarchy. I already achieved this with a Tree.

The difference is that for a tree I can separate the nodes by level (1 level = 1 class) and predict only one node (class-label) per level making it much easier. This cannot be replicated for a DAG, so I put every node in one single class and try to predict which one can be applied to a skill-label.

&amp;#x200B;

**My problem**

My model learns shit, it just predicts the most common class-label from the top of the hierarchy.

&amp;#x200B;

**Statistics**

I have a total of 14158 nodes/skills so 14158 class-label, which is a lot.

A skill-label belong to an an average of 7 class-label, full stats:

* Mean: 7.391687031437684
* Median: 5.0
* Min: 1
* Max: 43
* Std dev: 4.3136178158951815

&amp;#x200B;

[Distribution of the number of class-labels that should be predicted for a given skill-label](https://preview.redd.it/sawsnxmb18371.png?width=383&amp;format=png&amp;auto=webp&amp;s=dddfdb155405c8c2f2e9a3b9f64dab48b16782ff)

&amp;#x200B;

**Deep Learning**

I'm using BERT from the transformers library by hugginface, sigmoid as my output function, and AdamW as an optimizer. For the loss I've tried a few. First, MSE, but it's not adapted because of the vast majority of class-labels shouldn't be predicted, so predicting nothing would lead to a very low loss already. I also tried BCE, but with no success. I though about going for a jaccard index, which is the metric I'm using to evaluate my model, so I went with this loss that I found online :

    class IoULoss(torch.nn.Module):
        def __init__(self, weight=None, size_average=True):
            super(IoULoss, self).__init__()
    
        def forward(self, inputs, targets, smooth=1):
            #comment out if your model contains a sigmoid or equivalent activation layer
            #inputs = torch.sigmoid(inputs)
            #flatten label and prediction tensors
            inputs = inputs.view(-1)
            targets = targets.view(-1)
            #intersection is equivalent to True Positive count
            #union is the mutually inclusive area of all labels &amp; predictions
            intersection = (inputs * targets).sum()
            total = (inputs + targets).sum()
            union = total - intersection
            IoU = (intersection + smooth)/(union + smooth)
            return 1 - IoU

But it didn't work either.

I'm considering something might be off with my data, but I entirely remade the code to generate the dataset and I haven't found anything wrong, so I'm kinda stuck. Does anyone have sources for multi-label classification with this number of labels? Everything I found online is like 5-10 labels, nothing useful for me.",t2_o5nqh,False,,0,False,Need help for multilabel classifications with A LOT of labels,[],r/deeplearning,False,6,,0,,False,t3_ns1l9c,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1622830130.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I have a DAG representing an ontology of skills (ESCO), each node in this DAG has one to n skill-labels. I want to classify a skill-label to know to which node it belongs. The idea is that a skill-label is classified on its node and each of its node&amp;#39;s parents recursively up to the top of the DAG. Doing so should ensure a higher accuracy for the nodes at the top of the hierarchy. I already achieved this with a Tree.&lt;/p&gt;

&lt;p&gt;The difference is that for a tree I can separate the nodes by level (1 level = 1 class) and predict only one node (class-label) per level making it much easier. This cannot be replicated for a DAG, so I put every node in one single class and try to predict which one can be applied to a skill-label.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;My problem&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;My model learns shit, it just predicts the most common class-label from the top of the hierarchy.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Statistics&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I have a total of 14158 nodes/skills so 14158 class-label, which is a lot.&lt;/p&gt;

&lt;p&gt;A skill-label belong to an an average of 7 class-label, full stats:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Mean: 7.391687031437684&lt;/li&gt;
&lt;li&gt;Median: 5.0&lt;/li&gt;
&lt;li&gt;Min: 1&lt;/li&gt;
&lt;li&gt;Max: 43&lt;/li&gt;
&lt;li&gt;Std dev: 4.3136178158951815&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/sawsnxmb18371.png?width=383&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dddfdb155405c8c2f2e9a3b9f64dab48b16782ff""&gt;Distribution of the number of class-labels that should be predicted for a given skill-label&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Deep Learning&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I&amp;#39;m using BERT from the transformers library by hugginface, sigmoid as my output function, and AdamW as an optimizer. For the loss I&amp;#39;ve tried a few. First, MSE, but it&amp;#39;s not adapted because of the vast majority of class-labels shouldn&amp;#39;t be predicted, so predicting nothing would lead to a very low loss already. I also tried BCE, but with no success. I though about going for a jaccard index, which is the metric I&amp;#39;m using to evaluate my model, so I went with this loss that I found online :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class IoULoss(torch.nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(IoULoss, self).__init__()

    def forward(self, inputs, targets, smooth=1):
        #comment out if your model contains a sigmoid or equivalent activation layer
        #inputs = torch.sigmoid(inputs)
        #flatten label and prediction tensors
        inputs = inputs.view(-1)
        targets = targets.view(-1)
        #intersection is equivalent to True Positive count
        #union is the mutually inclusive area of all labels &amp;amp; predictions
        intersection = (inputs * targets).sum()
        total = (inputs + targets).sum()
        union = total - intersection
        IoU = (intersection + smooth)/(union + smooth)
        return 1 - IoU
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But it didn&amp;#39;t work either.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m considering something might be off with my data, but I entirely remade the code to generate the dataset and I haven&amp;#39;t found anything wrong, so I&amp;#39;m kinda stuck. Does anyone have sources for multi-label classification with this number of labels? Everything I found online is like 5-10 labels, nothing useful for me.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ns1l9c,True,,saig22,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ns1l9c/need_help_for_multilabel_classifications_with_a/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ns1l9c/need_help_for_multilabel_classifications_with_a/,66147,1622801330.0,0,,False,,,"{'sawsnxmb18371': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 77, 'x': 108, 'u': 'https://preview.redd.it/sawsnxmb18371.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f9170a4aea65da672f19efd37e6640c74c85aa90'}, {'y': 155, 'x': 216, 'u': 'https://preview.redd.it/sawsnxmb18371.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cf7b3cb9c72a326c7705eaa55f69d87dc7c88b1e'}, {'y': 229, 'x': 320, 'u': 'https://preview.redd.it/sawsnxmb18371.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b3222be32cc9633809771a0501e8ff95f038b97'}], 's': {'y': 275, 'x': 383, 'u': 'https://preview.redd.it/sawsnxmb18371.png?width=383&amp;format=png&amp;auto=webp&amp;s=dddfdb155405c8c2f2e9a3b9f64dab48b16782ff'}, 'id': 'sawsnxmb18371'}}",,,,
,deeplearning,"I have the following Graph neural network model and I am not able to get the learnable parameters of the model to do optimization.

&amp;#x200B;

    from torch.nn.parameter import Parameter
    from torch.nn.modules.module import Module
    class Graphconvlayer(nn.Module):
      def __init__(self,adj,input_feature_neurons,output_neurons):
        super(Graphconvlayer, self).__init__()
        self.adj=adj
        self.input_feature_neurons=input_feature_neurons
        self.output_neurons=output_neurons
        self.weights=Parameter(torch.normal(mean=0.0,std=torch.ones(input_feature_neurons,output_neurons)))
        self.bias=Parameter(torch.normal(mean=0.0,std=torch.ones(output_neurons)))
      
      def forward(self,inputfeaturedata):
        output1= torch.mm(self.adj,inputfeaturedata)
        print(output1.shape)
        print(self.weights.shape)
        print(self.bias.shape)
        output2= torch.matmul(output1,self.weights)+ self.bias
        return output2 
    
    class GCN(nn.Module):
       def __init__(self,adj,input_feature_neurons,output_neurons,lr,dropoutvalue,hidden,data):
         super(GCN, self).__init__()
         self.adj=adj
         self.input_feature_neurons=input_feature_neurons
         self.output_neurons=output_neurons
         self.lr=lr
         self.dropoutvalue=dropoutvalue
         self.hidden=hidden
         self.data=data
         self.gcn1 = Graphconvlayer(adj,input_feature_neurons,hidden)
         self.gcn2 = Graphconvlayer(adj,hidden,output_neurons)
      
       def forward(self,x):
         x= F.relu(self.gcn1(x))
         x= F.dropout(x,self.dropoutvalue)
         x= self.gcn2(x)
         print(""opop"")
         return F.log_softmax(x,dim=1)

&amp;#x200B;

    for n, p in a.named_parameters():
        print(n, p.shape)
    
    &gt;&gt;&gt;
    gcn1.weights torch.Size([1433, 2708])
    gcn1.bias torch.Size([2708])
    gcn2.weights torch.Size([2708, 7])
    gcn2.bias torch.Size([7])
    &gt;&gt;&gt;
    
    optimizer= optim.Adam(a.named_parameters()),lr=0.001)
    &gt;&gt;&gt;
    NameError: name 'optim' is not defined
    

&amp;#x200B;

When I pass it as a dict(a.named\_parameters()), I am able to print the values, but can not pass it to the optimization function. Can anyone guide me through this?",t2_c5febi8b,False,,0,False,Input parameters from a nested class to Pytorch Optimization Function,[],r/deeplearning,False,6,,0,,False,t3_ns1dw2,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1622829336.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have the following Graph neural network model and I am not able to get the learnable parameters of the model to do optimization.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from torch.nn.parameter import Parameter
from torch.nn.modules.module import Module
class Graphconvlayer(nn.Module):
  def __init__(self,adj,input_feature_neurons,output_neurons):
    super(Graphconvlayer, self).__init__()
    self.adj=adj
    self.input_feature_neurons=input_feature_neurons
    self.output_neurons=output_neurons
    self.weights=Parameter(torch.normal(mean=0.0,std=torch.ones(input_feature_neurons,output_neurons)))
    self.bias=Parameter(torch.normal(mean=0.0,std=torch.ones(output_neurons)))

  def forward(self,inputfeaturedata):
    output1= torch.mm(self.adj,inputfeaturedata)
    print(output1.shape)
    print(self.weights.shape)
    print(self.bias.shape)
    output2= torch.matmul(output1,self.weights)+ self.bias
    return output2 

class GCN(nn.Module):
   def __init__(self,adj,input_feature_neurons,output_neurons,lr,dropoutvalue,hidden,data):
     super(GCN, self).__init__()
     self.adj=adj
     self.input_feature_neurons=input_feature_neurons
     self.output_neurons=output_neurons
     self.lr=lr
     self.dropoutvalue=dropoutvalue
     self.hidden=hidden
     self.data=data
     self.gcn1 = Graphconvlayer(adj,input_feature_neurons,hidden)
     self.gcn2 = Graphconvlayer(adj,hidden,output_neurons)

   def forward(self,x):
     x= F.relu(self.gcn1(x))
     x= F.dropout(x,self.dropoutvalue)
     x= self.gcn2(x)
     print(&amp;quot;opop&amp;quot;)
     return F.log_softmax(x,dim=1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for n, p in a.named_parameters():
    print(n, p.shape)

&amp;gt;&amp;gt;&amp;gt;
gcn1.weights torch.Size([1433, 2708])
gcn1.bias torch.Size([2708])
gcn2.weights torch.Size([2708, 7])
gcn2.bias torch.Size([7])
&amp;gt;&amp;gt;&amp;gt;

optimizer= optim.Adam(a.named_parameters()),lr=0.001)
&amp;gt;&amp;gt;&amp;gt;
NameError: name &amp;#39;optim&amp;#39; is not defined
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;When I pass it as a dict(a.named_parameters()), I am able to print the values, but can not pass it to the optimization function. Can anyone guide me through this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ns1dw2,True,,popkept09,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ns1dw2/input_parameters_from_a_nested_class_to_pytorch/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ns1dw2/input_parameters_from_a_nested_class_to_pytorch/,66147,1622800536.0,2,,False,,,,,,,
,deeplearning,,t2_i4txk,False,,0,False,I'm looking for a tool that let's you visualize the models architecture like this. Any idea what it is called?,[],r/deeplearning,False,6,,0,,False,t3_nr91wq,False,dark,0.99,,public,76,0,{},,False,[],,True,False,,{},,False,76,,False,False,,False,,[],{},,False,,1622740260.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/c8puf6tlo0371.png,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nr91wq,True,,pitrucha,,27,True,all_ads,False,[],False,,/r/deeplearning/comments/nr91wq/im_looking_for_a_tool_that_lets_you_visualize_the/,all_ads,False,https://i.redd.it/c8puf6tlo0371.png,66147,1622711460.0,0,,False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,At a restaurant in Syria 🥰🥰,[],r/deeplearning,False,6,,0,,False,t3_ns805f,False,dark,0.17,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1622849780.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/qtt0vinxp9371.png,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ns805f,True,,Community-Of-Babel,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ns805f/at_a_restaurant_in_syria/,all_ads,False,https://i.redd.it/qtt0vinxp9371.png,66147,1622820980.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'At a restaurant in Syria 🥰🥰', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_ns7xwg', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1622849616.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/qtt0vinxp9371.png', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'ns7xwg', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/ns7xwg/at_a_restaurant_in_syria/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://i.redd.it/qtt0vinxp9371.png', 'subreddit_subscribers': 0, 'created_utc': 1622820816.0, 'num_crossposts': 3, 'media': None, 'is_video': False}]",t3_ns7xwg,,,,,
,deeplearning,,t2_128ob4,False,,0,False,Modality transfer with Variational autoencoder from t1 -&gt; t2,[],r/deeplearning,False,6,,0,,False,t3_nrpoek,False,dark,0.73,,public,5,0,{},,False,[],,True,False,,{},,False,5,,False,False,,False,,[],{},,False,,1622787706.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/0cu44y2tl4371.png,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nrpoek,True,,darvidas,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nrpoek/modality_transfer_with_variational_autoencoder/,all_ads,False,https://i.redd.it/0cu44y2tl4371.png,66147,1622758906.0,0,,False,,,,,,,
,deeplearning,I (19 M) am an undergrad CS major. I aim to go to a top grad school for AI. How important is understanding the mathematical proofs behind AI algorithms such as backpropagation? Is having an intuitive understanding of them enough or must it be rigorous? Should I be focusing on just being able to implement them for now?,t2_4jq5sigm,False,,0,False,Proving AI Algorithms Importance?,[],r/deeplearning,False,6,,0,,False,t3_nrr8gv,False,dark,0.43,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1622764628.0,,[],{},,True,,1622792196.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I (19 M) am an undergrad CS major. I aim to go to a top grad school for AI. How important is understanding the mathematical proofs behind AI algorithms such as backpropagation? Is having an intuitive understanding of them enough or must it be rigorous? Should I be focusing on just being able to implement them for now?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nrr8gv,True,,pottojam,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nrr8gv/proving_ai_algorithms_importance/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nrr8gv/proving_ai_algorithms_importance/,66147,1622763396.0,0,,False,,,,,,,
,deeplearning,"Guys, I am going through this boon called ""Hands-on Machine Learning with Scikit, Keras and Tensorflow"", I had already gone through the first part which was about ML and I have just started the second one, introduction to Neural Networks and I finally get to understand the mathematics behind and artificial neuron.

I'm enthusiastic about it, can't wait to have some more time to keep progressing on the book.

Just that, just sharing my happiness",t2_1fmeqg5h,False,,0,False,I just learnt what an AN is,[],r/deeplearning,False,6,,0,,False,t3_nreptn,False,dark,0.64,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1622759018.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Guys, I am going through this boon called &amp;quot;Hands-on Machine Learning with Scikit, Keras and Tensorflow&amp;quot;, I had already gone through the first part which was about ML and I have just started the second one, introduction to Neural Networks and I finally get to understand the mathematics behind and artificial neuron.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m enthusiastic about it, can&amp;#39;t wait to have some more time to keep progressing on the book.&lt;/p&gt;

&lt;p&gt;Just that, just sharing my happiness&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nreptn,True,,marmaduque_is_back,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nreptn/i_just_learnt_what_an_an_is/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nreptn/i_just_learnt_what_an_an_is/,66147,1622730218.0,0,,False,,,,,,,
,deeplearning,"Hi all,

I am a new student of neural networks and am looking for some pointers in terms of learning resources and technical direction for a new project that I am starting.

I am looking to build a solution to optimize route planning. I have a relational database of destinations, each with an address. Based on these addresses, or nodes, the goal is to create a solution (perhaps involving a neural network) that is able to create optimized routes based on the number of available trucks and their capacity.

My background consists of 7 years of software development experience. Save for reading about neural nets, I have not yet built anything as this is my first foray into the field. I am very excited to begin learning and building, but I have a lot of questions. I haven't yet found a community or forum where I can ask these questions, so any pointers would be greatly appreciated!

Thanks everyone.",t2_udsbc,False,,0,False,Looking For Direction For a New Route Automation Project,[],r/deeplearning,False,6,,0,,False,t3_nrgevb,False,dark,0.81,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,1622736078.0,,[],{},,True,,1622763522.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I am a new student of neural networks and am looking for some pointers in terms of learning resources and technical direction for a new project that I am starting.&lt;/p&gt;

&lt;p&gt;I am looking to build a solution to optimize route planning. I have a relational database of destinations, each with an address. Based on these addresses, or nodes, the goal is to create a solution (perhaps involving a neural network) that is able to create optimized routes based on the number of available trucks and their capacity.&lt;/p&gt;

&lt;p&gt;My background consists of 7 years of software development experience. Save for reading about neural nets, I have not yet built anything as this is my first foray into the field. I am very excited to begin learning and building, but I have a lot of questions. I haven&amp;#39;t yet found a community or forum where I can ask these questions, so any pointers would be greatly appreciated!&lt;/p&gt;

&lt;p&gt;Thanks everyone.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nrgevb,True,,tralfamadorian808,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nrgevb/looking_for_direction_for_a_new_route_automation/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nrgevb/looking_for_direction_for_a_new_route_automation/,66147,1622734722.0,0,,False,,,,,,,
,deeplearning,"A research team from Google proposes ByT5 architecture, a competitive token-free pretrained byte-to-byte transformer that can be straightforwardly adapted to process byte sequences without adding excessive computational cost. 

Here is a quick read: [Towards a Token-Free Future: Google Proposes Pretrained Byte-to-Byte Transformers for NLP.](https://syncedreview.com/2021/06/03/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-33/)

The paper *ByT5: Towards a Token-Free Future With Pre-Trained Byte-to-Byte Models* is on [arXiv](https://arxiv.org/abs/2105.13626).",t2_2fv4yodo,False,,0,False,[R] Towards a Token-Free Future: Google Proposes Pretrained Byte-to-Byte Transformers for NLP,[],r/deeplearning,False,6,,0,,False,t3_nrgmd2,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1622764071.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Google proposes ByT5 architecture, a competitive token-free pretrained byte-to-byte transformer that can be straightforwardly adapted to process byte sequences without adding excessive computational cost. &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/03/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-33/""&gt;Towards a Token-Free Future: Google Proposes Pretrained Byte-to-Byte Transformers for NLP.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;ByT5: Towards a Token-Free Future With Pre-Trained Byte-to-Byte Models&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.13626""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nrgmd2,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nrgmd2/r_towards_a_tokenfree_future_google_proposes/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nrgmd2/r_towards_a_tokenfree_future_google_proposes/,66147,1622735271.0,0,,False,,,,,,,
,deeplearning,"Hello everyone,

Where can I find the test set ground truth for ImageNet? or it is not available publicly?",t2_bgbkqzms,False,,0,False,ImageNet test set ground truth,[],r/deeplearning,False,6,,0,,False,t3_nriw0l,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622769969.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;Where can I find the test set ground truth for ImageNet? or it is not available publicly?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nriw0l,True,,mohamd95,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nriw0l/imagenet_test_set_ground_truth/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nriw0l/imagenet_test_set_ground_truth/,66147,1622741169.0,0,,False,,,,,,,
,deeplearning,"New publication from Interspeech 2021! We introduced STYLER which is non-autoregressive based style modeling TTS model.

paper: [https://arxiv.org/abs/2103.09474](https://arxiv.org/abs/2103.09474)

demo: [https://keonlee9420.github.io/STYLER-Demo/](https://keonlee9420.github.io/STYLER-Demo/)

code: [https://github.com/keonlee9420/STYLER](https://github.com/keonlee9420/STYLER)",t2_5z6vtwto,False,,0,False,STYLER: Style Factor Modeling with Rapidity and Robustness via Speech Decomposition for Expressive and Controllable Neural Text to Speech,[],r/deeplearning,False,6,,0,,False,t3_nr576n,False,dark,1.0,,public,10,0,{},,False,[],,False,False,,{},,False,10,,False,False,,False,,[],{},,True,,1622724652.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;New publication from Interspeech 2021! We introduced STYLER which is non-autoregressive based style modeling TTS model.&lt;/p&gt;

&lt;p&gt;paper: &lt;a href=""https://arxiv.org/abs/2103.09474""&gt;https://arxiv.org/abs/2103.09474&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;demo: &lt;a href=""https://keonlee9420.github.io/STYLER-Demo/""&gt;https://keonlee9420.github.io/STYLER-Demo/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;code: &lt;a href=""https://github.com/keonlee9420/STYLER""&gt;https://github.com/keonlee9420/STYLER&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nr576n,True,,keonlee9420,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nr576n/styler_style_factor_modeling_with_rapidity_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nr576n/styler_style_factor_modeling_with_rapidity_and/,66147,1622695852.0,0,,False,,,,,,,
,deeplearning,,t2_7mnq6l7d,False,,0,False,Did you know that with just one extra line of code you can get an almost 50% boost in the performance of your ONNX DL models? Learn more about the OpenVINO Execution Provider for ONNX Runtime and get your hands dirty by trying out some cool samples that we've created.,[],r/deeplearning,False,6,,0,,False,t3_nrfe3o,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1622760839.0,text,6,,,text,linkedin.com,False,,,,,https://www.linkedin.com/posts/maajid-khan-n-8891b68b_deeplearning-artificialintelligence-iamintel-activity-6806111957842837504-TVTj,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nrfe3o,True,,Jealous_Result_3283,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nrfe3o/did_you_know_that_with_just_one_extra_line_of/,all_ads,False,https://www.linkedin.com/posts/maajid-khan-n-8891b68b_deeplearning-artificialintelligence-iamintel-activity-6806111957842837504-TVTj,66147,1622732039.0,0,,False,,,,,,,
,deeplearning,"Hi, I have been browsing the web looking for an upgrade to my 2015 iMac. I came across Lambda Labs and their workstations and was quite convinced that their products are a bit overpriced but worth the money. However the further I looked into it the more problems arose.Firstly, why is there no NVlink for the dual rtx 3090 configuration? Secondly, the further I dove into the rabbit hole the more negative reviews appeared. Can someone explain to me if I should buy their 3090 config (I have never built a pc before)? And how come that they design a multi gpu  system without NVlink especially for machine learning? What’s even up with Lambda Labs it does seem like a scam of some sort as their prices are Sly high and their products barely work according to some. Also could someone give me a review of their product?

Sorry if I seem all over the place and kinda pissed, it’s just been a long day.",t2_ci6q3xwt,False,,0,False,Lambda Labs,[],r/deeplearning,False,6,,0,,False,t3_nreqj9,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622759071.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I have been browsing the web looking for an upgrade to my 2015 iMac. I came across Lambda Labs and their workstations and was quite convinced that their products are a bit overpriced but worth the money. However the further I looked into it the more problems arose.Firstly, why is there no NVlink for the dual rtx 3090 configuration? Secondly, the further I dove into the rabbit hole the more negative reviews appeared. Can someone explain to me if I should buy their 3090 config (I have never built a pc before)? And how come that they design a multi gpu  system without NVlink especially for machine learning? What’s even up with Lambda Labs it does seem like a scam of some sort as their prices are Sly high and their products barely work according to some. Also could someone give me a review of their product?&lt;/p&gt;

&lt;p&gt;Sorry if I seem all over the place and kinda pissed, it’s just been a long day.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nreqj9,True,,Solid_College8039,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nreqj9/lambda_labs/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nreqj9/lambda_labs/,66147,1622730271.0,0,,False,,,,,,,
,deeplearning,"I am training a binary classification CNN. The first class represents a background which often exhibits little variation in terms of content. The second class represents the presence of any object on this background. For this reason, the content diversity of the two classes is very different (i.e. the pixels are distributed in very different ways, with different variance). Can I exploit this characteristic in some way to improve the accuracy of my model? Is there any reference about this?",t2_sm74p,False,,0,False,Exploiting different pixel distribution and variance in binary classification,[],r/deeplearning,False,6,,0,,False,t3_nrc396,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622751495.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am training a binary classification CNN. The first class represents a background which often exhibits little variation in terms of content. The second class represents the presence of any object on this background. For this reason, the content diversity of the two classes is very different (i.e. the pixels are distributed in very different ways, with different variance). Can I exploit this characteristic in some way to improve the accuracy of my model? Is there any reference about this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nrc396,True,,fralbalbero,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nrc396/exploiting_different_pixel_distribution_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nrc396/exploiting_different_pixel_distribution_and/,66147,1622722695.0,0,,False,,,,,,,
,deeplearning,,t2_7mnq6l7d,False,,0,False,Did you know that with just one extra line of code you can get an almost 50% boost in the performance of your ONNX DL Models. Learn more about the OpenVINO Execution Provider for ONNX Runtime and get your hands dirty by trying out some cool samples that we've created.,[],r/deeplearning,False,6,,0,,False,t3_nrfbz6,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1622760684.0,text,6,,,text,intel.com,False,,,,,https://www.intel.com/content/www/us/en/artificial-intelligence/posts/faster-inferencing-with-one-line-of-code.html,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nrfbz6,True,,Jealous_Result_3283,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nrfbz6/did_you_know_that_with_just_one_extra_line_of/,all_ads,False,https://www.intel.com/content/www/us/en/artificial-intelligence/posts/faster-inferencing-with-one-line-of-code.html,66147,1622731884.0,0,,False,,,,,,,
,deeplearning,"I'm currently on the first course of the Specialization but I'm finding it hard to understand all the maths. I actually understand some. But most part of it is confusing. 

Do I really need to understand everything to be able to build deep learning models and get a job?

Please help.",t2_760eauxc,False,,0,False,Must I understand all the maths in Andrew Ng's Deep Learning Specialization,[],r/deeplearning,False,6,,0,,False,t3_nqvv5z,False,dark,0.74,,public,11,0,{},,False,[],,False,False,,{},,False,11,,False,False,,False,,[],{},,True,,1622695477.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m currently on the first course of the Specialization but I&amp;#39;m finding it hard to understand all the maths. I actually understand some. But most part of it is confusing. &lt;/p&gt;

&lt;p&gt;Do I really need to understand everything to be able to build deep learning models and get a job?&lt;/p&gt;

&lt;p&gt;Please help.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqvv5z,True,,thisisolaoluwa,,13,True,all_ads,False,[],False,,/r/deeplearning/comments/nqvv5z/must_i_understand_all_the_maths_in_andrew_ngs/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nqvv5z/must_i_understand_all_the_maths_in_andrew_ngs/,66147,1622666677.0,0,,False,,,,,,,
,deeplearning,,t2_58zcupf5,False,,0,False,Target Recovery for Robust Deep Learning-Based Person Following in Mobile Robots: Online Trajectory Prediction,[],r/deeplearning,False,6,,0,,False,t3_nqzk7p,False,dark,0.82,,public,7,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/sWuLUPdwqMw?start=286&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'The trajectory prediction while the robot follows the target person.', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/sWuLUPdwqMw?start=286&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Helper Lab', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/sWuLUPdwqMw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC_CXJbhz1noW_UR-zckzEqQ'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/sWuLUPdwqMw?start=286&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nqzk7p', 'height': 200}",,False,7,,False,False,,False,,[],{},,False,,1622705702.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=sWuLUPdwqMw&amp;t=286s,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqzk7p,True,,redhwanALgabri,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nqzk7p/target_recovery_for_robust_deep_learningbased/,all_ads,False,https://www.youtube.com/watch?v=sWuLUPdwqMw&amp;t=286s,66147,1622676902.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'The trajectory prediction while the robot follows the target person.', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/sWuLUPdwqMw?start=286&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Helper Lab', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/sWuLUPdwqMw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC_CXJbhz1noW_UR-zckzEqQ'}}",False,,,,,,,
,deeplearning,,t2_3jedp387,False,,0,False,Did Deepmind ever publish a paper on how they reduced the energy consumption of Google's data center?,[],r/deeplearning,False,6,,0,,False,t3_nqg5oz,False,dark,0.88,,public,29,0,{},,False,[],,False,False,,{},,False,29,,False,False,,False,,[],{},,True,,1622647940.0,text,6,,,text,self.deeplearning,False,,,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqg5oz,True,,kalzbra,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nqg5oz/did_deepmind_ever_publish_a_paper_on_how_they/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nqg5oz/did_deepmind_ever_publish_a_paper_on_how_they/,66147,1622619140.0,0,,False,,,,,,,
,deeplearning,,t2_4mny770,False,,0,False,Deep Learning A-Z™: Hands-On Artificial Neural Networks - Udemy 24,[],r/deeplearning,False,6,,0,,False,t3_nqnx7y,False,dark,0.82,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,False,,1622675328.0,text,6,,,text,udemy24.com,False,,,,,https://udemy24.com/deep-learning-a-z-hands-on-artificial-neural-networks/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqnx7y,True,,ezsou,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nqnx7y/deep_learning_az_handson_artificial_neural/,all_ads,False,https://udemy24.com/deep-learning-a-z-hands-on-artificial-neural-networks/,66147,1622646528.0,0,,False,,,,,,,
,deeplearning,"New AI Weekly Update - June 2nd, 2021 (#33!)

* Deep Learning with Code Data
* Reward is Enough
* AndroidEnv
* CogView
* Medically-aware GPT-3

https://youtu.be/6ic2PuWGhuA",t2_357rx0k0,False,,0,False,"AI Weekly Update - June 2nd, 2021",[],r/deeplearning,False,6,,0,,False,t3_nqqb39,False,dark,1.0,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1622681320.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;New AI Weekly Update - June 2nd, 2021 (#33!)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Deep Learning with Code Data&lt;/li&gt;
&lt;li&gt;Reward is Enough&lt;/li&gt;
&lt;li&gt;AndroidEnv&lt;/li&gt;
&lt;li&gt;CogView&lt;/li&gt;
&lt;li&gt;Medically-aware GPT-3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=""https://youtu.be/6ic2PuWGhuA""&gt;https://youtu.be/6ic2PuWGhuA&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqqb39,True,,HenryAILabs,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nqqb39/ai_weekly_update_june_2nd_2021/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nqqb39/ai_weekly_update_june_2nd_2021/,66147,1622652520.0,0,,False,,,,,,,
,deeplearning,"After getting a high score for some topics on [Workera.ai](https://Workera.ai) you eventually get a certificate for one of the tracks e.g.:(Data Scientist, Deep Learning Engineer, .. ).

My question is,

Is this certificate valuable for a fresh graduate enthusiastic about Machine Learning?",t2_4tx11540,False,,0,False,Workera.ai Certificate,[],r/deeplearning,False,6,,0,,False,t3_nqpwg4,False,dark,1.0,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1622680333.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;After getting a high score for some topics on &lt;a href=""https://Workera.ai""&gt;Workera.ai&lt;/a&gt; you eventually get a certificate for one of the tracks e.g.:(Data Scientist, Deep Learning Engineer, .. ).&lt;/p&gt;

&lt;p&gt;My question is,&lt;/p&gt;

&lt;p&gt;Is this certificate valuable for a fresh graduate enthusiastic about Machine Learning?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqpwg4,True,,PhyLake1337,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/nqpwg4/workeraai_certificate/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nqpwg4/workeraai_certificate/,66147,1622651533.0,0,,False,,,,,,,
,deeplearning,"A research team from Google Cloud AI, Google Research and Rutgers University simplifies vision transformers’ complex design, proposing nested transformers (NesT) that simply stack basic transformer layers to process non-overlapping image blocks individually. The approach achieves superior ImageNet classification accuracy and improves model training efficiency.

Here is a quick read: [Google &amp; Rutgers’ Aggregating Nested Transformers Yield Better Accuracy, Data Efficiency and Convergence.](https://syncedreview.com/2021/06/02/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-32/)

The paper *Aggregating Nested Transformers* is on [arXiv](https://arxiv.org/abs/2105.12723).",t2_2fv4yodo,False,,0,False,"[R] Google &amp; Rutgers’ Aggregating Nested Transformers Yield Better Accuracy, Data Efficiency and Convergence",[],r/deeplearning,False,6,,0,,False,t3_nqoak6,False,dark,0.8,,public,3,1,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{'gid_1': 1},,True,,1622676321.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Google Cloud AI, Google Research and Rutgers University simplifies vision transformers’ complex design, proposing nested transformers (NesT) that simply stack basic transformer layers to process non-overlapping image blocks individually. The approach achieves superior ImageNet classification accuracy and improves model training efficiency.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/02/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-32/""&gt;Google &amp;amp; Rutgers’ Aggregating Nested Transformers Yield Better Accuracy, Data Efficiency and Convergence.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Aggregating Nested Transformers&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.12723""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqoak6,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nqoak6/r_google_rutgers_aggregating_nested_transformers/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nqoak6/r_google_rutgers_aggregating_nested_transformers/,66147,1622647521.0,0,,False,,,,,,,
,deeplearning,"Hey , can i ask something my fyp dateline is near.....did u know how to classify snake species.I have 5 snake class dataset.....can i know what deep learning can be used and what software to apply in this project ......i really appreciate some explanation.....im newbie",t2_4epd5s3h,False,,0,False,Snake species identification,[],r/deeplearning,False,6,,0,,False,t3_nqmqq4,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622672019.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey , can i ask something my fyp dateline is near.....did u know how to classify snake species.I have 5 snake class dataset.....can i know what deep learning can be used and what software to apply in this project ......i really appreciate some explanation.....im newbie&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqmqq4,True,,fakhrul2898,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/nqmqq4/snake_species_identification/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nqmqq4/snake_species_identification/,66147,1622643219.0,0,,False,,,,,,,
,deeplearning,"Deep learning as we know it has largely been defined by advances in neural network architectures that took place in the last decade. Inspired by this work, this series takes a deeper look at field-defining deep learning architectures. In this first part we’ll look at AlexNet, VGG16, GoogleNet. We’ll cover the original papers published about each, including a look at the architecture, training, and comparative results on various tests. 

Article link:  [https://blog.paperspace.com/popular-deep-learning-architectures-alexnet-vgg-googlenet/](https://blog.paperspace.com/popular-deep-learning-architectures-alexnet-vgg-googlenet/)",t2_8glsx44k,False,,0,False,"[Article] Revisiting Classic Deep Network Architectures: AlexNet, VGG16, and GoogleNet",[],r/deeplearning,False,6,,0,,False,t3_nqlc35,False,dark,0.44,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622667896.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Deep learning as we know it has largely been defined by advances in neural network architectures that took place in the last decade. Inspired by this work, this series takes a deeper look at field-defining deep learning architectures. In this first part we’ll look at AlexNet, VGG16, GoogleNet. We’ll cover the original papers published about each, including a look at the architecture, training, and comparative results on various tests. &lt;/p&gt;

&lt;p&gt;Article link:  &lt;a href=""https://blog.paperspace.com/popular-deep-learning-architectures-alexnet-vgg-googlenet/""&gt;https://blog.paperspace.com/popular-deep-learning-architectures-alexnet-vgg-googlenet/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqlc35,True,,supportivedispatcher,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nqlc35/article_revisiting_classic_deep_network/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nqlc35/article_revisiting_classic_deep_network/,66147,1622639096.0,0,,False,,,,,,,
,deeplearning,"You can use it with Tampermonkey or Greasemonkey; 

[https://github.com/casab/andrew-ng-deesser](https://github.com/casab/andrew-ng-deesser)",t2_jkdi8,False,,0,False,I wrote a small script to remove that annoying sound in Andrew NG Courses,[],r/deeplearning,False,6,,0,,False,t3_npsknw,False,dark,0.97,,public,81,2,{},,False,[],,False,False,,{},,False,81,,False,False,,False,,[],{'gid_1': 1},,True,,1622578405.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;You can use it with Tampermonkey or Greasemonkey; &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/casab/andrew-ng-deesser""&gt;https://github.com/casab/andrew-ng-deesser&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,npsknw,True,,homunduruk,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/npsknw/i_wrote_a_small_script_to_remove_that_annoying/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/npsknw/i_wrote_a_small_script_to_remove_that_annoying/,66147,1622549605.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,How to Start Machine Learning in 2021 + How to Stay up to Date with AI research / data science news,[],r/deeplearning,False,6,,0,,False,t3_nqiugl,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/RirEw-uaS_8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How to Start Machine Learning in 2021 + How to Stay up to Date with AI research / data science news', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/RirEw-uaS_8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/RirEw-uaS_8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/RirEw-uaS_8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nqiugl', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1622659143.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/RirEw-uaS_8,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqiugl,True,,OnlyProggingForFun,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nqiugl/how_to_start_machine_learning_in_2021_how_to_stay/,all_ads,False,https://youtu.be/RirEw-uaS_8,66147,1622630343.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How to Start Machine Learning in 2021 + How to Stay up to Date with AI research / data science news', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/RirEw-uaS_8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/RirEw-uaS_8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,,,,,,,
,deeplearning,"Hi all,

I'm currently playing with [DiffSinger](https://arxiv.org/abs/2105.02446), which is a TTS system extended by diffusion models. For the naive version, It consists of encoders (for embedding text and pitch information) and a denoiser where the encoders' output is used to condition the denoiser. Everything is similar to [DiffWave](https://arxiv.org/pdf/2009.09761.pdf) including denoiser's structure and prediction but the neural net to predict epsilon would be changed to \`epsilon(noisy\_spectrogram, encoder\_outputs, diffusion\_step)\` compared to DiffWave's \`epsilon(noisy\_audio, upsampled\_spectrogram, diffusion\_step)\`.

While I'm successfully training encoders, I got an issue during training denoiser. I used LJSpeech. Here is what I did:

1. First of all, as a preliminary experiment, I try to check all modules to work well by setting denoiser as \`epsilon(noisy\_spectrogram, clean\_spectrogram, diffusion\_step)\` to predict the \`noisy\_spectrogram\`.
2. After the model converges, I went back to the denoiser of \`epsilon(noisy\_spectrogram, encoder\_outputs, diffusion\_step)\` to predict clean\_spectrogram. I detached the encoders\_output from the auto\_grad when the input (to prevent from updating) to the denoiser to fix the conditioner for model convergence. The model was broken when I didn't detach (allow the encoder to be updated during denoiser training).
3. I found that when the range of the conditioner (encoder\_outputs) values is smaller, then the model shows better evidence of successful training.

Bellows are the results I've got so far. The upper one is the sampled (synthesized) mel-spectrogram, and the lower one is the ground truth (on each image).

1. I can see the model converge during the primary experiment:

&amp;#x200B;

https://preview.redd.it/ynaubl438s271.png?width=1970&amp;format=png&amp;auto=webp&amp;s=baacb5d288be7a175b71a1bdeddd92f7807f9fb0

2. When the encoder's output directly input to the denoiser (value range: -9.xxx to 6.xxx):

&amp;#x200B;

https://preview.redd.it/tfyrgbr38s271.png?width=1138&amp;format=png&amp;auto=webp&amp;s=76064263afa64882d88f4d24397f4d772b1e53a9

3. When the encoder's output is multiplied by 0.01 to shrink the range:

&amp;#x200B;

https://preview.redd.it/blacrka48s271.png?width=1368&amp;format=png&amp;auto=webp&amp;s=3ca653d1cbefea008f83f7d551b094f51f8db32f

For case 2., It shows any clues on training. On contrary, the case 3. shows 'some' levels of training but it is not what we expected. I double-checked the inference part (reverse part), but it is exactly the same as that of 1. and diffwave.

So I just want to know if you have any idea on the successful conditions of the input conditioner of the denoiser. Why does the model show such an unsatisfying result above? Do I miss something to process the conditioner?

I will appreciate all suggestions or sharing of your experience.

Thanks in advance.",t2_5z6vtwto,False,,0,False,Training tips on diffusion models (DiffSinger) for a TTS?,[],r/deeplearning,False,6,,0,,False,t3_nqdksh,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,1622610324.0,,[],{},,True,,1622637828.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m currently playing with &lt;a href=""https://arxiv.org/abs/2105.02446""&gt;DiffSinger&lt;/a&gt;, which is a TTS system extended by diffusion models. For the naive version, It consists of encoders (for embedding text and pitch information) and a denoiser where the encoders&amp;#39; output is used to condition the denoiser. Everything is similar to &lt;a href=""https://arxiv.org/pdf/2009.09761.pdf""&gt;DiffWave&lt;/a&gt; including denoiser&amp;#39;s structure and prediction but the neural net to predict epsilon would be changed to `epsilon(noisy_spectrogram, encoder_outputs, diffusion_step)` compared to DiffWave&amp;#39;s `epsilon(noisy_audio, upsampled_spectrogram, diffusion_step)`.&lt;/p&gt;

&lt;p&gt;While I&amp;#39;m successfully training encoders, I got an issue during training denoiser. I used LJSpeech. Here is what I did:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;First of all, as a preliminary experiment, I try to check all modules to work well by setting denoiser as `epsilon(noisy_spectrogram, clean_spectrogram, diffusion_step)` to predict the `noisy_spectrogram`.&lt;/li&gt;
&lt;li&gt;After the model converges, I went back to the denoiser of `epsilon(noisy_spectrogram, encoder_outputs, diffusion_step)` to predict clean_spectrogram. I detached the encoders_output from the auto_grad when the input (to prevent from updating) to the denoiser to fix the conditioner for model convergence. The model was broken when I didn&amp;#39;t detach (allow the encoder to be updated during denoiser training).&lt;/li&gt;
&lt;li&gt;I found that when the range of the conditioner (encoder_outputs) values is smaller, then the model shows better evidence of successful training.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Bellows are the results I&amp;#39;ve got so far. The upper one is the sampled (synthesized) mel-spectrogram, and the lower one is the ground truth (on each image).&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;I can see the model converge during the primary experiment:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ynaubl438s271.png?width=1970&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=baacb5d288be7a175b71a1bdeddd92f7807f9fb0""&gt;https://preview.redd.it/ynaubl438s271.png?width=1970&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=baacb5d288be7a175b71a1bdeddd92f7807f9fb0&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;When the encoder&amp;#39;s output directly input to the denoiser (value range: -9.xxx to 6.xxx):&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/tfyrgbr38s271.png?width=1138&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=76064263afa64882d88f4d24397f4d772b1e53a9""&gt;https://preview.redd.it/tfyrgbr38s271.png?width=1138&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=76064263afa64882d88f4d24397f4d772b1e53a9&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;When the encoder&amp;#39;s output is multiplied by 0.01 to shrink the range:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/blacrka48s271.png?width=1368&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3ca653d1cbefea008f83f7d551b094f51f8db32f""&gt;https://preview.redd.it/blacrka48s271.png?width=1368&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3ca653d1cbefea008f83f7d551b094f51f8db32f&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For case 2., It shows any clues on training. On contrary, the case 3. shows &amp;#39;some&amp;#39; levels of training but it is not what we expected. I double-checked the inference part (reverse part), but it is exactly the same as that of 1. and diffwave.&lt;/p&gt;

&lt;p&gt;So I just want to know if you have any idea on the successful conditions of the input conditioner of the denoiser. Why does the model show such an unsatisfying result above? Do I miss something to process the conditioner?&lt;/p&gt;

&lt;p&gt;I will appreciate all suggestions or sharing of your experience.&lt;/p&gt;

&lt;p&gt;Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqdksh,True,,keonlee9420,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nqdksh/training_tips_on_diffusion_models_diffsinger_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nqdksh/training_tips_on_diffusion_models_diffsinger_for/,66147,1622609028.0,0,,False,,,"{'blacrka48s271': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 65, 'x': 108, 'u': 'https://preview.redd.it/blacrka48s271.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2465e49650dd37e143d7915dc2d3bd98270004b0'}, {'y': 130, 'x': 216, 'u': 'https://preview.redd.it/blacrka48s271.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3ca4075d82eb2dc240740bfb8abb2af3d396bf13'}, {'y': 193, 'x': 320, 'u': 'https://preview.redd.it/blacrka48s271.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=330b666f709971cc122f3bb3d101f513a4d5feb0'}, {'y': 387, 'x': 640, 'u': 'https://preview.redd.it/blacrka48s271.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe492f4ca2cbb59c1bcfe2567cbb07885a37a9bb'}, {'y': 581, 'x': 960, 'u': 'https://preview.redd.it/blacrka48s271.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=51b5ae4a09d2d4d5f3da0d572b1703178669045c'}, {'y': 653, 'x': 1080, 'u': 'https://preview.redd.it/blacrka48s271.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dc621da6b67656fddca3c35a755917b17832e30d'}], 's': {'y': 828, 'x': 1368, 'u': 'https://preview.redd.it/blacrka48s271.png?width=1368&amp;format=png&amp;auto=webp&amp;s=3ca653d1cbefea008f83f7d551b094f51f8db32f'}, 'id': 'blacrka48s271'}, 'ynaubl438s271': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 55, 'x': 108, 'u': 'https://preview.redd.it/ynaubl438s271.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=940f80f75b280a67d35b112927d42e2a07f58d1c'}, {'y': 110, 'x': 216, 'u': 'https://preview.redd.it/ynaubl438s271.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b9e8aff75bd61a46fa62df3320d27b667897062d'}, {'y': 163, 'x': 320, 'u': 'https://preview.redd.it/ynaubl438s271.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=96c395487dd083e8c1eb3e5a1f9d2c2221eecb2e'}, {'y': 326, 'x': 640, 'u': 'https://preview.redd.it/ynaubl438s271.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=dcaf60394dff4beff5ca5c2513cfdb227af8c812'}, {'y': 489, 'x': 960, 'u': 'https://preview.redd.it/ynaubl438s271.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=eb5fedc137ece37b2a31a63e0b7c05538beb600b'}, {'y': 550, 'x': 1080, 'u': 'https://preview.redd.it/ynaubl438s271.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=38fb3383a9e1a24c801eca647db2941eacdec698'}], 's': {'y': 1004, 'x': 1970, 'u': 'https://preview.redd.it/ynaubl438s271.png?width=1970&amp;format=png&amp;auto=webp&amp;s=baacb5d288be7a175b71a1bdeddd92f7807f9fb0'}, 'id': 'ynaubl438s271'}, 'tfyrgbr38s271': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 56, 'x': 108, 'u': 'https://preview.redd.it/tfyrgbr38s271.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3214120b8f264610da617f3e214279bc08bafd3a'}, {'y': 113, 'x': 216, 'u': 'https://preview.redd.it/tfyrgbr38s271.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3574593757a648dddc8a427519a9f2b2f671574e'}, {'y': 168, 'x': 320, 'u': 'https://preview.redd.it/tfyrgbr38s271.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d80e48ce811afc030d997e6de1d1a5ee76bb987b'}, {'y': 336, 'x': 640, 'u': 'https://preview.redd.it/tfyrgbr38s271.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f1055c72b52f511fbc71ff548611ad454ffade96'}, {'y': 504, 'x': 960, 'u': 'https://preview.redd.it/tfyrgbr38s271.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2aa076b99d1730b0477a3abc13b02a1245fa345c'}, {'y': 567, 'x': 1080, 'u': 'https://preview.redd.it/tfyrgbr38s271.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=272a74781f460745057fd89bba2fb3884f71b136'}], 's': {'y': 598, 'x': 1138, 'u': 'https://preview.redd.it/tfyrgbr38s271.png?width=1138&amp;format=png&amp;auto=webp&amp;s=76064263afa64882d88f4d24397f4d772b1e53a9'}, 'id': 'tfyrgbr38s271'}}",,,,
,deeplearning,,t2_aeilmmsn,False,,0,False,What should I do ?,[],r/deeplearning,False,6,,0,,False,t3_nqflw5,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1622645668.0,text,6,,,text,self.learnmachinelearning,False,,,,,/r/learnmachinelearning/comments/maev6l/what_should_i_do/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqflw5,True,,Jooojooo1020,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nqflw5/what_should_i_do/,all_ads,False,/r/learnmachinelearning/comments/maev6l/what_should_i_do/,66147,1622616868.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': ""I want to be able to predict when the user will come back\n\nI have a history of 15K event happened let's say :\n\nThe number of users are very limited ( Max 10) \nAnd minutes are not important \n\nUser-Type Date-Time\n\nAdmin 2020/1/5 14:02:03\n\nAdmin 2020/1/5 21:51:30\n\nAdmin 2020/1/6 0:36:24\n\nAdmin 2020/1/6 19:14:53\n\nUser\\_Type1 2020/1/7 19:13:07\n\nUser\\_Type2 2020/1/8 18:14:40\n\nUser\\_Type3 2020/1/11 12:56:49\n\nAdmin 2020/1/12 9:11:45\n\nUser\\_Type1 2020/1/13 7:52:04\n\nAdmin 2020/1/14 5:54:39\n\nUser\\_Type1 2020/1/14 20:42:58\n\nI want to be able to Predict:\n\n1: When most-likely UserX will submit tomorrow? (given month/day of the month/day of the week/ hr:)  \n\\* Will User1 submit tomorrow morning: 3/16 11:00 am  \n?   ( in hour based , I don’t care about minutes)\n2: When most likely no one will submit? (I could fix issues ( in hour based , I don’t care about minutes)\n\nDo I need to fill in all the missing data (did not submit anything, which will make the data set very huge)?\n\nAny guidance is greatly appreciated."", 'author_fullname': 't2_aeilmmsn', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What should I do ?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_maev6l', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': 1616435684.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1616416073.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnmachinelearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to be able to predict when the user will come back&lt;/p&gt;\n\n&lt;p&gt;I have a history of 15K event happened let&amp;#39;s say :&lt;/p&gt;\n\n&lt;p&gt;The number of users are very limited ( Max 10) \nAnd minutes are not important &lt;/p&gt;\n\n&lt;p&gt;User-Type Date-Time&lt;/p&gt;\n\n&lt;p&gt;Admin 2020/1/5 14:02:03&lt;/p&gt;\n\n&lt;p&gt;Admin 2020/1/5 21:51:30&lt;/p&gt;\n\n&lt;p&gt;Admin 2020/1/6 0:36:24&lt;/p&gt;\n\n&lt;p&gt;Admin 2020/1/6 19:14:53&lt;/p&gt;\n\n&lt;p&gt;User_Type1 2020/1/7 19:13:07&lt;/p&gt;\n\n&lt;p&gt;User_Type2 2020/1/8 18:14:40&lt;/p&gt;\n\n&lt;p&gt;User_Type3 2020/1/11 12:56:49&lt;/p&gt;\n\n&lt;p&gt;Admin 2020/1/12 9:11:45&lt;/p&gt;\n\n&lt;p&gt;User_Type1 2020/1/13 7:52:04&lt;/p&gt;\n\n&lt;p&gt;Admin 2020/1/14 5:54:39&lt;/p&gt;\n\n&lt;p&gt;User_Type1 2020/1/14 20:42:58&lt;/p&gt;\n\n&lt;p&gt;I want to be able to Predict:&lt;/p&gt;\n\n&lt;p&gt;1: When most-likely UserX will submit tomorrow? (given month/day of the month/day of the week/ hr:)&lt;br/&gt;\n* Will User1 submit tomorrow morning: 3/16 11:00 am&lt;br/&gt;\n?   ( in hour based , I don’t care about minutes)\n2: When most likely no one will submit? (I could fix issues ( in hour based , I don’t care about minutes)&lt;/p&gt;\n\n&lt;p&gt;Do I need to fill in all the missing data (did not submit anything, which will make the data set very huge)?&lt;/p&gt;\n\n&lt;p&gt;Any guidance is greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'maev6l', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Jooojooo1020', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/maev6l/what_should_i_do/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnmachinelearning/comments/maev6l/what_should_i_do/', 'subreddit_subscribers': 232336, 'created_utc': 1616387273.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_maev6l,,,,,
,deeplearning,,t2_c5febi8b,False,,0,False,[Project] Pytorch TypeError: forward() takes 2 positional arguments but 4 were given,[],r/deeplearning,False,6,,0,,False,t3_nqfhot,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1622645209.0,text,6,,,text,self.learnprogramming,False,,,,,/r/learnprogramming/comments/nqfg25/pytorch_typeerror_forward_takes_2_positional/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqfhot,True,,popkept09,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nqfhot/project_pytorch_typeerror_forward_takes_2/,all_ads,False,/r/learnprogramming/comments/nqfg25/pytorch_typeerror_forward_takes_2_positional/,66147,1622616409.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'learnprogramming', 'selftext': ""    from torch.nn.parameter import Parameter\n    from torch.nn.modules.module import Module\n    class Graphconvlayer(nn.Module):\n      def __init__(self,adj,input_feature_neurons,output_neurons):\n        super(Graphconvlayer, self).__init__()\n        self.adj=adj\n        self.input_feature_neurons=input_feature_neurons\n        self.output_neurons=output_neurons\n        self.weights=Parameter(torch.normal(mean=0.0,std=torch.ones(input_feature_neurons,output_neurons)))\n        self.bias=Parameter(torch.normal(mean=0.0,std=torch.ones(input_feature_neurons)))\n      \n      def forward(self,inputfeaturedata):\n        output1= torch.mm(self.adj,inputfeaturedata)\n        print(output1.shape)\n        print(self.weights.shape)\n        print(self.bias.shape)\n        output2= torch.matmul(output1,self.weights.t())+ self.bias\n        return output2 \n    \n    class GCN(nn.Module):\n       def __init__(self,lr,dropoutvalue,adjmatrix,inputneurons,hidden,outputneurons):\n         super(GCN, self).__init__()\n         self.lr=lr\n         self.dropoutvalue=dropoutvalue\n         self.adjmatrix=adjmatrix\n         self.inputneurons=inputneurons\n         self.hidden=hidden\n         self.outputneurons=outputneurons\n         self.gcn1 = Graphconvlayer(adjmatrix,inputneurons,hidden)\n         self.gcn2 = Graphconvlayer(adjmatrix,hidden,outputneurons)\n      \n       def forward(self,x,adj):\n         x= F.relu(self.gcn1(adj,x,64))\n         x= F.dropout(x,self.dropoutvalue)\n         x= self.gcn2(adj,x,7)\n         return F.log_softmax(x,dim=1)\n    \n    a=GCN(lr=0.001,dropoutvalue=0.5,adjmatrix=adj,inputneurons=features.shape[1],hidden=64,outputneurons=7)\n    a.forward(adj,features)\n    \n    \n\n&amp;#x200B;\n\n    TypeError                                 Traceback (most recent call last)\n    &lt;ipython-input-85-7d1a2a73ecad&gt; in &lt;module&gt;()\n         37 \n         38 a=GCN(lr=0.001,dropoutvalue=0.5,adjmatrix=adj,inputneurons=features.shape[1],hidden=64,outputneurons=7)\n    ---&gt; 39 a.forward(adj,features)\n    \n    1 frames\n    /usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n        887             result = self.forward(*input, **kwargs)\n        888         for hook in itertools.chain(\n    --&gt; 889                 _global_forward_hooks.values(),\n        890                 self._forward_hooks.values()):\n        891             hook_result = hook(self, input, result)\n    \n    TypeError: forward() takes 2 positional arguments but 4 were given\n\n&amp;#x200B;\n\n    print(a)\n    &gt;&gt;&gt;\n    GCN(\n      (gcn1): Graphconvlayer()\n      (gcn2): Graphconvlayer()\n    )\n\nThis is a graph neural network. What I am trying to get is the output from the forward layer. I am not sure why I am getting the above error and what I should change for the code to work.\n\nCan anyone guide me through this?\n\n&amp;#x200B;\n\nAlso I am if I pass class graphconvlayer to class GCN, do I have to now separately pass each of it's parameters also to the object ä of class GCN? \n\nIf I change method forward to say forwardtwo in both the classes  would that have an effect? I am asking to know if forward is an inbuilt method of pytorch. I did check the documentation and they do have forward class."", 'author_fullname': 't2_c5febi8b', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Pytorch TypeError: forward() takes 2 positional arguments but 4 were given', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/learnprogramming', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nqfg25', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1622645025.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnprogramming', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;pre&gt;&lt;code&gt;from torch.nn.parameter import Parameter\nfrom torch.nn.modules.module import Module\nclass Graphconvlayer(nn.Module):\n  def __init__(self,adj,input_feature_neurons,output_neurons):\n    super(Graphconvlayer, self).__init__()\n    self.adj=adj\n    self.input_feature_neurons=input_feature_neurons\n    self.output_neurons=output_neurons\n    self.weights=Parameter(torch.normal(mean=0.0,std=torch.ones(input_feature_neurons,output_neurons)))\n    self.bias=Parameter(torch.normal(mean=0.0,std=torch.ones(input_feature_neurons)))\n\n  def forward(self,inputfeaturedata):\n    output1= torch.mm(self.adj,inputfeaturedata)\n    print(output1.shape)\n    print(self.weights.shape)\n    print(self.bias.shape)\n    output2= torch.matmul(output1,self.weights.t())+ self.bias\n    return output2 \n\nclass GCN(nn.Module):\n   def __init__(self,lr,dropoutvalue,adjmatrix,inputneurons,hidden,outputneurons):\n     super(GCN, self).__init__()\n     self.lr=lr\n     self.dropoutvalue=dropoutvalue\n     self.adjmatrix=adjmatrix\n     self.inputneurons=inputneurons\n     self.hidden=hidden\n     self.outputneurons=outputneurons\n     self.gcn1 = Graphconvlayer(adjmatrix,inputneurons,hidden)\n     self.gcn2 = Graphconvlayer(adjmatrix,hidden,outputneurons)\n\n   def forward(self,x,adj):\n     x= F.relu(self.gcn1(adj,x,64))\n     x= F.dropout(x,self.dropoutvalue)\n     x= self.gcn2(adj,x,7)\n     return F.log_softmax(x,dim=1)\n\na=GCN(lr=0.001,dropoutvalue=0.5,adjmatrix=adj,inputneurons=features.shape[1],hidden=64,outputneurons=7)\na.forward(adj,features)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;TypeError                                 Traceback (most recent call last)\n&amp;lt;ipython-input-85-7d1a2a73ecad&amp;gt; in &amp;lt;module&amp;gt;()\n     37 \n     38 a=GCN(lr=0.001,dropoutvalue=0.5,adjmatrix=adj,inputneurons=features.shape[1],hidden=64,outputneurons=7)\n---&amp;gt; 39 a.forward(adj,features)\n\n1 frames\n/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n    887             result = self.forward(*input, **kwargs)\n    888         for hook in itertools.chain(\n--&amp;gt; 889                 _global_forward_hooks.values(),\n    890                 self._forward_hooks.values()):\n    891             hook_result = hook(self, input, result)\n\nTypeError: forward() takes 2 positional arguments but 4 were given\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;print(a)\n&amp;gt;&amp;gt;&amp;gt;\nGCN(\n  (gcn1): Graphconvlayer()\n  (gcn2): Graphconvlayer()\n)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This is a graph neural network. What I am trying to get is the output from the forward layer. I am not sure why I am getting the above error and what I should change for the code to work.&lt;/p&gt;\n\n&lt;p&gt;Can anyone guide me through this?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Also I am if I pass class graphconvlayer to class GCN, do I have to now separately pass each of it&amp;#39;s parameters also to the object ä of class GCN? &lt;/p&gt;\n\n&lt;p&gt;If I change method forward to say forwardtwo in both the classes  would that have an effect? I am asking to know if forward is an inbuilt method of pytorch. I did check the documentation and they do have forward class.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r7yd', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nqfg25', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'popkept09', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnprogramming/comments/nqfg25/pytorch_typeerror_forward_takes_2_positional/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnprogramming/comments/nqfg25/pytorch_typeerror_forward_takes_2_positional/', 'subreddit_subscribers': 2283891, 'created_utc': 1622616225.0, 'num_crossposts': 4, 'media': None, 'is_video': False}]",t3_nqfg25,,,,,
,deeplearning,"I am preparing for one test for the course that scratched a deep learning a bit in the end (mainly CNN)

In one of the examples for preparation I have, they ask :

Given that a convolutional neural network has five convolution layers (all the convolution layers are  composed of  3×3  convolution filters  with  stride  1  and  no pooling layers),  calculate  how many  pixel  in  the  input  image  are  supporting  a  neuron  in  the fifth layer?

&amp;#x200B;

I am very confused about this, and  have found guide for arithmetic [https://arxiv.org/pdf/1603.07285.pdf](https://arxiv.org/pdf/1603.07285.pdf)

but even assuming 0 padding I feel I am missing the input size of the image. However, they ask, so there should be a way to calculate it. Can someone point me in the right direction on how to calculate it actually?",t2_3y7tjzde,False,,0,False,How to calculate how many pixels from the input image support neuron in the last layer? CNN,[],r/deeplearning,False,6,,0,,False,t3_nq6l0m,False,dark,0.67,,public,3,1,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1622615694.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am preparing for one test for the course that scratched a deep learning a bit in the end (mainly CNN)&lt;/p&gt;

&lt;p&gt;In one of the examples for preparation I have, they ask :&lt;/p&gt;

&lt;p&gt;Given that a convolutional neural network has five convolution layers (all the convolution layers are  composed of  3×3  convolution filters  with  stride  1  and  no pooling layers),  calculate  how many  pixel  in  the  input  image  are  supporting  a  neuron  in  the fifth layer?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am very confused about this, and  have found guide for arithmetic &lt;a href=""https://arxiv.org/pdf/1603.07285.pdf""&gt;https://arxiv.org/pdf/1603.07285.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;but even assuming 0 padding I feel I am missing the input size of the image. However, they ask, so there should be a way to calculate it. Can someone point me in the right direction on how to calculate it actually?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,"[{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nq6l0m,True,,vitotittotitto,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nq6l0m/how_to_calculate_how_many_pixels_from_the_input/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nq6l0m/how_to_calculate_how_many_pixels_from_the_input/,66147,1622586894.0,0,,False,,,,,,,
,deeplearning,"I have a question about train image clasification model using dataset with two different datapoints. 

1. make a severals video of the object and converts to images sequences for trainset.
2. make a photographs of different images of the object for trainset.

What do you think?. What option is better for generalization?.  If you have a research's papers, blogs, video, etc...  pleases let me know and shared with me. I would really appreciate it

 psd: I'm not native speaker sorry for my bad english. correct me if you want.",t2_16seow,False,,0,False,Images sequences to train neural network works well for Gereneralization?,[],r/deeplearning,False,6,,0,,False,t3_nqeelf,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622640836.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a question about train image clasification model using dataset with two different datapoints. &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;make a severals video of the object and converts to images sequences for trainset.&lt;/li&gt;
&lt;li&gt;make a photographs of different images of the object for trainset.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;What do you think?. What option is better for generalization?.  If you have a research&amp;#39;s papers, blogs, video, etc...  pleases let me know and shared with me. I would really appreciate it&lt;/p&gt;

&lt;p&gt;psd: I&amp;#39;m not native speaker sorry for my bad english. correct me if you want.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nqeelf,True,,chrisArt10,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nqeelf/images_sequences_to_train_neural_network_works/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nqeelf/images_sequences_to_train_neural_network_works/,66147,1622612036.0,0,,False,,,,,,,
,deeplearning,"I’m really confused. I start learning in March. I first did the Machine Learning course by Andrew Ng and then I started with his Deep Learning specialization on Coursera. 

The material makes sense to me but I don’t know how I could get better at practical application. I also don’t know what domains exist inside of deep learning very well and have struggled to find any resource related to it as well. I’ve always wanted to do something related to game development so are their any domains in Deep Learning related to that?

I would appreciate any and all guidance.

Also if the post doesn’t fit the subreddit rules, let me know so that I can delete it ASAP.",t2_1tot17ny,False,,0,False,How to learn Deep Learning effectively?,[],r/deeplearning,False,6,,0,,False,t3_nq63tt,False,dark,0.64,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1622614335.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m really confused. I start learning in March. I first did the Machine Learning course by Andrew Ng and then I started with his Deep Learning specialization on Coursera. &lt;/p&gt;

&lt;p&gt;The material makes sense to me but I don’t know how I could get better at practical application. I also don’t know what domains exist inside of deep learning very well and have struggled to find any resource related to it as well. I’ve always wanted to do something related to game development so are their any domains in Deep Learning related to that?&lt;/p&gt;

&lt;p&gt;I would appreciate any and all guidance.&lt;/p&gt;

&lt;p&gt;Also if the post doesn’t fit the subreddit rules, let me know so that I can delete it ASAP.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nq63tt,True,,fireless-phoenix,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/nq63tt/how_to_learn_deep_learning_effectively/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nq63tt/how_to_learn_deep_learning_effectively/,66147,1622585535.0,0,,False,,,,,,,
,deeplearning,"If I want to extract features from some videos, what kind of models can I use? Do you have any good advice?",t2_c6gpgieh,False,,0,False,Video Feature Representation,[],r/deeplearning,False,6,,0,,False,t3_nq9wid,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622625704.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If I want to extract features from some videos, what kind of models can I use? Do you have any good advice?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nq9wid,True,,guuzaa,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nq9wid/video_feature_representation/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nq9wid/video_feature_representation/,66147,1622596904.0,0,,False,,,,,,,
,deeplearning,"I have used ResNet50 transfer learning to train a model for image classification of 5 categories. It has 95%+ test accuracy. I save the model as .h5, .hdf5, .json, etc.  Then I attempt to deploy the model to a Flask Web App using various load\_model methods, but when I do so, the model accuracy is not the same.  I have tried many, many things and the best attempt I have been able to find works well for 4/5 categories, but then the 5th category performs terribly... like it doesn't seem trained at all only on that one category. The images are balanced for each class and are color images. I have been told that it may be the preprocessing pipeline and that I should make sure that the image that flask is giving the model when uploaded to the website is the same as the exact format that the model has been trained on. I have noticed that the image array values include negative values when fed to the model during training/testing from keras ImageDataGenerator, but are all positive values when fed to the model in the flask web app. So I might be on to something here, but just can't quite figure out what exactly is happening and how to fix it.

The preprocessed images from the ResNet model seem to output negative values from imagedatagenerator, whereas the array values of the images in the Flask app are always positive. So maybe some solution lies here where I can make sure both :

ResNet model preprocessed image (print(image)) with negative values:

`Category: [0. 0. 1. 0. 0.] [[[-0.05466276 0.3498863 0.09145098]   [-0.05074119 0.3498863 0.09145098]   [-0.04681962 0.3498863 0.09145098]   ...   [-0.3644667  -0.27756473 -0.363451  ]   [-0.36054513 -0.29717258 -0.37129414]   [-0.37230983 -0.30893728 -0.37913728]]   [[-0.04681962 0.3498863 0.12282354]   [-0.05466276 0.34596473 0.11105883]   [-0.05858433 0.34596473 0.09929413]   ...   [-0.3644667  -0.2814863  -0.363451  ]   [-0.3644667  -0.30109414 -0.3752157 ]   [-0.37230983 -0.30893728 -0.37913728]]   [[ 0.01200391 0.22047453 0.1149804 ]   [-0.00368236 0.2636118 0.1267451 ]   [-0.01936864 0.3106706 0.14635295]   ...   [-0.3644667  -0.2814863  -0.36737257]   [-0.3644667  -0.3050157  -0.3752157 ]   [-0.36838827 -0.30893728 -0.37913728]]   ...   [[ 0.00808234 0.07929805 -0.14384314]   [ 0.00416077 0.07537648 -0.14384314]   [ 0.00416077 0.07537648 -0.14384314]   ...   [-0.39583924 -0.4187412  -0.4497255 ]   [-0.39583924 -0.41481963 -0.4497255 ]   [-0.3997608  -0.42266276 -0.45364708]]   [[ 0.01200391 0.09498432 -0.13992158]   [ 0.01200391 0.09498432 -0.136     ]   [ 0.01200391 0.09498432 -0.136     ]   ...   [-0.40368238 -0.42266276 -0.4497255 ]   [-0.40760395 -0.42266276 -0.45756865]   [-0.40760395 -0.42266276 -0.45756865]]   [[-0.00368236 0.1106706  -0.10462746]   [ 0.00416077 0.1106706  -0.1124706 ]   [ 0.00808234 0.10282746 -0.12815687]   ...   [-0.40760395 -0.41089806 -0.4497255 ]   [-0.40760395 -0.42266276 -0.4497255 ]   [-0.40368238 -0.42266276 -0.45364708]]]`

Flask web app image array with all positive values (note this is not the exact same image as above, but demonstrates the point):

`[[[[0.15686275 0.17254902 0.05098039]    [0.15294118 0.17254902 0.05098039]    [0.15686275 0.16862746 0.04705882]    ...    [0.20392157 0.18039216 0.13333334]    [0.10980392 0.07450981 0.05098039]    [0.09411765 0.05490196 0.03137255]]    [[0.16078432 0.1764706 0.05098039]    [0.16078432 0.1764706 0.05098039]    [0.15686275 0.17254902 0.04705882]    ...    [0.38431373 0.3529412 0.2       ]    [0.16470589 0.11764706 0.07450981]    [0.12156863 0.09019608 0.05882353]]    [[0.16078432 0.18039216 0.05098039]    [0.16078432 0.1764706 0.05098039]    [0.15686275 0.1764706 0.05098039]    ...    [0.68235296 0.7176471 0.4117647 ]    [0.38039216 0.34901962 0.18431373]    [0.18431373 0.14117648 0.08235294]]    ...    [[0.7490196 0.7372549 0.35686275]    [0.6862745 0.6862745 0.32941177]    [0.6039216 0.6039216 0.2901961 ]    ...    [0.47843137 0.34117648 0.09019608]    [0.49803922 0.3529412 0.09019608]    [0.5137255 0.36862746 0.10196079]]`",t2_q32cu,False,,0,False,Different Image Array Values? Transfer Learning Imagice Classification CNN Model -Imagadatagenerator and Flask Web App Deployment,[],r/deeplearning,False,6,,0,,False,t3_nq55dk,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1622611763.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have used ResNet50 transfer learning to train a model for image classification of 5 categories. It has 95%+ test accuracy. I save the model as .h5, .hdf5, .json, etc.  Then I attempt to deploy the model to a Flask Web App using various load_model methods, but when I do so, the model accuracy is not the same.  I have tried many, many things and the best attempt I have been able to find works well for 4/5 categories, but then the 5th category performs terribly... like it doesn&amp;#39;t seem trained at all only on that one category. The images are balanced for each class and are color images. I have been told that it may be the preprocessing pipeline and that I should make sure that the image that flask is giving the model when uploaded to the website is the same as the exact format that the model has been trained on. I have noticed that the image array values include negative values when fed to the model during training/testing from keras ImageDataGenerator, but are all positive values when fed to the model in the flask web app. So I might be on to something here, but just can&amp;#39;t quite figure out what exactly is happening and how to fix it.&lt;/p&gt;

&lt;p&gt;The preprocessed images from the ResNet model seem to output negative values from imagedatagenerator, whereas the array values of the images in the Flask app are always positive. So maybe some solution lies here where I can make sure both :&lt;/p&gt;

&lt;p&gt;ResNet model preprocessed image (print(image)) with negative values:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Category: [0. 0. 1. 0. 0.] [[[-0.05466276 0.3498863 0.09145098]   [-0.05074119 0.3498863 0.09145098]   [-0.04681962 0.3498863 0.09145098]   ...   [-0.3644667  -0.27756473 -0.363451  ]   [-0.36054513 -0.29717258 -0.37129414]   [-0.37230983 -0.30893728 -0.37913728]]   [[-0.04681962 0.3498863 0.12282354]   [-0.05466276 0.34596473 0.11105883]   [-0.05858433 0.34596473 0.09929413]   ...   [-0.3644667  -0.2814863  -0.363451  ]   [-0.3644667  -0.30109414 -0.3752157 ]   [-0.37230983 -0.30893728 -0.37913728]]   [[ 0.01200391 0.22047453 0.1149804 ]   [-0.00368236 0.2636118 0.1267451 ]   [-0.01936864 0.3106706 0.14635295]   ...   [-0.3644667  -0.2814863  -0.36737257]   [-0.3644667  -0.3050157  -0.3752157 ]   [-0.36838827 -0.30893728 -0.37913728]]   ...   [[ 0.00808234 0.07929805 -0.14384314]   [ 0.00416077 0.07537648 -0.14384314]   [ 0.00416077 0.07537648 -0.14384314]   ...   [-0.39583924 -0.4187412  -0.4497255 ]   [-0.39583924 -0.41481963 -0.4497255 ]   [-0.3997608  -0.42266276 -0.45364708]]   [[ 0.01200391 0.09498432 -0.13992158]   [ 0.01200391 0.09498432 -0.136     ]   [ 0.01200391 0.09498432 -0.136     ]   ...   [-0.40368238 -0.42266276 -0.4497255 ]   [-0.40760395 -0.42266276 -0.45756865]   [-0.40760395 -0.42266276 -0.45756865]]   [[-0.00368236 0.1106706  -0.10462746]   [ 0.00416077 0.1106706  -0.1124706 ]   [ 0.00808234 0.10282746 -0.12815687]   ...   [-0.40760395 -0.41089806 -0.4497255 ]   [-0.40760395 -0.42266276 -0.4497255 ]   [-0.40368238 -0.42266276 -0.45364708]]]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Flask web app image array with all positive values (note this is not the exact same image as above, but demonstrates the point):&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[[[[0.15686275 0.17254902 0.05098039]    [0.15294118 0.17254902 0.05098039]    [0.15686275 0.16862746 0.04705882]    ...    [0.20392157 0.18039216 0.13333334]    [0.10980392 0.07450981 0.05098039]    [0.09411765 0.05490196 0.03137255]]    [[0.16078432 0.1764706 0.05098039]    [0.16078432 0.1764706 0.05098039]    [0.15686275 0.17254902 0.04705882]    ...    [0.38431373 0.3529412 0.2       ]    [0.16470589 0.11764706 0.07450981]    [0.12156863 0.09019608 0.05882353]]    [[0.16078432 0.18039216 0.05098039]    [0.16078432 0.1764706 0.05098039]    [0.15686275 0.1764706 0.05098039]    ...    [0.68235296 0.7176471 0.4117647 ]    [0.38039216 0.34901962 0.18431373]    [0.18431373 0.14117648 0.08235294]]    ...    [[0.7490196 0.7372549 0.35686275]    [0.6862745 0.6862745 0.32941177]    [0.6039216 0.6039216 0.2901961 ]    ...    [0.47843137 0.34117648 0.09019608]    [0.49803922 0.3529412 0.09019608]    [0.5137255 0.36862746 0.10196079]]&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nq55dk,True,,NoahWild,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nq55dk/different_image_array_values_transfer_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nq55dk/different_image_array_values_transfer_learning/,66147,1622582963.0,0,,False,,,,,,,
,deeplearning,,t2_a5rrv,False,,0,False,"Applying deep learning to tabular data, new domains, depends on simple, powerful frameworks like fastai.",[],r/deeplearning,False,6,,0,,False,t3_npzai7,False,dark,0.81,,public,3,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VpsNMm4Os3Q?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'What allows us to use deep learning in new ways? The rise of simple frameworks like fast.ai.', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VpsNMm4Os3Q?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Futurati Podcast', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/VpsNMm4Os3Q/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCRSov16ZLE2UgekgBTgnrjw'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VpsNMm4Os3Q?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/npzai7', 'height': 200}",,False,3,,False,False,,False,,[],{},,False,,1622596898.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=VpsNMm4Os3Q,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,npzai7,True,,tmf1988,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/npzai7/applying_deep_learning_to_tabular_data_new/,all_ads,False,https://www.youtube.com/watch?v=VpsNMm4Os3Q,66147,1622568098.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'What allows us to use deep learning in new ways? The rise of simple frameworks like fast.ai.', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VpsNMm4Os3Q?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Futurati Podcast', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/VpsNMm4Os3Q/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCRSov16ZLE2UgekgBTgnrjw'}}",False,,,,,,,
,deeplearning,"A research team from Georgia Tech, Microsoft Research and Microsoft Azure AI studies the collections of ""lottery tickets"" in extremely over-parametrized models, revealing the generalization performance pattern of winning tickets and proving the existence of ""super tickets.""

Here is a quick read: [Georgia Tech &amp; Microsoft Reveal ‘Super Tickets’ in Pretrained Language Models: Improving Model Compression and Generalization.](https://syncedreview.com/2021/06/01/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-31/)

The paper *Super Tickets in Pre-Trained Language Models: From Model Compression to Improving Generalization* is on [arXiv](https://arxiv.org/abs/2105.12002?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+arxiv%2FQSXk+%28ExcitingAds%21+cs+updates+on+arXiv.org%29).",t2_2fv4yodo,False,,0,False,[R] Georgia Tech &amp; Microsoft Reveal ‘Super Tickets’ in Pretrained Language Models: Improving Model Compression and Generalization,[],r/deeplearning,False,6,,0,,False,t3_npwvtu,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1622590787.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Georgia Tech, Microsoft Research and Microsoft Azure AI studies the collections of &amp;quot;lottery tickets&amp;quot; in extremely over-parametrized models, revealing the generalization performance pattern of winning tickets and proving the existence of &amp;quot;super tickets.&amp;quot;&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/01/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-31/""&gt;Georgia Tech &amp;amp; Microsoft Reveal ‘Super Tickets’ in Pretrained Language Models: Improving Model Compression and Generalization.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Super Tickets in Pre-Trained Language Models: From Model Compression to Improving Generalization&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.12002?utm_source=feedburner&amp;amp;utm_medium=feed&amp;amp;utm_campaign=Feed%3A+arxiv%2FQSXk+%28ExcitingAds%21+cs+updates+on+arXiv.org%29""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,npwvtu,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/npwvtu/r_georgia_tech_microsoft_reveal_super_tickets_in/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/npwvtu/r_georgia_tech_microsoft_reveal_super_tickets_in/,66147,1622561987.0,0,,False,,,,,,,
,deeplearning,,t2_u58vv,False,,0,False,FaceBlit: State of the Art Facial Style Transfer that can run on the phone in Real-Time,[],r/deeplearning,False,6,,0,,False,t3_nq212x,False,dark,1.0,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/7t2SlHlXdMI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'This AI Face Filter Shows How CR7 Statue Should Have At Least Looked Like', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/7t2SlHlXdMI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'bycloud', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/7t2SlHlXdMI/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/bycloudAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/7t2SlHlXdMI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nq212x', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1622603741.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/7t2SlHlXdMI,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nq212x,True,,cloud_weather,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nq212x/faceblit_state_of_the_art_facial_style_transfer/,all_ads,False,https://youtu.be/7t2SlHlXdMI,66147,1622574941.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'This AI Face Filter Shows How CR7 Statue Should Have At Least Looked Like', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/7t2SlHlXdMI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'bycloud', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/7t2SlHlXdMI/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/bycloudAI'}}",False,,,,,,,
,deeplearning,"I want to create a model that takes as input video frames (2D images), converts them to 1D vectors using FC layer or simply by reshaping them (which is better you think?) and feeds them to a LSTM which outputs 1D vectors (same number as of input vectors). 

I want then to convert these 1D vectors to 2D images of the same size as input images. I.e. my model takes images and returns images of the same size (I want to perform segmentation of video frames).

What are the best options to go from 1D vector outputs from LSTM to 2D images of the same size as input images? Simply resize the 1D vectors to 2D images? Use deconvolution layers to gradually upsample them to the desired 2D images?",t2_5a3nrngq,False,,0,False,LSTM outputs to images,[],r/deeplearning,False,6,,0,,False,t3_nppnxk,False,dark,0.75,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1622567178.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to create a model that takes as input video frames (2D images), converts them to 1D vectors using FC layer or simply by reshaping them (which is better you think?) and feeds them to a LSTM which outputs 1D vectors (same number as of input vectors). &lt;/p&gt;

&lt;p&gt;I want then to convert these 1D vectors to 2D images of the same size as input images. I.e. my model takes images and returns images of the same size (I want to perform segmentation of video frames).&lt;/p&gt;

&lt;p&gt;What are the best options to go from 1D vector outputs from LSTM to 2D images of the same size as input images? Simply resize the 1D vectors to 2D images? Use deconvolution layers to gradually upsample them to the desired 2D images?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nppnxk,True,,Embarrassed-Raisin-1,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/nppnxk/lstm_outputs_to_images/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nppnxk/lstm_outputs_to_images/,66147,1622538378.0,0,,False,,,,,,,
,deeplearning,"I'm 19 M, undergrad CS major/Math minor, planning to go to grad school for AI. I'm wondering how I should be studying math efficiently in undergrad. To those of you doing research in AI in grad school, should I make sure I understand the rigorous proofs behind all the math theorems, or will just knowing the math theorems and the basic intuition behind them suffice? Thank you so much for your help.",t2_4jq5sigm,False,,0,False,AI Research Requires Intuitive or Rigorous Math?,[],r/deeplearning,False,6,,0,,False,t3_npkg3f,False,dark,0.82,,public,15,0,{},,False,[],,False,False,,{},,False,15,,False,False,,False,,[],{},,True,,1622546180.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m 19 M, undergrad CS major/Math minor, planning to go to grad school for AI. I&amp;#39;m wondering how I should be studying math efficiently in undergrad. To those of you doing research in AI in grad school, should I make sure I understand the rigorous proofs behind all the math theorems, or will just knowing the math theorems and the basic intuition behind them suffice? Thank you so much for your help.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,npkg3f,True,,pottojam,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/npkg3f/ai_research_requires_intuitive_or_rigorous_math/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/npkg3f/ai_research_requires_intuitive_or_rigorous_math/,66147,1622517380.0,0,,False,,,,,,,
,deeplearning,Can someone help me find an easy implementation of capsule network in keras?,t2_7actlkju,False,,0,False,CapsNet,[],r/deeplearning,False,6,,0,,False,t3_npzmhs,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622597744.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can someone help me find an easy implementation of capsule network in keras?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,npzmhs,True,,Ugly_Accident,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/npzmhs/capsnet/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/npzmhs/capsnet/,66147,1622568944.0,0,,False,,,,,,,
,deeplearning,"Please help me understand what this means. Around epoch 5 out of 100, the average epoch loss has settled around 0.85. I am training the model on the entire training data (no holdout data) for the purpose of making future forecasts. Is it safe to assume the ""fit"" is not improving, or are there alternate explanations?

https://preview.redd.it/o3jcgtwpqo271.png?width=782&amp;format=png&amp;auto=webp&amp;s=3f6126f91b7b973c675b5dfef6b94506d51932a0",t2_1q6oq5dl,False,,0,False,GluonTS DeepAR average epoch loss not improving,[],r/deeplearning,False,6,,0,,False,t3_npywo3,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622595930.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Please help me understand what this means. Around epoch 5 out of 100, the average epoch loss has settled around 0.85. I am training the model on the entire training data (no holdout data) for the purpose of making future forecasts. Is it safe to assume the &amp;quot;fit&amp;quot; is not improving, or are there alternate explanations?&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/o3jcgtwpqo271.png?width=782&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3f6126f91b7b973c675b5dfef6b94506d51932a0""&gt;https://preview.redd.it/o3jcgtwpqo271.png?width=782&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3f6126f91b7b973c675b5dfef6b94506d51932a0&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,npywo3,True,,dmorris87,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/npywo3/gluonts_deepar_average_epoch_loss_not_improving/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/npywo3/gluonts_deepar_average_epoch_loss_not_improving/,66147,1622567130.0,0,,False,,,"{'o3jcgtwpqo271': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 99, 'x': 108, 'u': 'https://preview.redd.it/o3jcgtwpqo271.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8329cd74946625fa5e2152f7deeb96cc488091f5'}, {'y': 199, 'x': 216, 'u': 'https://preview.redd.it/o3jcgtwpqo271.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=25486947c246211718947e51c33cc61522d240c3'}, {'y': 295, 'x': 320, 'u': 'https://preview.redd.it/o3jcgtwpqo271.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=34d85ae65c7ee37b4579f400f6f958e42a2e8d0f'}, {'y': 590, 'x': 640, 'u': 'https://preview.redd.it/o3jcgtwpqo271.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9558661e294ea56d2b225e7199ee6cc874e8a64d'}], 's': {'y': 721, 'x': 782, 'u': 'https://preview.redd.it/o3jcgtwpqo271.png?width=782&amp;format=png&amp;auto=webp&amp;s=3f6126f91b7b973c675b5dfef6b94506d51932a0'}, 'id': 'o3jcgtwpqo271'}}",,,,
,deeplearning,,t2_a5rrv,False,,0,False,When will deep learning permanently change the stock market? Maybe sooner than you think.,[],r/deeplearning,False,6,,0,,False,t3_nq3uws,False,dark,0.43,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HnoCUPPR6Tc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Expert weighs in: when will AI permanently change the stock market? Maybe sooner than you think.', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HnoCUPPR6Tc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Futurati Podcast', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/HnoCUPPR6Tc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCRSov16ZLE2UgekgBTgnrjw'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HnoCUPPR6Tc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nq3uws', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1622608413.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=HnoCUPPR6Tc,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nq3uws,True,,tmf1988,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nq3uws/when_will_deep_learning_permanently_change_the/,all_ads,False,https://www.youtube.com/watch?v=HnoCUPPR6Tc,66147,1622579613.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Expert weighs in: when will AI permanently change the stock market? Maybe sooner than you think.', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HnoCUPPR6Tc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Futurati Podcast', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/HnoCUPPR6Tc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCRSov16ZLE2UgekgBTgnrjw'}}",False,,,,,,,
,deeplearning,,t2_kzlsgns,False,,0,False,No-data ML,[],r/deeplearning,False,6,,0,,False,t3_npvdkf,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1622586728.0,text,6,,,text,medium.com,False,,,,,https://medium.com/ntropy-network/no-data-ml-ba01ea2dfd9b,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,npvdkf,True,,chaisan,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/npvdkf/nodata_ml/,all_ads,False,https://medium.com/ntropy-network/no-data-ml-ba01ea2dfd9b,66147,1622557928.0,0,,False,,,,,,,
,deeplearning,"We are still recruiting participants with a knowledge or interest of machine learning for our study exploring the acceptability of artificial intelligence in healthcare. The survey should only take around 5-10 minutes to complete and is being conducted at the University of Liverpool. Please let me know if you have any questions before participating (contact details on link). 
https://livpsych.eu.qualtrics.com/jfe/form/SV\_eCCHeVzRvR78goC",t2_90w0ssr2,False,,0,False,Short survey on acceptability of AI in healthcare,[],r/deeplearning,False,6,,0,,False,t3_npu6lp,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622583279.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We are still recruiting participants with a knowledge or interest of machine learning for our study exploring the acceptability of artificial intelligence in healthcare. The survey should only take around 5-10 minutes to complete and is being conducted at the University of Liverpool. Please let me know if you have any questions before participating (contact details on link). 
&lt;a href=""https://livpsych.eu.qualtrics.com/jfe/form/SV%5C_eCCHeVzRvR78goC""&gt;https://livpsych.eu.qualtrics.com/jfe/form/SV\_eCCHeVzRvR78goC&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,npu6lp,True,,tylermari96,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/npu6lp/short_survey_on_acceptability_of_ai_in_healthcare/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/npu6lp/short_survey_on_acceptability_of_ai_in_healthcare/,66147,1622554479.0,0,,False,,,,,,,
,deeplearning,"Here is our survey paper for GANs on computer vision, which has been published at [ACM Computing Surveys](https://dl.acm.org/doi/abs/10.1145/3439723?casa_token=S0r-Ncw1IuEAAAAA:pC4xBbSNQ3nghS-X9GP8BV2tWLvLKu8XQuno1obNAKBwyjsozYDhzKjjytudhjB3bO6-CntucOtiJg). Here is [arxiv version](https://arxiv.org/pdf/1906.01529.pdf). Codes related to this work are provided [here](https://github.com/sheqi/GAN_Review).",t2_3nmvziw,False,,0,False,Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy,[],r/deeplearning,False,6,,0,,False,t3_npphu3,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622566470.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Here is our survey paper for GANs on computer vision, which has been published at &lt;a href=""https://dl.acm.org/doi/abs/10.1145/3439723?casa_token=S0r-Ncw1IuEAAAAA:pC4xBbSNQ3nghS-X9GP8BV2tWLvLKu8XQuno1obNAKBwyjsozYDhzKjjytudhjB3bO6-CntucOtiJg""&gt;ACM Computing Surveys&lt;/a&gt;. Here is &lt;a href=""https://arxiv.org/pdf/1906.01529.pdf""&gt;arxiv version&lt;/a&gt;. Codes related to this work are provided &lt;a href=""https://github.com/sheqi/GAN_Review""&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,npphu3,True,,villawang,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/npphu3/generative_adversarial_networks_in_computer/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/npphu3/generative_adversarial_networks_in_computer/,66147,1622537670.0,0,,False,,,,,,,
,deeplearning,"Hi. I'm in the early release stage for my new python workflow/dataflow compute framework that makes writing parallel python processes simple and transparent. It has CPU/GPU scheduling, containers, hardware parallelism, concurrency, extensible, localized or distributed, etc. very lightweight. Have a look, comment or contribute!

[https://github.com/radiantone/entangle](https://github.com/radiantone/entangle)

With Entangle you can run simple, hardware parallelized code with conditional logic that looks like this. There are some AI/ML examples as well.

```python
result = add(
            add(
                num(6),
                two() if False else one()
            ),
            subtract(
                five(),
                two()
            )
)
print(result())
```",t2_8eerhzu,False,,0,False,New Parallel Compute Framework with AI Examples,[],r/deeplearning,False,6,,0,,False,t3_np86ul,False,dark,0.9,,public,17,0,{},,False,[],,False,False,,{},,False,17,,False,False,,False,,[],{},,True,,1622509632.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi. I&amp;#39;m in the early release stage for my new python workflow/dataflow compute framework that makes writing parallel python processes simple and transparent. It has CPU/GPU scheduling, containers, hardware parallelism, concurrency, extensible, localized or distributed, etc. very lightweight. Have a look, comment or contribute!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/radiantone/entangle""&gt;https://github.com/radiantone/entangle&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;With Entangle you can run simple, hardware parallelized code with conditional logic that looks like this. There are some AI/ML examples as well.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;python
result = add(
            add(
                num(6),
                two() if False else one()
            ),
            subtract(
                five(),
                two()
            )
)
print(result())
&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,np86ul,True,,northwolf56,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/np86ul/new_parallel_compute_framework_with_ai_examples/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/np86ul/new_parallel_compute_framework_with_ai_examples/,66147,1622480832.0,0,,False,,,,,,,
,deeplearning,"I'm (19M, undergrad CS major hoping to go to grad school for AI). I hear that most undergrads get laughed out of interviews (not literally) if they demand AI experience. So, what kind of internships should I do during my undergrad years to go to an AI grad school? Thank you for your help.",t2_4jq5sigm,False,,0,False,AI Undergrad Internships?,[],r/deeplearning,False,6,,0,,False,t3_npfgnb,False,dark,0.71,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1622530032.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m (19M, undergrad CS major hoping to go to grad school for AI). I hear that most undergrads get laughed out of interviews (not literally) if they demand AI experience. So, what kind of internships should I do during my undergrad years to go to an AI grad school? Thank you for your help.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,npfgnb,True,,pottojam,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/npfgnb/ai_undergrad_internships/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/npfgnb/ai_undergrad_internships/,66147,1622501232.0,0,,False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,New Android RL environment by DeepMind! (why we should care? and how to get started?),[],r/deeplearning,False,6,,0,,False,t3_noxm17,False,dark,0.93,,public,31,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/847zrERIr-k?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""DeepMind's Android RL Environment - AndroidEnv"", 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/847zrERIr-k?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/847zrERIr-k/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/847zrERIr-k?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/noxm17', 'height': 200}",,False,31,,False,False,,False,,[],{},,False,,1622475019.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/847zrERIr-k,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,noxm17,True,,gordicaleksa,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/noxm17/new_android_rl_environment_by_deepmind_why_we/,all_ads,False,https://youtu.be/847zrERIr-k,66147,1622446219.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""DeepMind's Android RL Environment - AndroidEnv"", 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/847zrERIr-k?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/847zrERIr-k/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,,t2_4aflqwk0,False,,0,False,Multi-Type-TD-TSR - Extracting Tables from Document Images using a Multi-stage Pipeline for Table Detection and Table Structure Recognition: from OCR to Structured Table Representations,[],r/deeplearning,False,6,,0,,False,t3_npbdpt,False,dark,0.81,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1622518375.0,text,6,,,text,reddit.com,False,,,,,https://www.reddit.com/gallery/npbd5f,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,npbdpt,True,,psarpei,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/npbdpt/multitypetdtsr_extracting_tables_from_document/,all_ads,False,https://www.reddit.com/gallery/npbd5f,66147,1622489575.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'DeepLearningPapers', 'selftext': '', 'author_fullname': 't2_4aflqwk0', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'is_gallery': True, 'title': 'Multi-Type-TD-TSR - Extracting Tables from Document Images using a Multi-stage Pipeline for Table Detection and Table Structure Recognition: from OCR to Structured Table Representations', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/DeepLearningPapers', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'00rvmwvpci271': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 51, 'x': 108, 'u': 'https://preview.redd.it/00rvmwvpci271.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=24f827395932fb3b0b84bad916491a32d450f10c'}, {'y': 103, 'x': 216, 'u': 'https://preview.redd.it/00rvmwvpci271.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=3ba58cf8da222d8142e32203b396e6d92e35bbf7'}, {'y': 152, 'x': 320, 'u': 'https://preview.redd.it/00rvmwvpci271.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=00d61172067a38d0d107d47b046d93d94a140156'}, {'y': 305, 'x': 640, 'u': 'https://preview.redd.it/00rvmwvpci271.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=b1fa074d4b6d79509705115179e5ea473a231c6b'}, {'y': 458, 'x': 960, 'u': 'https://preview.redd.it/00rvmwvpci271.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=cc5495013fae8e4cae2f4e5ef1882ee8568f8335'}, {'y': 516, 'x': 1080, 'u': 'https://preview.redd.it/00rvmwvpci271.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=2a1891063246f74385f9c09dbd3294674b09bae6'}], 's': {'y': 829, 'gif': 'https://i.redd.it/00rvmwvpci271.gif', 'mp4': 'https://preview.redd.it/00rvmwvpci271.gif?format=mp4&amp;s=f5c369de57d0874e2d0091dde12beb54a5a3b25e', 'x': 1735}, 'id': '00rvmwvpci271'}, 'hg7797wpci271': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 138, 'x': 108, 'u': 'https://preview.redd.it/hg7797wpci271.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=dc15bc1f69fb10750a4bf67548d14a870a37c09a'}, {'y': 277, 'x': 216, 'u': 'https://preview.redd.it/hg7797wpci271.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=c9c8f21468a51f546cc413c68c58766d9f7939ce'}, {'y': 410, 'x': 320, 'u': 'https://preview.redd.it/hg7797wpci271.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=ffbf63e083bf36522977d1c87e00d9f26a311eca'}, {'y': 821, 'x': 640, 'u': 'https://preview.redd.it/hg7797wpci271.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=8ba6053c3865af652b600acee2ddcff09565eaef'}, {'y': 1231, 'x': 960, 'u': 'https://preview.redd.it/hg7797wpci271.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=96b5ef0746e52ded243bd75275f396de929be05a'}], 's': {'y': 1359, 'gif': 'https://i.redd.it/hg7797wpci271.gif', 'mp4': 'https://preview.redd.it/hg7797wpci271.gif?format=mp4&amp;s=66fc53940c774e5818d30d5fef5c9a225edd6b58', 'x': 1059}, 'id': 'hg7797wpci271'}, 'euat7dwpci271': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 153, 'x': 108, 'u': 'https://preview.redd.it/euat7dwpci271.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=2bbd2f1b77be78577c5e719726dc788e79c17bb7'}, {'y': 306, 'x': 216, 'u': 'https://preview.redd.it/euat7dwpci271.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=7c78b42cdf35d28f6e9c1975b9a705dc468504c4'}, {'y': 453, 'x': 320, 'u': 'https://preview.redd.it/euat7dwpci271.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=ec8502fe84e05645f8cc894e13bd01bad95ce3d5'}, {'y': 906, 'x': 640, 'u': 'https://preview.redd.it/euat7dwpci271.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=48b345bc0813d5a715dab498305bce6ba17e1697'}, {'y': 1360, 'x': 960, 'u': 'https://preview.redd.it/euat7dwpci271.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=333a8ca943fc4123f65c9c1887f76880043e23ca'}], 's': {'y': 1428, 'gif': 'https://i.redd.it/euat7dwpci271.gif', 'mp4': 'https://preview.redd.it/euat7dwpci271.gif?format=mp4&amp;s=9b8f502d811cd7bce1e2ec2792e755724ed0b026', 'x': 1008}, 'id': 'euat7dwpci271'}, 'uts3m1wpci271': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 64, 'x': 108, 'u': 'https://preview.redd.it/uts3m1wpci271.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=6ed6b2af3c2410a4123349757eddf1c1785c0e44'}, {'y': 129, 'x': 216, 'u': 'https://preview.redd.it/uts3m1wpci271.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=33220182cb67b94a3c52fc539d9266506b1688e4'}, {'y': 192, 'x': 320, 'u': 'https://preview.redd.it/uts3m1wpci271.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=b932f68a81d859bfa596f5acf2bfce3b3c20ffda'}, {'y': 384, 'x': 640, 'u': 'https://preview.redd.it/uts3m1wpci271.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=fc7960429149112c14e12de71c068cc290c9e89b'}, {'y': 576, 'x': 960, 'u': 'https://preview.redd.it/uts3m1wpci271.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=6e2b917444ab8b08e4e142ee7e243138a46a5ef1'}, {'y': 648, 'x': 1080, 'u': 'https://preview.redd.it/uts3m1wpci271.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=7130a49d24fd49ae4e5e3cfe9ae496015435b6b5'}], 's': {'y': 1239, 'gif': 'https://i.redd.it/uts3m1wpci271.gif', 'mp4': 'https://preview.redd.it/uts3m1wpci271.gif?format=mp4&amp;s=a434ad6886176626e505fd420f69ebbc37a0f2f9', 'x': 2064}, 'id': 'uts3m1wpci271'}}, 'name': 't3_npbd5f', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.95, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 19, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'gallery_data': {'items': [{'media_id': 'euat7dwpci271', 'id': 47910517}, {'caption': 'New state-of-the-art for table structure recognition check it out on Github: https://github.com/Psarpei/Multi-Type-TD-TSR', 'outbound_url': 'https://github.com/Psarpei/Multi-Type-TD-TSR', 'media_id': 'uts3m1wpci271', 'id': 47910518}, {'media_id': '00rvmwvpci271', 'id': 47910519}, {'media_id': 'hg7797wpci271', 'id': 47910520}]}, 'link_flair_text': None, 'can_mod_post': False, 'score': 19, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1622518335.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'reddit.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.reddit.com/gallery/npbd5f', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_38ri8', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'npbd5f', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'psarpei', 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/DeepLearningPapers/comments/npbd5f/multitypetdtsr_extracting_tables_from_document/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/gallery/npbd5f', 'subreddit_subscribers': 15755, 'created_utc': 1622489535.0, 'num_crossposts': 13, 'media': None, 'is_video': False}]",t3_npbd5f,,,,,
,deeplearning," 

Hi, I have been given a task to  classify pictures of electronic scooters and to create an algorithm that  recognises whether a scooter has been parked correctly or not.

I  received 85,000 pictures. I would like to solve the task using a CNN. I  quickly realised that labelling the training data is very complicated.  Various questions arose, for example

* when is the scooter parked correctly?
* Is there a scooter?
* At what point do I say that too little scooter is visible in the picture?

I have set up 3 labels:

1. scooter is well visible and location is good
2. scooter is well recognisable and location is poor
3. scooter is poorly recognisable

I  am not sure if these 3 classifications are good because I am especially  unsure about the 2nd classification. No location is the same. I don't  think I can get the model trained correctly to recognise, for example,  that the scooter is in front of the driveway of a garage, etc.

I tend to set up 2 classes.

1. good:  scooter is there, easily visible, not broken, structures (angle,  wheels, handlebars) recognisable, surface doesn't matter, night or day  doesn't matter.
2. bad: no scooter or only very few scooters visible or few unclear scooter structures on the photo.

The problem here is that I have to train the model to recognise a scooter correctly. **But how do I get the model to recognise if the location of the scooter is correct?**

After  labelling 2000 images, I have only found 50 images that may not  represent a correct location. The reason for this is always different.

I use Python with Tensorflow and Keras.Various YouTube videos help me to write the code.

Maybe someone has an idea how I can better approach the problem or whether I am already making basic mistakes when labelling.

Thanks a lot!",t2_3nkkk0uk,False,,0,False,Electronic scooter classification,[],r/deeplearning,False,6,,0,,False,t3_np71wp,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1622506499.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I have been given a task to  classify pictures of electronic scooters and to create an algorithm that  recognises whether a scooter has been parked correctly or not.&lt;/p&gt;

&lt;p&gt;I  received 85,000 pictures. I would like to solve the task using a CNN. I  quickly realised that labelling the training data is very complicated.  Various questions arose, for example&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;when is the scooter parked correctly?&lt;/li&gt;
&lt;li&gt;Is there a scooter?&lt;/li&gt;
&lt;li&gt;At what point do I say that too little scooter is visible in the picture?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I have set up 3 labels:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;scooter is well visible and location is good&lt;/li&gt;
&lt;li&gt;scooter is well recognisable and location is poor&lt;/li&gt;
&lt;li&gt;scooter is poorly recognisable&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I  am not sure if these 3 classifications are good because I am especially  unsure about the 2nd classification. No location is the same. I don&amp;#39;t  think I can get the model trained correctly to recognise, for example,  that the scooter is in front of the driveway of a garage, etc.&lt;/p&gt;

&lt;p&gt;I tend to set up 2 classes.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;good:  scooter is there, easily visible, not broken, structures (angle,  wheels, handlebars) recognisable, surface doesn&amp;#39;t matter, night or day  doesn&amp;#39;t matter.&lt;/li&gt;
&lt;li&gt;bad: no scooter or only very few scooters visible or few unclear scooter structures on the photo.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The problem here is that I have to train the model to recognise a scooter correctly. &lt;strong&gt;But how do I get the model to recognise if the location of the scooter is correct?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;After  labelling 2000 images, I have only found 50 images that may not  represent a correct location. The reason for this is always different.&lt;/p&gt;

&lt;p&gt;I use Python with Tensorflow and Keras.Various YouTube videos help me to write the code.&lt;/p&gt;

&lt;p&gt;Maybe someone has an idea how I can better approach the problem or whether I am already making basic mistakes when labelling.&lt;/p&gt;

&lt;p&gt;Thanks a lot!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,np71wp,True,,Arne97,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/np71wp/electronic_scooter_classification/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/np71wp/electronic_scooter_classification/,66147,1622477699.0,0,,False,,,,,,,
,deeplearning,"A research team from New York University, Facebook AI, and a CIFAR Fellow in Learning in Machines &amp; Brains raise doubts regarding large-scale pretrained language models’ few-shot learning abilities. The researchers re-evaluate such abilities with held-out examples unavailable, which they propose constitutes “true few-shot learning.” 

Here is a quick read: [NYU, Facebook &amp; CIFAR Present ‘True Few-Shot Learning’ for Language Models Whose Few-Shot Ability They Say Is Overestimated.](https://syncedreview.com/2021/05/31/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-30/)

The paper *True Few-Shot Learning with Language Models* is on [arXiv](https://arxiv.org/abs/2105.11447).",t2_2fv4yodo,False,,0,False,"[R] NYU, Facebook &amp; CIFAR Present ‘True Few-Shot Learning’ for Language Models Whose Few-Shot Ability They Say Is Overestimated",[],r/deeplearning,False,6,,0,,False,t3_np6ooe,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622505530.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from New York University, Facebook AI, and a CIFAR Fellow in Learning in Machines &amp;amp; Brains raise doubts regarding large-scale pretrained language models’ few-shot learning abilities. The researchers re-evaluate such abilities with held-out examples unavailable, which they propose constitutes “true few-shot learning.” &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/31/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-30/""&gt;NYU, Facebook &amp;amp; CIFAR Present ‘True Few-Shot Learning’ for Language Models Whose Few-Shot Ability They Say Is Overestimated.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;True Few-Shot Learning with Language Models&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.11447""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,np6ooe,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/np6ooe/r_nyu_facebook_cifar_present_true_fewshot/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/np6ooe/r_nyu_facebook_cifar_present_true_fewshot/,66147,1622476730.0,0,,False,,,,,,,
,deeplearning,,t2_bu3iimzg,False,,0,False,Street Murals start singing thanks to Deepfake,[],r/deeplearning,False,6,,0,,False,t3_no9wjf,False,dark,0.95,,public,138,1,{},,False,[],"{'reddit_video': {'bitrate_kbps': 2400, 'fallback_url': 'https://v.redd.it/xp89vy8719271/DASH_720.mp4?source=fallback', 'height': 720, 'width': 720, 'scrubber_media_url': 'https://v.redd.it/xp89vy8719271/DASH_96.mp4', 'dash_url': 'https://v.redd.it/xp89vy8719271/DASHPlaylist.mpd?a=1626449765%2CNmE3OWJhZjA5N2I3ZjNkYTA4YjFhMDc3YzQ2Njc1MTM1MTJhNzVkNDA4MzY3MjcxM2EyOWYyNmI5YTY3Mjg5MQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 29, 'hls_url': 'https://v.redd.it/xp89vy8719271/HLSPlaylist.m3u8?a=1626449765%2CN2U4ZmQxODJhODhiNTcwOTUxNDgyZDNmNjljYmYwMjVmYjJkODhmNzI5ZjMzYTc2YjFlZmQxZjNkNzFhZGFlNA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,138,,False,False,,False,,[],{},,False,,1622405495.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/xp89vy8719271,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,no9wjf,True,,Olyapyramid,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/no9wjf/street_murals_start_singing_thanks_to_deepfake/,all_ads,False,https://v.redd.it/xp89vy8719271,66147,1622376695.0,0,"{'reddit_video': {'bitrate_kbps': 2400, 'fallback_url': 'https://v.redd.it/xp89vy8719271/DASH_720.mp4?source=fallback', 'height': 720, 'width': 720, 'scrubber_media_url': 'https://v.redd.it/xp89vy8719271/DASH_96.mp4', 'dash_url': 'https://v.redd.it/xp89vy8719271/DASHPlaylist.mpd?a=1626449765%2CNmE3OWJhZjA5N2I3ZjNkYTA4YjFhMDc3YzQ2Njc1MTM1MTJhNzVkNDA4MzY3MjcxM2EyOWYyNmI5YTY3Mjg5MQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 29, 'hls_url': 'https://v.redd.it/xp89vy8719271/HLSPlaylist.m3u8?a=1626449765%2CN2U4ZmQxODJhODhiNTcwOTUxNDgyZDNmNjljYmYwMjVmYjJkODhmNzI5ZjMzYTc2YjFlZmQxZjNkNzFhZGFlNA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,"Hi Reddit,

I've been looking for some AI/Computer Vision based automated way to remove crease, wrinkles, folds, dirt from clothes in fashion images captured for ecommerce.

I did try to search for GAN based methods or Image inpainting based methods but couldn't find anything reliable. I am looking for some way to retouch the image in a way that the wrinkles/folds/crease/dirt on the clothes could be removed.

I could find few websites which are doing the similar work which I require to attain programmatically but I couldn't find exactly where in computer vision to look for.

Sample Solution:  

https://imageedit.ai/   

https://retouch4.me/cleanbackdrop   

https://studiodrop.com/retouching/   


Could anyone provide me any pointers where I can look for?

Any help is highly appreciated. Thanks.",t2_93rilu9d,False,,0,False,Garments Crease/Wrinkles/Dirt Removal using AI/Computer Vision?,[],r/deeplearning,False,6,,0,,False,t3_np2opd,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622494261.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Reddit,&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been looking for some AI/Computer Vision based automated way to remove crease, wrinkles, folds, dirt from clothes in fashion images captured for ecommerce.&lt;/p&gt;

&lt;p&gt;I did try to search for GAN based methods or Image inpainting based methods but couldn&amp;#39;t find anything reliable. I am looking for some way to retouch the image in a way that the wrinkles/folds/crease/dirt on the clothes could be removed.&lt;/p&gt;

&lt;p&gt;I could find few websites which are doing the similar work which I require to attain programmatically but I couldn&amp;#39;t find exactly where in computer vision to look for.&lt;/p&gt;

&lt;p&gt;Sample Solution:  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://imageedit.ai/""&gt;https://imageedit.ai/&lt;/a&gt;   &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://retouch4.me/cleanbackdrop""&gt;https://retouch4.me/cleanbackdrop&lt;/a&gt;   &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://studiodrop.com/retouching/""&gt;https://studiodrop.com/retouching/&lt;/a&gt;   &lt;/p&gt;

&lt;p&gt;Could anyone provide me any pointers where I can look for?&lt;/p&gt;

&lt;p&gt;Any help is highly appreciated. Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,np2opd,True,,gpahul,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/np2opd/garments_creasewrinklesdirt_removal_using/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/np2opd/garments_creasewrinklesdirt_removal_using/,66147,1622465461.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,"My AI Monthly Top 3 for May 2021 is Out! (with a bonus paper) This is a curated list of the latest AI and Data Science breakthroughs in May 2021 with a clear video explanation, link to a more in-depth article, and code (if applicable).",[],r/deeplearning,False,6,,0,,False,t3_np1rj2,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1622491194.0,text,6,,,text,louisbouchard.ai,False,,,,,https://www.louisbouchard.ai/the-ai-monthly-top-3-may-2021/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,np1rj2,True,,OnlyProggingForFun,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/np1rj2/my_ai_monthly_top_3_for_may_2021_is_out_with_a/,all_ads,False,https://www.louisbouchard.ai/the-ai-monthly-top-3-may-2021/,66147,1622462394.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,AI drone killed a human for the first time,[],r/deeplearning,False,6,,0,,False,t3_np4w4i,False,dark,0.2,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VwKlHrS6DfQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI drone killed a human for the first time', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VwKlHrS6DfQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/VwKlHrS6DfQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VwKlHrS6DfQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/np4w4i', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1622500740.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/VwKlHrS6DfQ,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,np4w4i,True,,cmillionaire9,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/np4w4i/ai_drone_killed_a_human_for_the_first_time/,all_ads,False,https://youtu.be/VwKlHrS6DfQ,66147,1622471940.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI drone killed a human for the first time', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VwKlHrS6DfQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/VwKlHrS6DfQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,AI-created humans rapped,[],r/deeplearning,False,6,,0,,False,t3_no73ko,False,dark,0.77,,public,18,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/vBahAUhgkeg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI-created humans rapped', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/vBahAUhgkeg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/vBahAUhgkeg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/vBahAUhgkeg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/no73ko', 'height': 200}",,False,18,,False,False,,False,,[],{},,False,,1622393616.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/vBahAUhgkeg,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,no73ko,True,,cmillionaire9,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/no73ko/aicreated_humans_rapped/,all_ads,False,https://youtu.be/vBahAUhgkeg,66147,1622364816.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI-created humans rapped', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/vBahAUhgkeg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/vBahAUhgkeg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,"Hi,
I am Machine Learning Engineer working on Computer Vision. I am interested in conducting research in this Computer Vision but it is getting hard for me to conduct research independently. Is there any one I can collaborate to get involve in research?",t2_3bh5lmdv,False,,0,False,Deep Learning research,[],r/deeplearning,False,6,,0,,False,t3_nog5iz,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622425009.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,
I am Machine Learning Engineer working on Computer Vision. I am interested in conducting research in this Computer Vision but it is getting hard for me to conduct research independently. Is there any one I can collaborate to get involve in research?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nog5iz,True,,prabin96,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nog5iz/deep_learning_research/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nog5iz/deep_learning_research/,66147,1622396209.0,0,,False,,,,,,,
,deeplearning,,t2_3747346o,False,,0,False,Any open source online street sign organized set for deep leaning with python?,[],r/deeplearning,False,6,,0,,False,t3_nofmcv,False,dark,0.5,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1622423490.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/7gz095yuia271.jpg,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nofmcv,True,,sutethejester,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nofmcv/any_open_source_online_street_sign_organized_set/,all_ads,False,https://i.redd.it/7gz095yuia271.jpg,66147,1622394690.0,0,,False,,,,,,,
,deeplearning,,t2_4bgr16zo,False,,0,False,One Shot Learning Network with PyTorch,[],r/deeplearning,False,6,,0,,False,t3_noehwb,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1622420188.0,text,6,,,text,medium.com,False,,,,,https://medium.com/@taying.cheng/building-a-one-shot-learning-network-with-pytorch-d1c3a5fafa4a,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,noehwb,True,,Fokrtuj56,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/noehwb/one_shot_learning_network_with_pytorch/,all_ads,False,https://medium.com/@taying.cheng/building-a-one-shot-learning-network-with-pytorch-d1c3a5fafa4a,66147,1622391388.0,0,,False,,,,,,,
,deeplearning,I have come accross tutorials which can visualise 2d featuremaps.. but what if I have some 1D feature map as output? How do I understand that kind of info?,t2_celgls4m,False,,0,False,How to visualise featuremaps in pytorch?,[],r/deeplearning,False,6,,0,,False,t3_no6ofe,False,dark,0.79,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1622391741.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have come accross tutorials which can visualise 2d featuremaps.. but what if I have some 1D feature map as output? How do I understand that kind of info?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,no6ofe,True,,ThatGurlWithFreckles,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/no6ofe/how_to_visualise_featuremaps_in_pytorch/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/no6ofe/how_to_visualise_featuremaps_in_pytorch/,66147,1622362941.0,0,,False,,,,,,,
,deeplearning,"Hello, I have been trying to understand MirrorGAN architecture using the paper : https://arxiv.org/pdf/1903.05854 

But I am struggling to understand the maths behind STEM and GLAM phase. I know about working of attention model and GANs as well but however, I am unable to fit in the concept expressed in the paper. 

Can somebody help me providing relevant resource(s) which could be helpful in grasping these concepts?

Thanks for reading.",t2_60tdrwyh,False,,0,False,Help in understanding MirrorGAN,[],r/deeplearning,False,6,,0,,False,t3_nodkbc,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622417415.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I have been trying to understand MirrorGAN architecture using the paper : &lt;a href=""https://arxiv.org/pdf/1903.05854""&gt;https://arxiv.org/pdf/1903.05854&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;But I am struggling to understand the maths behind STEM and GLAM phase. I know about working of attention model and GANs as well but however, I am unable to fit in the concept expressed in the paper. &lt;/p&gt;

&lt;p&gt;Can somebody help me providing relevant resource(s) which could be helpful in grasping these concepts?&lt;/p&gt;

&lt;p&gt;Thanks for reading.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nodkbc,True,,ElidaFraley,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nodkbc/help_in_understanding_mirrorgan/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nodkbc/help_in_understanding_mirrorgan/,66147,1622388615.0,0,,False,,,,,,,
,deeplearning,,t2_7g9hli6d,False,,0,False,[D] Is there any way to use multiple google colab accounts' gpu for distributed training?,[],r/deeplearning,False,6,,0,,False,t3_no92cr,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1622402266.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/no91s0/d_is_there_any_way_to_use_multiple_google_colab/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,no92cr,True,,soul_express99,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/no92cr/d_is_there_any_way_to_use_multiple_google_colab/,all_ads,False,/r/MachineLearning/comments/no91s0/d_is_there_any_way_to_use_multiple_google_colab/,66147,1622373466.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'I wanna train the RoBERTa language model for Nepali language  from scratch. But neither I have money to get GCP with powerful gpus nor my college has a powerful computer. Therefore I was thinking is there any way to get collective power of multiple google colab machines....\n\nAny help or suggestion is appreciated....', 'author_fullname': 't2_7g9hli6d', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': ""[D] Is there any way to use multiple google colab accounts' gpu for distributed training?"", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_no91s0', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.43, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1622402204.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I wanna train the RoBERTa language model for Nepali language  from scratch. But neither I have money to get GCP with powerful gpus nor my college has a powerful computer. Therefore I was thinking is there any way to get collective power of multiple google colab machines....&lt;/p&gt;\n\n&lt;p&gt;Any help or suggestion is appreciated....&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'no91s0', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'soul_express99', 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/no91s0/d_is_there_any_way_to_use_multiple_google_colab/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/no91s0/d_is_there_any_way_to_use_multiple_google_colab/', 'subreddit_subscribers': 1931377, 'created_utc': 1622373404.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_no91s0,,,,,
,deeplearning,"Hi..I was inspired by the kind and useful feedback from this group on my first post about using deep learning to mimic how young children learn to add. Here is my second post. Thoughts and feedback would be very much appreciated again ...

[https://mrshrekblogs.com/my-ai-brainchild/99-2-wrong-but-my-maths-ai-brainchild-is-definitely-learning/](https://mrshrekblogs.com/my-ai-brainchild/99-2-wrong-but-my-maths-ai-brainchild-is-definitely-learning/)

&amp;#x200B;

https://preview.redd.it/wgggh4o5u8271.jpg?width=1050&amp;format=pjpg&amp;auto=webp&amp;s=1e3ea07eabdf9ad728985f631b8259693ae6b0bd",t2_c9vfuv4n,False,,0,False,"99.2% wrong, but my maths AI brainchild is definitely learning - My AI brainchild",[],r/deeplearning,False,6,,0,,False,t3_no99rh,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622403098.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi..I was inspired by the kind and useful feedback from this group on my first post about using deep learning to mimic how young children learn to add. Here is my second post. Thoughts and feedback would be very much appreciated again ...&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://mrshrekblogs.com/my-ai-brainchild/99-2-wrong-but-my-maths-ai-brainchild-is-definitely-learning/""&gt;https://mrshrekblogs.com/my-ai-brainchild/99-2-wrong-but-my-maths-ai-brainchild-is-definitely-learning/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/wgggh4o5u8271.jpg?width=1050&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=1e3ea07eabdf9ad728985f631b8259693ae6b0bd""&gt;https://preview.redd.it/wgggh4o5u8271.jpg?width=1050&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=1e3ea07eabdf9ad728985f631b8259693ae6b0bd&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,no99rh,True,,My_AI_brainchild,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/no99rh/992_wrong_but_my_maths_ai_brainchild_is/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/no99rh/992_wrong_but_my_maths_ai_brainchild_is/,66147,1622374298.0,0,,False,,,"{'wgggh4o5u8271': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 64, 'x': 108, 'u': 'https://preview.redd.it/wgggh4o5u8271.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=912855de595f56e7bdaf757b95b341a56f52d434'}, {'y': 129, 'x': 216, 'u': 'https://preview.redd.it/wgggh4o5u8271.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b881e9cf6870dbc8193f9af7aaa89baba07c5407'}, {'y': 192, 'x': 320, 'u': 'https://preview.redd.it/wgggh4o5u8271.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ce36866e09fb0cb473b1e469bb577c412f402fd8'}, {'y': 384, 'x': 640, 'u': 'https://preview.redd.it/wgggh4o5u8271.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=afea39142c97acd5e51426495571197273f7791d'}, {'y': 576, 'x': 960, 'u': 'https://preview.redd.it/wgggh4o5u8271.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fdcc43ee75464593d10352bfb240495740f246aa'}], 's': {'y': 630, 'x': 1050, 'u': 'https://preview.redd.it/wgggh4o5u8271.jpg?width=1050&amp;format=pjpg&amp;auto=webp&amp;s=1e3ea07eabdf9ad728985f631b8259693ae6b0bd'}, 'id': 'wgggh4o5u8271'}}",,,,
,deeplearning,,t2_7vj0iivj,False,,0,False,Can someone explain in brief how does Zero-shot learning (ZSL) work?,[],r/deeplearning,False,6,,0,,False,t3_nntfsh,False,dark,0.89,,public,18,0,{},,False,[],,False,False,,{},,False,18,,False,False,,False,,[],{},,True,,1622341869.0,text,6,,,text,self.deeplearning,False,,,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nntfsh,True,,setting_sun_,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/nntfsh/can_someone_explain_in_brief_how_does_zeroshot/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nntfsh/can_someone_explain_in_brief_how_does_zeroshot/,66147,1622313069.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,Real-Time 4K Style Transfer,[],r/deeplearning,False,6,,0,,False,t3_no8lbk,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/X7WzlAyUGPo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'High-Resolution Photorealistic Image Translation in Real-Time', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/X7WzlAyUGPo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/X7WzlAyUGPo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/X7WzlAyUGPo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/no8lbk', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1622400280.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/X7WzlAyUGPo,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,no8lbk,True,,OnlyProggingForFun,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/no8lbk/realtime_4k_style_transfer/,all_ads,False,https://youtu.be/X7WzlAyUGPo,66147,1622371480.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'High-Resolution Photorealistic Image Translation in Real-Time', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/X7WzlAyUGPo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/X7WzlAyUGPo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,Real-time YOLOv3 on a Laptop Using Sparse Quantization,[],r/deeplearning,False,6,,0,,False,t3_no7ge4,False,dark,0.57,,public,1,0,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/wQs26NL8Ctw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Real-time YOLOv3 on a Laptop Using Sparse Quantization', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/wQs26NL8Ctw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/wQs26NL8Ctw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/wQs26NL8Ctw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/no7ge4', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1622395204.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/wQs26NL8Ctw,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,no7ge4,True,,cmillionaire9,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/no7ge4/realtime_yolov3_on_a_laptop_using_sparse/,all_ads,False,https://youtu.be/wQs26NL8Ctw,66147,1622366404.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Real-time YOLOv3 on a Laptop Using Sparse Quantization', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/wQs26NL8Ctw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/wQs26NL8Ctw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,,t2_onq0,False,,0,False,ProteinBERT: A universal deep-learning model of protein sequence and function,[],r/deeplearning,False,6,,0,,False,t3_no77gu,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1622394092.0,text,6,,,text,self.bioinformatics,False,,,,,/r/bioinformatics/comments/no76jp/proteinbert_a_universal_deeplearning_model_of/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,no77gu,True,,ddofer,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/no77gu/proteinbert_a_universal_deeplearning_model_of/,all_ads,False,/r/bioinformatics/comments/no76jp/proteinbert_a_universal_deeplearning_model_of/,66147,1622365292.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'bioinformatics', 'selftext': ""# ProteinBERT: A universal deep-learning model of protein sequence and function\n\n&gt;Brandes, Nadav and Ofer, Dan and Peleg, Yam and Rappoport, Nadav and Linial, Michal\n\nPaper: [https://www.biorxiv.org/content/10.1101/2021.05.24.445464v1](https://www.biorxiv.org/content/10.1101/2021.05.24.445464v1)\n\nTL;DR:\n\n&gt;Deep learning language models (like BERT in NLP) but for proteins!  \n&gt;  \n&gt;We trained a model on over 100 million proteins to predict their sequence and GO annotations (i.e their functions and properties). We show \\~SOTA performance on a wide range of benchmarks. Our model is much smaller and faster than comparable works (TAPE, ESM), and is quite interpretable thanks to our global attention. We provide the pretrained models and code, in a simple Keras/Tensorflow Python package.\n\nCode &amp; pretrained models:\n\n[https://github.com/nadavbra/protein\\_bert](https://github.com/nadavbra/protein_bert)\n\n&amp;#x200B;\n\nI'm one of the authors, AMA! :)"", 'author_fullname': 't2_onq0', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'ProteinBERT: A universal deep-learning model of protein sequence and function', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/bioinformatics', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'academic', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_no76jp', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.97, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 90, 'total_awards_received': 3, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'academic', 'can_mod_post': False, 'score': 90, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {'gid_1': 2}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1622394001.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.bioinformatics', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h1&gt;ProteinBERT: A universal deep-learning model of protein sequence and function&lt;/h1&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Brandes, Nadav and Ofer, Dan and Peleg, Yam and Rappoport, Nadav and Linial, Michal&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Paper: &lt;a href=""https://www.biorxiv.org/content/10.1101/2021.05.24.445464v1""&gt;https://www.biorxiv.org/content/10.1101/2021.05.24.445464v1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;TL;DR:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Deep learning language models (like BERT in NLP) but for proteins!  &lt;/p&gt;\n\n&lt;p&gt;We trained a model on over 100 million proteins to predict their sequence and GO annotations (i.e their functions and properties). We show ~SOTA performance on a wide range of benchmarks. Our model is much smaller and faster than comparable works (TAPE, ESM), and is quite interpretable thanks to our global attention. We provide the pretrained models and code, in a simple Keras/Tensorflow Python package.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Code &amp;amp; pretrained models:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://github.com/nadavbra/protein_bert""&gt;https://github.com/nadavbra/protein_bert&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m one of the authors, AMA! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 2, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}], 'awarders': [], 'media_only': False, 'link_flair_template_id': '12168aa0-7f51-11e4-8866-22000b3396c4', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0x', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'no76jp', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'ddofer', 'discussion_type': None, 'num_comments': 36, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/bioinformatics/comments/no76jp/proteinbert_a_universal_deeplearning_model_of/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/bioinformatics/comments/no76jp/proteinbert_a_universal_deeplearning_model_of/', 'subreddit_subscribers': 65776, 'created_utc': 1622365201.0, 'num_crossposts': 7, 'media': None, 'is_video': False}]",t3_no76jp,,,,,
,deeplearning,,t2_72ljbbrh,False,,0,False,What percentage of accuracy has been reached in CIFAR10 using only a multi-layer perceptron ?,[],r/deeplearning,False,6,,0,,False,t3_no747x,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622393698.0,text,6,,,text,self.deeplearning,False,,,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,no747x,True,,march__08,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/no747x/what_percentage_of_accuracy_has_been_reached_in/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/no747x/what_percentage_of_accuracy_has_been_reached_in/,66147,1622364898.0,0,,False,,,,,,,
,deeplearning,"Hi. In order to understand how much does a particular component of a new architecture help in generalisation one can perform an ablation study. 

What are some requirements one needs to satisfy for the study to be valid?

Let's say I have an architecture A with new components A_1 and A_2. Should I train A-A_1 and A-A_2 independently and then compare their performance with A ? Or should I train A , remove A_1 to compare the performance between A and A - A_1? And likewise for the comparison between A and A-A_2.

Someone has asked a similar question on [stackexchange](https://stats.stackexchange.com/questions/380040/what-is-an-ablation-study-and-is-there-a-systematic-way-to-perform-it) but I could not get a definitive answer there. Please help!",t2_1j22sdtp,False,,0,False,How to do a proper ablation study?,[],r/deeplearning,False,6,,0,,False,t3_nnvtv5,False,dark,0.79,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1622349489.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi. In order to understand how much does a particular component of a new architecture help in generalisation one can perform an ablation study. &lt;/p&gt;

&lt;p&gt;What are some requirements one needs to satisfy for the study to be valid?&lt;/p&gt;

&lt;p&gt;Let&amp;#39;s say I have an architecture A with new components A_1 and A_2. Should I train A-A_1 and A-A_2 independently and then compare their performance with A ? Or should I train A , remove A_1 to compare the performance between A and A - A_1? And likewise for the comparison between A and A-A_2.&lt;/p&gt;

&lt;p&gt;Someone has asked a similar question on &lt;a href=""https://stats.stackexchange.com/questions/380040/what-is-an-ablation-study-and-is-there-a-systematic-way-to-perform-it""&gt;stackexchange&lt;/a&gt; but I could not get a definitive answer there. Please help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nnvtv5,True,,captainRubik_,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nnvtv5/how_to_do_a_proper_ablation_study/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nnvtv5/how_to_do_a_proper_ablation_study/,66147,1622320689.0,1,,False,,,,,,,
,deeplearning,"«[The Modern Mathematics of Deep Learning](https://arxiv.org/pdf/2105.04026v1.pdf)» is a 78 pages paper to become a chapter in a book entitled «Theory of Deep Learning» to be published by Cambridge University Press. After usual definitions and theorems about learning, NN, optimization, approximation, generalization, VC-dimension, etc. the paper provides some math guidances about fundamental ideas in order to answer many concrete questions. Why DNN don't overfit? What is the role of depth? How DNN are overcoming the curse of dimensionality? Why does SGD succeed despite the non-convexity of the problem? Which aspects of an DNN architecture affect the performance of the models and how? Which features of data are learned by DNN? Why DNN perform as well or better than specialized numerical  tools?",t2_13c9kq,False,,0,False,[D] Nice paper showcasing many fundamental ideas on Mathematics of Deep Learning to answer concrete questions.,[],r/deeplearning,False,6,,0,,False,t3_nnhdz3,False,dark,0.96,,public,67,0,{},,False,[],,False,False,,{},,False,67,,False,False,,1622274961.0,,[],{},,True,,1622298894.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;«&lt;a href=""https://arxiv.org/pdf/2105.04026v1.pdf""&gt;The Modern Mathematics of Deep Learning&lt;/a&gt;» is a 78 pages paper to become a chapter in a book entitled «Theory of Deep Learning» to be published by Cambridge University Press. After usual definitions and theorems about learning, NN, optimization, approximation, generalization, VC-dimension, etc. the paper provides some math guidances about fundamental ideas in order to answer many concrete questions. Why DNN don&amp;#39;t overfit? What is the role of depth? How DNN are overcoming the curse of dimensionality? Why does SGD succeed despite the non-convexity of the problem? Which aspects of an DNN architecture affect the performance of the models and how? Which features of data are learned by DNN? Why DNN perform as well or better than specialized numerical  tools?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nnhdz3,True,,ClaudeCoulombe,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/nnhdz3/d_nice_paper_showcasing_many_fundamental_ideas_on/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nnhdz3/d_nice_paper_showcasing_many_fundamental_ideas_on/,66147,1622270094.0,0,,False,,,,,,,
,deeplearning,APPLE M1 vs RYZEN 5000 SERIES vs INTEL 11 GEN,t2_9a6sswcl,False,,0,False,What is the best processor for machine learning for June 2021? ¿Cuál es el mejor procesador para aprendizaje automático para junio de 2021?,[],r/deeplearning,False,6,,0,,False,t3_nnzyii,False,dark,0.55,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622363967.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;APPLE M1 vs RYZEN 5000 SERIES vs INTEL 11 GEN&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nnzyii,True,,billsan_1,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nnzyii/what_is_the_best_processor_for_machine_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nnzyii/what_is_the_best_processor_for_machine_learning/,66147,1622335167.0,0,,False,,,,,,,
,deeplearning,"I generated a call function graph(CFG) from a PE-binary using IDA. I then exported all nodes and edges into a list using python.

nodes: \[0,1,2,3,4,5, ...\]

edges: \[(0,1), (0,3), (1,3), (4,5), ...\]

I now want to use this information in a deep neural network. A [paper](https://web.njit.edu/~wangj/publications/ARTICLES/ICMLA2018.pdf) suggested that node2vec can be used for this. But how exactly do I convert those to lists into a vector for a deep neural network?",t2_8z96dun8,False,,0,False,Convert graph to vector for deep learning,[],r/deeplearning,False,6,,0,,False,t3_nnsgs1,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622338945.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I generated a call function graph(CFG) from a PE-binary using IDA. I then exported all nodes and edges into a list using python.&lt;/p&gt;

&lt;p&gt;nodes: [0,1,2,3,4,5, ...]&lt;/p&gt;

&lt;p&gt;edges: [(0,1), (0,3), (1,3), (4,5), ...]&lt;/p&gt;

&lt;p&gt;I now want to use this information in a deep neural network. A &lt;a href=""https://web.njit.edu/%7Ewangj/publications/ARTICLES/ICMLA2018.pdf""&gt;paper&lt;/a&gt; suggested that node2vec can be used for this. But how exactly do I convert those to lists into a vector for a deep neural network?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nnsgs1,True,,ijustwanttostudy123,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nnsgs1/convert_graph_to_vector_for_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nnsgs1/convert_graph_to_vector_for_deep_learning/,66147,1622310145.0,0,,False,,,,,,,
,deeplearning,"Hi Reddit,

I've been looking for some AI/Computer Vision based automated way to remove crease, wrinkles, folds, dirt from clothes in fashion images captured for ecommerce.

I did try to search for GAN based methods or Image inpainting based methods but couldn't find anything reliable. I am looking for some way to retouch the image in a way that the wrinkles/folds/crease/dirt on the clothes could be removed.

I could find few websites which are doing the similar work which I require to attain programmatically but I couldn't find exactly where in computer vision to look for.

Sample Solution:  

https://imageedit.ai/   

https://retouch4.me/cleanbackdrop   

https://studiodrop.com/retouching/   


Could anyone provide me any pointers where I can look for?

Any help is highly appreciated. Thanks.",t2_93rilu9d,False,,0,False,Garments Crease/Wrinkles/Dirt Removal using Computer Visions?,[],r/deeplearning,False,6,,0,,False,t3_nnpqws,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622330782.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Reddit,&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been looking for some AI/Computer Vision based automated way to remove crease, wrinkles, folds, dirt from clothes in fashion images captured for ecommerce.&lt;/p&gt;

&lt;p&gt;I did try to search for GAN based methods or Image inpainting based methods but couldn&amp;#39;t find anything reliable. I am looking for some way to retouch the image in a way that the wrinkles/folds/crease/dirt on the clothes could be removed.&lt;/p&gt;

&lt;p&gt;I could find few websites which are doing the similar work which I require to attain programmatically but I couldn&amp;#39;t find exactly where in computer vision to look for.&lt;/p&gt;

&lt;p&gt;Sample Solution:  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://imageedit.ai/""&gt;https://imageedit.ai/&lt;/a&gt;   &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://retouch4.me/cleanbackdrop""&gt;https://retouch4.me/cleanbackdrop&lt;/a&gt;   &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://studiodrop.com/retouching/""&gt;https://studiodrop.com/retouching/&lt;/a&gt;   &lt;/p&gt;

&lt;p&gt;Could anyone provide me any pointers where I can look for?&lt;/p&gt;

&lt;p&gt;Any help is highly appreciated. Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nnpqws,True,,gpahul,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nnpqws/garments_creasewrinklesdirt_removal_using/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nnpqws/garments_creasewrinklesdirt_removal_using/,66147,1622301982.0,0,,False,,,,,,,
,deeplearning,"&amp;#x200B;

[The animation is created from a single still image](https://reddit.com/link/nnp0t9/video/lmlkoq5io2271/player)

Have you ever taken a still photo and later realized how cool it would have been to take a video instead. The authors of the ""Endless Loops"" paper got you covered. They propose a novel method that creates seamless animated loops from single images. The algorithm is able to detect periodic structures in the input images that it uses to predict a motion field for the region, and finally smoothly warps the image to produce a continuous animation loop. Read the [full explanation](https://t.me/casual_gan/44) in the Casual GAN Papers blog to find out about detecting repetitions in images, predicting the motion field and generating seamless animation loops from the flow vectors!

\[[Full Explanation Post](https://t.me/casual_gan/44)\] \[[Arxiv](https://storage.googleapis.com/ltx-public-images/Endless_Loops__Detecting_and_animating_periodic_patterns_in_still_images.pdf)\] \[[Project page](https://pub.res.lightricks.com/endless-loops/)\]

&amp;#x200B;

More recent popular computer vision paper explanations:

&gt;\[[CoModGAN](https://t.me/casual_gan/43)\]  
&gt;  
&gt;\[[GANCraft](https://t.me/casual_gan/41)\]  
&gt;  
&gt;\[[DINO](https://t.me/casual_gan/40)\]",t2_hhio3,False,,0,False,[D] Paper explained: Endless Loops: Detecting and Animating Periodic Patterns in Still Images.,[],r/deeplearning,False,6,,0,,False,t3_nnp0t9,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622328600.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://reddit.com/link/nnp0t9/video/lmlkoq5io2271/player""&gt;The animation is created from a single still image&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Have you ever taken a still photo and later realized how cool it would have been to take a video instead. The authors of the &amp;quot;Endless Loops&amp;quot; paper got you covered. They propose a novel method that creates seamless animated loops from single images. The algorithm is able to detect periodic structures in the input images that it uses to predict a motion field for the region, and finally smoothly warps the image to produce a continuous animation loop. Read the &lt;a href=""https://t.me/casual_gan/44""&gt;full explanation&lt;/a&gt; in the Casual GAN Papers blog to find out about detecting repetitions in images, predicting the motion field and generating seamless animation loops from the flow vectors!&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/44""&gt;Full Explanation Post&lt;/a&gt;] [&lt;a href=""https://storage.googleapis.com/ltx-public-images/Endless_Loops__Detecting_and_animating_periodic_patterns_in_still_images.pdf""&gt;Arxiv&lt;/a&gt;] [&lt;a href=""https://pub.res.lightricks.com/endless-loops/""&gt;Project page&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;More recent popular computer vision paper explanations:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/43""&gt;CoModGAN&lt;/a&gt;]  &lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/41""&gt;GANCraft&lt;/a&gt;]  &lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/40""&gt;DINO&lt;/a&gt;]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nnp0t9,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nnp0t9/d_paper_explained_endless_loops_detecting_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nnp0t9/d_paper_explained_endless_loops_detecting_and/,66147,1622299800.0,0,,False,,,"{'lmlkoq5io2271': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/nnp0t9/asset/lmlkoq5io2271/DASHPlaylist.mpd?a=1626449790%2CZTM2YTA0YzBkNmIzOTYwNjJjMjg2OTA3MTA4YTRiZmQ2ZmU5NmRmY2Y2M2NlNjFlOTNjYTBjOTg0N2JkZGViYg%3D%3D&amp;v=1&amp;f=sd', 'x': 1058, 'y': 1080, 'hlsUrl': 'https://v.redd.it/link/nnp0t9/asset/lmlkoq5io2271/HLSPlaylist.m3u8?a=1626449790%2CNzViNjRlNWVlYmUwYjE0OTQ3MWVjNGM0NmQwMThjMWMxZDEzNzI4NzFjY2Y3MDMzYzEwMjY4MzM3NmJiY2E5Yg%3D%3D&amp;v=1&amp;f=sd', 'id': 'lmlkoq5io2271', 'isGif': False}}",,,,
,deeplearning,Hello everyone! I'm recently working on my graduate project and my task is to have the model perform 2 tasks ( tracking and depth estimation) at the same time which is very slow. Is that combining 2 models into 1 accelerate the inference time? Thanks,t2_69zez810,False,,0,False,[D] Combine 3 models performing 3 tasks into 1 model?,[],r/deeplearning,False,6,,0,,False,t3_nnfzw6,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1622293289.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone! I&amp;#39;m recently working on my graduate project and my task is to have the model perform 2 tasks ( tracking and depth estimation) at the same time which is very slow. Is that combining 2 models into 1 accelerate the inference time? Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nnfzw6,True,,authorwong31,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/nnfzw6/d_combine_3_models_performing_3_tasks_into_1_model/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nnfzw6/d_combine_3_models_performing_3_tasks_into_1_model/,66147,1622264489.0,0,,False,,,,,,,
,deeplearning,"\[ELSA Lab\]DAVO: Dynamic Attention-based Visual Odometry

Abstract:Visual Odometry is the process of determining the position and orientation of an object by analyzing the associated camera images. Each semantic category in a frame may contribute different extents of information. For example, cars or pedestrians are usually considered as dynamic objects that may harm the performance of ego-motion estimation. Thus, DAVO dynamically adjusts the attention weights on different semantic categories based on optical flow maps by using learning based approaches such as deep convolutional neural networks (DCNNs).

Advanced detail please visit: [https://reurl.cc/ZGOpa6](https://reurl.cc/ZGOpa6)

Paper Download: [https://ieeexplore.ieee.org/document/9340890](https://ieeexplore.ieee.org/document/9340890?fbclid=IwAR1O-ioV5BjpBZ7N7nr0p8fLyi-4Z2UVp7egSUJuhmMp8VVQ6NW56OBQhiI)

Github Link: [https://github.com/elsa-lab/DAVO](https://github.com/elsa-lab/DAVO?fbclid=IwAR10Drj0eY3f6IUDMx7DLd5R_rDO9RSLEgUTQfZosk1eh86cCn7B5njG6pI)

ELSA Lab is a research laboratory focusing on Deep Reinforcement Learning, Intelligent Robotics, and Computer Vision. Please visit our website: [https://elsalab.ai/](https://elsalab.ai/?fbclid=IwAR1b9_FbzWzB877yzE71miOKYWEjV1q8_vKSAOVeclMH2J3hOoZR1YfrKZM)",t2_86tudln0,False,,0,False,DAVO: Dynamic Attention-based Visual Odometry,[],r/deeplearning,False,6,,0,,False,t3_nnhwlm,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1622351138.0,,[],{},,True,,1622301171.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[ELSA Lab]DAVO: Dynamic Attention-based Visual Odometry&lt;/p&gt;

&lt;p&gt;Abstract:Visual Odometry is the process of determining the position and orientation of an object by analyzing the associated camera images. Each semantic category in a frame may contribute different extents of information. For example, cars or pedestrians are usually considered as dynamic objects that may harm the performance of ego-motion estimation. Thus, DAVO dynamically adjusts the attention weights on different semantic categories based on optical flow maps by using learning based approaches such as deep convolutional neural networks (DCNNs).&lt;/p&gt;

&lt;p&gt;Advanced detail please visit: &lt;a href=""https://reurl.cc/ZGOpa6""&gt;https://reurl.cc/ZGOpa6&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Paper Download: &lt;a href=""https://ieeexplore.ieee.org/document/9340890?fbclid=IwAR1O-ioV5BjpBZ7N7nr0p8fLyi-4Z2UVp7egSUJuhmMp8VVQ6NW56OBQhiI""&gt;https://ieeexplore.ieee.org/document/9340890&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Github Link: &lt;a href=""https://github.com/elsa-lab/DAVO?fbclid=IwAR10Drj0eY3f6IUDMx7DLd5R_rDO9RSLEgUTQfZosk1eh86cCn7B5njG6pI""&gt;https://github.com/elsa-lab/DAVO&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ELSA Lab is a research laboratory focusing on Deep Reinforcement Learning, Intelligent Robotics, and Computer Vision. Please visit our website: &lt;a href=""https://elsalab.ai/?fbclid=IwAR1b9_FbzWzB877yzE71miOKYWEjV1q8_vKSAOVeclMH2J3hOoZR1YfrKZM""&gt;https://elsalab.ai/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nnhwlm,True,,ElsaLab,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nnhwlm/davo_dynamic_attentionbased_visual_odometry/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nnhwlm/davo_dynamic_attentionbased_visual_odometry/,66147,1622272371.0,0,,False,,,,,,,
,deeplearning,"An IEEE team proposes AngularGrad — a novel optimization algorithm that takes both gradient direction and angular information into consideration. The method successfully reduces the zig-zag effect in the optimization trajectory and speeds up convergence. 

Here is a quick read: [New IEEE Research Equips Gradient Descent with Angular Information to Boost DNN Training.](https://syncedreview.com/2021/05/28/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-29/)

The paper *AngularGrad: A New Optimization Technique for Angular Convergence of Convolutional Neural Networks* is on [arXiv](https://arxiv.org/abs/2105.10190).",t2_2fv4yodo,False,,0,False,[R] New IEEE Research Equips Gradient Descent with Angular Information to Boost DNN Training,[],r/deeplearning,False,6,,0,,False,t3_nmzurg,False,dark,0.83,,public,15,0,{},,False,[],,False,False,,{},,False,15,,False,False,,False,,[],{},,True,,1622243194.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;An IEEE team proposes AngularGrad — a novel optimization algorithm that takes both gradient direction and angular information into consideration. The method successfully reduces the zig-zag effect in the optimization trajectory and speeds up convergence. &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/28/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-29/""&gt;New IEEE Research Equips Gradient Descent with Angular Information to Boost DNN Training.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;AngularGrad: A New Optimization Technique for Angular Convergence of Convolutional Neural Networks&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.10190""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nmzurg,True,,Yuqing7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nmzurg/r_new_ieee_research_equips_gradient_descent_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nmzurg/r_new_ieee_research_equips_gradient_descent_with/,66147,1622214394.0,0,,False,,,,,,,
,deeplearning,,t2_cdtk5xxo,False,,0,False,Sexual assault in AI community,[],r/deeplearning,False,6,,0,,False,t3_nmx47v,False,dark,0.62,,public,5,0,"{'content': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;Walter Lasecki assaulted me. He pinned me against a bar, he put his hand up my skirt and his fingers in my underwear. He grabbed and twisted. He leaned in and insisted that I sleep with him. “It could be innocent,” he said.&lt;/p&gt;&amp;mdash; Geneviève Patterson (@genevievemp) &lt;a href=""https://twitter.com/genevievemp/status/1397916604285915140?ref_src=twsrc%5Etfw""&gt;May 27, 2021&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'width': 350, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'twitter.com', 'oembed': {'provider_url': 'https://twitter.com', 'version': '1.0', 'url': 'https://twitter.com/genevievemp/status/1397916604285915140', 'author_name': 'Geneviève Patterson', 'height': None, 'width': 350, 'html': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;Walter Lasecki assaulted me. He pinned me against a bar, he put his hand up my skirt and his fingers in my underwear. He grabbed and twisted. He leaned in and insisted that I sleep with him. “It could be innocent,” he said.&lt;/p&gt;&amp;mdash; Geneviève Patterson (@genevievemp) &lt;a href=""https://twitter.com/genevievemp/status/1397916604285915140?ref_src=twsrc%5Etfw""&gt;May 27, 2021&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'author_url': 'https://twitter.com/genevievemp', 'provider_name': 'Twitter', 'cache_age': 3153600000, 'type': 'rich'}}",False,False,,"{'content': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;Walter Lasecki assaulted me. He pinned me against a bar, he put his hand up my skirt and his fingers in my underwear. He grabbed and twisted. He leaned in and insisted that I sleep with him. “It could be innocent,” he said.&lt;/p&gt;&amp;mdash; Geneviève Patterson (@genevievemp) &lt;a href=""https://twitter.com/genevievemp/status/1397916604285915140?ref_src=twsrc%5Etfw""&gt;May 27, 2021&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'width': 350, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nmx47v', 'height': 200}",,False,5,,False,False,,False,,[],{},,False,,1622234957.0,text,6,,,text,twitter.com,False,,,,,https://twitter.com/genevievemp/status/1397916604285915140?s=09,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nmx47v,True,,church_turing,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nmx47v/sexual_assault_in_ai_community/,all_ads,False,https://twitter.com/genevievemp/status/1397916604285915140?s=09,66147,1622206157.0,0,"{'type': 'twitter.com', 'oembed': {'provider_url': 'https://twitter.com', 'version': '1.0', 'url': 'https://twitter.com/genevievemp/status/1397916604285915140', 'author_name': 'Geneviève Patterson', 'height': None, 'width': 350, 'html': '&lt;blockquote class=""twitter-video""&gt;&lt;p lang=""en"" dir=""ltr""&gt;Walter Lasecki assaulted me. He pinned me against a bar, he put his hand up my skirt and his fingers in my underwear. He grabbed and twisted. He leaned in and insisted that I sleep with him. “It could be innocent,” he said.&lt;/p&gt;&amp;mdash; Geneviève Patterson (@genevievemp) &lt;a href=""https://twitter.com/genevievemp/status/1397916604285915140?ref_src=twsrc%5Etfw""&gt;May 27, 2021&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""&gt;&lt;/script&gt;\n', 'author_url': 'https://twitter.com/genevievemp', 'provider_name': 'Twitter', 'cache_age': 3153600000, 'type': 'rich'}}",False,,,,,,,
,deeplearning,,t2_7zbfn18b,False,,0,False,"Deep Learning Market Trends, Sales Revenue, Industry Growth, Development Status, Top Leaders, Future Plans and Opportunity Assessment 2025",[],r/deeplearning,False,6,,0,,False,t3_nmuvis,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1622226792.0,text,6,,,text,millioninsights.com,False,,,,,https://www.millioninsights.com/industry-reports/deep-learning-market/request-sample?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=sunilR_28May21,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nmuvis,True,,Josephscott2504,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nmuvis/deep_learning_market_trends_sales_revenue/,all_ads,False,https://www.millioninsights.com/industry-reports/deep-learning-market/request-sample?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=sunilR_28May21,66147,1622197992.0,0,,False,,,,,,,
,deeplearning,,t2_ac8xe4ig,False,,0,False,[R] From Motor Control to Team Play in Simulated Humanoid Football (Soccer),[],r/deeplearning,False,6,,0,,False,t3_nmtvsn,False,dark,0.71,,public,3,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KHMwq9pv7mg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'From Motor Control to Team Play in Simulated Humanoid Football', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KHMwq9pv7mg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Ali Eslami', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/KHMwq9pv7mg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC-WsRFO3YBEKjmceuTT2gxQ'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KHMwq9pv7mg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nmtvsn', 'height': 200}",,False,3,,False,False,,False,,[],{},,False,,1622222582.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=KHMwq9pv7mg,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nmtvsn,True,,MLJunkie,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nmtvsn/r_from_motor_control_to_team_play_in_simulated/,all_ads,False,https://www.youtube.com/watch?v=KHMwq9pv7mg,66147,1622193782.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'From Motor Control to Team Play in Simulated Humanoid Football', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KHMwq9pv7mg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Ali Eslami', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/KHMwq9pv7mg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC-WsRFO3YBEKjmceuTT2gxQ'}}",False,,,,,,,
,deeplearning,"A team from Cornell University and NTT Research proposes Physical Neural Networks (PNNs), a universal framework that leverages a backpropagation algorithm to train arbitrary, real physical systems to execute deep neural networks.

Here is a quick read: [Cornell &amp; NTT’s Physical Neural Networks: a “Radical Alternative for Implementing Deep Neural Networks” That Enables Arbitrary Physical Systems Training.](https://syncedreview.com/2021/05/27/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-28/)

The paper *Deep Physical Neural Networks Enabled by a Backpropagation Algorithm for Arbitrary Physical Systems* is on [arXiv](https://arxiv.org/abs/2104.13386).",t2_2fv4yodo,False,,0,False,[R] Cornell &amp; NTT’s Physical Neural Networks: a “Radical Alternative for Implementing Deep Neural Networks” That Enables Arbitrary Physical Systems Training,[],r/deeplearning,False,6,,0,,False,t3_nmacqd,False,dark,0.95,,public,20,0,{},,False,[],,False,False,,{},,False,20,,False,False,,False,,[],{},,True,,1622159158.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A team from Cornell University and NTT Research proposes Physical Neural Networks (PNNs), a universal framework that leverages a backpropagation algorithm to train arbitrary, real physical systems to execute deep neural networks.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/27/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-28/""&gt;Cornell &amp;amp; NTT’s Physical Neural Networks: a “Radical Alternative for Implementing Deep Neural Networks” That Enables Arbitrary Physical Systems Training.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Deep Physical Neural Networks Enabled by a Backpropagation Algorithm for Arbitrary Physical Systems&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2104.13386""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nmacqd,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nmacqd/r_cornell_ntts_physical_neural_networks_a_radical/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nmacqd/r_cornell_ntts_physical_neural_networks_a_radical/,66147,1622130358.0,0,,False,,,,,,,
,deeplearning,,t2_63ay634e,False,,0,False,State of the art in multi-object tracking from Amazon researchers!,[],r/deeplearning,False,6,,0,,False,t3_nmf979,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1622172071.0,text,6,,,text,self.LatestInML,False,,,,,/r/LatestInML/comments/nmf8kx/state_of_the_art_in_multiobject_tracking_from/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nmf979,True,,cv2020br,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nmf979/state_of_the_art_in_multiobject_tracking_from/,all_ads,False,/r/LatestInML/comments/nmf8kx/state_of_the_art_in_multiobject_tracking_from/,66147,1622143271.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper](https://www.catalyzex.com/paper/arxiv:2105.11595)\n\nhttps://reddit.com/link/nmf8kx/video/4aeffme3rp171/player\n\n👇 Free extension to get code for ML papers (❤️'d by Andrew Ng) Chrome: https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil\n\nFirefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_63ay634e', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'State of the art in multi-object tracking from Amazon researchers!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'4aeffme3rp171': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/nmf8kx/asset/4aeffme3rp171/DASHPlaylist.mpd?a=1626449790%2CMWI2MzczNjhiYTQ2NzBiZWM3YTBlZTlhNzIzZDg0ZmM0NmFmMzhjNzliODcyZjMwYWFhYjMyNTMxNzY1MzY5Nw%3D%3D&amp;v=1&amp;f=sd', 'x': 320, 'y': 180, 'hlsUrl': 'https://v.redd.it/link/nmf8kx/asset/4aeffme3rp171/HLSPlaylist.m3u8?a=1626449790%2CY2Y3NWExZmE3ZDM5YWI5NDI4NGE2MTRmOWMyZjUwMjgwZGFlMGU1NjBhMWMwOTNkZGVjMWNjZDRjZDg5NTk0NA%3D%3D&amp;v=1&amp;f=sd', 'id': '4aeffme3rp171', 'isGif': False}}, 'name': 't3_nmf8kx', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.86, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 24, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 24, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1622172025.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2105.11595""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/nmf8kx/video/4aeffme3rp171/player""&gt;https://reddit.com/link/nmf8kx/video/4aeffme3rp171/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39;d by Andrew Ng) Chrome: &lt;a href=""https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nmf8kx', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'cv2020br', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/nmf8kx/state_of_the_art_in_multiobject_tracking_from/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/nmf8kx/state_of_the_art_in_multiobject_tracking_from/', 'subreddit_subscribers': 7049, 'created_utc': 1622143225.0, 'num_crossposts': 6, 'media': None, 'is_video': False}]",t3_nmf8kx,,,,,
,deeplearning,"Hi everyone,
I'm currently working as a DS in a small company. We're dealing mainly in web search and recommendation areas.
We want to start utilizing DL for ranking and CTR calculations, and we're debating on which DL framework would suit us best.

The most important thing for us is fast inference. We tried googling for benchmarks comparison but we found inconclusive results (everyone agrees that the low level APIs have the potential to be faster, but between them every comparison favours different framework). 
Other things that we care about include training time, development time, debugging complexity and flexibility in building the model. While these things are important, inference time is a necessary condition for our product. 

Does anyone have experience with the different frameworks and can help us understand which direction we should go? 

Thanks a lot in advance!",t2_3gsxa2jq,False,,0,False,DL framework inference speed comparisons,[],r/deeplearning,False,6,,0,,False,t3_nmbpuo,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1622162815.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,
I&amp;#39;m currently working as a DS in a small company. We&amp;#39;re dealing mainly in web search and recommendation areas.
We want to start utilizing DL for ranking and CTR calculations, and we&amp;#39;re debating on which DL framework would suit us best.&lt;/p&gt;

&lt;p&gt;The most important thing for us is fast inference. We tried googling for benchmarks comparison but we found inconclusive results (everyone agrees that the low level APIs have the potential to be faster, but between them every comparison favours different framework). 
Other things that we care about include training time, development time, debugging complexity and flexibility in building the model. While these things are important, inference time is a necessary condition for our product. &lt;/p&gt;

&lt;p&gt;Does anyone have experience with the different frameworks and can help us understand which direction we should go? &lt;/p&gt;

&lt;p&gt;Thanks a lot in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nmbpuo,True,,johnRalphio33,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nmbpuo/dl_framework_inference_speed_comparisons/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nmbpuo/dl_framework_inference_speed_comparisons/,66147,1622134015.0,0,,False,,,,,,,
,deeplearning,,t2_5lzf2ci4,False,,0,False,Tutorial: Real-time YOLOv3 on a Laptop Using Sparse Quantization,[],r/deeplearning,False,6,,0,,False,t3_nll3ce,False,dark,0.99,,public,133,2,{},,False,[],"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/j1f0yi39rh171/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1250, 'scrubber_media_url': 'https://v.redd.it/j1f0yi39rh171/DASH_96.mp4', 'dash_url': 'https://v.redd.it/j1f0yi39rh171/DASHPlaylist.mpd?a=1626449790%2CNTNkMGIyMzk0YjQyNzA2NzI1Mjg4MWM0YzVkYzNhYWI1MGZjZDNiNTM4NTBhMTNkOTJkZWIzNGFkYzBhMTNkMA%3D%3D&amp;v=1&amp;f=sd', 'duration': 10, 'hls_url': 'https://v.redd.it/j1f0yi39rh171/HLSPlaylist.m3u8?a=1626449790%2COWI4NDQxZTZhNWQ3ZTZmMjk5NTBlMDJhY2Q2NDg3ZGEzNTEyZTliMjJkOTI1MzdiYjM1MjNiZmYzOTlmMjljNQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': True, 'transcoding_status': 'completed'}}",True,False,,{},,False,133,,False,False,,False,,[],{},,False,,1622075260.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/j1f0yi39rh171,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nll3ce,True,,markurtz,,13,True,all_ads,False,[],False,,/r/deeplearning/comments/nll3ce/tutorial_realtime_yolov3_on_a_laptop_using_sparse/,all_ads,False,https://v.redd.it/j1f0yi39rh171,66147,1622046460.0,0,"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/j1f0yi39rh171/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1250, 'scrubber_media_url': 'https://v.redd.it/j1f0yi39rh171/DASH_96.mp4', 'dash_url': 'https://v.redd.it/j1f0yi39rh171/DASHPlaylist.mpd?a=1626449790%2CNTNkMGIyMzk0YjQyNzA2NzI1Mjg4MWM0YzVkYzNhYWI1MGZjZDNiNTM4NTBhMTNkOTJkZWIzNGFkYzBhMTNkMA%3D%3D&amp;v=1&amp;f=sd', 'duration': 10, 'hls_url': 'https://v.redd.it/j1f0yi39rh171/HLSPlaylist.m3u8?a=1626449790%2COWI4NDQxZTZhNWQ3ZTZmMjk5NTBlMDJhY2Q2NDg3ZGEzNTEyZTliMjJkOTI1MzdiYjM1MjNiZmYzOTlmMjljNQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': True, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,"Hey, so, I'm a developer but no experience/knowledge in AI/Deeplearning/MachineLearning subject.

Still, as far as I know, it is kinda ""brute force"" trial and error til it finds a logical path.

And my doubt is: is there a way to, out of a bunch of inputs, and a specific result, having the machine find out what's the math formula in use?",t2_5setgrow,False,,0,False,Find out a formula,[],r/deeplearning,False,6,,0,,False,t3_nmdr43,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622168143.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey, so, I&amp;#39;m a developer but no experience/knowledge in AI/Deeplearning/MachineLearning subject.&lt;/p&gt;

&lt;p&gt;Still, as far as I know, it is kinda &amp;quot;brute force&amp;quot; trial and error til it finds a logical path.&lt;/p&gt;

&lt;p&gt;And my doubt is: is there a way to, out of a bunch of inputs, and a specific result, having the machine find out what&amp;#39;s the math formula in use?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nmdr43,True,,Chapoletada,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nmdr43/find_out_a_formula/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nmdr43/find_out_a_formula/,66147,1622139343.0,0,,False,,,,,,,
,deeplearning,Hello! Can anyone guide me to a tutorial or article explaining  variational convolutional autoencoder on RGB images! All the tutorials of VAEs i came across are trained on mnist images which are 1 dimensional and i want to train on cityscapes images dataset which are RGB images! Thanks in Advance,t2_22p7upb5,False,,0,False,Tutorial hunting,[],r/deeplearning,False,6,,0,,False,t3_nm49sj,False,dark,0.67,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1622139459.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello! Can anyone guide me to a tutorial or article explaining  variational convolutional autoencoder on RGB images! All the tutorials of VAEs i came across are trained on mnist images which are 1 dimensional and i want to train on cityscapes images dataset which are RGB images! Thanks in Advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nm49sj,True,,Accurate_Tale,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nm49sj/tutorial_hunting/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nm49sj/tutorial_hunting/,66147,1622110659.0,0,,False,,,,,,,
,deeplearning,"This new paper MLP-Mixer talks about the inductive Biases of CNNs and Transformers for Vision tasks and tries to draw a conclusion to the data size limit after which the models go past their inductive barriers and move towards generalization.  


This paper was published in CVPR 21 by google brain from the same folks who published the paper ""An Image is Worth 16x16 Words""  


  
Annotated paper link: [https://au1206.github.io/annotated%20paper/mlp\_mixer/](https://au1206.github.io/annotated%20paper/mlp_mixer/)  
Github Link: [https://github.com/au1206/paper\_annotations/blob/master/mlp\_mixer.pdf](https://github.com/au1206/paper_annotations/blob/master/mlp_mixer.pdf)  


Feel free to download and read along. Happy learning",t2_qxkg2,False,,0,False,Annotated Paper: MLP-Mixer An all-MLP Architecture for Vision,[],r/deeplearning,False,6,,0,,False,t3_nm5yzo,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622146107.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This new paper MLP-Mixer talks about the inductive Biases of CNNs and Transformers for Vision tasks and tries to draw a conclusion to the data size limit after which the models go past their inductive barriers and move towards generalization.  &lt;/p&gt;

&lt;p&gt;This paper was published in CVPR 21 by google brain from the same folks who published the paper &amp;quot;An Image is Worth 16x16 Words&amp;quot;  &lt;/p&gt;

&lt;p&gt;Annotated paper link: &lt;a href=""https://au1206.github.io/annotated%20paper/mlp_mixer/""&gt;https://au1206.github.io/annotated%20paper/mlp_mixer/&lt;/a&gt;&lt;br/&gt;
Github Link: &lt;a href=""https://github.com/au1206/paper_annotations/blob/master/mlp_mixer.pdf""&gt;https://github.com/au1206/paper_annotations/blob/master/mlp_mixer.pdf&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;Feel free to download and read along. Happy learning&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nm5yzo,True,,au1206,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nm5yzo/annotated_paper_mlpmixer_an_allmlp_architecture/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nm5yzo/annotated_paper_mlpmixer_an_allmlp_architecture/,66147,1622117307.0,0,,False,,,,,,,
,deeplearning,"Has anyone worked on TTS?
If yes, please help me to choose between the following two

[View Poll](https://www.reddit.com/poll/nm5fqq)",t2_4mfaukjg,False,,0,False,Confused between two models for Text to speech application,[],r/deeplearning,False,6,,0,,False,t3_nm5fqq,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622144142.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Has anyone worked on TTS?
If yes, please help me to choose between the following two&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.reddit.com/poll/nm5fqq""&gt;View Poll&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nm5fqq,True,,omkar_veng,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nm5fqq/confused_between_two_models_for_text_to_speech/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nm5fqq/confused_between_two_models_for_text_to_speech/,66147,1622115342.0,0,,False,,,,,"{'user_won_amount': None, 'tournament_id': None, 'voting_end_timestamp': 1622720142622, 'options': [{'text': ""Nvidia's Pytorch implementation (Tacotron 2 + WaveGlow)"", 'vote_count': 16, 'id': '8200232'}, {'text': ""Deepmind's Tensorflow implementation (Tacotron 2 + WaveNet)"", 'vote_count': 14, 'id': '8200233'}], 'user_selection': None, 'is_prediction': False, 'resolved_option_id': None, 'total_vote_count': 30, 'total_stake_amount': None}",,
,deeplearning,"I captured a drone protocol and filtered it.

The following hex array is the result. Each line is one packet.

My question is: Which command influences which bytes how?

This is what I did and what I need the details for:

1. Rotate left
2. Rotate right
3. Ascend
4. Descend
5. Move left
6. Move right
7. Move forward
8. Move backwards

I looked into it and it seems that using the values separated the way shown here, they are connected to each other.

So there is not a single value representing an action.

But it could be separated in a wrong way and some values have to be seen together.

It looks like this(excerpt):

    63 63 0A 00 00 0B 00 66 00 00 00 00 00 00 00 00 00 99
    63 63 0A 00 00 0B 00 66 80 80 80 80 80 80 80 04 84 99
    63 63 0A 00 00 0B 00 66 80 80 80 80 80 80 80 04 84 99
    63 63 0A 00 00 0B 00 66 80 80 80 79 80 80 80 04 7D 99
    .....

See the rest at [https://pastebin.com/ZxVpaWBM](https://pastebin.com/ZxVpaWBM)",t2_30leyc02,False,,0,False,Protocol analysis - Which command influences which bytes how?,[],r/deeplearning,False,6,,0,,False,t3_nm4w25,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1622113472.0,,[],{},,True,,1622142043.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I captured a drone protocol and filtered it.&lt;/p&gt;

&lt;p&gt;The following hex array is the result. Each line is one packet.&lt;/p&gt;

&lt;p&gt;My question is: Which command influences which bytes how?&lt;/p&gt;

&lt;p&gt;This is what I did and what I need the details for:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Rotate left&lt;/li&gt;
&lt;li&gt;Rotate right&lt;/li&gt;
&lt;li&gt;Ascend&lt;/li&gt;
&lt;li&gt;Descend&lt;/li&gt;
&lt;li&gt;Move left&lt;/li&gt;
&lt;li&gt;Move right&lt;/li&gt;
&lt;li&gt;Move forward&lt;/li&gt;
&lt;li&gt;Move backwards&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I looked into it and it seems that using the values separated the way shown here, they are connected to each other.&lt;/p&gt;

&lt;p&gt;So there is not a single value representing an action.&lt;/p&gt;

&lt;p&gt;But it could be separated in a wrong way and some values have to be seen together.&lt;/p&gt;

&lt;p&gt;It looks like this(excerpt):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;63 63 0A 00 00 0B 00 66 00 00 00 00 00 00 00 00 00 99
63 63 0A 00 00 0B 00 66 80 80 80 80 80 80 80 04 84 99
63 63 0A 00 00 0B 00 66 80 80 80 80 80 80 80 04 84 99
63 63 0A 00 00 0B 00 66 80 80 80 79 80 80 80 04 7D 99
.....
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;See the rest at &lt;a href=""https://pastebin.com/ZxVpaWBM""&gt;https://pastebin.com/ZxVpaWBM&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nm4w25,True,,Caspar_Ostermann,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nm4w25/protocol_analysis_which_command_influences_which/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nm4w25/protocol_analysis_which_command_influences_which/,66147,1622113243.0,0,,False,,,,,,,
,deeplearning,"Hi. I am contemplating my next PC configuration. Currently, I am using an old enterprise server with 2x 8-core Intel Xeon E5-2600v1 and 192 GB of DDR3 RAM. This machine has no GPU, which is what I am primarily looking to rectify in the new PC.

I am considering two alternatives:

a) a pre-built gaming PC with Ryzen 3600x 6 core, RTX 3070, and 48GB of DDR4 RAM (\~2000 USD).

b) buying the RTX 3070 card separately and pairing it with a dual LGA-2011 DDR3 motherboard, 2x Intel e5-2687w v2 (3.4 GHz 8 core), and my 192 GB of DDR3 RAM.

The cost is going to be roughly the same, provided I can source the NVIDIA card without much premium over retail.

The CPUs are going to be more or less comparable on single-threaded performance, I think. However, I will have more cores on the dual-Xeon machine. I can upgrade to a 16 core Ryzen processor down the line that will outperform the Xeons, but that's another $1000 right there, and that Ryzen processor still has only 24 PCI lanes (compared to 40 lanes each for the Xeons).

My biggest concern is the amount of RAM. Even if I upgrade to more DDR4 in the future, at most I can put 128GB in a Ryzen board (+$450) vs. the 192 GB of ""free"" DDR3 RAM I already have and the headroom to add more cheap eBay-sourced DDR3 if I need to).

The question I have is how much RAM do I really need to do BERT/NLP type work, relying on PyTorch, Keras, and similar libraries. Currently, my memory load routinely goes up to 100GB during CPU computation but usually not more than that. Should I expect a lower RAM load, doing computation on the GPU? Or should I expect it to be roughly the same?

Do you think having more than 128GB is unnecessary for most tasks and the benefits of going to newer overall hardware outweigh the freedom of having more RAM and more PCI lanes?

Anything else I should factor into my decision? Thank you!",t2_58q7utb2,False,,0,False,Need input on configuring an ML PC,[],r/deeplearning,False,6,,0,,False,t3_nm1731,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1622125529.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi. I am contemplating my next PC configuration. Currently, I am using an old enterprise server with 2x 8-core Intel Xeon E5-2600v1 and 192 GB of DDR3 RAM. This machine has no GPU, which is what I am primarily looking to rectify in the new PC.&lt;/p&gt;

&lt;p&gt;I am considering two alternatives:&lt;/p&gt;

&lt;p&gt;a) a pre-built gaming PC with Ryzen 3600x 6 core, RTX 3070, and 48GB of DDR4 RAM (~2000 USD).&lt;/p&gt;

&lt;p&gt;b) buying the RTX 3070 card separately and pairing it with a dual LGA-2011 DDR3 motherboard, 2x Intel e5-2687w v2 (3.4 GHz 8 core), and my 192 GB of DDR3 RAM.&lt;/p&gt;

&lt;p&gt;The cost is going to be roughly the same, provided I can source the NVIDIA card without much premium over retail.&lt;/p&gt;

&lt;p&gt;The CPUs are going to be more or less comparable on single-threaded performance, I think. However, I will have more cores on the dual-Xeon machine. I can upgrade to a 16 core Ryzen processor down the line that will outperform the Xeons, but that&amp;#39;s another $1000 right there, and that Ryzen processor still has only 24 PCI lanes (compared to 40 lanes each for the Xeons).&lt;/p&gt;

&lt;p&gt;My biggest concern is the amount of RAM. Even if I upgrade to more DDR4 in the future, at most I can put 128GB in a Ryzen board (+$450) vs. the 192 GB of &amp;quot;free&amp;quot; DDR3 RAM I already have and the headroom to add more cheap eBay-sourced DDR3 if I need to).&lt;/p&gt;

&lt;p&gt;The question I have is how much RAM do I really need to do BERT/NLP type work, relying on PyTorch, Keras, and similar libraries. Currently, my memory load routinely goes up to 100GB during CPU computation but usually not more than that. Should I expect a lower RAM load, doing computation on the GPU? Or should I expect it to be roughly the same?&lt;/p&gt;

&lt;p&gt;Do you think having more than 128GB is unnecessary for most tasks and the benefits of going to newer overall hardware outweigh the freedom of having more RAM and more PCI lanes?&lt;/p&gt;

&lt;p&gt;Anything else I should factor into my decision? Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nm1731,True,,sharsenij14,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/nm1731/need_input_on_configuring_an_ml_pc/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nm1731/need_input_on_configuring_an_ml_pc/,66147,1622096729.0,0,,False,,,,,,,
,deeplearning," Hi people, I'm trying to get a result of my orientation relative to a pictured object using neural networks.

So I have taken a few thousand pictures from 4 angles (0, 90 180 and 270 degrees). This is to be my dataset. Now I want my neural network to then determine from which of those 4 angles the picture was taken.

I have looked at YOLO but that seems more catered towards object detection.

Any and all advice, pointers or links are welcome. Cheers!",t2_z6v6b,False,,0,False,[Question] Which network do you suggest for determining orientation relative to an object?,[],r/deeplearning,False,6,,0,,False,t3_nm3uts,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622137628.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi people, I&amp;#39;m trying to get a result of my orientation relative to a pictured object using neural networks.&lt;/p&gt;

&lt;p&gt;So I have taken a few thousand pictures from 4 angles (0, 90 180 and 270 degrees). This is to be my dataset. Now I want my neural network to then determine from which of those 4 angles the picture was taken.&lt;/p&gt;

&lt;p&gt;I have looked at YOLO but that seems more catered towards object detection.&lt;/p&gt;

&lt;p&gt;Any and all advice, pointers or links are welcome. Cheers!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nm3uts,True,,YoloTeabaggins,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nm3uts/question_which_network_do_you_suggest_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nm3uts/question_which_network_do_you_suggest_for/,66147,1622108828.0,0,,False,,,,,,,
,deeplearning,,t2_7geadqbk,False,,0,False,DataScience Digest — 26.05.21,[],r/deeplearning,False,6,,0,,False,t3_nm32xd,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1622134037.0,text,6,,,text,datasciencedigest.net,False,,,,,https://datasciencedigest.net/tpost/m5vsbyemy1-datascience-digest-260521,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nm32xd,True,,DataScienceDigest,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nm32xd/datascience_digest_260521/,all_ads,False,https://datasciencedigest.net/tpost/m5vsbyemy1-datascience-digest-260521,66147,1622105237.0,0,,False,,,,,,,
,deeplearning,"I was looking for a face detection model in opencv and found several different models. I am confused about their naming conventions and how they are different from each other.

* res10\_300x300\_ssd\_iter\_140000.caffemodel
* pose\_iter\_102000.caffemodel
* pose\_iter\_116000.caffemodel
* pose\_iter\_160000.caffemodel

...",t2_7sngffyv,False,,0,False,Can someone please guide me on these different Caffe models?,[],r/deeplearning,False,6,,0,,False,t3_nm23u8,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622129602.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was looking for a face detection model in opencv and found several different models. I am confused about their naming conventions and how they are different from each other.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;res10_300x300_ssd_iter_140000.caffemodel&lt;/li&gt;
&lt;li&gt;pose_iter_102000.caffemodel&lt;/li&gt;
&lt;li&gt;pose_iter_116000.caffemodel&lt;/li&gt;
&lt;li&gt;pose_iter_160000.caffemodel&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;...&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nm23u8,True,,_ikv,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nm23u8/can_someone_please_guide_me_on_these_different/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nm23u8/can_someone_please_guide_me_on_these_different/,66147,1622100802.0,0,,False,,,,,,,
,deeplearning,,t2_8qp6bxjs,False,,0,False,What is the best free deep-learning-based OCR service or app to extract the book list from this attached image?,[],r/deeplearning,False,6,,0,,False,t3_nluxrg,False,dark,0.83,,public,4,0,{},,False,[],,True,False,,{},,False,4,,False,False,,False,,[],{},,False,,1622102174.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/m6vqzjx477151.jpg,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nluxrg,True,,Neck_Dismal,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/nluxrg/what_is_the_best_free_deeplearningbased_ocr/,all_ads,False,https://i.redd.it/m6vqzjx477151.jpg,66147,1622073374.0,0,,False,,,,,,,
,deeplearning,"A research team from UC Davis, Microsoft Research and Johns Hopkins University extends work on training massive amounts of linguistic data to reveal the grammatical structures in their representations to the domain of mathematical reasoning, showing that both the standard transformer and the TP-Transformer can compose the meanings of mathematical symbols based on their structured relationships.

Here is a quick read: [Study Shows Transformers Possess the Compositionality Power for Mathematical Reasoning.](https://syncedreview.com/2021/05/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-27/)

The paper *Compositional Processing Emerges in Neural Networks Solving Math Problems* is on [arXiv](https://arxiv.org/abs/2105.08961).",t2_2fv4yodo,False,,0,False,[R] Study Shows Transformers Possess the Compositionality Power for Mathematical Reasoning,[],r/deeplearning,False,6,,0,,False,t3_nljkw1,False,dark,0.88,,public,11,1,{},,False,[],,False,False,,{},,False,11,,False,False,,False,,[],{},,True,,1622071287.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from UC Davis, Microsoft Research and Johns Hopkins University extends work on training massive amounts of linguistic data to reveal the grammatical structures in their representations to the domain of mathematical reasoning, showing that both the standard transformer and the TP-Transformer can compose the meanings of mathematical symbols based on their structured relationships.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-27/""&gt;Study Shows Transformers Possess the Compositionality Power for Mathematical Reasoning.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Compositional Processing Emerges in Neural Networks Solving Math Problems&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.08961""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nljkw1,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nljkw1/r_study_shows_transformers_possess_the/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nljkw1/r_study_shows_transformers_possess_the/,66147,1622042487.0,0,,False,,,,,,,
,deeplearning,"In regression scene, if the label distribution is like :

[label distribution](https://preview.redd.it/7lqy80os5l171.png?width=548&amp;format=png&amp;auto=webp&amp;s=6d2afeb1e6d6cbb81b4814c021174edbf4d10a89)

And I choise MSE as loss funtion, and here is the prediction value distribution:

[prediction distribution](https://preview.redd.it/1zao8fp85l171.png?width=746&amp;format=png&amp;auto=webp&amp;s=46022c00ec6dd14a688d2ecc50a6c72bec2cac4b)

It looks they are not very fitting,

is there any ways to improve it?",t2_5trl3fv6,False,,0,False,Problem about label distribution,[],r/deeplearning,False,6,,0,,False,t3_nlyxvf,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622116334.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In regression scene, if the label distribution is like :&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/7lqy80os5l171.png?width=548&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6d2afeb1e6d6cbb81b4814c021174edbf4d10a89""&gt;label distribution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And I choise MSE as loss funtion, and here is the prediction value distribution:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/1zao8fp85l171.png?width=746&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=46022c00ec6dd14a688d2ecc50a6c72bec2cac4b""&gt;prediction distribution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It looks they are not very fitting,&lt;/p&gt;

&lt;p&gt;is there any ways to improve it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nlyxvf,True,,bytedance_sh,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nlyxvf/problem_about_label_distribution/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nlyxvf/problem_about_label_distribution/,66147,1622087534.0,0,,False,,,"{'7lqy80os5l171': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 68, 'x': 108, 'u': 'https://preview.redd.it/7lqy80os5l171.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=aaac664b00ccd39d2b8aeb9453a3860ad8998df4'}, {'y': 137, 'x': 216, 'u': 'https://preview.redd.it/7lqy80os5l171.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=73e0f90afa24264c1923decf0d1fdcf5617aff15'}, {'y': 203, 'x': 320, 'u': 'https://preview.redd.it/7lqy80os5l171.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9a4015cbd6941c7434606067d65dca26cb572c1b'}], 's': {'y': 348, 'x': 548, 'u': 'https://preview.redd.it/7lqy80os5l171.png?width=548&amp;format=png&amp;auto=webp&amp;s=6d2afeb1e6d6cbb81b4814c021174edbf4d10a89'}, 'id': '7lqy80os5l171'}, '1zao8fp85l171': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 69, 'x': 108, 'u': 'https://preview.redd.it/1zao8fp85l171.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0668f6ed5755194e5d7720d6c6567f0159ffd174'}, {'y': 138, 'x': 216, 'u': 'https://preview.redd.it/1zao8fp85l171.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=56db2adf15869fce7f3d02e18ab6179b0a489d93'}, {'y': 204, 'x': 320, 'u': 'https://preview.redd.it/1zao8fp85l171.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2c0c53114d9f7a27b232b1e4620b3b5cff292b1f'}, {'y': 409, 'x': 640, 'u': 'https://preview.redd.it/1zao8fp85l171.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=11a1b147ca3de9d7890358db3d3f2ef69fbaa35b'}], 's': {'y': 477, 'x': 746, 'u': 'https://preview.redd.it/1zao8fp85l171.png?width=746&amp;format=png&amp;auto=webp&amp;s=46022c00ec6dd14a688d2ecc50a6c72bec2cac4b'}, 'id': '1zao8fp85l171'}}",,,,
,deeplearning,I work on computer vision (mostly object recognition and detection) projects. But these projects I do for my academic research. I want to move from academic research to industrial research. How to prepare for the interviews? Where can I find content to prepare for the interview? What contents should I prepare?,t2_cu3r9v,False,,0,False,[D] Where can I find content to prepare for Computer Vision interview? Or What contents should I prepare?,[],r/deeplearning,False,6,,0,,False,t3_nlj7f9,False,dark,0.91,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1622070322.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I work on computer vision (mostly object recognition and detection) projects. But these projects I do for my academic research. I want to move from academic research to industrial research. How to prepare for the interviews? Where can I find content to prepare for the interview? What contents should I prepare?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nlj7f9,True,,SAbdusSamad,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/nlj7f9/d_where_can_i_find_content_to_prepare_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nlj7f9/d_where_can_i_find_content_to_prepare_for/,66147,1622041522.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,"What is the state of AI in computer vision? This article is about a paper that openly shares everything about deep nets for vision applications, their successes, and the limitations we have to address. I think it is extremely interesting, accurate, and up-to-date.",[],r/deeplearning,False,6,,0,,False,t3_nljpes,False,dark,0.6,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1622071627.0,text,6,,,text,louisbouchard.ai,False,,,,,https://www.louisbouchard.ai/ai-in-computer-vision/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nljpes,True,,OnlyProggingForFun,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nljpes/what_is_the_state_of_ai_in_computer_vision_this/,all_ads,False,https://www.louisbouchard.ai/ai-in-computer-vision/,66147,1622042827.0,0,,False,,,,,,,
,deeplearning,"Hi,

I've found that I struggle to know when to apply each architecture based on the use case, other than the big ""Use CNN for Image tasks"" I struggle to define a network for my problem.

Are there rules of thumb or good ways to know when to use which architecture? Or how to create an architecture?

Obviously, I know the answer is ""it depends"" but I'm looking for a thought framework on how to approach a ML problem using NN.

Thanks",t2_4luizwuh,False,,0,False,[D] Neural network architectures to use case mapping,[],r/deeplearning,False,6,,0,,False,t3_nlndq0,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1622081110.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve found that I struggle to know when to apply each architecture based on the use case, other than the big &amp;quot;Use CNN for Image tasks&amp;quot; I struggle to define a network for my problem.&lt;/p&gt;

&lt;p&gt;Are there rules of thumb or good ways to know when to use which architecture? Or how to create an architecture?&lt;/p&gt;

&lt;p&gt;Obviously, I know the answer is &amp;quot;it depends&amp;quot; but I&amp;#39;m looking for a thought framework on how to approach a ML problem using NN.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nlndq0,True,,the_travelo_,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nlndq0/d_neural_network_architectures_to_use_case_mapping/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nlndq0/d_neural_network_architectures_to_use_case_mapping/,66147,1622052310.0,0,,False,,,,,,,
,deeplearning,"I'd like trying to move a project from my local machine to some cloud service to be able to work on it from anywhere.

I'm unsure how to go about it, since my dataset is relatively large (\~ 600K images / 50GB right now) and growing. I anticipate 10x that in the long term.

Am I right to assume that I can just upload/publish it to Kaggle and then use it there? Is this reasonable?

&amp;#x200B;

Bonus questions: What is the CPU performance like? For how long can you let a notebook run?

On my current machine (i5-2500K + 1070) training is CPU bound, since I'm doing image-augmentation on the fly and my model is pretty small (\~50K params). I usually train for 2-10h.",t2_3qj0400d,False,,0,False,Kaggle vs Colab for big datasets,[],r/deeplearning,False,6,,0,,False,t3_nlcbmd,False,dark,0.85,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,1622021274.0,,[],{},,True,,1622048321.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;d like trying to move a project from my local machine to some cloud service to be able to work on it from anywhere.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m unsure how to go about it, since my dataset is relatively large (~ 600K images / 50GB right now) and growing. I anticipate 10x that in the long term.&lt;/p&gt;

&lt;p&gt;Am I right to assume that I can just upload/publish it to Kaggle and then use it there? Is this reasonable?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Bonus questions: What is the CPU performance like? For how long can you let a notebook run?&lt;/p&gt;

&lt;p&gt;On my current machine (i5-2500K + 1070) training is CPU bound, since I&amp;#39;m doing image-augmentation on the fly and my model is pretty small (~50K params). I usually train for 2-10h.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nlcbmd,True,,Single_Blueberry,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nlcbmd/kaggle_vs_colab_for_big_datasets/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nlcbmd/kaggle_vs_colab_for_big_datasets/,66147,1622019521.0,0,,False,,,,,,,
,deeplearning,"I recently just got into deep learning and have been on the fence for a PC build for a while now. These are the specs i will be going with:

my budget will not exceed $3500(all other PC components included)

Ryzen 9 5950x

Rtx 3090

32 gb ram

is this combination of specs the best for this price? Is there anything i am missing? what would you rather opt for and this is totally out of topic but why are high end pc builds needed anyways? We already have virtual deep learning machines made by companies like google and amazon. that offer much better services?",t2_8qp7rsco,False,,0,False,Deep learning PC build.,[],r/deeplearning,False,6,,0,,False,t3_nlnpgv,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622081968.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I recently just got into deep learning and have been on the fence for a PC build for a while now. These are the specs i will be going with:&lt;/p&gt;

&lt;p&gt;my budget will not exceed $3500(all other PC components included)&lt;/p&gt;

&lt;p&gt;Ryzen 9 5950x&lt;/p&gt;

&lt;p&gt;Rtx 3090&lt;/p&gt;

&lt;p&gt;32 gb ram&lt;/p&gt;

&lt;p&gt;is this combination of specs the best for this price? Is there anything i am missing? what would you rather opt for and this is totally out of topic but why are high end pc builds needed anyways? We already have virtual deep learning machines made by companies like google and amazon. that offer much better services?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nlnpgv,True,,Hot-Vermicelli9242,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nlnpgv/deep_learning_pc_build/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nlnpgv/deep_learning_pc_build/,66147,1622053168.0,0,,False,,,,,,,
,deeplearning,"Large Scale Image Completion via Co-Modulated Generative Adversarial Networks (ICLR 2021 Spotlight)

Is it true that all existing methods fail to inpaint large-scale missing regions? The authors of CoModGAN claim that it is impossible to complete an object that is missing a large part unless the model is able to generate a completely new object of that kind, and propose a novel GAN architecture that bridges the gap between image-conditional and unconditional generators, which enables it to generate very convincing complete images from inputs with large portions masked out.

Continue reading about co-modulation and paired/unpaired inception discriminative score in [the full paper explanation in the casual GANs channel](https://t.me/casual_gan/43).

[Samples from the model](https://preview.redd.it/5aqn5vji3h171.png?width=1548&amp;format=png&amp;auto=webp&amp;s=e141197eed3c72b741e8768e01a9b2efc665c34b)

\[[Full Explanation Post](https://t.me/casual_gan/43)\] \[[Arxiv](https://openreview.net/pdf?id=sSjqmfsk95O)\] \[[Code](https://github.com/zsyzzsoft/co-mod-gan)\]  
More recent popular computer vision paper explanations:  
\[[GANCraft](https://t.me/casual_gan/41)\]  
\[[DINO](https://t.me/casual_gan/40)\]  
\[[MLP-mixer](https://t.me/casual_gan/35)\]",t2_hhio3,False,,0,False,[D] Paper explained - Large Scale Image Completion via Co-Modulated Generative Adversarial Networks. Finally solving large region inpainting!,[],r/deeplearning,False,6,,0,,False,t3_nli1k2,False,dark,0.66,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1622067252.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Large Scale Image Completion via Co-Modulated Generative Adversarial Networks (ICLR 2021 Spotlight)&lt;/p&gt;

&lt;p&gt;Is it true that all existing methods fail to inpaint large-scale missing regions? The authors of CoModGAN claim that it is impossible to complete an object that is missing a large part unless the model is able to generate a completely new object of that kind, and propose a novel GAN architecture that bridges the gap between image-conditional and unconditional generators, which enables it to generate very convincing complete images from inputs with large portions masked out.&lt;/p&gt;

&lt;p&gt;Continue reading about co-modulation and paired/unpaired inception discriminative score in &lt;a href=""https://t.me/casual_gan/43""&gt;the full paper explanation in the casual GANs channel&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/5aqn5vji3h171.png?width=1548&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e141197eed3c72b741e8768e01a9b2efc665c34b""&gt;Samples from the model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/43""&gt;Full Explanation Post&lt;/a&gt;] [&lt;a href=""https://openreview.net/pdf?id=sSjqmfsk95O""&gt;Arxiv&lt;/a&gt;] [&lt;a href=""https://github.com/zsyzzsoft/co-mod-gan""&gt;Code&lt;/a&gt;]&lt;br/&gt;
More recent popular computer vision paper explanations:&lt;br/&gt;
[&lt;a href=""https://t.me/casual_gan/41""&gt;GANCraft&lt;/a&gt;]&lt;br/&gt;
[&lt;a href=""https://t.me/casual_gan/40""&gt;DINO&lt;/a&gt;]&lt;br/&gt;
[&lt;a href=""https://t.me/casual_gan/35""&gt;MLP-mixer&lt;/a&gt;]&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nli1k2,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nli1k2/d_paper_explained_large_scale_image_completion/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nli1k2/d_paper_explained_large_scale_image_completion/,66147,1622038452.0,0,,False,,,"{'5aqn5vji3h171': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 93, 'x': 108, 'u': 'https://preview.redd.it/5aqn5vji3h171.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=00996aed588b52271823414772e1ecddba28d666'}, {'y': 187, 'x': 216, 'u': 'https://preview.redd.it/5aqn5vji3h171.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d4cec51a4ed24d27afd15ac929890b3f9c99b029'}, {'y': 278, 'x': 320, 'u': 'https://preview.redd.it/5aqn5vji3h171.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1e354e1e5cb8a0b2e882f3543904a7d5c9bcb9b5'}, {'y': 556, 'x': 640, 'u': 'https://preview.redd.it/5aqn5vji3h171.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b96f70a5c8b6f86665c0b8f86ac1061e7b62dca7'}, {'y': 834, 'x': 960, 'u': 'https://preview.redd.it/5aqn5vji3h171.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ea9e4c513edd48cd4ecc3d648287f093dea859e6'}, {'y': 939, 'x': 1080, 'u': 'https://preview.redd.it/5aqn5vji3h171.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9cdbea1cab2305fe84a32c1af690294c36db387a'}], 's': {'y': 1346, 'x': 1548, 'u': 'https://preview.redd.it/5aqn5vji3h171.png?width=1548&amp;format=png&amp;auto=webp&amp;s=e141197eed3c72b741e8768e01a9b2efc665c34b'}, 'id': '5aqn5vji3h171'}}",,,,
,deeplearning,[https://youtu.be/0TouyDNzEEY](https://youtu.be/0TouyDNzEEY),t2_357rx0k0,False,,0,False,"AI Weekly Update - May 26th, 2021 (#32!)",[],r/deeplearning,False,6,,0,,False,t3_nlmw9v,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622079867.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://youtu.be/0TouyDNzEEY""&gt;https://youtu.be/0TouyDNzEEY&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nlmw9v,True,,HenryAILabs,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nlmw9v/ai_weekly_update_may_26th_2021_32/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nlmw9v/ai_weekly_update_may_26th_2021_32/,66147,1622051067.0,0,,False,,,,,,,
,deeplearning,"Hello all,

I was wondering if I could get some help with a problem I am currently struggling with. I am trying to train a CNN to learn 5D (kind of) data. The data is such: it has three spatial dimensions \[x,y,z\] but then it also has two ""internal dimensions"" \[theta,phi\] at each \[x,y,z\]. What I am trying to do is upsample the internal space from fewer \[theta,phi\] data points.

When I train a 2d residual network with random \[x,y,z\] points in just the internal space it learns -- but there is some noise in the x,y,z space, there should be correlation with neighbouring points. What I wanted was some way to also include convolutions over the 3D \[x,y,z\] space to try remedy this.

A possible but maybe naive approach is to do the following:Stack the images as \[theta \* phi, x, y, z\]  (so many input channels) and then have some 3d convolution layers, then after that stack as \[x \* y \* z, theta, phi\] and take 2d convolutions in the internal space.

Another approach is to use 5d filters that span over all dimensions. This might be hard to implement for me and probably very memory hungry.

Were there any other ways?  Thanks!",t2_cc4iglef,False,,0,False,Need help figuring out 5D architecture for CNN,[],r/deeplearning,False,6,,0,,False,t3_nl5hqh,False,dark,0.93,,public,12,0,{},,False,[],,False,False,,{},,False,12,,False,False,,1621993860.0,,[],{},,True,,1622022442.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all,&lt;/p&gt;

&lt;p&gt;I was wondering if I could get some help with a problem I am currently struggling with. I am trying to train a CNN to learn 5D (kind of) data. The data is such: it has three spatial dimensions [x,y,z] but then it also has two &amp;quot;internal dimensions&amp;quot; [theta,phi] at each [x,y,z]. What I am trying to do is upsample the internal space from fewer [theta,phi] data points.&lt;/p&gt;

&lt;p&gt;When I train a 2d residual network with random [x,y,z] points in just the internal space it learns -- but there is some noise in the x,y,z space, there should be correlation with neighbouring points. What I wanted was some way to also include convolutions over the 3D [x,y,z] space to try remedy this.&lt;/p&gt;

&lt;p&gt;A possible but maybe naive approach is to do the following:Stack the images as [theta * phi, x, y, z]  (so many input channels) and then have some 3d convolution layers, then after that stack as [x * y * z, theta, phi] and take 2d convolutions in the internal space.&lt;/p&gt;

&lt;p&gt;Another approach is to use 5d filters that span over all dimensions. This might be hard to implement for me and probably very memory hungry.&lt;/p&gt;

&lt;p&gt;Were there any other ways?  Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nl5hqh,True,,uz_hu,,20,True,all_ads,False,[],False,,/r/deeplearning/comments/nl5hqh/need_help_figuring_out_5d_architecture_for_cnn/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nl5hqh/need_help_figuring_out_5d_architecture_for_cnn/,66147,1621993642.0,0,,False,,,,,,,
,deeplearning,"I have an object detection notebook here. Link to note book: [https://colab.research.google.com/drive/1g6m7gCEBRlDU04UqDjF-gQH-UV4xpjpf?usp=sharing](https://colab.research.google.com/drive/1g6m7gCEBRlDU04UqDjF-gQH-UV4xpjpf?usp=sharing)  
I would like to change the optimizer, the epoch, and the batch size.   
I'm having trouble understanding because I've only worked with keras.   
It would be great if someone can just point out what I have to change.",t2_1ijstjs7,False,,0,False,Help needed to make some changes.,[],r/deeplearning,False,6,,0,,False,t3_nlizko,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622069772.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have an object detection notebook here. Link to note book: &lt;a href=""https://colab.research.google.com/drive/1g6m7gCEBRlDU04UqDjF-gQH-UV4xpjpf?usp=sharing""&gt;https://colab.research.google.com/drive/1g6m7gCEBRlDU04UqDjF-gQH-UV4xpjpf?usp=sharing&lt;/a&gt;&lt;br/&gt;
I would like to change the optimizer, the epoch, and the batch size.&lt;br/&gt;
I&amp;#39;m having trouble understanding because I&amp;#39;ve only worked with keras.&lt;br/&gt;
It would be great if someone can just point out what I have to change.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nlizko,True,,salmanc2,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nlizko/help_needed_to_make_some_changes/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nlizko/help_needed_to_make_some_changes/,66147,1622040972.0,0,,False,,,,,,,
,deeplearning," hello, can you recommend deep learning tools similar to google vision AI to extract text from images, thanks",t2_c8f9ylzw,False,,0,False,deep learning tools,[],r/deeplearning,False,6,,0,,False,t3_nlhb3l,False,dark,0.43,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622065239.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;hello, can you recommend deep learning tools similar to google vision AI to extract text from images, thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nlhb3l,True,,dev_palma,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nlhb3l/deep_learning_tools/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nlhb3l/deep_learning_tools/,66147,1622036439.0,0,,False,,,,,,,
,deeplearning,"Hi guys, I'm data science student and i'm working on deep learning project using Mask r cnn repository but today, when i import keras (2.3.0, mandatory) on google colab, i get this error:

    AttributeError: module 'tensorflow._api.v1.compat.v2' has no attribute '__internal__'
    
    my tensorflow version (mandatory) is 1.14.0

How can i fix it? Thanks all.",t2_3zwz9769,False,,0,False,AttributeError: module 'tensorflow._api.v1.compat.v2' has no attribute '__internal__' GOOGLE COLAB,[],r/deeplearning,False,6,,0,,False,t3_nlhap0,False,dark,0.43,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622065209.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, I&amp;#39;m data science student and i&amp;#39;m working on deep learning project using Mask r cnn repository but today, when i import keras (2.3.0, mandatory) on google colab, i get this error:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AttributeError: module &amp;#39;tensorflow._api.v1.compat.v2&amp;#39; has no attribute &amp;#39;__internal__&amp;#39;

my tensorflow version (mandatory) is 1.14.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How can i fix it? Thanks all.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nlhap0,True,,Dario_Della,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nlhap0/attributeerror_module_tensorflow_apiv1compatv2/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nlhap0/attributeerror_module_tensorflow_apiv1compatv2/,66147,1622036409.0,0,,False,,,,,,,
,deeplearning," hello, can you recommend deep learning tools similar to google vision AI to extract text from images, thanks",t2_c8f9ylzw,False,,0,False,deep learning tools,[],r/deeplearning,False,6,,0,,False,t3_nlhaa4,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622065175.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;hello, can you recommend deep learning tools similar to google vision AI to extract text from images, thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nlhaa4,True,,dev_palma,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nlhaa4/deep_learning_tools/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nlhaa4/deep_learning_tools/,66147,1622036375.0,0,,False,,,,,,,
,deeplearning,"This tutorial covers all of the concepts and background required to understand time series forecasting for stock price prediction. This is the first part in a two-part series, where Part 2 will be covering a complete and intuitive example of how you can build your own stock market price prediction model from scratch (namely a stacked LSTM model).

Topics covered include:

* Introduction
* Why do we require time series analysis?
* Essential components of time series analysis such as trend, seasonality, irregularity, and cyclicity
* Understanding stationary and non-stationary series
* Understanding LSTMs in detail
* When not to use time series analysis
* Conclusion

Article link: [https://blog.paperspace.com/forecasting-stock-prices-using-deep-learning/](https://blog.paperspace.com/forecasting-stock-prices-using-deep-learning/)",t2_15en0l,False,,0,False,[Article] Stock Price Prediction Using Deep Learning,[],r/deeplearning,False,6,,0,,False,t3_nlicph,False,dark,0.25,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1622068076.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This tutorial covers all of the concepts and background required to understand time series forecasting for stock price prediction. This is the first part in a two-part series, where Part 2 will be covering a complete and intuitive example of how you can build your own stock market price prediction model from scratch (namely a stacked LSTM model).&lt;/p&gt;

&lt;p&gt;Topics covered include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Introduction&lt;/li&gt;
&lt;li&gt;Why do we require time series analysis?&lt;/li&gt;
&lt;li&gt;Essential components of time series analysis such as trend, seasonality, irregularity, and cyclicity&lt;/li&gt;
&lt;li&gt;Understanding stationary and non-stationary series&lt;/li&gt;
&lt;li&gt;Understanding LSTMs in detail&lt;/li&gt;
&lt;li&gt;When not to use time series analysis&lt;/li&gt;
&lt;li&gt;Conclusion&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Article link: &lt;a href=""https://blog.paperspace.com/forecasting-stock-prices-using-deep-learning/""&gt;https://blog.paperspace.com/forecasting-stock-prices-using-deep-learning/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nlicph,True,,hellopaperspace,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nlicph/article_stock_price_prediction_using_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nlicph/article_stock_price_prediction_using_deep_learning/,66147,1622039276.0,0,,False,,,,,,,
,deeplearning,"A research team from the University of Montreal and Max Planck Institute for Intelligent Systems constructs a reinforcement learning agent whose knowledge and reward function can be reused across tasks, along with an attention mechanism that dynamically selects unchangeable knowledge pieces to enable out-of-distribution adaptation and generalization.

Here is a quick read: [Yoshua Bengio Team’s Recurrent Independent Mechanisms Endow RL Agents With Out-of-Distribution Adaptation and Generalization Abilities.](https://syncedreview.com/2021/05/25/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-26/)

The paper *Fast and Slow Learning of Recurrent Independent Mechanisms* is on [arXiv](https://arxiv.org/abs/2105.08710).",t2_2fv4yodo,False,,0,False,[R] Yoshua Bengio Team’s Recurrent Independent Mechanisms Endow RL Agents With Out-of-Distribution Adaptation and Generalization Abilities,[],r/deeplearning,False,6,,0,,False,t3_nkse9o,False,dark,0.89,,public,22,0,{},,False,[],,False,False,,{},,False,22,,False,False,,False,,[],{},,True,,1621985227.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from the University of Montreal and Max Planck Institute for Intelligent Systems constructs a reinforcement learning agent whose knowledge and reward function can be reused across tasks, along with an attention mechanism that dynamically selects unchangeable knowledge pieces to enable out-of-distribution adaptation and generalization.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/25/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-26/""&gt;Yoshua Bengio Team’s Recurrent Independent Mechanisms Endow RL Agents With Out-of-Distribution Adaptation and Generalization Abilities.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Fast and Slow Learning of Recurrent Independent Mechanisms&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.08710""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkse9o,True,,Yuqing7,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nkse9o/r_yoshua_bengio_teams_recurrent_independent/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nkse9o/r_yoshua_bengio_teams_recurrent_independent/,66147,1621956427.0,0,,False,,,,,,,
,deeplearning,,t2_oupz3m9,False,,0,False,I made this video explaining how BERT is trained with next sentence prediction,[],r/deeplearning,False,6,,0,,False,t3_nkrzkr,False,dark,0.82,,public,14,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/1gN1snKBLP0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How BERT Next Sentence Prediction Works (With PyTorch)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/1gN1snKBLP0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'James Briggs', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/1gN1snKBLP0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/JamesBriggs'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/1gN1snKBLP0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nkrzkr', 'height': 200}",,False,14,,False,True,,False,,[],{},,False,,1621984171.0,text,6,,,text,youtube.com,False,,,,,https://youtube.com/watch?v=1gN1snKBLP0&amp;feature=share,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkrzkr,True,,jamescalam,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nkrzkr/i_made_this_video_explaining_how_bert_is_trained/,all_ads,False,https://youtube.com/watch?v=1gN1snKBLP0&amp;feature=share,66147,1621955371.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How BERT Next Sentence Prediction Works (With PyTorch)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/1gN1snKBLP0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'James Briggs', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/1gN1snKBLP0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/JamesBriggs'}}",False,,,,,,,
,deeplearning,"Hi,

I am going through the Graph convolutional neural network paper for semisupervised label classification ([https://arxiv.org/pdf/1609.02907.pdf](https://arxiv.org/pdf/1609.02907.pdf) ).

The github repository for the same is here \[[https://github.com/tkipf/pygcn/blob/master/pygcn/train.py](https://github.com/tkipf/pygcn/blob/master/pygcn/train.py)\]

What I do not understand is how they do semi-supervised training. I see that they input all the data but train with only few examples. They at some-point mask the labels. This is the part that I am not getting. 

Should I mask all labels other than the training examples? Then what am I testing against? Can someone who has done this before please clarify?",t2_c5febi8b,False,,0,False,Can someone explain to be training process for semi-supervised classification task,[],r/deeplearning,False,6,,0,,False,t3_nl0nto,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1622007311.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I am going through the Graph convolutional neural network paper for semisupervised label classification (&lt;a href=""https://arxiv.org/pdf/1609.02907.pdf""&gt;https://arxiv.org/pdf/1609.02907.pdf&lt;/a&gt; ).&lt;/p&gt;

&lt;p&gt;The github repository for the same is here [&lt;a href=""https://github.com/tkipf/pygcn/blob/master/pygcn/train.py""&gt;https://github.com/tkipf/pygcn/blob/master/pygcn/train.py&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;What I do not understand is how they do semi-supervised training. I see that they input all the data but train with only few examples. They at some-point mask the labels. This is the part that I am not getting. &lt;/p&gt;

&lt;p&gt;Should I mask all labels other than the training examples? Then what am I testing against? Can someone who has done this before please clarify?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nl0nto,True,,popkept09,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nl0nto/can_someone_explain_to_be_training_process_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nl0nto/can_someone_explain_to_be_training_process_for/,66147,1621978511.0,1,,False,,,,,,,
,deeplearning,"I am interested in working in the field of understanding the hidden dynamics of unexplainable machine learning. But I am not really sure what is that field called. I have found someone was working in the field of statistical mechanics of deep neural network or something like that and that is probably the closest thing I was able to find.

Is it part of complex systems? Or maybe statistical physics or pure statistics? I just don't seem to find anything.

Would someone please explain what is this field called, what are the tools or technologies used to do research in that field? And if possible, then also suggest some decent places where this kind of work is done.

Please note that I am not really interested in Explainable and Interpretable Machine Learning. Or are these two fields basically same or have many things in common?

Thank you very much.

Edit: Just to make it clearer, what I am interested in is explaining 'black box' models.",t2_1722gv,False,,0,False,Unexplainable Machine Learning,[],r/deeplearning,False,6,,0,,False,t3_nktfmi,False,dark,0.76,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,1622009166.0,,[],{},,True,,1621987922.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am interested in working in the field of understanding the hidden dynamics of unexplainable machine learning. But I am not really sure what is that field called. I have found someone was working in the field of statistical mechanics of deep neural network or something like that and that is probably the closest thing I was able to find.&lt;/p&gt;

&lt;p&gt;Is it part of complex systems? Or maybe statistical physics or pure statistics? I just don&amp;#39;t seem to find anything.&lt;/p&gt;

&lt;p&gt;Would someone please explain what is this field called, what are the tools or technologies used to do research in that field? And if possible, then also suggest some decent places where this kind of work is done.&lt;/p&gt;

&lt;p&gt;Please note that I am not really interested in Explainable and Interpretable Machine Learning. Or are these two fields basically same or have many things in common?&lt;/p&gt;

&lt;p&gt;Thank you very much.&lt;/p&gt;

&lt;p&gt;Edit: Just to make it clearer, what I am interested in is explaining &amp;#39;black box&amp;#39; models.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nktfmi,True,,ShahriarTasnim,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/nktfmi/unexplainable_machine_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nktfmi/unexplainable_machine_learning/,66147,1621959122.0,0,,False,,,,,,,
,deeplearning,"Hi,
I am new to seq2seq. I was following machine translation from:
https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html
The program runs fine. But to evaluate i have to train the model again and again.
How can I save and load the model?",t2_7wron7g8,False,,0,False,Saving and loading seq2seq models,[],r/deeplearning,False,6,,0,,False,t3_nkycor,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1622000856.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,
I am new to seq2seq. I was following machine translation from:
&lt;a href=""https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html""&gt;https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html&lt;/a&gt;
The program runs fine. But to evaluate i have to train the model again and again.
How can I save and load the model?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkycor,True,,arkhamrising,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nkycor/saving_and_loading_seq2seq_models/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nkycor/saving_and_loading_seq2seq_models/,66147,1621972056.0,0,,False,,,,,,,
,deeplearning,"I've been wracking my brains on trying to do this efficiently.  I want to learn a probability distribution of a bunch of values and sample new data points from that curve

Given a numpy array/matrix of integers/floats, I want to be able to learn the probability density function of those values(per array in matrix) and sample or generate new values or columns for the matrix as per the probability distribution of that row

If possible, group similar rows in the matrix or pick a subset and then do a signal to noise kind of thing  to generate more data points as features or columns. 

Is there any prebuilt package in numpy, sklearn or scipy that allows me to achieve this or apply it to a whole matrix at a time to scale quickly?  Even if some part of this is achievable through a package that would be a huge help",t2_69fak7f,False,,0,False,Data Augmentation idea help,[],r/deeplearning,False,6,,0,,False,t3_nl59j3,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,True,,False,,[],{},,True,,1622021674.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been wracking my brains on trying to do this efficiently.  I want to learn a probability distribution of a bunch of values and sample new data points from that curve&lt;/p&gt;

&lt;p&gt;Given a numpy array/matrix of integers/floats, I want to be able to learn the probability density function of those values(per array in matrix) and sample or generate new values or columns for the matrix as per the probability distribution of that row&lt;/p&gt;

&lt;p&gt;If possible, group similar rows in the matrix or pick a subset and then do a signal to noise kind of thing  to generate more data points as features or columns. &lt;/p&gt;

&lt;p&gt;Is there any prebuilt package in numpy, sklearn or scipy that allows me to achieve this or apply it to a whole matrix at a time to scale quickly?  Even if some part of this is achievable through a package that would be a huge help&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nl59j3,True,,Nike_Zoldyck,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nl59j3/data_augmentation_idea_help/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nl59j3/data_augmentation_idea_help/,66147,1621992874.0,0,,False,,,,,,,
,deeplearning,"Introducing version 0.2 of JetBrains deep learning library, [KotlinDL](https://github.com/JetBrains/KotlinDL) 

[https://zaleslaw.medium.com/kotlin-dl-version-0-2-da2ed079f567](https://zaleslaw.medium.com/kotlin-dl-version-0-2-da2ed079f567)

KotlinDL 0.2 version (high-level deep learning library on Kotlin from JetBrains) is here: with new layers and Functional API that makes it possible for you to build and train models such as ResNet or MobileNet 

Also, a special Kotlin-idiomatic DSL for image preprocessing is included (you could rotate, shrink, resize images). 

If you are ready to contribute, there are \~ 20 new tickets with labels ""good first issue,"" ""good second issue."" https://github.com/JetBrains/KotlinDL/issues  

If you have any feature requests, feel free to create an issue or rise a question in the Discussion chapter.  

KotlinDL is built on top of the TensorFlow Java API and has an API close to Keras and other high-level frameworks like Sonnet, PyTorch Lighting, and Catalyst.   

Give a star on Github to KotlinDL if you support this project, run tutorials, taste the Kotlin with Deep Learning!",t2_99alkktj,False,,0,False,KotlinDL (Keras-like DL library at the top of TensorFlow) 0.2 from JetBrains is released,[],r/deeplearning,False,6,,0,,False,t3_nknry9,False,dark,0.84,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1621971999.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Introducing version 0.2 of JetBrains deep learning library, &lt;a href=""https://github.com/JetBrains/KotlinDL""&gt;KotlinDL&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://zaleslaw.medium.com/kotlin-dl-version-0-2-da2ed079f567""&gt;https://zaleslaw.medium.com/kotlin-dl-version-0-2-da2ed079f567&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;KotlinDL 0.2 version (high-level deep learning library on Kotlin from JetBrains) is here: with new layers and Functional API that makes it possible for you to build and train models such as ResNet or MobileNet &lt;/p&gt;

&lt;p&gt;Also, a special Kotlin-idiomatic DSL for image preprocessing is included (you could rotate, shrink, resize images). &lt;/p&gt;

&lt;p&gt;If you are ready to contribute, there are ~ 20 new tickets with labels &amp;quot;good first issue,&amp;quot; &amp;quot;good second issue.&amp;quot; &lt;a href=""https://github.com/JetBrains/KotlinDL/issues""&gt;https://github.com/JetBrains/KotlinDL/issues&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;If you have any feature requests, feel free to create an issue or rise a question in the Discussion chapter.  &lt;/p&gt;

&lt;p&gt;KotlinDL is built on top of the TensorFlow Java API and has an API close to Keras and other high-level frameworks like Sonnet, PyTorch Lighting, and Catalyst.   &lt;/p&gt;

&lt;p&gt;Give a star on Github to KotlinDL if you support this project, run tutorials, taste the Kotlin with Deep Learning!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nknry9,True,,NetHairy4282,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nknry9/kotlindl_keraslike_dl_library_at_the_top_of/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nknry9/kotlindl_keraslike_dl_library_at_the_top_of/,66147,1621943199.0,0,,False,,,,,,,
,deeplearning,"Hello, I want to build a machine translation system from English to Georgian. Georgian is a language similar (and simpler) to the Russian language. it's syntax looks like **base + suffix.**  only suffix changes, most of the time base is frozen, to describe time only suffix is changed. Unfortunately, I couldn't find a tokenizer for Georgian language, so could you link or provide useful resources to help me to build a tokenizer?",t2_3rqev321,False,,0,False,How to build a custom tokenizer,[],r/deeplearning,False,6,,0,,False,t3_nkuvok,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,1621963237.0,,[],{},,True,,1621991660.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I want to build a machine translation system from English to Georgian. Georgian is a language similar (and simpler) to the Russian language. it&amp;#39;s syntax looks like &lt;strong&gt;base + suffix.&lt;/strong&gt;  only suffix changes, most of the time base is frozen, to describe time only suffix is changed. Unfortunately, I couldn&amp;#39;t find a tokenizer for Georgian language, so could you link or provide useful resources to help me to build a tokenizer?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkuvok,True,,datonefaridze,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nkuvok/how_to_build_a_custom_tokenizer/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nkuvok/how_to_build_a_custom_tokenizer/,66147,1621962860.0,0,,False,,,,,,,
,deeplearning,"Hi, total noob in deep learning here looking for some expertise and qualified opinions. 

I was wondering if the selection of an optimizer rather depends on a specific problem setting or on the underlying network architecture which is built to solve that specific problem. 

With ""optimizer"", I am referring to the plane type of the optimizer (adam, adagrad, ...) and not on hyperparams like weight decay, lr, etc..

Opinions?",t2_jvyb4yz,False,,0,False,What influences the selection of an optimizer?,[],r/deeplearning,False,6,,0,,False,t3_nkz1i1,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1622002716.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, total noob in deep learning here looking for some expertise and qualified opinions. &lt;/p&gt;

&lt;p&gt;I was wondering if the selection of an optimizer rather depends on a specific problem setting or on the underlying network architecture which is built to solve that specific problem. &lt;/p&gt;

&lt;p&gt;With &amp;quot;optimizer&amp;quot;, I am referring to the plane type of the optimizer (adam, adagrad, ...) and not on hyperparams like weight decay, lr, etc..&lt;/p&gt;

&lt;p&gt;Opinions?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkz1i1,True,,Lavair,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nkz1i1/what_influences_the_selection_of_an_optimizer/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nkz1i1/what_influences_the_selection_of_an_optimizer/,66147,1621973916.0,0,,False,,,,,,,
,deeplearning,,t2_1568ks,False,,0,False,What Intel’s image-enhancing AI means for the gaming industry?,[],r/deeplearning,False,6,,0,,False,t3_nkpzlt,False,dark,0.6,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1621978751.0,text,6,,,text,bdtechtalks.com,False,,,,,https://bdtechtalks.com/2021/05/24/intel-ai-photorealistic-enhancement/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkpzlt,True,,bendee983,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nkpzlt/what_intels_imageenhancing_ai_means_for_the/,all_ads,False,https://bdtechtalks.com/2021/05/24/intel-ai-photorealistic-enhancement/,66147,1621949951.0,0,,False,,,,,,,
,deeplearning,"I saw that some people here are new to DL and wants to get started with DL, CV, Robotics, etc. My team has curated a roadmap on how to study these topics. 

Do go through it and let me know how it is. If you feel anything is missing raise an issue. 

https://github.com/IvLabs/resources

We also have a collection of research paper notes in related fields. Do checkout at

https://github.com/IvLabs/ResearchPaperNotes

Do star these repo if you like it. We are inviting collaborators who can contribute to these repos as well. Through this we are trying to contribute to the open source community.",t2_6gp6tywz,False,,0,False,Roadmap/Resources for getting started with DL and Robotics. (Bonus: Research Paper notes repo also included),[],r/deeplearning,False,6,,0,,False,t3_nk97lg,False,dark,0.95,,public,50,0,{},,False,[],,False,False,,{},,False,50,,False,False,,False,,[],{},,True,,1621921317.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I saw that some people here are new to DL and wants to get started with DL, CV, Robotics, etc. My team has curated a roadmap on how to study these topics. &lt;/p&gt;

&lt;p&gt;Do go through it and let me know how it is. If you feel anything is missing raise an issue. &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/IvLabs/resources""&gt;https://github.com/IvLabs/resources&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We also have a collection of research paper notes in related fields. Do checkout at&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/IvLabs/ResearchPaperNotes""&gt;https://github.com/IvLabs/ResearchPaperNotes&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Do star these repo if you like it. We are inviting collaborators who can contribute to these repos as well. Through this we are trying to contribute to the open source community.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nk97lg,True,,take2rohit,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nk97lg/roadmapresources_for_getting_started_with_dl_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nk97lg/roadmapresources_for_getting_started_with_dl_and/,66147,1621892517.0,0,,False,,,,,,,
,deeplearning,"Hello guys, I'm data science student and i would like to use Colab pro. Is it available in Italy? If not, can i subscribe to French or German Colab pro ?

Thanks all.",t2_3zwz9769,False,,0,False,GOOGLE COLAB PRO ITALY,[],r/deeplearning,False,6,,0,,False,t3_nklitr,False,dark,0.78,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1621963486.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello guys, I&amp;#39;m data science student and i would like to use Colab pro. Is it available in Italy? If not, can i subscribe to French or German Colab pro ?&lt;/p&gt;

&lt;p&gt;Thanks all.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nklitr,True,,Dario_Della,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/nklitr/google_colab_pro_italy/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nklitr/google_colab_pro_italy/,66147,1621934686.0,0,,False,,,,,,,
,deeplearning,,t2_c5febi8b,False,,0,False,Type error: “Only size-1 arrays can be converted to Python scalars”,[],r/deeplearning,False,6,,0,,False,t3_nkoc5y,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1621973828.0,text,6,,,text,self.learnprogramming,False,,,,,/r/learnprogramming/comments/nkobro/type_error_only_size1_arrays_can_be_converted_to/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkoc5y,True,,popkept09,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nkoc5y/type_error_only_size1_arrays_can_be_converted_to/,all_ads,False,/r/learnprogramming/comments/nkobro/type_error_only_size1_arrays_can_be_converted_to/,66147,1621945028.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'learnprogramming', 'selftext': ""    class GCN:\n      def __init__(self,alpha,adj,feature,hiddenlayer_neurons,output_layer_neurons):\n        self.alpha=alpha\n        self.adj=adj\n        self.feature=feature\n        self.hiddenlayer_neurons=hiddenlayer_neurons\n        self.output_layer_neurons=output_layer_neurons\n      \n      def weightlayers(self):\n        self.weights1= np.random.normal(loc=0,scale=0.5,size=(features.shape[1],self.hiddenlayer_neurons))\n        print(features.shape)\n        print(adj.shape)\n        self.weights2= np.random.normal(loc=0,scale=0.5,size=(self.hiddenlayer_neurons,self.output_layer_neurons))\n        self.bias1= np.random.normal(loc=0, scale=0.05, size=self.hiddenlayer_neurons)\n        self.bias2=np.random.normal(loc=0, scale=0.05, size= self.output_layer_neurons)\n        return self.weights1,self.weights2,self.bias1,self.bias2\n    \n      def sigmoid(self,x):\n        sigma=1/(1+np.exp(-x))\n        return sigma\n      \n      def softmax(self,inputs):\n        inputs=inputs.astype(np.float)\n        inputs=np.vectorize(inputs)\n        f=np.exp(inputs) / float(sum(np.exp(inputs)))\n        #f2 = np.vectorize(f)\n        return f\n    \n      def forwardpropagation(self):\n        self.weights1,self.weights2,self.bias1,self.bias2=self.weightlayers()\n    \n        self.bias1=(np.reshape(self.bias1,(-1,1))).T\n        self.bias2=(np.reshape(self.bias2,(-1,1))).T\n        print(self.bias1.ndim)\n        #self.sigmoid=self.sigmoid()\n        self.adj=self.adj.T\n        self.input= self.adj.dot(self.feature).dot(self.weights1) + (self.bias1)\n        print(self.input.shape)\n        self.sigmaactivation= self.sigmoid(self.input)\n        self.hiddeninput=(self.sigmaactivation @ self.weights2 ) + (self.bias2)\n        self.output=self.softmax(self.hiddeninput)\n        return self.output\n\n \n\nFor the softmax function it is throwing the above mentioned error. Following previous answers for somewhat similar question I tried to vectorize and convert it to float.But that does't seen to work.\n\nWhen I vectorize it, I get this error :\n\n    TypeError: loop of ufunc does not support"", 'author_fullname': 't2_c5febi8b', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Type error: “Only size-1 arrays can be converted to Python scalars”', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/learnprogramming', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nkobro', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1621973795.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnprogramming', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;pre&gt;&lt;code&gt;class GCN:\n  def __init__(self,alpha,adj,feature,hiddenlayer_neurons,output_layer_neurons):\n    self.alpha=alpha\n    self.adj=adj\n    self.feature=feature\n    self.hiddenlayer_neurons=hiddenlayer_neurons\n    self.output_layer_neurons=output_layer_neurons\n\n  def weightlayers(self):\n    self.weights1= np.random.normal(loc=0,scale=0.5,size=(features.shape[1],self.hiddenlayer_neurons))\n    print(features.shape)\n    print(adj.shape)\n    self.weights2= np.random.normal(loc=0,scale=0.5,size=(self.hiddenlayer_neurons,self.output_layer_neurons))\n    self.bias1= np.random.normal(loc=0, scale=0.05, size=self.hiddenlayer_neurons)\n    self.bias2=np.random.normal(loc=0, scale=0.05, size= self.output_layer_neurons)\n    return self.weights1,self.weights2,self.bias1,self.bias2\n\n  def sigmoid(self,x):\n    sigma=1/(1+np.exp(-x))\n    return sigma\n\n  def softmax(self,inputs):\n    inputs=inputs.astype(np.float)\n    inputs=np.vectorize(inputs)\n    f=np.exp(inputs) / float(sum(np.exp(inputs)))\n    #f2 = np.vectorize(f)\n    return f\n\n  def forwardpropagation(self):\n    self.weights1,self.weights2,self.bias1,self.bias2=self.weightlayers()\n\n    self.bias1=(np.reshape(self.bias1,(-1,1))).T\n    self.bias2=(np.reshape(self.bias2,(-1,1))).T\n    print(self.bias1.ndim)\n    #self.sigmoid=self.sigmoid()\n    self.adj=self.adj.T\n    self.input= self.adj.dot(self.feature).dot(self.weights1) + (self.bias1)\n    print(self.input.shape)\n    self.sigmaactivation= self.sigmoid(self.input)\n    self.hiddeninput=(self.sigmaactivation @ self.weights2 ) + (self.bias2)\n    self.output=self.softmax(self.hiddeninput)\n    return self.output\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;For the softmax function it is throwing the above mentioned error. Following previous answers for somewhat similar question I tried to vectorize and convert it to float.But that does&amp;#39;t seen to work.&lt;/p&gt;\n\n&lt;p&gt;When I vectorize it, I get this error :&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;TypeError: loop of ufunc does not support\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r7yd', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nkobro', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'popkept09', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnprogramming/comments/nkobro/type_error_only_size1_arrays_can_be_converted_to/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnprogramming/comments/nkobro/type_error_only_size1_arrays_can_be_converted_to/', 'subreddit_subscribers': 2283896, 'created_utc': 1621944995.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_nkobro,,,,,
,deeplearning,"I know there isn't an exact answer to this question but would be fun to hear some rough estimates of how much money you think it would cost to create an AI for a turn based game.

The game that made me ask this questions is Blood Bowl, which is turn based but allows you to move ""all your pieces"" before the opponents turn. The extra twist is that moving a piece often comprises performing an action with a probability of success (dice-roll) and if you fail certain actions your whole turn ends early (turnover). In short it is a game about both creating a favorable board state (like chess) and managing risk/reward, which makes traditional rules-based ""AI"" pretty terrible at the game.

So given all that I assume humanity has learned from Alpha Zero and the likes, how cheap could you create/buy a decent AI for Blood Bowl trained with machine learning? Is the price-tag still millions of dollars?

Cheers",t2_xy0cx,False,,0,False,Ballpark cost of training an AI to compete against humans in a game like chess?,[],r/deeplearning,False,6,,0,,False,t3_nkjpv1,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1621955846.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know there isn&amp;#39;t an exact answer to this question but would be fun to hear some rough estimates of how much money you think it would cost to create an AI for a turn based game.&lt;/p&gt;

&lt;p&gt;The game that made me ask this questions is Blood Bowl, which is turn based but allows you to move &amp;quot;all your pieces&amp;quot; before the opponents turn. The extra twist is that moving a piece often comprises performing an action with a probability of success (dice-roll) and if you fail certain actions your whole turn ends early (turnover). In short it is a game about both creating a favorable board state (like chess) and managing risk/reward, which makes traditional rules-based &amp;quot;AI&amp;quot; pretty terrible at the game.&lt;/p&gt;

&lt;p&gt;So given all that I assume humanity has learned from Alpha Zero and the likes, how cheap could you create/buy a decent AI for Blood Bowl trained with machine learning? Is the price-tag still millions of dollars?&lt;/p&gt;

&lt;p&gt;Cheers&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkjpv1,True,,stygger,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nkjpv1/ballpark_cost_of_training_an_ai_to_compete/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nkjpv1/ballpark_cost_of_training_an_ai_to_compete/,66147,1621927046.0,0,,False,,,,,,,
,deeplearning,"Hi,
I am new to pytorch. Everytime i run:

1) torch. Cuda. Is available  i get FALSE
2)  torch. Version shows 1.8.1+cpu
3) cuda. Gpu shows mx130 [supported] 

I Have Windows,py 3.7 Idle, Nvidia MX 130 whose Compute capability is 5.0.

Here are the steps i performed :

1) I installed cuda 11.0.2 from nvdia website
2) i extracted cudnn 8.0 and replaced cuda toolkit lib, include and bin file with cudnn's file. 

3) i did pip install Torch ==1.8.1


nvidia - smi displays
NVIDIA SMI 462.3
CUDA VERSION : 11.2",t2_7wron7g8,False,,0,False,Unable to run pytorch on gpu,[],r/deeplearning,False,6,,0,,False,t3_nkn0i0,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621969311.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,
I am new to pytorch. Everytime i run:&lt;/p&gt;

&lt;p&gt;1) torch. Cuda. Is available  i get FALSE
2)  torch. Version shows 1.8.1+cpu
3) cuda. Gpu shows mx130 [supported] &lt;/p&gt;

&lt;p&gt;I Have Windows,py 3.7 Idle, Nvidia MX 130 whose Compute capability is 5.0.&lt;/p&gt;

&lt;p&gt;Here are the steps i performed :&lt;/p&gt;

&lt;p&gt;1) I installed cuda 11.0.2 from nvdia website
2) i extracted cudnn 8.0 and replaced cuda toolkit lib, include and bin file with cudnn&amp;#39;s file. &lt;/p&gt;

&lt;p&gt;3) i did pip install Torch ==1.8.1&lt;/p&gt;

&lt;p&gt;nvidia - smi displays
NVIDIA SMI 462.3
CUDA VERSION : 11.2&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkn0i0,True,,arkhamrising,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nkn0i0/unable_to_run_pytorch_on_gpu/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nkn0i0/unable_to_run_pytorch_on_gpu/,66147,1621940511.0,0,,False,,,,,,,
,deeplearning,"I have installed TensorFlow using a virtual environment running python 3.8 as described by Apple. This should theoretically run natively and utilise the GPU. I tried installing TensorFlow using miniforge last time and it was not able to use the GPU as miniforge uses python 3.9 and Tensorflow for m1 macs currently require python 3.8.

On sklearns website, the only way to install sklearn libraries currently is by using conda install sklearn  
which is through miniforge.

Is there a way to install sklearn on a TensorFlow environment created using

    python3 -m venv TFGPU 

I have already tried pip. I was able to install most other libraries other than sklearn which I use for pre-processing.",t2_2l0l3q92,False,,0,False,How to run sklearn library with native TensorFlow on m1 mac,[],r/deeplearning,False,6,,0,,False,t3_nklsvx,False,dark,0.56,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621964685.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have installed TensorFlow using a virtual environment running python 3.8 as described by Apple. This should theoretically run natively and utilise the GPU. I tried installing TensorFlow using miniforge last time and it was not able to use the GPU as miniforge uses python 3.9 and Tensorflow for m1 macs currently require python 3.8.&lt;/p&gt;

&lt;p&gt;On sklearns website, the only way to install sklearn libraries currently is by using conda install sklearn&lt;br/&gt;
which is through miniforge.&lt;/p&gt;

&lt;p&gt;Is there a way to install sklearn on a TensorFlow environment created using&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python3 -m venv TFGPU 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I have already tried pip. I was able to install most other libraries other than sklearn which I use for pre-processing.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nklsvx,True,,d619demolish,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/nklsvx/how_to_run_sklearn_library_with_native_tensorflow/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nklsvx/how_to_run_sklearn_library_with_native_tensorflow/,66147,1621935885.0,0,,False,,,,,,,
,deeplearning," Hi,

I am currently working on a project which involves measuring the time dependance of a varying quantity with time. So I have a video and the quantity changes with time in it. Now I want to extract each frame in it (every few seconds- which is input by the user) and then apply operations on it.

So essentially I want to extract frames. Can anyone suggest how do I go about doing this? Is their an automated tool which does this? Or else how can I do this task using python code?

Any advice would be greatly appreciated

TIA!",t2_77ats1u7,False,,0,False,Extracting images from a video in python,[],r/deeplearning,False,6,,0,,False,t3_nkkb4h,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621958350.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I am currently working on a project which involves measuring the time dependance of a varying quantity with time. So I have a video and the quantity changes with time in it. Now I want to extract each frame in it (every few seconds- which is input by the user) and then apply operations on it.&lt;/p&gt;

&lt;p&gt;So essentially I want to extract frames. Can anyone suggest how do I go about doing this? Is their an automated tool which does this? Or else how can I do this task using python code?&lt;/p&gt;

&lt;p&gt;Any advice would be greatly appreciated&lt;/p&gt;

&lt;p&gt;TIA!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkkb4h,True,,HyenaDistinct9600,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nkkb4h/extracting_images_from_a_video_in_python/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nkkb4h/extracting_images_from_a_video_in_python/,66147,1621929550.0,0,,False,,,,,,,
,deeplearning,"Do you know AI researcher are trying to get rid of Batch Normalization from deep neural network ?

Check out the blog which provides in depth reasoning of why you should and shouldn't use batch normalization in networks 

[Link to the blog](https://highontechs.com/deep-learning/batch-normalization-everything-you-need-to-know/)",t2_730sjlh9,False,,0,False,Know why AI researchers are trying to get rid of batch-normalization from deep neural nets,[],r/deeplearning,False,6,,0,,False,t3_nkjgdx,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621954804.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Do you know AI researcher are trying to get rid of Batch Normalization from deep neural network ?&lt;/p&gt;

&lt;p&gt;Check out the blog which provides in depth reasoning of why you should and shouldn&amp;#39;t use batch normalization in networks &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://highontechs.com/deep-learning/batch-normalization-everything-you-need-to-know/""&gt;Link to the blog&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkjgdx,True,,Vivekvpawar,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nkjgdx/know_why_ai_researchers_are_trying_to_get_rid_of/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nkjgdx/know_why_ai_researchers_are_trying_to_get_rid_of/,66147,1621926004.0,0,,False,,,,,,,
,deeplearning,,t2_12xsye6m,False,,0,False,"Over 200 figures and diagrams of the most popular deep learning architectures and layers FREE TO USE in your blog posts, slides, presentations, or papers.",[],r/deeplearning,False,6,,0,,False,t3_njxgi2,False,dark,0.91,,public,28,1,{},,False,[],,False,False,,{},,False,28,,False,False,,False,,[],{},,False,,1621890132.0,text,6,,,text,github.com,False,,,,,https://github.com/dvgodoy/dl-visuals/,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 300, 'id': 'award_3dd248bc-3438-4c5b-98d4-24421fd6d670', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 250, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/cr1mq4yysv541_CoinGift.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/cr1mq4yysv541_CoinGift.png?width=16&amp;height=16&amp;auto=webp&amp;s=7bc7d3a9d7950d9b8bfd3fe1da96c06dbd3012c4', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/cr1mq4yysv541_CoinGift.png?width=32&amp;height=32&amp;auto=webp&amp;s=c5bcd1a05b74e7a6371c9a71399a28c492a293cb', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/cr1mq4yysv541_CoinGift.png?width=48&amp;height=48&amp;auto=webp&amp;s=a913bad178f017a572393be1fc36013a4fa59803', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/cr1mq4yysv541_CoinGift.png?width=64&amp;height=64&amp;auto=webp&amp;s=4932f5feebaec182f69be2b329ab40e82a23406f', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/cr1mq4yysv541_CoinGift.png?width=128&amp;height=128&amp;auto=webp&amp;s=eee972a9cf8852ff83b635ee7c5efbbf03bd4ecc', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': 1576887960, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Give the gift of %{coin_symbol}250 Reddit Coins.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Coin Gift', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/cr1mq4yysv541_CoinGift.png?width=16&amp;height=16&amp;auto=webp&amp;s=7bc7d3a9d7950d9b8bfd3fe1da96c06dbd3012c4', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/cr1mq4yysv541_CoinGift.png?width=32&amp;height=32&amp;auto=webp&amp;s=c5bcd1a05b74e7a6371c9a71399a28c492a293cb', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/cr1mq4yysv541_CoinGift.png?width=48&amp;height=48&amp;auto=webp&amp;s=a913bad178f017a572393be1fc36013a4fa59803', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/cr1mq4yysv541_CoinGift.png?width=64&amp;height=64&amp;auto=webp&amp;s=4932f5feebaec182f69be2b329ab40e82a23406f', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/cr1mq4yysv541_CoinGift.png?width=128&amp;height=128&amp;auto=webp&amp;s=eee972a9cf8852ff83b635ee7c5efbbf03bd4ecc', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/cr1mq4yysv541_CoinGift.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,njxgi2,True,,dvgodoy,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/njxgi2/over_200_figures_and_diagrams_of_the_most_popular/,all_ads,False,https://github.com/dvgodoy/dl-visuals/,66147,1621861332.0,0,,False,,,,,,,
,deeplearning,,t2_8zskk,False,,0,False,Disable CPU boost for long training session is a bless for Power Usage / Temperature,[],r/deeplearning,False,6,,0,,False,t3_njszsg,False,dark,0.92,,public,47,0,{},,False,[],,True,False,,{},,False,47,,False,False,,False,,[],{},,False,,1621873656.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/hx0o409w31171.png,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,njszsg,True,,kajika91,,4,False,all_ads,False,[],False,,/r/deeplearning/comments/njszsg/disable_cpu_boost_for_long_training_session_is_a/,all_ads,False,https://i.redd.it/hx0o409w31171.png,66147,1621844856.0,0,,False,,,,,,,
,deeplearning,"* Google hasn't rolled out this feature for all the videos
* You are more likely to see this feature on mobile

&amp;#x200B;

https://preview.redd.it/li6bdoj917171.jpg?width=667&amp;format=pjpg&amp;auto=webp&amp;s=e9d29d0b86e85edf47b203881dff01f4448aa3a6

I am really curious about how they split videos into sections and assign Learning Objective to each section. I couldn't find any research paper related to this.

Any insight into this will be appreciated. Thank You. :)",t2_66w37ao6,False,,0,False,The technology used by Google for KeyMoment detection when youtube videos are searched on google search engine?,[],r/deeplearning,False,6,,0,,False,t3_nkgxjl,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1621916634.0,,[],{},,True,,1621945142.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;ul&gt;
&lt;li&gt;Google hasn&amp;#39;t rolled out this feature for all the videos&lt;/li&gt;
&lt;li&gt;You are more likely to see this feature on mobile&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/li6bdoj917171.jpg?width=667&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e9d29d0b86e85edf47b203881dff01f4448aa3a6""&gt;https://preview.redd.it/li6bdoj917171.jpg?width=667&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e9d29d0b86e85edf47b203881dff01f4448aa3a6&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I am really curious about how they split videos into sections and assign Learning Objective to each section. I couldn&amp;#39;t find any research paper related to this.&lt;/p&gt;

&lt;p&gt;Any insight into this will be appreciated. Thank You. :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkgxjl,True,,sharmajiAIwale,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nkgxjl/the_technology_used_by_google_for_keymoment/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nkgxjl/the_technology_used_by_google_for_keymoment/,66147,1621916342.0,0,,False,,,"{'li6bdoj917171': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 63, 'x': 108, 'u': 'https://preview.redd.it/li6bdoj917171.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f0bc4cc215009cf03b91192c01f94eee6e96d51'}, {'y': 127, 'x': 216, 'u': 'https://preview.redd.it/li6bdoj917171.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c1017d5b3dda816597ad6c46561f649e3c3b3213'}, {'y': 189, 'x': 320, 'u': 'https://preview.redd.it/li6bdoj917171.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c7fe9392673f76528c8820b558ee432a0f4fb883'}, {'y': 379, 'x': 640, 'u': 'https://preview.redd.it/li6bdoj917171.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4f1e68bea77ce9044fb233ad235ba98ed1409fc6'}], 's': {'y': 395, 'x': 667, 'u': 'https://preview.redd.it/li6bdoj917171.jpg?width=667&amp;format=pjpg&amp;auto=webp&amp;s=e9d29d0b86e85edf47b203881dff01f4448aa3a6'}, 'id': 'li6bdoj917171'}}",,,,
,deeplearning,"Looking into training a classifier for 3D models on the ShaoeNetCore dataset. I'm coming across papers that use many different data formats, such as voxels, meshes, and renders. What data formats perform best for classification and what are some of the newest papers you can recommend that achieve SOTA performance for 3D object classification?",t2_iug84,False,,0,False,What are the current state-of-the-art methods for 3D object/mesh classification?,[],r/deeplearning,False,6,,0,,False,t3_nkgvrw,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621944976.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Looking into training a classifier for 3D models on the ShaoeNetCore dataset. I&amp;#39;m coming across papers that use many different data formats, such as voxels, meshes, and renders. What data formats perform best for classification and what are some of the newest papers you can recommend that achieve SOTA performance for 3D object classification?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkgvrw,True,,ofcervine,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nkgvrw/what_are_the_current_stateoftheart_methods_for_3d/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nkgvrw/what_are_the_current_stateoftheart_methods_for_3d/,66147,1621916176.0,0,,False,,,,,,,
,deeplearning,"Hi Guys, I have a problem statement where there is a need for fire detection which is usually handled by Computer Vision Object Detection models - YOLO, Faster R-CNN, etc. However, I was thinking about using Multimodal DL for this to take inputs from heat/thermal sensor, etc. apart from video feeds.

Any practical blog/tutorial you can point me to?

Thanks!",t2_2mmql89p,False,,0,False,Multimodal Deep Learning,[],r/deeplearning,False,6,,0,,False,t3_nkgdrt,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621943296.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi Guys, I have a problem statement where there is a need for fire detection which is usually handled by Computer Vision Object Detection models - YOLO, Faster R-CNN, etc. However, I was thinking about using Multimodal DL for this to take inputs from heat/thermal sensor, etc. apart from video feeds.&lt;/p&gt;

&lt;p&gt;Any practical blog/tutorial you can point me to?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nkgdrt,True,,grid_world,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nkgdrt/multimodal_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nkgdrt/multimodal_deep_learning/,66147,1621914496.0,0,,False,,,,,,,
,deeplearning,,t2_whtyj,False,,0,False,Deep Learning Sessions Lisbon - Recent Advances in model-based Deep Reinforcement Learning #17,[],r/deeplearning,False,6,,0,,False,t3_nk2f6e,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1621903711.0,text,6,,,text,meetup.com,False,,,,,https://www.meetup.com/pt-BR/Deep-Learning-Sessions-Lisboa/events/278319177,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nk2f6e,True,,LESSSE,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nk2f6e/deep_learning_sessions_lisbon_recent_advances_in/,all_ads,False,https://www.meetup.com/pt-BR/Deep-Learning-Sessions-Lisboa/events/278319177,66147,1621874911.0,0,,False,,,,,,,
,deeplearning," Hi guys, I'm data science student and I'm training a mask r cnn on custom dataset: 1144 images (train set) - 309 (val set), 1 class, loss: 60 - val\_loss: 45. My config:

    
    Configurations:
    BACKBONE                       resnet101
    BACKBONE_STRIDES               [4, 8, 16, 32, 64]
    BATCH_SIZE                     2
    BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]
    COMPUTE_BACKBONE_SHAPE         None
    DETECTION_MAX_INSTANCES        100
    DETECTION_MIN_CONFIDENCE       0.85
    DETECTION_NMS_THRESHOLD        0.0
    FPN_CLASSIF_FC_LAYERS_SIZE     1024
    GPU_COUNT                      1
    GRADIENT_CLIP_NORM             5.0
    IMAGES_PER_GPU                 2
    IMAGE_CHANNEL_COUNT            3
    IMAGE_MAX_DIM                  512
    IMAGE_META_SIZE                14
    IMAGE_MIN_DIM                  512
    IMAGE_MIN_SCALE                0
    IMAGE_RESIZE_MODE              none
    IMAGE_SHAPE                    [512 512   3]
    LEARNING_MOMENTUM              0.9
    LEARNING_RATE                  0.01
    LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}
    MASK_POOL_SIZE                 14
    MASK_SHAPE                     [28, 28]
    MAX_GT_INSTANCES               10
    MEAN_PIXEL                     [123.7 116.8 103.9]
    MINI_MASK_SHAPE                (56, 56)
    NAME                           object
    NUM_CLASSES                    2
    POOL_SIZE                      7
    POST_NMS_ROIS_INFERENCE        1000
    POST_NMS_ROIS_TRAINING         2000
    PRE_NMS_LIMIT                  6000
    ROI_POSITIVE_RATIO             0.33
    RPN_ANCHOR_RATIOS              [0.5, 1, 2]
    RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)
    RPN_ANCHOR_STRIDE              1
    RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]
    RPN_NMS_THRESHOLD              0.7
    RPN_TRAIN_ANCHORS_PER_IMAGE    256
    STEPS_PER_EPOCH                100
    TOP_DOWN_PYRAMID_SIZE          256
    TRAIN_BN                       False
    TRAIN_ROIS_PER_IMAGE           64
    USE_MINI_MASK                  True
    USE_RPN_ROIS                   True
    VALIDATION_STEPS               20
    WEIGHT_DECAY                   0.0001

 I tried these changes:

    Configurations:
    BACKBONE                       resnet101/50
    
    BACKBONE_STRIDES               [64,128,256,512, 1024] or [32,64,128,256,512]            
    
    IMAGE_MAX_DIM                  1024
    
    IMAGE_MIN_DIM                  1024
    
    EPOCHS                         [3, 10, 15, 25, 40]
    
    LEARNING_RATE V1             first 3 epochs 0.0001,10-15 0.0001/10, 25-40 0.0001/100
    LEARNING_RATE V2             first 3 epochs 0.0001*2,10-15 0.0001, 25-40 0.0001/5
                    
    STEPS_PER_EPOCH                100 / 20 / 10 / 500
    
    VALIDATION_STEPS              STEPS_PER_EPOCH / 4
    
    WEIGHT_DECAY                   0.0001

How can i do to improve my performance ? Thanks all.",t2_3zwz9769,False,,0,False,High loss mask r cnn training,[],r/deeplearning,False,6,,0,,False,t3_njzm6i,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621896337.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, I&amp;#39;m data science student and I&amp;#39;m training a mask r cnn on custom dataset: 1144 images (train set) - 309 (val set), 1 class, loss: 60 - val_loss: 45. My config:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Configurations:
BACKBONE                       resnet101
BACKBONE_STRIDES               [4, 8, 16, 32, 64]
BATCH_SIZE                     2
BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]
COMPUTE_BACKBONE_SHAPE         None
DETECTION_MAX_INSTANCES        100
DETECTION_MIN_CONFIDENCE       0.85
DETECTION_NMS_THRESHOLD        0.0
FPN_CLASSIF_FC_LAYERS_SIZE     1024
GPU_COUNT                      1
GRADIENT_CLIP_NORM             5.0
IMAGES_PER_GPU                 2
IMAGE_CHANNEL_COUNT            3
IMAGE_MAX_DIM                  512
IMAGE_META_SIZE                14
IMAGE_MIN_DIM                  512
IMAGE_MIN_SCALE                0
IMAGE_RESIZE_MODE              none
IMAGE_SHAPE                    [512 512   3]
LEARNING_MOMENTUM              0.9
LEARNING_RATE                  0.01
LOSS_WEIGHTS                   {&amp;#39;rpn_class_loss&amp;#39;: 1.0, &amp;#39;rpn_bbox_loss&amp;#39;: 1.0, &amp;#39;mrcnn_class_loss&amp;#39;: 1.0, &amp;#39;mrcnn_bbox_loss&amp;#39;: 1.0, &amp;#39;mrcnn_mask_loss&amp;#39;: 1.0}
MASK_POOL_SIZE                 14
MASK_SHAPE                     [28, 28]
MAX_GT_INSTANCES               10
MEAN_PIXEL                     [123.7 116.8 103.9]
MINI_MASK_SHAPE                (56, 56)
NAME                           object
NUM_CLASSES                    2
POOL_SIZE                      7
POST_NMS_ROIS_INFERENCE        1000
POST_NMS_ROIS_TRAINING         2000
PRE_NMS_LIMIT                  6000
ROI_POSITIVE_RATIO             0.33
RPN_ANCHOR_RATIOS              [0.5, 1, 2]
RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)
RPN_ANCHOR_STRIDE              1
RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]
RPN_NMS_THRESHOLD              0.7
RPN_TRAIN_ANCHORS_PER_IMAGE    256
STEPS_PER_EPOCH                100
TOP_DOWN_PYRAMID_SIZE          256
TRAIN_BN                       False
TRAIN_ROIS_PER_IMAGE           64
USE_MINI_MASK                  True
USE_RPN_ROIS                   True
VALIDATION_STEPS               20
WEIGHT_DECAY                   0.0001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I tried these changes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Configurations:
BACKBONE                       resnet101/50

BACKBONE_STRIDES               [64,128,256,512, 1024] or [32,64,128,256,512]            

IMAGE_MAX_DIM                  1024

IMAGE_MIN_DIM                  1024

EPOCHS                         [3, 10, 15, 25, 40]

LEARNING_RATE V1             first 3 epochs 0.0001,10-15 0.0001/10, 25-40 0.0001/100
LEARNING_RATE V2             first 3 epochs 0.0001*2,10-15 0.0001, 25-40 0.0001/5

STEPS_PER_EPOCH                100 / 20 / 10 / 500

VALIDATION_STEPS              STEPS_PER_EPOCH / 4

WEIGHT_DECAY                   0.0001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How can i do to improve my performance ? Thanks all.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,njzm6i,True,,Dario_Della,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/njzm6i/high_loss_mask_r_cnn_training/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/njzm6i/high_loss_mask_r_cnn_training/,66147,1621867537.0,0,,False,,,,,,,
,deeplearning,"Hi,

I am trying to train an object detection model for my custom data. While I've constructed the model and data loading, I am having some doubts over how to prepare targets and calculate the loss.

The details of the training are:

1. The problem is a binary classification task with localization.
2. I am using Yolov3 for the base model with a bit of customization for my project needs.
3. For each scale in Yolov3, I am constructing an adjacent zero tensor that is identical to the output of the model then calculating the midpoint of any objects in the image, finding out which grid cell does the midpoint belongs to, and assigning that grid cell with the necessary information about object co-ordinates and height/width. This tensor will be used as the target tensor for the scale.
4. Find which grid cells are responsible for objects then save indices for the non-zero positions.
5. Filter target and feature tensors for both objectness score and coordination regression by using the indices from step 3.
6. Reshape the features and target tensor to (-1, n), meaning no information about batch, grid cell, or anything, just plain old 1:1 comparison.
7. Calculate IOU between the predicted box and target box.
8. Object Loss is being calculated as (IOU \* Object Confidence).
9. Add to Total Loss.
10. Repeat for another scale.
11. Backprop Object Loss.

Some training shenanigans:

1. For each scale, positional weights are being calculated for object == 0 or object == 1 then negative/positive as pos\_weight for BCEWithLogitsLoss which means criterion is being created for each scale in each batch.
2. Adam Optimizer with 1e-3 LR and ReduceOnPlateau with the patience of 2 and learning rate reduction of 0.1 per step on eval\_loss. This was done because my loss stops decreasing at some point and starts increasing and I read on multiple Github issues that something like this could help but it hasn't in my case. Also, train\_loss is oscillating a lot while monitoring in Tensorboard.
3. Batch Size of 16, can go up to 256.
4. Clipping gradients to 10.

My questions are:

1. Is it okay to only assign a single grid cell for the target? I am only considering whether the grid cell ""supposed"" to detect the object is successful or not. I have gone through the paper and multiple codes from various sources and never been able to grasp how they are building targets.
2. What if the object is sufficiently large and the scale at which I am predicting is not able to fully detect it? Do I still calculate the loss for that scale?
3. I am using ""mean"" as the reduction for the BCEWithLogitsLoss but reading the paper I get the impression that they are summing over the losses which is the reduction ""sum"". Does this affect the training procedure much?
4. Before using (IOU \* Object Confidence), I was trying to train by using Object Confidence + (1 - IOU) or MSE\_Loss(IOU, 1). When using this formulation, the output of the model for Object Confidence became NaN after a few steps to a few epochs based on the learning rate. What might've caused this?
5. Should I use MSE\_Loss on coordinates and height/width directly instead of IOUs? I am using the IOUs because using the bounding box attributes directly just gives larger numbers while using IOUs the same information can be supplied to the criterion while keeping the numbers in check.

I am sorry for the lengthy post. I have been self-studying and there is none to ask my questions so I am turning to the community for some guidance. Thank you for your time.

&amp;#x200B;

Edit: Clarification",t2_15xl36,False,,0,False,Object Detection Training Procedure,[],r/deeplearning,False,6,,0,,False,t3_njuy9b,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1621856664.0,,[],{},,True,,1621881582.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I am trying to train an object detection model for my custom data. While I&amp;#39;ve constructed the model and data loading, I am having some doubts over how to prepare targets and calculate the loss.&lt;/p&gt;

&lt;p&gt;The details of the training are:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The problem is a binary classification task with localization.&lt;/li&gt;
&lt;li&gt;I am using Yolov3 for the base model with a bit of customization for my project needs.&lt;/li&gt;
&lt;li&gt;For each scale in Yolov3, I am constructing an adjacent zero tensor that is identical to the output of the model then calculating the midpoint of any objects in the image, finding out which grid cell does the midpoint belongs to, and assigning that grid cell with the necessary information about object co-ordinates and height/width. This tensor will be used as the target tensor for the scale.&lt;/li&gt;
&lt;li&gt;Find which grid cells are responsible for objects then save indices for the non-zero positions.&lt;/li&gt;
&lt;li&gt;Filter target and feature tensors for both objectness score and coordination regression by using the indices from step 3.&lt;/li&gt;
&lt;li&gt;Reshape the features and target tensor to (-1, n), meaning no information about batch, grid cell, or anything, just plain old 1:1 comparison.&lt;/li&gt;
&lt;li&gt;Calculate IOU between the predicted box and target box.&lt;/li&gt;
&lt;li&gt;Object Loss is being calculated as (IOU * Object Confidence).&lt;/li&gt;
&lt;li&gt;Add to Total Loss.&lt;/li&gt;
&lt;li&gt;Repeat for another scale.&lt;/li&gt;
&lt;li&gt;Backprop Object Loss.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Some training shenanigans:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;For each scale, positional weights are being calculated for object == 0 or object == 1 then negative/positive as pos_weight for BCEWithLogitsLoss which means criterion is being created for each scale in each batch.&lt;/li&gt;
&lt;li&gt;Adam Optimizer with 1e-3 LR and ReduceOnPlateau with the patience of 2 and learning rate reduction of 0.1 per step on eval_loss. This was done because my loss stops decreasing at some point and starts increasing and I read on multiple Github issues that something like this could help but it hasn&amp;#39;t in my case. Also, train_loss is oscillating a lot while monitoring in Tensorboard.&lt;/li&gt;
&lt;li&gt;Batch Size of 16, can go up to 256.&lt;/li&gt;
&lt;li&gt;Clipping gradients to 10.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;My questions are:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Is it okay to only assign a single grid cell for the target? I am only considering whether the grid cell &amp;quot;supposed&amp;quot; to detect the object is successful or not. I have gone through the paper and multiple codes from various sources and never been able to grasp how they are building targets.&lt;/li&gt;
&lt;li&gt;What if the object is sufficiently large and the scale at which I am predicting is not able to fully detect it? Do I still calculate the loss for that scale?&lt;/li&gt;
&lt;li&gt;I am using &amp;quot;mean&amp;quot; as the reduction for the BCEWithLogitsLoss but reading the paper I get the impression that they are summing over the losses which is the reduction &amp;quot;sum&amp;quot;. Does this affect the training procedure much?&lt;/li&gt;
&lt;li&gt;Before using (IOU * Object Confidence), I was trying to train by using Object Confidence + (1 - IOU) or MSE_Loss(IOU, 1). When using this formulation, the output of the model for Object Confidence became NaN after a few steps to a few epochs based on the learning rate. What might&amp;#39;ve caused this?&lt;/li&gt;
&lt;li&gt;Should I use MSE_Loss on coordinates and height/width directly instead of IOUs? I am using the IOUs because using the bounding box attributes directly just gives larger numbers while using IOUs the same information can be supplied to the criterion while keeping the numbers in check.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I am sorry for the lengthy post. I have been self-studying and there is none to ask my questions so I am turning to the community for some guidance. Thank you for your time.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Edit: Clarification&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,njuy9b,True,,therealhoboscientist,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/njuy9b/object_detection_training_procedure/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/njuy9b/object_detection_training_procedure/,66147,1621852782.0,0,,False,,,,,,,
,deeplearning,"Implemented StyleGAN2 model and training loop from paper ""Analyzing and Improving the Image Quality of StyleGAN"".

Code with annotations: [https://nn.labml.ai/gan/stylegan/index.html](https://nn.labml.ai/gan/stylegan/index.html)

This is a minimalistic implementation with only 425 lines of code and lots of documentations and diagrams explaining the model.

&amp;#x200B;

* [Github](https://github.com/lab-ml/annotated_deep_learning_paper_implementations/tree/master/labml_nn/gan/stylegan)
* [Paper on arXiv](https://arxiv.org/abs/1912.04958)
* [Twitter Thread](https://twitter.com/labmlai/status/1396298504872423425)",t2_1jyhaoq,False,,0,False,StyleGAN2 implementation with side-by-side notes,[],r/deeplearning,False,6,,0,,False,t3_nj4ke2,False,dark,0.94,,public,46,3,{},,False,[],,False,False,,{},,False,46,,False,False,,False,,[],{'gid_1': 1},,True,,1621792393.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Implemented StyleGAN2 model and training loop from paper &amp;quot;Analyzing and Improving the Image Quality of StyleGAN&amp;quot;.&lt;/p&gt;

&lt;p&gt;Code with annotations: &lt;a href=""https://nn.labml.ai/gan/stylegan/index.html""&gt;https://nn.labml.ai/gan/stylegan/index.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is a minimalistic implementation with only 425 lines of code and lots of documentations and diagrams explaining the model.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://github.com/lab-ml/annotated_deep_learning_paper_implementations/tree/master/labml_nn/gan/stylegan""&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://arxiv.org/abs/1912.04958""&gt;Paper on arXiv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://twitter.com/labmlai/status/1396298504872423425""&gt;Twitter Thread&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 200, 'id': 'award_1703f934-cf44-40cc-a96d-3729d0b48262', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=16&amp;height=16&amp;auto=webp&amp;s=e3adc32e42cf534e27afea719ff932b1ce797cfd', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=32&amp;height=32&amp;auto=webp&amp;s=08542909c94777e870c41a35413bce688ca2fd6c', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=48&amp;height=48&amp;auto=webp&amp;s=4d85746d584b5494087da3561944d6d241f57674', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=64&amp;height=64&amp;auto=webp&amp;s=fd7683c8de2839998a432e7e53e1e06d66c35ad3', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=128&amp;height=128&amp;auto=webp&amp;s=a750da7a573bb231bd863be9725abece0332b828', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'My kindergarten teacher, my cat, my mom, and you.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': ""I'd Like to Thank..."", 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=16&amp;height=16&amp;auto=webp&amp;s=e3adc32e42cf534e27afea719ff932b1ce797cfd', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=32&amp;height=32&amp;auto=webp&amp;s=08542909c94777e870c41a35413bce688ca2fd6c', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=48&amp;height=48&amp;auto=webp&amp;s=4d85746d584b5494087da3561944d6d241f57674', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=64&amp;height=64&amp;auto=webp&amp;s=fd7683c8de2839998a432e7e53e1e06d66c35ad3', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=128&amp;height=128&amp;auto=webp&amp;s=a750da7a573bb231bd863be9725abece0332b828', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}, {'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nj4ke2,True,,mlvpj,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nj4ke2/stylegan2_implementation_with_sidebyside_notes/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nj4ke2/stylegan2_implementation_with_sidebyside_notes/,66147,1621763593.0,0,,False,,,,,,,
,deeplearning,"Hi,

I'm trying to download the pre-trained [DoveNet](https://github.com/bcmi/Image-Harmonization-Dataset-iHarmony4/tree/master/DoveNet) model (for image harmonization) but it seems you need a Baidu account to download from Baidu Cloud. I've spent almost 2 hours google-translating my way through the app but I don't think I can register without a Chinese phone number. 

I would really really appreciate it if you could please download the model and upload it to Google drive or somewhere else 😅 

[https://pan.baidu.com/s/12oGrBF88O-x0BlWGVkMjag](https://pan.baidu.com/s/12oGrBF88O-x0BlWGVkMjag)

Access code: 8q8a",t2_4xlj6vkw,False,,0,False,Need help from someone with a Baidu account,[],r/deeplearning,False,6,,0,,False,t3_njbe19,False,dark,0.87,,public,11,0,{},,False,[],,False,False,,{},,False,11,,False,False,,False,,[],{},,True,,1621816513.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m trying to download the pre-trained &lt;a href=""https://github.com/bcmi/Image-Harmonization-Dataset-iHarmony4/tree/master/DoveNet""&gt;DoveNet&lt;/a&gt; model (for image harmonization) but it seems you need a Baidu account to download from Baidu Cloud. I&amp;#39;ve spent almost 2 hours google-translating my way through the app but I don&amp;#39;t think I can register without a Chinese phone number. &lt;/p&gt;

&lt;p&gt;I would really really appreciate it if you could please download the model and upload it to Google drive or somewhere else 😅 &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://pan.baidu.com/s/12oGrBF88O-x0BlWGVkMjag""&gt;https://pan.baidu.com/s/12oGrBF88O-x0BlWGVkMjag&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Access code: 8q8a&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,njbe19,True,,alxcnwy,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/njbe19/need_help_from_someone_with_a_baidu_account/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/njbe19/need_help_from_someone_with_a_baidu_account/,66147,1621787713.0,0,,False,,,,,,,
,deeplearning,"The GPT-2 model was a major breakthrough in the path of creating a general multitask NLP system that was totally unsupervised. It demonstrated that given a large training corpus and a large model size, the language model was capable of learning the knowledge required for solving these tasks. It was not perfect, however, and performed poorly on some tasks as well.

I went through the paper and have written an informative summary of the paper.  The paper was quite easy to follow and the experimentation section had interesting observations. Check out the links below and happy reading!

Paper Summary -  [Language Models are Unsupervised Multitask Learners](https://shreyansh26.github.io/post/2021-05-23_language_models_unsupervised_multitask_learners_gpt2/)

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT2.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT2.pdf)",t2_5xzd9om,False,,0,False,GPT-2 - Annotated Paper + Paper Summary,[],r/deeplearning,False,6,,0,,False,t3_nja6n2,False,dark,0.78,,public,7,1,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,True,,1621813002.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The GPT-2 model was a major breakthrough in the path of creating a general multitask NLP system that was totally unsupervised. It demonstrated that given a large training corpus and a large model size, the language model was capable of learning the knowledge required for solving these tasks. It was not perfect, however, and performed poorly on some tasks as well.&lt;/p&gt;

&lt;p&gt;I went through the paper and have written an informative summary of the paper.  The paper was quite easy to follow and the experimentation section had interesting observations. Check out the links below and happy reading!&lt;/p&gt;

&lt;p&gt;Paper Summary -  &lt;a href=""https://shreyansh26.github.io/post/2021-05-23_language_models_unsupervised_multitask_learners_gpt2/""&gt;Language Models are Unsupervised Multitask Learners&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Annotated Paper -  &lt;a href=""https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT2.pdf""&gt;https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT2.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nja6n2,True,,shreyansh26,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nja6n2/gpt2_annotated_paper_paper_summary/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nja6n2/gpt2_annotated_paper_paper_summary/,66147,1621784202.0,0,,False,,,,,,,
,deeplearning,"Text similarity is the task of determining how 'close' two pieces of text are.

In this paper, author’s propose a n-gram graph based text similarity method infused with Named Entity information for doing the same.

https://link.medium.com/bmYk6voRugb",t2_hkv9s,False,,0,False,A Graph-based Text Similarity Method with Named Entity Information in NLP (Research Paper Summary),[],r/deeplearning,False,6,,0,,False,t3_njaizf,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1621814015.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Text similarity is the task of determining how &amp;#39;close&amp;#39; two pieces of text are.&lt;/p&gt;

&lt;p&gt;In this paper, author’s propose a n-gram graph based text similarity method infused with Named Entity information for doing the same.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://link.medium.com/bmYk6voRugb""&gt;https://link.medium.com/bmYk6voRugb&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,njaizf,True,,prakhar21,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/njaizf/a_graphbased_text_similarity_method_with_named/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/njaizf/a_graphbased_text_similarity_method_with_named/,66147,1621785215.0,0,,False,,,,,,,
,deeplearning,"What is the intuitive difference between attention and weights? Weight is also a number that signfies the relevance of the input, right? Attention mechanism also seems to do the same. So what is the difference?",t2_a81x3c83,False,,0,False,Difference between Attention and Weights,[],r/deeplearning,False,6,,0,,False,t3_nj8013,False,dark,0.84,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1621806121.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What is the intuitive difference between attention and weights? Weight is also a number that signfies the relevance of the input, right? Attention mechanism also seems to do the same. So what is the difference?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nj8013,True,,prometheus0717,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nj8013/difference_between_attention_and_weights/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nj8013/difference_between_attention_and_weights/,66147,1621777321.0,0,,False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,Getting Started With Reinforcement Learning! (My experiences over the past 3 months),[],r/deeplearning,False,6,,0,,False,t3_nj66me,False,dark,0.88,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,False,,1621799359.0,text,6,,,text,gordicaleksa.medium.com,False,,,,,https://gordicaleksa.medium.com/how-to-get-started-with-reinforcement-learning-rl-4922fafeaf8c,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nj66me,True,,gordicaleksa,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nj66me/getting_started_with_reinforcement_learning_my/,all_ads,False,https://gordicaleksa.medium.com/how-to-get-started-with-reinforcement-learning-rl-4922fafeaf8c,66147,1621770559.0,0,,False,,,,,,,
,deeplearning,"Hi, this is a basic question. I have looked around and I am confused so asking here.

I have a input feature matrix( row-normalized) of size 1200\*2000.

When I am writing my neural network, is the number of input neurons equal to the number of columns that is 2000?

Is it valid then to think about the dimension of each neuron? What is the dimension of each neuron here? is it 1200\* 1?

When we forward propagate using the weight matrix, is taking the dot product same as multiplying each neuron with a just one row of the weight matrix and summing it? Should not we multiply each neuron with the all the weights and repeat that for 2000 neuron and then sum up?

Also should you always transpose the weight matrix when you forward propagate? (In the step of multiplying the input with the weights, should you multiply with transposed weight matrix always?)",t2_c5febi8b,False,,0,False,Number of input neurons in a neural network,[],r/deeplearning,False,6,,0,,False,t3_nj3cim,False,dark,0.8,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,1621758667.0,,[],{},,True,,1621787058.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, this is a basic question. I have looked around and I am confused so asking here.&lt;/p&gt;

&lt;p&gt;I have a input feature matrix( row-normalized) of size 1200*2000.&lt;/p&gt;

&lt;p&gt;When I am writing my neural network, is the number of input neurons equal to the number of columns that is 2000?&lt;/p&gt;

&lt;p&gt;Is it valid then to think about the dimension of each neuron? What is the dimension of each neuron here? is it 1200* 1?&lt;/p&gt;

&lt;p&gt;When we forward propagate using the weight matrix, is taking the dot product same as multiplying each neuron with a just one row of the weight matrix and summing it? Should not we multiply each neuron with the all the weights and repeat that for 2000 neuron and then sum up?&lt;/p&gt;

&lt;p&gt;Also should you always transpose the weight matrix when you forward propagate? (In the step of multiplying the input with the weights, should you multiply with transposed weight matrix always?)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nj3cim,True,,popkept09,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/nj3cim/number_of_input_neurons_in_a_neural_network/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nj3cim/number_of_input_neurons_in_a_neural_network/,66147,1621758258.0,0,,False,,,,,,,
,deeplearning,"Neighbour2Neighbour is a new self-supervised image denoising training, which outperforms Noise2Noise training despite the fact that the former requires only single noisy image for training.

It gives outstanding denoising performance with just 300 training images. Have a look at these image results and minimal network implementation here: [https://github.com/neeraj3029/Ne2Ne-Image-Denoising](https://github.com/neeraj3029/Ne2Ne-Image-Denoising).

In case you have questions or related to the implementation, feel feel to write an issue, or star the repo to make reach wider community!

Neighbour2Neighbour ([https://arxiv.org/abs/2101.02824](https://arxiv.org/abs/2101.02824)) creates subsamples from the noisy images and performs training with them.

&amp;#x200B;

https://preview.redd.it/bwmt70yk23171.png?width=529&amp;format=png&amp;auto=webp&amp;s=86acd7ffaad7135c79a91cb6eae95bf2693620fd

&amp;#x200B;",t2_9uzzvchb,False,,0,False,Neighbour2Neighbour: The new self-supervised Image Denoising training,[],r/deeplearning,False,6,,0,,False,t3_niz56w,False,dark,0.92,,public,10,0,{},,False,[],,False,False,,{},,False,10,,False,False,,1621868624.0,,[],{},,True,,1621769790.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Neighbour2Neighbour is a new self-supervised image denoising training, which outperforms Noise2Noise training despite the fact that the former requires only single noisy image for training.&lt;/p&gt;

&lt;p&gt;It gives outstanding denoising performance with just 300 training images. Have a look at these image results and minimal network implementation here: &lt;a href=""https://github.com/neeraj3029/Ne2Ne-Image-Denoising""&gt;https://github.com/neeraj3029/Ne2Ne-Image-Denoising&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In case you have questions or related to the implementation, feel feel to write an issue, or star the repo to make reach wider community!&lt;/p&gt;

&lt;p&gt;Neighbour2Neighbour (&lt;a href=""https://arxiv.org/abs/2101.02824""&gt;https://arxiv.org/abs/2101.02824&lt;/a&gt;) creates subsamples from the noisy images and performs training with them.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/bwmt70yk23171.png?width=529&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=86acd7ffaad7135c79a91cb6eae95bf2693620fd""&gt;https://preview.redd.it/bwmt70yk23171.png?width=529&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=86acd7ffaad7135c79a91cb6eae95bf2693620fd&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,niz56w,True,,Familiar_Guess3712,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/niz56w/neighbour2neighbour_the_new_selfsupervised_image/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/niz56w/neighbour2neighbour_the_new_selfsupervised_image/,66147,1621740990.0,0,,False,,,"{'bwmt70yk23171': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 48, 'x': 108, 'u': 'https://preview.redd.it/bwmt70yk23171.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ea58ee8f55914a51e421faf671f0e4a0202c4ae2'}, {'y': 97, 'x': 216, 'u': 'https://preview.redd.it/bwmt70yk23171.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bf317db16cb00e529caeccafa0c4a654824a941f'}, {'y': 145, 'x': 320, 'u': 'https://preview.redd.it/bwmt70yk23171.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fe6ab468572429342c19096a7d6f43e56db8e88f'}], 's': {'y': 240, 'x': 529, 'u': 'https://preview.redd.it/bwmt70yk23171.png?width=529&amp;format=png&amp;auto=webp&amp;s=86acd7ffaad7135c79a91cb6eae95bf2693620fd'}, 'id': 'bwmt70yk23171'}}",,,,
,deeplearning,"ResNet-18 global, unstrctured, magnitude based and iterative pruning with CIFAR-10 dataset. The pruning goes on till 99.08% sparsity.

This is based on the research papers:

1. ""Learning both Weights and Connections for Efficient Neural Networks"" by Song Han et al.
2. ""Deep Compression: by Song Han et al.
3. ""The Lottery Ticket Hypothesis"" by Frankle et al.
4. ""What is the State of Neural Network Pruning?"" by Blalock et al.

Original and unpruned model has  val\_accuracy = 88.990% . Original model size = 42.7 MB, zipped model size = 40 MB.

Pruned model with sparsity = 99.063% has  val\_accuracy = 91.260%. Pruned, trained and zipped model size = 3.5 MB. This results into a compression ratio = 11.43%.

You can refer to the code [here](https://github.com/arjun-majumdar/Neural_Network_Pruning/blob/main/ResNet18_Global_Magnitude_Custom_Pruning.ipynb).

*NOTE:* Post pruning PyTorch doesn't cast tensors to sparse format. Therefore, the tensors are of the same dimensions as before but with 0s in it to denote pruned connections.

Thoughts?",t2_2mmql89p,False,,0,False,ResNet-18 magnitude based pruning,[],r/deeplearning,False,6,,0,,False,t3_nj9pad,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621811560.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;ResNet-18 global, unstrctured, magnitude based and iterative pruning with CIFAR-10 dataset. The pruning goes on till 99.08% sparsity.&lt;/p&gt;

&lt;p&gt;This is based on the research papers:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&amp;quot;Learning both Weights and Connections for Efficient Neural Networks&amp;quot; by Song Han et al.&lt;/li&gt;
&lt;li&gt;&amp;quot;Deep Compression: by Song Han et al.&lt;/li&gt;
&lt;li&gt;&amp;quot;The Lottery Ticket Hypothesis&amp;quot; by Frankle et al.&lt;/li&gt;
&lt;li&gt;&amp;quot;What is the State of Neural Network Pruning?&amp;quot; by Blalock et al.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Original and unpruned model has  val_accuracy = 88.990% . Original model size = 42.7 MB, zipped model size = 40 MB.&lt;/p&gt;

&lt;p&gt;Pruned model with sparsity = 99.063% has  val_accuracy = 91.260%. Pruned, trained and zipped model size = 3.5 MB. This results into a compression ratio = 11.43%.&lt;/p&gt;

&lt;p&gt;You can refer to the code &lt;a href=""https://github.com/arjun-majumdar/Neural_Network_Pruning/blob/main/ResNet18_Global_Magnitude_Custom_Pruning.ipynb""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;NOTE:&lt;/em&gt; Post pruning PyTorch doesn&amp;#39;t cast tensors to sparse format. Therefore, the tensors are of the same dimensions as before but with 0s in it to denote pruned connections.&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nj9pad,True,,grid_world,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nj9pad/resnet18_magnitude_based_pruning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nj9pad/resnet18_magnitude_based_pruning/,66147,1621782760.0,0,,False,,,,,,,
,deeplearning,"Is there any way to get weight matrices of popular pre trained deep learning models like alexnet, preferably in text format?",t2_1styp0s5,False,,0,False,Where to get weight matrices of popular deep learning models?,[],r/deeplearning,False,6,,0,,False,t3_nj7u1q,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621805545.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is there any way to get weight matrices of popular pre trained deep learning models like alexnet, preferably in text format?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nj7u1q,True,,apsientardiy,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nj7u1q/where_to_get_weight_matrices_of_popular_deep/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nj7u1q/where_to_get_weight_matrices_of_popular_deep/,66147,1621776745.0,0,,False,,,,,,,
,deeplearning,"In global, unstructured and iterative pruning algorithms such as:

1. ""Learning both Weights and Connections for Efficient Neural Networks"" by Han et al.
2. ""Deep Compression"" by Han et al.
3. ""The Lottery Ticket Hypothesis"" by Frankle et al.

except ""The Lottery Ticket Hypothesis"" where the weights are rewind-ed to their original values and resulting sub-network is trained from scratch thereby needed more time/epoch.

Since the usual algorithm is:

Take a trained neural network and repeat steps 1 and 2:

1. prune globally smallest magnitude p% of weights
2. re-train/fine-tune pruned neural network to recover from pruning

Usually, the number of pruning rounds needed to go from original and unpruned network (sparsity = 0%) to 99% sparsity requires 25-34 rounds depending on the exact architecture and number of trainable parameters.

In my experiments I have observed that during this repeated *prune and repeat* algorithm, the resulting pruned neural networks start to overfit to the training dataset, which is to be expected. Apart from using techniques such as regularization, dropout, data augmentation, learning rate scheduler, etc. are there any other techniques to prevent this overfit?

I assume that such a resulting pruned sub-network when used for real world tasks might not perform as expected due to the overfitting induced due to the *iterative* process. Correct me if I am wrong.

You can refer to my previous experiments [here](https://github.com/arjun-majumdar/Neural_Network_Pruning) and [here](https://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2).

Thanks!",t2_2mmql89p,False,,0,False,Over-fitting in Iterative Pruning,[],r/deeplearning,False,6,,0,,False,t3_nj6v27,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1621773473.0,,[],{},,True,,1621802021.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In global, unstructured and iterative pruning algorithms such as:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&amp;quot;Learning both Weights and Connections for Efficient Neural Networks&amp;quot; by Han et al.&lt;/li&gt;
&lt;li&gt;&amp;quot;Deep Compression&amp;quot; by Han et al.&lt;/li&gt;
&lt;li&gt;&amp;quot;The Lottery Ticket Hypothesis&amp;quot; by Frankle et al.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;except &amp;quot;The Lottery Ticket Hypothesis&amp;quot; where the weights are rewind-ed to their original values and resulting sub-network is trained from scratch thereby needed more time/epoch.&lt;/p&gt;

&lt;p&gt;Since the usual algorithm is:&lt;/p&gt;

&lt;p&gt;Take a trained neural network and repeat steps 1 and 2:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;prune globally smallest magnitude p% of weights&lt;/li&gt;
&lt;li&gt;re-train/fine-tune pruned neural network to recover from pruning&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Usually, the number of pruning rounds needed to go from original and unpruned network (sparsity = 0%) to 99% sparsity requires 25-34 rounds depending on the exact architecture and number of trainable parameters.&lt;/p&gt;

&lt;p&gt;In my experiments I have observed that during this repeated &lt;em&gt;prune and repeat&lt;/em&gt; algorithm, the resulting pruned neural networks start to overfit to the training dataset, which is to be expected. Apart from using techniques such as regularization, dropout, data augmentation, learning rate scheduler, etc. are there any other techniques to prevent this overfit?&lt;/p&gt;

&lt;p&gt;I assume that such a resulting pruned sub-network when used for real world tasks might not perform as expected due to the overfitting induced due to the &lt;em&gt;iterative&lt;/em&gt; process. Correct me if I am wrong.&lt;/p&gt;

&lt;p&gt;You can refer to my previous experiments &lt;a href=""https://github.com/arjun-majumdar/Neural_Network_Pruning""&gt;here&lt;/a&gt; and &lt;a href=""https://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nj6v27,True,,grid_world,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nj6v27/overfitting_in_iterative_pruning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nj6v27/overfitting_in_iterative_pruning/,66147,1621773221.0,0,,False,,,,,,,
,deeplearning,,t2_2bpezwg9,False,,0,False,3D Neural Network simulation,[],r/deeplearning,False,6,,0,,False,t3_ninvez,False,dark,0.8,,public,29,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/j53noXmkBRQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Neural Network 3D Simulation', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/j53noXmkBRQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'dDev Tech', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/j53noXmkBRQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCwsrCNLN4xQE9OVSP5Sz2dA'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/j53noXmkBRQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ninvez', 'height': 200}",,False,29,,False,False,,False,,[],{},,False,,1621734112.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=j53noXmkBRQ,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ninvez,True,,DevTechRetopall,,10,True,all_ads,False,[],False,,/r/deeplearning/comments/ninvez/3d_neural_network_simulation/,all_ads,False,https://www.youtube.com/watch?v=j53noXmkBRQ,66147,1621705312.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Neural Network 3D Simulation', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/j53noXmkBRQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'dDev Tech', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/j53noXmkBRQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCwsrCNLN4xQE9OVSP5Sz2dA'}}",False,,,,,,,
,deeplearning,,t2_quhzzcn,False,,0,False,"Deep learning, old film enhancing [4K, 60fps, 3D] 1897 Lumiere brothers snowball fight.",[],r/deeplearning,False,6,,0,,False,t3_nj42p2,False,dark,0.43,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FBWZFUDb_Qs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Lumiere Brothers Snowball Fight 1897 in Colorized HD', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FBWZFUDb_Qs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Life Before', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/FBWZFUDb_Qs/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCfyuV6aPhlEPt9fEhLcmttg'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FBWZFUDb_Qs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nj42p2', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1621790295.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=FBWZFUDb_Qs,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nj42p2,True,,Cytical0,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nj42p2/deep_learning_old_film_enhancing_4k_60fps_3d_1897/,all_ads,False,https://www.youtube.com/watch?v=FBWZFUDb_Qs,66147,1621761495.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Lumiere Brothers Snowball Fight 1897 in Colorized HD', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FBWZFUDb_Qs?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Life Before', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/FBWZFUDb_Qs/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCfyuV6aPhlEPt9fEhLcmttg'}}",False,,,,,,,
,deeplearning,"The pianist AI is an artificial intelligence project that through semi-unsupervised learning tries to generate unique piano pieces. From generating pure random pieces (e.g. [https://youtu.be/Pd5wSw-SSM8](https://youtu.be/Pd5wSw-SSM8) ) it has reached to this: [https://youtu.be/CiU-q0EtIdc](https://youtu.be/CiU-q0EtIdc)

The optimization is in process and still long way to go. But generally, what do you think? Has there been any progress?",t2_3r02kqm0,False,,0,False,Pianist AI,[],r/deeplearning,False,6,,0,,False,t3_nidiv9,False,dark,0.84,,public,22,0,{},,False,[],,False,False,,{},,False,22,,False,False,,False,,[],{},,True,,1621698620.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The pianist AI is an artificial intelligence project that through semi-unsupervised learning tries to generate unique piano pieces. From generating pure random pieces (e.g. &lt;a href=""https://youtu.be/Pd5wSw-SSM8""&gt;https://youtu.be/Pd5wSw-SSM8&lt;/a&gt; ) it has reached to this: &lt;a href=""https://youtu.be/CiU-q0EtIdc""&gt;https://youtu.be/CiU-q0EtIdc&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The optimization is in process and still long way to go. But generally, what do you think? Has there been any progress?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nidiv9,True,,amin_mlm,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/nidiv9/pianist_ai/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nidiv9/pianist_ai/,66147,1621669820.0,0,,False,,,,,,,
,deeplearning,"Hi...I'm a keen amateur (and ex-maths teacher) using Python/TensorFlow to research and create a childlike maths brain. I've started recording my work as a blog, and would value any feedback ...

[https://mrshrekblogs.com/my-ai-brainchild/mathematical-childlike-deep-learning/](https://mrshrekblogs.com/my-ai-brainchild/mathematical-childlike-deep-learning/)

&amp;#x200B;

https://preview.redd.it/icwb2raa8p071.png?width=1772&amp;format=png&amp;auto=webp&amp;s=30a6d443d0406455958c2db12e8249cce7e39f75",t2_c9vfuv4n,False,,0,False,Mathematical childlike deep learning - My AI brainchild,[],r/deeplearning,False,6,,0,,False,t3_nimd5k,False,dark,0.62,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1621729844.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi...I&amp;#39;m a keen amateur (and ex-maths teacher) using Python/TensorFlow to research and create a childlike maths brain. I&amp;#39;ve started recording my work as a blog, and would value any feedback ...&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://mrshrekblogs.com/my-ai-brainchild/mathematical-childlike-deep-learning/""&gt;https://mrshrekblogs.com/my-ai-brainchild/mathematical-childlike-deep-learning/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/icwb2raa8p071.png?width=1772&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=30a6d443d0406455958c2db12e8249cce7e39f75""&gt;https://preview.redd.it/icwb2raa8p071.png?width=1772&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=30a6d443d0406455958c2db12e8249cce7e39f75&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nimd5k,True,,My_AI_brainchild,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nimd5k/mathematical_childlike_deep_learning_my_ai/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nimd5k/mathematical_childlike_deep_learning_my_ai/,66147,1621701044.0,0,,False,,,"{'icwb2raa8p071': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 77, 'x': 108, 'u': 'https://preview.redd.it/icwb2raa8p071.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=aa8f2fe6cc2e25ec2781908feac6ad8b56b38922'}, {'y': 154, 'x': 216, 'u': 'https://preview.redd.it/icwb2raa8p071.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ff8cc34ab5a26c82f2d099d5eb218860d10cd8e9'}, {'y': 229, 'x': 320, 'u': 'https://preview.redd.it/icwb2raa8p071.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8e7c87f153ad02f9c4251e6bb13b0e718ed29444'}, {'y': 458, 'x': 640, 'u': 'https://preview.redd.it/icwb2raa8p071.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7a48a4f9bf83739e8d84044b1343863fe2a437f1'}, {'y': 688, 'x': 960, 'u': 'https://preview.redd.it/icwb2raa8p071.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8c4505348b5d4062cc4ebbcfbfeee67375076fde'}, {'y': 774, 'x': 1080, 'u': 'https://preview.redd.it/icwb2raa8p071.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f566e6d049ecad4b4abe95ceb2d98046e6b2d113'}], 's': {'y': 1270, 'x': 1772, 'u': 'https://preview.redd.it/icwb2raa8p071.png?width=1772&amp;format=png&amp;auto=webp&amp;s=30a6d443d0406455958c2db12e8249cce7e39f75'}, 'id': 'icwb2raa8p071'}}",,,,
,deeplearning,"I have cityscape data set. Each image has a mask. Suppose 11 classes there .ex- sky, car... Etc.  How can i label the mask image pixel with class id",t2_9makuodb,False,,0,False,How labeling Mask image pixels with Class ids for Image segmentation?,[],r/deeplearning,False,6,,0,,False,t3_nijhpb,False,dark,0.76,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,1621700522.0,,[],{},,True,,1621721566.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have cityscape data set. Each image has a mask. Suppose 11 classes there .ex- sky, car... Etc.  How can i label the mask image pixel with class id&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nijhpb,True,,Professional_Fox1206,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nijhpb/how_labeling_mask_image_pixels_with_class_ids_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nijhpb/how_labeling_mask_image_pixels_with_class_ids_for/,66147,1621692766.0,0,,False,,,,,,,
,deeplearning,Is it possible to detect solar panels using satellite image data? If yes then how the data of a particular city is supposed to be collected?,t2_8s1tooht,False,,0,False,Deep Learning for solar panel detection,[],r/deeplearning,False,6,,0,,False,t3_nipwwv,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621739930.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is it possible to detect solar panels using satellite image data? If yes then how the data of a particular city is supposed to be collected?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nipwwv,True,,rapchickk,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nipwwv/deep_learning_for_solar_panel_detection/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nipwwv/deep_learning_for_solar_panel_detection/,66147,1621711130.0,0,,False,,,,,,,
,deeplearning,,t2_159buvym,False,,0,False,What is the role of centring block in DINO,[],r/deeplearning,False,6,,0,,False,t3_nilbcz,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621726856.0,text,6,,,text,self.deeplearning,False,,,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nilbcz,True,,rakshith291,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nilbcz/what_is_the_role_of_centring_block_in_dino/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nilbcz/what_is_the_role_of_centring_block_in_dino/,66147,1621698056.0,0,,False,,,,,,,
,deeplearning,,t2_7zyjqab2,False,,0,False,Proud of this air cooled/3990x/2XA6000 Deep Learning build for my client! Let me know what you think!,[],r/deeplearning,False,6,,0,,False,t3_nhtwq4,False,dark,0.94,,public,99,1,{},,False,[],"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/kzjzy7c2ih071/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 607, 'scrubber_media_url': 'https://v.redd.it/kzjzy7c2ih071/DASH_96.mp4', 'dash_url': 'https://v.redd.it/kzjzy7c2ih071/DASHPlaylist.mpd?a=1626449865%2CZWUwODEyM2RkMDY3M2MxYTRiNmE2YTQyYmE1NGNjMDgxY2ViNTMyZjU2MDMyNWE4M2M1OGFhMmE3YTEwNDU3Mg%3D%3D&amp;v=1&amp;f=sd', 'duration': 49, 'hls_url': 'https://v.redd.it/kzjzy7c2ih071/HLSPlaylist.m3u8?a=1626449865%2CZWZiMTA4NzA3ZjhkZGFmMmI3NWY2ZmM0NjYwZmYxNDUwMzhhN2ZkMTZhMmM4MjU0MzYxMWZkOTc4NzQwN2JlZA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,99,,False,False,,False,,[],{'gid_1': 1},,False,,1621636284.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/kzjzy7c2ih071,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nhtwq4,True,,GPUaccelerated,,17,True,all_ads,False,[],False,,/r/deeplearning/comments/nhtwq4/proud_of_this_air_cooled3990x2xa6000_deep/,all_ads,False,https://v.redd.it/kzjzy7c2ih071,66147,1621607484.0,0,"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/kzjzy7c2ih071/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 607, 'scrubber_media_url': 'https://v.redd.it/kzjzy7c2ih071/DASH_96.mp4', 'dash_url': 'https://v.redd.it/kzjzy7c2ih071/DASHPlaylist.mpd?a=1626449865%2CZWUwODEyM2RkMDY3M2MxYTRiNmE2YTQyYmE1NGNjMDgxY2ViNTMyZjU2MDMyNWE4M2M1OGFhMmE3YTEwNDU3Mg%3D%3D&amp;v=1&amp;f=sd', 'duration': 49, 'hls_url': 'https://v.redd.it/kzjzy7c2ih071/HLSPlaylist.m3u8?a=1626449865%2CZWZiMTA4NzA3ZjhkZGFmMmI3NWY2ZmM0NjYwZmYxNDUwMzhhN2ZkMTZhMmM4MjU0MzYxMWZkOTc4NzQwN2JlZA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,,t2_lgfw9rg,False,,0,False,Radiologist vs Artificial Intelligence Ep.02 - Fracture Detection,[],r/deeplearning,False,6,,0,,False,t3_niiajb,False,dark,0.4,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KrurfmdXQlc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Radiologist vs Artificial Intelligence Ep.02 - Fracture Detection', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KrurfmdXQlc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Dr Christoph Agten', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/KrurfmdXQlc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/DrChristophAgten'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KrurfmdXQlc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/niiajb', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1621717753.0,text,6,,,text,youtube.com,False,,,,,https://youtube.com/watch?v=KrurfmdXQlc&amp;feature=share,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,niiajb,True,,ogcdark,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/niiajb/radiologist_vs_artificial_intelligence_ep02/,all_ads,False,https://youtube.com/watch?v=KrurfmdXQlc&amp;feature=share,66147,1621688953.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Radiologist vs Artificial Intelligence Ep.02 - Fracture Detection', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KrurfmdXQlc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Dr Christoph Agten', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/KrurfmdXQlc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/DrChristophAgten'}}",False,"[{'approved_at_utc': None, 'subreddit': 'Radiology', 'selftext': '', 'author_fullname': 't2_lgfw9rg', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Radiologist vs Artificial Intelligence Ep.02 - Fracture Detection', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/Radiology', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'news', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nii98e', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.99, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 93, 'total_awards_received': 1, 'media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KrurfmdXQlc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Radiologist vs Artificial Intelligence Ep.02 - Fracture Detection', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KrurfmdXQlc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Dr Christoph Agten', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/KrurfmdXQlc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/DrChristophAgten'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KrurfmdXQlc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nii98e', 'height': 200}, 'link_flair_text': 'News/Article', 'can_mod_post': False, 'score': 93, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {'gid_1': 1}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1621717627.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtube.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'top', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://youtube.com/watch?v=KrurfmdXQlc&amp;feature=share', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}], 'awarders': [], 'media_only': False, 'link_flair_template_id': '7c458654-e115-11e3-a2a3-12313b073d11', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qpaw', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': 'nii98e', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'ogcdark', 'discussion_type': None, 'num_comments': 9, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/Radiology/comments/nii98e/radiologist_vs_artificial_intelligence_ep02/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://youtube.com/watch?v=KrurfmdXQlc&amp;feature=share', 'subreddit_subscribers': 51982, 'created_utc': 1621688827.0, 'num_crossposts': 3, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Radiologist vs Artificial Intelligence Ep.02 - Fracture Detection', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KrurfmdXQlc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Dr Christoph Agten', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/KrurfmdXQlc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/DrChristophAgten'}}, 'is_video': False}]",t3_nii98e,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,Is AI The Future Of Video Game Design? Enhancing Photorealism Enhancement,[],r/deeplearning,False,6,,0,,False,t3_nii92r,False,dark,0.62,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/3rYosbwXm1w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Is AI The Future Of Video Game Design? Enhancing Photorealism Enhancement', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/3rYosbwXm1w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/3rYosbwXm1w/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/3rYosbwXm1w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nii92r', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1621717613.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/3rYosbwXm1w,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nii92r,True,,OnlyProggingForFun,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nii92r/is_ai_the_future_of_video_game_design_enhancing/,all_ads,False,https://youtu.be/3rYosbwXm1w,66147,1621688813.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Is AI The Future Of Video Game Design? Enhancing Photorealism Enhancement', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/3rYosbwXm1w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/3rYosbwXm1w/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,,,,,,,
,deeplearning,"I have a DL Model in Pytorch, and I want to make an app for both iOS and Android with the deployed model. Any suggestions how to go about it? 

I know Deep learning and model deployment in AWS sagemaker but don't know how to utilize that and build an app. Any resources or tutorials or suggestions for the same?",t2_3pd85vij,False,,0,False,How to deploy a Deep Learning model to a mobile application?,[],r/deeplearning,False,6,,0,,False,t3_ni7u80,False,dark,0.76,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1621675970.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a DL Model in Pytorch, and I want to make an app for both iOS and Android with the deployed model. Any suggestions how to go about it? &lt;/p&gt;

&lt;p&gt;I know Deep learning and model deployment in AWS sagemaker but don&amp;#39;t know how to utilize that and build an app. Any resources or tutorials or suggestions for the same?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ni7u80,True,,mishti__doi,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/ni7u80/how_to_deploy_a_deep_learning_model_to_a_mobile/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ni7u80/how_to_deploy_a_deep_learning_model_to_a_mobile/,66147,1621647170.0,0,,False,,,,,,,
,deeplearning,"Here is a list of existing video datasets for cv research [https://github.com/xiaobai1217/Awesome-Video-Datasets](https://github.com/xiaobai1217/Awesome-Video-Datasets)

&amp;#x200B;

https://preview.redd.it/2oz578d3zm071.png?width=718&amp;format=png&amp;auto=webp&amp;s=2a94c3318d4226a50c90ee0f0615ffaaeabbf7f9",t2_5kraegh0,False,,0,False,Video Datasets,[],r/deeplearning,False,6,,0,,False,t3_nieebw,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621702539.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Here is a list of existing video datasets for cv research &lt;a href=""https://github.com/xiaobai1217/Awesome-Video-Datasets""&gt;https://github.com/xiaobai1217/Awesome-Video-Datasets&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/2oz578d3zm071.png?width=718&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a94c3318d4226a50c90ee0f0615ffaaeabbf7f9""&gt;https://preview.redd.it/2oz578d3zm071.png?width=718&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2a94c3318d4226a50c90ee0f0615ffaaeabbf7f9&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nieebw,True,,SnooPandas1226,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nieebw/video_datasets/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nieebw/video_datasets/,66147,1621673739.0,0,,False,,,"{'2oz578d3zm071': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 205, 'x': 108, 'u': 'https://preview.redd.it/2oz578d3zm071.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ed91a83687187be223c1cbe932a026f3ba95ce4d'}, {'y': 410, 'x': 216, 'u': 'https://preview.redd.it/2oz578d3zm071.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c1a9bef0b33b6d27478da6e1dda4e86e13fd6db6'}, {'y': 607, 'x': 320, 'u': 'https://preview.redd.it/2oz578d3zm071.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=419005de9bf65ab3133a8d1a9fc5151a83c18987'}, {'y': 1215, 'x': 640, 'u': 'https://preview.redd.it/2oz578d3zm071.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=3ba0a1bdde8689c5acf1666a2a7cdd5c0153e0e2'}], 's': {'y': 1364, 'x': 718, 'u': 'https://preview.redd.it/2oz578d3zm071.png?width=718&amp;format=png&amp;auto=webp&amp;s=2a94c3318d4226a50c90ee0f0615ffaaeabbf7f9'}, 'id': '2oz578d3zm071'}}",,,,
,deeplearning,,t2_63ay634e,False,,0,False,Breakthrough!: Video Person-Clustering – an essential step towards story understanding!,[],r/deeplearning,False,6,,0,,False,t3_ni9sgz,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1621683142.0,text,6,,,text,self.LatestInML,False,,,,,/r/LatestInML/comments/ni9s75/breakthrough_video_personclustering_an_essential/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ni9sgz,True,,cv2020br,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ni9sgz/breakthrough_video_personclustering_an_essential/,all_ads,False,/r/LatestInML/comments/ni9s75/breakthrough_video_personclustering_an_essential/,66147,1621654342.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper](https://www.catalyzex.com/paper/arxiv:2105.09939)\n\nhttps://reddit.com/link/ni9s75/video/u3gyyc0bdl071/player\n\n👇 Free extension to get code for ML papers (❤️'d by Andrew Ng) Chrome: https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil\n\nFirefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_63ay634e', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Breakthrough!: Video Person-Clustering – an essential step towards story understanding!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'u3gyyc0bdl071': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/ni9s75/asset/u3gyyc0bdl071/DASHPlaylist.mpd?a=1626449865%2CZDhjNTYxMmVhNjkwZjgxZjYxNzFhNmM2ODg0MTk4NWZlY2VlYjk0MWFlZjAxOTQ2N2UwYjk3MWNlZDg0MTg5NQ%3D%3D&amp;v=1&amp;f=sd', 'x': 640, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/ni9s75/asset/u3gyyc0bdl071/HLSPlaylist.m3u8?a=1626449865%2CMmI4MGMyMTE0MDUzMmQ0MzRlYWQyNzQ5MDczMDQ4ZDcwYWQ3YTU1NTAxNmZhMjg0NmVlMDAyMjhkN2Y0YzBkMQ%3D%3D&amp;v=1&amp;f=sd', 'id': 'u3gyyc0bdl071', 'isGif': False}}, 'name': 't3_ni9s75', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1621683116.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2105.09939""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/ni9s75/video/u3gyyc0bdl071/player""&gt;https://reddit.com/link/ni9s75/video/u3gyyc0bdl071/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39;d by Andrew Ng) Chrome: &lt;a href=""https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'ni9s75', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'cv2020br', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/ni9s75/breakthrough_video_personclustering_an_essential/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/ni9s75/breakthrough_video_personclustering_an_essential/', 'subreddit_subscribers': 7049, 'created_utc': 1621654316.0, 'num_crossposts': 8, 'media': None, 'is_video': False}]",t3_ni9s75,,,,,
,deeplearning,"I am a year 11 student conducting a survey for a subject called the Research Project. This subject involves formulating a question and using a vairety of research processes to answer the question. My Question is 

""To what extent can the use of machine learning detect deepfake video and voice impersonation?"". I have created a survey which asks questions about voice impersonations using Neural Networks, the questions are for academic purposes and to grasp theoretical concepts around voice impersonation using neural networks. Please note that you will remain anonymous and that you do not have to answer every question if you feel uncomfortable with any of the questions.

&amp;#x200B;

The survey can be found at: [https://forms.gle/bgMvJ9BUgj4PrASz8](https://forms.gle/bgMvJ9BUgj4PrASz8)

&amp;#x200B;

Thanks for your time and efforts in participating in my survey.",t2_1s1zb3cu,False,,0,False,"Voice Impersonation Using Neural Networks ""[R]""",[],r/deeplearning,False,6,,0,,False,t3_ni6dla,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1621670625.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a year 11 student conducting a survey for a subject called the Research Project. This subject involves formulating a question and using a vairety of research processes to answer the question. My Question is &lt;/p&gt;

&lt;p&gt;&amp;quot;To what extent can the use of machine learning detect deepfake video and voice impersonation?&amp;quot;. I have created a survey which asks questions about voice impersonations using Neural Networks, the questions are for academic purposes and to grasp theoretical concepts around voice impersonation using neural networks. Please note that you will remain anonymous and that you do not have to answer every question if you feel uncomfortable with any of the questions.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The survey can be found at: &lt;a href=""https://forms.gle/bgMvJ9BUgj4PrASz8""&gt;https://forms.gle/bgMvJ9BUgj4PrASz8&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks for your time and efforts in participating in my survey.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ni6dla,True,,Vas5,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ni6dla/voice_impersonation_using_neural_networks_r/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ni6dla/voice_impersonation_using_neural_networks_r/,66147,1621641825.0,0,,False,,,,,,,
,deeplearning,"Facebook has recently developed an AI tool that allows machine learning models to preserve certain information while forgetting the rest. It claims that the tool, [**Expire-Span**](https://arxiv.org/pdf/2105.06548.pdf), can predict information most relevant to a task at hand thereby, allowing AI systems to process data at larger scales. 

Conventionally, AI models memorize information without distinction, unlike humans. Therefore, creating the ability to decide whether to forget the information or not at the software level is challenging. Usually, state-of-the-art models struggle with large quantities of information like books or videos and incurring high computing costs. This can lead to many other problems such as catastrophic learning or catastrophic interference, a situation where AI systems fail to recall what they’ve learned from a training dataset. 

Source: [https://www.marktechpost.com/2021/05/21/facebooks-expire-span-tool-enables-machine-learning-models-to-forget-irrelevant-data/](https://www.marktechpost.com/2021/05/21/facebooks-expire-span-tool-enables-machine-learning-models-to-forget-irrelevant-data/?_ga=2.232088284.2144888320.1621650511-488125022.1618729090)

Codes: [https://github.com/facebookresearch/transformer-sequential](https://github.com/facebookresearch/transformer-sequential) 

Paper: [https://arxiv.org/pdf/2105.06548.pdf](https://arxiv.org/pdf/2105.06548.pdf)",t2_2wsvqwhg,False,,0,False,Facebook’s ‘Expire-Span’ Tool Enables Machine Learning Models to Forget Irrelevant Data (Paper and Code included),[],r/deeplearning,False,6,,0,,False,t3_ni91pm,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621680407.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Facebook has recently developed an AI tool that allows machine learning models to preserve certain information while forgetting the rest. It claims that the tool, &lt;a href=""https://arxiv.org/pdf/2105.06548.pdf""&gt;&lt;strong&gt;Expire-Span&lt;/strong&gt;&lt;/a&gt;, can predict information most relevant to a task at hand thereby, allowing AI systems to process data at larger scales. &lt;/p&gt;

&lt;p&gt;Conventionally, AI models memorize information without distinction, unlike humans. Therefore, creating the ability to decide whether to forget the information or not at the software level is challenging. Usually, state-of-the-art models struggle with large quantities of information like books or videos and incurring high computing costs. This can lead to many other problems such as catastrophic learning or catastrophic interference, a situation where AI systems fail to recall what they’ve learned from a training dataset. &lt;/p&gt;

&lt;p&gt;Source: &lt;a href=""https://www.marktechpost.com/2021/05/21/facebooks-expire-span-tool-enables-machine-learning-models-to-forget-irrelevant-data/?_ga=2.232088284.2144888320.1621650511-488125022.1618729090""&gt;https://www.marktechpost.com/2021/05/21/facebooks-expire-span-tool-enables-machine-learning-models-to-forget-irrelevant-data/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Codes: &lt;a href=""https://github.com/facebookresearch/transformer-sequential""&gt;https://github.com/facebookresearch/transformer-sequential&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Paper: &lt;a href=""https://arxiv.org/pdf/2105.06548.pdf""&gt;https://arxiv.org/pdf/2105.06548.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ni91pm,True,,ai-lover,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ni91pm/facebooks_expirespan_tool_enables_machine/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ni91pm/facebooks_expirespan_tool_enables_machine/,66147,1621651607.0,0,,False,,,,,,,
,deeplearning,"Q1: The purpose of Spatial Pyramid Pooling(SSP) is to eliminate the limits of the fully connected layer for different resolutions of inputs. If one model uses Global Average Pooling before the fully connected layer, does it still need to use SSP? 

Q2: Could I view AdaptiveAvgPool2d() in PyTorch as the Global Average Pooling technique?

Q3: many neural networks implemented in PyTorch, like ResNet in torchvision, have an AdaptiveAvgPool2d() layer before the fully connected layer, why? in order to remove the restriction to the input size?",t2_87scchcm,False,,0,False,"What is the relationship between Spatial Pyramid Pooling, Global Average Pooling and Adaptive AvgPool2d of PyTorch?",[],r/deeplearning,False,6,,0,,False,t3_nhx1nm,False,dark,1.0,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,True,,1621644378.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Q1: The purpose of Spatial Pyramid Pooling(SSP) is to eliminate the limits of the fully connected layer for different resolutions of inputs. If one model uses Global Average Pooling before the fully connected layer, does it still need to use SSP? &lt;/p&gt;

&lt;p&gt;Q2: Could I view AdaptiveAvgPool2d() in PyTorch as the Global Average Pooling technique?&lt;/p&gt;

&lt;p&gt;Q3: many neural networks implemented in PyTorch, like ResNet in torchvision, have an AdaptiveAvgPool2d() layer before the fully connected layer, why? in order to remove the restriction to the input size?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nhx1nm,True,,EconomicsSimple174,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nhx1nm/what_is_the_relationship_between_spatial_pyramid/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nhx1nm/what_is_the_relationship_between_spatial_pyramid/,66147,1621615578.0,0,,False,,,,,,,
,deeplearning,"If you are looking for quick outputs then OpenPose or DeepLabCut Model Zoo seems to be one approach for rapidly outputting pose estimation predictions without the need to training a deep net.

Are there other easy-to-use algorithms that also do this? In both of the above cases, you can run this fully in Google Golab, which is nice and convenient.

[https://www.youtube.com/watch?v=efndNkXLsHg](https://www.youtube.com/watch?v=efndNkXLsHg)

&amp;#x200B;

https://preview.redd.it/t2y5nsakxi071.png?width=1760&amp;format=png&amp;auto=webp&amp;s=8b1a8def25890a6f76abbb231cdc16d955ac49dc",t2_bz4qzvu8,False,,0,False,Using various pose estimation algorithms to predict joint kinematics of a person jumping.,[],r/deeplearning,False,6,,0,,False,t3_ni0hru,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621653472.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If you are looking for quick outputs then OpenPose or DeepLabCut Model Zoo seems to be one approach for rapidly outputting pose estimation predictions without the need to training a deep net.&lt;/p&gt;

&lt;p&gt;Are there other easy-to-use algorithms that also do this? In both of the above cases, you can run this fully in Google Golab, which is nice and convenient.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=efndNkXLsHg""&gt;https://www.youtube.com/watch?v=efndNkXLsHg&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/t2y5nsakxi071.png?width=1760&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8b1a8def25890a6f76abbb231cdc16d955ac49dc""&gt;https://preview.redd.it/t2y5nsakxi071.png?width=1760&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8b1a8def25890a6f76abbb231cdc16d955ac49dc&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ni0hru,True,,BioMechanicaLab,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ni0hru/using_various_pose_estimation_algorithms_to/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ni0hru/using_various_pose_estimation_algorithms_to/,66147,1621624672.0,0,,False,,,"{'t2y5nsakxi071': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 110, 'x': 108, 'u': 'https://preview.redd.it/t2y5nsakxi071.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=90c3f34bc1b1ddba1e75fd3e7ed920aacbeb0676'}, {'y': 221, 'x': 216, 'u': 'https://preview.redd.it/t2y5nsakxi071.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3126d88917fa68784bbcdf623b7e4ad9f85c5035'}, {'y': 328, 'x': 320, 'u': 'https://preview.redd.it/t2y5nsakxi071.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6f19a2376d328628b1c537d1d19f5ecd84b7b294'}, {'y': 656, 'x': 640, 'u': 'https://preview.redd.it/t2y5nsakxi071.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=631542d01d65a635d59285160a82b7d673382abf'}, {'y': 983, 'x': 960, 'u': 'https://preview.redd.it/t2y5nsakxi071.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5324263f566aab6e620949e15f242aa64e85c67f'}, {'y': 1107, 'x': 1080, 'u': 'https://preview.redd.it/t2y5nsakxi071.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8efa071f0c5b9f33ace04ede5f85033149e944ab'}], 's': {'y': 1804, 'x': 1760, 'u': 'https://preview.redd.it/t2y5nsakxi071.png?width=1760&amp;format=png&amp;auto=webp&amp;s=8b1a8def25890a6f76abbb231cdc16d955ac49dc'}, 'id': 't2y5nsakxi071'}}",,,,
,deeplearning,"This tutorial breaks down Coordinate Attention, a new attention mechanism introduced at CVPR 2021.  At first glance, this attention mechanism seems to be a hybrid between Triplet Attention and Strip Pooling, but more specifically targeted for lightweight mobile-deployed networks.

The goal of Coordinate attention is to embed positional information into channel attention, to enable mobile networks to attend over large regions while avoiding incurring significant computational overhead. Topics covered include:

1. Motivation
2. Coordinate Attention
3. PyTorch Code
4. Results
5. Conclusion

Article link: [https://blog.paperspace.com/coordinate-attention/](https://blog.paperspace.com/coordinate-attention/)",t2_15en0l,False,,0,False,[Article] The Coordinate Attention Mechanism Explained,[],r/deeplearning,False,6,,0,,False,t3_nhzuep,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1621623668.0,,[],{},,True,,1621651727.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This tutorial breaks down Coordinate Attention, a new attention mechanism introduced at CVPR 2021.  At first glance, this attention mechanism seems to be a hybrid between Triplet Attention and Strip Pooling, but more specifically targeted for lightweight mobile-deployed networks.&lt;/p&gt;

&lt;p&gt;The goal of Coordinate attention is to embed positional information into channel attention, to enable mobile networks to attend over large regions while avoiding incurring significant computational overhead. Topics covered include:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Motivation&lt;/li&gt;
&lt;li&gt;Coordinate Attention&lt;/li&gt;
&lt;li&gt;PyTorch Code&lt;/li&gt;
&lt;li&gt;Results&lt;/li&gt;
&lt;li&gt;Conclusion&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Article link: &lt;a href=""https://blog.paperspace.com/coordinate-attention/""&gt;https://blog.paperspace.com/coordinate-attention/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nhzuep,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nhzuep/article_the_coordinate_attention_mechanism/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nhzuep/article_the_coordinate_attention_mechanism/,66147,1621622927.0,0,,False,,,,,,,
,deeplearning,"A research team from ETH Zürich and Microsoft presents a systematic, comparative study of distributed ML training over serverless infrastructures (FaaS) and “serverful” infrastructures (IaaS), aiming to understand the system tradeoffs of distributed ML training with serverless infrastructures.

Here is a quick read: [ETH Zürich &amp; Microsoft Study: Demystifying Serverless ML Training.](https://syncedreview.com/2021/05/21/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-24/)

The paper *Towards Demystifying Serverless Machine Learning Training* is on [arXiv](https://arxiv.org/abs/2105.07806).",t2_2fv4yodo,False,,0,False,[R] ETH Zürich &amp; Microsoft Study: Demystifying Serverless ML Training,[],r/deeplearning,False,6,,0,,False,t3_nhv1y7,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621639254.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from ETH Zürich and Microsoft presents a systematic, comparative study of distributed ML training over serverless infrastructures (FaaS) and “serverful” infrastructures (IaaS), aiming to understand the system tradeoffs of distributed ML training with serverless infrastructures.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/21/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-24/""&gt;ETH Zürich &amp;amp; Microsoft Study: Demystifying Serverless ML Training.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Towards Demystifying Serverless Machine Learning Training&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.07806""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nhv1y7,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nhv1y7/r_eth_zürich_microsoft_study_demystifying/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nhv1y7/r_eth_zürich_microsoft_study_demystifying/,66147,1621610454.0,0,,False,,,,,,,
,deeplearning,"I was trying to look at some papers which used LSTM models for forecasting, and strangely all of them have used a single layer of LSTM. Is there a reason why time series prediction involves only one LSTM layer?",t2_6bacxfsd,False,,0,False,Time series prediction using Deep Learning,[],r/deeplearning,False,6,,0,,False,t3_nhdvtw,False,dark,0.92,,public,20,0,{},,False,[],,False,False,,{},,False,20,,False,False,,False,,[],{},,True,,1621580012.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was trying to look at some papers which used LSTM models for forecasting, and strangely all of them have used a single layer of LSTM. Is there a reason why time series prediction involves only one LSTM layer?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nhdvtw,True,,pandi20,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/nhdvtw/time_series_prediction_using_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nhdvtw/time_series_prediction_using_deep_learning/,66147,1621551212.0,0,,False,,,,,,,
,deeplearning,Can i use GAN to detect and recognize blur or distorted characters from vehicle plate?,t2_7rmi111c,False,,0,False,Can i use GAN?,[],r/deeplearning,False,6,,0,,False,t3_nhps1n,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621623704.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can i use GAN to detect and recognize blur or distorted characters from vehicle plate?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nhps1n,True,,ali-nawaz14,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nhps1n/can_i_use_gan/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nhps1n/can_i_use_gan/,66147,1621594904.0,0,,False,,,,,,,
,deeplearning,"A research team from ETH Zürich presents an overview of priors for (deep) Gaussian processes, variational autoencoders and Bayesian neural networks. The researchers propose that well-chosen priors can achieve theoretical and empirical properties such as uncertainty estimation, model selection and optimal decision support; and provide guidance on how to choose them.

Here is a quick read: [ETH Zürich Identifies Priors That Boost Bayesian Deep Learning Models.](https://syncedreview.com/2021/05/20/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-23/)

The paper *Priors in Bayesian Deep Learning: A Review* is on [arXiv](https://arxiv.org/abs/2105.06868).",t2_2fv4yodo,False,,0,False,[R] ETH Zürich Identifies Priors That Boost Bayesian Deep Learning Models,[],r/deeplearning,False,6,,0,,False,t3_nh3fnf,False,dark,0.9,,public,16,0,{},,False,[],,False,False,,{},,False,16,,False,False,,False,,[],{},,True,,1621553893.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from ETH Zürich presents an overview of priors for (deep) Gaussian processes, variational autoencoders and Bayesian neural networks. The researchers propose that well-chosen priors can achieve theoretical and empirical properties such as uncertainty estimation, model selection and optimal decision support; and provide guidance on how to choose them.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/20/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-23/""&gt;ETH Zürich Identifies Priors That Boost Bayesian Deep Learning Models.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Priors in Bayesian Deep Learning: A Review&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.06868""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nh3fnf,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nh3fnf/r_eth_zürich_identifies_priors_that_boost/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nh3fnf/r_eth_zürich_identifies_priors_that_boost/,66147,1621525093.0,0,,False,,,,,,,
,deeplearning,,t2_c7lfuw9x,False,,0,False,Evolutionary Deep Intelligence is Deep Learning’s New Advancement,[],r/deeplearning,False,6,,0,,False,t3_nhk4sf,False,dark,0.66,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1621600617.0,text,6,,,text,analyticsinsight.net,False,,,,,https://www.analyticsinsight.net/evolutionary-deep-intelligence-is-deep-learnings-new-advancement/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nhk4sf,True,,Analyticsinsight01,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nhk4sf/evolutionary_deep_intelligence_is_deep_learnings/,all_ads,False,https://www.analyticsinsight.net/evolutionary-deep-intelligence-is-deep-learnings-new-advancement/,66147,1621571817.0,0,,False,,,,,,,
,deeplearning,"It'd be fed a

* low quality 3d model
* And a couple other high quality similar sample models for reference

And it would spit out the high quality version of the original model?   
Is there such thing on the market?",t2_1tqi9abh,False,,0,False,"Deep learning for 3d models ( low-poly to high-poly conversion ), does such thing exist?",[],r/deeplearning,False,6,,0,,False,t3_nh8zm2,False,dark,0.87,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1621567231.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It&amp;#39;d be fed a&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;low quality 3d model&lt;/li&gt;
&lt;li&gt;And a couple other high quality similar sample models for reference&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And it would spit out the high quality version of the original model?&lt;br/&gt;
Is there such thing on the market?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nh8zm2,True,,lajos93,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nh8zm2/deep_learning_for_3d_models_lowpoly_to_highpoly/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nh8zm2/deep_learning_for_3d_models_lowpoly_to_highpoly/,66147,1621538431.0,0,,False,,,,,,,
,deeplearning,"Hello everyone, 

Sorry if it's a noob question I am new to this. As far as I understand I need the mean and std of the dataset to preprocess the data before training, but where do I get these values? is there are standard values since the dataset is the same or should I calculate them on my own? If so how can I do so?",t2_bgbkqzms,False,,0,False,CIFAR 100 Mean &amp; STD,[],r/deeplearning,False,6,,0,,False,t3_nh1zqa,False,dark,0.89,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,True,,1621550455.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone, &lt;/p&gt;

&lt;p&gt;Sorry if it&amp;#39;s a noob question I am new to this. As far as I understand I need the mean and std of the dataset to preprocess the data before training, but where do I get these values? is there are standard values since the dataset is the same or should I calculate them on my own? If so how can I do so?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nh1zqa,True,,mohamd95,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/nh1zqa/cifar_100_mean_std/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nh1zqa/cifar_100_mean_std/,66147,1621521655.0,0,,False,,,,,,,
,deeplearning,"The main thing I am confused about is what type of aws service to use ? I have found mainly two ways to train deep learning models on AWS.

Firstly the EC2 p2 (which p2 type to select for V100 ?), where I can spin up a server with some preinstalled libraries, ssh to it and run my scripts. Here I want to know what's good way to store my dataset (5-10GB or more) and model logs - s3 or elastic block storage ? and to shutdown once training finishes.

Secondly I have seen aws Sagemaker which provides full development environment which I think I don't need.

I have my code and dataset ready just need to find best way to quickly run and get most out of my credits and not waste time/money running instances. If anyone is using aws for training, it would be helpful if u could share some tips and gotchas.

Thank you.

PS: I am already using colab, just need to use my AWS credits for longer stable training.",t2_4oe65o93,False,,0,False,Looking for best way to use AWS credits for deep learning ?,[],r/deeplearning,False,6,,0,,False,t3_nguk6s,False,dark,0.94,,public,16,0,{},,False,[],,False,False,,{},,False,16,,False,False,,1621499412.0,,[],{},,True,,1621527743.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The main thing I am confused about is what type of aws service to use ? I have found mainly two ways to train deep learning models on AWS.&lt;/p&gt;

&lt;p&gt;Firstly the EC2 p2 (which p2 type to select for V100 ?), where I can spin up a server with some preinstalled libraries, ssh to it and run my scripts. Here I want to know what&amp;#39;s good way to store my dataset (5-10GB or more) and model logs - s3 or elastic block storage ? and to shutdown once training finishes.&lt;/p&gt;

&lt;p&gt;Secondly I have seen aws Sagemaker which provides full development environment which I think I don&amp;#39;t need.&lt;/p&gt;

&lt;p&gt;I have my code and dataset ready just need to find best way to quickly run and get most out of my credits and not waste time/money running instances. If anyone is using aws for training, it would be helpful if u could share some tips and gotchas.&lt;/p&gt;

&lt;p&gt;Thank you.&lt;/p&gt;

&lt;p&gt;PS: I am already using colab, just need to use my AWS credits for longer stable training.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nguk6s,True,,0x00groot,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/nguk6s/looking_for_best_way_to_use_aws_credits_for_deep/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nguk6s/looking_for_best_way_to_use_aws_credits_for_deep/,66147,1621498943.0,0,,False,,,,,,,
,deeplearning,,t2_1di8jk8w,False,,0,False,The next step of a Bayesian Brain | Scientists can now brainstorm with Tzager to find solutions for…,[],r/deeplearning,False,6,,0,,False,t3_nh8p5h,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1621566496.0,text,6,,,text,link.medium.com,False,,,,,https://link.medium.com/jUJl3wn6pgb,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nh8p5h,True,,nikostzagkarakis,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nh8p5h/the_next_step_of_a_bayesian_brain_scientists_can/,all_ads,False,https://link.medium.com/jUJl3wn6pgb,66147,1621537696.0,0,,False,,,,,,,
,deeplearning,,t2_6e37cydc,False,,0,False,The 5 Top AI-Powered Drug Discovery Tools in 2021,[],r/deeplearning,False,6,,0,,False,t3_nhc49c,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1621575099.0,text,6,,,text,medium.com,False,,,,,https://medium.com/geekculture/5-cool-ai-powered-drug-discovery-tools-1d7e976ffc2a,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nhc49c,True,,pasticciociccio,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nhc49c/the_5_top_aipowered_drug_discovery_tools_in_2021/,all_ads,False,https://medium.com/geekculture/5-cool-ai-powered-drug-discovery-tools-1d7e976ffc2a,66147,1621546299.0,0,,False,,,,,,,
,deeplearning,"Hi all,

I have a locally written python project with a TensorFlow model. Is it possible to use the processing power of Google Colab to train this model remotely?

More detailed explanation:

I have a project locally (and on GitHub) that I wrote in PyCharm to train a model with TensorFlow. It's up and running so far and locally I can use the CPU and GPU of my PC. I am wondering if it is also possible to train my model with Google Colab or Google Colab Pro.

I was thinking about moving the complete project to google drive, including the dataset. From my understanding, I could then execute my '[main.py](https://main.py)' normally. Are there any limitations I am not aware of?",t2_69srzkcq,False,,0,False,Is it possible to use Google Colab with a local python TensorFlow project?,[],r/deeplearning,False,6,,0,,False,t3_nhbtvj,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621574373.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I have a locally written python project with a TensorFlow model. Is it possible to use the processing power of Google Colab to train this model remotely?&lt;/p&gt;

&lt;p&gt;More detailed explanation:&lt;/p&gt;

&lt;p&gt;I have a project locally (and on GitHub) that I wrote in PyCharm to train a model with TensorFlow. It&amp;#39;s up and running so far and locally I can use the CPU and GPU of my PC. I am wondering if it is also possible to train my model with Google Colab or Google Colab Pro.&lt;/p&gt;

&lt;p&gt;I was thinking about moving the complete project to google drive, including the dataset. From my understanding, I could then execute my &amp;#39;&lt;a href=""https://main.py""&gt;main.py&lt;/a&gt;&amp;#39; normally. Are there any limitations I am not aware of?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nhbtvj,True,,Dunkin_1,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nhbtvj/is_it_possible_to_use_google_colab_with_a_local/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nhbtvj/is_it_possible_to_use_google_colab_with_a_local/,66147,1621545573.0,0,,False,,,,,,,
,deeplearning,"I have an assignment that can detect words/numbers by interpret lip reading , but I am not sure what is the best model to use. I am fine with open source code.

Would you please recommended any model/open source code that can help me",t2_8r3rei00,False,,0,False,What is the best model for Lip reading?,[],r/deeplearning,False,6,,0,,False,t3_nha3aq,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1621544047.0,,[],{},,True,,1621569960.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have an assignment that can detect words/numbers by interpret lip reading , but I am not sure what is the best model to use. I am fine with open source code.&lt;/p&gt;

&lt;p&gt;Would you please recommended any model/open source code that can help me&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nha3aq,True,,Ideal-Financial,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nha3aq/what_is_the_best_model_for_lip_reading/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nha3aq/what_is_the_best_model_for_lip_reading/,66147,1621541160.0,0,,False,,,,,,,
,deeplearning,"I'm looking to grade some objects relative to one another. So instead of trying to classify objects to a category in a database, I want it to say how similar or dissimilar they are from each other.
So in theory this wouldn't even need a database or categories, it's only comparing them to one another. 

Can someone please point me in the right direction of what type of deep learning algorithm would work like this?",t2_10vys7,False,,0,False,No classification categories?,[],r/deeplearning,False,6,,0,,False,t3_nh914c,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621567340.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking to grade some objects relative to one another. So instead of trying to classify objects to a category in a database, I want it to say how similar or dissimilar they are from each other.
So in theory this wouldn&amp;#39;t even need a database or categories, it&amp;#39;s only comparing them to one another. &lt;/p&gt;

&lt;p&gt;Can someone please point me in the right direction of what type of deep learning algorithm would work like this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nh914c,True,,spro22,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nh914c/no_classification_categories/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nh914c/no_classification_categories/,66147,1621538540.0,0,,False,,,,,,,
,deeplearning,"Hello everyone
I need help with finding  an audio dataset .

Wall Streeet journal 0 ( WSJ0) 
Please gays 🙏.",t2_87kw7udb,False,,0,False,WsJ0,[],r/deeplearning,False,6,,0,,False,t3_nhbvg3,False,dark,0.25,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621574482.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone
I need help with finding  an audio dataset .&lt;/p&gt;

&lt;p&gt;Wall Streeet journal 0 ( WSJ0) 
Please gays 🙏.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nhbvg3,True,,Abdennour_Abour,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nhbvg3/wsj0/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nhbvg3/wsj0/,66147,1621545682.0,0,,False,,,,,,,
,deeplearning,"# NLU 3.0.1 Release Notes
We are very excited to announce NLU 3.0.1 has been released!
This is one of the most visually appealing releases, with the integration of the [Spark-NLP-Display](https://nlp.johnsnowlabs.com/docs/en/display) library and visualizations for `dependency trees`, `entity resolution`, `entity assertion`, `relationship between entities` and `named
entity recognition`. In addition to this, the schema of how columns are named by NLU has been reworked and all 140+ tutorial notebooks have been updated to reflect the latest changes in NLU 3.0.0+
Finally, new multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese` are now available.




# New Features and Enhancements
- 1 line to visualization for `NER`, `Dependency`, `Resolution`, `Assertion` and `Relation` via [Spark-NLP-Display](https://nlp.johnsnowlabs.com/docs/en/display) integration
- Improved column naming schema
- [Over 140 + NLU tutorial Notebooks updated](https://github.com/JohnSnowLabs/nlu/tree/master/examples) and improved to reflect latest changes in NLU 3.0.0 +
- New multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese`
- Enhanced offline loading


## NLU visualization
The latest NLU release integrated the beautiful Spark-NLP-Display package visualizations. You do not need to worry about installing it, when you try to visualize something, NLU will check if
Spark-NLP-Display is installed, if it is missing it will be dynamically installed into your python executable environment, so you don't need to worry about anything!

See the [visualization tutorial notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/visualization/NLU_visualizations_tutorial.ipynb)  and [visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples) for more info.

![Cheat Sheet visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/cheat_sheet.png)

## NER visualization
Applicable to any of the [100+ NER models! See here for an overview](https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition)
```python
nlu.load('ner').viz(""Donald Trump from America and Angela Merkel from Germany don't share many oppinions."")
```
![NER visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/NER.png)

## Dependency tree visualization
Visualizes the structure of the labeled dependency tree and part of speech tags
```python
nlu.load('dep.typed').viz(""Billy went to the mall"")
```

![Dependency Tree visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP.png)

```python
#Bigger Example
nlu.load('dep.typed').viz(""Donald Trump from America and Angela Merkel from Germany don't share many oppinions but they both love John Snow Labs software"")
```
![Dependency Tree visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP_big.png)

## Assertion status visualization
Visualizes asserted statuses and entities.        
Applicable to any of the [10 + Assertion models! See here for an overview](https://nlp.johnsnowlabs.com/models?task=Assertion+Status)
```python
nlu.load('med_ner.clinical assert').viz(""The MRI scan showed no signs of cancer in the left lung"")
```


![Assert visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion.png)

```python
#bigger example
data ='This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed.'
nlu.load('med_ner.clinical assert').viz(data)
```
![Assert visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion_big.png)


## Relationship between entities visualization
Visualizes the extracted entities between relationship.    
Applicable to any of the [20 + Relation Extractor models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Relation+Extraction)
```python
nlu.load('med_ner.jsl.wip.clinical relation.temporal_events').viz('The patient developed cancer after a mercury poisoning in 1999 ')
```
![Entity Relation visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation.png)

```python
# bigger example
data = 'This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed'
pipe = nlu.load('med_ner.jsl.wip.clinical relation.clinical').viz(data)
```
![Entity Relation visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation_big.png)


## Entity Resolution visualization for chunks
Visualizes resolutions of entities
Applicable to any of the [100+ Resolver models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Entity+Resolution)
```python
nlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(""He took Prevacid 30 mg  daily"")
```
![Chunk Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk.png)

```python
# bigger example
data = ""This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret\'s Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .""
nlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(data)
```

![Chunk Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk_big.png)


## Entity Resolution visualization for sentences
Visualizes resolutions of entities in sentences
Applicable to any of the [100+ Resolver models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Entity+Resolution)
```python
nlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz('She was diagnosed with a respiratory congestion')
```
![Sentence Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence.png)

```python
# bigger example
data = 'The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion'
nlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz(data)
```
![Sentence Resolution visualization](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence_big.png)

## Configure visualizations
### Define custom colors for labels
Some entity and relation labels will be highlighted with a pre-defined color, which you [can find here](https://github.com/JohnSnowLabs/spark-nlp-display/tree/main/sparknlp_display/label_colors).    
For labels that have no color defined, a random color will be generated.     
You can define colors for labels manually, by specifying via the `viz_colors` parameter
and defining `hex color codes` in a dictionary that maps `labels` to `colors` .
```python
data = 'Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough'
# Define custom colors for labels
viz_colors={'STRENGTH':'#800080', 'DRUG_BRANDNAME':'#77b5fe', 'GENDER':'#77ffe'}
nlu.load('med_ner.jsl.wip.clinical').viz(data,viz_colors =viz_colors)
```
![define colors labels](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/define_colors.png)


### Filter entities that get highlighted
By default every entity class will be visualized.    
The `labels_to_viz` can be used to define a set of labels to highlight.       
Applicable for ner, resolution and assert.
```python
data = 'Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough'
# Filter wich NER label to viz
labels_to_viz=['SYMPTOM']
nlu.load('med_ner.jsl.wip.clinical').viz(data,labels_to_viz=labels_to_viz)
```
![filter labels](https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/filter_labels.png)


## New models
New multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese`

| nlu.load() Refrence                                          | Spark NLP Refrence                                           |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [vi.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html) |
| [mt.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html) |
| [ta.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html) |
| [af.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html) |
| [af.pos](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) | [pos_afribooms](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html) |
| [cy.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) | [lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html) |

## Reworked and updated NLU tutorial notebooks

All of the [140+ NLU tutorial Notebooks](https://github.com/JohnSnowLabs/nlu/tree/master/examples) have been updated and reworked to reflect the latest changes in NLU 3.0.0+


## Improved Column Name generation
- NLU categorized each internal component now with boolean labels for `name_deductable` and `always_name_deductable` .
- Before generating column names, NLU checks wether each component is of unique in the pipeline or not. If a component is not unique in the
  pipe and there are multiple components of same type, i.e. multiple `NER` models, NLU will deduct a base name for the final output columns from the
  NLU reference each NER model is pointing to.
- If on the other hand, there is only one `NER` model in the pipeline, only the default `ner` column prefixed will be generated.
- For some components, like `embeddings` and `classifiers` are now defined as `always_name_deductable`, for those NLU will always try to infer a meaningful base name for the output columns.
- Newly trained component output columns will now be prefixed with `trained_&lt;type&gt;` , for types `pos` , `ner`, `cLassifier`, `sentiment` and `multi_classifier`

## Enhanced offline mode
- You can still load a model from a path as usual with `nlu.load(path=model_path)` and output columns will be suffixed with `from_disk`
- You can now optionally also specify `request` parameter during  load a model from HDD, it will be used to deduct more meaningful column name suffixes, instead of `from_disk`, i.e. by calling `nlu.load(request ='en.embed_sentence.biobert.pubmed_pmc_base_cased', path=model_path)`


### Bugfixes
- Fixed a bug that caused  resolution algorithms output level to be inferred incorrectly
- Fixed a bug that caused stranger cols got dropped
- Fixed a bug that caused endings to miss when  .predict(position=True) was specified
- Fixed a bug that caused pd.Series to be converted incorrectly internally
- Fixed a bug that caused output level transformations to crash
- Fixed a bug that caused verbose mode not to turn of properly after turning it on.
- fixed a bug that caused some models to crash when loaded for HDD

# Additional NLU resources
* [140+ updates tutorials](https://github.com/JohnSnowLabs/nlu/tree/master/examples)
* [Updated visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples)
* [Models Hub](https://nlp.johnsnowlabs.com/models) with new models
* [Spark NLP publications](https://medium.com/spark-nlp)
* [NLU in Action](https://nlp.johnsnowlabs.com/demo)
* [NLU documentation](https://nlu.johnsnowlabs.com/docs/en/install)
* [Discussions](https://github.com/JohnSnowLabs/spark-nlp/discussions) Engage with other community members, share ideas, and show off how you use Spark NLP and NLU!

# 1 line Install NLU on Google Colab
```!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash```
# 1 line Install NLU on Kaggle
```!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash```
# Install via PIP
```! pip install nlu pyspark==3.0.1```",t2_53n73cus,False,,0,False,"1 line to visualizations for dependency trees, entity relationships, resolution, assertion, NER and new models for Afrikaans, Welsh, Maltese, Tamil, and Vietnamese - John Snow Labs NLU 3.0.1 for Python",[],r/deeplearning,False,6,,0,,False,t3_nh4rq8,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621557096.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h1&gt;NLU 3.0.1 Release Notes&lt;/h1&gt;

&lt;p&gt;We are very excited to announce NLU 3.0.1 has been released!
This is one of the most visually appealing releases, with the integration of the &lt;a href=""https://nlp.johnsnowlabs.com/docs/en/display""&gt;Spark-NLP-Display&lt;/a&gt; library and visualizations for &lt;code&gt;dependency trees&lt;/code&gt;, &lt;code&gt;entity resolution&lt;/code&gt;, &lt;code&gt;entity assertion&lt;/code&gt;, &lt;code&gt;relationship between entities&lt;/code&gt; and &lt;code&gt;named
entity recognition&lt;/code&gt;. In addition to this, the schema of how columns are named by NLU has been reworked and all 140+ tutorial notebooks have been updated to reflect the latest changes in NLU 3.0.0+
Finally, new multilingual models for &lt;code&gt;Afrikaans&lt;/code&gt;, &lt;code&gt;Welsh&lt;/code&gt;, &lt;code&gt;Maltese&lt;/code&gt;, &lt;code&gt;Tamil&lt;/code&gt;, and&lt;code&gt;Vietnamese&lt;/code&gt; are now available.&lt;/p&gt;

&lt;h1&gt;New Features and Enhancements&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;1 line to visualization for &lt;code&gt;NER&lt;/code&gt;, &lt;code&gt;Dependency&lt;/code&gt;, &lt;code&gt;Resolution&lt;/code&gt;, &lt;code&gt;Assertion&lt;/code&gt; and &lt;code&gt;Relation&lt;/code&gt; via &lt;a href=""https://nlp.johnsnowlabs.com/docs/en/display""&gt;Spark-NLP-Display&lt;/a&gt; integration&lt;/li&gt;
&lt;li&gt;Improved column naming schema&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/tree/master/examples""&gt;Over 140 + NLU tutorial Notebooks updated&lt;/a&gt; and improved to reflect latest changes in NLU 3.0.0 +&lt;/li&gt;
&lt;li&gt;New multilingual models for &lt;code&gt;Afrikaans&lt;/code&gt;, &lt;code&gt;Welsh&lt;/code&gt;, &lt;code&gt;Maltese&lt;/code&gt;, &lt;code&gt;Tamil&lt;/code&gt;, and&lt;code&gt;Vietnamese&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Enhanced offline loading&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;NLU visualization&lt;/h2&gt;

&lt;p&gt;The latest NLU release integrated the beautiful Spark-NLP-Display package visualizations. You do not need to worry about installing it, when you try to visualize something, NLU will check if
Spark-NLP-Display is installed, if it is missing it will be dynamically installed into your python executable environment, so you don&amp;#39;t need to worry about anything!&lt;/p&gt;

&lt;p&gt;See the &lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/visualization/NLU_visualizations_tutorial.ipynb""&gt;visualization tutorial notebook&lt;/a&gt;  and &lt;a href=""https://nlu.johnsnowlabs.com/docs/en/viz_examples""&gt;visualization docs&lt;/a&gt; for more info.&lt;/p&gt;

&lt;p&gt;![Cheat Sheet visualization](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/cheat_sheet.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/cheat_sheet.png&lt;/a&gt;)&lt;/p&gt;

&lt;h2&gt;NER visualization&lt;/h2&gt;

&lt;p&gt;Applicable to any of the &lt;a href=""https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition""&gt;100+ NER models! See here for an overview&lt;/a&gt;
&lt;code&gt;python
nlu.load(&amp;#39;ner&amp;#39;).viz(&amp;quot;Donald Trump from America and Angela Merkel from Germany don&amp;#39;t share many oppinions.&amp;quot;)
&lt;/code&gt;
![NER visualization](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/NER.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/NER.png&lt;/a&gt;)&lt;/p&gt;

&lt;h2&gt;Dependency tree visualization&lt;/h2&gt;

&lt;p&gt;Visualizes the structure of the labeled dependency tree and part of speech tags
&lt;code&gt;python
nlu.load(&amp;#39;dep.typed&amp;#39;).viz(&amp;quot;Billy went to the mall&amp;quot;)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;![Dependency Tree visualization](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP.png&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;```python&lt;/p&gt;

&lt;h1&gt;Bigger Example&lt;/h1&gt;

&lt;p&gt;nlu.load(&amp;#39;dep.typed&amp;#39;).viz(&amp;quot;Donald Trump from America and Angela Merkel from Germany don&amp;#39;t share many oppinions but they both love John Snow Labs software&amp;quot;)
```
![Dependency Tree visualization](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP_big.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/DEP_big.png&lt;/a&gt;)&lt;/p&gt;

&lt;h2&gt;Assertion status visualization&lt;/h2&gt;

&lt;p&gt;Visualizes asserted statuses and entities.&lt;br/&gt;
Applicable to any of the &lt;a href=""https://nlp.johnsnowlabs.com/models?task=Assertion+Status""&gt;10 + Assertion models! See here for an overview&lt;/a&gt;
&lt;code&gt;python
nlu.load(&amp;#39;med_ner.clinical assert&amp;#39;).viz(&amp;quot;The MRI scan showed no signs of cancer in the left lung&amp;quot;)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;![Assert visualization](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion.png&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;```python&lt;/p&gt;

&lt;h1&gt;bigger example&lt;/h1&gt;

&lt;p&gt;data =&amp;#39;This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed.&amp;#39;
nlu.load(&amp;#39;med_ner.clinical assert&amp;#39;).viz(data)
```
![Assert visualization](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion_big.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/assertion_big.png&lt;/a&gt;)&lt;/p&gt;

&lt;h2&gt;Relationship between entities visualization&lt;/h2&gt;

&lt;p&gt;Visualizes the extracted entities between relationship.&lt;br/&gt;
Applicable to any of the &lt;a href=""https://nlp.johnsnowlabs.com/models?task=Relation+Extraction""&gt;20 + Relation Extractor models See here for an overview&lt;/a&gt;
&lt;code&gt;python
nlu.load(&amp;#39;med_ner.jsl.wip.clinical relation.temporal_events&amp;#39;).viz(&amp;#39;The patient developed cancer after a mercury poisoning in 1999 &amp;#39;)
&lt;/code&gt;
![Entity Relation visualization](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation.png&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;```python&lt;/p&gt;

&lt;h1&gt;bigger example&lt;/h1&gt;

&lt;p&gt;data = &amp;#39;This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed&amp;#39;
pipe = nlu.load(&amp;#39;med_ner.jsl.wip.clinical relation.clinical&amp;#39;).viz(data)
```
![Entity Relation visualization](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation_big.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/relation_big.png&lt;/a&gt;)&lt;/p&gt;

&lt;h2&gt;Entity Resolution visualization for chunks&lt;/h2&gt;

&lt;p&gt;Visualizes resolutions of entities
Applicable to any of the &lt;a href=""https://nlp.johnsnowlabs.com/models?task=Entity+Resolution""&gt;100+ Resolver models See here for an overview&lt;/a&gt;
&lt;code&gt;python
nlu.load(&amp;#39;med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in&amp;#39;).viz(&amp;quot;He took Prevacid 30 mg  daily&amp;quot;)
&lt;/code&gt;
![Chunk Resolution visualization](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk.png&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;```python&lt;/p&gt;

&lt;h1&gt;bigger example&lt;/h1&gt;

&lt;p&gt;data = &amp;quot;This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret\&amp;#39;s Center for Women &amp;amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .&amp;quot;
nlu.load(&amp;#39;med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in&amp;#39;).viz(data)
```&lt;/p&gt;

&lt;p&gt;![Chunk Resolution visualization](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk_big.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_chunk_big.png&lt;/a&gt;)&lt;/p&gt;

&lt;h2&gt;Entity Resolution visualization for sentences&lt;/h2&gt;

&lt;p&gt;Visualizes resolutions of entities in sentences
Applicable to any of the &lt;a href=""https://nlp.johnsnowlabs.com/models?task=Entity+Resolution""&gt;100+ Resolver models See here for an overview&lt;/a&gt;
&lt;code&gt;python
nlu.load(&amp;#39;med_ner.jsl.wip.clinical resolve.icd10cm&amp;#39;).viz(&amp;#39;She was diagnosed with a respiratory congestion&amp;#39;)
&lt;/code&gt;
![Sentence Resolution visualization](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence.png&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;```python&lt;/p&gt;

&lt;h1&gt;bigger example&lt;/h1&gt;

&lt;p&gt;data = &amp;#39;The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion&amp;#39;
nlu.load(&amp;#39;med_ner.jsl.wip.clinical resolve.icd10cm&amp;#39;).viz(data)
```
![Sentence Resolution visualization](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence_big.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/resolve_sentence_big.png&lt;/a&gt;)&lt;/p&gt;

&lt;h2&gt;Configure visualizations&lt;/h2&gt;

&lt;h3&gt;Define custom colors for labels&lt;/h3&gt;

&lt;p&gt;Some entity and relation labels will be highlighted with a pre-defined color, which you &lt;a href=""https://github.com/JohnSnowLabs/spark-nlp-display/tree/main/sparknlp_display/label_colors""&gt;can find here&lt;/a&gt;.&lt;br/&gt;
For labels that have no color defined, a random color will be generated.&lt;br/&gt;
You can define colors for labels manually, by specifying via the &lt;code&gt;viz_colors&lt;/code&gt; parameter
and defining &lt;code&gt;hex color codes&lt;/code&gt; in a dictionary that maps &lt;code&gt;labels&lt;/code&gt; to &lt;code&gt;colors&lt;/code&gt; .
```python
data = &amp;#39;Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough&amp;#39;&lt;/p&gt;

&lt;h1&gt;Define custom colors for labels&lt;/h1&gt;

&lt;p&gt;viz_colors={&amp;#39;STRENGTH&amp;#39;:&amp;#39;#800080&amp;#39;, &amp;#39;DRUG_BRANDNAME&amp;#39;:&amp;#39;#77b5fe&amp;#39;, &amp;#39;GENDER&amp;#39;:&amp;#39;#77ffe&amp;#39;}
nlu.load(&amp;#39;med_ner.jsl.wip.clinical&amp;#39;).viz(data,viz_colors =viz_colors)
```
![define colors labels](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/define_colors.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/define_colors.png&lt;/a&gt;)&lt;/p&gt;

&lt;h3&gt;Filter entities that get highlighted&lt;/h3&gt;

&lt;p&gt;By default every entity class will be visualized.&lt;br/&gt;
The &lt;code&gt;labels_to_viz&lt;/code&gt; can be used to define a set of labels to highlight.&lt;br/&gt;
Applicable for ner, resolution and assert.
```python
data = &amp;#39;Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough&amp;#39;&lt;/p&gt;

&lt;h1&gt;Filter wich NER label to viz&lt;/h1&gt;

&lt;p&gt;labels_to_viz=[&amp;#39;SYMPTOM&amp;#39;]
nlu.load(&amp;#39;med_ner.jsl.wip.clinical&amp;#39;).viz(data,labels_to_viz=labels_to_viz)
```
![filter labels](&lt;a href=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/filter_labels.png""&gt;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz_module/filter_labels.png&lt;/a&gt;)&lt;/p&gt;

&lt;h2&gt;New models&lt;/h2&gt;

&lt;p&gt;New multilingual models for &lt;code&gt;Afrikaans&lt;/code&gt;, &lt;code&gt;Welsh&lt;/code&gt;, &lt;code&gt;Maltese&lt;/code&gt;, &lt;code&gt;Tamil&lt;/code&gt;, and&lt;code&gt;Vietnamese&lt;/code&gt;&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;nlu.load() Refrence&lt;/th&gt;
&lt;th&gt;Spark NLP Refrence&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html""&gt;vi.lemma&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html""&gt;lemma&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html""&gt;mt.lemma&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html""&gt;lemma&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html""&gt;ta.lemma&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html""&gt;lemma&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html""&gt;af.lemma&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html""&gt;lemma&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html""&gt;af.pos&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html""&gt;pos_afribooms&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html""&gt;cy.lemma&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html""&gt;lemma&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;Reworked and updated NLU tutorial notebooks&lt;/h2&gt;

&lt;p&gt;All of the &lt;a href=""https://github.com/JohnSnowLabs/nlu/tree/master/examples""&gt;140+ NLU tutorial Notebooks&lt;/a&gt; have been updated and reworked to reflect the latest changes in NLU 3.0.0+&lt;/p&gt;

&lt;h2&gt;Improved Column Name generation&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;NLU categorized each internal component now with boolean labels for &lt;code&gt;name_deductable&lt;/code&gt; and &lt;code&gt;always_name_deductable&lt;/code&gt; .&lt;/li&gt;
&lt;li&gt;Before generating column names, NLU checks wether each component is of unique in the pipeline or not. If a component is not unique in the
pipe and there are multiple components of same type, i.e. multiple &lt;code&gt;NER&lt;/code&gt; models, NLU will deduct a base name for the final output columns from the
NLU reference each NER model is pointing to.&lt;/li&gt;
&lt;li&gt;If on the other hand, there is only one &lt;code&gt;NER&lt;/code&gt; model in the pipeline, only the default &lt;code&gt;ner&lt;/code&gt; column prefixed will be generated.&lt;/li&gt;
&lt;li&gt;For some components, like &lt;code&gt;embeddings&lt;/code&gt; and &lt;code&gt;classifiers&lt;/code&gt; are now defined as &lt;code&gt;always_name_deductable&lt;/code&gt;, for those NLU will always try to infer a meaningful base name for the output columns.&lt;/li&gt;
&lt;li&gt;Newly trained component output columns will now be prefixed with &lt;code&gt;trained_&amp;lt;type&amp;gt;&lt;/code&gt; , for types &lt;code&gt;pos&lt;/code&gt; , &lt;code&gt;ner&lt;/code&gt;, &lt;code&gt;cLassifier&lt;/code&gt;, &lt;code&gt;sentiment&lt;/code&gt; and &lt;code&gt;multi_classifier&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Enhanced offline mode&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;You can still load a model from a path as usual with &lt;code&gt;nlu.load(path=model_path)&lt;/code&gt; and output columns will be suffixed with &lt;code&gt;from_disk&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;You can now optionally also specify &lt;code&gt;request&lt;/code&gt; parameter during  load a model from HDD, it will be used to deduct more meaningful column name suffixes, instead of &lt;code&gt;from_disk&lt;/code&gt;, i.e. by calling &lt;code&gt;nlu.load(request =&amp;#39;en.embed_sentence.biobert.pubmed_pmc_base_cased&amp;#39;, path=model_path)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Bugfixes&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Fixed a bug that caused  resolution algorithms output level to be inferred incorrectly&lt;/li&gt;
&lt;li&gt;Fixed a bug that caused stranger cols got dropped&lt;/li&gt;
&lt;li&gt;Fixed a bug that caused endings to miss when  .predict(position=True) was specified&lt;/li&gt;
&lt;li&gt;Fixed a bug that caused pd.Series to be converted incorrectly internally&lt;/li&gt;
&lt;li&gt;Fixed a bug that caused output level transformations to crash&lt;/li&gt;
&lt;li&gt;Fixed a bug that caused verbose mode not to turn of properly after turning it on.&lt;/li&gt;
&lt;li&gt;fixed a bug that caused some models to crash when loaded for HDD&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;Additional NLU resources&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/tree/master/examples""&gt;140+ updates tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlu.johnsnowlabs.com/docs/en/viz_examples""&gt;Updated visualization docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlp.johnsnowlabs.com/models""&gt;Models Hub&lt;/a&gt; with new models&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://medium.com/spark-nlp""&gt;Spark NLP publications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlp.johnsnowlabs.com/demo""&gt;NLU in Action&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlu.johnsnowlabs.com/docs/en/install""&gt;NLU documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/spark-nlp/discussions""&gt;Discussions&lt;/a&gt; Engage with other community members, share ideas, and show off how you use Spark NLP and NLU!&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;1 line Install NLU on Google Colab&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;!wget https://setup.johnsnowlabs.com/nlu/colab.sh  -O - | bash&lt;/code&gt;&lt;/p&gt;

&lt;h1&gt;1 line Install NLU on Kaggle&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh  -O - | bash&lt;/code&gt;&lt;/p&gt;

&lt;h1&gt;Install via PIP&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;! pip install nlu pyspark==3.0.1&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nh4rq8,True,,CKL-IT,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nh4rq8/1_line_to_visualizations_for_dependency_trees/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nh4rq8/1_line_to_visualizations_for_dependency_trees/,66147,1621528296.0,0,,False,,,,,,,
,deeplearning,"# NLU 3.0.1 Release Notes

We are very excited to announce NLU 3.0.1 has been released! This is one of the most visually appealing releases, with the integration of the [Spark-NLP-Display](https://nlp.johnsnowlabs.com/docs/en/display) library and visualizations for `dependency trees`, `entity resolution`, `entity assertion`, `relationship between entities` and `named entity recognition`. In addition to this, the schema of how columns are named by NLU has been reworked and all 140+ tutorial notebooks have been updated to reflect the latest changes in NLU 3.0.0+ Finally, new multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese` are now available.

# New Features and Enhancements

* 1 line to visualization for `NER`, `Dependency`, `Resolution`, `Assertion` and `Relation` via [Spark-NLP-Display](https://nlp.johnsnowlabs.com/docs/en/display) integration
* Improved column naming schema
* [Over 140 + NLU tutorial Notebooks updated](https://github.com/JohnSnowLabs/nlu/tree/master/examples) and improved to reflect latest changes in NLU 3.0.0 +
* New multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese`
* Enhanced offline loading

https://preview.redd.it/jcdi7fjxza071.png?width=1498&amp;format=png&amp;auto=webp&amp;s=8092331204f0d38e08b220dc470c7f8d44503fa2

## NLU visualization

The latest NLU release integrated the beautiful Spark-NLP-Display package visualizations. You do not need to worry about installing it, when you try to visualize something, NLU will check if Spark-NLP-Display is installed, if it is missing it will be dynamically installed into your python executable environment, so you don't need to worry about anything!

See the [visualization tutorial notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/visualization/NLU_visualizations_tutorial.ipynb)  and [visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples) for more info.

&lt;img src=""https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz\_module/cheat\_sheet.png"" alt=""Cheat Sheet visualization""&gt;  


## NER visualization

Applicable to any of the [100+ NER models! See here for an overview](https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition)

    nlu.load('ner').viz(""Donald Trump from America and Angela Merkel from Germany don't share many oppinions."")

NER visualization

## Dependency tree visualization

Visualizes the structure of the labeled dependency tree and part of speech tags

    nlu.load('dep.typed').viz(""Billy went to the mall"")

Dependency Tree visualization

    #Bigger Example
    nlu.load('dep.typed').viz(""Donald Trump from America and Angela Merkel from Germany don't share many oppinions but they both love John Snow Labs software"")

Dependency Tree visualization

## Assertion status visualization

Visualizes asserted statuses and entities.Applicable to any of the [10 + Assertion models! See here for an overview](https://nlp.johnsnowlabs.com/models?task=Assertion+Status)

    nlu.load('med_ner.clinical assert').viz(""The MRI scan showed no signs of cancer in the left lung"")

Assert visualization

    #bigger example
    data ='This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed.'
    nlu.load('med_ner.clinical assert').viz(data)

Assert visualization

## Relationship between entities visualization

Visualizes the extracted entities between relationship.Applicable to any of the [20 + Relation Extractor models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Relation+Extraction)

    nlu.load('med_ner.jsl.wip.clinical relation.temporal_events').viz('The patient developed cancer after a mercury poisoning in 1999 ')

Entity Relation visualization

    # bigger example
    data = 'This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed'
    pipe = nlu.load('med_ner.jsl.wip.clinical relation.clinical').viz(data)

Entity Relation visualization

## Entity Resolution visualization for chunks

Visualizes resolutions of entities Applicable to any of the [100+ Resolver models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Entity+Resolution)

    nlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(""He took Prevacid 30 mg  daily"")

Chunk Resolution visualization

    # bigger example
    data = ""This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret\'s Center for Women &amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .""
    nlu.load('med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in').viz(data)

Chunk Resolution visualization

## Entity Resolution visualization for sentences

Visualizes resolutions of entities in sentences Applicable to any of the [100+ Resolver models See here for an overview](https://nlp.johnsnowlabs.com/models?task=Entity+Resolution)

    nlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz('She was diagnosed with a respiratory congestion')

Sentence Resolution visualization

    # bigger example
    data = 'The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion'
    nlu.load('med_ner.jsl.wip.clinical resolve.icd10cm').viz(data)

Sentence Resolution visualization

## Configure visualizations

## Define custom colors for labels

Some entity and relation labels will be highlighted with a pre-defined color, which you [can find here](https://github.com/JohnSnowLabs/spark-nlp-display/tree/main/sparknlp_display/label_colors).For labels that have no color defined, a random color will be generated.You can define colors for labels manually, by specifying via the `viz_colors` parameter and defining `hex color codes` in a dictionary that maps `labels` to `colors` .

    data = 'Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough'
    # Define custom colors for labels
    viz_colors={'STRENGTH':'#800080', 'DRUG_BRANDNAME':'#77b5fe', 'GENDER':'#77ffe'}
    nlu.load('med_ner.jsl.wip.clinical').viz(data,viz_colors =viz_colors)

define colors labels

## Filter entities that get highlighted

By default every entity class will be visualized.The `labels_to_viz` can be used to define a set of labels to highlight.Applicable for ner, resolution and assert.

    data = 'Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough'
    # Filter wich NER label to viz
    labels_to_viz=['SYMPTOM']
    nlu.load('med_ner.jsl.wip.clinical').viz(data,labels_to_viz=labels_to_viz)

filter labels

## New models

New multilingual models for `Afrikaans`, `Welsh`, `Maltese`, `Tamil`, and`Vietnamese`

|nlu.load() Refrence|Spark NLP Refrence|
|:-|:-|
|[vi.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html)|[lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html)|
|[mt.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html)|[lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html)|
|[ta.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html)|[lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html)|
|[af.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html)|[lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html)|
|[af.pos](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html)|[pos\_afribooms](https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html)|
|[cy.lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html)|[lemma](https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html)|

## Reworked and updated NLU tutorial notebooks

All of the [140+ NLU tutorial Notebooks](https://github.com/JohnSnowLabs/nlu/tree/master/examples) have been updated and reworked to reflect the latest changes in NLU 3.0.0+

## Improved Column Name generation

* NLU categorized each internal component now with boolean labels for `name_deductable` and `always_name_deductable` .
* Before generating column names, NLU checks wether each component is of unique in the pipeline or not. If a component is not unique in the pipe and there are multiple components of same type, i.e. multiple `NER` models, NLU will deduct a base name for the final output columns from the NLU reference each NER model is pointing to.
* If on the other hand, there is only one `NER` model in the pipeline, only the default `ner` column prefixed will be generated.
* For some components, like `embeddings` and `classifiers` are now defined as `always_name_deductable`, for those NLU will always try to infer a meaningful base name for the output columns.
* Newly trained component output columns will now be prefixed with `trained_&lt;type&gt;` , for types `pos` , `ner`, `cLassifier`, `sentiment` and `multi_classifier`

## Enhanced offline mode

* You can still load a model from a path as usual with `nlu.load(path=model_path)` and output columns will be suffixed with `from_disk`
* You can now optionally also specify `request` parameter during  load a model from HDD, it will be used to deduct more meaningful column name suffixes, instead of `from_disk`, i.e. by calling `nlu.load(request ='en.embed_sentence.biobert.pubmed_pmc_base_cased', path=model_path)`

## Bugfixes

* Fixed a bug that caused  resolution algorithms output level to be inferred incorrectly
* Fixed a bug that caused stranger cols got dropped
* Fixed a bug that caused endings to miss when  .predict(position=True) was specified
* Fixed a bug that caused pd.Series to be converted incorrectly internally
* Fixed a bug that caused output level transformations to crash
* Fixed a bug that caused verbose mode not to turn of properly after turning it on.
* fixed a bug that caused some models to crash when loaded for HDD

# Additional NLU resources

* [140+ updates tutorials](https://github.com/JohnSnowLabs/nlu/tree/master/examples)
* [Updated visualization docs](https://nlu.johnsnowlabs.com/docs/en/viz_examples)
* [Models Hub](https://nlp.johnsnowlabs.com/models) with new models
* [Spark NLP publications](https://medium.com/spark-nlp)
* [NLU in Action](https://nlp.johnsnowlabs.com/demo)
* [NLU documentation](https://nlu.johnsnowlabs.com/docs/en/install)
* [Discussions](https://github.com/JohnSnowLabs/spark-nlp/discussions) Engage with other community members, share ideas, and show off how you use Spark NLP and NLU!

# 1 line Install NLU on Google Colab

`!wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash`

# 1 line Install NLU on Kaggle

`!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash`

# Install via PIP

`! pip install nlu pyspark==3.0.1`",t2_53n73cus,False,,0,False,"1 line to visualizations for dependency trees, entity relationships, resolution, assertion, NER and new models for Afrikaans, Welsh, Maltese, Tamil, and Vietnamese - John Snow Labs NLU 3.0.1 for Python",[],r/deeplearning,False,6,,0,,False,t3_nh4qja,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1621528737.0,,[],{},,True,,1621557017.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h1&gt;NLU 3.0.1 Release Notes&lt;/h1&gt;

&lt;p&gt;We are very excited to announce NLU 3.0.1 has been released! This is one of the most visually appealing releases, with the integration of the &lt;a href=""https://nlp.johnsnowlabs.com/docs/en/display""&gt;Spark-NLP-Display&lt;/a&gt; library and visualizations for &lt;code&gt;dependency trees&lt;/code&gt;, &lt;code&gt;entity resolution&lt;/code&gt;, &lt;code&gt;entity assertion&lt;/code&gt;, &lt;code&gt;relationship between entities&lt;/code&gt; and &lt;code&gt;named entity recognition&lt;/code&gt;. In addition to this, the schema of how columns are named by NLU has been reworked and all 140+ tutorial notebooks have been updated to reflect the latest changes in NLU 3.0.0+ Finally, new multilingual models for &lt;code&gt;Afrikaans&lt;/code&gt;, &lt;code&gt;Welsh&lt;/code&gt;, &lt;code&gt;Maltese&lt;/code&gt;, &lt;code&gt;Tamil&lt;/code&gt;, and&lt;code&gt;Vietnamese&lt;/code&gt; are now available.&lt;/p&gt;

&lt;h1&gt;New Features and Enhancements&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;1 line to visualization for &lt;code&gt;NER&lt;/code&gt;, &lt;code&gt;Dependency&lt;/code&gt;, &lt;code&gt;Resolution&lt;/code&gt;, &lt;code&gt;Assertion&lt;/code&gt; and &lt;code&gt;Relation&lt;/code&gt; via &lt;a href=""https://nlp.johnsnowlabs.com/docs/en/display""&gt;Spark-NLP-Display&lt;/a&gt; integration&lt;/li&gt;
&lt;li&gt;Improved column naming schema&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/tree/master/examples""&gt;Over 140 + NLU tutorial Notebooks updated&lt;/a&gt; and improved to reflect latest changes in NLU 3.0.0 +&lt;/li&gt;
&lt;li&gt;New multilingual models for &lt;code&gt;Afrikaans&lt;/code&gt;, &lt;code&gt;Welsh&lt;/code&gt;, &lt;code&gt;Maltese&lt;/code&gt;, &lt;code&gt;Tamil&lt;/code&gt;, and&lt;code&gt;Vietnamese&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Enhanced offline loading&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/jcdi7fjxza071.png?width=1498&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8092331204f0d38e08b220dc470c7f8d44503fa2""&gt;https://preview.redd.it/jcdi7fjxza071.png?width=1498&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8092331204f0d38e08b220dc470c7f8d44503fa2&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;NLU visualization&lt;/h2&gt;

&lt;p&gt;The latest NLU release integrated the beautiful Spark-NLP-Display package visualizations. You do not need to worry about installing it, when you try to visualize something, NLU will check if Spark-NLP-Display is installed, if it is missing it will be dynamically installed into your python executable environment, so you don&amp;#39;t need to worry about anything!&lt;/p&gt;

&lt;p&gt;See the &lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/visualization/NLU_visualizations_tutorial.ipynb""&gt;visualization tutorial notebook&lt;/a&gt;  and &lt;a href=""https://nlu.johnsnowlabs.com/docs/en/viz_examples""&gt;visualization docs&lt;/a&gt; for more info.&lt;/p&gt;

&lt;p&gt;&amp;lt;img src=&amp;quot;https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/docs/assets/images/nlu/VizExamples/viz\_module/cheat\_sheet.png&amp;quot; alt=&amp;quot;Cheat Sheet visualization&amp;quot;&amp;gt;  &lt;/p&gt;

&lt;h2&gt;NER visualization&lt;/h2&gt;

&lt;p&gt;Applicable to any of the &lt;a href=""https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition""&gt;100+ NER models! See here for an overview&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nlu.load(&amp;#39;ner&amp;#39;).viz(&amp;quot;Donald Trump from America and Angela Merkel from Germany don&amp;#39;t share many oppinions.&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;NER visualization&lt;/p&gt;

&lt;h2&gt;Dependency tree visualization&lt;/h2&gt;

&lt;p&gt;Visualizes the structure of the labeled dependency tree and part of speech tags&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nlu.load(&amp;#39;dep.typed&amp;#39;).viz(&amp;quot;Billy went to the mall&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dependency Tree visualization&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#Bigger Example
nlu.load(&amp;#39;dep.typed&amp;#39;).viz(&amp;quot;Donald Trump from America and Angela Merkel from Germany don&amp;#39;t share many oppinions but they both love John Snow Labs software&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dependency Tree visualization&lt;/p&gt;

&lt;h2&gt;Assertion status visualization&lt;/h2&gt;

&lt;p&gt;Visualizes asserted statuses and entities.Applicable to any of the &lt;a href=""https://nlp.johnsnowlabs.com/models?task=Assertion+Status""&gt;10 + Assertion models! See here for an overview&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nlu.load(&amp;#39;med_ner.clinical assert&amp;#39;).viz(&amp;quot;The MRI scan showed no signs of cancer in the left lung&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assert visualization&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#bigger example
data =&amp;#39;This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed.&amp;#39;
nlu.load(&amp;#39;med_ner.clinical assert&amp;#39;).viz(data)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Assert visualization&lt;/p&gt;

&lt;h2&gt;Relationship between entities visualization&lt;/h2&gt;

&lt;p&gt;Visualizes the extracted entities between relationship.Applicable to any of the &lt;a href=""https://nlp.johnsnowlabs.com/models?task=Relation+Extraction""&gt;20 + Relation Extractor models See here for an overview&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nlu.load(&amp;#39;med_ner.jsl.wip.clinical relation.temporal_events&amp;#39;).viz(&amp;#39;The patient developed cancer after a mercury poisoning in 1999 &amp;#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Entity Relation visualization&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# bigger example
data = &amp;#39;This is the case of a very pleasant 46-year-old Caucasian female, seen in clinic on 12/11/07 during which time MRI of the left shoulder showed no evidence of rotator cuff tear. She did have a previous MRI of the cervical spine that did show an osteophyte on the left C6-C7 level. Based on this, negative MRI of the shoulder, the patient was recommended to have anterior cervical discectomy with anterior interbody fusion at C6-C7 level. Operation, expected outcome, risks, and benefits were discussed with her. Risks include, but not exclusive of bleeding and infection, bleeding could be soft tissue bleeding, which may compromise airway and may result in return to the operating room emergently for evacuation of said hematoma. There is also the possibility of bleeding into the epidural space, which can compress the spinal cord and result in weakness and numbness of all four extremities as well as impairment of bowel and bladder function. However, the patient may develop deeper-seated infection, which may require return to the operating room. Should the infection be in the area of the spinal instrumentation, this will cause a dilemma since there might be a need to remove the spinal instrumentation and/or allograft. There is also the possibility of potential injury to the esophageus, the trachea, and the carotid artery. There is also the risks of stroke on the right cerebral circulation should an undiagnosed plaque be propelled from the right carotid. She understood all of these risks and agreed to have the procedure performed&amp;#39;
pipe = nlu.load(&amp;#39;med_ner.jsl.wip.clinical relation.clinical&amp;#39;).viz(data)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Entity Relation visualization&lt;/p&gt;

&lt;h2&gt;Entity Resolution visualization for chunks&lt;/h2&gt;

&lt;p&gt;Visualizes resolutions of entities Applicable to any of the &lt;a href=""https://nlp.johnsnowlabs.com/models?task=Entity+Resolution""&gt;100+ Resolver models See here for an overview&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nlu.load(&amp;#39;med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in&amp;#39;).viz(&amp;quot;He took Prevacid 30 mg  daily&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Chunk Resolution visualization&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# bigger example
data = &amp;quot;This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD , gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret\&amp;#39;s Center for Women &amp;amp; Infants for cardiac catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .&amp;quot;
nlu.load(&amp;#39;med_ner.jsl.wip.clinical resolve_chunk.rxnorm.in&amp;#39;).viz(data)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Chunk Resolution visualization&lt;/p&gt;

&lt;h2&gt;Entity Resolution visualization for sentences&lt;/h2&gt;

&lt;p&gt;Visualizes resolutions of entities in sentences Applicable to any of the &lt;a href=""https://nlp.johnsnowlabs.com/models?task=Entity+Resolution""&gt;100+ Resolver models See here for an overview&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nlu.load(&amp;#39;med_ner.jsl.wip.clinical resolve.icd10cm&amp;#39;).viz(&amp;#39;She was diagnosed with a respiratory congestion&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sentence Resolution visualization&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# bigger example
data = &amp;#39;The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion&amp;#39;
nlu.load(&amp;#39;med_ner.jsl.wip.clinical resolve.icd10cm&amp;#39;).viz(data)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sentence Resolution visualization&lt;/p&gt;

&lt;h2&gt;Configure visualizations&lt;/h2&gt;

&lt;h2&gt;Define custom colors for labels&lt;/h2&gt;

&lt;p&gt;Some entity and relation labels will be highlighted with a pre-defined color, which you &lt;a href=""https://github.com/JohnSnowLabs/spark-nlp-display/tree/main/sparknlp_display/label_colors""&gt;can find here&lt;/a&gt;.For labels that have no color defined, a random color will be generated.You can define colors for labels manually, by specifying via the &lt;code&gt;viz_colors&lt;/code&gt; parameter and defining &lt;code&gt;hex color codes&lt;/code&gt; in a dictionary that maps &lt;code&gt;labels&lt;/code&gt; to &lt;code&gt;colors&lt;/code&gt; .&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data = &amp;#39;Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough&amp;#39;
# Define custom colors for labels
viz_colors={&amp;#39;STRENGTH&amp;#39;:&amp;#39;#800080&amp;#39;, &amp;#39;DRUG_BRANDNAME&amp;#39;:&amp;#39;#77b5fe&amp;#39;, &amp;#39;GENDER&amp;#39;:&amp;#39;#77ffe&amp;#39;}
nlu.load(&amp;#39;med_ner.jsl.wip.clinical&amp;#39;).viz(data,viz_colors =viz_colors)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;define colors labels&lt;/p&gt;

&lt;h2&gt;Filter entities that get highlighted&lt;/h2&gt;

&lt;p&gt;By default every entity class will be visualized.The &lt;code&gt;labels_to_viz&lt;/code&gt; can be used to define a set of labels to highlight.Applicable for ner, resolution and assert.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;data = &amp;#39;Dr. John Snow suggested that Fritz takes 5mg penicilin for his cough&amp;#39;
# Filter wich NER label to viz
labels_to_viz=[&amp;#39;SYMPTOM&amp;#39;]
nlu.load(&amp;#39;med_ner.jsl.wip.clinical&amp;#39;).viz(data,labels_to_viz=labels_to_viz)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;filter labels&lt;/p&gt;

&lt;h2&gt;New models&lt;/h2&gt;

&lt;p&gt;New multilingual models for &lt;code&gt;Afrikaans&lt;/code&gt;, &lt;code&gt;Welsh&lt;/code&gt;, &lt;code&gt;Maltese&lt;/code&gt;, &lt;code&gt;Tamil&lt;/code&gt;, and&lt;code&gt;Vietnamese&lt;/code&gt;&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th align=""left""&gt;nlu.load() Refrence&lt;/th&gt;
&lt;th align=""left""&gt;Spark NLP Refrence&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html""&gt;vi.lemma&lt;/a&gt;&lt;/td&gt;
&lt;td align=""left""&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_vi.html""&gt;lemma&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html""&gt;mt.lemma&lt;/a&gt;&lt;/td&gt;
&lt;td align=""left""&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_mt.html""&gt;lemma&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html""&gt;ta.lemma&lt;/a&gt;&lt;/td&gt;
&lt;td align=""left""&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_ta.html""&gt;lemma&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html""&gt;af.lemma&lt;/a&gt;&lt;/td&gt;
&lt;td align=""left""&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_af.html""&gt;lemma&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html""&gt;af.pos&lt;/a&gt;&lt;/td&gt;
&lt;td align=""left""&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/06/pos_afribooms_af.html""&gt;pos_afribooms&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=""left""&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html""&gt;cy.lemma&lt;/a&gt;&lt;/td&gt;
&lt;td align=""left""&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/lemma_cy.html""&gt;lemma&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;Reworked and updated NLU tutorial notebooks&lt;/h2&gt;

&lt;p&gt;All of the &lt;a href=""https://github.com/JohnSnowLabs/nlu/tree/master/examples""&gt;140+ NLU tutorial Notebooks&lt;/a&gt; have been updated and reworked to reflect the latest changes in NLU 3.0.0+&lt;/p&gt;

&lt;h2&gt;Improved Column Name generation&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;NLU categorized each internal component now with boolean labels for &lt;code&gt;name_deductable&lt;/code&gt; and &lt;code&gt;always_name_deductable&lt;/code&gt; .&lt;/li&gt;
&lt;li&gt;Before generating column names, NLU checks wether each component is of unique in the pipeline or not. If a component is not unique in the pipe and there are multiple components of same type, i.e. multiple &lt;code&gt;NER&lt;/code&gt; models, NLU will deduct a base name for the final output columns from the NLU reference each NER model is pointing to.&lt;/li&gt;
&lt;li&gt;If on the other hand, there is only one &lt;code&gt;NER&lt;/code&gt; model in the pipeline, only the default &lt;code&gt;ner&lt;/code&gt; column prefixed will be generated.&lt;/li&gt;
&lt;li&gt;For some components, like &lt;code&gt;embeddings&lt;/code&gt; and &lt;code&gt;classifiers&lt;/code&gt; are now defined as &lt;code&gt;always_name_deductable&lt;/code&gt;, for those NLU will always try to infer a meaningful base name for the output columns.&lt;/li&gt;
&lt;li&gt;Newly trained component output columns will now be prefixed with &lt;code&gt;trained_&amp;lt;type&amp;gt;&lt;/code&gt; , for types &lt;code&gt;pos&lt;/code&gt; , &lt;code&gt;ner&lt;/code&gt;, &lt;code&gt;cLassifier&lt;/code&gt;, &lt;code&gt;sentiment&lt;/code&gt; and &lt;code&gt;multi_classifier&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Enhanced offline mode&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;You can still load a model from a path as usual with &lt;code&gt;nlu.load(path=model_path)&lt;/code&gt; and output columns will be suffixed with &lt;code&gt;from_disk&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;You can now optionally also specify &lt;code&gt;request&lt;/code&gt; parameter during  load a model from HDD, it will be used to deduct more meaningful column name suffixes, instead of &lt;code&gt;from_disk&lt;/code&gt;, i.e. by calling &lt;code&gt;nlu.load(request =&amp;#39;en.embed_sentence.biobert.pubmed_pmc_base_cased&amp;#39;, path=model_path)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Bugfixes&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Fixed a bug that caused  resolution algorithms output level to be inferred incorrectly&lt;/li&gt;
&lt;li&gt;Fixed a bug that caused stranger cols got dropped&lt;/li&gt;
&lt;li&gt;Fixed a bug that caused endings to miss when  .predict(position=True) was specified&lt;/li&gt;
&lt;li&gt;Fixed a bug that caused pd.Series to be converted incorrectly internally&lt;/li&gt;
&lt;li&gt;Fixed a bug that caused output level transformations to crash&lt;/li&gt;
&lt;li&gt;Fixed a bug that caused verbose mode not to turn of properly after turning it on.&lt;/li&gt;
&lt;li&gt;fixed a bug that caused some models to crash when loaded for HDD&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;Additional NLU resources&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/tree/master/examples""&gt;140+ updates tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlu.johnsnowlabs.com/docs/en/viz_examples""&gt;Updated visualization docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlp.johnsnowlabs.com/models""&gt;Models Hub&lt;/a&gt; with new models&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://medium.com/spark-nlp""&gt;Spark NLP publications&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlp.johnsnowlabs.com/demo""&gt;NLU in Action&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlu.johnsnowlabs.com/docs/en/install""&gt;NLU documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/spark-nlp/discussions""&gt;Discussions&lt;/a&gt; Engage with other community members, share ideas, and show off how you use Spark NLP and NLU!&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;1 line Install NLU on Google Colab&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;!wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash&lt;/code&gt;&lt;/p&gt;

&lt;h1&gt;1 line Install NLU on Kaggle&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;!wget https://setup.johnsnowlabs.com/nlu/kaggle.sh -O - | bash&lt;/code&gt;&lt;/p&gt;

&lt;h1&gt;Install via PIP&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;! pip install nlu pyspark==3.0.1&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nh4qja,True,,CKL-IT,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nh4qja/1_line_to_visualizations_for_dependency_trees/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nh4qja/1_line_to_visualizations_for_dependency_trees/,66147,1621528217.0,0,,False,,,"{'jcdi7fjxza071': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 76, 'x': 108, 'u': 'https://preview.redd.it/jcdi7fjxza071.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=caa3d91099df4ba52b24400a80f4c8aec15ca4c7'}, {'y': 153, 'x': 216, 'u': 'https://preview.redd.it/jcdi7fjxza071.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=08094c0de50babe5c7e47e47f918685a54354c74'}, {'y': 228, 'x': 320, 'u': 'https://preview.redd.it/jcdi7fjxza071.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f062a935ba255075588e167aa274365184e8f72a'}, {'y': 456, 'x': 640, 'u': 'https://preview.redd.it/jcdi7fjxza071.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ba36583fd4cb744fa34fa6ea9184e014fac6f9e3'}, {'y': 684, 'x': 960, 'u': 'https://preview.redd.it/jcdi7fjxza071.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c8ff9614707e15e8d3d6f97cd061ca78c788be56'}, {'y': 769, 'x': 1080, 'u': 'https://preview.redd.it/jcdi7fjxza071.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=651463d79073fccf0270d9df3d1a8b718fd40b99'}], 's': {'y': 1068, 'x': 1498, 'u': 'https://preview.redd.it/jcdi7fjxza071.png?width=1498&amp;format=png&amp;auto=webp&amp;s=8092331204f0d38e08b220dc470c7f8d44503fa2'}, 'id': 'jcdi7fjxza071'}}",,,,
,deeplearning,"Hi, so I understand that the epsilon in a VAE is introuduced to shift the source of randomness from z to epsilon so that the backprop flows efficiently through z. This helps to regularize the latent space by pulling it down to a normal distribution and reducing the variance in the latent space.  
However, at inference, this epsilon is still a random point from a said normal distribution, so how can we expect the model to give the reproducible results when we are using a random variable in it?

Do we not generate epsilon and the corresponding KLDiv term during inference? i.e. do we feed the latent variable z directly to the decoder during inference?",t2_4xhrybaz,False,,0,False,How can VAE produce reproducible results if epsilon is a random value from a normal distribution?,[],r/deeplearning,False,6,,0,,False,t3_ngsszg,False,dark,0.75,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1621520944.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, so I understand that the epsilon in a VAE is introuduced to shift the source of randomness from z to epsilon so that the backprop flows efficiently through z. This helps to regularize the latent space by pulling it down to a normal distribution and reducing the variance in the latent space.&lt;br/&gt;
However, at inference, this epsilon is still a random point from a said normal distribution, so how can we expect the model to give the reproducible results when we are using a random variable in it?&lt;/p&gt;

&lt;p&gt;Do we not generate epsilon and the corresponding KLDiv term during inference? i.e. do we feed the latent variable z directly to the decoder during inference?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ngsszg,True,,banenvy,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/ngsszg/how_can_vae_produce_reproducible_results_if/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ngsszg/how_can_vae_produce_reproducible_results_if/,66147,1621492144.0,0,,False,,,,,,,
,deeplearning,,t2_265t3i5h,False,,0,False,12 Best Courses to Learn Deep Learning,[],r/deeplearning,False,6,,0,,False,t3_ngv40j,False,dark,0.58,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1621529896.0,text,6,,,text,mltut.com,False,,,,,https://www.mltut.com/best-courses-to-learn-deep-learning/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ngv40j,True,,MlTut,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ngv40j/12_best_courses_to_learn_deep_learning/,all_ads,False,https://www.mltut.com/best-courses-to-learn-deep-learning/,66147,1621501096.0,0,,False,,,,,,,
,deeplearning,"I was trying to deploy a Flask App consisting of an Image Classification Model coded in Pytorch to a free tier EC2 instance. The error occurs at installing dependencies i.e The torch v1.8.1 installation gets stuck at 94% (754Mb).

After hitting 94%, the speed drops to 8 Kb/s and the eta jumps to years. I tried installing Pytorch only, still, the issue remains.

&amp;#x200B;

[The Error](https://preview.redd.it/t1eoykygb8071.png?width=1415&amp;format=png&amp;auto=webp&amp;s=4f985f8608512a96a922ae39805efc1ef9704a21)

Here is the tutorial I followed -: [https://youtu.be/oOqqwYI60FI?list=PLZoTAELRMXVOAvUbePX1lTdxQR8EY35Z1](https://youtu.be/oOqqwYI60FI?list=PLZoTAELRMXVOAvUbePX1lTdxQR8EY35Z1)

The Flask App project link - [https://github.com/milangeorge2000/Mamukka\_Lalettan-Classifier](https://github.com/milangeorge2000/Mamukka_Lalettan-Classifier)

Please help me with this. Thanks in advance.",t2_7hgg4h0v,False,,0,False,Unable to host a Flask App consisting of an Image Classification Model coded in Pytorch to a free tier AWS EC2 instance. The issue occurs at requirements installation i.e The torch v1.8.1 installation gets stuck at 94%.,[],r/deeplearning,False,6,,0,,False,t3_ngtwl8,False,dark,0.7,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1621525166.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was trying to deploy a Flask App consisting of an Image Classification Model coded in Pytorch to a free tier EC2 instance. The error occurs at installing dependencies i.e The torch v1.8.1 installation gets stuck at 94% (754Mb).&lt;/p&gt;

&lt;p&gt;After hitting 94%, the speed drops to 8 Kb/s and the eta jumps to years. I tried installing Pytorch only, still, the issue remains.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/t1eoykygb8071.png?width=1415&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4f985f8608512a96a922ae39805efc1ef9704a21""&gt;The Error&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here is the tutorial I followed -: &lt;a href=""https://youtu.be/oOqqwYI60FI?list=PLZoTAELRMXVOAvUbePX1lTdxQR8EY35Z1""&gt;https://youtu.be/oOqqwYI60FI?list=PLZoTAELRMXVOAvUbePX1lTdxQR8EY35Z1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The Flask App project link - &lt;a href=""https://github.com/milangeorge2000/Mamukka_Lalettan-Classifier""&gt;https://github.com/milangeorge2000/Mamukka_Lalettan-Classifier&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Please help me with this. Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ngtwl8,True,,-JuliusSeizure,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/ngtwl8/unable_to_host_a_flask_app_consisting_of_an_image/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ngtwl8/unable_to_host_a_flask_app_consisting_of_an_image/,66147,1621496366.0,0,,False,,,"{'t1eoykygb8071': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 33, 'x': 108, 'u': 'https://preview.redd.it/t1eoykygb8071.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=de1eab655fac18562bc8bfb2396cb28439e8d723'}, {'y': 67, 'x': 216, 'u': 'https://preview.redd.it/t1eoykygb8071.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b64ffd9f3b429a8d4cf37f47ac3668c7e7ae9828'}, {'y': 99, 'x': 320, 'u': 'https://preview.redd.it/t1eoykygb8071.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9b6e02461db0ab05073c9b617843848f04580780'}, {'y': 199, 'x': 640, 'u': 'https://preview.redd.it/t1eoykygb8071.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7063cf94699b1e9633854448ec5aad3012759a87'}, {'y': 299, 'x': 960, 'u': 'https://preview.redd.it/t1eoykygb8071.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=47ebe7e3ab6f271c98f4e8f6b09f1222d961df73'}, {'y': 336, 'x': 1080, 'u': 'https://preview.redd.it/t1eoykygb8071.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8866aa13212e67e21292cf38a873e5c6ce6fb7ea'}], 's': {'y': 441, 'x': 1415, 'u': 'https://preview.redd.it/t1eoykygb8071.png?width=1415&amp;format=png&amp;auto=webp&amp;s=4f985f8608512a96a922ae39805efc1ef9704a21'}, 'id': 't1eoykygb8071'}}",,,,
,deeplearning,"Check out the [new post from Casual GAN Papers](https://t.me/casual_gan/39) that explains the main ideas from Self-Supervised Vision Transformers with DINO.

1 Minute summary:

&gt;In this paper from Facebook AI Research the authors propose a novel pipeline to train a [ViT](https://t.me/casual_gan/33) model in a self-supervised setup. Perhaps the most interesting consequence of this setup is that the learned features are good enough to achieve 80.1% top-1 score on ImageNet. At the core of their pipeline is a pair of networks that learn to predict the outputs of one another. The trick is that while the student network is trained via gradient descent over the cross-entropy loss functions, the teacher network is updated with an exponentially moving average of the student network weights. Several tricks such as centering and sharpening are employed to combat mode collapse. As a fortunate side-effect the learned self-attention maps of the final layer automatically learns class-specific features leading to unsupervised object segmentations.

\[[Full Explanation Post](https://t.me/casual_gan/39)\] \[[Arxiv](https://arxiv.org/pdf/2104.14294v1.pdf)\] \[[Project Page](https://github.com/facebookresearch/dino)\]

[Self supervised video segmentation](https://reddit.com/link/ng883y/video/vr1jszyyd3071/player)

More recent popular paper explanations:  
\[[MLP-mixer](https://t.me/casual_gan/35)\]  
\[[Vision Transformer (ViT)](https://t.me/casual_gan/33)\]",t2_hhio3,False,,0,False,[D] Why Transformers are taking over the Compute Vision world: Self-Supervised Vision Transformers with DINO explained in 7 minutes!,[],r/deeplearning,False,6,,0,,False,t3_ng883y,False,dark,0.94,,public,46,0,{},,False,[],,False,False,,{},,False,46,,False,False,,False,,[],{},,True,,1621465431.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Check out the &lt;a href=""https://t.me/casual_gan/39""&gt;new post from Casual GAN Papers&lt;/a&gt; that explains the main ideas from Self-Supervised Vision Transformers with DINO.&lt;/p&gt;

&lt;p&gt;1 Minute summary:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In this paper from Facebook AI Research the authors propose a novel pipeline to train a &lt;a href=""https://t.me/casual_gan/33""&gt;ViT&lt;/a&gt; model in a self-supervised setup. Perhaps the most interesting consequence of this setup is that the learned features are good enough to achieve 80.1% top-1 score on ImageNet. At the core of their pipeline is a pair of networks that learn to predict the outputs of one another. The trick is that while the student network is trained via gradient descent over the cross-entropy loss functions, the teacher network is updated with an exponentially moving average of the student network weights. Several tricks such as centering and sharpening are employed to combat mode collapse. As a fortunate side-effect the learned self-attention maps of the final layer automatically learns class-specific features leading to unsupervised object segmentations.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/39""&gt;Full Explanation Post&lt;/a&gt;] [&lt;a href=""https://arxiv.org/pdf/2104.14294v1.pdf""&gt;Arxiv&lt;/a&gt;] [&lt;a href=""https://github.com/facebookresearch/dino""&gt;Project Page&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://reddit.com/link/ng883y/video/vr1jszyyd3071/player""&gt;Self supervised video segmentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;More recent popular paper explanations:&lt;br/&gt;
[&lt;a href=""https://t.me/casual_gan/35""&gt;MLP-mixer&lt;/a&gt;]&lt;br/&gt;
[&lt;a href=""https://t.me/casual_gan/33""&gt;Vision Transformer (ViT)&lt;/a&gt;]&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ng883y,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ng883y/d_why_transformers_are_taking_over_the_compute/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ng883y/d_why_transformers_are_taking_over_the_compute/,66147,1621436631.0,0,,False,,,"{'vr1jszyyd3071': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/ng883y/asset/vr1jszyyd3071/DASHPlaylist.mpd?a=1626449877%2CNGI4ZDRkY2IyZTY0MjExYTU2MWI2M2I0YTA1ZGRiMWVhNWYwYmNjNDZhZjYxN2IxZTIzZDkwZTliNmNhMjQ5ZQ%3D%3D&amp;v=1&amp;f=sd', 'x': 854, 'y': 241, 'hlsUrl': 'https://v.redd.it/link/ng883y/asset/vr1jszyyd3071/HLSPlaylist.m3u8?a=1626449877%2CMGFkNDNjMzU1NTQ2OTcyYWM0YjE2OTZjMjA4MjJiODk0ZmM5Y2RiYmY4ZjdmMjJmNTRkZjJlNGQ4ZmQ4YzM5OQ%3D%3D&amp;v=1&amp;f=sd', 'id': 'vr1jszyyd3071', 'isGif': False}}",,,,
,deeplearning,,t2_l6ugg,False,,0,False,"Bias in AI - What is it, why does it happen and can it be fixed?",[],r/deeplearning,False,6,,0,,False,t3_nh1z8h,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1621550420.0,text,6,,,text,blog.re-work.co,False,,,,,https://blog.re-work.co/could-bias-be-the-biggest-roadblock-in-ai/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nh1z8h,True,,nikitaljohnson,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nh1z8h/bias_in_ai_what_is_it_why_does_it_happen_and_can/,all_ads,False,https://blog.re-work.co/could-bias-be-the-biggest-roadblock-in-ai/,66147,1621521620.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'compsci', 'selftext': '', 'author_fullname': 't2_l6ugg', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Bias in AI - What is it, why does it happen and can it be fixed?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/compsci', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nh1vrq', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.77, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 44, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 44, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1621550179.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'blog.re-work.co', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://blog.re-work.co/could-bias-be-the-biggest-roadblock-in-ai/', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qhmr', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nh1vrq', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'nikitaljohnson', 'discussion_type': None, 'num_comments': 14, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/compsci/comments/nh1vrq/bias_in_ai_what_is_it_why_does_it_happen_and_can/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://blog.re-work.co/could-bias-be-the-biggest-roadblock-in-ai/', 'subreddit_subscribers': 1455292, 'created_utc': 1621521379.0, 'num_crossposts': 3, 'media': None, 'is_video': False}]",t3_nh1vrq,,,,,
,deeplearning,"I am trying to install PyTorch YOLOv5 from ultralytics from [here](https://pytorch.org/hub/ultralytics_yolov5/) in Windows 10 x86\_64 system. The instructions seem pretty straightforward and I after having installed PyTorch for GPU, I am attempting to install the required requirements by using the command:

pip install -qr [https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt](https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt)

&amp;#x200B;

to which I get the following ERROR log:

&amp;#x200B;

&gt;ERROR: Command errored out with exit status 1:    command:  
&gt;  
&gt;'C:\\Users\\arjun\\anaconda3\\envs\\pytorch\_object\_detection\\python.exe' -u  
&gt;  
&gt;\-c 'import sys, setuptools, tokenize; sys.argv\[0\] = '""'""'C:\\\\Users\\\\arjun\\\\AppData\\\\Local\\\\Temp\\\\pip-install-7kbo300l\\\\pycocotools\_e5774d8d59d14fa9b3baece40c2b7248\\\\[setup.py](https://setup.py)'""'""';  
&gt;  
&gt;\_\_file\_\_='""'""'C:\\\\Users\\\\arjun\\\\AppData\\\\Local\\\\Temp\\\\pip-install-7kbo300l\\\\pycocotools\_e5774d8d59d14fa9b3baece40c2b7248\\\\[setup.py](https://setup.py)'""'""';f=getattr(tokenize,  
&gt;  
&gt;'""'""'open'""'""', open)(\_\_file\_\_);[code=f.read](https://code=f.read)().replace('""'""'\\r\\n'""'""',  
&gt;  
&gt;'""'""'\\n'""'""');f.close();exec(compile(code, \_\_file\_\_, '""'""'exec'""'""'))'  
&gt;  
&gt;bdist\_wheel -d 'C:\\Users\\arjun\\AppData\\Local\\Temp\\pip-wheel-kc1jnk9w'  
&gt;  
&gt;cwd: C:\\Users\\arjun\\AppData\\Local\\Temp\\pip-install-7kbo300l\\pycocotools\_e5774d8d59d14fa9b3baece40c2b7248\\  
&gt;  
&gt;Complete output (16 lines):   running bdist\_wheel   running build  
&gt;  
&gt;running build\_py   creating build   creating build\\lib.win-amd64-3.8  
&gt;  
&gt;creating build\\lib.win-amd64-3.8\\pycocotools   copying  
&gt;  
&gt;pycocotools\\[coco.py](https://coco.py) \-&gt; build\\lib.win-amd64-3.8\\pycocotools   copying  
&gt;  
&gt;pycocotools\\[cocoeval.py](https://cocoeval.py) \-&gt; build\\lib.win-amd64-3.8\\pycocotools  
&gt;  
&gt;copying pycocotools\\[mask.py](https://mask.py) \-&gt; build\\lib.win-amd64-3.8\\pycocotools  
&gt;  
&gt;copying pycocotools\\\_\_init\_\_.py -&gt; build\\lib.win-amd64-3.8\\pycocotools  
&gt;  
&gt;running build\_ext   cythoning pycocotools/\_mask.pyx to  
&gt;  
&gt;pycocotools\\\_mask.c  
&gt;  
&gt;C:\\Users\\arjun\\anaconda3\\envs\\pytorch\_object\_detection\\lib\\site-packages\\Cython\\Compiler\\[Main.py:369](https://Main.py:369):  
&gt;  
&gt;FutureWarning: Cython directive 'language\_level' not set, using 2 for  
&gt;  
&gt;now (Py2). This will change in a later release! File:  
&gt;  
&gt;C:\\Users\\arjun\\AppData\\Local\\Temp\\pip-install-7kbo300l\\pycocotools\_e5774d8d59d14fa9b3baece40c2b7248\\pycocotools\\\_mask.pyx  
&gt;  
&gt;tree = Parsing.p\_module(s, pxd, full\_module\_name)   building 'pycocotools.\_mask' extension   error: Microsoft Visual C++ 14.0 or  
&gt;  
&gt;greater is required. Get it with ""Microsoft C++ Build Tools"":  
&gt;  
&gt;[https://visualstudio.microsoft.com/visual-cpp-build-tools/](https://visualstudio.microsoft.com/visual-cpp-build-tools/)  
&gt;  
&gt;\----------------------------------------   ERROR: Failed building wheel for pycocotools  
&gt;  
&gt;ERROR: Command errored out with exit status 1:  
&gt;  
&gt;command: 'C:\\Users\\arjun\\anaconda3\\envs\\pytorch\_object\_detection\\python.exe' -u  
&gt;  
&gt;\-c 'import sys, setuptools, tokenize; sys.argv\[0\] = '""'""'C:\\\\Users\\\\arjun\\\\AppData\\\\Local\\\\Temp\\\\pip-install-7kbo300l\\\\pycocotools\_e5774d8d59d14fa9b3baece40c2b7248\\\\[setup.py](https://setup.py)'""'""';  
&gt;  
&gt;\_\_file\_\_='""'""'C:\\\\Users\\\\arjun\\\\AppData\\\\Local\\\\Temp\\\\pip-install-7kbo300l\\\\pycocotools\_e5774d8d59d14fa9b3baece40c2b7248\\\\[setup.py](https://setup.py)'""'""';f=getattr(tokenize,  
&gt;  
&gt;'""'""'open'""'""', open)(\_\_file\_\_);[code=f.read](https://code=f.read)().replace('""'""'\\r\\n'""'""',  
&gt;  
&gt;'""'""'\\n'""'""');f.close();exec(compile(code, \_\_file\_\_, '""'""'exec'""'""'))'  
&gt;  
&gt;install --record  
&gt;  
&gt;'C:\\Users\\arjun\\AppData\\Local\\Temp\\pip-record-l60dglwi\\install-record.txt'  
&gt;  
&gt;\--single-version-externally-managed --compile --install-headers 'C:\\Users\\arjun\\anaconda3\\envs\\pytorch\_object\_detection\\Include\\pycocotools'  
&gt;  
&gt;cwd: C:\\Users\\arjun\\AppData\\Local\\Temp\\pip-install-7kbo300l\\pycocotools\_e5774d8d59d14fa9b3baece40c2b7248\\  
&gt;  
&gt;Complete output (14 lines):  
&gt;  
&gt;running install  
&gt;  
&gt;running build  
&gt;  
&gt;running build\_py  
&gt;  
&gt;creating build  
&gt;  
&gt;creating build\\lib.win-amd64-3.8  
&gt;  
&gt;creating build\\lib.win-amd64-3.8\\pycocotools  
&gt;  
&gt;copying pycocotools\\[coco.py](https://coco.py) \-&gt; build\\lib.win-amd64-3.8\\pycocotools  
&gt;  
&gt;copying pycocotools\\[cocoeval.py](https://cocoeval.py) \-&gt; build\\lib.win-amd64-3.8\\pycocotools  
&gt;  
&gt;copying pycocotools\\[mask.py](https://mask.py) \-&gt; build\\lib.win-amd64-3.8\\pycocotools  
&gt;  
&gt;copying pycocotools\\\_\_init\_\_.py -&gt; build\\lib.win-amd64-3.8\\pycocotools  
&gt;  
&gt;running build\_ext  
&gt;  
&gt;skipping 'pycocotools\\\_mask.c' Cython extension (up-to-date)  
&gt;  
&gt;building 'pycocotools.\_mask' extension  
&gt;  
&gt;error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"":  
&gt;  
&gt;[https://visualstudio.microsoft.com/visual-cpp-build-tools/](https://visualstudio.microsoft.com/visual-cpp-build-tools/)  
&gt;  
&gt;\---------------------------------------- ERROR: Command errored out with exit status 1:  
&gt;  
&gt;'C:\\Users\\arjun\\anaconda3\\envs\\pytorch\_object\_detection\\python.exe' -u  
&gt;  
&gt;\-c 'import sys, setuptools, tokenize; sys.argv\[0\] = '""'""'C:\\\\Users\\\\arjun\\\\AppData\\\\Local\\\\Temp\\\\pip-install-7kbo300l\\\\pycocotools\_e5774d8d59d14fa9b3baece40c2b7248\\\\[setup.py](https://setup.py)'""'""';  
&gt;  
&gt;\_\_file\_\_='""'""'C:\\\\Users\\\\arjun\\\\AppData\\\\Local\\\\Temp\\\\pip-install-7kbo300l\\\\pycocotools\_e5774d8d59d14fa9b3baece40c2b7248\\\\[setup.py](https://setup.py)'""'""';f=getattr(tokenize,  
&gt;  
&gt;'""'""'open'""'""', open)(\_\_file\_\_);[code=f.read](https://code=f.read)().replace('""'""'\\r\\n'""'""',  
&gt;  
&gt;'""'""'\\n'""'""');f.close();exec(compile(code, \_\_file\_\_, '""'""'exec'""'""'))'  
&gt;  
&gt;install --record  
&gt;  
&gt;'C:\\Users\\arjun\\AppData\\Local\\Temp\\pip-record-l60dglwi\\install-record.txt'  
&gt;  
&gt;\--single-version-externally-managed --compile --install-headers 'C:\\Users\\arjun\\anaconda3\\envs\\pytorch\_object\_detection\\Include\\pycocotools'  
&gt;  
&gt;Check the logs for full command output.

&amp;#x200B;

I have installed Microsoft C++ Build Tools and get the following output in CMD:

&gt;\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*  
&gt;  
&gt;\*\* Visual Studio 2019 Developer Command Prompt v16.9.6  
&gt;  
&gt;\*\* Copyright (c) 2021 Microsoft Corporation  
&gt;  
&gt;\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*

I am trying to reinstall the requirements.txt but the error for Microsoft C++ Build Tools still exist.

&amp;#x200B;

What should I do?",t2_2mmql89p,False,,0,False,PyTorch YOLOv5 - Microsoft C++ Build Tools,[],r/deeplearning,False,6,,0,,False,t3_ngrilp,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1621516367.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to install PyTorch YOLOv5 from ultralytics from &lt;a href=""https://pytorch.org/hub/ultralytics_yolov5/""&gt;here&lt;/a&gt; in Windows 10 x86_64 system. The instructions seem pretty straightforward and I after having installed PyTorch for GPU, I am attempting to install the required requirements by using the command:&lt;/p&gt;

&lt;p&gt;pip install -qr &lt;a href=""https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt""&gt;https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;to which I get the following ERROR log:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;ERROR: Command errored out with exit status 1:    command:  &lt;/p&gt;

&lt;p&gt;&amp;#39;C:\Users\arjun\anaconda3\envs\pytorch_object_detection\python.exe&amp;#39; -u  &lt;/p&gt;

&lt;p&gt;-c &amp;#39;import sys, setuptools, tokenize; sys.argv[0] = &amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;C:\\Users\\arjun\\AppData\\Local\\Temp\\pip-install-7kbo300l\\pycocotools_e5774d8d59d14fa9b3baece40c2b7248\\&lt;a href=""https://setup.py""&gt;setup.py&lt;/a&gt;&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;;  &lt;/p&gt;

&lt;p&gt;__file__=&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;C:\\Users\\arjun\\AppData\\Local\\Temp\\pip-install-7kbo300l\\pycocotools_e5774d8d59d14fa9b3baece40c2b7248\\&lt;a href=""https://setup.py""&gt;setup.py&lt;/a&gt;&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;;f=getattr(tokenize,  &lt;/p&gt;

&lt;p&gt;&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;open&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;, open)(__file__);&lt;a href=""https://code=f.read""&gt;code=f.read&lt;/a&gt;().replace(&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;\r\n&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;,  &lt;/p&gt;

&lt;p&gt;&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;\n&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;);f.close();exec(compile(code, __file__, &amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;exec&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;))&amp;#39;  &lt;/p&gt;

&lt;p&gt;bdist_wheel -d &amp;#39;C:\Users\arjun\AppData\Local\Temp\pip-wheel-kc1jnk9w&amp;#39;  &lt;/p&gt;

&lt;p&gt;cwd: C:\Users\arjun\AppData\Local\Temp\pip-install-7kbo300l\pycocotools_e5774d8d59d14fa9b3baece40c2b7248\  &lt;/p&gt;

&lt;p&gt;Complete output (16 lines):   running bdist_wheel   running build  &lt;/p&gt;

&lt;p&gt;running build_py   creating build   creating build\lib.win-amd64-3.8  &lt;/p&gt;

&lt;p&gt;creating build\lib.win-amd64-3.8\pycocotools   copying  &lt;/p&gt;

&lt;p&gt;pycocotools\&lt;a href=""https://coco.py""&gt;coco.py&lt;/a&gt; -&amp;gt; build\lib.win-amd64-3.8\pycocotools   copying  &lt;/p&gt;

&lt;p&gt;pycocotools\&lt;a href=""https://cocoeval.py""&gt;cocoeval.py&lt;/a&gt; -&amp;gt; build\lib.win-amd64-3.8\pycocotools  &lt;/p&gt;

&lt;p&gt;copying pycocotools\&lt;a href=""https://mask.py""&gt;mask.py&lt;/a&gt; -&amp;gt; build\lib.win-amd64-3.8\pycocotools  &lt;/p&gt;

&lt;p&gt;copying pycocotools\__init__.py -&amp;gt; build\lib.win-amd64-3.8\pycocotools  &lt;/p&gt;

&lt;p&gt;running build_ext   cythoning pycocotools/_mask.pyx to  &lt;/p&gt;

&lt;p&gt;pycocotools\_mask.c  &lt;/p&gt;

&lt;p&gt;C:\Users\arjun\anaconda3\envs\pytorch_object_detection\lib\site-packages\Cython\Compiler\&lt;a href=""https://Main.py:369""&gt;Main.py:369&lt;/a&gt;:  &lt;/p&gt;

&lt;p&gt;FutureWarning: Cython directive &amp;#39;language_level&amp;#39; not set, using 2 for  &lt;/p&gt;

&lt;p&gt;now (Py2). This will change in a later release! File:  &lt;/p&gt;

&lt;p&gt;C:\Users\arjun\AppData\Local\Temp\pip-install-7kbo300l\pycocotools_e5774d8d59d14fa9b3baece40c2b7248\pycocotools\_mask.pyx  &lt;/p&gt;

&lt;p&gt;tree = Parsing.p_module(s, pxd, full_module_name)   building &amp;#39;pycocotools._mask&amp;#39; extension   error: Microsoft Visual C++ 14.0 or  &lt;/p&gt;

&lt;p&gt;greater is required. Get it with &amp;quot;Microsoft C++ Build Tools&amp;quot;:  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://visualstudio.microsoft.com/visual-cpp-build-tools/""&gt;https://visualstudio.microsoft.com/visual-cpp-build-tools/&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;----------------------------------------   ERROR: Failed building wheel for pycocotools  &lt;/p&gt;

&lt;p&gt;ERROR: Command errored out with exit status 1:  &lt;/p&gt;

&lt;p&gt;command: &amp;#39;C:\Users\arjun\anaconda3\envs\pytorch_object_detection\python.exe&amp;#39; -u  &lt;/p&gt;

&lt;p&gt;-c &amp;#39;import sys, setuptools, tokenize; sys.argv[0] = &amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;C:\\Users\\arjun\\AppData\\Local\\Temp\\pip-install-7kbo300l\\pycocotools_e5774d8d59d14fa9b3baece40c2b7248\\&lt;a href=""https://setup.py""&gt;setup.py&lt;/a&gt;&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;;  &lt;/p&gt;

&lt;p&gt;__file__=&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;C:\\Users\\arjun\\AppData\\Local\\Temp\\pip-install-7kbo300l\\pycocotools_e5774d8d59d14fa9b3baece40c2b7248\\&lt;a href=""https://setup.py""&gt;setup.py&lt;/a&gt;&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;;f=getattr(tokenize,  &lt;/p&gt;

&lt;p&gt;&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;open&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;, open)(__file__);&lt;a href=""https://code=f.read""&gt;code=f.read&lt;/a&gt;().replace(&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;\r\n&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;,  &lt;/p&gt;

&lt;p&gt;&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;\n&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;);f.close();exec(compile(code, __file__, &amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;exec&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;))&amp;#39;  &lt;/p&gt;

&lt;p&gt;install --record  &lt;/p&gt;

&lt;p&gt;&amp;#39;C:\Users\arjun\AppData\Local\Temp\pip-record-l60dglwi\install-record.txt&amp;#39;  &lt;/p&gt;

&lt;p&gt;--single-version-externally-managed --compile --install-headers &amp;#39;C:\Users\arjun\anaconda3\envs\pytorch_object_detection\Include\pycocotools&amp;#39;  &lt;/p&gt;

&lt;p&gt;cwd: C:\Users\arjun\AppData\Local\Temp\pip-install-7kbo300l\pycocotools_e5774d8d59d14fa9b3baece40c2b7248\  &lt;/p&gt;

&lt;p&gt;Complete output (14 lines):  &lt;/p&gt;

&lt;p&gt;running install  &lt;/p&gt;

&lt;p&gt;running build  &lt;/p&gt;

&lt;p&gt;running build_py  &lt;/p&gt;

&lt;p&gt;creating build  &lt;/p&gt;

&lt;p&gt;creating build\lib.win-amd64-3.8  &lt;/p&gt;

&lt;p&gt;creating build\lib.win-amd64-3.8\pycocotools  &lt;/p&gt;

&lt;p&gt;copying pycocotools\&lt;a href=""https://coco.py""&gt;coco.py&lt;/a&gt; -&amp;gt; build\lib.win-amd64-3.8\pycocotools  &lt;/p&gt;

&lt;p&gt;copying pycocotools\&lt;a href=""https://cocoeval.py""&gt;cocoeval.py&lt;/a&gt; -&amp;gt; build\lib.win-amd64-3.8\pycocotools  &lt;/p&gt;

&lt;p&gt;copying pycocotools\&lt;a href=""https://mask.py""&gt;mask.py&lt;/a&gt; -&amp;gt; build\lib.win-amd64-3.8\pycocotools  &lt;/p&gt;

&lt;p&gt;copying pycocotools\__init__.py -&amp;gt; build\lib.win-amd64-3.8\pycocotools  &lt;/p&gt;

&lt;p&gt;running build_ext  &lt;/p&gt;

&lt;p&gt;skipping &amp;#39;pycocotools\_mask.c&amp;#39; Cython extension (up-to-date)  &lt;/p&gt;

&lt;p&gt;building &amp;#39;pycocotools._mask&amp;#39; extension  &lt;/p&gt;

&lt;p&gt;error: Microsoft Visual C++ 14.0 or greater is required. Get it with &amp;quot;Microsoft C++ Build Tools&amp;quot;:  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://visualstudio.microsoft.com/visual-cpp-build-tools/""&gt;https://visualstudio.microsoft.com/visual-cpp-build-tools/&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;---------------------------------------- ERROR: Command errored out with exit status 1:  &lt;/p&gt;

&lt;p&gt;&amp;#39;C:\Users\arjun\anaconda3\envs\pytorch_object_detection\python.exe&amp;#39; -u  &lt;/p&gt;

&lt;p&gt;-c &amp;#39;import sys, setuptools, tokenize; sys.argv[0] = &amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;C:\\Users\\arjun\\AppData\\Local\\Temp\\pip-install-7kbo300l\\pycocotools_e5774d8d59d14fa9b3baece40c2b7248\\&lt;a href=""https://setup.py""&gt;setup.py&lt;/a&gt;&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;;  &lt;/p&gt;

&lt;p&gt;__file__=&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;C:\\Users\\arjun\\AppData\\Local\\Temp\\pip-install-7kbo300l\\pycocotools_e5774d8d59d14fa9b3baece40c2b7248\\&lt;a href=""https://setup.py""&gt;setup.py&lt;/a&gt;&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;;f=getattr(tokenize,  &lt;/p&gt;

&lt;p&gt;&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;open&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;, open)(__file__);&lt;a href=""https://code=f.read""&gt;code=f.read&lt;/a&gt;().replace(&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;\r\n&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;,  &lt;/p&gt;

&lt;p&gt;&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;\n&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;);f.close();exec(compile(code, __file__, &amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;exec&amp;#39;&amp;quot;&amp;#39;&amp;quot;&amp;#39;))&amp;#39;  &lt;/p&gt;

&lt;p&gt;install --record  &lt;/p&gt;

&lt;p&gt;&amp;#39;C:\Users\arjun\AppData\Local\Temp\pip-record-l60dglwi\install-record.txt&amp;#39;  &lt;/p&gt;

&lt;p&gt;--single-version-externally-managed --compile --install-headers &amp;#39;C:\Users\arjun\anaconda3\envs\pytorch_object_detection\Include\pycocotools&amp;#39;  &lt;/p&gt;

&lt;p&gt;Check the logs for full command output.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have installed Microsoft C++ Build Tools and get the following output in CMD:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;**********************************************************************  &lt;/p&gt;

&lt;p&gt;** Visual Studio 2019 Developer Command Prompt v16.9.6  &lt;/p&gt;

&lt;p&gt;** Copyright (c) 2021 Microsoft Corporation  &lt;/p&gt;

&lt;p&gt;**********************************************************************&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I am trying to reinstall the requirements.txt but the error for Microsoft C++ Build Tools still exist.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;What should I do?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ngrilp,True,,grid_world,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ngrilp/pytorch_yolov5_microsoft_c_build_tools/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ngrilp/pytorch_yolov5_microsoft_c_build_tools/,66147,1621487567.0,0,,False,,,,,,,
,deeplearning,"A research team from Adobe proposes Directional GAN (DGAN), a novel and simple approach for generating high-resolution images conditioned on expected semantic attributes, greatly simplifying the image content generating process for marketing campaigns, websites and banners.

Here is a quick read: [Intelligent Graphic Design: Adobe’s Directional GAN Automates Image Content Generation for Marketing Campaigns.](https://syncedreview.com/2021/05/19/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-22/)

The paper *Directional GAN: A Novel Conditioning Strategy for Generative Networks* is on [arXiv](https://arxiv.org/abs/2105.05712).",t2_2fv4yodo,False,,0,False,[R] Intelligent Graphic Design: Adobe’s Directional GAN Automates Image Content Generation for Marketing Campaigns,[],r/deeplearning,False,6,,0,,False,t3_ng8lbh,False,dark,0.93,,public,21,0,{},,False,[],,False,False,,{},,False,21,,False,False,,False,,[],{},,True,,1621466291.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Adobe proposes Directional GAN (DGAN), a novel and simple approach for generating high-resolution images conditioned on expected semantic attributes, greatly simplifying the image content generating process for marketing campaigns, websites and banners.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/19/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-22/""&gt;Intelligent Graphic Design: Adobe’s Directional GAN Automates Image Content Generation for Marketing Campaigns.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Directional GAN: A Novel Conditioning Strategy for Generative Networks&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.05712""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ng8lbh,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ng8lbh/r_intelligent_graphic_design_adobes_directional/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ng8lbh/r_intelligent_graphic_design_adobes_directional/,66147,1621437491.0,0,,False,,,,,,,
,deeplearning,,t2_71atywgj,False,,0,False,AI Robot Artist Makes Masterpiece | Google Develops AI App for Skin Disease,[],r/deeplearning,False,6,,0,,False,t3_ngptsh,False,dark,0.57,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/UeGm7Kml8sc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI Robot Artist Makes Masterpiece | Google Develops AI App for Skin Disease  | Today in AI Episode 2', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/UeGm7Kml8sc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The Teen Innovator', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/UeGm7Kml8sc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCHGbO2h8gRi-w4tx_nZcMMw'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/UeGm7Kml8sc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ngptsh', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1621511024.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/UeGm7Kml8sc,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ngptsh,True,,Snoo28889,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ngptsh/ai_robot_artist_makes_masterpiece_google_develops/,all_ads,False,https://youtu.be/UeGm7Kml8sc,66147,1621482224.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI Robot Artist Makes Masterpiece | Google Develops AI App for Skin Disease  | Today in AI Episode 2', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/UeGm7Kml8sc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The Teen Innovator', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/UeGm7Kml8sc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCHGbO2h8gRi-w4tx_nZcMMw'}}",False,,,,,,,
,deeplearning,Hi guys i am trying to create neural music video clip is anyway to get timecodes of jukebox of singing,t2_8b223d6v,False,,0,False,Jukebox advanced usage,[],r/deeplearning,False,6,,0,,False,t3_ngf3em,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1621482261.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys i am trying to create neural music video clip is anyway to get timecodes of jukebox of singing&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ngf3em,True,,Mysterious_Hearing14,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ngf3em/jukebox_advanced_usage/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ngf3em/jukebox_advanced_usage/,66147,1621453461.0,0,,False,,,,,,,
,deeplearning,"Hey everyone, I dropped out of college in the 4th sem to learn Deep learning on my own. I am still a noobie. I have completed the Andrew Ng's deep learning course. Now I am learning pytorch.(+ Following MIT Deep learning Course) But every time I look for job/internship postings I get worried as all of them require some kind of degree. Wha should I focus on to increase my odds of lending a job. Any help would be great.

 Thank you:)",t2_a8mjqp18,False,,0,False,Need help!!,[],r/deeplearning,False,6,,0,,False,t3_ngao4w,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1621471334.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone, I dropped out of college in the 4th sem to learn Deep learning on my own. I am still a noobie. I have completed the Andrew Ng&amp;#39;s deep learning course. Now I am learning pytorch.(+ Following MIT Deep learning Course) But every time I look for job/internship postings I get worried as all of them require some kind of degree. Wha should I focus on to increase my odds of lending a job. Any help would be great.&lt;/p&gt;

&lt;p&gt;Thank you:)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ngao4w,True,,AdAdventurous3684,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/ngao4w/need_help/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ngao4w/need_help/,66147,1621442534.0,0,,False,,,,,,,
,deeplearning,,t2_1568ks,False,,0,False,Project CodeNet: 14M code samples to train DL models for programming tasks,[],r/deeplearning,False,6,,0,,False,t3_nfy0xh,False,dark,0.76,,public,12,0,{},,False,[],,False,False,,{},,False,12,,False,False,,False,,[],{},,False,,1621434077.0,text,6,,,text,bdtechtalks.com,False,,,,,https://bdtechtalks.com/2021/05/17/ibms-codenet-machine-learning-programming/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nfy0xh,True,,bendee983,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nfy0xh/project_codenet_14m_code_samples_to_train_dl/,all_ads,False,https://bdtechtalks.com/2021/05/17/ibms-codenet-machine-learning-programming/,66147,1621405277.0,0,,False,,,,,,,
,deeplearning,"I am using a Conv-6 CNN in TensorFlow 2.5 and Python3. The objective is to selectively set certain weights within any trainable layer. The Conv-6 CNN model definition is as follows:

&amp;#x200B;

        def conv6_cnn():
            """"""
            Function to define the architecture of a neural network model
            following Conv-6 architecture for CIFAR-10 dataset and using
            provided parameter which are used to prune the model.
            
            Conv-6 architecture-
            64, 64, pool  -- convolutional layers
            128, 128, pool -- convolutional layers
            256, 256, pool -- convolutional layers
            256, 256, 10  -- fully connected layers
            
            Output: Returns designed and compiled neural network model
            """"""
            
            l = tf.keras.layers
            
            model = Sequential()
            
            model.add(
                Conv2D(
                    filters = 64, kernel_size = (3, 3),
                    activation='relu', kernel_initializer = tf.initializers.GlorotNormal(),
                    strides = (1, 1), padding = 'same',
                    input_shape=(32, 32, 3)
                )    
            )
                
            model.add(
                Conv2D(
                    filters = 64, kernel_size = (3, 3),
                    activation='relu', kernel_initializer = tf.initializers.GlorotNormal(),
                    strides = (1, 1), padding = 'same'
                )
            )
            
            model.add(
                MaxPooling2D(
                    pool_size = (2, 2),
                    strides = (2, 2)
                )
            )
            
            model.add(
                Conv2D(
                    filters = 128, kernel_size = (3, 3),
                    activation='relu', kernel_initializer = tf.initializers.GlorotNormal(),
                    strides = (1, 1), padding = 'same'
                )
            )
        
            model.add(
                Conv2D(
                    filters = 128, kernel_size = (3, 3),
                    activation='relu', kernel_initializer = tf.initializers.GlorotNormal(),
                    strides = (1, 1), padding = 'same'
                )
            )
        
            model.add(
                MaxPooling2D(
                    pool_size = (2, 2),
                    strides = (2, 2)
                )
            )
        
            model.add(
                Conv2D(
                    filters = 256, kernel_size = (3, 3),
                    activation='relu', kernel_initializer = tf.initializers.GlorotNormal(),
                    strides = (1, 1), padding = 'same'
                )
            )
        
            model.add(
                Conv2D(
                    filters = 256, kernel_size = (3, 3),
                    activation='relu', kernel_initializer = tf.initializers.GlorotNormal(),
                    strides = (1, 1), padding = 'same'
                )
            )
        
            model.add(
                MaxPooling2D(
                    pool_size = (2, 2),
                    strides = (2, 2)
                )
            )
            
            model.add(Flatten())
            
            model.add(
                Dense(
                    units = 256, activation='relu',
                    kernel_initializer = tf.initializers.GlorotNormal()
                )
            )
            
            model.add(
                Dense(
                    units = 256, activation='relu',
                    kernel_initializer = tf.initializers.GlorotNormal()
                )
            )
            
            model.add(
                Dense(
                    units = 10, activation='softmax'
                )
            )
            
        
            '''
            # Compile CNN-
            model.compile(
                loss=tf.keras.losses.categorical_crossentropy,
                # optimizer='adam',
                optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0003),
                metrics=['accuracy']
            )
            '''
            
            
            return model
    
    
        # Load trained model from before-
        best_model = conv6_cnn()
        best_model.load_weights(""best_weights.h5"")

&amp;#x200B;

I came across [this](https://github.com/tensorflow/tensorflow/issues/6264) GitHub answer of freezing certain weights during training. On it's basis, I coded the following to freeze weights in the first and sixth conv layers:

&amp;#x200B;

        conv1 = pruned_model.trainable_weights[0]
        
        # Find all weights less than a threshold (0.1) and set them to zero-
        conv1 = tf.where(conv1 &lt; 0.1, 0, conv1)
        
        # For all weights set to zero, stop training them-
        conv1 = tf.where(conv1 == 0, tf.stop_gradient(conv1), conv1)
        
        
        # Sanity check: number of parameters set at 0-
        tf.math.count_nonzero(conv1, axis = None).numpy()
        # 133
        
        # Original number of paramaters-
        tf.math.count_nonzero(best_model.trainable_weights[0], axis = None).numpy()
        # 1728
        
        # Assign conv layer1 back to pruned model-
        pruned_model.trainable_weights[0].assign(conv1)
        
        # Sanity check-
        tf.math.count_nonzero(pruned_model.trainable_weights[0], axis = None).numpy()
        # 133
        
        # conv layer 6-
        conv6 = pruned_model.trainable_weights[10]
        
        # Find all weights less than a threshold (0.1) and set them to zero-
        conv6 = tf.where(conv6 &lt; 0.1, 0, conv6)
        
        # For all weights set to zero, stop training them-
        conv6 = tf.where(conv6 == 0, tf.stop_gradient(conv6), conv6)
        
        # Sanity check: number of parameters set at 0-
        tf.math.count_nonzero(conv6, axis = None).numpy()
        # 5369
        
        # Original number of paramaters-
        tf.math.count_nonzero(best_model.trainable_weights[10], axis = None).numpy()
        # 589824
        
        # Assign conv layer6 back to pruned model-
        pruned_model.trainable_weights[10].assign(conv6)
        
        # Sanity check-
        tf.math.count_nonzero(pruned_model.trainable_weights[10], axis = None).numpy()
        # 5369
        
        
        # Train model for 10 epochs for testing:
        
        # Compile CNN-
        pruned_model.compile(
            loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False),
            optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01),
            metrics=['accuracy']
        )
        
        history = pruned_model.fit(
            x = X_train, y = y_train,
            epochs = 10, validation_data = (X_test, y_test)
        )

However, after training when I check the number of non-zero weights:

&amp;#x200B;

        # first conv layer-
        tf.math.count_nonzero(pruned_model.trainable_weights[0], axis = None).numpy()
        
        # sixth conv layer-
        tf.math.count_nonzero(pruned_model.trainable_weights[10], axis = None).numpy()

&amp;#x200B;

The weights have increased in numbers again. They should have been 133 and 5369, but they are not.

&amp;#x200B;

Help?",t2_2mmql89p,False,,0,False,Freeze certain weights - TensorFlow 2,[],r/deeplearning,False,6,,0,,False,t3_ng7was,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1621464647.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am using a Conv-6 CNN in TensorFlow 2.5 and Python3. The objective is to selectively set certain weights within any trainable layer. The Conv-6 CNN model definition is as follows:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    def conv6_cnn():
        &amp;quot;&amp;quot;&amp;quot;
        Function to define the architecture of a neural network model
        following Conv-6 architecture for CIFAR-10 dataset and using
        provided parameter which are used to prune the model.

        Conv-6 architecture-
        64, 64, pool  -- convolutional layers
        128, 128, pool -- convolutional layers
        256, 256, pool -- convolutional layers
        256, 256, 10  -- fully connected layers

        Output: Returns designed and compiled neural network model
        &amp;quot;&amp;quot;&amp;quot;

        l = tf.keras.layers

        model = Sequential()

        model.add(
            Conv2D(
                filters = 64, kernel_size = (3, 3),
                activation=&amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.GlorotNormal(),
                strides = (1, 1), padding = &amp;#39;same&amp;#39;,
                input_shape=(32, 32, 3)
            )    
        )

        model.add(
            Conv2D(
                filters = 64, kernel_size = (3, 3),
                activation=&amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.GlorotNormal(),
                strides = (1, 1), padding = &amp;#39;same&amp;#39;
            )
        )

        model.add(
            MaxPooling2D(
                pool_size = (2, 2),
                strides = (2, 2)
            )
        )

        model.add(
            Conv2D(
                filters = 128, kernel_size = (3, 3),
                activation=&amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.GlorotNormal(),
                strides = (1, 1), padding = &amp;#39;same&amp;#39;
            )
        )

        model.add(
            Conv2D(
                filters = 128, kernel_size = (3, 3),
                activation=&amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.GlorotNormal(),
                strides = (1, 1), padding = &amp;#39;same&amp;#39;
            )
        )

        model.add(
            MaxPooling2D(
                pool_size = (2, 2),
                strides = (2, 2)
            )
        )

        model.add(
            Conv2D(
                filters = 256, kernel_size = (3, 3),
                activation=&amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.GlorotNormal(),
                strides = (1, 1), padding = &amp;#39;same&amp;#39;
            )
        )

        model.add(
            Conv2D(
                filters = 256, kernel_size = (3, 3),
                activation=&amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.GlorotNormal(),
                strides = (1, 1), padding = &amp;#39;same&amp;#39;
            )
        )

        model.add(
            MaxPooling2D(
                pool_size = (2, 2),
                strides = (2, 2)
            )
        )

        model.add(Flatten())

        model.add(
            Dense(
                units = 256, activation=&amp;#39;relu&amp;#39;,
                kernel_initializer = tf.initializers.GlorotNormal()
            )
        )

        model.add(
            Dense(
                units = 256, activation=&amp;#39;relu&amp;#39;,
                kernel_initializer = tf.initializers.GlorotNormal()
            )
        )

        model.add(
            Dense(
                units = 10, activation=&amp;#39;softmax&amp;#39;
            )
        )


        &amp;#39;&amp;#39;&amp;#39;
        # Compile CNN-
        model.compile(
            loss=tf.keras.losses.categorical_crossentropy,
            # optimizer=&amp;#39;adam&amp;#39;,
            optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0003),
            metrics=[&amp;#39;accuracy&amp;#39;]
        )
        &amp;#39;&amp;#39;&amp;#39;


        return model


    # Load trained model from before-
    best_model = conv6_cnn()
    best_model.load_weights(&amp;quot;best_weights.h5&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I came across &lt;a href=""https://github.com/tensorflow/tensorflow/issues/6264""&gt;this&lt;/a&gt; GitHub answer of freezing certain weights during training. On it&amp;#39;s basis, I coded the following to freeze weights in the first and sixth conv layers:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    conv1 = pruned_model.trainable_weights[0]

    # Find all weights less than a threshold (0.1) and set them to zero-
    conv1 = tf.where(conv1 &amp;lt; 0.1, 0, conv1)

    # For all weights set to zero, stop training them-
    conv1 = tf.where(conv1 == 0, tf.stop_gradient(conv1), conv1)


    # Sanity check: number of parameters set at 0-
    tf.math.count_nonzero(conv1, axis = None).numpy()
    # 133

    # Original number of paramaters-
    tf.math.count_nonzero(best_model.trainable_weights[0], axis = None).numpy()
    # 1728

    # Assign conv layer1 back to pruned model-
    pruned_model.trainable_weights[0].assign(conv1)

    # Sanity check-
    tf.math.count_nonzero(pruned_model.trainable_weights[0], axis = None).numpy()
    # 133

    # conv layer 6-
    conv6 = pruned_model.trainable_weights[10]

    # Find all weights less than a threshold (0.1) and set them to zero-
    conv6 = tf.where(conv6 &amp;lt; 0.1, 0, conv6)

    # For all weights set to zero, stop training them-
    conv6 = tf.where(conv6 == 0, tf.stop_gradient(conv6), conv6)

    # Sanity check: number of parameters set at 0-
    tf.math.count_nonzero(conv6, axis = None).numpy()
    # 5369

    # Original number of paramaters-
    tf.math.count_nonzero(best_model.trainable_weights[10], axis = None).numpy()
    # 589824

    # Assign conv layer6 back to pruned model-
    pruned_model.trainable_weights[10].assign(conv6)

    # Sanity check-
    tf.math.count_nonzero(pruned_model.trainable_weights[10], axis = None).numpy()
    # 5369


    # Train model for 10 epochs for testing:

    # Compile CNN-
    pruned_model.compile(
        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False),
        optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01),
        metrics=[&amp;#39;accuracy&amp;#39;]
    )

    history = pruned_model.fit(
        x = X_train, y = y_train,
        epochs = 10, validation_data = (X_test, y_test)
    )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, after training when I check the number of non-zero weights:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    # first conv layer-
    tf.math.count_nonzero(pruned_model.trainable_weights[0], axis = None).numpy()

    # sixth conv layer-
    tf.math.count_nonzero(pruned_model.trainable_weights[10], axis = None).numpy()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The weights have increased in numbers again. They should have been 133 and 5369, but they are not.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ng7was,True,,grid_world,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/ng7was/freeze_certain_weights_tensorflow_2/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ng7was/freeze_certain_weights_tensorflow_2/,66147,1621435847.0,0,,False,,,,,,,
,deeplearning,"I've read through a couple of blogs related to VAE. But I'm still having trouble understanding the concept of disentangled representations. 

I understand that such representations improve the human interpretability of the vae model, but does it improve the model's training and if yes, how?

I also haven't come across any concrete math involved in this apart from the basic vae model, so it'd be nice if someone can suggest those too.",t2_4xhrybaz,False,,0,False,Any good references on disentangled representations of VAE?,[],r/deeplearning,False,6,,0,,False,t3_nfxbq9,False,dark,0.84,,public,9,0,{},,False,[],,False,False,,{},,False,9,,False,False,,False,,[],{},,True,,1621431733.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve read through a couple of blogs related to VAE. But I&amp;#39;m still having trouble understanding the concept of disentangled representations. &lt;/p&gt;

&lt;p&gt;I understand that such representations improve the human interpretability of the vae model, but does it improve the model&amp;#39;s training and if yes, how?&lt;/p&gt;

&lt;p&gt;I also haven&amp;#39;t come across any concrete math involved in this apart from the basic vae model, so it&amp;#39;d be nice if someone can suggest those too.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nfxbq9,True,,banenvy,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nfxbq9/any_good_references_on_disentangled/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nfxbq9/any_good_references_on_disentangled/,66147,1621402933.0,0,,False,,,,,,,
,deeplearning," Hy all,

is it possible/feasible to train a TensorFlow U-Net model für image segmentation over cloud services like Google Cloud or Paperspace?

Currently, I am using my tower pc (even though I am not utilizing the GPU right now) to build a U-Net based image segmentation model. Following this tutorial:

[https://www.youtube.com/watch?v=XyX5HNuv-xE&amp;t=674s](https://www.youtube.com/watch?v=XyX5HNuv-xE&amp;t=674s)

I will move to another country in a few weeks and there I will only have access to my laptop. I worry that my Laptop might not be powerful enough, therefore I am looking for other solutions for training. Would Google Cloud or Paperspace be a solution?

In general, I am missing a feeling of what is a big/computational expensive model. If I would train with about 10.000 images with U-Net, would this be considered something big?

I appreciate all answers as well as links for sources where I can read up on those topics. Thanks a lot!",t2_69srzkcq,False,,0,False,"Using Google Cloud or Paperspace for U-Net image segmentation and Tensorflow, possible?",[],r/deeplearning,False,6,,0,,False,t3_ng559j,False,dark,0.66,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1621457947.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hy all,&lt;/p&gt;

&lt;p&gt;is it possible/feasible to train a TensorFlow U-Net model für image segmentation over cloud services like Google Cloud or Paperspace?&lt;/p&gt;

&lt;p&gt;Currently, I am using my tower pc (even though I am not utilizing the GPU right now) to build a U-Net based image segmentation model. Following this tutorial:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=XyX5HNuv-xE&amp;amp;t=674s""&gt;https://www.youtube.com/watch?v=XyX5HNuv-xE&amp;amp;t=674s&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I will move to another country in a few weeks and there I will only have access to my laptop. I worry that my Laptop might not be powerful enough, therefore I am looking for other solutions for training. Would Google Cloud or Paperspace be a solution?&lt;/p&gt;

&lt;p&gt;In general, I am missing a feeling of what is a big/computational expensive model. If I would train with about 10.000 images with U-Net, would this be considered something big?&lt;/p&gt;

&lt;p&gt;I appreciate all answers as well as links for sources where I can read up on those topics. Thanks a lot!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ng559j,True,,Dunkin_1,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/ng559j/using_google_cloud_or_paperspace_for_unet_image/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ng559j/using_google_cloud_or_paperspace_for_unet_image/,66147,1621429147.0,0,,False,,,,,,,
,deeplearning,"As promised, here's the second and final video in AI researcher Ahmed Gad's series on Mask R-CNN.

This tutorial covers how to train Mask R-CNN on your own custom dataset with Keras. 

Stay tuned for more ML tutorial videos in the coming weeks!  

&amp;#x200B;

Full tutorial: [https://youtu.be/Y53PtAVoyP4](https://youtu.be/Y53PtAVoyP4)

Run the full code on a free GPU: [https://ml-showcase.paperspace.com/projects/object-detection-with-mask-r-cnn](https://ml-showcase.paperspace.com/projects/object-detection-with-mask-r-cnn)",t2_15en0l,False,,0,False,[Video Tutorial] Train Mask R-CNN on Your Custom Data,[],r/deeplearning,False,6,,0,,False,t3_ng999i,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621467871.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As promised, here&amp;#39;s the second and final video in AI researcher Ahmed Gad&amp;#39;s series on Mask R-CNN.&lt;/p&gt;

&lt;p&gt;This tutorial covers how to train Mask R-CNN on your own custom dataset with Keras. &lt;/p&gt;

&lt;p&gt;Stay tuned for more ML tutorial videos in the coming weeks!  &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Full tutorial: &lt;a href=""https://youtu.be/Y53PtAVoyP4""&gt;https://youtu.be/Y53PtAVoyP4&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Run the full code on a free GPU: &lt;a href=""https://ml-showcase.paperspace.com/projects/object-detection-with-mask-r-cnn""&gt;https://ml-showcase.paperspace.com/projects/object-detection-with-mask-r-cnn&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ng999i,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ng999i/video_tutorial_train_mask_rcnn_on_your_custom_data/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ng999i/video_tutorial_train_mask_rcnn_on_your_custom_data/,66147,1621439071.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,"You have some experience with AI? Join us! We are a Discord Community with over 12'000 members and we need you! We are looking for more experienced members that are willing to help others and share their projects. Click the link, agree to the rules, select the ""teacher"" role, and start helping!",[],r/deeplearning,False,6,,0,,False,t3_ng8cfy,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1621465723.0,text,6,,,text,louisbouchard.ai,False,,,,,https://www.louisbouchard.ai/learn-ai-together/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ng8cfy,True,,OnlyProggingForFun,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ng8cfy/you_have_some_experience_with_ai_join_us_we_are_a/,all_ads,False,https://www.louisbouchard.ai/learn-ai-together/,66147,1621436923.0,0,,False,,,,,,,
,deeplearning," Hi, I am a beginner at ML and I want to build a Mask Detector (which will detect if the person is wearing a mask or not) as my project for college. I will really appreciate it if someone can guide me. Like which libraries or algorithms can be best for it, what things I need to learn, or anything.",t2_7sngffyv,False,,0,False,Can Someone please guide me on this project.,[],r/deeplearning,False,6,,0,,False,t3_ng4s46,False,dark,0.5,,public,0,1,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{'gid_1': 1},,True,,1621456978.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I am a beginner at ML and I want to build a Mask Detector (which will detect if the person is wearing a mask or not) as my project for college. I will really appreciate it if someone can guide me. Like which libraries or algorithms can be best for it, what things I need to learn, or anything.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ng4s46,True,,_ikv,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ng4s46/can_someone_please_guide_me_on_this_project/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ng4s46/can_someone_please_guide_me_on_this_project/,66147,1621428178.0,0,,False,,,,,,,
,deeplearning,"Is there a VM solution to install on my MacBook Pro (15-inch, 2018) so that I can run Linux on that has access to the GPU (for deep learning training purposes)?

Pytorch has a Linux version to run on AMD GPU via ROCm for Linux. However, I have tried VMBox, parallels and docker and I can't access the gpu from within the guest OS.  


Any ideas?",t2_3l5ve9zj,False,,0,False,Access gpu via vm on mac,[],r/deeplearning,False,6,,0,,False,t3_nfy4js,False,dark,0.81,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1621434414.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is there a VM solution to install on my MacBook Pro (15-inch, 2018) so that I can run Linux on that has access to the GPU (for deep learning training purposes)?&lt;/p&gt;

&lt;p&gt;Pytorch has a Linux version to run on AMD GPU via ROCm for Linux. However, I have tried VMBox, parallels and docker and I can&amp;#39;t access the gpu from within the guest OS.  &lt;/p&gt;

&lt;p&gt;Any ideas?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nfy4js,True,,yaeha83,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nfy4js/access_gpu_via_vm_on_mac/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nfy4js/access_gpu_via_vm_on_mac/,66147,1621405614.0,0,,False,,,,,,,
,deeplearning,,t2_ifxd7,False,,0,False,I reviewed techniques we've been using to cut GPU costs from training and inference,[],r/deeplearning,False,6,,0,,False,t3_ng36ep,False,dark,0.56,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1621452216.0,text,6,,,text,thomasmetcalfe.com,False,,,,,https://thomasmetcalfe.com/cut-gpu-from-machine-learning/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ng36ep,True,,Yororoto,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ng36ep/i_reviewed_techniques_weve_been_using_to_cut_gpu/,all_ads,False,https://thomasmetcalfe.com/cut-gpu-from-machine-learning/,66147,1621423416.0,0,,False,,,,,,,
,deeplearning,"I executed the same mode (written in PyTorch) on both GTX 1080 and K80 (on google colab) and found that the performance of both is similar as can be seen;

Execution Time (GTX 1080): 27.85

Execution Time (K80): 27.10

Some say that GTX is faster whereas others say K80. Definitely GTX 1080 is more cost effective as we are getting similar performance on both though there is a huge price gap between the two. What do you thin, which one is faster between the two or why are they giving the similar performance here?

Thank you.",t2_5diq79z0,False,,0,False,K80 vs GTX 1080 speed,[],r/deeplearning,False,6,,0,,False,t3_nfv3dw,False,dark,0.81,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1621424717.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I executed the same mode (written in PyTorch) on both GTX 1080 and K80 (on google colab) and found that the performance of both is similar as can be seen;&lt;/p&gt;

&lt;p&gt;Execution Time (GTX 1080): 27.85&lt;/p&gt;

&lt;p&gt;Execution Time (K80): 27.10&lt;/p&gt;

&lt;p&gt;Some say that GTX is faster whereas others say K80. Definitely GTX 1080 is more cost effective as we are getting similar performance on both though there is a huge price gap between the two. What do you thin, which one is faster between the two or why are they giving the similar performance here?&lt;/p&gt;

&lt;p&gt;Thank you.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nfv3dw,True,,navdeepsony13,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nfv3dw/k80_vs_gtx_1080_speed/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nfv3dw/k80_vs_gtx_1080_speed/,66147,1621395917.0,0,,False,,,,,,,
,deeplearning,"A research team from Facebook shows how the power of transfer learning can enable pretraining on non-IDE, non-autocompletion and different-language example code sequences before fine-tuning on the autocompletion prediction task to improve model accuracy by over 50 percent on very small fine-tuning datasets and over 10 percent on 50k labelled examples.

Here is a quick read: [Facebook Transfer Learning Method Boosts Code Autocompletion Accuracy by Over 50%.](https://syncedreview.com/2021/05/18/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-21/)

The paper *Improving Code Autocompletion with Transfer Learning* is on [arXiv](https://arxiv.org/abs/2105.05991).",t2_2fv4yodo,False,,0,False,[R] Facebook Transfer Learning Method Boosts Code Autocompletion Accuracy by Over 50%,[],r/deeplearning,False,6,,0,,False,t3_nfdtgk,False,dark,0.89,,public,25,0,{},,False,[],,False,False,,{},,False,25,,False,False,,False,,[],{},,True,,1621380962.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Facebook shows how the power of transfer learning can enable pretraining on non-IDE, non-autocompletion and different-language example code sequences before fine-tuning on the autocompletion prediction task to improve model accuracy by over 50 percent on very small fine-tuning datasets and over 10 percent on 50k labelled examples.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/18/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-21/""&gt;Facebook Transfer Learning Method Boosts Code Autocompletion Accuracy by Over 50%.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Improving Code Autocompletion with Transfer Learning&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.05991""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nfdtgk,True,,Yuqing7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nfdtgk/r_facebook_transfer_learning_method_boosts_code/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nfdtgk/r_facebook_transfer_learning_method_boosts_code/,66147,1621352162.0,0,,False,,,,,,,
,deeplearning,"For some time now, Transformers have taken the vision world by storm. In this work, we question the robustness aspects of Vision Transformers. Specifically, we investigate the question:

*With the virtue of self-attention, can Vision Transformers provide improved robustness to common corruptions, perturbations, etc.? If so, why?* 

We build on top of existing works &amp; investigate the robustness aspects of ViT. Through a series of six systematically designed experiments, we present analyses that provide both quantitative &amp; qualitative indications to explain why ViTs are indeed more robust learners. 

* Paper: [https://arxiv.org/abs/2105.07581](https://arxiv.org/abs/2105.07581)
* Code: [https://git.io/J3VO0](https://git.io/J3VO0)",t2_240yqv19,False,,0,False,Vision Transformers are Robust Learners,[],r/deeplearning,False,6,,0,,False,t3_ng0nln,False,dark,0.56,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621443615.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For some time now, Transformers have taken the vision world by storm. In this work, we question the robustness aspects of Vision Transformers. Specifically, we investigate the question:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;With the virtue of self-attention, can Vision Transformers provide improved robustness to common corruptions, perturbations, etc.? If so, why?&lt;/em&gt; &lt;/p&gt;

&lt;p&gt;We build on top of existing works &amp;amp; investigate the robustness aspects of ViT. Through a series of six systematically designed experiments, we present analyses that provide both quantitative &amp;amp; qualitative indications to explain why ViTs are indeed more robust learners. &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Paper: &lt;a href=""https://arxiv.org/abs/2105.07581""&gt;https://arxiv.org/abs/2105.07581&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code: &lt;a href=""https://git.io/J3VO0""&gt;https://git.io/J3VO0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ng0nln,True,,spsayakpaul,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ng0nln/vision_transformers_are_robust_learners/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ng0nln/vision_transformers_are_robust_learners/,66147,1621414815.0,0,,False,,,,,,,
,deeplearning,"I'm just starting with practical deep learning. I would like to retrain a YOLO type model, but I prefer a more mainstream environment than the Darknet. I looked at the catalog of models at TensorFlow Hub and Model Garden, but there is no YOLO models there. What is the reason?",t2_b2137,False,,0,False,Why there is no YOLO models at TensorFlow Hub or Model Garden.,[],r/deeplearning,False,6,,0,,False,t3_nflm0y,False,dark,0.76,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1621399218.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m just starting with practical deep learning. I would like to retrain a YOLO type model, but I prefer a more mainstream environment than the Darknet. I looked at the catalog of models at TensorFlow Hub and Model Garden, but there is no YOLO models there. What is the reason?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nflm0y,True,,puplan,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/nflm0y/why_there_is_no_yolo_models_at_tensorflow_hub_or/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nflm0y/why_there_is_no_yolo_models_at_tensorflow_hub_or/,66147,1621370418.0,0,,False,,,,,,,
,deeplearning,,t2_71atywgj,False,,0,False,Intel makes GTA V Hyperrealistic with CNN's,[],r/deeplearning,False,6,,0,,False,t3_nf0kov,False,dark,0.77,,public,35,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/eE7WmJl7j14?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Intel makes GTA V Hyperrealistic with CNN's! | Amazon's AI used Slur? || Today in AI Episode One"", 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/eE7WmJl7j14?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The Teen Innovator', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/eE7WmJl7j14/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCHGbO2h8gRi-w4tx_nZcMMw'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/eE7WmJl7j14?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nf0kov', 'height': 200}",,False,35,,False,False,,False,,[],{},,False,,1621339087.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/eE7WmJl7j14,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nf0kov,True,,Snoo28889,,15,True,all_ads,False,[],False,,/r/deeplearning/comments/nf0kov/intel_makes_gta_v_hyperrealistic_with_cnns/,all_ads,False,https://youtu.be/eE7WmJl7j14,66147,1621310287.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Intel makes GTA V Hyperrealistic with CNN's! | Amazon's AI used Slur? || Today in AI Episode One"", 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/eE7WmJl7j14?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The Teen Innovator', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/eE7WmJl7j14/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCHGbO2h8gRi-w4tx_nZcMMw'}}",False,,,,,,,
,deeplearning,,t2_8fknx0jo,False,,0,False,The Best Machine Learning Courses on Udemy (According to Experts),[],r/deeplearning,False,6,,0,,False,t3_nfi1e1,False,dark,0.63,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1621390864.0,text,6,,,text,pythonstacks.com,False,,,,,https://www.pythonstacks.com/blog/post/machine-learning-courses/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nfi1e1,True,,Jan_Prince,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nfi1e1/the_best_machine_learning_courses_on_udemy/,all_ads,False,https://www.pythonstacks.com/blog/post/machine-learning-courses/,66147,1621362064.0,0,,False,,,,,,,
,deeplearning,"I am watching for some free deepfake that changes the spoken text in video, found only this one and its not public [https://www.youtube.com/watch?v=0ybLCfVeFL4](https://www.youtube.com/watch?v=0ybLCfVeFL4) and was in 2019. Any software available in 2021 for free ?",t2_5kospy8k,False,,0,False,Any free deepfake that changes the spoken text in video ?,[],r/deeplearning,False,6,,0,,False,t3_nfgola,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1621387712.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am watching for some free deepfake that changes the spoken text in video, found only this one and its not public &lt;a href=""https://www.youtube.com/watch?v=0ybLCfVeFL4""&gt;https://www.youtube.com/watch?v=0ybLCfVeFL4&lt;/a&gt; and was in 2019. Any software available in 2021 for free ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nfgola,True,,xSNYPSx,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nfgola/any_free_deepfake_that_changes_the_spoken_text_in/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nfgola/any_free_deepfake_that_changes_the_spoken_text_in/,66147,1621358912.0,0,,False,,,,,,,
,deeplearning,"[https://smc-datachallenge.ornl.gov/data-challenges-2021/](https://smc-datachallenge.ornl.gov/data-challenges-2021/)

[https://www.hpcwire.com/off-the-wire/ornl-invites-student-scientists-experts-to-enter-smoky-mountains-data-challenge/](https://www.hpcwire.com/off-the-wire/ornl-invites-student-scientists-experts-to-enter-smoky-mountains-data-challenge/)",t2_1i5emt3w,False,,0,False,Data Challenge Conference by Oak Ridge National Laboratory #SMC2021,[],r/deeplearning,False,6,,0,,False,t3_nfe0l3,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1621381435.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://smc-datachallenge.ornl.gov/data-challenges-2021/""&gt;https://smc-datachallenge.ornl.gov/data-challenges-2021/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.hpcwire.com/off-the-wire/ornl-invites-student-scientists-experts-to-enter-smoky-mountains-data-challenge/""&gt;https://www.hpcwire.com/off-the-wire/ornl-invites-student-scientists-experts-to-enter-smoky-mountains-data-challenge/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nfe0l3,True,,abhi_d104,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nfe0l3/data_challenge_conference_by_oak_ridge_national/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nfe0l3/data_challenge_conference_by_oak_ridge_national/,66147,1621352635.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,Cartoon Style | ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement,[],r/deeplearning,False,6,,0,,False,t3_nfh29h,False,dark,0.6,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/s34aN-voYBk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Cartoon Style | ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/s34aN-voYBk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/s34aN-voYBk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/s34aN-voYBk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nfh29h', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1621388593.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/s34aN-voYBk,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nfh29h,True,,cmillionaire9,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nfh29h/cartoon_style_restyle_a_residualbased_stylegan/,all_ads,False,https://youtu.be/s34aN-voYBk,66147,1621359793.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Cartoon Style | ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/s34aN-voYBk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/s34aN-voYBk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,,t2_15fqy2,False,,0,False,How to transform an Abstract Syntax Tree (AST) to an Abstract Binding Tree (ABT)? (for machine learning fo theorem proving),[],r/deeplearning,False,6,,0,,False,t3_nfdkbg,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1621380357.0,text,6,,,text,cs.stackexchange.com,False,,,,,https://cs.stackexchange.com/questions/140463/how-to-transform-an-abstract-syntax-tree-ast-to-an-abstract-binding-tree-abt,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nfdkbg,True,,brandojazz,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nfdkbg/how_to_transform_an_abstract_syntax_tree_ast_to/,all_ads,False,https://cs.stackexchange.com/questions/140463/how-to-transform-an-abstract-syntax-tree-ast-to-an-abstract-binding-tree-abt,66147,1621351557.0,0,,False,,,,,,,
,deeplearning,,t2_9makuodb,False,,0,False,"How can I convert a scene segmentation mask image shape=(n,m,3) to shape=(n,m, number of classes) for scene segmentation?",[],r/deeplearning,False,6,,0,,False,t3_nf96nl,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621368995.0,text,6,,,text,self.deeplearning,False,,,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nf96nl,True,,Professional_Fox1206,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nf96nl/how_can_i_convert_a_scene_segmentation_mask_image/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nf96nl/how_can_i_convert_a_scene_segmentation_mask_image/,66147,1621340195.0,0,,False,,,,,,,
,deeplearning,,t2_aawxwzjf,False,,0,False,"[Q]: DS -&gt;ML Algorithms -&gt; Deep Learning (ANN,CNN,RNN etc.) -&gt; what next ?",[],r/deeplearning,False,6,,0,,False,t3_nfcy4l,False,dark,0.25,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1621378890.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/nfcvt5/d_ds_ml_algorithms_deep_learning_anncnnrnn_etc/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nfcy4l,True,,Meem_yay,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nfcy4l/q_ds_ml_algorithms_deep_learning_anncnnrnn_etc/,all_ads,False,/r/MachineLearning/comments/nfcvt5/d_ds_ml_algorithms_deep_learning_anncnnrnn_etc/,66147,1621350090.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '[removed]', 'author_fullname': 't2_aawxwzjf', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D]: DS -&gt;ML Algorithms -&gt; Deep Learning (ANN,CNN,RNN etc.) -&gt; what next ?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nfcvt5', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1621378753.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': 'moderator', 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nfcvt5', 'is_robot_indexable': False, 'report_reasons': None, 'author': 'Meem_yay', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/nfcvt5/d_ds_ml_algorithms_deep_learning_anncnnrnn_etc/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/nfcvt5/d_ds_ml_algorithms_deep_learning_anncnnrnn_etc/', 'subreddit_subscribers': 1931381, 'created_utc': 1621349953.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_nfcvt5,,,,,
,deeplearning,"I am reading the paper ""are Pre-trained Convolutions Better than Pre-trained Transformers?"". However, it is not introduce the term ""cross attention"". I cannot search it. Anyone does know it?",t2_abqn4ac9,False,,0,False,what is the cross attention?,[],r/deeplearning,False,6,,0,,False,t3_nf08zz,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1621338032.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am reading the paper &amp;quot;are Pre-trained Convolutions Better than Pre-trained Transformers?&amp;quot;. However, it is not introduce the term &amp;quot;cross attention&amp;quot;. I cannot search it. Anyone does know it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nf08zz,True,,korjyman,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nf08zz/what_is_the_cross_attention/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nf08zz/what_is_the_cross_attention/,66147,1621309232.0,0,,False,,,,,,,
,deeplearning,,t2_a7i59xms,False,,0,False,MLP-Mixer in Flax and PyTorch,[],r/deeplearning,False,6,,0,,False,t3_nekj7f,False,dark,0.79,,public,11,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HqytB2GUbHA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'MLP-Mixer in Flax and PyTorch', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HqytB2GUbHA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'mildlyoverfitted', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/HqytB2GUbHA/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/mildlyoverfitted'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HqytB2GUbHA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nekj7f', 'height': 200}",,False,11,,False,False,,False,,[],{},,False,,1621297178.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/HqytB2GUbHA,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nekj7f,True,,mildlyoverfitted,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nekj7f/mlpmixer_in_flax_and_pytorch/,all_ads,False,https://youtu.be/HqytB2GUbHA,66147,1621268378.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'MLP-Mixer in Flax and PyTorch', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HqytB2GUbHA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'mildlyoverfitted', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/HqytB2GUbHA/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/mildlyoverfitted'}}",False,,,,,,,
,deeplearning,"Hello, I’m working on a 3D segmentation task.

Let’s say I have a volume of 500 x 500 x 500 voxels. In which I try to segment 4 different items. Let’s say 4 different organs in a full body scan.

So far my current approach is to use 
A model that predict a tensor of 4 x 500 x 500 x 500 and use a sigmoid.

Of course most of the voxels don’t belong to those target organs so most of them should have zero
In all four channels.

A co-worker of mine suggested I should have 5 channels and that new channel would be one if that voxel doesn’t belong to anything. This way I could use a softmax.

My opinion is that the result should still be the same because the information doesn’t change.

I’d gladly have your thoughts on that ! Is it the standard approach ? Having a background channel ?

Thanks !",t2_92m269w6,False,,0,False,Should you use a specific channel for the background ?,[],r/deeplearning,False,6,,0,,False,t3_neu0rb,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,1621294159.0,,[],{},,True,,1621319752.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I’m working on a 3D segmentation task.&lt;/p&gt;

&lt;p&gt;Let’s say I have a volume of 500 x 500 x 500 voxels. In which I try to segment 4 different items. Let’s say 4 different organs in a full body scan.&lt;/p&gt;

&lt;p&gt;So far my current approach is to use 
A model that predict a tensor of 4 x 500 x 500 x 500 and use a sigmoid.&lt;/p&gt;

&lt;p&gt;Of course most of the voxels don’t belong to those target organs so most of them should have zero
In all four channels.&lt;/p&gt;

&lt;p&gt;A co-worker of mine suggested I should have 5 channels and that new channel would be one if that voxel doesn’t belong to anything. This way I could use a softmax.&lt;/p&gt;

&lt;p&gt;My opinion is that the result should still be the same because the information doesn’t change.&lt;/p&gt;

&lt;p&gt;I’d gladly have your thoughts on that ! Is it the standard approach ? Having a background channel ?&lt;/p&gt;

&lt;p&gt;Thanks !&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,neu0rb,True,,PositiveElectro,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/neu0rb/should_you_use_a_specific_channel_for_the/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/neu0rb/should_you_use_a_specific_channel_for_the/,66147,1621290952.0,0,,False,,,,,,,
,deeplearning,"A research team from Google proposes GSPMD, an automatic parallelism system for ML computation graphs that uses simple tensor sharding annotations to achieve different parallelism paradigms in a unified way, including data parallelism, within-layer model parallelism, spatial partitioning, weight-update sharding, optimizer-state sharding and pipeline parallelism.

Here is a quick read: Google Proposes Scalable Parallelism for ML Computation on All Devices: Compilation Time Remains Constant As Devices Increase.

The paper *GSPMD: General and Scalable Parallelization for ML Computation Graphs* is on [arXiv](https://arxiv.org/abs/2105.04663).",t2_2fv4yodo,False,,0,False,[R] Google Proposes Scalable Parallelism for ML Computation on All Devices: Compilation Time Remains Constant As Devices Increase,[],r/deeplearning,False,6,,0,,False,t3_neivbl,False,dark,0.77,,public,11,0,{},,False,[],,False,False,,{},,False,11,,False,False,,False,,[],{},,True,,1621293216.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Google proposes GSPMD, an automatic parallelism system for ML computation graphs that uses simple tensor sharding annotations to achieve different parallelism paradigms in a unified way, including data parallelism, within-layer model parallelism, spatial partitioning, weight-update sharding, optimizer-state sharding and pipeline parallelism.&lt;/p&gt;

&lt;p&gt;Here is a quick read: Google Proposes Scalable Parallelism for ML Computation on All Devices: Compilation Time Remains Constant As Devices Increase.&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;GSPMD: General and Scalable Parallelization for ML Computation Graphs&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.04663""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,neivbl,True,,Yuqing7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/neivbl/r_google_proposes_scalable_parallelism_for_ml/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/neivbl/r_google_proposes_scalable_parallelism_for_ml/,66147,1621264416.0,0,,False,,,,,,,
,deeplearning,"Hello,

I am preparing a 15 minute talk my 'knowledge-based systems'-course. I am having some problems to answer the question properly.

The question I need to answer, also title of this post, is:

&gt;*How do we get knowledge into the computer on different representation levels?*

The course follows the knowledge representation level proposed by Gardenfors ([Gardenfors - Knowledge Representation](https://youtu.be/Y3_zlm9DrYk)). Shortly summarized knowledge can be represented on a

* symbolic or
* conceptual/geometric or
* subconceptual/connectivist

\- level.

&amp;#x200B;

The main focus should be on the pipeline. So how can we 'fill' a knowledge representation with knowledge? And are there differences between these levels or can we use the same pipeline?

I have read a lot of literature so far but haven't found any reliable information about a general pipeline.

As far as I can see if I take the subconceptual level as example here:

Lets say we have some plain text and want to generate word embeddings (e.g. subword embeddings) it is more easy for me to model the path from information to knowledge.

Roughly speaking we have our input data and want to extract useful information. Then structure the meaningful parts and give it to the system organized in a way a knowledge representation can be build based on this structured input. Am I right with that?

So asked my professor about this and he told me this task is more about thinking myself than searching for information in papers. But I am not sure if I am getting this right and also can't think of any examples on these other knowledge representation levels.

&amp;#x200B;

Can anyone help me out with some ideas on how information is transferred to knowledge on these different levels?

&amp;#x200B;

Feel free to come back at me if you have any questions or something is unclear. :)

&amp;#x200B;

Thanks in advance!",t2_447708fv,False,,0,False,"""How do we get knowledge into the computer on different representation levels?""",[],r/deeplearning,False,6,,0,,False,t3_nehex6,False,dark,1.0,,public,12,0,{},,False,[],,False,False,,{},,False,12,,False,False,,False,,[],{},,True,,1621289756.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I am preparing a 15 minute talk my &amp;#39;knowledge-based systems&amp;#39;-course. I am having some problems to answer the question properly.&lt;/p&gt;

&lt;p&gt;The question I need to answer, also title of this post, is:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;How do we get knowledge into the computer on different representation levels?&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The course follows the knowledge representation level proposed by Gardenfors (&lt;a href=""https://youtu.be/Y3_zlm9DrYk""&gt;Gardenfors - Knowledge Representation&lt;/a&gt;). Shortly summarized knowledge can be represented on a&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;symbolic or&lt;/li&gt;
&lt;li&gt;conceptual/geometric or&lt;/li&gt;
&lt;li&gt;subconceptual/connectivist&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;- level.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;The main focus should be on the pipeline. So how can we &amp;#39;fill&amp;#39; a knowledge representation with knowledge? And are there differences between these levels or can we use the same pipeline?&lt;/p&gt;

&lt;p&gt;I have read a lot of literature so far but haven&amp;#39;t found any reliable information about a general pipeline.&lt;/p&gt;

&lt;p&gt;As far as I can see if I take the subconceptual level as example here:&lt;/p&gt;

&lt;p&gt;Lets say we have some plain text and want to generate word embeddings (e.g. subword embeddings) it is more easy for me to model the path from information to knowledge.&lt;/p&gt;

&lt;p&gt;Roughly speaking we have our input data and want to extract useful information. Then structure the meaningful parts and give it to the system organized in a way a knowledge representation can be build based on this structured input. Am I right with that?&lt;/p&gt;

&lt;p&gt;So asked my professor about this and he told me this task is more about thinking myself than searching for information in papers. But I am not sure if I am getting this right and also can&amp;#39;t think of any examples on these other knowledge representation levels.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Can anyone help me out with some ideas on how information is transferred to knowledge on these different levels?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Feel free to come back at me if you have any questions or something is unclear. :)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nehex6,True,,Yannisch96,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nehex6/how_do_we_get_knowledge_into_the_computer_on/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nehex6/how_do_we_get_knowledge_into_the_computer_on/,66147,1621260956.0,0,,False,,,,,,,
,deeplearning," Hello. I have made an object detection model(Yolo) and being new to the whole concept I am a bit confused as to how to interpret my results. My Map is .70, Recall is quite high(.90) and precision is low(.45). What do low precision and high recall essentially mean in terms of bounding boxes prediction and how should I interpret them in terms of TP, TN, FP, FN for my model? Thank you.",t2_2h9gdmeu,False,,0,False,"Yolo with high recall, low precision",[],r/deeplearning,False,6,,0,,False,t3_neexq6,False,dark,0.82,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,True,,1621283349.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello. I have made an object detection model(Yolo) and being new to the whole concept I am a bit confused as to how to interpret my results. My Map is .70, Recall is quite high(.90) and precision is low(.45). What do low precision and high recall essentially mean in terms of bounding boxes prediction and how should I interpret them in terms of TP, TN, FP, FN for my model? Thank you.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,neexq6,True,,Hipocampus777,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/neexq6/yolo_with_high_recall_low_precision/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/neexq6/yolo_with_high_recall_low_precision/,66147,1621254549.0,0,,False,,,,,,,
,deeplearning,"Hello,

My name is Diahandra I am with Aves Lair. I appreciate you guys letting me be included in this community. You guys are extremely helpful and supportive. I work for startup tech company. We have Q and A webinar coming up about our accelerator program. Anyone interested is welcomed to come and join in on the conversation. It is just a chance for us let others know who we are and what our company is about and what we have to offer. Plus, a chance to see how we do our programs and if interested you can get involved.

Thanks again

[https://www.eventbrite.com/e/want-to-get-involved-in-an-accelerator-tickets-153698218509?aff=ebdssbonlinesearch](https://www.eventbrite.com/e/want-to-get-involved-in-an-accelerator-tickets-153698218509?aff=ebdssbonlinesearch)",t2_83ql2zp9,False,,0,False,Free Webinar: Want to get involved in an accelerator?,[],r/deeplearning,False,6,,0,,False,t3_nemxvl,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1621302712.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;My name is Diahandra I am with Aves Lair. I appreciate you guys letting me be included in this community. You guys are extremely helpful and supportive. I work for startup tech company. We have Q and A webinar coming up about our accelerator program. Anyone interested is welcomed to come and join in on the conversation. It is just a chance for us let others know who we are and what our company is about and what we have to offer. Plus, a chance to see how we do our programs and if interested you can get involved.&lt;/p&gt;

&lt;p&gt;Thanks again&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.eventbrite.com/e/want-to-get-involved-in-an-accelerator-tickets-153698218509?aff=ebdssbonlinesearch""&gt;https://www.eventbrite.com/e/want-to-get-involved-in-an-accelerator-tickets-153698218509?aff=ebdssbonlinesearch&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nemxvl,True,,aveslair123,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nemxvl/free_webinar_want_to_get_involved_in_an/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nemxvl/free_webinar_want_to_get_involved_in_an/,66146,1621273912.0,0,,False,,,,,,,
,deeplearning,"I am trying to train a convolutional neural network for video processing, using some kind of early fusion strategy: 10 subsequent grayscale video frames are stacked together, resulting in a H x W x 10 input image. So instead of the usual RGB input channels I have 10 channels. Now, as far as I understood, when a 2D convolutin is applied, each kernel is convolved with each channel separately, and the outputs are summed together. However, I don't think this is good for my case as the relationships between channels (i.e. time frames) are extremely important. Is there a better alternative to 2D convolution? Maybe a separable convolution, or just a depthwise convolution?

I can only rely on convolutions so I cannot use LSTM or RNN layers for this project.",t2_sm74p,False,,0,False,Better alternative to 2D convolution for video processing?,[],r/deeplearning,False,6,,0,,False,t3_ne9b5c,False,dark,0.9,,public,15,0,{},,False,[],,False,False,,{},,False,15,,False,False,,False,,[],{},,True,,1621264175.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to train a convolutional neural network for video processing, using some kind of early fusion strategy: 10 subsequent grayscale video frames are stacked together, resulting in a H x W x 10 input image. So instead of the usual RGB input channels I have 10 channels. Now, as far as I understood, when a 2D convolutin is applied, each kernel is convolved with each channel separately, and the outputs are summed together. However, I don&amp;#39;t think this is good for my case as the relationships between channels (i.e. time frames) are extremely important. Is there a better alternative to 2D convolution? Maybe a separable convolution, or just a depthwise convolution?&lt;/p&gt;

&lt;p&gt;I can only rely on convolutions so I cannot use LSTM or RNN layers for this project.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ne9b5c,True,,fralbalbero,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/ne9b5c/better_alternative_to_2d_convolution_for_video/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ne9b5c/better_alternative_to_2d_convolution_for_video/,66146,1621235375.0,0,,False,,,,,,,
,deeplearning,"Hello,

My name is Diahandra I am with Aves Lair. I appreciate you guys letting me be included in this community. You guys are extremely helpful and supportive. I work for startup tech company. We have Q and A webinar coming up about our accelerator program. Anyone interested is welcomed to come and join in on the conversation. It is just a chance for us let others know who we are and what our company is about and what we have to offer. Plus, a chance to see how we do our programs and if interested you can get involved.

Thanks again

[https://www.eventbrite.com/e/want-to-get-involved-in-an-accelerator-tickets-153698218509?aff=ebdssbonlinesearch](https://www.eventbrite.com/e/want-to-get-involved-in-an-accelerator-tickets-153698218509?aff=ebdssbonlinesearch)",t2_83ql2zp9,False,,0,False,Free Webinar: Want to get involved in an accelerator?,[],r/deeplearning,False,6,,0,,False,t3_nemtmz,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621302437.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;My name is Diahandra I am with Aves Lair. I appreciate you guys letting me be included in this community. You guys are extremely helpful and supportive. I work for startup tech company. We have Q and A webinar coming up about our accelerator program. Anyone interested is welcomed to come and join in on the conversation. It is just a chance for us let others know who we are and what our company is about and what we have to offer. Plus, a chance to see how we do our programs and if interested you can get involved.&lt;/p&gt;

&lt;p&gt;Thanks again&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.eventbrite.com/e/want-to-get-involved-in-an-accelerator-tickets-153698218509?aff=ebdssbonlinesearch""&gt;https://www.eventbrite.com/e/want-to-get-involved-in-an-accelerator-tickets-153698218509?aff=ebdssbonlinesearch&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nemtmz,True,,aveslair123,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nemtmz/free_webinar_want_to_get_involved_in_an/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nemtmz/free_webinar_want_to_get_involved_in_an/,66146,1621273637.0,0,,False,,,,,,,
,deeplearning,,t2_8emfs7ji,False,,0,False,What is it like to build a productivity startup with a GPT-3 backbone? I sat down with Flowrite CEO Aaro Isosaari to find out. Aaro kindly shared his insight into the challenges and discoveries connected with building an AI product people love based on the API. I hope it is valuable for you 🙏,[],r/deeplearning,False,6,,0,,False,t3_nejw0m,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FmIWLtk-o60?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Building a GPT 3 productivity startup | Interview with Flowrite CEO Aaro Isosaari', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FmIWLtk-o60?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'techn0cratic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/FmIWLtk-o60/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Technocratic'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FmIWLtk-o60?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nejw0m', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1621295677.0,text,6,,,text,youtube.com,False,,,,,https://youtube.com/watch?v=FmIWLtk-o60&amp;feature=share,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nejw0m,True,,techn0_cratic,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nejw0m/what_is_it_like_to_build_a_productivity_startup/,all_ads,False,https://youtube.com/watch?v=FmIWLtk-o60&amp;feature=share,66146,1621266877.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Building a GPT 3 productivity startup | Interview with Flowrite CEO Aaro Isosaari', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FmIWLtk-o60?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'techn0cratic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/FmIWLtk-o60/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Technocratic'}}",False,"[{'approved_at_utc': None, 'subreddit': 'OpenAI', 'selftext': '', 'author_fullname': 't2_8emfs7ji', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What is it like to build a productivity startup with a GPT-3 backbone? I sat down with Flowrite CEO Aaro Isosaari to find out. Aaro kindly shared his insight into the challenges and discoveries connected with building an AI product people love based on the API. I hope it is valuable for you 🙏', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/OpenAI', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nejspg', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.69, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FmIWLtk-o60?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Building a GPT 3 productivity startup | Interview with Flowrite CEO Aaro Isosaari', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FmIWLtk-o60?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'techn0cratic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/FmIWLtk-o60/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Technocratic'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FmIWLtk-o60?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nejspg', 'height': 200}, 'link_flair_text': '[Video]', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1621295461.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtube.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://youtube.com/watch?v=FmIWLtk-o60&amp;feature=share', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3b9u5', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nejspg', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'techn0_cratic', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/OpenAI/comments/nejspg/what_is_it_like_to_build_a_productivity_startup/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://youtube.com/watch?v=FmIWLtk-o60&amp;feature=share', 'subreddit_subscribers': 8646, 'created_utc': 1621266661.0, 'num_crossposts': 3, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Building a GPT 3 productivity startup | Interview with Flowrite CEO Aaro Isosaari', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FmIWLtk-o60?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'techn0cratic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/FmIWLtk-o60/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Technocratic'}}, 'is_video': False}]",t3_nejspg,,,,,
,deeplearning,"Hi guys, 

I'm new to deep learning and especially with text processing. For gain experience i tried to do a multi label classification. 

**Dataset**

I have some text and tags associated. Given the text, I want to predict the tag. The tag have **high dimensionality ( &gt; 10K )**

**My approach**

I tokenize the text in input, transform into an embedding and pad it.

For the tags, that are my label, i transform it with [MultiLabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer.inverse_transform)

The model is formed by an embedding layer and some lstm. The final layer is a dense one with #of possible tags as unit, sigmoid activation function. I fit the model with binary\_crossentropy as loss.

&amp;#x200B;

**Question**

Just after a few layer i have on the training set loss: 0.0023 - accuracy: 0.0440, aka super low. I think the problem could be the high dimensionality of the tags (the last layer).

&amp;#x200B;

Is this approach the right one (and so there are some kind of errors) or i have to change completely the approach?

&amp;#x200B;

thank you",t2_9knxu1lq,False,,0,False,Question about the approach for multi-label prediction,[],r/deeplearning,False,6,,0,,False,t3_nebsuw,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1621273245.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, &lt;/p&gt;

&lt;p&gt;I&amp;#39;m new to deep learning and especially with text processing. For gain experience i tried to do a multi label classification. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dataset&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I have some text and tags associated. Given the text, I want to predict the tag. The tag have &lt;strong&gt;high dimensionality ( &amp;gt; 10K )&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;My approach&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I tokenize the text in input, transform into an embedding and pad it.&lt;/p&gt;

&lt;p&gt;For the tags, that are my label, i transform it with &lt;a href=""https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer.inverse_transform""&gt;MultiLabelBinarizer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The model is formed by an embedding layer and some lstm. The final layer is a dense one with #of possible tags as unit, sigmoid activation function. I fit the model with binary_crossentropy as loss.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Just after a few layer i have on the training set loss: 0.0023 - accuracy: 0.0440, aka super low. I think the problem could be the high dimensionality of the tags (the last layer).&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Is this approach the right one (and so there are some kind of errors) or i have to change completely the approach?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nebsuw,True,,backprop_,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nebsuw/question_about_the_approach_for_multilabel/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nebsuw/question_about_the_approach_for_multilabel/,66146,1621244445.0,0,,False,,,,,,,
,deeplearning,"Hi every one ! I'm currently working on a signal classification problem with a classfication of a signal which can be represented by an array of size \[7:15000\]. This signal represent the eye movement. The first column is for time. The six others are for eye movement. I want to try neural networks to solve this problem. I have a database of 800 signals of 2 categories A and B. 400 of A and 400 of B. 

I'v already work with CNN for classical image classification or segmentation task. But i don't know if is it possible to do the same task with a signal. I work with Pytorch. 

Thanks for you're help :)",t2_buru3d4o,False,,0,False,Need help for signal classification,[],r/deeplearning,False,6,,0,,False,t3_neaof7,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621269123.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi every one ! I&amp;#39;m currently working on a signal classification problem with a classfication of a signal which can be represented by an array of size [7:15000]. This signal represent the eye movement. The first column is for time. The six others are for eye movement. I want to try neural networks to solve this problem. I have a database of 800 signals of 2 categories A and B. 400 of A and 400 of B. &lt;/p&gt;

&lt;p&gt;I&amp;#39;v already work with CNN for classical image classification or segmentation task. But i don&amp;#39;t know if is it possible to do the same task with a signal. I work with Pytorch. &lt;/p&gt;

&lt;p&gt;Thanks for you&amp;#39;re help :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,neaof7,True,,matmadmax,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/neaof7/need_help_for_signal_classification/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/neaof7/need_help_for_signal_classification/,66146,1621240323.0,0,,False,,,,,,,
,deeplearning,"Although BERT became really popular after its release, it did have some limitations. And there were certain limitations associated with autoregressive methods like ELMo and GPT as well. XLNet was introduced to get the best of both worlds while at the same time not include their weaknesses.

In continuation of my Paper Notes series, I have written an informative summary of the paper. Personally, reading the XLNet paper was a very fun experience. I was amazed at every step, how they were including stuff to make the whole model work so well. The paper contained many interesting concepts that I had to give time to understand. So don't worry if you don't get it on the first go. Check out the links below and happy reading!

Paper Summary - [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://shreyansh26.github.io/post/2021-05-16_generalized_autoregressive_pretraining_xlnet/)

Annotated Paper - [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf)",t2_5xzd9om,False,,0,False,XLNet - Annotated Paper + Paper Summary,[],r/deeplearning,False,6,,0,,False,t3_ndpsv7,False,dark,0.84,,public,17,1,{},,False,[],,False,False,,{},,False,17,,False,False,,False,,[],{},,True,,1621205016.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Although BERT became really popular after its release, it did have some limitations. And there were certain limitations associated with autoregressive methods like ELMo and GPT as well. XLNet was introduced to get the best of both worlds while at the same time not include their weaknesses.&lt;/p&gt;

&lt;p&gt;In continuation of my Paper Notes series, I have written an informative summary of the paper. Personally, reading the XLNet paper was a very fun experience. I was amazed at every step, how they were including stuff to make the whole model work so well. The paper contained many interesting concepts that I had to give time to understand. So don&amp;#39;t worry if you don&amp;#39;t get it on the first go. Check out the links below and happy reading!&lt;/p&gt;

&lt;p&gt;Paper Summary - &lt;a href=""https://shreyansh26.github.io/post/2021-05-16_generalized_autoregressive_pretraining_xlnet/""&gt;XLNet: Generalized Autoregressive Pretraining for Language Understanding&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Annotated Paper - &lt;a href=""https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf""&gt;https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/XLNet.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ndpsv7,True,,shreyansh26,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/ndpsv7/xlnet_annotated_paper_paper_summary/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ndpsv7/xlnet_annotated_paper_paper_summary/,66146,1621176216.0,0,,False,,,,,,,
,deeplearning," recently I was reading [this](https://towardsdatascience.com/bert-to-the-rescue-17671379687f#:%7E:text=BERT%20allows%20us%20to%20perform,the%20output%20of%20the%20model.) tutorial about BERT which was intended to classify IMDB's comments. In computer vision when we add our custom layers we freeze the base of the model, but this guy didn't freeze pre-trained BERT's model, and added his custom layers, is it normal? why people do that? I thought adding a layer which is randomly initialized and training whole model would mess up already trained weights but it seems that it didn't.",t2_3rqev321,False,,0,False,Why do we train whole BERT model for fine tuning and not freeze it?,[],r/deeplearning,False,6,,0,,False,t3_ndmqm6,False,dark,0.9,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1621194854.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;recently I was reading &lt;a href=""https://towardsdatascience.com/bert-to-the-rescue-17671379687f#:%7E:text=BERT%20allows%20us%20to%20perform,the%20output%20of%20the%20model.""&gt;this&lt;/a&gt; tutorial about BERT which was intended to classify IMDB&amp;#39;s comments. In computer vision when we add our custom layers we freeze the base of the model, but this guy didn&amp;#39;t freeze pre-trained BERT&amp;#39;s model, and added his custom layers, is it normal? why people do that? I thought adding a layer which is randomly initialized and training whole model would mess up already trained weights but it seems that it didn&amp;#39;t.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ndmqm6,True,,datonefaridze,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/ndmqm6/why_do_we_train_whole_bert_model_for_fine_tuning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ndmqm6/why_do_we_train_whole_bert_model_for_fine_tuning/,66146,1621166054.0,0,,False,,,,,,,
,deeplearning,"Hello! I am working with a data set of around 100K images ,All images are of different  rectangular  shapes and I tried 

    transforms.Resize()

,But  it distorts most of the images and therefore I settled for a training  loader with a batch size of 1 and using gradient accumulation , with  images as their original size ,but even with `num_workers : 0 and  pin_memory : True` the speed up gain  after first epoch is almost  negligible, I assume this is because of high resolution of images  because with the same setting for smaller images it worked faster .I  want to know about any other approaches I can use to speed up the  training(using PyTorch) as it takes more than 45  mins to just complete   one epoch.",t2_6xrd6ojt,False,,0,False,Suggestions to prepare / load data and train a model with PyTorch efficiently?,[],r/deeplearning,False,6,,0,,False,t3_ndi9i9,False,dark,0.8,,public,11,0,{},,False,[],,False,False,,{},,False,11,,False,False,,False,,[],{},,True,,1621175581.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello! I am working with a data set of around 100K images ,All images are of different  rectangular  shapes and I tried &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;transforms.Resize()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;,But  it distorts most of the images and therefore I settled for a training  loader with a batch size of 1 and using gradient accumulation , with  images as their original size ,but even with &lt;code&gt;num_workers : 0 and  pin_memory : True&lt;/code&gt; the speed up gain  after first epoch is almost  negligible, I assume this is because of high resolution of images  because with the same setting for smaller images it worked faster .I  want to know about any other approaches I can use to speed up the  training(using PyTorch) as it takes more than 45  mins to just complete   one epoch.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ndi9i9,True,,Awesome-355,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/ndi9i9/suggestions_to_prepare_load_data_and_train_a/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ndi9i9/suggestions_to_prepare_load_data_and_train_a/,66146,1621146781.0,0,,False,,,,,,,
,deeplearning,"I have been working on coding a CNN in python from scratch using numpy as a semester project and I think I have successfully implemented it up to backpropagation in the MaxPool Layers. However, my model seems to never converge whenever there is a Convolutional Layer(s) added. I am assuming there is a problem with the way I have implemented the backpropagation.

Most examples that I have seen for this implementation either really simplify it by using a one-channel input and a single one-channel filter, or just dive straight into the Mathematics which doesn't only not help but also confuses me more.

Here is the way I have tried to implement both Forward and Backward Propagation for multichannel inputs and outputs based on my own understanding and things I read online.

**Forward Prop:**

[Forward Propagation](https://preview.redd.it/141uuioc0hz61.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=1c791004c18b8569528e81af19d9718a6dbe88ca)

**Backward Prop for Filter Gradients:**

[Backward Prop for Filter Gradients](https://preview.redd.it/feg7r4zh0hz61.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=e33ae9cf25352016883f0c235e27bbe72ce57fc1)

**Backward Prop for Input Gradients:**

[ Backward Prop for Input Gradients](https://preview.redd.it/k9q3vdul0hz61.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=f1f5e9c7688280e5ac3084256aa2d1ba8f991e1e)

Kindly point out anything that's wrong here. I have been working on this part for the last 2 days but there has to be a problem because my model never seems to converge. Thanks!",t2_14w6x8,False,,0,False,Convolutional Layer Multichannel Backpropagation Implementation,[],r/deeplearning,False,6,,0,,False,t3_ndmoau,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1621194611.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been working on coding a CNN in python from scratch using numpy as a semester project and I think I have successfully implemented it up to backpropagation in the MaxPool Layers. However, my model seems to never converge whenever there is a Convolutional Layer(s) added. I am assuming there is a problem with the way I have implemented the backpropagation.&lt;/p&gt;

&lt;p&gt;Most examples that I have seen for this implementation either really simplify it by using a one-channel input and a single one-channel filter, or just dive straight into the Mathematics which doesn&amp;#39;t only not help but also confuses me more.&lt;/p&gt;

&lt;p&gt;Here is the way I have tried to implement both Forward and Backward Propagation for multichannel inputs and outputs based on my own understanding and things I read online.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Forward Prop:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/141uuioc0hz61.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=1c791004c18b8569528e81af19d9718a6dbe88ca""&gt;Forward Propagation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Backward Prop for Filter Gradients:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/feg7r4zh0hz61.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=e33ae9cf25352016883f0c235e27bbe72ce57fc1""&gt;Backward Prop for Filter Gradients&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Backward Prop for Input Gradients:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/k9q3vdul0hz61.jpg?width=1280&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=f1f5e9c7688280e5ac3084256aa2d1ba8f991e1e""&gt; Backward Prop for Input Gradients&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Kindly point out anything that&amp;#39;s wrong here. I have been working on this part for the last 2 days but there has to be a problem because my model never seems to converge. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ndmoau,True,,theahmedmustafa,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ndmoau/convolutional_layer_multichannel_backpropagation/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ndmoau/convolutional_layer_multichannel_backpropagation/,66146,1621165811.0,0,,False,,,"{'141uuioc0hz61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 61, 'x': 108, 'u': 'https://preview.redd.it/141uuioc0hz61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c4e4538ea082ca347893057b4a71889914dca99e'}, {'y': 123, 'x': 216, 'u': 'https://preview.redd.it/141uuioc0hz61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=03884a45e8a43a99757478deaeaaadddb3e457d8'}, {'y': 182, 'x': 320, 'u': 'https://preview.redd.it/141uuioc0hz61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8a9b9f51ea693c6d5db9e014579354c4d735a254'}, {'y': 365, 'x': 640, 'u': 'https://preview.redd.it/141uuioc0hz61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=85584ea5c0779907db80ab0d63e2a09ba2dd2211'}, {'y': 547, 'x': 960, 'u': 'https://preview.redd.it/141uuioc0hz61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3c79cb50cbcd67f4253de16357e59012bfa07941'}, {'y': 615, 'x': 1080, 'u': 'https://preview.redd.it/141uuioc0hz61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fdf6a32a6cca3cb225fd8cb476bc2b3327e443b8'}], 's': {'y': 730, 'x': 1280, 'u': 'https://preview.redd.it/141uuioc0hz61.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=1c791004c18b8569528e81af19d9718a6dbe88ca'}, 'id': '141uuioc0hz61'}, 'k9q3vdul0hz61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 85, 'x': 108, 'u': 'https://preview.redd.it/k9q3vdul0hz61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6acd05063bc3f45df4f533b4fc9e30f0d9bbdb49'}, {'y': 171, 'x': 216, 'u': 'https://preview.redd.it/k9q3vdul0hz61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e25493721bc7d01a063c3c77f3b09af653e2eaad'}, {'y': 254, 'x': 320, 'u': 'https://preview.redd.it/k9q3vdul0hz61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=301421daeccd8f1e8e3ac47839ca4fae38fbacd2'}, {'y': 508, 'x': 640, 'u': 'https://preview.redd.it/k9q3vdul0hz61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=346692efcf22b0ef26ce5c392792c8c39e8223a7'}, {'y': 762, 'x': 960, 'u': 'https://preview.redd.it/k9q3vdul0hz61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=424142936b3ed4939f44667523e0735486009e48'}, {'y': 858, 'x': 1080, 'u': 'https://preview.redd.it/k9q3vdul0hz61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8e405a229083edf9083045eb1a4e1c0016549a7f'}], 's': {'y': 1017, 'x': 1280, 'u': 'https://preview.redd.it/k9q3vdul0hz61.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=f1f5e9c7688280e5ac3084256aa2d1ba8f991e1e'}, 'id': 'k9q3vdul0hz61'}, 'feg7r4zh0hz61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 83, 'x': 108, 'u': 'https://preview.redd.it/feg7r4zh0hz61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cf8725791efc0460fde23e1d336b9d56ad3a31a8'}, {'y': 166, 'x': 216, 'u': 'https://preview.redd.it/feg7r4zh0hz61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c36c965f0545503686f1deeefbd61f26757f08b'}, {'y': 246, 'x': 320, 'u': 'https://preview.redd.it/feg7r4zh0hz61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=70f2f96f5ed42cf61ab051831032e5bb776fe500'}, {'y': 493, 'x': 640, 'u': 'https://preview.redd.it/feg7r4zh0hz61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9cf35e8ea1df0bdfa348525885480f30da2214ee'}, {'y': 740, 'x': 960, 'u': 'https://preview.redd.it/feg7r4zh0hz61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f89b58c6c9ac8536d610ae7a9129a9e6782ada44'}, {'y': 832, 'x': 1080, 'u': 'https://preview.redd.it/feg7r4zh0hz61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=47165aea90c8f247b8a372826bf77d857f80ce55'}], 's': {'y': 987, 'x': 1280, 'u': 'https://preview.redd.it/feg7r4zh0hz61.jpg?width=1280&amp;format=pjpg&amp;auto=webp&amp;s=e33ae9cf25352016883f0c235e27bbe72ce57fc1'}, 'id': 'feg7r4zh0hz61'}}",,,,
,deeplearning,,t2_lfhik,False,,0,False,ACORN: Adaptive Coordinate Networks for Neural Representation | SIGGRAPH 2021,[],r/deeplearning,False,6,,0,,False,t3_ndafwk,False,dark,0.87,,public,11,0,{},,False,[],,False,False,,{},,False,11,,False,False,,False,,[],{},,False,,1621147396.0,text,6,,,text,computationalimaging.org,False,,,,,https://www.computationalimaging.org/publications/acorn/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ndafwk,True,,TriggerWarningHappy,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/ndafwk/acorn_adaptive_coordinate_networks_for_neural/,all_ads,False,https://www.computationalimaging.org/publications/acorn/,66146,1621118596.0,0,,False,,,,,,,
,deeplearning,"Used **Global**, **Absolute Magnitude Weight**, **Unstructured** and **Iterative** pruning using ResNet-50 with *Transfer Learning* on CIFAR-10 dataset. Surprisingly, a **sparsity of 99.078%** has been achieved with an increase of performance! The code can be referred [here](https://github.com/arjun-majumdar/Neural_Network_Pruning/blob/main/ResNet50_Global_Absolute_Magnitude_Pruning.ipynb).

Original and unpruned model's val\_accuracy = 92.58%, original model size = 90 MB, zipped model size = 83.5 MB.

Pruned model's (sparsity = 99.078%) val\_accuracy = 92.94%, original model size = 90 MB, zipped model size = 7.1 MB.

**This results into a compression ratio of 11.76x.**

Thoughts?",t2_2mmql89p,False,,0,False,ResNet-50 PyTorch Pruning,[],r/deeplearning,False,6,,0,,False,t3_nczc24,False,dark,0.9,,public,23,1,{},,False,[],,False,False,,{},,False,23,,False,False,,False,,[],{},,True,,1621115445.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Used &lt;strong&gt;Global&lt;/strong&gt;, &lt;strong&gt;Absolute Magnitude Weight&lt;/strong&gt;, &lt;strong&gt;Unstructured&lt;/strong&gt; and &lt;strong&gt;Iterative&lt;/strong&gt; pruning using ResNet-50 with &lt;em&gt;Transfer Learning&lt;/em&gt; on CIFAR-10 dataset. Surprisingly, a &lt;strong&gt;sparsity of 99.078%&lt;/strong&gt; has been achieved with an increase of performance! The code can be referred &lt;a href=""https://github.com/arjun-majumdar/Neural_Network_Pruning/blob/main/ResNet50_Global_Absolute_Magnitude_Pruning.ipynb""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Original and unpruned model&amp;#39;s val_accuracy = 92.58%, original model size = 90 MB, zipped model size = 83.5 MB.&lt;/p&gt;

&lt;p&gt;Pruned model&amp;#39;s (sparsity = 99.078%) val_accuracy = 92.94%, original model size = 90 MB, zipped model size = 7.1 MB.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This results into a compression ratio of 11.76x.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nczc24,True,,grid_world,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/nczc24/resnet50_pytorch_pruning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nczc24/resnet50_pytorch_pruning/,66146,1621086645.0,0,,False,,,,,,,
,deeplearning,"What are the kind of topic that one should choose that are research based in field of data science , ml/dl
I want this for my portfolio for MS.
Whatever i am thinking of, i can find a full fledged project available already, pls let me know how can i choose something to have a impressive portfolio.",t2_8nkn14wp,False,,0,False,Advice needed!,[],r/deeplearning,False,6,,0,,False,t3_ndirww,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1621154012.0,,[],{},,True,,1621177860.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What are the kind of topic that one should choose that are research based in field of data science , ml/dl
I want this for my portfolio for MS.
Whatever i am thinking of, i can find a full fledged project available already, pls let me know how can i choose something to have a impressive portfolio.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ndirww,True,,rushUpp,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/ndirww/advice_needed/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ndirww/advice_needed/,66146,1621149060.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,"Generate 3D models of humans or animals moving from only a short video as input with LASR, a new model from Google Research and Carnegie Mellon University!",[],r/deeplearning,False,6,,0,,False,t3_ncz9md,False,dark,0.75,,public,6,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/lac7wqjS-8E?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'LASR: Articulated Shape Reconstruction from Videos', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/lac7wqjS-8E?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/lac7wqjS-8E/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/lac7wqjS-8E?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ncz9md', 'height': 200}",,False,6,,False,False,,False,,[],{},,False,,1621115249.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/lac7wqjS-8E,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ncz9md,True,,OnlyProggingForFun,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ncz9md/generate_3d_models_of_humans_or_animals_moving/,all_ads,False,https://youtu.be/lac7wqjS-8E,66146,1621086449.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'LASR: Articulated Shape Reconstruction from Videos', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/lac7wqjS-8E?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/lac7wqjS-8E/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,,,,,,,
,deeplearning,"# [Improving Inversion and Generation Diversity in StyleGAN using a Gaussianized Latent Space](https://t.me/casual_gan/38)

🎯 At a glance:

&gt;In this paper about improving latent space inversion for a pretrained StyleGAN2 generator the authors propose to model the output of the mapping network as a Gaussian, which can be expressed as a mean and a covariance matrix. This prior is used to regularize images that are projected into latent space via optimization, which makes the inverted images lie in well conditioned regions of the generator's latent space, and allows for smoother interpolations and better editing.

[Samples from the model](https://preview.redd.it/s692zea8mbz61.png?width=1219&amp;format=png&amp;auto=webp&amp;s=3e5d735783b7f128a78518c36225daa9594ec2c3)

\[[5 minute summary of main ideas](https://t.me/casual_gan/38)\] \[[arxiv](https://arxiv.org/pdf/2009.06529.pdf)\]

P.S. Thanks for reading!  
If you found this useful check out other popular ML papers explained on [my channel](https://t.me/casual_gan)!

**Links to other recent papers explained:**

* [VQ-VAE2](https://t.me/casual_gan/30)
* [StyleGAN2-ada](https://t.me/casual_gan/28)
* [MLP-Mixer](https://t.me/casual_gan/35)",t2_hhio3,False,,0,False,[D] How to improve image inversion with Gaussianized latent spaces explained,[],r/deeplearning,False,6,,0,,False,t3_nd487p,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621129194.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h1&gt;&lt;a href=""https://t.me/casual_gan/38""&gt;Improving Inversion and Generation Diversity in StyleGAN using a Gaussianized Latent Space&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;🎯 At a glance:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In this paper about improving latent space inversion for a pretrained StyleGAN2 generator the authors propose to model the output of the mapping network as a Gaussian, which can be expressed as a mean and a covariance matrix. This prior is used to regularize images that are projected into latent space via optimization, which makes the inverted images lie in well conditioned regions of the generator&amp;#39;s latent space, and allows for smoother interpolations and better editing.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/s692zea8mbz61.png?width=1219&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3e5d735783b7f128a78518c36225daa9594ec2c3""&gt;Samples from the model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/38""&gt;5 minute summary of main ideas&lt;/a&gt;] [&lt;a href=""https://arxiv.org/pdf/2009.06529.pdf""&gt;arxiv&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;P.S. Thanks for reading!&lt;br/&gt;
If you found this useful check out other popular ML papers explained on &lt;a href=""https://t.me/casual_gan""&gt;my channel&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Links to other recent papers explained:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://t.me/casual_gan/30""&gt;VQ-VAE2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://t.me/casual_gan/28""&gt;StyleGAN2-ada&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://t.me/casual_gan/35""&gt;MLP-Mixer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nd487p,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nd487p/d_how_to_improve_image_inversion_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nd487p/d_how_to_improve_image_inversion_with/,66146,1621100394.0,0,,False,,,"{'s692zea8mbz61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 113, 'x': 108, 'u': 'https://preview.redd.it/s692zea8mbz61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7ce8216d6f2045fe93e0dfe7743b9453356a8957'}, {'y': 226, 'x': 216, 'u': 'https://preview.redd.it/s692zea8mbz61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=af743e00c3f0d3a04cd24da27cbe609f2d964ad1'}, {'y': 336, 'x': 320, 'u': 'https://preview.redd.it/s692zea8mbz61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=99562b60dd457cf13078981bf507bc97d9a235ca'}, {'y': 672, 'x': 640, 'u': 'https://preview.redd.it/s692zea8mbz61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f517a7171baa6e34783340ccbc10ba85867e3855'}, {'y': 1008, 'x': 960, 'u': 'https://preview.redd.it/s692zea8mbz61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fbc08520cd466d32e02bcdf6632b3c404f85fc7c'}, {'y': 1134, 'x': 1080, 'u': 'https://preview.redd.it/s692zea8mbz61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5fd7cebfef8adf37e5b7b9b55fe03fc6fb2a4d5c'}], 's': {'y': 1280, 'x': 1219, 'u': 'https://preview.redd.it/s692zea8mbz61.png?width=1219&amp;format=png&amp;auto=webp&amp;s=3e5d735783b7f128a78518c36225daa9594ec2c3'}, 'id': 's692zea8mbz61'}}",,,,
,deeplearning,"A research team from Google shows that replacing transformers’ self-attention sublayers with Fourier Transform achieves 92 percent of BERT accuracy on the GLUE benchmark with training times seven times faster on GPUs and twice as fast on TPUs.

Here is a quick read: [Google Replaces BERT Self-Attention with Fourier Transform: 92% Accuracy, 7 Times Faster on GPUs.](https://syncedreview.com/2021/05/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-19/)

The paper *FNet: Mixing Tokens with Fourier Transforms* is on [arXiv](https://arxiv.org/abs/2105.03824).",t2_2fv4yodo,False,,0,False,"[R] Google Replaces BERT Self-Attention with Fourier Transform: 92% Accuracy, 7 Times Faster on GPUs",[],r/deeplearning,False,6,,0,,False,t3_ncdyqr,False,dark,0.99,,public,81,0,{},,False,[],,False,False,,{},,False,81,,False,False,,False,,[],{},,True,,1621041801.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Google shows that replacing transformers’ self-attention sublayers with Fourier Transform achieves 92 percent of BERT accuracy on the GLUE benchmark with training times seven times faster on GPUs and twice as fast on TPUs.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-19/""&gt;Google Replaces BERT Self-Attention with Fourier Transform: 92% Accuracy, 7 Times Faster on GPUs.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;FNet: Mixing Tokens with Fourier Transforms&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.03824""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ncdyqr,True,,Yuqing7,,12,True,all_ads,False,[],False,,/r/deeplearning/comments/ncdyqr/r_google_replaces_bert_selfattention_with_fourier/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ncdyqr/r_google_replaces_bert_selfattention_with_fourier/,66146,1621013001.0,0,,False,,,,,,,
,deeplearning,Do we need something extra for being part of ML industry like Data Structure and Algorithms or it is just fine to have knowledge about Statistics and Machine Learning models and Frameworks. What are your thoughts on this ?,t2_85081em6,False,,0,False,Is it enough having knowledge of Statistics and ML/DL models in India ?,[],r/deeplearning,False,6,,0,,False,t3_nd1l82,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1621121879.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Do we need something extra for being part of ML industry like Data Structure and Algorithms or it is just fine to have knowledge about Statistics and Machine Learning models and Frameworks. What are your thoughts on this ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nd1l82,True,,gouravbais08,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nd1l82/is_it_enough_having_knowledge_of_statistics_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nd1l82/is_it_enough_having_knowledge_of_statistics_and/,66146,1621093079.0,0,,False,,,,,,,
,deeplearning,,t2_68wfew41,False,,0,False,Czech Deep learning videos - image processing course,[],r/deeplearning,False,6,,0,,False,t3_ncva59,False,dark,0.6,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/gkYeIpeAbcY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Úvod do detekce objektů v obraze (RCNN, Fast RCNN, Faster RCNN, YOLO)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/gkYeIpeAbcY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'neuronovesite_cz', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/gkYeIpeAbcY/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCJHPgSh6Tm3PHZIAka8R7OQ'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/gkYeIpeAbcY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ncva59', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1621101161.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/gkYeIpeAbcY,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ncva59,True,,neuronovesite_cz,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ncva59/czech_deep_learning_videos_image_processing_course/,all_ads,False,https://youtu.be/gkYeIpeAbcY,66146,1621072361.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Úvod do detekce objektů v obraze (RCNN, Fast RCNN, Faster RCNN, YOLO)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/gkYeIpeAbcY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'neuronovesite_cz', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/gkYeIpeAbcY/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCJHPgSh6Tm3PHZIAka8R7OQ'}}",False,,,,,,,
,deeplearning,,t2_3ehjypm2,False,,0,False,Is AI use on Anime Sketch really that useful? Here a comparison [Anime2Sketch],[],r/deeplearning,False,6,,0,,False,t3_ncsuel,False,dark,0.72,,public,3,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/up0Uby5IaLE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Comparison AI (Anime Sketch) Vs Video Filter Effects on Castlevania S4x09 Death vs Trevor Belmont', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/up0Uby5IaLE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""The Collector's Hubs"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/up0Uby5IaLE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCZ_xZYgAE6lGN4f5-988RRA'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/up0Uby5IaLE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ncsuel', 'height': 200}",,False,3,,False,False,,False,,[],{},,False,,1621091013.0,text,6,,,text,youtube.com,False,,,,,https://youtube.com/watch?v=up0Uby5IaLE&amp;feature=share,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ncsuel,True,,captainchico,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ncsuel/is_ai_use_on_anime_sketch_really_that_useful_here/,all_ads,False,https://youtube.com/watch?v=up0Uby5IaLE&amp;feature=share,66146,1621062213.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Comparison AI (Anime Sketch) Vs Video Filter Effects on Castlevania S4x09 Death vs Trevor Belmont', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/up0Uby5IaLE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""The Collector's Hubs"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/up0Uby5IaLE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCZ_xZYgAE6lGN4f5-988RRA'}}",False,,,,,,,
,deeplearning,"This tutorial breaks down xUnit, a new activation unit that is particularly suitable for image restoration problems. xUnit implements a learnable nonlinear function with spatial connections, enabling the net to capture much more complex features while requiring a significantly smaller number of layers in order to reach the same performance. 

Topics covered include:

1. Motivation behind xUnit
2. xUnit explained
3. PyTorch Code
4. Paper results
5. Conclusion

Article link: [https://blog.paperspace.com/xunit-spatial-activation/](https://blog.paperspace.com/xunit-spatial-activation/)",t2_15en0l,False,,0,False,"[Article] xUnit Activation for Denoising, De-Raining, and Image Super-Resolution",[],r/deeplearning,False,6,,0,,False,t3_ncb37p,False,dark,0.87,,public,10,0,{},,False,[],,False,False,,{},,False,10,,False,False,,False,,[],{},,True,,1621034374.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This tutorial breaks down xUnit, a new activation unit that is particularly suitable for image restoration problems. xUnit implements a learnable nonlinear function with spatial connections, enabling the net to capture much more complex features while requiring a significantly smaller number of layers in order to reach the same performance. &lt;/p&gt;

&lt;p&gt;Topics covered include:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Motivation behind xUnit&lt;/li&gt;
&lt;li&gt;xUnit explained&lt;/li&gt;
&lt;li&gt;PyTorch Code&lt;/li&gt;
&lt;li&gt;Paper results&lt;/li&gt;
&lt;li&gt;Conclusion&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Article link: &lt;a href=""https://blog.paperspace.com/xunit-spatial-activation/""&gt;https://blog.paperspace.com/xunit-spatial-activation/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ncb37p,True,,hellopaperspace,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/ncb37p/article_xunit_activation_for_denoising_deraining/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ncb37p/article_xunit_activation_for_denoising_deraining/,66146,1621005574.0,0,,False,,,,,,,
,deeplearning,,t2_c4ocqisv,False,,0,False,Ludwig Code Free Deep Learning Tool Box,[],r/deeplearning,False,6,,0,,False,t3_ncc0js,False,dark,0.89,,public,7,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6dqG2B0XkFw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'ludwig code free deep learning tool box || part 1', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6dqG2B0XkFw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vinay Nataraja', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6dqG2B0XkFw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCx2Q4gg7NnvgcZTWUV_kGgQ'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6dqG2B0XkFw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ncc0js', 'height': 200}",,False,7,,False,False,,False,,[],{},,False,,1621036764.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/6dqG2B0XkFw,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ncc0js,True,,vinaynataraja,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/ncc0js/ludwig_code_free_deep_learning_tool_box/,all_ads,False,https://youtu.be/6dqG2B0XkFw,66146,1621007964.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'ludwig code free deep learning tool box || part 1', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6dqG2B0XkFw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vinay Nataraja', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6dqG2B0XkFw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCx2Q4gg7NnvgcZTWUV_kGgQ'}}",False,,,,,,,
,deeplearning,"+ There are many ways of improving machine learning model performance.

+ One such is feature selection.

+ Amongst many feature selection techniques, genetic algorithm is one.

+ I have created a python library that helps you perform feature selection for your machine learning models.

+ It helps you identify the best set of features for your model. Feel free to use it.

pip install EvolutionaryFS


Example notebook: https://www.kaggle.com/azimulh/feature-selection-using-evolutionaryfs-library

Pypi page with documentation: https://pypi.org/project/EvolutionaryFS/",t2_1bf418yx,False,,0,False,Genetic algorithm for feature selection,[],r/deeplearning,False,6,,0,,False,t3_ncjaq0,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,1621080805.0,,[],{},,True,,1621055931.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;There are many ways of improving machine learning model performance.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;One such is feature selection.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;+ Amongst many feature selection techniques, genetic algorithm is one.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;I have created a python library that helps you perform feature selection for your machine learning models.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It helps you identify the best set of features for your model. Feel free to use it.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;pip install EvolutionaryFS&lt;/p&gt;

&lt;p&gt;Example notebook: &lt;a href=""https://www.kaggle.com/azimulh/feature-selection-using-evolutionaryfs-library""&gt;https://www.kaggle.com/azimulh/feature-selection-using-evolutionaryfs-library&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Pypi page with documentation: &lt;a href=""https://pypi.org/project/EvolutionaryFS/""&gt;https://pypi.org/project/EvolutionaryFS/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ncjaq0,True,,Enthusiast_new,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ncjaq0/genetic_algorithm_for_feature_selection/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ncjaq0/genetic_algorithm_for_feature_selection/,66146,1621027131.0,0,,False,,,,,,,
,deeplearning,"Hi, looking for your thoughts and feedback. How would you have approached it?

If anyone is looking to play in latent domain, checkout this side project that I hosted on Streamlit. The aim was to transform an input image to something that looks somewhere between 2 digits. The repository below will give you a practical exposure to Auto Encoders, Latent Domain, PyTorch, Hosting on Streamlit.

GitHub Repository - [LINK](https://github.com/vdivakar/mnistMuddle)

Streamlit App Demo - [PAGE](https://share.streamlit.io/vdivakar/mnistmuddle/br_streamlit/app.py)

https://i.redd.it/9r7t48bgi1z61.gif",t2_13eos63x,False,,0,False,Basic Auto Encoder project - Generating poorly written digits [PyTorch],[],r/deeplearning,False,6,,0,,False,t3_nc30u0,False,dark,0.91,,public,16,0,{},,False,[],,False,False,,{},,False,16,,False,False,,1621011727.0,,[],{},,True,,1621006976.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, looking for your thoughts and feedback. How would you have approached it?&lt;/p&gt;

&lt;p&gt;If anyone is looking to play in latent domain, checkout this side project that I hosted on Streamlit. The aim was to transform an input image to something that looks somewhere between 2 digits. The repository below will give you a practical exposure to Auto Encoders, Latent Domain, PyTorch, Hosting on Streamlit.&lt;/p&gt;

&lt;p&gt;GitHub Repository - &lt;a href=""https://github.com/vdivakar/mnistMuddle""&gt;LINK&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Streamlit App Demo - &lt;a href=""https://share.streamlit.io/vdivakar/mnistmuddle/br_streamlit/app.py""&gt;PAGE&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://i.redd.it/9r7t48bgi1z61.gif""&gt;https://i.redd.it/9r7t48bgi1z61.gif&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nc30u0,True,,_dv96_,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nc30u0/basic_auto_encoder_project_generating_poorly/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nc30u0/basic_auto_encoder_project_generating_poorly/,66146,1620978176.0,0,,False,,,"{'9r7t48bgi1z61': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 96, 'x': 108, 'u': 'https://preview.redd.it/9r7t48bgi1z61.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=1a526b8c281d40d7f71a661f8a2a09607b0af802'}, {'y': 192, 'x': 216, 'u': 'https://preview.redd.it/9r7t48bgi1z61.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=d66ab1aff80d7d2edaec7b9dde63febff76f36dd'}, {'y': 285, 'x': 320, 'u': 'https://preview.redd.it/9r7t48bgi1z61.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=484cae71bb15f47749eff22dcec0e302f5d7b742'}], 's': {'y': 481, 'gif': 'https://i.redd.it/9r7t48bgi1z61.gif', 'mp4': 'https://preview.redd.it/9r7t48bgi1z61.gif?format=mp4&amp;s=0682bc117ec4b3c43f3afda286addf889c66022e', 'x': 540}, 'id': '9r7t48bgi1z61'}}",,,,
,deeplearning,"So the conv layers in Neural Networks combined with pooling operations cause the hierarchical representations to be translation invariant, i.e. it should not matter for e.g. a digit if it appears in the upper left or lower right corner of an image. 

&amp;#x200B;

However, if the location of the objects/information within a signal/image carries information as well, the translation invariance seems disadvantageous. What are the possibilities to build translational variance into the network if any?",t2_82nufyen,False,,0,False,Undesired translation invariance,[],r/deeplearning,False,6,,0,,False,t3_nc380d,False,dark,1.0,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1621007888.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So the conv layers in Neural Networks combined with pooling operations cause the hierarchical representations to be translation invariant, i.e. it should not matter for e.g. a digit if it appears in the upper left or lower right corner of an image. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;However, if the location of the objects/information within a signal/image carries information as well, the translation invariance seems disadvantageous. What are the possibilities to build translational variance into the network if any?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nc380d,True,,jsmsj,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nc380d/undesired_translation_invariance/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nc380d/undesired_translation_invariance/,66146,1620979088.0,0,,False,,,,,,,
,deeplearning,"A research team from DeepMind explores how neural networks can be fused with algorithmic computation and demonstrates an elegant neural end-to-end pipeline that goes straight from raw inputs to general outputs while emulating an algorithm internally.

Here is a quick read: [DeepMind Presents Neural Algorithmic Reasoning: The Art of Fusing Neural Networks With Algorithmic Computation.](https://syncedreview.com/2021/05/13/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-18/)

 The paper *Neural Algorithmic Reasoning* is on [arXiv](https://arxiv.org/pdf/2105.02761.pdf).",t2_2fv4yodo,False,,0,False,[R] DeepMind Presents Neural Algorithmic Reasoning: The Art of Fusing Neural Networks With Algorithmic Computation,[],r/deeplearning,False,6,,0,,False,t3_nbjtgv,False,dark,0.95,,public,52,0,{},,False,[],,False,False,,{},,False,52,,False,False,,False,,[],{},,True,,1620949931.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from DeepMind explores how neural networks can be fused with algorithmic computation and demonstrates an elegant neural end-to-end pipeline that goes straight from raw inputs to general outputs while emulating an algorithm internally.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/13/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-18/""&gt;DeepMind Presents Neural Algorithmic Reasoning: The Art of Fusing Neural Networks With Algorithmic Computation.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Neural Algorithmic Reasoning&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2105.02761.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nbjtgv,True,,Yuqing7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nbjtgv/r_deepmind_presents_neural_algorithmic_reasoning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nbjtgv/r_deepmind_presents_neural_algorithmic_reasoning/,66146,1620921131.0,0,,False,,,,,,,
,deeplearning,,t2_u58vv,False,,0,False,This AI Transfers Anime Back Into Sketch [Anime2Sketch],[],r/deeplearning,False,6,,0,,False,t3_nbl6h0,False,dark,0.81,,public,13,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/txYpuniEI0M?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'This AI Transfers Anime Back Into Sketch [Anime2Sketch]', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/txYpuniEI0M?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'bycloud', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/txYpuniEI0M/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/bycloudAI'}, 'type': 'youtube.com'}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/txYpuniEI0M?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nbl6h0', 'height': 200}",,False,13,,False,False,,False,,[],{},,False,,1620953367.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/txYpuniEI0M,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nbl6h0,True,,cloud_weather,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nbl6h0/this_ai_transfers_anime_back_into_sketch/,all_ads,False,https://youtu.be/txYpuniEI0M,66146,1620924567.0,0,"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'This AI Transfers Anime Back Into Sketch [Anime2Sketch]', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/txYpuniEI0M?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'bycloud', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/txYpuniEI0M/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/bycloudAI'}, 'type': 'youtube.com'}",False,,,,,,,
,deeplearning,"&amp;#x200B;

[PyGAD &amp; Keras](https://preview.redd.it/l20gbrs2r0z61.png?width=1789&amp;format=png&amp;auto=webp&amp;s=c5b111397c007b3c2447a1830a8f3201c8b44c98)

[https://towardsdatascience.com/how-to-train-keras-models-using-the-genetic-algorithm-with-pygad-9d9d626782d1](https://towardsdatascience.com/how-to-train-keras-models-using-the-genetic-algorithm-with-pygad-9d9d626782d1)",t2_a8i2hluj,False,,0,False,How To Train Keras Models Using the Genetic Algorithm with PyGAD,[],r/deeplearning,False,6,,0,,False,t3_nc0vm9,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620997652.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/l20gbrs2r0z61.png?width=1789&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c5b111397c007b3c2447a1830a8f3201c8b44c98""&gt;PyGAD &amp;amp; Keras&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://towardsdatascience.com/how-to-train-keras-models-using-the-genetic-algorithm-with-pygad-9d9d626782d1""&gt;https://towardsdatascience.com/how-to-train-keras-models-using-the-genetic-algorithm-with-pygad-9d9d626782d1&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nc0vm9,True,,ahmed26gad,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nc0vm9/how_to_train_keras_models_using_the_genetic/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nc0vm9/how_to_train_keras_models_using_the_genetic/,66146,1620968852.0,0,,False,,,"{'l20gbrs2r0z61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 40, 'x': 108, 'u': 'https://preview.redd.it/l20gbrs2r0z61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1fd83626f6e0571a567e7005f0b0aab6152165e9'}, {'y': 80, 'x': 216, 'u': 'https://preview.redd.it/l20gbrs2r0z61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=30cc838cd91852196c04a2793cda6ce9476b0c0b'}, {'y': 119, 'x': 320, 'u': 'https://preview.redd.it/l20gbrs2r0z61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0edefd07726a824a414c0bf774c10661296355d7'}, {'y': 238, 'x': 640, 'u': 'https://preview.redd.it/l20gbrs2r0z61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=83b69b7a7a928c1f3fe0f76280ee848e8148e8db'}, {'y': 357, 'x': 960, 'u': 'https://preview.redd.it/l20gbrs2r0z61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3312a646da205f165bdc35386a80ea1e4f7de0c5'}, {'y': 402, 'x': 1080, 'u': 'https://preview.redd.it/l20gbrs2r0z61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3bebbaf4b1430fb75eb3da2484cbcf74cdf44198'}], 's': {'y': 667, 'x': 1789, 'u': 'https://preview.redd.it/l20gbrs2r0z61.png?width=1789&amp;format=png&amp;auto=webp&amp;s=c5b111397c007b3c2447a1830a8f3201c8b44c98'}, 'id': 'l20gbrs2r0z61'}}",,,,
,deeplearning,"A quick announcement before we jump to our post today.  


We will launch a Kickstarter campaign for OpenCV for Beginners on May 18, 2021. It is a short, fun, and extremely affordable course.  
Please create a Kickstarter account and click on the ""Notify me on Launch"" button on the pre-launch page so you don't miss the special price on Day 1. 1130 people are already following our project on Kickstarter - don't wait until the last moment!  


[https://www.kickstarter.com/projects/opencv/opencv-for-beginners](https://www.kickstarter.com/projects/opencv/opencv-for-beginners)  


Today's post is about Generative and Discriminative Models  
In machine learning and deep learning, we often create these two different kinds of models for solving problems.  


Discriminative Models: These kinds of models focus on differences between classes to solve a problem. For example, a classifier built to classify dogs and cats is a discriminative model that learns the differences between a dog and a cat.  


Generative Models: A generative model tries to learn the appearance of the classes. For example, a generative model may be used to create a realistic picture of a dog.  


You will also get a foundational understanding of generative models.  


[https://learnopencv.com/generative-and-discriminative-models/](https://learnopencv.com/generative-and-discriminative-models/)

https://preview.redd.it/1c4s4lssp0z61.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=9fe765ec7393de659b54095d9a99c087415c6827",t2_cvc9f,False,,0,False,Generative and Discriminative Models,[],r/deeplearning,False,6,,0,,False,t3_nc0ssd,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620997324.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A quick announcement before we jump to our post today.  &lt;/p&gt;

&lt;p&gt;We will launch a Kickstarter campaign for OpenCV for Beginners on May 18, 2021. It is a short, fun, and extremely affordable course.&lt;br/&gt;
Please create a Kickstarter account and click on the &amp;quot;Notify me on Launch&amp;quot; button on the pre-launch page so you don&amp;#39;t miss the special price on Day 1. 1130 people are already following our project on Kickstarter - don&amp;#39;t wait until the last moment!  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.kickstarter.com/projects/opencv/opencv-for-beginners""&gt;https://www.kickstarter.com/projects/opencv/opencv-for-beginners&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;Today&amp;#39;s post is about Generative and Discriminative Models&lt;br/&gt;
In machine learning and deep learning, we often create these two different kinds of models for solving problems.  &lt;/p&gt;

&lt;p&gt;Discriminative Models: These kinds of models focus on differences between classes to solve a problem. For example, a classifier built to classify dogs and cats is a discriminative model that learns the differences between a dog and a cat.  &lt;/p&gt;

&lt;p&gt;Generative Models: A generative model tries to learn the appearance of the classes. For example, a generative model may be used to create a realistic picture of a dog.  &lt;/p&gt;

&lt;p&gt;You will also get a foundational understanding of generative models.  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://learnopencv.com/generative-and-discriminative-models/""&gt;https://learnopencv.com/generative-and-discriminative-models/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/1c4s4lssp0z61.jpg?width=600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=9fe765ec7393de659b54095d9a99c087415c6827""&gt;https://preview.redd.it/1c4s4lssp0z61.jpg?width=600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=9fe765ec7393de659b54095d9a99c087415c6827&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nc0ssd,True,,spmallick,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nc0ssd/generative_and_discriminative_models/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nc0ssd/generative_and_discriminative_models/,66146,1620968524.0,0,,False,,,"{'1c4s4lssp0z61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/1c4s4lssp0z61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=38251bdc278ec89191e2c6e864910fedae587dda'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/1c4s4lssp0z61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba2d2b55b511f9ef98288641ad9413c7ebd2e536'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/1c4s4lssp0z61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=505ef388d4edbcc0eced87f4bf424b8615f63965'}], 's': {'y': 338, 'x': 600, 'u': 'https://preview.redd.it/1c4s4lssp0z61.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=9fe765ec7393de659b54095d9a99c087415c6827'}, 'id': '1c4s4lssp0z61'}}",,,,
,deeplearning,,t2_8zly4shq,False,,0,False,[Research] [R] Extreme Face Inpainting with Sketch-Guided Conditional GAN,[],r/deeplearning,False,6,,0,,False,t3_nbzino,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1620992564.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/nbxj75/research_r_extreme_face_inpainting_with/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nbzino,True,,Green_General_9111,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nbzino/research_r_extreme_face_inpainting_with/,all_ads,False,/r/MachineLearning/comments/nbxj75/research_r_extreme_face_inpainting_with/,66146,1620963764.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Link: [https://arxiv.org/abs/2105.06033](https://arxiv.org/abs/2105.06033)\n\nRecovering badly damaged face images is a useful yet challenging task, especially in extreme cases where the masked or damaged region is very large. One of the major challenges is the ability of the system to generalize on faces outside the training dataset. We propose to tackle this extreme inpainting task with a conditional Generative Adversarial Network (GAN) that utilizes structural information, such as edges, as a prior condition. Edge information can be obtained from the partially masked image and a structurally similar image or a hand drawing. In our proposed conditional GAN, we pass the conditional input in every layer of the encoder while maintaining consistency in the distributions between the learned weights and the incoming conditional input. We demonstrate the effectiveness of our method with badly damaged face examples.\n\n&amp;#x200B;\n\n[Using edges as sketch condition](https://preview.redd.it/tqhnts8nszy61.png?width=1115&amp;format=png&amp;auto=webp&amp;s=be9708fdc17d18fbc3b735c46eb7df884932b130)\n\n[Using the hand-drawn sketch as a condition.](https://preview.redd.it/tjgz3w8nszy61.png?width=1680&amp;format=png&amp;auto=webp&amp;s=522baee91e1d45e745264407d529922e162663c6)\n\n&amp;#x200B;\n\nWe were supposed to publish this paper in 2019, but due to unforeseen issues, we had to delay to EI2021.', 'author_fullname': 't2_8zly4shq', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[Research] [R] Extreme Face Inpainting with Sketch-Guided Conditional GAN', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'tqhnts8nszy61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 129, 'x': 108, 'u': 'https://preview.redd.it/tqhnts8nszy61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=89636dcd7752fd56d9f70af62c9a3fcb43c96e6a'}, {'y': 259, 'x': 216, 'u': 'https://preview.redd.it/tqhnts8nszy61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c027876dc867b11c0f6bd0aac80f66dd22dce0f0'}, {'y': 384, 'x': 320, 'u': 'https://preview.redd.it/tqhnts8nszy61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=44dbea381f776a77588ddebd992d1f3baa576bb4'}, {'y': 769, 'x': 640, 'u': 'https://preview.redd.it/tqhnts8nszy61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=70ebb2d79f6d16ab667f456641d822d3c6048387'}, {'y': 1153, 'x': 960, 'u': 'https://preview.redd.it/tqhnts8nszy61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=953c549fb3f2c2b4a2582fe758fcf47da92d990b'}, {'y': 1297, 'x': 1080, 'u': 'https://preview.redd.it/tqhnts8nszy61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=eafa9382ea9a268bdb4b192570f4d9a47a078acf'}], 's': {'y': 1340, 'x': 1115, 'u': 'https://preview.redd.it/tqhnts8nszy61.png?width=1115&amp;format=png&amp;auto=webp&amp;s=be9708fdc17d18fbc3b735c46eb7df884932b130'}, 'id': 'tqhnts8nszy61'}, 'tjgz3w8nszy61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 72, 'x': 108, 'u': 'https://preview.redd.it/tjgz3w8nszy61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=54fc57b29954e501df0b748677a09af514d3e957'}, {'y': 144, 'x': 216, 'u': 'https://preview.redd.it/tjgz3w8nszy61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2ffbd43cdace7c85c63cdb53fc86cc736eb12c3'}, {'y': 213, 'x': 320, 'u': 'https://preview.redd.it/tjgz3w8nszy61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9be45e08be46d951858e5ed736d17ad5c9747c09'}, {'y': 426, 'x': 640, 'u': 'https://preview.redd.it/tjgz3w8nszy61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=07898dc1c28fbd6948330b7e7206c9b64d2a11f0'}, {'y': 640, 'x': 960, 'u': 'https://preview.redd.it/tjgz3w8nszy61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=84da1d2e3578393bf355c3b1701d5b5cb1e6c903'}, {'y': 720, 'x': 1080, 'u': 'https://preview.redd.it/tjgz3w8nszy61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0ce1ee77b8a48e1e5ff57fa1d229d9175c6523d1'}], 's': {'y': 1120, 'x': 1680, 'u': 'https://preview.redd.it/tjgz3w8nszy61.png?width=1680&amp;format=png&amp;auto=webp&amp;s=522baee91e1d45e745264407d529922e162663c6'}, 'id': 'tjgz3w8nszy61'}}, 'name': 't3_nbxj75', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.57, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': 1620957489.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1620986031.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Link: &lt;a href=""https://arxiv.org/abs/2105.06033""&gt;https://arxiv.org/abs/2105.06033&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Recovering badly damaged face images is a useful yet challenging task, especially in extreme cases where the masked or damaged region is very large. One of the major challenges is the ability of the system to generalize on faces outside the training dataset. We propose to tackle this extreme inpainting task with a conditional Generative Adversarial Network (GAN) that utilizes structural information, such as edges, as a prior condition. Edge information can be obtained from the partially masked image and a structurally similar image or a hand drawing. In our proposed conditional GAN, we pass the conditional input in every layer of the encoder while maintaining consistency in the distributions between the learned weights and the incoming conditional input. We demonstrate the effectiveness of our method with badly damaged face examples.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/tqhnts8nszy61.png?width=1115&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=be9708fdc17d18fbc3b735c46eb7df884932b130""&gt;Using edges as sketch condition&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/tjgz3w8nszy61.png?width=1680&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=522baee91e1d45e745264407d529922e162663c6""&gt;Using the hand-drawn sketch as a condition.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;We were supposed to publish this paper in 2019, but due to unforeseen issues, we had to delay to EI2021.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nbxj75', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Green_General_9111', 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/nbxj75/research_r_extreme_face_inpainting_with/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/nbxj75/research_r_extreme_face_inpainting_with/', 'subreddit_subscribers': 1931382, 'created_utc': 1620957231.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_nbxj75,,,,,
,deeplearning,"I considered posting this to r/PhD, but ultimately decided that here was more relevant.

In short, I am a 2nd year PhD student looking to get a good industry job once I graduate. My lab is in the biomed engineering department and focuses on deep learning applied to medical imaging, but I am part of the electrical engineering dept. All of my experience in DL has come from my graduate courses in the past 2 years, which have all been math-heavy, and in that time, I've thought that I might be more interested in more general deep learning/computer vision research or deep learning for something like robotics, but I don't know if deviating from my lab would be wise.

My advisor's awesome and well established in his field, and I don't see myself switching labs (funding is also not an issue). He's pretty hands-off and gives me latitude to pursue my interests, but if I research something outside the lab's scope, then I'm not really leveraging any of the resources, network, or past knowledge that's here, which somewhat eliminates the purpose of being in a lab. Additionally, I'd be competing against researchers in their fields, who do have all of these resources. Also, while I think that I may be more interested general DL/CV or applied robotics, this could honestly be 'grass is greener' syndrome, where I automatically see fields that I know less about as comparatively more interesting and lucrative.

Overall, my options are to stick with my lab's direction, completely deviate and do my own thing, or somehow try and find something in between. My current goal is to get a lucrative and interesting job doing research in industry, but I don't have a good sense of how the PhD market for theoretical/applied DL fields really works/is. Is it common, or even possible for PhD students to study one application, but then ultimately land jobs in different applications that have some common principles?",t2_c4055v6r,False,,0,False,How can I decide the direction of my DL studies?,[],r/deeplearning,False,6,,0,,False,t3_nbk227,False,dark,0.87,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1620950532.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I considered posting this to &lt;a href=""/r/PhD""&gt;r/PhD&lt;/a&gt;, but ultimately decided that here was more relevant.&lt;/p&gt;

&lt;p&gt;In short, I am a 2nd year PhD student looking to get a good industry job once I graduate. My lab is in the biomed engineering department and focuses on deep learning applied to medical imaging, but I am part of the electrical engineering dept. All of my experience in DL has come from my graduate courses in the past 2 years, which have all been math-heavy, and in that time, I&amp;#39;ve thought that I might be more interested in more general deep learning/computer vision research or deep learning for something like robotics, but I don&amp;#39;t know if deviating from my lab would be wise.&lt;/p&gt;

&lt;p&gt;My advisor&amp;#39;s awesome and well established in his field, and I don&amp;#39;t see myself switching labs (funding is also not an issue). He&amp;#39;s pretty hands-off and gives me latitude to pursue my interests, but if I research something outside the lab&amp;#39;s scope, then I&amp;#39;m not really leveraging any of the resources, network, or past knowledge that&amp;#39;s here, which somewhat eliminates the purpose of being in a lab. Additionally, I&amp;#39;d be competing against researchers in their fields, who do have all of these resources. Also, while I think that I may be more interested general DL/CV or applied robotics, this could honestly be &amp;#39;grass is greener&amp;#39; syndrome, where I automatically see fields that I know less about as comparatively more interesting and lucrative.&lt;/p&gt;

&lt;p&gt;Overall, my options are to stick with my lab&amp;#39;s direction, completely deviate and do my own thing, or somehow try and find something in between. My current goal is to get a lucrative and interesting job doing research in industry, but I don&amp;#39;t have a good sense of how the PhD market for theoretical/applied DL fields really works/is. Is it common, or even possible for PhD students to study one application, but then ultimately land jobs in different applications that have some common principles?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nbk227,True,,rand_student,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nbk227/how_can_i_decide_the_direction_of_my_dl_studies/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nbk227/how_can_i_decide_the_direction_of_my_dl_studies/,66146,1620921732.0,0,,False,,,,,,,
,deeplearning,"I have come across a plethora of tools to be able to do this, with tensorboard being the most common by quite a distance. I generally do not have a problem with tensorboard per se but could not help but be curious about if the alternatives are really that much better? A lot of the alternatives like W&amp;B or [Neptune.ai](https://Neptune.ai) , even charge for premium services to businesses. 

Given that there seem to be so many options now, what would people say is the best free option and which is the best paid one? and is there really such a big difference between them?",t2_22cdz9au,False,,0,False,"Recommended dashboard tool (live loss tracking, experiment tracking, etc.) for deep learning?",[],r/deeplearning,False,6,,0,,False,t3_nbd76h,False,dark,0.94,,public,15,0,{},,False,[],,False,False,,{},,False,15,,False,False,,False,,[],{},,True,,1620929235.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have come across a plethora of tools to be able to do this, with tensorboard being the most common by quite a distance. I generally do not have a problem with tensorboard per se but could not help but be curious about if the alternatives are really that much better? A lot of the alternatives like W&amp;amp;B or &lt;a href=""https://Neptune.ai""&gt;Neptune.ai&lt;/a&gt; , even charge for premium services to businesses. &lt;/p&gt;

&lt;p&gt;Given that there seem to be so many options now, what would people say is the best free option and which is the best paid one? and is there really such a big difference between them?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nbd76h,True,,therealjesusofficial,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/nbd76h/recommended_dashboard_tool_live_loss_tracking/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nbd76h/recommended_dashboard_tool_live_loss_tracking/,66146,1620900435.0,0,,False,,,,,,,
,deeplearning,"Hey i'm looking to build a deep learning pc. It seems im best off getting a RTX 3090. I'm not too clued up on parts for deep learning so could people recommend me what to have for the rest of the build? Should i get a full tower or a mid tower? What CPU and how much ram? 

Thanks",t2_64z4wyoo,False,,0,False,3090 PC build help,[],r/deeplearning,False,6,,0,,False,t3_nbpo2i,False,dark,0.43,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620964262.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey i&amp;#39;m looking to build a deep learning pc. It seems im best off getting a RTX 3090. I&amp;#39;m not too clued up on parts for deep learning so could people recommend me what to have for the rest of the build? Should i get a full tower or a mid tower? What CPU and how much ram? &lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nbpo2i,True,,SensiTemple,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/nbpo2i/3090_pc_build_help/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nbpo2i/3090_pc_build_help/,66146,1620935462.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,AI turns GTA 5 into the real world,[],r/deeplearning,False,6,,0,,False,t3_nax6od,False,dark,0.67,,public,28,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/DfYb4AvT5Qo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI turns GTA 5 into the real world', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/DfYb4AvT5Qo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/DfYb4AvT5Qo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/DfYb4AvT5Qo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nax6od', 'height': 200}",,False,28,,False,False,,False,,[],{},,False,,1620876606.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/DfYb4AvT5Qo,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nax6od,True,,cmillionaire9,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/nax6od/ai_turns_gta_5_into_the_real_world/,all_ads,False,https://youtu.be/DfYb4AvT5Qo,66146,1620847806.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI turns GTA 5 into the real world', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/DfYb4AvT5Qo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/DfYb4AvT5Qo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,"Hi everyone! I recently read this [wonderful piece](https://distill.pub/2017/momentum/) about the optimization of neural networks. And then I start to research on latest optimization algoritms such as Adagrad and Adam, but I realized that I can only scratch the surface. The original papers was really intense, and the blog posts that I saw was too simple.

So my question is where should I learn these topics in advance? What is the starting point? I think Classical convex optimization books is little bit different, am I right? Any book or blog post or course suggestion will be appreciated.

Ps: I have some background on basics (linear algebra, probability, neural networks in general)",t2_gl6rlz5,False,,0,False,Understanding Optimization Algorithms of Neural Networks,[],r/deeplearning,False,6,,0,,False,t3_nanbdg,False,dark,0.97,,public,30,0,{},,False,[],,False,False,,{},,False,30,,False,False,,False,,[],{},,True,,1620850797.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone! I recently read this &lt;a href=""https://distill.pub/2017/momentum/""&gt;wonderful piece&lt;/a&gt; about the optimization of neural networks. And then I start to research on latest optimization algoritms such as Adagrad and Adam, but I realized that I can only scratch the surface. The original papers was really intense, and the blog posts that I saw was too simple.&lt;/p&gt;

&lt;p&gt;So my question is where should I learn these topics in advance? What is the starting point? I think Classical convex optimization books is little bit different, am I right? Any book or blog post or course suggestion will be appreciated.&lt;/p&gt;

&lt;p&gt;Ps: I have some background on basics (linear algebra, probability, neural networks in general)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nanbdg,True,,tandir_boy,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nanbdg/understanding_optimization_algorithms_of_neural/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nanbdg/understanding_optimization_algorithms_of_neural/,66146,1620821997.0,0,,False,,,,,,,
,deeplearning,"This tutorial video covers how to get set up and running with Mask R-CNN for object detection with Keras in minutes.  

Full tutorial: [https://youtu.be/c1xCaw1tcQQ](https://youtu.be/c1xCaw1tcQQ)

Run the full code on a free GPU: [https://ml-showcase.paperspace.com/projects/object-detection-with-mask-r-cnn](https://ml-showcase.paperspace.com/projects/object-detection-with-mask-r-cnn)

Comments and discussion welcome!",t2_15en0l,False,,0,False,[Video Tutorial] Run Mask R-CNN for Object Detection,[],r/deeplearning,False,6,,0,,False,t3_nar4ue,False,dark,0.84,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1620861390.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This tutorial video covers how to get set up and running with Mask R-CNN for object detection with Keras in minutes.  &lt;/p&gt;

&lt;p&gt;Full tutorial: &lt;a href=""https://youtu.be/c1xCaw1tcQQ""&gt;https://youtu.be/c1xCaw1tcQQ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Run the full code on a free GPU: &lt;a href=""https://ml-showcase.paperspace.com/projects/object-detection-with-mask-r-cnn""&gt;https://ml-showcase.paperspace.com/projects/object-detection-with-mask-r-cnn&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Comments and discussion welcome!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nar4ue,True,,hellopaperspace,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/nar4ue/video_tutorial_run_mask_rcnn_for_object_detection/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nar4ue/video_tutorial_run_mask_rcnn_for_object_detection/,66146,1620832590.0,0,,False,,,,,,,
,deeplearning,"Hey! Sorry if this is the wrong subreddit for this. This might sound weird but I really want to mimic the voice of a radio host for a voice over of a custom music mix. Of the programs I’ve seen, the only work with your own voice, and I’m not sure if there are any relatively easy ways for me to do this. If this technology exists yet, is there any way that I can learn to do it?",t2_59g2ssvs,False,,0,False,Is there a usable AI that can recreate someone’s voice from just audio file samples of them?,[],r/deeplearning,False,6,,0,,False,t3_nav2ow,False,dark,0.67,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1620871230.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey! Sorry if this is the wrong subreddit for this. This might sound weird but I really want to mimic the voice of a radio host for a voice over of a custom music mix. Of the programs I’ve seen, the only work with your own voice, and I’m not sure if there are any relatively easy ways for me to do this. If this technology exists yet, is there any way that I can learn to do it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nav2ow,True,,a_hungo,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nav2ow/is_there_a_usable_ai_that_can_recreate_someones/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nav2ow/is_there_a_usable_ai_that_can_recreate_someones/,66146,1620842430.0,0,,False,,,,,,,
,deeplearning,"# [Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing](https://t.me/casual_gan/36)

One more paper about inverting images into latent spaces of generators. This time with the twist that it uses explicit spatial styles (style tensors instead of style vectors) in the generator, and the encoder, hence making it possible to perform local edits, and smoothly swap parts of images. Overall the authors show that their approach outperforms other baseline in the aforementioned tasks as well as image interpolation. Read [more details](https://t.me/casual_gan/36).

[Samples and model architecture](https://preview.redd.it/8tlmgnfynpy61.png?width=983&amp;format=png&amp;auto=webp&amp;s=c49a27c0b2b41a9ce8125c0ee60606d109a8b92a)

\[[paper explained in 10 minutes](https://t.me/casual_gan/36)\] \[[Arxiv](https://arxiv.org/pdf/2104.14754.pdf)\]",t2_hhio3,False,,0,False,[D] Using spatial styles for image editing with a StyleMapGAN explained!,[],r/deeplearning,False,6,,0,,False,t3_nary4e,False,dark,1.0,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1620863450.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h1&gt;&lt;a href=""https://t.me/casual_gan/36""&gt;Exploiting Spatial Dimensions of Latent in GAN for Real-time Image Editing&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;One more paper about inverting images into latent spaces of generators. This time with the twist that it uses explicit spatial styles (style tensors instead of style vectors) in the generator, and the encoder, hence making it possible to perform local edits, and smoothly swap parts of images. Overall the authors show that their approach outperforms other baseline in the aforementioned tasks as well as image interpolation. Read &lt;a href=""https://t.me/casual_gan/36""&gt;more details&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/8tlmgnfynpy61.png?width=983&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c49a27c0b2b41a9ce8125c0ee60606d109a8b92a""&gt;Samples and model architecture&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/36""&gt;paper explained in 10 minutes&lt;/a&gt;] [&lt;a href=""https://arxiv.org/pdf/2104.14754.pdf""&gt;Arxiv&lt;/a&gt;]&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nary4e,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nary4e/d_using_spatial_styles_for_image_editing_with_a/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nary4e/d_using_spatial_styles_for_image_editing_with_a/,66146,1620834650.0,0,,False,,,"{'8tlmgnfynpy61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 140, 'x': 108, 'u': 'https://preview.redd.it/8tlmgnfynpy61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=375fdd6e6863be833bd8b5ac8ef05436ba5747d7'}, {'y': 281, 'x': 216, 'u': 'https://preview.redd.it/8tlmgnfynpy61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=487aa61b7acca5004a056718a7036991c943c999'}, {'y': 416, 'x': 320, 'u': 'https://preview.redd.it/8tlmgnfynpy61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1c1b5817f51dcd93cb4b5e6cd9ea6cccad966cc4'}, {'y': 833, 'x': 640, 'u': 'https://preview.redd.it/8tlmgnfynpy61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=525618dab46f31d2395ea615eb2168a56e3c20e8'}, {'y': 1250, 'x': 960, 'u': 'https://preview.redd.it/8tlmgnfynpy61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=535b4ab6756bdef12a394f7bff25b732426d8c97'}], 's': {'y': 1280, 'x': 983, 'u': 'https://preview.redd.it/8tlmgnfynpy61.png?width=983&amp;format=png&amp;auto=webp&amp;s=c49a27c0b2b41a9ce8125c0ee60606d109a8b92a'}, 'id': '8tlmgnfynpy61'}}",,,,
,deeplearning,"Hi all, I'm trying to train a forecasting model using deep learning with 1D-CNN. Currently, I train a single model per company. What I want to do is train a single model by combining the time-series values from all companies together.

&amp;#x200B;

But this poses a problem because the values are vastly different from each other (some stocks trade a 10 units/share while others in 10,000 units/share). I will normalize the data ofc but wouldn't there be this jump in values every n-rows when the company changes? Should I use the company as a feature then? or should I treat close prices from all the companies as just one single company's close prices?   


Does anybody know a good way to do this?",t2_62qklhft,False,,0,False,"Joint forecasting of multiple entities (companies, stocks etc)",[],r/deeplearning,False,6,,0,,False,t3_naw8p5,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,1620845813.0,,[],{},,True,,1620874174.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I&amp;#39;m trying to train a forecasting model using deep learning with 1D-CNN. Currently, I train a single model per company. What I want to do is train a single model by combining the time-series values from all companies together.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;But this poses a problem because the values are vastly different from each other (some stocks trade a 10 units/share while others in 10,000 units/share). I will normalize the data ofc but wouldn&amp;#39;t there be this jump in values every n-rows when the company changes? Should I use the company as a feature then? or should I treat close prices from all the companies as just one single company&amp;#39;s close prices?   &lt;/p&gt;

&lt;p&gt;Does anybody know a good way to do this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,naw8p5,True,,silent_lantern,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/naw8p5/joint_forecasting_of_multiple_entities_companies/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/naw8p5/joint_forecasting_of_multiple_entities_companies/,66146,1620845374.0,0,,False,,,,,,,
,deeplearning,I badly need  research partners. If anyone interested lemme knw!,t2_9616hzj7,False,,0,False,"Hey all fellows! Lets create a chat group where we will share idea, help one another nd doing projects together.",[],r/deeplearning,False,6,,0,,False,t3_naiueg,False,dark,0.66,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,True,,1620832736.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I badly need  research partners. If anyone interested lemme knw!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,naiueg,True,,Sami10644,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/naiueg/hey_all_fellows_lets_create_a_chat_group_where_we/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/naiueg/hey_all_fellows_lets_create_a_chat_group_where_we/,66146,1620803936.0,0,,False,,,,,,,
,deeplearning,"A research team from DeepMind and Onshape combines a general-purpose language modelling technique and an off-the-shelf data serialization protocol to propose a machine learning model that can automatically generate high-quality sketches for Computer-Aided Design.

Here is a quick read: DeepMind &amp; Onshape Leverage Transformers to Advance Automatic Computer-Aided Design.

The paper *Computer-Aided Design as Language* is on [arXiv](https://arxiv.org/pdf/2105.02769.pdf).",t2_2fv4yodo,False,,0,False,[R] DeepMind &amp; Onshape Leverage Transformers to Advance Automatic Computer-Aided Design,[],r/deeplearning,False,6,,0,,False,t3_nasckc,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620864449.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from DeepMind and Onshape combines a general-purpose language modelling technique and an off-the-shelf data serialization protocol to propose a machine learning model that can automatically generate high-quality sketches for Computer-Aided Design.&lt;/p&gt;

&lt;p&gt;Here is a quick read: DeepMind &amp;amp; Onshape Leverage Transformers to Advance Automatic Computer-Aided Design.&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Computer-Aided Design as Language&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2105.02769.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nasckc,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nasckc/r_deepmind_onshape_leverage_transformers_to/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nasckc/r_deepmind_onshape_leverage_transformers_to/,66146,1620835649.0,0,,False,,,,,,,
,deeplearning,"Hey everyone, I wanted to share a project of mine with you all. Hopefully you guys will like. 
Please have a look, if you could provide some feedback it would mean a lot to me. 

I am currently pursuing my masters and my work involves implementing lot of research paper but most of pipelines I implement are some variants of each other, hence I wanted to reuse them so I coalesced everything into a simple high level framework. 


TorchFlare is a simple, beginner-friendly and an easy-to-use PyTorch Framework train your models without much effort. It provides an almost Keras-like experience for training your models with all the callbacks, metrics, etc

Features

A high-level module for Keras-like training.

Off-the-shelf Pytorch style Datasets/Dataloaders for standard tasks such as Image classification, Image segmentation, Text Classification, etc

Callbacks for model checkpoints, early stopping, and much more!

Metrics and  much more.

Checkout the github. 

[Github ](https://github.com/Atharva-Phatak/torchflare)",t2_8c8l4gi7,False,,0,False,"TorchFlare : is a simple, beginner-friendly, and easy-to-use PyTorch Framework train your models effortlessly",[],r/deeplearning,False,6,,0,,False,t3_napusq,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620858123.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone, I wanted to share a project of mine with you all. Hopefully you guys will like. 
Please have a look, if you could provide some feedback it would mean a lot to me. &lt;/p&gt;

&lt;p&gt;I am currently pursuing my masters and my work involves implementing lot of research paper but most of pipelines I implement are some variants of each other, hence I wanted to reuse them so I coalesced everything into a simple high level framework. &lt;/p&gt;

&lt;p&gt;TorchFlare is a simple, beginner-friendly and an easy-to-use PyTorch Framework train your models without much effort. It provides an almost Keras-like experience for training your models with all the callbacks, metrics, etc&lt;/p&gt;

&lt;p&gt;Features&lt;/p&gt;

&lt;p&gt;A high-level module for Keras-like training.&lt;/p&gt;

&lt;p&gt;Off-the-shelf Pytorch style Datasets/Dataloaders for standard tasks such as Image classification, Image segmentation, Text Classification, etc&lt;/p&gt;

&lt;p&gt;Callbacks for model checkpoints, early stopping, and much more!&lt;/p&gt;

&lt;p&gt;Metrics and  much more.&lt;/p&gt;

&lt;p&gt;Checkout the github. &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/Atharva-Phatak/torchflare""&gt;Github &lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,napusq,True,,NotSoGenius00,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/napusq/torchflare_is_a_simple_beginnerfriendly_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/napusq/torchflare_is_a_simple_beginnerfriendly_and/,66146,1620829323.0,0,,False,,,,,,,
,deeplearning,"So i am implementing a Variational Autoencoders for big size images (1280x720). 
After convolutional layers and flatten layer I have a output dim of 61440. So I use some FC layers to reduce dimensions to 215 for latent vector. Is this still too big (or too small)?

Thanks",t2_abbcm4w8,False,,0,False,Is 215 too big for a latent vector dim in VAE?,[],r/deeplearning,False,6,,0,,False,t3_naownj,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620855609.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So i am implementing a Variational Autoencoders for big size images (1280x720). 
After convolutional layers and flatten layer I have a output dim of 61440. So I use some FC layers to reduce dimensions to 215 for latent vector. Is this still too big (or too small)?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,naownj,True,,I_am_not_doing_this,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/naownj/is_215_too_big_for_a_latent_vector_dim_in_vae/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/naownj/is_215_too_big_for_a_latent_vector_dim_in_vae/,66146,1620826809.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,"A Complete Roadmap for learning Machine Learning with many valuable resources + how to stay up-to-date with the news. Intended for anyone having zero or a small background in programming, maths, and machine learning.",[],r/deeplearning,False,6,,0,,False,t3_nanwes,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1620852633.0,text,6,,,text,louisbouchard.ai,False,,,,,https://www.louisbouchard.ai/learnai/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nanwes,True,,OnlyProggingForFun,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nanwes/a_complete_roadmap_for_learning_machine_learning/,all_ads,False,https://www.louisbouchard.ai/learnai/,66146,1620823833.0,0,,False,,,,,,,
,deeplearning,"While using convolutional nets to perform image classification, I encountered several difficulties importing image data using the native Tensorflow functions. So, I created my own custom image data pipeline, which gives the user finer control and more flexibility when importing image data. I hope it is useful to you guys as well. Let me know what you think.

https://github.com/nenyehub/tf-image-pipeline",t2_byr8u2i,False,,0,False,Custom Image Data Pipeline using Tensorflow,[],r/deeplearning,False,6,,0,,False,t3_nacydw,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620811023.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;While using convolutional nets to perform image classification, I encountered several difficulties importing image data using the native Tensorflow functions. So, I created my own custom image data pipeline, which gives the user finer control and more flexibility when importing image data. I hope it is useful to you guys as well. Let me know what you think.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/nenyehub/tf-image-pipeline""&gt;https://github.com/nenyehub/tf-image-pipeline&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nacydw,True,,kidFNSS,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nacydw/custom_image_data_pipeline_using_tensorflow/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nacydw/custom_image_data_pipeline_using_tensorflow/,66146,1620782223.0,0,,False,,,,,,,
,deeplearning,"I was working on fish detection and tracking system in 3 dimensions using MS Kinect, and used yolov5s for rgb frames. I wanted to experiment a bit with the architecture

of yolov5, but as a beginner i am struggling to find the relation between the arguments in the classes used in [common.py](https://common.py)  file and the arguments used in YAML  file in the Ultralytics repo. Can anybody help ?

PS : If you can add in some resources from where i can learn about the architecture and layers, then it would really help. Thank you !",t2_a969sovp,False,,0,False,What is the relation between the arguments in YAML of layer and arguments in the class of the layers in Ultralytics yolov5 repo ?,[],r/deeplearning,False,6,,0,,False,t3_n9v2cu,False,dark,0.91,,public,9,0,{},,False,[],,False,False,,{},,False,9,,False,False,,False,,[],{},,True,,1620762125.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was working on fish detection and tracking system in 3 dimensions using MS Kinect, and used yolov5s for rgb frames. I wanted to experiment a bit with the architecture&lt;/p&gt;

&lt;p&gt;of yolov5, but as a beginner i am struggling to find the relation between the arguments in the classes used in &lt;a href=""https://common.py""&gt;common.py&lt;/a&gt;  file and the arguments used in YAML  file in the Ultralytics repo. Can anybody help ?&lt;/p&gt;

&lt;p&gt;PS : If you can add in some resources from where i can learn about the architecture and layers, then it would really help. Thank you !&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n9v2cu,True,,sukhiatma69,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n9v2cu/what_is_the_relation_between_the_arguments_in/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n9v2cu/what_is_the_relation_between_the_arguments_in/,66146,1620733325.0,0,,False,,,,,,,
,deeplearning,"Hello community, I was wondering how self-attention handle multivariate time series data. Knowing that the block usually accept vectors as input, but in my case I have a Matrix of data ( 5,7) where 5 is the sequence length and 7 is the dimension embedding.

will the self attention be applied for every feature sequentially ( 5,d1) then same for the second dimension (5,d2) etc... ? Or can it be applied on a context matrix as well ?",t2_7l9ti89m,False,,0,False,[!QUESTION] Self attention for multivariate time series,[],r/deeplearning,False,6,,0,,False,t3_na9svi,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620801491.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello community, I was wondering how self-attention handle multivariate time series data. Knowing that the block usually accept vectors as input, but in my case I have a Matrix of data ( 5,7) where 5 is the sequence length and 7 is the dimension embedding.&lt;/p&gt;

&lt;p&gt;will the self attention be applied for every feature sequentially ( 5,d1) then same for the second dimension (5,d2) etc... ? Or can it be applied on a context matrix as well ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,na9svi,True,,rayanaay,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/na9svi/question_self_attention_for_multivariate_time/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/na9svi/question_self_attention_for_multivariate_time/,66146,1620772691.0,0,,False,,,,,,,
,deeplearning,"For instance, if I want to run CPU inference on a server I might consider the following things:

\- How much memory is required for my model parameters? (and how much memory is available on the server)

\- How long it takes to do inference on my machine? (and what type of CPU the server has)

With the above two I can usually do a back of the envelope calculation and get a ballpark understanding of what's required.

What about for mobile devices?

And is there such thing as some sort of emulation bench-marking tool?",t2_4e0q6fsl,False,,0,False,What sorts of specs should I consider when deciding if a model will work on a mobile device?,[],r/deeplearning,False,6,,0,,False,t3_n9t37r,False,dark,0.94,,public,12,0,{},,False,[],,False,False,,{},,False,12,,False,False,,1620738149.0,,[],{},,True,,1620754298.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;For instance, if I want to run CPU inference on a server I might consider the following things:&lt;/p&gt;

&lt;p&gt;- How much memory is required for my model parameters? (and how much memory is available on the server)&lt;/p&gt;

&lt;p&gt;- How long it takes to do inference on my machine? (and what type of CPU the server has)&lt;/p&gt;

&lt;p&gt;With the above two I can usually do a back of the envelope calculation and get a ballpark understanding of what&amp;#39;s required.&lt;/p&gt;

&lt;p&gt;What about for mobile devices?&lt;/p&gt;

&lt;p&gt;And is there such thing as some sort of emulation bench-marking tool?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n9t37r,True,,_4lexander_,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n9t37r/what_sorts_of_specs_should_i_consider_when/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n9t37r/what_sorts_of_specs_should_i_consider_when/,66146,1620725498.0,0,,False,,,,,,,
,deeplearning,"A research team from ETH Zurich combines continual learning and self-supervision to propose a novel robot system that enables online life-long self-supervised learning of semantic scene understanding. 

Here is a quick read: [ETH Zurich Proposes a Robotic System Capable of Self-Improving Its Semantic Perception.](https://syncedreview.com/2021/05/11/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-16/)

The paper *Self-Improving Semantic Perception on a Construction Robot* is on [arXiv](https://arxiv.org/pdf/2105.01595.pdf).",t2_2fv4yodo,False,,0,False,[R] ETH Zurich Proposes a Robotic System Capable of Self-Improving Its Semantic Perception,[],r/deeplearning,False,6,,0,,False,t3_na0p0c,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620778523.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from ETH Zurich combines continual learning and self-supervision to propose a novel robot system that enables online life-long self-supervised learning of semantic scene understanding. &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/11/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-16/""&gt;ETH Zurich Proposes a Robotic System Capable of Self-Improving Its Semantic Perception.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Self-Improving Semantic Perception on a Construction Robot&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2105.01595.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,na0p0c,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/na0p0c/r_eth_zurich_proposes_a_robotic_system_capable_of/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/na0p0c/r_eth_zurich_proposes_a_robotic_system_capable_of/,66146,1620749723.0,0,,False,,,,,,,
,deeplearning,"I have 3D textured meshes for a dozen of objects, which have to be detected in synthetic images. I have 2D textures of backgrounds these objects will be visible in front of. Object detection will be performed on 2D images taken inside a 3D simulation (all data is synthetic).

In order to get the training data for DNN, I would overlay renderings of 3D meshes with varying viewpoint, scale and lighting over all available background textures at different locations. I'm sure, this obvious method was used by others countless times in the past and presumably there are some tools to automate it. Can someone point me in the right direction and post a link to an easy-to-use tool, which can do what I described above?",t2_b2137,False,,0,False,Automated tools to generate synthetic training images out of synthetic 3D models and 2D backgrounds,[],r/deeplearning,False,6,,0,,False,t3_na5yth,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620791525.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have 3D textured meshes for a dozen of objects, which have to be detected in synthetic images. I have 2D textures of backgrounds these objects will be visible in front of. Object detection will be performed on 2D images taken inside a 3D simulation (all data is synthetic).&lt;/p&gt;

&lt;p&gt;In order to get the training data for DNN, I would overlay renderings of 3D meshes with varying viewpoint, scale and lighting over all available background textures at different locations. I&amp;#39;m sure, this obvious method was used by others countless times in the past and presumably there are some tools to automate it. Can someone point me in the right direction and post a link to an easy-to-use tool, which can do what I described above?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,na5yth,True,,puplan,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/na5yth/automated_tools_to_generate_synthetic_training/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/na5yth/automated_tools_to_generate_synthetic_training/,66146,1620762725.0,0,,False,,,,,,,
,deeplearning,"Hi all, 

I posted a bit around updating an old machine my lab has so it can be more suited for DL, turns out our budget was a lot more than I anticipated so we can actually afford a new machine - I don't however want to end up wasting money on overshooting on components I don't need. Any input on the specs below would be greatly appreciated. At the moment I'm looking at two options, either the Alienware Aurora r12 top-spec, or a custom build from PC specialist. I'll outline the two specs below. 

It should be noted I can't change many of the Alienware specs, but the PC specialist is fully customizable. They are roughly around the same price give or take £100-£200.

&amp;#x200B;

**Alienware r12**

11th Gen i9-11900KF (8 core, 16MB cache, 3.5GHz to 5.3GHz w/Thermal Velocity Boost)

NVIDIA RTX 3090

64GB Dual Channel DDR4 XMP @ 3400MHz 

2TB M.2 NVMe SSD 

2TB 7200RPM SATA 6GB/s

High Performance CPU Liquid Cooling (they don't state specifically what, so I assume it's a custom in house job)

1000W Power Supply

&amp;#x200B;

**PC Specialist** 

i9-10940X (14 core, 19.25 MB cache, 3.3GHz)

NVIDIA RTX3090

64GB Corsair Vengence DDR4 2400MHz (4 x 16GB sticks)

500GB Samsung EVO 970 PLUS M.2 NVMe (up to 3500MB/R, 3200MB/W)

4TB Corsair MP400 M.2 NVMe (up to 3480 MB/R, 3000 MB/W

8TB Seagate Barracuda SATA-III, 5400RPM

Corsair 850W power supply (Ultra Quiet apparently)

PC Specialist FrostFlow 150 Series high-performance CPU cooler (180W) - this is air flow cooling",t2_2t7g6k8t,False,,0,False,System Specification Help,[],r/deeplearning,False,6,,0,,False,t3_n9su5b,False,dark,0.82,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,True,,1620753241.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, &lt;/p&gt;

&lt;p&gt;I posted a bit around updating an old machine my lab has so it can be more suited for DL, turns out our budget was a lot more than I anticipated so we can actually afford a new machine - I don&amp;#39;t however want to end up wasting money on overshooting on components I don&amp;#39;t need. Any input on the specs below would be greatly appreciated. At the moment I&amp;#39;m looking at two options, either the Alienware Aurora r12 top-spec, or a custom build from PC specialist. I&amp;#39;ll outline the two specs below. &lt;/p&gt;

&lt;p&gt;It should be noted I can&amp;#39;t change many of the Alienware specs, but the PC specialist is fully customizable. They are roughly around the same price give or take £100-£200.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Alienware r12&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;11th Gen i9-11900KF (8 core, 16MB cache, 3.5GHz to 5.3GHz w/Thermal Velocity Boost)&lt;/p&gt;

&lt;p&gt;NVIDIA RTX 3090&lt;/p&gt;

&lt;p&gt;64GB Dual Channel DDR4 XMP @ 3400MHz &lt;/p&gt;

&lt;p&gt;2TB M.2 NVMe SSD &lt;/p&gt;

&lt;p&gt;2TB 7200RPM SATA 6GB/s&lt;/p&gt;

&lt;p&gt;High Performance CPU Liquid Cooling (they don&amp;#39;t state specifically what, so I assume it&amp;#39;s a custom in house job)&lt;/p&gt;

&lt;p&gt;1000W Power Supply&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PC Specialist&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;i9-10940X (14 core, 19.25 MB cache, 3.3GHz)&lt;/p&gt;

&lt;p&gt;NVIDIA RTX3090&lt;/p&gt;

&lt;p&gt;64GB Corsair Vengence DDR4 2400MHz (4 x 16GB sticks)&lt;/p&gt;

&lt;p&gt;500GB Samsung EVO 970 PLUS M.2 NVMe (up to 3500MB/R, 3200MB/W)&lt;/p&gt;

&lt;p&gt;4TB Corsair MP400 M.2 NVMe (up to 3480 MB/R, 3000 MB/W&lt;/p&gt;

&lt;p&gt;8TB Seagate Barracuda SATA-III, 5400RPM&lt;/p&gt;

&lt;p&gt;Corsair 850W power supply (Ultra Quiet apparently)&lt;/p&gt;

&lt;p&gt;PC Specialist FrostFlow 150 Series high-performance CPU cooler (180W) - this is air flow cooling&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n9su5b,True,,Molem7b5,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n9su5b/system_specification_help/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n9su5b/system_specification_help/,66146,1620724441.0,0,,False,,,,,,,
,deeplearning,"My professor asked me to produce images using the Cyclegan architecture as this semester project. I intend to work on a computer vision project with Cyclegan architecture and looking for Dataset from the facade of buildings and paintings from the building.  The second DataSet can also be the images of the buildings in Japanese anime or manga or something similar. If you know such datasets, please let me know.

It is very urgent",t2_8a7rf9yb,False,,0,False,architectural facade dataset for CycleGAN,[],r/deeplearning,False,6,,0,,False,t3_na5dtd,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620790103.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My professor asked me to produce images using the Cyclegan architecture as this semester project. I intend to work on a computer vision project with Cyclegan architecture and looking for Dataset from the facade of buildings and paintings from the building.  The second DataSet can also be the images of the buildings in Japanese anime or manga or something similar. If you know such datasets, please let me know.&lt;/p&gt;

&lt;p&gt;It is very urgent&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,na5dtd,True,,AromaticCustomer7765,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/na5dtd/architectural_facade_dataset_for_cyclegan/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/na5dtd/architectural_facade_dataset_for_cyclegan/,66146,1620761303.0,0,,False,,,,,,,
,deeplearning,"I don't understand why Levine says at minute 3.00 in this video ([https://www.youtube.com/watch?v=xAcAWaeUxYs&amp;list=PL\_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A&amp;index=18](https://www.youtube.com/watch?v=xAcAWaeUxYs&amp;list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A&amp;index=18)) that filters always have one more dimension (4D) than the activations (3D).

Could you explain?   


Thanks!",t2_9cjb5thn,False,,0,False,Kernel size in CNNs,[],r/deeplearning,False,6,,0,,False,t3_n9tfod,False,dark,0.84,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1620755835.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I don&amp;#39;t understand why Levine says at minute 3.00 in this video (&lt;a href=""https://www.youtube.com/watch?v=xAcAWaeUxYs&amp;amp;list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A&amp;amp;index=18""&gt;https://www.youtube.com/watch?v=xAcAWaeUxYs&amp;amp;list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A&amp;amp;index=18&lt;/a&gt;) that filters always have one more dimension (4D) than the activations (3D).&lt;/p&gt;

&lt;p&gt;Could you explain?   &lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n9tfod,True,,No_Possibility_7588,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n9tfod/kernel_size_in_cnns/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n9tfod/kernel_size_in_cnns/,66146,1620727035.0,0,,False,,,,,,,
,deeplearning,"One of the most common pruning techniques is ""unstructured, iterative, global magnitude pruning"" which prunes smallest magnitude p% of weights in each iterative pruning round. 'p' is typically between (10-20)%. However, after the desired sparsity is reached, say 96% (meaning that 96% of the weights in the neural network is 0), how can I remove these 0s to essentially remove say filters/neurons?

Because this pruning technique produces a lot of 0s which still participate in forward propagation using *out = W.out\_prev + b.* Therefore, this pruning technique will help in compression but not in the reduction of inference time.

Thanks!",t2_2mmql89p,False,,0,False,Remove pruned connections,[],r/deeplearning,False,6,,0,,False,t3_n9mcba,False,dark,0.78,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1620727629.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;One of the most common pruning techniques is &amp;quot;unstructured, iterative, global magnitude pruning&amp;quot; which prunes smallest magnitude p% of weights in each iterative pruning round. &amp;#39;p&amp;#39; is typically between (10-20)%. However, after the desired sparsity is reached, say 96% (meaning that 96% of the weights in the neural network is 0), how can I remove these 0s to essentially remove say filters/neurons?&lt;/p&gt;

&lt;p&gt;Because this pruning technique produces a lot of 0s which still participate in forward propagation using &lt;em&gt;out = W.out_prev + b.&lt;/em&gt; Therefore, this pruning technique will help in compression but not in the reduction of inference time.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n9mcba,True,,grid_world,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/n9mcba/remove_pruned_connections/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n9mcba/remove_pruned_connections/,66146,1620698829.0,0,,False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,MLP-Mixer: An all-MLP Architecture for Vision | Paper overview (MLP is all you need folks and 300 M pics),[],r/deeplearning,False,6,,0,,False,t3_n9aqlv,False,dark,0.83,,public,24,1,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/AoKf3SvvTIU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'MLP-Mixer: An all-MLP Architecture for Vision | Paper explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/AoKf3SvvTIU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/AoKf3SvvTIU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/AoKf3SvvTIU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n9aqlv', 'height': 200}",,False,24,,False,False,,False,,[],{},,False,,1620696334.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/AoKf3SvvTIU,,False,False,False,False,False,"[{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n9aqlv,True,,gordicaleksa,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/n9aqlv/mlpmixer_an_allmlp_architecture_for_vision_paper/,all_ads,False,https://youtu.be/AoKf3SvvTIU,66146,1620667534.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'MLP-Mixer: An all-MLP Architecture for Vision | Paper explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/AoKf3SvvTIU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/AoKf3SvvTIU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,"Used Transfer Learning with ResNet-50 on CIFAR-10 in PyTorch to achieve val\_accuracy = 92.58%. You can see the code [here](https://github.com/arjun-majumdar/CNN_Classifications/blob/master/ResNet50_Transfer_Learning_CIFAR10_Finetuning_entire_model.ipynb).

**Key takeaway:** Change the first conv layer to have the hyper-parameters kernel\_size = (3, 3), stride = (1, 1) and padding = (1, 1) instead of the original ones since CIFAR-10 dataset has much smaller images and using the original conv layer hyper-parameters reduces the image size due to which the resulting model performs not so good, according to my experiments.

Thoughts?",t2_2mmql89p,False,,0,False,PyTorch Transfer Learning,[],r/deeplearning,False,6,,0,,False,t3_n9p220,False,dark,1.0,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,1620716915.0,,[],{},,True,,1620737131.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Used Transfer Learning with ResNet-50 on CIFAR-10 in PyTorch to achieve val_accuracy = 92.58%. You can see the code &lt;a href=""https://github.com/arjun-majumdar/CNN_Classifications/blob/master/ResNet50_Transfer_Learning_CIFAR10_Finetuning_entire_model.ipynb""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key takeaway:&lt;/strong&gt; Change the first conv layer to have the hyper-parameters kernel_size = (3, 3), stride = (1, 1) and padding = (1, 1) instead of the original ones since CIFAR-10 dataset has much smaller images and using the original conv layer hyper-parameters reduces the image size due to which the resulting model performs not so good, according to my experiments.&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n9p220,True,,grid_world,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n9p220/pytorch_transfer_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n9p220/pytorch_transfer_learning/,66146,1620708331.0,0,,False,,,,,,,
,deeplearning,"I have two text columns. 

The objective is to vectorize each column separately. And then pass them into a MLP, so that the model can also understand which column a word is coming from.

But I am confused as to how to actually implement this.

Any help or resources would be appreciated. Let me know if there is a different approach to solve this problem as well.

Thank you!",t2_3xirs0ww,False,,0,False,How to let a NN model know which column a word is coming from?,[],r/deeplearning,False,6,,0,,False,t3_n9gepc,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620710372.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have two text columns. &lt;/p&gt;

&lt;p&gt;The objective is to vectorize each column separately. And then pass them into a MLP, so that the model can also understand which column a word is coming from.&lt;/p&gt;

&lt;p&gt;But I am confused as to how to actually implement this.&lt;/p&gt;

&lt;p&gt;Any help or resources would be appreciated. Let me know if there is a different approach to solve this problem as well.&lt;/p&gt;

&lt;p&gt;Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n9gepc,True,,GetStuffTogether,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/n9gepc/how_to_let_a_nn_model_know_which_column_a_word_is/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n9gepc/how_to_let_a_nn_model_know_which_column_a_word_is/,66146,1620681572.0,0,,False,,,,,,,
,deeplearning,"&amp;#x200B;

https://reddit.com/link/n8y5m8/video/j9dmhm03oay61/player

https://preview.redd.it/6r23c8t3oay61.jpg?width=2501&amp;format=pjpg&amp;auto=webp&amp;s=25300c65c071332c9d7a84bd976953855cfdc691

&amp;#x200B;",t2_ibqd1,False,,0,False,Benchmark challenge by Sony on sound source separation,[],r/deeplearning,False,6,,0,,False,t3_n8y5m8,False,dark,0.96,,public,24,0,{},,False,[],,False,False,,{},,False,24,,False,False,,1620660071.0,,[],{},,True,,1620658776.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://reddit.com/link/n8y5m8/video/j9dmhm03oay61/player""&gt;https://reddit.com/link/n8y5m8/video/j9dmhm03oay61/player&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/6r23c8t3oay61.jpg?width=2501&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=25300c65c071332c9d7a84bd976953855cfdc691""&gt;https://preview.redd.it/6r23c8t3oay61.jpg?width=2501&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=25300c65c071332c9d7a84bd976953855cfdc691&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n8y5m8,True,,EscapedLaughter,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/n8y5m8/benchmark_challenge_by_sony_on_sound_source/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n8y5m8/benchmark_challenge_by_sony_on_sound_source/,66146,1620629976.0,0,,False,,,"{'6r23c8t3oay61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 56, 'x': 108, 'u': 'https://preview.redd.it/6r23c8t3oay61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d3180f15873c15055bdb374a176acd34191e8274'}, {'y': 113, 'x': 216, 'u': 'https://preview.redd.it/6r23c8t3oay61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3072be24631756e4e5b2e4d9f566b02ba57bb417'}, {'y': 167, 'x': 320, 'u': 'https://preview.redd.it/6r23c8t3oay61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bc111d4166d6c78c0736866e695a26e8baffa23e'}, {'y': 335, 'x': 640, 'u': 'https://preview.redd.it/6r23c8t3oay61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a18ac456eb71a90a459fe56be11dbffbb13a8b0f'}, {'y': 502, 'x': 960, 'u': 'https://preview.redd.it/6r23c8t3oay61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3dad1f01e6e2ea00489f6ec16f8913c7657a5f67'}, {'y': 565, 'x': 1080, 'u': 'https://preview.redd.it/6r23c8t3oay61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8227fe13d304658bf28d7ee9d53653510346c570'}], 's': {'y': 1310, 'x': 2501, 'u': 'https://preview.redd.it/6r23c8t3oay61.jpg?width=2501&amp;format=pjpg&amp;auto=webp&amp;s=25300c65c071332c9d7a84bd976953855cfdc691'}, 'id': '6r23c8t3oay61'}, 'j9dmhm03oay61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/n8y5m8/asset/j9dmhm03oay61/DASHPlaylist.mpd?a=1626449924%2CMmUwZDRmYzIzMDhjZTA0ZWE2YmIxNGRkY2ZjYzk5N2QzYzA2ZjNmNDA1MGY0ZDdhOWY1NzEzZmI4NTRlMTdiNA%3D%3D&amp;v=1&amp;f=sd', 'x': 640, 'y': 340, 'hlsUrl': 'https://v.redd.it/link/n8y5m8/asset/j9dmhm03oay61/HLSPlaylist.m3u8?a=1626449924%2CMzk5YTEwMzkzYjE3NmY2ZTE5OWQzY2RmNWU5Y2U5NzFiNmVkNDc5NWJhMWNiNjFiYjI0OTY0MGYzYWRlNjEyZg%3D%3D&amp;v=1&amp;f=sd', 'id': 'j9dmhm03oay61', 'isGif': False}}",,,,
,deeplearning,"As the title said. Been looking to no avail for now. 

Thanks in advance for any help!",t2_lp3x6,False,,0,False,Is there any Deep Learning package/module that handles Imaginary numbers like how the usual would Real numbers?,[],r/deeplearning,False,6,,0,,False,t3_n9bu9a,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620698971.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As the title said. Been looking to no avail for now. &lt;/p&gt;

&lt;p&gt;Thanks in advance for any help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n9bu9a,True,,YsrYsl,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/n9bu9a/is_there_any_deep_learning_packagemodule_that/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n9bu9a/is_there_any_deep_learning_packagemodule_that/,66146,1620670171.0,0,,False,,,,,,,
,deeplearning,"Imperial College London researchers show how to optimally train a variational quantum algorithm to represent quantum states and propose a stable variant of the quantum natural gradient, a generalized quantum natural gradient that can be trained free of barren plateaus.

Here is a quick read: [Imperial College London Proposes Optimal Training of Variational Quantum Algorithms Without Barren Plateaus.](https://syncedreview.com/2021/05/10/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-15/)

 The paper *Optimal Training of Variational Quantum Algorithms Without Barren Plateaus* is on [arXiv](https://arxiv.org/pdf/2104.14543.pdf).",t2_2fv4yodo,False,,0,False,[R] Imperial College London Proposes Optimal Training of Variational Quantum Algorithms Without Barren Plateaus,[],r/deeplearning,False,6,,0,,False,t3_n990qo,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620692157.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Imperial College London researchers show how to optimally train a variational quantum algorithm to represent quantum states and propose a stable variant of the quantum natural gradient, a generalized quantum natural gradient that can be trained free of barren plateaus.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/10/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-15/""&gt;Imperial College London Proposes Optimal Training of Variational Quantum Algorithms Without Barren Plateaus.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Optimal Training of Variational Quantum Algorithms Without Barren Plateaus&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.14543.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n990qo,True,,Yuqing7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n990qo/r_imperial_college_london_proposes_optimal/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n990qo/r_imperial_college_london_proposes_optimal/,66146,1620663357.0,0,,False,,,,,,,
,deeplearning,,t2_40d0zt4s,False,,0,False,NVIDIA’s Kaolin: A 3D Deep Learning Library - Analytics India Magazine,[],r/deeplearning,False,6,,0,,False,t3_n92ngx,False,dark,0.58,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1620676471.0,text,6,,,text,analyticsindiamag.com,False,,,,,https://analyticsindiamag.com/nvidias-kaolin-3d-deep-learning-library/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n92ngx,True,,analyticsindiam,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n92ngx/nvidias_kaolin_a_3d_deep_learning_library/,all_ads,False,https://analyticsindiamag.com/nvidias-kaolin-3d-deep-learning-library/,66146,1620647671.0,0,,False,,,,,,,
,deeplearning,,t2_8emfs7ji,False,,0,False,Hi All! On May 29th Nextgrid hosts the 3rd GPT-3 Hackathon in a collab with OpenAI. Details below.,[],r/deeplearning,False,6,,0,,False,t3_n963qn,False,dark,0.63,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1620685947.0,text,6,,,text,nextgrid.ai,False,,,,,https://nextgrid.ai/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n963qn,True,,techn0_cratic,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n963qn/hi_all_on_may_29th_nextgrid_hosts_the_3rd_gpt3/,all_ads,False,https://nextgrid.ai/,66146,1620657147.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'OpenAI', 'selftext': '', 'author_fullname': 't2_8emfs7ji', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Hi All! On May 29th Nextgrid hosts 3rd GPT-3 Hackathon in a collab with OpenAI❤️ As a participant, you will get access to GPT-3. If you already have it, you will get 300k tokens added. The winning teams will receive extra tokens for development. Posting their www, you will be guided to register', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/OpenAI', 'hidden': False, 'pwls': None, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_n961dr', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.9, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 22, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': '[The 3rd GPT-3 Hackathon🏓]', 'can_mod_post': False, 'score': 22, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1620685835.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'nextgrid.ai', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://nextgrid.ai/', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'f50afd20-a0eb-11e5-bdec-0e6d402a538f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3b9u5', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'n961dr', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'techn0_cratic', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/OpenAI/comments/n961dr/hi_all_on_may_29th_nextgrid_hosts_3rd_gpt3/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://nextgrid.ai/', 'subreddit_subscribers': 8646, 'created_utc': 1620657035.0, 'num_crossposts': 3, 'media': None, 'is_video': False}]",t3_n961dr,,,,,
,deeplearning," Trained a deep learning model that will convert your grayscale photos into colorful mode

 

https://preview.redd.it/bpme36geray61.png?width=817&amp;format=png&amp;auto=webp&amp;s=7329ff427662b921f7a5b9da0658adfb8f6d1bbe

 

\-AutoEncoder Based Deep learning model that colorizes the old black and white images

· Used resnet18 for encoder part and up-sampled that latent representation in decoder part

· Deployed the simple webapp using streamlit on Heroku

Though this is just a based model. I know some ways of improving like using good encoder , training for higher epochs .I would like to hear from you guys

Suggestions are always welome :)

git -[https://github.com/Pranav082001/Neural-Image-Colorizer](https://github.com/Pranav082001/Neural-Image-Colorizer)",t2_757mta07,False,,0,False,AI Colorizes your old B/W photos [Neural-Image-Colorizer],[],r/deeplearning,False,6,,0,,False,t3_n94r8m,False,dark,0.62,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620683012.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Trained a deep learning model that will convert your grayscale photos into colorful mode&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/bpme36geray61.png?width=817&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7329ff427662b921f7a5b9da0658adfb8f6d1bbe""&gt;https://preview.redd.it/bpme36geray61.png?width=817&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7329ff427662b921f7a5b9da0658adfb8f6d1bbe&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;-AutoEncoder Based Deep learning model that colorizes the old black and white images&lt;/p&gt;

&lt;p&gt;· Used resnet18 for encoder part and up-sampled that latent representation in decoder part&lt;/p&gt;

&lt;p&gt;· Deployed the simple webapp using streamlit on Heroku&lt;/p&gt;

&lt;p&gt;Though this is just a based model. I know some ways of improving like using good encoder , training for higher epochs .I would like to hear from you guys&lt;/p&gt;

&lt;p&gt;Suggestions are always welome :)&lt;/p&gt;

&lt;p&gt;git -&lt;a href=""https://github.com/Pranav082001/Neural-Image-Colorizer""&gt;https://github.com/Pranav082001/Neural-Image-Colorizer&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n94r8m,True,,Heisenberg_082001,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n94r8m/ai_colorizes_your_old_bw_photos/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n94r8m/ai_colorizes_your_old_bw_photos/,66146,1620654212.0,0,,False,,,"{'bpme36geray61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 49, 'x': 108, 'u': 'https://preview.redd.it/bpme36geray61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4ca03bfbbd593416cd043d39482e7099b7d28ca'}, {'y': 99, 'x': 216, 'u': 'https://preview.redd.it/bpme36geray61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6755e134ba71e927ceafd20f7a6875a116798d04'}, {'y': 148, 'x': 320, 'u': 'https://preview.redd.it/bpme36geray61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d3acb784c9c25ec9e2cc1f9bee39960cc9cb715'}, {'y': 296, 'x': 640, 'u': 'https://preview.redd.it/bpme36geray61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9d80d5c7f4ee5675b91cb2e2dffe01faeb760265'}], 's': {'y': 378, 'x': 817, 'u': 'https://preview.redd.it/bpme36geray61.png?width=817&amp;format=png&amp;auto=webp&amp;s=7329ff427662b921f7a5b9da0658adfb8f6d1bbe'}, 'id': 'bpme36geray61'}}",,,,
,deeplearning,,t2_3r02kqm0,False,,0,False,"Pianist AI&gt; Deep learning approach, still long way to go but the progress is promising :) : Level 4 Try 5",[],r/deeplearning,False,6,,0,,False,t3_n966g5,False,dark,0.43,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/J1KU6W72Hx0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Level 4: Try 5', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/J1KU6W72Hx0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '[ The Pianist AI ]', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/J1KU6W72Hx0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ThePianistAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/J1KU6W72Hx0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n966g5', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1620686077.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/J1KU6W72Hx0,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n966g5,True,,amin_mlm,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n966g5/pianist_ai_deep_learning_approach_still_long_way/,all_ads,False,https://youtu.be/J1KU6W72Hx0,66146,1620657277.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Level 4: Try 5', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/J1KU6W72Hx0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '[ The Pianist AI ]', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/J1KU6W72Hx0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ThePianistAI'}}",False,,,,,,,
,deeplearning,"In this tutorial, we'll cover how to train YOLO v5 on a road sign object detection task, which can easily be swapped for your own custom dataset. This tutorial will be broken down into the following parts:

1. Setting up YOLO v5 and dependencies
2. Downloading the data and converting it to YOLO v5 format (we'll write a custom function for this so you can easily apply it to your own data)
3. Training options
4. Inference on images and videos

Tutorial link: [https://blog.paperspace.com/train-yolov5-custom-data/](https://blog.paperspace.com/train-yolov5-custom-data/)

Run the full code on a free GPU: [https://ml-showcase.paperspace.com/projects/yolov5](https://ml-showcase.paperspace.com/projects/yolov5)

Comments and questions welcome!",t2_15en0l,False,,0,False,[Tutorial] Train YOLOv5 on your own custom data,[],r/deeplearning,False,6,,0,,False,t3_n95o55,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620685212.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In this tutorial, we&amp;#39;ll cover how to train YOLO v5 on a road sign object detection task, which can easily be swapped for your own custom dataset. This tutorial will be broken down into the following parts:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Setting up YOLO v5 and dependencies&lt;/li&gt;
&lt;li&gt;Downloading the data and converting it to YOLO v5 format (we&amp;#39;ll write a custom function for this so you can easily apply it to your own data)&lt;/li&gt;
&lt;li&gt;Training options&lt;/li&gt;
&lt;li&gt;Inference on images and videos&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Tutorial link: &lt;a href=""https://blog.paperspace.com/train-yolov5-custom-data/""&gt;https://blog.paperspace.com/train-yolov5-custom-data/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Run the full code on a free GPU: &lt;a href=""https://ml-showcase.paperspace.com/projects/yolov5""&gt;https://ml-showcase.paperspace.com/projects/yolov5&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Comments and questions welcome!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n95o55,True,,hellopaperspace,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n95o55/tutorial_train_yolov5_on_your_own_custom_data/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n95o55/tutorial_train_yolov5_on_your_own_custom_data/,66146,1620656412.0,0,,False,,,,,,,
,deeplearning,"

I have been out of the loop for around one year, doing diverse projects not related to DL.

I have a couple of Keras models using custom layers, based on TensorFlow 1.13, I was wondering what is the best way to upgrade them to TF 2.x

I have read of an official TF function that analyzes your code, is that also applied to Keras? What has been your experience?

Thanks in advance",t2_ounyo,False,,0,False,Best way to upgrade keras models (built on TensorFlow 1.13) to TF2,[],r/deeplearning,False,6,,0,,False,t3_n94umi,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620683288.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been out of the loop for around one year, doing diverse projects not related to DL.&lt;/p&gt;

&lt;p&gt;I have a couple of Keras models using custom layers, based on TensorFlow 1.13, I was wondering what is the best way to upgrade them to TF 2.x&lt;/p&gt;

&lt;p&gt;I have read of an official TF function that analyzes your code, is that also applied to Keras? What has been your experience?&lt;/p&gt;

&lt;p&gt;Thanks in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n94umi,True,,aendrs,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/n94umi/best_way_to_upgrade_keras_models_built_on/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n94umi/best_way_to_upgrade_keras_models_built_on/,66146,1620654488.0,0,,False,,,,,,,
,deeplearning,"Everyone who is interested in NLP or even DL and ML for that matter, has definitely heard about the BERT family of models. BERT, RoBERTa, DistilBERT and many many more. This paper ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"" first introduced this and it has now completely changed the way AI practitioners are solving and looking at NLP problems these days.

As a part of my Paper Notes series, I have gone through the paper and created an informative summary of the paper. This time it goes a bit longer than the previous paper summaries, but it had to be done. The paper contained many tiny interesting nuggets that I had to include. Check out the links below and happy reading!

Paper Summary -  [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://shreyansh26.github.io/post/2021-05-09_pretraining_deep_bidirectional_transformers_bert/)

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf)",t2_5xzd9om,False,,0,False,BERT - Annotated Paper + Paper Summary,[],r/deeplearning,False,6,,0,,False,t3_n8ikdk,False,dark,0.87,,public,37,1,{},,False,[],,False,False,,{},,False,37,,False,False,,False,,[],{},,True,,1620608945.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Everyone who is interested in NLP or even DL and ML for that matter, has definitely heard about the BERT family of models. BERT, RoBERTa, DistilBERT and many many more. This paper &amp;quot;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&amp;quot; first introduced this and it has now completely changed the way AI practitioners are solving and looking at NLP problems these days.&lt;/p&gt;

&lt;p&gt;As a part of my Paper Notes series, I have gone through the paper and created an informative summary of the paper. This time it goes a bit longer than the previous paper summaries, but it had to be done. The paper contained many tiny interesting nuggets that I had to include. Check out the links below and happy reading!&lt;/p&gt;

&lt;p&gt;Paper Summary -  &lt;a href=""https://shreyansh26.github.io/post/2021-05-09_pretraining_deep_bidirectional_transformers_bert/""&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Annotated Paper -  &lt;a href=""https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf""&gt;https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n8ikdk,True,,shreyansh26,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/n8ikdk/bert_annotated_paper_paper_summary/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n8ikdk/bert_annotated_paper_paper_summary/,66146,1620580145.0,0,,False,,,,,,,
,deeplearning,,t2_5tjqypkb,False,,0,False,Is it overfitting?,[],r/deeplearning,False,6,,0,,False,t3_n884jv,False,dark,0.8,,public,28,0,{},,False,[],,True,False,,{},,False,28,,False,False,,False,,[],{},,False,,1620569659.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/qrx5l2ksc1y61.png,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n884jv,True,,Just-A-abnormal-Guy,,20,True,all_ads,False,[],False,,/r/deeplearning/comments/n884jv/is_it_overfitting/,all_ads,False,https://i.redd.it/qrx5l2ksc1y61.png,66146,1620540859.0,0,,False,,,,,,,
,deeplearning,,t2_5fsp2x6v,False,,0,False,Pooled Contextualised Embeddings for NER | Research Papers Summary 017,[],r/deeplearning,False,6,,0,,False,t3_n8k1fc,False,dark,0.67,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HJtapl3zWC0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Pooled Contextualised Embeddings for NER | Research Papers Summary 017', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HJtapl3zWC0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Ryan Ong', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/HJtapl3zWC0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/basketball10029508'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HJtapl3zWC0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n8k1fc', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1620613162.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/HJtapl3zWC0,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n8k1fc,True,,RyanAI100,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n8k1fc/pooled_contextualised_embeddings_for_ner_research/,all_ads,False,https://youtu.be/HJtapl3zWC0,66146,1620584362.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Pooled Contextualised Embeddings for NER | Research Papers Summary 017', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HJtapl3zWC0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Ryan Ong', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/HJtapl3zWC0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/basketball10029508'}}",False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,The neural network makes movie dubbing more natural,[],r/deeplearning,False,6,,0,,False,t3_n7wsrj,False,dark,0.93,,public,43,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/T7vrk6NCNsU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'The neural network makes movie dubbing more natural', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/T7vrk6NCNsU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/T7vrk6NCNsU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/T7vrk6NCNsU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n7wsrj', 'height': 200}",,False,43,,False,False,,False,,[],{},,False,,1620531571.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/T7vrk6NCNsU,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n7wsrj,True,,cmillionaire9,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n7wsrj/the_neural_network_makes_movie_dubbing_more/,all_ads,False,https://youtu.be/T7vrk6NCNsU,66146,1620502771.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'The neural network makes movie dubbing more natural', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/T7vrk6NCNsU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/T7vrk6NCNsU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,"I've been working on a WGAN-GP with a custom dataset, but I've been getting the erratic loss seen in the figure below. The figure plots the losses for batched over 8 epochs.

The base is a DCGAN with 32x32x3 images with no normalization layers, and I've implemented the WGAN-GP using code straight out of the Keras docs ([https://keras.io/examples/generative/wgan\_gp/](https://keras.io/examples/generative/wgan_gp/)), the output images are just noise with (mostly) similar colors to the examples.  


So what could be the issue? And how can I solve this?

Thank you

https://preview.redd.it/xm7siosl14y61.png?width=397&amp;format=png&amp;auto=webp&amp;s=85e2935901c48e528586707a5dfd1f61deb86ceb",t2_2rqe7crt,False,,0,False,WGAN-GP loss all over the place,[],r/deeplearning,False,6,,0,,False,t3_n8g3n7,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620601694.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been working on a WGAN-GP with a custom dataset, but I&amp;#39;ve been getting the erratic loss seen in the figure below. The figure plots the losses for batched over 8 epochs.&lt;/p&gt;

&lt;p&gt;The base is a DCGAN with 32x32x3 images with no normalization layers, and I&amp;#39;ve implemented the WGAN-GP using code straight out of the Keras docs (&lt;a href=""https://keras.io/examples/generative/wgan_gp/""&gt;https://keras.io/examples/generative/wgan_gp/&lt;/a&gt;), the output images are just noise with (mostly) similar colors to the examples.  &lt;/p&gt;

&lt;p&gt;So what could be the issue? And how can I solve this?&lt;/p&gt;

&lt;p&gt;Thank you&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/xm7siosl14y61.png?width=397&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=85e2935901c48e528586707a5dfd1f61deb86ceb""&gt;https://preview.redd.it/xm7siosl14y61.png?width=397&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=85e2935901c48e528586707a5dfd1f61deb86ceb&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n8g3n7,True,,aft_xstar,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n8g3n7/wgangp_loss_all_over_the_place/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n8g3n7/wgangp_loss_all_over_the_place/,66146,1620572894.0,0,,False,,,"{'xm7siosl14y61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 67, 'x': 108, 'u': 'https://preview.redd.it/xm7siosl14y61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=61fc18b3558eba7421672aa8cab8b012446342a2'}, {'y': 134, 'x': 216, 'u': 'https://preview.redd.it/xm7siosl14y61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b3190df95d6a005f30a09cce349804e6d43d16c2'}, {'y': 199, 'x': 320, 'u': 'https://preview.redd.it/xm7siosl14y61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e6f8c3aa6482666fe96762475f88ad07b75913ff'}], 's': {'y': 248, 'x': 397, 'u': 'https://preview.redd.it/xm7siosl14y61.png?width=397&amp;format=png&amp;auto=webp&amp;s=85e2935901c48e528586707a5dfd1f61deb86ceb'}, 'id': 'xm7siosl14y61'}}",,,,
,deeplearning,,t2_a93ac7vs,False,,0,False,What books to learn Time Series Analysis and Forecasting for Python beginner ?,[],r/deeplearning,False,6,,0,,False,t3_n8bnpw,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620585640.0,text,6,,,text,self.deeplearning,False,,,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n8bnpw,True,,learner2611,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n8bnpw/what_books_to_learn_time_series_analysis_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n8bnpw/what_books_to_learn_time_series_analysis_and/,66146,1620556840.0,0,,False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,"Open-sourcing DeepMind's DQN (call for contribution, I plan to make it the go-to RL resource eventually! &lt;3)",[],r/deeplearning,False,6,,0,,False,t3_n8dpl9,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1620593816.0,text,6,,,text,github.com,False,,,,,https://github.com/gordicaleksa/pytorch-learn-reinforcement-learning,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n8dpl9,True,,gordicaleksa,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n8dpl9/opensourcing_deepminds_dqn_call_for_contribution/,all_ads,False,https://github.com/gordicaleksa/pytorch-learn-reinforcement-learning,66146,1620565016.0,0,,False,,,,,,,
,deeplearning,,t2_b2blvutz,False,,0,False,are zero shot learning and self supervised learning nearly the same?,[],r/deeplearning,False,6,,0,,False,t3_n8d7mz,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1620591940.0,text,6,,,text,self.DeepLearningPapers,False,,,,,/r/DeepLearningPapers/comments/mmmbh2/are_zero_shot_learning_and_self_supervised/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n8d7mz,True,,onnkeat,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n8d7mz/are_zero_shot_learning_and_self_supervised/,all_ads,False,/r/DeepLearningPapers/comments/mmmbh2/are_zero_shot_learning_and_self_supervised/,66146,1620563140.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'DeepLearningPapers', 'selftext': 'I\'ve been following up on self supervised learning like simclr\n\nand also been studying on zero shot learning.\n\nFrom my understanding, the two are extremely identical at the core\n\nsince both are focusing on learning a good representation of the input\n\nand then zsl is about using this well trained representation model for classifying unseen data\n\nand self supervised learning is fine tuning this to downstream task.\n\n&amp;#x200B;\n\ncome to think of it, seems like recent advances are about ""how to train a better representation learning model""...\n\n&amp;#x200B;\n\nDo you agree with this opinion? what do you think?', 'author_fullname': 't2_g7e0ajf', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'are zero shot learning and self supervised learning nearly the same?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/DeepLearningPapers', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mmmbh2', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1617894913.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.DeepLearningPapers', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been following up on self supervised learning like simclr&lt;/p&gt;\n\n&lt;p&gt;and also been studying on zero shot learning.&lt;/p&gt;\n\n&lt;p&gt;From my understanding, the two are extremely identical at the core&lt;/p&gt;\n\n&lt;p&gt;since both are focusing on learning a good representation of the input&lt;/p&gt;\n\n&lt;p&gt;and then zsl is about using this well trained representation model for classifying unseen data&lt;/p&gt;\n\n&lt;p&gt;and self supervised learning is fine tuning this to downstream task.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;come to think of it, seems like recent advances are about &amp;quot;how to train a better representation learning model&amp;quot;...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Do you agree with this opinion? what do you think?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_38ri8', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mmmbh2', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'chadrick-kwag', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/DeepLearningPapers/comments/mmmbh2/are_zero_shot_learning_and_self_supervised/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/DeepLearningPapers/comments/mmmbh2/are_zero_shot_learning_and_self_supervised/', 'subreddit_subscribers': 15755, 'created_utc': 1617866113.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_mmmbh2,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,Realistic Lighting with Different Backgrounds,[],r/deeplearning,False,6,,0,,False,t3_n8c8nt,False,dark,0.6,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/rVP2tcF_yRI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Realistic Lighting with Different Backgrounds', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/rVP2tcF_yRI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/rVP2tcF_yRI/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/rVP2tcF_yRI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n8c8nt', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1620588098.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/rVP2tcF_yRI,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n8c8nt,True,,OnlyProggingForFun,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n8c8nt/realistic_lighting_with_different_backgrounds/,all_ads,False,https://youtu.be/rVP2tcF_yRI,66146,1620559298.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Realistic Lighting with Different Backgrounds', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/rVP2tcF_yRI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/rVP2tcF_yRI/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,,,,,,,
,deeplearning,,t2_a93ac7vs,False,,0,False,What books to learn Time Series Analysis and Forecasting for Python beginner ?,[],r/deeplearning,False,6,,0,,False,t3_n8bo4i,False,dark,0.44,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620585685.0,text,6,,,text,self.deeplearning,False,,,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n8bo4i,True,,learner2611,,15,True,all_ads,False,[],False,,/r/deeplearning/comments/n8bo4i/what_books_to_learn_time_series_analysis_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n8bo4i/what_books_to_learn_time_series_analysis_and/,66146,1620556885.0,0,,False,,,,,,,
,deeplearning,,t2_c0p4tyk7,False,,0,False,We are researchers that work to improve Machine Learning models. If you have experience with python and/or java and a few minutes to spare please take our survey!,[],r/deeplearning,False,6,,0,,False,t3_n80hcm,False,dark,0.55,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1620542881.0,text,6,,,text,usc.qualtrics.com,False,,,,,https://usc.qualtrics.com/jfe/form/SV_cHEhJ5YRoEOBwcC?Q_CHL=social&amp;Q_SocialSource=reddit,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n80hcm,True,,_iordanis,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n80hcm/we_are_researchers_that_work_to_improve_machine/,all_ads,False,https://usc.qualtrics.com/jfe/form/SV_cHEhJ5YRoEOBwcC?Q_CHL=social&amp;Q_SocialSource=reddit,66146,1620514081.0,0,,False,,,,,,,
,deeplearning,"Hello guys,

I'm struggling with my DL model (regression task, LSTM combined with some dense layers), since despite some hyperparameters tuning i always end with a sudden rise of the loss function and then a 'infinite"" plateau for hundreds of epochs.

My hypothesis were: 
-learning rate and local minima issue? i tried several (1e-3,1e-4) 
-Optimizer issue? i tried SGD for example
 -Too complex model? i removed some layers or neurons 
-Metric issue? i tried MAE

Among theses hypothesis and perhaps others, which one seems the most likely ? I looked for differents curve patterns but didn't find this one.

Thanks a lot!",t2_c0ktj61d,False,,0,False,Why is the loss stuck in high plateau?,[],r/deeplearning,False,6,,0,,False,t3_n7wszv,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620531593.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello guys,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m struggling with my DL model (regression task, LSTM combined with some dense layers), since despite some hyperparameters tuning i always end with a sudden rise of the loss function and then a &amp;#39;infinite&amp;quot; plateau for hundreds of epochs.&lt;/p&gt;

&lt;p&gt;My hypothesis were: 
-learning rate and local minima issue? i tried several (1e-3,1e-4) 
-Optimizer issue? i tried SGD for example
 -Too complex model? i removed some layers or neurons 
-Metric issue? i tried MAE&lt;/p&gt;

&lt;p&gt;Among theses hypothesis and perhaps others, which one seems the most likely ? I looked for differents curve patterns but didn&amp;#39;t find this one.&lt;/p&gt;

&lt;p&gt;Thanks a lot!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n7wszv,True,,DrBonobo87,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n7wszv/why_is_the_loss_stuck_in_high_plateau/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n7wszv/why_is_the_loss_stuck_in_high_plateau/,66146,1620502793.0,0,,False,,,,,,,
,deeplearning,"Every data scientist will have to use SOM at least once in their life. So here you are a Very Simplified Introduction to Self Organizing Map.

[https://ravinduramesh.blogspot.com/2021/04/intro-to-self-organizing-map-and-self.html](https://ravinduramesh.blogspot.com/2021/04/intro-to-self-organizing-map-and-self.html)",t2_9tkcfu03,False,,0,False,Very simplified intro to Self Organizing Maps,[],r/deeplearning,False,6,,0,,False,t3_n7q4xn,False,dark,0.58,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1620512161.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Every data scientist will have to use SOM at least once in their life. So here you are a Very Simplified Introduction to Self Organizing Map.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://ravinduramesh.blogspot.com/2021/04/intro-to-self-organizing-map-and-self.html""&gt;https://ravinduramesh.blogspot.com/2021/04/intro-to-self-organizing-map-and-self.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n7q4xn,True,,ravinduramesh,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/n7q4xn/very_simplified_intro_to_self_organizing_maps/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n7q4xn/very_simplified_intro_to_self_organizing_maps/,66146,1620483361.0,0,,False,,,,,,,
,deeplearning,,t2_1568ks,False,,0,False,AttendSeg: high-performance on-device semantic segmentation,[],r/deeplearning,False,6,,0,,False,t3_n7uqyy,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1620525617.0,text,6,,,text,bdtechtalks.com,False,,,,,https://bdtechtalks.com/2021/05/07/attendseg-deep-learning-edge-semantic-segmentation/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n7uqyy,True,,bendee983,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n7uqyy/attendseg_highperformance_ondevice_semantic/,all_ads,False,https://bdtechtalks.com/2021/05/07/attendseg-deep-learning-edge-semantic-segmentation/,66146,1620496817.0,0,,False,,,,,,,
,deeplearning,"I am building a ConvNet using Keras for classifying A and B phases in EEG signals. I have a dataset of 21984 samples (10992 of each A and B phase). I have plotted the recurrence plot for each of these samples, giving me a 2D image which is the input for my ConvNet. I am using ResNet50V2 architecture followed by fully connected using Sigmoid classifier.

The issue is, I am not able to achieve accuracy beyond 63-65%. My hyperparameters are, Batch size = 128, Nadam optimizer with a learning rate of 1e-6 and 1000 epochs that has an EarlyStopping callback with the patience of 50 epochs, monitoring the minimization of Validation Loss. I am splitting the dataset as 60% training, 20% validation, and 20% testing sets.

I need suggestions on how to improve the score. Do suggest alternative approaches for time-series classification using ConvNets",t2_aogq7hz4,False,,0,False,ConvNet for Time Series Classification,[],r/deeplearning,False,6,,0,,False,t3_n7n0ap,False,dark,0.7,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1620501077.0,text,6,,,text,self.deeplearning,True,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am building a ConvNet using Keras for classifying A and B phases in EEG signals. I have a dataset of 21984 samples (10992 of each A and B phase). I have plotted the recurrence plot for each of these samples, giving me a 2D image which is the input for my ConvNet. I am using ResNet50V2 architecture followed by fully connected using Sigmoid classifier.&lt;/p&gt;

&lt;p&gt;The issue is, I am not able to achieve accuracy beyond 63-65%. My hyperparameters are, Batch size = 128, Nadam optimizer with a learning rate of 1e-6 and 1000 epochs that has an EarlyStopping callback with the patience of 50 epochs, monitoring the minimization of Validation Loss. I am splitting the dataset as 60% training, 20% validation, and 20% testing sets.&lt;/p&gt;

&lt;p&gt;I need suggestions on how to improve the score. Do suggest alternative approaches for time-series classification using ConvNets&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n7n0ap,True,,sithtrooper24,,13,True,all_ads,False,[],False,,/r/deeplearning/comments/n7n0ap/convnet_for_time_series_classification/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n7n0ap/convnet_for_time_series_classification/,66146,1620472277.0,0,,False,,,,,,,
,deeplearning,,t2_c0p4tyk7,False,,0,False,We are researchers that work to improve Machine Learning models. If you have experience with python and/or java and a few minutes to spare please take our survey!,[],r/deeplearning,False,6,,0,,False,t3_n80l67,False,dark,0.2,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1620543214.0,text,6,,,text,usc.qualtrics.com,False,,,,,https://usc.qualtrics.com/jfe/form/SV_cHEhJ5YRoEOBwcC?Q_CHL=social&amp;Q_SocialSource=reddit,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n80l67,True,,_iordanis,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n80l67/we_are_researchers_that_work_to_improve_machine/,all_ads,False,https://usc.qualtrics.com/jfe/form/SV_cHEhJ5YRoEOBwcC?Q_CHL=social&amp;Q_SocialSource=reddit,66146,1620514414.0,0,,False,,,,,,,
,deeplearning,[deleted],t2_a22bmjyj,False,,0,False,RTX 2080 Ti on Ubuntu 18.04,[],r/deeplearning,False,6,,0,,False,t3_n7km1p,False,dark,0.63,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620490836.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[deleted]&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n7km1p,True,,RocketToTheMoonlight,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n7km1p/rtx_2080_ti_on_ubuntu_1804/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n7km1p/rtx_2080_ti_on_ubuntu_1804/,66146,1620462036.0,0,,False,,,,,,,
,deeplearning,,t2_9xwzo9vx,False,,0,False,Using AI (StyleCLIP) to Photoshop Youtubers,[],r/deeplearning,False,6,,0,,False,t3_n6xf9f,False,dark,0.89,,public,49,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/wwUD07H0pt8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Using AI to Photoshop Youtubers', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/wwUD07H0pt8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Stochastic Machine', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/wwUD07H0pt8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCWAQ2jS_jftqV65hLtxPfLA'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/wwUD07H0pt8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n6xf9f', 'height': 200}",,False,49,,False,False,,False,,[],{},,False,,1620419587.0,text,6,,,text,youtube.com,False,,,,,https://youtube.com/watch?v=wwUD07H0pt8&amp;feature=share,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n6xf9f,True,,Stochastic_Machine,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n6xf9f/using_ai_styleclip_to_photoshop_youtubers/,all_ads,False,https://youtube.com/watch?v=wwUD07H0pt8&amp;feature=share,66146,1620390787.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Using AI to Photoshop Youtubers', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/wwUD07H0pt8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Stochastic Machine', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/wwUD07H0pt8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCWAQ2jS_jftqV65hLtxPfLA'}}",False,,,,,,,
,deeplearning,"I'm in the process of building a univariate LSTM model for stock prediction but I'm stuck on how to properly scale/norm my training and test data.  Since the data is non-stationary (generally increasing trend) I cannot simply fit\_transform() a scaler on training and fit() on test because the distributions among training and test are different.  I would have high test values which wouldnt scale properly. I'm using a sliding window approach (30 day windows) predicting 1 day in the future.

Been reading into ""Adaptive Normalization"" but I'm open to ideas.

Thanks!",t2_fvyvwj1,False,,0,False,Scaling non-stationary time series data,[],r/deeplearning,False,6,,0,,False,t3_n7893q,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620448411.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m in the process of building a univariate LSTM model for stock prediction but I&amp;#39;m stuck on how to properly scale/norm my training and test data.  Since the data is non-stationary (generally increasing trend) I cannot simply fit_transform() a scaler on training and fit() on test because the distributions among training and test are different.  I would have high test values which wouldnt scale properly. I&amp;#39;m using a sliding window approach (30 day windows) predicting 1 day in the future.&lt;/p&gt;

&lt;p&gt;Been reading into &amp;quot;Adaptive Normalization&amp;quot; but I&amp;#39;m open to ideas.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n7893q,True,,Kmysiak,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n7893q/scaling_nonstationary_time_series_data/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n7893q/scaling_nonstationary_time_series_data/,66146,1620419611.0,0,,False,,,,,,,
,deeplearning,,t2_5tjqypkb,False,,0,False,High val_loss but accuracy is also high. Why?,[],r/deeplearning,False,6,,0,,False,t3_n6sb0v,False,dark,0.73,,public,13,0,{},,False,[],,False,False,,{},,False,13,,False,False,,False,,[],{},,False,,1620398635.0,text,6,,,text,reddit.com,False,,,,,https://www.reddit.com/gallery/n6sb0v,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n6sb0v,True,,Just-A-abnormal-Guy,,18,True,all_ads,False,[],False,,/r/deeplearning/comments/n6sb0v/high_val_loss_but_accuracy_is_also_high_why/,all_ads,False,https://www.reddit.com/gallery/n6sb0v,66146,1620369835.0,0,,False,,,"{'ttin3g4x9nx61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/ttin3g4x9nx61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=01712e1fffe32da6c99bea67941c0d9e120bf51a'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/ttin3g4x9nx61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d93e11d7ff0c71a07d08c47beec4838b9d5a20f9'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/ttin3g4x9nx61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2d1c3b394fa0d6387bbe16b540e022cb35365d91'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/ttin3g4x9nx61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c2c846c8f2cb2a3d858366a6c4ab276d8ebfeb48'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/ttin3g4x9nx61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=736c6ed4a130f1dc0a6be5d4676dac79eae720bc'}, {'y': 608, 'x': 1080, 'u': 'https://preview.redd.it/ttin3g4x9nx61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=db97c55e1a51b0ac6f7cbac117320ba3d3ea190f'}], 's': {'y': 608, 'x': 1080, 'u': 'https://preview.redd.it/ttin3g4x9nx61.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=019b581b1b89b248225605b4013421fe61e01745'}, 'id': 'ttin3g4x9nx61'}, '6lbkpccx9nx61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/6lbkpccx9nx61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b502c4b42326582da32c08f85d79b70e2d36b87d'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/6lbkpccx9nx61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ed8e9138b18035c4295f8736f3f888319f7ad83c'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/6lbkpccx9nx61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d30d855af092d0fbd7c65385b73e915dc4b5ecd3'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/6lbkpccx9nx61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7daf9b2e7daa84a8ca91c542b5ebcb53ea78c5ad'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/6lbkpccx9nx61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2e4bb0a49da42140a7325ad3c6a0ba4123eb5561'}, {'y': 608, 'x': 1080, 'u': 'https://preview.redd.it/6lbkpccx9nx61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=79bc20cf7208de98431855dd0cf46861ea8e6aa5'}], 's': {'y': 608, 'x': 1080, 'u': 'https://preview.redd.it/6lbkpccx9nx61.jpg?width=1080&amp;format=pjpg&amp;auto=webp&amp;s=80a5dbcf6bcb63596ddd0d044f34db3c4db9af7a'}, 'id': '6lbkpccx9nx61'}}",,,True,"{'items': [{'media_id': 'ttin3g4x9nx61', 'id': 43186332}, {'media_id': '6lbkpccx9nx61', 'id': 43186333}]}"
,deeplearning,"A research team from MIT and MIT-IBM Watson AI Lab proposes Curious Representation Learning (CRL), a framework that learns to understand the surrounding environment by training a reinforcement learning (RL) agent to maximize the error of a representation learner to gain an incentive to explore the environment.

Here is a quick read: [MIT &amp; IBM 'Curiosity' Framework Explores Embodied Environments to Learn Task-Agnostic Visual Representations.](https://syncedreview.com/2021/05/07/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-14/)

 The paper *Curious Representation Learning for Embodied Intelligence* is on [arXiv](https://arxiv.org/pdf/2105.01060.pdf).",t2_2fv4yodo,False,,0,False,[R] MIT &amp; IBM 'Curiosity' Framework Explores Embodied Environments to Learn Task-Agnostic Visual Representations,[],r/deeplearning,False,6,,0,,False,t3_n71oom,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620431525.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from MIT and MIT-IBM Watson AI Lab proposes Curious Representation Learning (CRL), a framework that learns to understand the surrounding environment by training a reinforcement learning (RL) agent to maximize the error of a representation learner to gain an incentive to explore the environment.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/07/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-14/""&gt;MIT &amp;amp; IBM &amp;#39;Curiosity&amp;#39; Framework Explores Embodied Environments to Learn Task-Agnostic Visual Representations.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Curious Representation Learning for Embodied Intelligence&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2105.01060.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n71oom,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n71oom/r_mit_ibm_curiosity_framework_explores_embodied/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n71oom/r_mit_ibm_curiosity_framework_explores_embodied/,66146,1620402725.0,0,,False,,,,,,,
,deeplearning,"Hello everyone,

Quick question: I am working on a low resource language that even large multilingual models such as [mBERT](https://huggingface.co/bert-base-multilingual-cased) fail to represent properly. So, can I fine-tune these models on MLM just like they were originally trained and then fine-tune it again on a specific task? In other words:

1. Fine-tune mBERT on the masked language modeling task (using a domain-specific corpus)
2. Fine-tune the resulting model on a different task (say semantic analysis)
3. Test the model

Does this make sense? Is this equivalent to training a BERT model from scratch using the same multilingual corpus in mBERT, with my corpus added to it, or is it different? If so, how's it different?

Thank you for your time. I really appreciate any knowledge on the matter.",t2_429oy0lo,False,,0,False,"Does this process make sense? Fine-tuning a BERT model twice, once on MLM and then a second time on a specific task",[],r/deeplearning,False,6,,0,,False,t3_n706ux,False,dark,0.63,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620427602.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;Quick question: I am working on a low resource language that even large multilingual models such as &lt;a href=""https://huggingface.co/bert-base-multilingual-cased""&gt;mBERT&lt;/a&gt; fail to represent properly. So, can I fine-tune these models on MLM just like they were originally trained and then fine-tune it again on a specific task? In other words:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Fine-tune mBERT on the masked language modeling task (using a domain-specific corpus)&lt;/li&gt;
&lt;li&gt;Fine-tune the resulting model on a different task (say semantic analysis)&lt;/li&gt;
&lt;li&gt;Test the model&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Does this make sense? Is this equivalent to training a BERT model from scratch using the same multilingual corpus in mBERT, with my corpus added to it, or is it different? If so, how&amp;#39;s it different?&lt;/p&gt;

&lt;p&gt;Thank you for your time. I really appreciate any knowledge on the matter.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n706ux,True,,le-zakkaz,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/n706ux/does_this_process_make_sense_finetuning_a_bert/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n706ux/does_this_process_make_sense_finetuning_a_bert/,66146,1620398802.0,0,,False,,,,,,,
,deeplearning,,t2_hkv9s,False,,0,False,graph2vec: Learning Distributed Representations of Graphs | ML with Graphs (Paper Walkthrough),[],r/deeplearning,False,6,,0,,False,t3_n6ud1h,False,dark,0.67,,public,3,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/h400_OMWNLo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'graph2vec: Learning Distributed Representations of Graphs | ML with Graphs (Paper Walkthrough)', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/h400_OMWNLo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/h400_OMWNLo/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}, 'type': 'youtube.com'}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/h400_OMWNLo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n6ud1h', 'height': 200}",,False,3,,False,False,,False,,[],{},,False,,1620407693.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/h400_OMWNLo,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n6ud1h,True,,prakhar21,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n6ud1h/graph2vec_learning_distributed_representations_of/,all_ads,False,https://youtu.be/h400_OMWNLo,66146,1620378893.0,0,"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'graph2vec: Learning Distributed Representations of Graphs | ML with Graphs (Paper Walkthrough)', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/h400_OMWNLo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/h400_OMWNLo/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}, 'type': 'youtube.com'}",False,,,,,,,
,deeplearning,,t2_3b2htmnk,False,,0,False,Using Deep learning for construction,[],r/deeplearning,False,6,,0,,False,t3_n743yy,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1620437714.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/n6iqjz/research_seeing_use_of_ml_for_ordinary_work_puts/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n743yy,True,,this_username_is_tkn,,0,False,all_ads,False,[],False,,/r/deeplearning/comments/n743yy/using_deep_learning_for_construction/,all_ads,False,/r/MachineLearning/comments/n6iqjz/research_seeing_use_of_ml_for_ordinary_work_puts/,66146,1620408914.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'The objective of this paper is to find an alternative to conventional method of concrete mix design. For finding the alternative, 4 machine learning algorithms viz. multi-variable linear regression, Support Vector Regression, Decision Tree Regression and Artificial Neural Network for designing concrete mix of desired properties. \n\n[original Article ](https://dx.doi.org/10.22115/scce.2021.248779.1257)', 'author_fullname': 't2_3b2htmnk', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[Research] Seeing use of ML for ordinary work puts a smile on my face.', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_n6iqjz', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.65, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1620366667.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The objective of this paper is to find an alternative to conventional method of concrete mix design. For finding the alternative, 4 machine learning algorithms viz. multi-variable linear regression, Support Vector Regression, Decision Tree Regression and Artificial Neural Network for designing concrete mix of desired properties. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://dx.doi.org/10.22115/scce.2021.248779.1257""&gt;original Article &lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'n6iqjz', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'this_username_is_tkn', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/n6iqjz/research_seeing_use_of_ml_for_ordinary_work_puts/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/n6iqjz/research_seeing_use_of_ml_for_ordinary_work_puts/', 'subreddit_subscribers': 1931385, 'created_utc': 1620337867.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_n6iqjz,,,,,
,deeplearning,,t2_40yj1u6s,False,,0,False,"SciReC2021 - Scientific Recommendation Challenge co-located at the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM BCB)",[],r/deeplearning,False,6,,0,,False,t3_n7337w,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1620435095.0,text,6,,,text,lasigebiotm.github.io,False,,,,,https://lasigebiotm.github.io/scirec2021/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n7337w,True,,fjmcouto,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n7337w/scirec2021_scientific_recommendation_challenge/,all_ads,False,https://lasigebiotm.github.io/scirec2021/,66146,1620406295.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'bioinformatics', 'selftext': '', 'author_fullname': 't2_40yj1u6s', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'SciReC2021 - Scientific Recommendation Challenge co-located at the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM BCB)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/bioinformatics', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'other', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_n1ucox', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.95, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 20, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'other', 'can_mod_post': False, 'score': 20, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1619819720.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'lasigebiotm.github.io', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://lasigebiotm.github.io/scirec2021/', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '34a39158-7f51-11e4-97cb-22000b3396c4', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh0x', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'n1ucox', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'fjmcouto', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/bioinformatics/comments/n1ucox/scirec2021_scientific_recommendation_challenge/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://lasigebiotm.github.io/scirec2021/', 'subreddit_subscribers': 65776, 'created_utc': 1619790920.0, 'num_crossposts': 5, 'media': None, 'is_video': False}]",t3_n1ucox,,,,,
,deeplearning,"This tutorial covers how to implement 5 different question-answering models with Hugging Face, along with the theory behind each model and the different datasets used to pre-train them. We'll also look at the varying baselines for each of the models in terms of F1 and EM scores.  

Topics covered include:

* The Transformer Architecture
* Popular Datasets and Evaluation Metrics
* BERT (Bidirectional Encoder Representations from Transformers)
* ALBERT: A Lite BERT
* ELECTRA
* BART
* Issues with Long Document Question-Answering Using Standard Models
* LONGFORMER: the Long-Document Transformer

Tutorial link: [https://blog.paperspace.com/question-answering-models-a-comparison/](https://blog.paperspace.com/question-answering-models-a-comparison/)

Run the full code on a free GPU: [https://ml-showcase.paperspace.com/projects/question-answering-models](https://ml-showcase.paperspace.com/projects/question-answering-models)

Questions and comments encouraged!",t2_15en0l,False,,0,False,[Tutorial] Implementing different question-answering models with Hugging Face,[],r/deeplearning,False,6,,0,,False,t3_n72vo5,False,dark,0.56,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620434559.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This tutorial covers how to implement 5 different question-answering models with Hugging Face, along with the theory behind each model and the different datasets used to pre-train them. We&amp;#39;ll also look at the varying baselines for each of the models in terms of F1 and EM scores.  &lt;/p&gt;

&lt;p&gt;Topics covered include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The Transformer Architecture&lt;/li&gt;
&lt;li&gt;Popular Datasets and Evaluation Metrics&lt;/li&gt;
&lt;li&gt;BERT (Bidirectional Encoder Representations from Transformers)&lt;/li&gt;
&lt;li&gt;ALBERT: A Lite BERT&lt;/li&gt;
&lt;li&gt;ELECTRA&lt;/li&gt;
&lt;li&gt;BART&lt;/li&gt;
&lt;li&gt;Issues with Long Document Question-Answering Using Standard Models&lt;/li&gt;
&lt;li&gt;LONGFORMER: the Long-Document Transformer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tutorial link: &lt;a href=""https://blog.paperspace.com/question-answering-models-a-comparison/""&gt;https://blog.paperspace.com/question-answering-models-a-comparison/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Run the full code on a free GPU: &lt;a href=""https://ml-showcase.paperspace.com/projects/question-answering-models""&gt;https://ml-showcase.paperspace.com/projects/question-answering-models&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Questions and comments encouraged!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n72vo5,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n72vo5/tutorial_implementing_different_questionanswering/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n72vo5/tutorial_implementing_different_questionanswering/,66146,1620405759.0,0,,False,,,,,,,
,deeplearning,"doing an art project on memories and want to want to use perhaps some ai software like stylegan(welcome to any suggestions) to merge faces together to create a weird outcomes, if u peeps could point me in the right direction for any tutorial, link, websites or methods.bearing in mind i am using a mac operating system which seem like it might be a bit of a hinderance. but anyway all the best, if anybody could help out it would be very much appreciated",t2_4k3v0ypf,False,,0,False,stylegan art,[],r/deeplearning,False,6,,0,,False,t3_n70j82,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620428503.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;doing an art project on memories and want to want to use perhaps some ai software like stylegan(welcome to any suggestions) to merge faces together to create a weird outcomes, if u peeps could point me in the right direction for any tutorial, link, websites or methods.bearing in mind i am using a mac operating system which seem like it might be a bit of a hinderance. but anyway all the best, if anybody could help out it would be very much appreciated&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n70j82,True,,jdpdatzme,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n70j82/stylegan_art/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n70j82/stylegan_art/,66146,1620399703.0,0,,False,,,,,,,
,deeplearning,"Hi all, 

I'm a PhD student and I've got some funding to put together a machine for ML/DL. My lab currently has a pretty powerful machine....or at least it was pretty powerful about 10 years ago. I'm wondering whether I can just upgrade a couple of components on it to make it fit for purpose or whether I'm better off just trying to spec out a whole new machine. 

These are the current specs:

* Dual Xeon e5-2670
* 256GB RAM (I'm going to assume DDR3) - I'm not actually in the lab to check.
* Quatro FX 5800

I'm wondering can I just get away with updating the GPU to something like a 3080? If I get a new machine there's no way (I don't think) I'll have the budget to match the RAM amount and get a decent GPU inside it.   


Or would I be better off spending the extra cash to get less but newer faster RAM, more up-to-date CPU, and a better GPU? If money was no object I'd obviously just a new machine, but I'm trying to be cost-efficient.",t2_2t7g6k8t,False,,0,False,Updating an old machine for Deep Learning,[],r/deeplearning,False,6,,0,,False,t3_n6wd3a,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620415894.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, &lt;/p&gt;

&lt;p&gt;I&amp;#39;m a PhD student and I&amp;#39;ve got some funding to put together a machine for ML/DL. My lab currently has a pretty powerful machine....or at least it was pretty powerful about 10 years ago. I&amp;#39;m wondering whether I can just upgrade a couple of components on it to make it fit for purpose or whether I&amp;#39;m better off just trying to spec out a whole new machine. &lt;/p&gt;

&lt;p&gt;These are the current specs:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Dual Xeon e5-2670&lt;/li&gt;
&lt;li&gt;256GB RAM (I&amp;#39;m going to assume DDR3) - I&amp;#39;m not actually in the lab to check.&lt;/li&gt;
&lt;li&gt;Quatro FX 5800&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;#39;m wondering can I just get away with updating the GPU to something like a 3080? If I get a new machine there&amp;#39;s no way (I don&amp;#39;t think) I&amp;#39;ll have the budget to match the RAM amount and get a decent GPU inside it.   &lt;/p&gt;

&lt;p&gt;Or would I be better off spending the extra cash to get less but newer faster RAM, more up-to-date CPU, and a better GPU? If money was no object I&amp;#39;d obviously just a new machine, but I&amp;#39;m trying to be cost-efficient.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n6wd3a,True,,Molem7b5,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n6wd3a/updating_an_old_machine_for_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n6wd3a/updating_an_old_machine_for_deep_learning/,66146,1620387094.0,0,,False,,,,,,,
,deeplearning,"I have coded ""Global, unstructured &amp; iterative"" pruning using ResNet-18 trained from scratch on CIFAR-10 dataset in PyTorch. You can refer to the code [here](https://github.com/arjun-majumdar/Neural_Network_Pruning/blob/main/ResNet18_Global_Pruning.ipynb). Let me know your comments/thoughts.

Cheers!",t2_2mmql89p,False,,0,False,ResNet-18 Pruning PyTorch,[],r/deeplearning,False,6,,0,,False,t3_n6v0ez,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620410571.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have coded &amp;quot;Global, unstructured &amp;amp; iterative&amp;quot; pruning using ResNet-18 trained from scratch on CIFAR-10 dataset in PyTorch. You can refer to the code &lt;a href=""https://github.com/arjun-majumdar/Neural_Network_Pruning/blob/main/ResNet18_Global_Pruning.ipynb""&gt;here&lt;/a&gt;. Let me know your comments/thoughts.&lt;/p&gt;

&lt;p&gt;Cheers!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n6v0ez,True,,grid_world,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n6v0ez/resnet18_pruning_pytorch/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n6v0ez/resnet18_pruning_pytorch/,66146,1620381771.0,0,,False,,,,,,,
,deeplearning,,t2_7gb16qup,False,,0,False,Synthetic Data generation in Sky Engine AI – Deep Learning in Virtual Reality Platform for Data Scientists and Software Engineers. PyTorch and TensorFlow supported and soon MindSpore ready. Edge cases can be easily covered with physics-based simulated data.,[],r/deeplearning,False,6,,0,,False,t3_n6jre7,False,dark,0.73,,public,5,0,{},,False,[],"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/z9i5kjotukx61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/z9i5kjotukx61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/z9i5kjotukx61/DASHPlaylist.mpd?a=1626449948%2CMmNiMDZhYmU0OGZkZjVhZjJmOGEyMGU2ZDE0YWU2YWQwMTg3YzVhYWM0ZGNhZTBjNWFjMzBhYzVkZWUxYTJhMg%3D%3D&amp;v=1&amp;f=sd', 'duration': 66, 'hls_url': 'https://v.redd.it/z9i5kjotukx61/HLSPlaylist.m3u8?a=1626449948%2CNGI4ZDkyNjdkZmU4YTA5NGFhOWE4MGY1NDViZjE0NTc1YWMzMGM3N2QyM2FkMTU5NDk5MjI2Y2NiYzRmNDQ2OA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,5,,False,False,,False,,[],{},,False,,1620369487.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/z9i5kjotukx61,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n6jre7,True,,SkyEngineAI_BW,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n6jre7/synthetic_data_generation_in_sky_engine_ai_deep/,all_ads,False,https://v.redd.it/z9i5kjotukx61,66146,1620340687.0,0,"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/z9i5kjotukx61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/z9i5kjotukx61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/z9i5kjotukx61/DASHPlaylist.mpd?a=1626449948%2CMmNiMDZhYmU0OGZkZjVhZjJmOGEyMGU2ZDE0YWU2YWQwMTg3YzVhYWM0ZGNhZTBjNWFjMzBhYzVkZWUxYTJhMg%3D%3D&amp;v=1&amp;f=sd', 'duration': 66, 'hls_url': 'https://v.redd.it/z9i5kjotukx61/HLSPlaylist.m3u8?a=1626449948%2CNGI4ZDkyNjdkZmU4YTA5NGFhOWE4MGY1NDViZjE0NTc1YWMzMGM3N2QyM2FkMTU5NDk5MjI2Y2NiYzRmNDQ2OA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,"Hi all,

I have recently started blogging and as initial attempt, I tried to write on domain adaptation. Kindly have a read of you are interested in the topic.
Follow us on medium to know about more such topics
 https://medium.com/@AandE/understanding-domain-adaptation-5baa723ac71f",t2_3n79n5eg,False,,0,False,"Wanted to understand what is domain adaptation, but never got a good article?",[],r/deeplearning,False,6,,0,,False,t3_n6eyxz,False,dark,0.77,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,1620359845.0,,[],{},,True,,1620356938.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all,&lt;/p&gt;

&lt;p&gt;I have recently started blogging and as initial attempt, I tried to write on domain adaptation. Kindly have a read of you are interested in the topic.
Follow us on medium to know about more such topics
 &lt;a href=""https://medium.com/@AandE/understanding-domain-adaptation-5baa723ac71f""&gt;https://medium.com/@AandE/understanding-domain-adaptation-5baa723ac71f&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n6eyxz,True,,harsh-99,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n6eyxz/wanted_to_understand_what_is_domain_adaptation/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n6eyxz/wanted_to_understand_what_is_domain_adaptation/,66146,1620328138.0,0,,False,,,,,,,
,deeplearning,,t2_l6ugg,False,,0,False,"AI in Finance - 5 Industry-Leading Presentations - New presentations from AI leaders at J.P.Morgan x 2, Nasdaq, Vanguard &amp; Scotiabank. Topics covered include pattern recognition, NLP, ML, mondrian models, fund2vec &amp; more.",[],r/deeplearning,False,6,,0,,False,t3_n64uht,False,dark,0.87,,public,26,0,{},,False,[],,False,False,,{},,False,26,,False,False,,False,,[],{},,False,,1620328392.0,text,6,,,text,blog.re-work.co,False,,,,,https://blog.re-work.co/ai-in-finance-5-key-industry-trends-2021/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n64uht,True,,nikitaljohnson,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n64uht/ai_in_finance_5_industryleading_presentations_new/,all_ads,False,https://blog.re-work.co/ai-in-finance-5-key-industry-trends-2021/,66146,1620299592.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'compsci', 'selftext': '', 'author_fullname': 't2_l6ugg', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'AI in Finance - 5 Industry-Leading Presentations - New presentations from AI leaders at J.P.Morgan x 2, Nasdaq, Vanguard &amp; Scotiabank. Topics covered include pattern recognition, NLP, ML, mondrian models, fund2vec &amp; more.', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/compsci', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_n64rif', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.86, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 25, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 25, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1620328044.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'blog.re-work.co', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://blog.re-work.co/ai-in-finance-5-key-industry-trends-2021/', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qhmr', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'n64rif', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'nikitaljohnson', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/compsci/comments/n64rif/ai_in_finance_5_industryleading_presentations_new/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://blog.re-work.co/ai-in-finance-5-key-industry-trends-2021/', 'subreddit_subscribers': 1455293, 'created_utc': 1620299244.0, 'num_crossposts': 9, 'media': None, 'is_video': False}]",t3_n64rif,,,,,
,deeplearning,"Hey everyone,

A friend and I developed [Nimbo](https://nimbo.sh), a dead-simple CLI that wraps the AWS CLI, allowing you to run code on AWS as if you were running it locally. You can find the source code here ([https://github.com/nimbo-sh/nimbo](https://github.com/nimbo-sh/nimbo)) and the docs here ([https://docs.nimbo.sh](https://docs.nimbo.sh/)).

We decided to build this because we were frustrated with how cumbersome using AWS was, and we just wanted to be able to run jobs on AWS as easily as we run them locally. At the same time, we wanted to make use of the cheap spot instances (on Nimbo, this is a single parameter). All in all, we didn't like the current user experience of working with AWS, and we believed it was possible to vastly improve it.

For this reason, we also provide many useful commands to make it faster and easier to work with AWS, such as launching notebooks on EC2, easily checking prices, logging onto an instance, or syncing data to/from S3 (you can see some useful commands at [https://docs.nimbo.sh/useful-commands](https://docs.nimbo.sh/useful-commands)).

Unlike other similar services, we are solely client-side, meaning that the code runs on your EC2 instances and data is stored in your S3 buckets (we don't have a server; all the infrastructure orchestration happens in the Nimbo package). We are also open contribution, meaning that all the source code is publicly available on our GitHub, and we welcome community contribution.

We have tons of ideas for Nimbo, like adding docker support, and providing instances with preloaded datasets like ImageNet, so that you don't have to download and store it yourself - you simply spin the instance, and the dataset is available at /datasets. We are currently working on adding GCP support, so that you can use AWS or GCP with the same config file.

We are happy to receive any feedback and suggestions you have.",t2_6y9zu6h8,False,,0,False,Train neural networks on AWS with a single command,[],r/deeplearning,False,6,,0,,False,t3_n64bbx,False,dark,0.85,,public,27,0,{},,False,[],,False,False,,{},,False,27,,False,False,,False,,[],{},,True,,1620326249.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;

&lt;p&gt;A friend and I developed &lt;a href=""https://nimbo.sh""&gt;Nimbo&lt;/a&gt;, a dead-simple CLI that wraps the AWS CLI, allowing you to run code on AWS as if you were running it locally. You can find the source code here (&lt;a href=""https://github.com/nimbo-sh/nimbo""&gt;https://github.com/nimbo-sh/nimbo&lt;/a&gt;) and the docs here (&lt;a href=""https://docs.nimbo.sh/""&gt;https://docs.nimbo.sh&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;We decided to build this because we were frustrated with how cumbersome using AWS was, and we just wanted to be able to run jobs on AWS as easily as we run them locally. At the same time, we wanted to make use of the cheap spot instances (on Nimbo, this is a single parameter). All in all, we didn&amp;#39;t like the current user experience of working with AWS, and we believed it was possible to vastly improve it.&lt;/p&gt;

&lt;p&gt;For this reason, we also provide many useful commands to make it faster and easier to work with AWS, such as launching notebooks on EC2, easily checking prices, logging onto an instance, or syncing data to/from S3 (you can see some useful commands at &lt;a href=""https://docs.nimbo.sh/useful-commands""&gt;https://docs.nimbo.sh/useful-commands&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Unlike other similar services, we are solely client-side, meaning that the code runs on your EC2 instances and data is stored in your S3 buckets (we don&amp;#39;t have a server; all the infrastructure orchestration happens in the Nimbo package). We are also open contribution, meaning that all the source code is publicly available on our GitHub, and we welcome community contribution.&lt;/p&gt;

&lt;p&gt;We have tons of ideas for Nimbo, like adding docker support, and providing instances with preloaded datasets like ImageNet, so that you don&amp;#39;t have to download and store it yourself - you simply spin the instance, and the dataset is available at /datasets. We are currently working on adding GCP support, so that you can use AWS or GCP with the same config file.&lt;/p&gt;

&lt;p&gt;We are happy to receive any feedback and suggestions you have.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n64bbx,True,,seuqaj114,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/n64bbx/train_neural_networks_on_aws_with_a_single_command/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n64bbx/train_neural_networks_on_aws_with_a_single_command/,66146,1620297449.0,0,,False,,,,,,,
,deeplearning,"Hey folks! Please help support us by reviewing our post our Product Hunt!    🥳 **😃** 🥳  

[https://www.producthunt.com/posts/open-source-ai-ml-data-annotation](https://www.producthunt.com/posts/open-source-ai-ml-data-annotation)",t2_ospzt,False,,0,False,😃🎉 Open source AI/ML data annotation platform for Free [Product Hunt],[],r/deeplearning,False,6,,0,,False,t3_n6cz6q,False,dark,0.56,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620351813.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey folks! Please help support us by reviewing our post our Product Hunt!    🥳 &lt;strong&gt;😃&lt;/strong&gt; 🥳  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.producthunt.com/posts/open-source-ai-ml-data-annotation""&gt;https://www.producthunt.com/posts/open-source-ai-ml-data-annotation&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n6cz6q,True,,a-789,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n6cz6q/open_source_aiml_data_annotation_platform_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n6cz6q/open_source_aiml_data_annotation_platform_for/,66146,1620323013.0,0,,False,,,,,,,
,deeplearning," I'm training a mask r cnn model to detect 13 class. When I'm testing the model, I get the following error: \*\*\* No instances to display \*\*\* .

I tried this changes:

    &gt; utils.py line 866: shift = np.array ([0, 0, 1, 1]) to shift = np.array ([0, 0, 1., 1.]);
    
    &gt; downgrade scipy to 1.2.3 version;
    
    &gt; set model.load_weights(weights_path, by_name=True, exclude=[""mrcnn_class_logits"", ""mrcnn_bbox_fc"", ""mrcnn_bbox"", ""mrcnn_mask""]) ;
    
    &gt;  from __future__ import division

 

Sometimes them work, other times they don't.

I have another question: I have 21 classes but i want to clasify only 13 of them. My goals are:

* detect this 13 classes inside a specif area (like a truck), how can I do this?
* i would like to predict all items in a single image in maximum 1 second, how can I do this?

Thanks all.",t2_3zwz9769,False,,0,False,*** No instances to display *** on Google Colab,[],r/deeplearning,False,6,,0,,False,t3_n68yqb,False,dark,0.64,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1620341270.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m training a mask r cnn model to detect 13 class. When I&amp;#39;m testing the model, I get the following error: *** No instances to display *** .&lt;/p&gt;

&lt;p&gt;I tried this changes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; utils.py line 866: shift = np.array ([0, 0, 1, 1]) to shift = np.array ([0, 0, 1., 1.]);

&amp;gt; downgrade scipy to 1.2.3 version;

&amp;gt; set model.load_weights(weights_path, by_name=True, exclude=[&amp;quot;mrcnn_class_logits&amp;quot;, &amp;quot;mrcnn_bbox_fc&amp;quot;, &amp;quot;mrcnn_bbox&amp;quot;, &amp;quot;mrcnn_mask&amp;quot;]) ;

&amp;gt;  from __future__ import division
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sometimes them work, other times they don&amp;#39;t.&lt;/p&gt;

&lt;p&gt;I have another question: I have 21 classes but i want to clasify only 13 of them. My goals are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;detect this 13 classes inside a specif area (like a truck), how can I do this?&lt;/li&gt;
&lt;li&gt;i would like to predict all items in a single image in maximum 1 second, how can I do this?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thanks all.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n68yqb,True,,Dario_Della,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n68yqb/no_instances_to_display_on_google_colab/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n68yqb/no_instances_to_display_on_google_colab/,66146,1620312470.0,0,,False,,,,,,,
,deeplearning,"Hi, beginner in deeplearning here, so if my question seems odd, please apologize.

I wanted to do a land use classification using a CNN. For my training data, I have access to normal RGB satellite imagery and CIR imagery. The question is, can I mix both? My first guess was no, since my network would learn that f.ex. trees are green pixels in RGB, and red pixels in CIR, so it would become confused with lets say a rooftop, which is also a red pixel (in both RGB and CIR)

Am I getting this right or can I just feed both types of images into the network?

Thanks!

Edit: For reference, I attched an image of an RGB/CIR image pair (not related to my own data, just for those who might not know the difference) 

&amp;#x200B;

https://preview.redd.it/6zhm0wxjkix61.png?width=850&amp;format=png&amp;auto=webp&amp;s=eacf2e84f9ca588dba79e3b4b75b7f64fb957e6e",t2_q5ifzne,False,,0,False,Land use classification with RGB and CIR imagery mixed?,[],r/deeplearning,False,6,,0,,False,t3_n691vi,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,1620312883.0,,[],{},,True,,1620341492.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, beginner in deeplearning here, so if my question seems odd, please apologize.&lt;/p&gt;

&lt;p&gt;I wanted to do a land use classification using a CNN. For my training data, I have access to normal RGB satellite imagery and CIR imagery. The question is, can I mix both? My first guess was no, since my network would learn that f.ex. trees are green pixels in RGB, and red pixels in CIR, so it would become confused with lets say a rooftop, which is also a red pixel (in both RGB and CIR)&lt;/p&gt;

&lt;p&gt;Am I getting this right or can I just feed both types of images into the network?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;

&lt;p&gt;Edit: For reference, I attched an image of an RGB/CIR image pair (not related to my own data, just for those who might not know the difference) &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/6zhm0wxjkix61.png?width=850&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eacf2e84f9ca588dba79e3b4b75b7f64fb957e6e""&gt;https://preview.redd.it/6zhm0wxjkix61.png?width=850&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eacf2e84f9ca588dba79e3b4b75b7f64fb957e6e&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n691vi,True,,AlbrechtWallenstein,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n691vi/land_use_classification_with_rgb_and_cir_imagery/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n691vi/land_use_classification_with_rgb_and_cir_imagery/,66146,1620312692.0,0,,False,,,"{'6zhm0wxjkix61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 35, 'x': 108, 'u': 'https://preview.redd.it/6zhm0wxjkix61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c1e65973a58c3b9926cdbb01e480d4952c023179'}, {'y': 70, 'x': 216, 'u': 'https://preview.redd.it/6zhm0wxjkix61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ffa91fe8c7bd308f0149f6042ba83fba338a6045'}, {'y': 104, 'x': 320, 'u': 'https://preview.redd.it/6zhm0wxjkix61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d0b03853863e0eeb0dc96e592387e772c6df22eb'}, {'y': 208, 'x': 640, 'u': 'https://preview.redd.it/6zhm0wxjkix61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ab99876b2ca4c51c0aea58d8c2e63d605edcdc34'}], 's': {'y': 277, 'x': 850, 'u': 'https://preview.redd.it/6zhm0wxjkix61.png?width=850&amp;format=png&amp;auto=webp&amp;s=eacf2e84f9ca588dba79e3b4b75b7f64fb957e6e'}, 'id': '6zhm0wxjkix61'}}",,,,
,deeplearning,"# [StyleGAN2 Distillation for Feed-forward Image Manipulation](https://t.me/casual_gan/34)

In this paper from October, 2020 the authors propose a pipeline to discover semantic editing directions in StyleGAN in an unsupervised way, gather a paired synthetic dataset using these directions, and use it to train a light Image2Image model that can perform one specific edit (add a smile, change hair color, etc) on any new image with a single forward pass. If you are not familiar with this paper, check out the [5 minute summary](https://t.me/casual_gan/34).

[Samples from the model](https://preview.redd.it/vca8jtqp8ix61.png?width=1280&amp;format=png&amp;auto=webp&amp;s=81a9e58acc8119e1b3f7323b4188db895a0e43f9)

\[[Arxiv](https://arxiv.org/abs/2003.03581)\]\[[paper explanained in 5 minutes](https://t.me/casual_gan/34)\]",t2_hhio3,False,,0,False,[D] StyleGAN2 Distillation for Feed-forward Image Manipulation. How to gender swap Harry-Potter and easily edit any image explained!,[],r/deeplearning,False,6,,0,,False,t3_n67orr,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620337701.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h1&gt;&lt;a href=""https://t.me/casual_gan/34""&gt;StyleGAN2 Distillation for Feed-forward Image Manipulation&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;In this paper from October, 2020 the authors propose a pipeline to discover semantic editing directions in StyleGAN in an unsupervised way, gather a paired synthetic dataset using these directions, and use it to train a light Image2Image model that can perform one specific edit (add a smile, change hair color, etc) on any new image with a single forward pass. If you are not familiar with this paper, check out the &lt;a href=""https://t.me/casual_gan/34""&gt;5 minute summary&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/vca8jtqp8ix61.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81a9e58acc8119e1b3f7323b4188db895a0e43f9""&gt;Samples from the model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://arxiv.org/abs/2003.03581""&gt;Arxiv&lt;/a&gt;][&lt;a href=""https://t.me/casual_gan/34""&gt;paper explanained in 5 minutes&lt;/a&gt;]&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n67orr,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n67orr/d_stylegan2_distillation_for_feedforward_image/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n67orr/d_stylegan2_distillation_for_feedforward_image/,66146,1620308901.0,0,,False,,,"{'vca8jtqp8ix61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 54, 'x': 108, 'u': 'https://preview.redd.it/vca8jtqp8ix61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=03faf97beaec66bc648c1608daaf083519636948'}, {'y': 109, 'x': 216, 'u': 'https://preview.redd.it/vca8jtqp8ix61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=717c36de07ddb248a0ad42ddccaa0a9445ab3674'}, {'y': 161, 'x': 320, 'u': 'https://preview.redd.it/vca8jtqp8ix61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e2d0be884dd6a6fc2b898a0ca24ba52ef18544eb'}, {'y': 323, 'x': 640, 'u': 'https://preview.redd.it/vca8jtqp8ix61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e83dfa09e68cbf6653a8bb77c747ca179729e347'}, {'y': 485, 'x': 960, 'u': 'https://preview.redd.it/vca8jtqp8ix61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e163fbcd94e93c32b3f0f425ee7484b94dc66ecd'}, {'y': 545, 'x': 1080, 'u': 'https://preview.redd.it/vca8jtqp8ix61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ad685fa1c54da4e15015547ffc9af43bc5aa8399'}], 's': {'y': 647, 'x': 1280, 'u': 'https://preview.redd.it/vca8jtqp8ix61.png?width=1280&amp;format=png&amp;auto=webp&amp;s=81a9e58acc8119e1b3f7323b4188db895a0e43f9'}, 'id': 'vca8jtqp8ix61'}}",,,,
,deeplearning,"I've finished Andrew Ng's Machine learning course and two of his courses in the Deep learning specialization. I understand neural networks, backpropagation, and have a rudimentary grasp of CNNs and RNNs.

Should I read the book Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville before getting started on reading research papers?

Thank you so much for your advice!",t2_4jq5sigm,False,,0,False,Book Before Papers?,[],r/deeplearning,False,6,,0,,False,t3_n5va3v,False,dark,0.91,,public,9,0,{},,False,[],,False,False,,{},,False,9,,False,False,,False,,[],{},,True,,1620291063.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve finished Andrew Ng&amp;#39;s Machine learning course and two of his courses in the Deep learning specialization. I understand neural networks, backpropagation, and have a rudimentary grasp of CNNs and RNNs.&lt;/p&gt;

&lt;p&gt;Should I read the book Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville before getting started on reading research papers?&lt;/p&gt;

&lt;p&gt;Thank you so much for your advice!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5va3v,True,,pottojam,,10,True,all_ads,False,[],False,,/r/deeplearning/comments/n5va3v/book_before_papers/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n5va3v/book_before_papers/,66146,1620262263.0,0,,False,,,,,,,
,deeplearning,"A research team from Facebook AI conducts a large-scale study on unsupervised spatiotemporal representation learning from videos. The work takes a unified perspective on four recent image-based frameworks (MoCo, SimCLR, BYOL, SwAV) and investigates a simple objective that can easily generalize unsupervised representation learning methodologies to space-time.

Here is a quick read: [Facebook AI Conducts Large-Scale Study on Unsupervised Spatiotemporal Representation Learning.](https://syncedreview.com/2021/05/06/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-13/)

 The paper *A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning* is on [arXiv](https://arxiv.org/pdf/2104.14558.pdf).",t2_2fv4yodo,False,,0,False,[R] Facebook AI Conducts Large-Scale Study on Unsupervised Spatiotemporal Representation Learning,[],r/deeplearning,False,6,,0,,False,t3_n69f1i,False,dark,0.25,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620342432.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Facebook AI conducts a large-scale study on unsupervised spatiotemporal representation learning from videos. The work takes a unified perspective on four recent image-based frameworks (MoCo, SimCLR, BYOL, SwAV) and investigates a simple objective that can easily generalize unsupervised representation learning methodologies to space-time.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/06/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-13/""&gt;Facebook AI Conducts Large-Scale Study on Unsupervised Spatiotemporal Representation Learning.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.14558.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n69f1i,True,,Yuqing7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n69f1i/r_facebook_ai_conducts_largescale_study_on/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n69f1i/r_facebook_ai_conducts_largescale_study_on/,66146,1620313632.0,0,,False,,,,,,,
,deeplearning,"
## 200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support in  NLU 3.0 Release and much more
We are incredibly excited to announce the release of `NLU 3.0.0` which makes most of John Snow Labs medical healthcare model available in just 1 line of code in NLU.
These models are the most accurate in their domains and highly scalable in Spark clusters.  
In addition, `Spark 3.0.X`  and `Spark 3.1.X ` is now supported, together with Python3.8

This is enabled by the amazing [Spark NLP3.0.1](https://nlp.johnsnowlabs.com/docs/en/release_notes#300) and [Spark NLP for Healthcare 3.0.1](https://nlp.johnsnowlabs.com/docs/en/licensed_release_notes#301) releases.

# New Features
- Over 200 new models for the `healthcare` domain
- 6 new classes of models, Assertion, Sentence/Chunk Resolvers, Relation Extractors, Medical NER models, De-Identificator Models
- Spark 3.0.X and 3.1.X support
- Python 3.8 Support
- New Output level `relation`
- 1 Line to install NLU  just run `!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash`
- [Various new EMR and Databricks versions supported](https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.0.0)
- GPU Mode, more then 600% speedup by enabling GPU mode.
- Authorized mode for licensed features

## New Documentation
- [NLU for Healthcare Examples](https://nlu.johnsnowlabs.com/docs/en/examples_hc#usage-examples-of-nluload)
- [Instrunctions to authorize your environment to use Licensed features](https://nlu.johnsnowlabs.com/docs/en/examples_hc#authorize-access-to-licensed-features-and-install-healthcare-dependencies)


## New Notebooks
- [Medical Named Entity Extraction (NER) notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/medical_named_entity_recognition/overview_medical_entity_recognizers.ipynb)
- [Relation extraction notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/relation_extraction/overview_relation.ipynb)
- [Entity Resolution overview notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/entity_resolution/entity_resolvers_overview.ipynb)
- [Assertion overview notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/assertion/assertion_overview.ipynb)
- [De-Identification overview notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/de_identification/DeIdentification_model_overview.ipynb)
- [Graph NLU tutorial](https://github.com/JohnSnowLabs/nlu/blob/3.0rc1/examples/webinars_conferences_etc/graph_ai_summit/Healthcare_Graph_NLU_COVID_Tigergraph.ipynb)


## AssertionDLModels

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [assert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html) | [assertion_dl](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html)                   |
| English  | [assert.biobert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html) | [assertion_dl_biobert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html)                   |
| English  | [assert.healthcare](https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html) | [assertion_dl_healthcare](https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html)                   |
| English  | [assert.large](https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html) | [assertion_dl_large](https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html)                   |

##  New Word Embeddings

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [embed.glove.clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html) | [embeddings_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html)                   |
| English  | [embed.glove.biovec](https://nlp.johnsnowlabs.com/2020/06/02/embeddings_biovec_en.html) | [embeddings_biovec](https://nlp.johnsnowlabs.com/2020/06/02/embeddings_biovec_en.html)                   |
| English  | [embed.glove.healthcare](https://nlp.johnsnowlabs.com/2020/03/26/embeddings_healthcare_en.html) | [embeddings_healthcare](https://nlp.johnsnowlabs.com/2020/03/26/embeddings_healthcare_en.html)                   |
| English  | [embed.glove.healthcare_100d](https://nlp.johnsnowlabs.com/2020/05/29/embeddings_healthcare_100d_en.html) | [embeddings_healthcare_100d](https://nlp.johnsnowlabs.com/2020/05/29/embeddings_healthcare_100d_en.html)                   |
| English  | en.embed.glove.icdoem | embeddings_icdoem          |
| English  | en.embed.glove.icdoem_2ng | embeddings_icdoem_2ng          |

## Sentence Entity resolvers

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | embed_sentence.biobert.mli | sbiobert_base_cased_mli          |
| English  | resolve | sbiobertresolve_cpt          |
| English  | resolve.cpt | sbiobertresolve_cpt          |
| English  | resolve.cpt.augmented | sbiobertresolve_cpt_augmented          |
| English  | resolve.cpt.procedures_augmented | sbiobertresolve_cpt_procedures_augmented          |
| English  | resolve.hcc.augmented | sbiobertresolve_hcc_augmented          |
| English  | [resolve.icd10cm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html) | [sbiobertresolve_icd10cm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html)                   |
| English  | [resolve.icd10cm.augmented](https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html) | [sbiobertresolve_icd10cm_augmented](https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html)                   |
| English  | [resolve.icd10cm.augmented_billable](https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html) | [sbiobertresolve_icd10cm_augmented_billable_hcc](https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html)                   |
| English  | [resolve.icd10pcs](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html) | [sbiobertresolve_icd10pcs](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html)                   |
| English  | [resolve.icdo](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html) | [sbiobertresolve_icdo](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html)                   |
| English  | [resolve.rxcui](https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html) | [sbiobertresolve_rxcui](https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html)                   |
| English  | [resolve.rxnorm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html) | [sbiobertresolve_rxnorm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html)                   |
| English  | [resolve.snomed](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html) | [sbiobertresolve_snomed_auxConcepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html)                   |
| English  | [resolve.snomed.aux_concepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html) | [sbiobertresolve_snomed_auxConcepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html)                   |
| English  | [resolve.snomed.aux_concepts_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html) | [sbiobertresolve_snomed_auxConcepts_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html)                   |
| English  | [resolve.snomed.findings](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html) | [sbiobertresolve_snomed_findings](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html)                   |
| English  | [resolve.snomed.findings_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html) | [sbiobertresolve_snomed_findings_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html)                   |

## RelationExtractionModel

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | relation.posology | posology_re          |
| English  | [relation](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html) | [redl_bodypart_direction_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html)                   |
| English  | [relation.bodypart.direction](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html) | [redl_bodypart_direction_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html)                   |
| English  | [relation.bodypart.problem](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_problem_biobert_en.html) | [redl_bodypart_problem_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_problem_biobert_en.html)                   |
| English  | [relation.bodypart.procedure](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_procedure_test_biobert_en.html) | [redl_bodypart_procedure_test_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_procedure_test_biobert_en.html)                   |
| English  | [relation.chemprot](https://nlp.johnsnowlabs.com/2021/02/04/redl_chemprot_biobert_en.html) | [redl_chemprot_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_chemprot_biobert_en.html)                   |
| English  | [relation.clinical](https://nlp.johnsnowlabs.com/2021/02/04/redl_clinical_biobert_en.html) | [redl_clinical_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_clinical_biobert_en.html)                   |
| English  | [relation.date](https://nlp.johnsnowlabs.com/2021/02/04/redl_date_clinical_biobert_en.htmls) | [redl_date_clinical_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_date_clinical_biobert_en.htmls)                   |
| English  | [relation.drug_drug_interaction](https://nlp.johnsnowlabs.com/2021/02/04/redl_drug_drug_interaction_biobert_en.html) | [redl_drug_drug_interaction_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_drug_drug_interaction_biobert_en.html)                   |
| English  | [relation.humen_phenotype_gene](https://nlp.johnsnowlabs.com/2021/02/04/redl_human_phenotype_gene_biobert_en.html) | [redl_human_phenotype_gene_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_human_phenotype_gene_biobert_en.html)                   |
| English  | [relation.temporal_events](https://nlp.johnsnowlabs.com/2021/02/04/redl_temporal_events_biobert_en.html) | [redl_temporal_events_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_temporal_events_biobert_en.html)                   |



## NERDLModels

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
|English  | [med_ner.ade.clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinical_en.html) | [ner_ade_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinical_en.html)                   |
| English  | [med_ner.ade.clinical_bert](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinicalbert_en.html) | [ner_ade_clinicalbert](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinicalbert_en.html)                   |
| English  | [med_ner.ade.ade_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_healthcare_en.html) | [ner_ade_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_healthcare_en.html)                   |
| English  | [med_ner.anatomy](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_en.html) | [ner_anatomy](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_en.html)                   |
| English  | [med_ner.anatomy.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_anatomy_biobert_en.html) | [ner_anatomy_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_anatomy_biobert_en.html)                   |
| English  | [med_ner.anatomy.coarse](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html) | [ner_anatomy_coarse](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html)                   |
| English  | [med_ner.anatomy.coarse_biobert](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_biobert_en.html) | [ner_anatomy_coarse_biobert](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_biobert_en.html)                   |
| English  | [med_ner.aspect_sentiment](https://nlp.johnsnowlabs.com/2021/03/31/ner_aspect_based_sentiment_en.html) | [ner_aspect_based_sentiment](https://nlp.johnsnowlabs.com/2021/03/31/ner_aspect_based_sentiment_en.html)                   |
| English  | [med_ner.bacterial_species](https://nlp.johnsnowlabs.com/2021/04/01/ner_bacterial_species_en.html) | [ner_bacterial_species](https://nlp.johnsnowlabs.com/2021/04/01/ner_bacterial_species_en.html)                   |
| English  | [med_ner.bionlp](https://nlp.johnsnowlabs.com/2021/03/31/ner_bionlp_en.html) | [ner_bionlp](https://nlp.johnsnowlabs.com/2021/03/31/ner_bionlp_en.html)                   |
| English  | [med_ner.bionlp.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_bionlp_biobert_en.html) | [ner_bionlp_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_bionlp_biobert_en.html)                   |
| English  | [med_ner.cancer](https://nlp.johnsnowlabs.com/2021/03/31/ner_cancer_genetics_en.html) | [ner_cancer_genetics](https://nlp.johnsnowlabs.com/2021/03/31/ner_cancer_genetics_en.html)                   |
| Englishs | [med_ner.cellular](https://nlp.johnsnowlabs.com/2021/03/31/ner_cellular_en.html) | [ner_cellular](https://nlp.johnsnowlabs.com/2021/03/31/ner_cellular_en.html)                   |
| English  | [med_ner.cellular.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_cellular_biobert_en.html) | [ner_cellular_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_cellular_biobert_en.html)                   |
| English  | [med_ner.chemicals](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemicals_en.html) | [ner_chemicals](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemicals_en.html)                   |
| English  | [med_ner.chemprot](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemprot_biobert_en.html) | [ner_chemprot_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemprot_biobert_en.html)           |
| English  | [med_ner.chemprot.clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_chemprot_clinical_en.html) | [ner_chemprot_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_chemprot_clinical_en.html)           |
| English  | [med_ner.clinical](https://nlp.johnsnowlabs.com/2020/01/30/ner_clinical_en.html) | [ner_clinical](https://nlp.johnsnowlabs.com/2020/01/30/ner_clinical_en.html)           |
| English  | [med_ner.clinical.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_clinical_biobert_en.html) | [ner_clinical_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_clinical_biobert_en.html)           |
| English  | med_ner.clinical.noncontrib | ner_clinical_noncontrib          |
| English  | [med_ner.diseases](https://nlp.johnsnowlabs.com/2021/03/31/ner_diseases_en.html) | [ner_diseases](https://nlp.johnsnowlabs.com/2021/03/31/ner_diseases_en.html)           |
| English  | [med_ner.diseases.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_biobert_en.html) | [ner_diseases_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_biobert_en.html)           |
| English  | [med_ner.diseases.large](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_large_en.html) | [ner_diseases_large](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_large_en.html)           |
| English  | [med_ner.drugs](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_en.html) | [ner_drugs](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_en.html)           |
| English  | [med_ner.drugsgreedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_greedy_en.html) | [ner_drugs_greedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_greedy_en.html)           |
| English  | [med_ner.drugs.large](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_large_en.html) | [ner_drugs_large](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_large_en.html)           |
| English  | [med_ner.events_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_biobert_en.html) | [ner_events_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_biobert_en.html)           |
| English  | [med_ner.events_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_events_clinical_en.html) | [ner_events_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_events_clinical_en.html)           |
| English  | [med_ner.events_healthcre](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_healthcare_en.html) | [ner_events_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_healthcare_en.html)           |
| English  | [med_ner.financial_contract](https://nlp.johnsnowlabs.com/2021/04/01/ner_financial_contract_en.html) | [ner_financial_contract](https://nlp.johnsnowlabs.com/2021/04/01/ner_financial_contract_en.html)           |
| English  | [med_ner.healthcare](https://nlp.johnsnowlabs.com/2021/03/31/ner_healthcare_de.html) | [ner_healthcare](https://nlp.johnsnowlabs.com/2021/03/31/ner_healthcare_de.html)           |
| English  | [med_ner.human_phenotype.gene_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_gene_biobert_en.html) | [ner_human_phenotype_gene_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_gene_biobert_en.html)           |
| English  | [med_ner.human_phenotype.gene_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html) | [ner_human_phenotype_gene_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html)           |
| English  | [med_ner.human_phenotype.go_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_go_biobert_en.html) | [ner_human_phenotype_go_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_go_biobert_en.html)           |
| English  | [med_ner.human_phenotype.go_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html) | [ner_human_phenotype_go_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html)           |
| English  | [med_ner.jsl](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_en.html) | [ner_jsl](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_en.html)           |
| English  | [med_ner.jsl.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_biobert_en.html) | [ner_jsl_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_biobert_en.html)           |
| English  | [med_ner.jsl.enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_enriched_en.html) | [ner_jsl_enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_enriched_en.html)           |
| English  | [med_ner.jsl.enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_enriched_biobert_en.html) | [ner_jsl_enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_enriched_biobert_en.html)           |
| English  | [med_ner.measurements](https://nlp.johnsnowlabs.com/2021/04/01/ner_measurements_clinical_en.html) | [ner_measurements_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_measurements_clinical_en.html)           |
| English  | [med_ner.medmentions](https://nlp.johnsnowlabs.com/2021/04/01/ner_medmentions_coarse_en.html) | [ner_medmentions_coarse](https://nlp.johnsnowlabs.com/2021/04/01/ner_medmentions_coarse_en.html)           |
| English  | [med_ner.posology](https://nlp.johnsnowlabs.com/2020/04/15/ner_posology_en.html) | [ner_posology](https://nlp.johnsnowlabs.com/2020/04/15/ner_posology_en.html)           |
| English  | [med_ner.posology.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_biobert_en.html) | [ner_posology_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_biobert_en.html)           |
| English  | [med_ner.posology.greedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_greedy_en.html) | [ner_posology_greedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_greedy_en.html)           |
| English  | [med_ner.posology.healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_healthcare_en.html) | [ner_posology_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_healthcare_en.html)           |
| English  | [med_ner.posology.large](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_large_en.html) | [ner_posology_large](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_large_en.html)           |
| English  | [med_ner.posology.large_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_large_biobert_en.html) | [ner_posology_large_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_large_biobert_en.html)           |
| English  | [med_ner.posology.small](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_small_en.html) | [ner_posology_small](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_small_en.html)           |
| English  | [med_ner.radiology](https://nlp.johnsnowlabs.com/2021/03/31/ner_radiology_en.html) | [ner_radiology](https://nlp.johnsnowlabs.com/2021/03/31/ner_radiology_en.html)           |
| English  | [med_ner.radiology.wip_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_radiology_wip_clinical_en.html) | [ner_radiology_wip_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_radiology_wip_clinical_en.html)           |
| English  | [med_ner.risk_factors](https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html) | [ner_risk_factors](https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html)           |
| English  | [med_ner.risk_factors.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_risk_factors_biobert_en.html) | [ner_risk_factors_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_risk_factors_biobert_en.html)           |
| English  | med_ner.i2b2 | nerdl_i2b2          |
| English  | [med_ner.tumour](https://nlp.johnsnowlabs.com/2021/04/01/nerdl_tumour_demo_en.html) | [nerdl_tumour_demo](https://nlp.johnsnowlabs.com/2021/04/01/nerdl_tumour_demo_en.html)           |
| English  | med_ner.jsl.wip.clinical | jsl_ner_wip_clinical          |
| English  | [med_ner.jsl.wip.clinical.greedy](https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html) | [jsl_ner_wip_greedy_clinical](https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html)           |
| English  | [med_ner.jsl.wip.clinical.modifier](https://nlp.johnsnowlabs.com/2021/04/01/jsl_ner_wip_modifier_clinical_en.html) | [jsl_ner_wip_modifier_clinical](https://nlp.johnsnowlabs.com/2021/04/01/jsl_ner_wip_modifier_clinical_en.html)           |
| English  | [med_ner.jsl.wip.clinical.rd](https://nlp.johnsnowlabs.com/2021/04/01/jsl_rd_ner_wip_greedy_clinical_en.html) | [jsl_rd_ner_wip_greedy_clinical](https://nlp.johnsnowlabs.com/2021/04/01/jsl_rd_ner_wip_greedy_clinical_en.html)           |


## De-Identification Models

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [med_ner.deid.augmented](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_augmented_en.html) | [ner_deid_augmented](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_augmented_en.html)           |
| English  | [med_ner.deid.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_biobert_en.html) | [ner_deid_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_biobert_en.html)           |
| English  | [med_ner.deid.enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_enriched_en.html) | [ner_deid_enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_enriched_en.html)           |
| English  | [med_ner.deid.enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_enriched_biobert_en.html) | [ner_deid_enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_enriched_biobert_en.html)           |
| English  | [med_ner.deid.large](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_large_en.html) | [ner_deid_large](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_large_en.html)           |
| English  | [med_ner.deid.sd](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_en.html) | [ner_deid_sd](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_en.html)           |
| English  | [med_ner.deid.sd_large](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_large_en.html) | [ner_deid_sd_large](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_large_en.html)           |
| English  | med_ner.deid | nerdl_deid          |
| English  | med_ner.deid.synthetic | ner_deid_synthetic          |
| English  | [med_ner.deid.dl](https://nlp.johnsnowlabs.com/2021/03/31/ner_deidentify_dl_en.html) | [ner_deidentify_dl](https://nlp.johnsnowlabs.com/2021/03/31/ner_deidentify_dl_en.html)           |
| English  | [en.de_identify](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html) | [deidentify_rb](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html)           |
| English  | de_identify.rules | deid_rules          |
| English  | [de_identify.clinical](https://nlp.johnsnowlabs.com/2021/01/29/deidentify_enriched_clinical_en.html) | [deidentify_enriched_clinical](https://nlp.johnsnowlabs.com/2021/01/29/deidentify_enriched_clinical_en.html)           |
| English  | [de_identify.large](https://nlp.johnsnowlabs.com/2020/08/04/deidentify_large_en.html) | [deidentify_large](https://nlp.johnsnowlabs.com/2020/08/04/deidentify_large_en.html)           |
| English  | [de_identify.rb](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html) | [deidentify_rb](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html)           |
| English  | de_identify.rb_no_regex | deidentify_rb_no_regex          |



# Chunk resolvers

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [resolve_chunk.athena_conditions](https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html) | [chunkresolve_athena_conditions_healthcare](https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html)           |
| English  | [resolve_chunk.cpt_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_cpt_clinical_en.html) | [chunkresolve_cpt_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_cpt_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_clinical_en.html) | [chunkresolve_icd10cm_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.diseases_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_diseases_clinical_en.html) | [chunkresolve_icd10cm_diseases_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_diseases_clinical_en.html)           |
| English  | resolve_chunk.icd10cm.hcc_clinical | chunkresolve_icd10cm_hcc_clinical          |
| English  | resolve_chunk.icd10cm.hcc_healthcare | chunkresolve_icd10cm_hcc_healthcare          |
| English  | [resolve_chunk.icd10cm.injuries](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_injuries_clinical_en.html) | [chunkresolve_icd10cm_injuries_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_injuries_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.musculoskeletal](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_musculoskeletal_clinical_en.html) | [chunkresolve_icd10cm_musculoskeletal_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_musculoskeletal_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.neoplasms](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_neoplasms_clinical_en.html) | [chunkresolve_icd10cm_neoplasms_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_neoplasms_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.poison](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_poison_ext_clinical_en.html) | [chunkresolve_icd10cm_poison_ext_clinical](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_poison_ext_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.puerile](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_puerile_clinical_en.html) | [chunkresolve_icd10cm_puerile_clinical](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_puerile_clinical_en.html)           |
| English  | resolve_chunk.icd10pcs.clinical | chunkresolve_icd10pcs_clinical          |
| English  | [resolve_chunk.icdo.clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10pcs_clinical_en.html) | [chunkresolve_icdo_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10pcs_clinical_en.html)           |
| English  | [resolve_chunk.loinc](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_loinc_clinical_en.html) | [chunkresolve_loinc_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_loinc_clinical_en.html)           |
| English  | [resolve_chunk.rxnorm.cd](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_cd_clinical_en.html) | [chunkresolve_rxnorm_cd_clinical](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_cd_clinical_en.html)           |
| English  | resolve_chunk.rxnorm.in | chunkresolve_rxnorm_in_clinical          |
| English  | resolve_chunk.rxnorm.in_healthcare | chunkresolve_rxnorm_in_healthcare          |
| English  | [resolve_chunk.rxnorm.sbd](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_sbd_clinical_en.html) | [chunkresolve_rxnorm_sbd_clinical](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_sbd_clinical_en.html)           |
| English  | [resolve_chunk.rxnorm.scd](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_scd_clinical_en.html) | [chunkresolve_rxnorm_scd_clinical](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_scd_clinical_en.html)           |
| English  | resolve_chunk.rxnorm.scdc | chunkresolve_rxnorm_scdc_clinical          |
| English  | resolve_chunk.rxnorm.scdc_healthcare | chunkresolve_rxnorm_scdc_healthcare          |
| English  | [resolve_chunk.rxnorm.xsmall.clinical](https://nlp.johnsnowlabs.com/2020/06/24/chunkresolve_rxnorm_xsmall_clinical_en.html) | [chunkresolve_rxnorm_xsmall_clinical](https://nlp.johnsnowlabs.com/2020/06/24/chunkresolve_rxnorm_xsmall_clinical_en.html)           |
| English  | [resolve_chunk.snomed.findings](https://nlp.johnsnowlabs.com/2020/06/20/chunkresolve_snomed_findings_clinical_en.html) | [chunkresolve_snomed_findings_clinical](https://nlp.johnsnowlabs.com/2020/06/20/chunkresolve_snomed_findings_clinical_en.html)           |


# New Classifiers

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | classify.icd10.clinical | classifier_icd10cm_hcc_clinical          |
| English  | classify.icd10.healthcare | classifier_icd10cm_hcc_healthcare          |
| English  | [classify.ade.biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_biobert_en.html) | [classifierdl_ade_biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_biobert_en.html)           |
| English  | [classify.ade.clinical](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_clinicalbert_en.html) | [classifierdl_ade_clinicalbert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_clinicalbert_en.html)           |
| English  | [classify.ade.conversational](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_conversational_biobert_en.html) | [classifierdl_ade_conversational_biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_conversational_biobert_en.html)           |
| English  | [classify.gender.biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_biobert_en.html) | [classifierdl_gender_biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_biobert_en.html)           |
| English  | [classify.gender.sbert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_sbert_en.html) | [classifierdl_gender_sbert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_sbert_en.html)           |
| English  | classify.pico | classifierdl_pico_biobert          |


# German Medical models

| nlu.load() reference                                         | Spark NLP Model reference          |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [embed]    | w2v_cc_300d|
| [embed.w2v]    | w2v_cc_300d|
| [resolve_chunk]    | chunkresolve_ICD10GM|
| [resolve_chunk.icd10gm]    | chunkresolve_ICD10GM|
| resolve_chunk.icd10gm.2021    | chunkresolve_ICD10GM_2021|
| med_ner.legal   | ner_legal|
| med_ner    | ner_healthcare|
| med_ner.healthcare    | ner_healthcare|
| med_ner.healthcare_slim    | ner_healthcare_slim|
| med_ner.traffic    | ner_traffic|

# Spanish Medical models
| nlu.load() reference                                         | Spark NLP Model reference          |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [embed.scielo.150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_150d_es.html) | [embeddings_scielo_150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_150d_es.html)| 
| [embed.scielo.300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_300d_es.html)   | [embeddings_scielo_300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_300d_es.html)| 
| [embed.scielo.50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_50d_es.html)  | [embeddings_scielo_50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_50d_es.html)| 
| [embed.scielowiki.150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_150d_es.html)   | [embeddings_scielowiki_150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_150d_es.html)| 
| [embed.scielowiki.300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_300d_es.html)   | [embeddings_scielowiki_300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_300d_es.html)| 
| [embed.scielowiki.50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_50d_es.html)   | [embeddings_scielowiki_50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_50d_es.html)| 
| [embed.sciwiki.150d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_150d_es.html)   | [embeddings_sciwiki_150d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_150d_es.html)| 
| [embed.sciwiki.300d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_300d_es.html)   | [embeddings_sciwiki_300d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_300d_es.html)| 
| [embed.sciwiki.50d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_50d_es.html)   | [embeddings_sciwiki_50d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_50d_es.html)| 
| [med_ner](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)   |  [ner_diag_proc](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)| 
| [med_ner.neoplasm](https://nlp.johnsnowlabs.com/2021/03/31/ner_neoplasms_es.html)  | [ner_neoplasms](https://nlp.johnsnowlabs.com/2021/03/31/ner_neoplasms_es.html)| 
| [med_ner.diag_proc](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)  | [ner_diag_proc](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)| 

# GPU Mode
You can now enable NLU GPU mode by setting `gpu=true` while loading a model. I.e. `nlu.load('train.sentiment' gpu=True)` . If must resart you kernel, if you already loaded a nlu pipeline withouth GPU mode.

# Output Level Relation
This new output level is used for relation extractors and will give you 1 row per relation extracted.


# Bug fixes
- Fixed a bug that caused loading NLU models in offline mode not to work in some occasions


# 1 line Install NLU
```!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash```

# Install via PIP 
```! pip install nlu pyspark==3.0.1```


## Additional NLU ressources

- [NLU Website](https://nlu.johnsnowlabs.com/)
- [All NLU Tutorial Notebooks](https://nlu.johnsnowlabs.com/docs/en/notebooks)
- [NLU Videos and Blogposts on NLU](https://nlp.johnsnowlabs.com/learn#pythons-nlu-library)
- [NLU on Github](https://github.com/JohnSnowLabs/nlu)
- [Suggestions or Questions? Contact us in Slack!](https://join.slack.com/t/spark-nlp/shared_invite/zt-lutct9gm-kuUazcyFKhuGY3_0AMkxqA)",t2_53n73cus,False,,0,False,"200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support - John Snow Labs NLU 3.0.0",[],r/deeplearning,False,6,,0,,False,t3_n5gvok,False,dark,0.86,,public,22,0,{},,False,[],,False,False,,{},,False,22,,False,False,,False,,[],{},,True,,1620252817.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h2&gt;200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support in  NLU 3.0 Release and much more&lt;/h2&gt;

&lt;p&gt;We are incredibly excited to announce the release of &lt;code&gt;NLU 3.0.0&lt;/code&gt; which makes most of John Snow Labs medical healthcare model available in just 1 line of code in NLU.
These models are the most accurate in their domains and highly scalable in Spark clusters.&lt;br/&gt;
In addition, &lt;code&gt;Spark 3.0.X&lt;/code&gt;  and &lt;code&gt;Spark 3.1.X&lt;/code&gt; is now supported, together with Python3.8&lt;/p&gt;

&lt;p&gt;This is enabled by the amazing &lt;a href=""https://nlp.johnsnowlabs.com/docs/en/release_notes#300""&gt;Spark NLP3.0.1&lt;/a&gt; and &lt;a href=""https://nlp.johnsnowlabs.com/docs/en/licensed_release_notes#301""&gt;Spark NLP for Healthcare 3.0.1&lt;/a&gt; releases.&lt;/p&gt;

&lt;h1&gt;New Features&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Over 200 new models for the &lt;code&gt;healthcare&lt;/code&gt; domain&lt;/li&gt;
&lt;li&gt;6 new classes of models, Assertion, Sentence/Chunk Resolvers, Relation Extractors, Medical NER models, De-Identificator Models&lt;/li&gt;
&lt;li&gt;Spark 3.0.X and 3.1.X support&lt;/li&gt;
&lt;li&gt;Python 3.8 Support&lt;/li&gt;
&lt;li&gt;New Output level &lt;code&gt;relation&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;1 Line to install NLU  just run &lt;code&gt;!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.0.0""&gt;Various new EMR and Databricks versions supported&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GPU Mode, more then 600% speedup by enabling GPU mode.&lt;/li&gt;
&lt;li&gt;Authorized mode for licensed features&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;New Documentation&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://nlu.johnsnowlabs.com/docs/en/examples_hc#usage-examples-of-nluload""&gt;NLU for Healthcare Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlu.johnsnowlabs.com/docs/en/examples_hc#authorize-access-to-licensed-features-and-install-healthcare-dependencies""&gt;Instrunctions to authorize your environment to use Licensed features&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;New Notebooks&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/medical_named_entity_recognition/overview_medical_entity_recognizers.ipynb""&gt;Medical Named Entity Extraction (NER) notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/relation_extraction/overview_relation.ipynb""&gt;Relation extraction notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/entity_resolution/entity_resolvers_overview.ipynb""&gt;Entity Resolution overview notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/assertion/assertion_overview.ipynb""&gt;Assertion overview notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/de_identification/DeIdentification_model_overview.ipynb""&gt;De-Identification overview notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/3.0rc1/examples/webinars_conferences_etc/graph_ai_summit/Healthcare_Graph_NLU_COVID_Tigergraph.ipynb""&gt;Graph NLU tutorial&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;AssertionDLModels&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html""&gt;assert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html""&gt;assertion_dl&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html""&gt;assert.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html""&gt;assertion_dl_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html""&gt;assert.healthcare&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html""&gt;assertion_dl_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html""&gt;assert.large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html""&gt;assertion_dl_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;New Word Embeddings&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html""&gt;embed.glove.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html""&gt;embeddings_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/06/02/embeddings_biovec_en.html""&gt;embed.glove.biovec&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/06/02/embeddings_biovec_en.html""&gt;embeddings_biovec&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/03/26/embeddings_healthcare_en.html""&gt;embed.glove.healthcare&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/03/26/embeddings_healthcare_en.html""&gt;embeddings_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/29/embeddings_healthcare_100d_en.html""&gt;embed.glove.healthcare_100d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/29/embeddings_healthcare_100d_en.html""&gt;embeddings_healthcare_100d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;en.embed.glove.icdoem&lt;/td&gt;
&lt;td&gt;embeddings_icdoem&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;en.embed.glove.icdoem_2ng&lt;/td&gt;
&lt;td&gt;embeddings_icdoem_2ng&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;Sentence Entity resolvers&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;embed_sentence.biobert.mli&lt;/td&gt;
&lt;td&gt;sbiobert_base_cased_mli&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve&lt;/td&gt;
&lt;td&gt;sbiobertresolve_cpt&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve.cpt&lt;/td&gt;
&lt;td&gt;sbiobertresolve_cpt&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve.cpt.augmented&lt;/td&gt;
&lt;td&gt;sbiobertresolve_cpt_augmented&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve.cpt.procedures_augmented&lt;/td&gt;
&lt;td&gt;sbiobertresolve_cpt_procedures_augmented&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve.hcc.augmented&lt;/td&gt;
&lt;td&gt;sbiobertresolve_hcc_augmented&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html""&gt;resolve.icd10cm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html""&gt;sbiobertresolve_icd10cm&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html""&gt;resolve.icd10cm.augmented&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html""&gt;sbiobertresolve_icd10cm_augmented&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html""&gt;resolve.icd10cm.augmented_billable&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html""&gt;sbiobertresolve_icd10cm_augmented_billable_hcc&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html""&gt;resolve.icd10pcs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html""&gt;sbiobertresolve_icd10pcs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html""&gt;resolve.icdo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html""&gt;sbiobertresolve_icdo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html""&gt;resolve.rxcui&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html""&gt;sbiobertresolve_rxcui&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html""&gt;resolve.rxnorm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html""&gt;sbiobertresolve_rxnorm&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html""&gt;resolve.snomed&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html""&gt;sbiobertresolve_snomed_auxConcepts&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html""&gt;resolve.snomed.aux_concepts&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html""&gt;sbiobertresolve_snomed_auxConcepts&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html""&gt;resolve.snomed.aux_concepts_int&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html""&gt;sbiobertresolve_snomed_auxConcepts_int&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html""&gt;resolve.snomed.findings&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html""&gt;sbiobertresolve_snomed_findings&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html""&gt;resolve.snomed.findings_int&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html""&gt;sbiobertresolve_snomed_findings_int&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;RelationExtractionModel&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;relation.posology&lt;/td&gt;
&lt;td&gt;posology_re&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html""&gt;relation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html""&gt;redl_bodypart_direction_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html""&gt;relation.bodypart.direction&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html""&gt;redl_bodypart_direction_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_problem_biobert_en.html""&gt;relation.bodypart.problem&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_problem_biobert_en.html""&gt;redl_bodypart_problem_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_procedure_test_biobert_en.html""&gt;relation.bodypart.procedure&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_procedure_test_biobert_en.html""&gt;redl_bodypart_procedure_test_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_chemprot_biobert_en.html""&gt;relation.chemprot&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_chemprot_biobert_en.html""&gt;redl_chemprot_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_clinical_biobert_en.html""&gt;relation.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_clinical_biobert_en.html""&gt;redl_clinical_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_date_clinical_biobert_en.htmls""&gt;relation.date&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_date_clinical_biobert_en.htmls""&gt;redl_date_clinical_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_drug_drug_interaction_biobert_en.html""&gt;relation.drug_drug_interaction&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_drug_drug_interaction_biobert_en.html""&gt;redl_drug_drug_interaction_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_human_phenotype_gene_biobert_en.html""&gt;relation.humen_phenotype_gene&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_human_phenotype_gene_biobert_en.html""&gt;redl_human_phenotype_gene_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_temporal_events_biobert_en.html""&gt;relation.temporal_events&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_temporal_events_biobert_en.html""&gt;redl_temporal_events_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;NERDLModels&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinical_en.html""&gt;med_ner.ade.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinical_en.html""&gt;ner_ade_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinicalbert_en.html""&gt;med_ner.ade.clinical_bert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinicalbert_en.html""&gt;ner_ade_clinicalbert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_healthcare_en.html""&gt;med_ner.ade.ade_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_healthcare_en.html""&gt;ner_ade_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_en.html""&gt;med_ner.anatomy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_en.html""&gt;ner_anatomy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_anatomy_biobert_en.html""&gt;med_ner.anatomy.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_anatomy_biobert_en.html""&gt;ner_anatomy_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html""&gt;med_ner.anatomy.coarse&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html""&gt;ner_anatomy_coarse&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_biobert_en.html""&gt;med_ner.anatomy.coarse_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_biobert_en.html""&gt;ner_anatomy_coarse_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_aspect_based_sentiment_en.html""&gt;med_ner.aspect_sentiment&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_aspect_based_sentiment_en.html""&gt;ner_aspect_based_sentiment&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_bacterial_species_en.html""&gt;med_ner.bacterial_species&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_bacterial_species_en.html""&gt;ner_bacterial_species&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_bionlp_en.html""&gt;med_ner.bionlp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_bionlp_en.html""&gt;ner_bionlp&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_bionlp_biobert_en.html""&gt;med_ner.bionlp.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_bionlp_biobert_en.html""&gt;ner_bionlp_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_cancer_genetics_en.html""&gt;med_ner.cancer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_cancer_genetics_en.html""&gt;ner_cancer_genetics&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Englishs&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_cellular_en.html""&gt;med_ner.cellular&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_cellular_en.html""&gt;ner_cellular&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_cellular_biobert_en.html""&gt;med_ner.cellular.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_cellular_biobert_en.html""&gt;ner_cellular_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_chemicals_en.html""&gt;med_ner.chemicals&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_chemicals_en.html""&gt;ner_chemicals&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_chemprot_biobert_en.html""&gt;med_ner.chemprot&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_chemprot_biobert_en.html""&gt;ner_chemprot_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_chemprot_clinical_en.html""&gt;med_ner.chemprot.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_chemprot_clinical_en.html""&gt;ner_chemprot_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/01/30/ner_clinical_en.html""&gt;med_ner.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/01/30/ner_clinical_en.html""&gt;ner_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_clinical_biobert_en.html""&gt;med_ner.clinical.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_clinical_biobert_en.html""&gt;ner_clinical_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;med_ner.clinical.noncontrib&lt;/td&gt;
&lt;td&gt;ner_clinical_noncontrib&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_diseases_en.html""&gt;med_ner.diseases&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_diseases_en.html""&gt;ner_diseases&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_biobert_en.html""&gt;med_ner.diseases.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_biobert_en.html""&gt;ner_diseases_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_large_en.html""&gt;med_ner.diseases.large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_large_en.html""&gt;ner_diseases_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_en.html""&gt;med_ner.drugs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_en.html""&gt;ner_drugs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_greedy_en.html""&gt;med_ner.drugsgreedy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_greedy_en.html""&gt;ner_drugs_greedy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_large_en.html""&gt;med_ner.drugs.large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_large_en.html""&gt;ner_drugs_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_events_biobert_en.html""&gt;med_ner.events_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_events_biobert_en.html""&gt;ner_events_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_events_clinical_en.html""&gt;med_ner.events_clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_events_clinical_en.html""&gt;ner_events_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_events_healthcare_en.html""&gt;med_ner.events_healthcre&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_events_healthcare_en.html""&gt;ner_events_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_financial_contract_en.html""&gt;med_ner.financial_contract&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_financial_contract_en.html""&gt;ner_financial_contract&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_healthcare_de.html""&gt;med_ner.healthcare&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_healthcare_de.html""&gt;ner_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_gene_biobert_en.html""&gt;med_ner.human_phenotype.gene_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_gene_biobert_en.html""&gt;ner_human_phenotype_gene_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html""&gt;med_ner.human_phenotype.gene_clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html""&gt;ner_human_phenotype_gene_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_go_biobert_en.html""&gt;med_ner.human_phenotype.go_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_go_biobert_en.html""&gt;ner_human_phenotype_go_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html""&gt;med_ner.human_phenotype.go_clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html""&gt;ner_human_phenotype_go_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_en.html""&gt;med_ner.jsl&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_en.html""&gt;ner_jsl&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_biobert_en.html""&gt;med_ner.jsl.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_biobert_en.html""&gt;ner_jsl_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_enriched_en.html""&gt;med_ner.jsl.enriched&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_enriched_en.html""&gt;ner_jsl_enriched&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_enriched_biobert_en.html""&gt;med_ner.jsl.enriched_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_enriched_biobert_en.html""&gt;ner_jsl_enriched_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_measurements_clinical_en.html""&gt;med_ner.measurements&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_measurements_clinical_en.html""&gt;ner_measurements_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_medmentions_coarse_en.html""&gt;med_ner.medmentions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_medmentions_coarse_en.html""&gt;ner_medmentions_coarse&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/04/15/ner_posology_en.html""&gt;med_ner.posology&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/04/15/ner_posology_en.html""&gt;ner_posology&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_biobert_en.html""&gt;med_ner.posology.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_biobert_en.html""&gt;ner_posology_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_greedy_en.html""&gt;med_ner.posology.greedy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_greedy_en.html""&gt;ner_posology_greedy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_healthcare_en.html""&gt;med_ner.posology.healthcare&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_healthcare_en.html""&gt;ner_posology_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_large_en.html""&gt;med_ner.posology.large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_large_en.html""&gt;ner_posology_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_large_biobert_en.html""&gt;med_ner.posology.large_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_large_biobert_en.html""&gt;ner_posology_large_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_small_en.html""&gt;med_ner.posology.small&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_small_en.html""&gt;ner_posology_small&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_radiology_en.html""&gt;med_ner.radiology&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_radiology_en.html""&gt;ner_radiology&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_radiology_wip_clinical_en.html""&gt;med_ner.radiology.wip_clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_radiology_wip_clinical_en.html""&gt;ner_radiology_wip_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html""&gt;med_ner.risk_factors&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html""&gt;ner_risk_factors&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_risk_factors_biobert_en.html""&gt;med_ner.risk_factors.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_risk_factors_biobert_en.html""&gt;ner_risk_factors_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;med_ner.i2b2&lt;/td&gt;
&lt;td&gt;nerdl_i2b2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/nerdl_tumour_demo_en.html""&gt;med_ner.tumour&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/nerdl_tumour_demo_en.html""&gt;nerdl_tumour_demo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;med_ner.jsl.wip.clinical&lt;/td&gt;
&lt;td&gt;jsl_ner_wip_clinical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html""&gt;med_ner.jsl.wip.clinical.greedy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html""&gt;jsl_ner_wip_greedy_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/jsl_ner_wip_modifier_clinical_en.html""&gt;med_ner.jsl.wip.clinical.modifier&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/jsl_ner_wip_modifier_clinical_en.html""&gt;jsl_ner_wip_modifier_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/jsl_rd_ner_wip_greedy_clinical_en.html""&gt;med_ner.jsl.wip.clinical.rd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/jsl_rd_ner_wip_greedy_clinical_en.html""&gt;jsl_rd_ner_wip_greedy_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;De-Identification Models&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_augmented_en.html""&gt;med_ner.deid.augmented&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_augmented_en.html""&gt;ner_deid_augmented&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_biobert_en.html""&gt;med_ner.deid.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_biobert_en.html""&gt;ner_deid_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_enriched_en.html""&gt;med_ner.deid.enriched&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_enriched_en.html""&gt;ner_deid_enriched&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_enriched_biobert_en.html""&gt;med_ner.deid.enriched_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_enriched_biobert_en.html""&gt;ner_deid_enriched_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_large_en.html""&gt;med_ner.deid.large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_large_en.html""&gt;ner_deid_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_en.html""&gt;med_ner.deid.sd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_en.html""&gt;ner_deid_sd&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_large_en.html""&gt;med_ner.deid.sd_large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_large_en.html""&gt;ner_deid_sd_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;med_ner.deid&lt;/td&gt;
&lt;td&gt;nerdl_deid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;med_ner.deid.synthetic&lt;/td&gt;
&lt;td&gt;ner_deid_synthetic&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deidentify_dl_en.html""&gt;med_ner.deid.dl&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deidentify_dl_en.html""&gt;ner_deidentify_dl&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html""&gt;en.de_identify&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html""&gt;deidentify_rb&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;de_identify.rules&lt;/td&gt;
&lt;td&gt;deid_rules&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/29/deidentify_enriched_clinical_en.html""&gt;de_identify.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/29/deidentify_enriched_clinical_en.html""&gt;deidentify_enriched_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/08/04/deidentify_large_en.html""&gt;de_identify.large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/08/04/deidentify_large_en.html""&gt;deidentify_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html""&gt;de_identify.rb&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html""&gt;deidentify_rb&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;de_identify.rb_no_regex&lt;/td&gt;
&lt;td&gt;deidentify_rb_no_regex&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h1&gt;Chunk resolvers&lt;/h1&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html""&gt;resolve_chunk.athena_conditions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html""&gt;chunkresolve_athena_conditions_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_cpt_clinical_en.html""&gt;resolve_chunk.cpt_clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_cpt_clinical_en.html""&gt;chunkresolve_cpt_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_clinical_en.html""&gt;resolve_chunk.icd10cm.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_clinical_en.html""&gt;chunkresolve_icd10cm_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_diseases_clinical_en.html""&gt;resolve_chunk.icd10cm.diseases_clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_diseases_clinical_en.html""&gt;chunkresolve_icd10cm_diseases_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.icd10cm.hcc_clinical&lt;/td&gt;
&lt;td&gt;chunkresolve_icd10cm_hcc_clinical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.icd10cm.hcc_healthcare&lt;/td&gt;
&lt;td&gt;chunkresolve_icd10cm_hcc_healthcare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_injuries_clinical_en.html""&gt;resolve_chunk.icd10cm.injuries&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_injuries_clinical_en.html""&gt;chunkresolve_icd10cm_injuries_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_musculoskeletal_clinical_en.html""&gt;resolve_chunk.icd10cm.musculoskeletal&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_musculoskeletal_clinical_en.html""&gt;chunkresolve_icd10cm_musculoskeletal_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_neoplasms_clinical_en.html""&gt;resolve_chunk.icd10cm.neoplasms&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_neoplasms_clinical_en.html""&gt;chunkresolve_icd10cm_neoplasms_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_poison_ext_clinical_en.html""&gt;resolve_chunk.icd10cm.poison&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_poison_ext_clinical_en.html""&gt;chunkresolve_icd10cm_poison_ext_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_puerile_clinical_en.html""&gt;resolve_chunk.icd10cm.puerile&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_puerile_clinical_en.html""&gt;chunkresolve_icd10cm_puerile_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.icd10pcs.clinical&lt;/td&gt;
&lt;td&gt;chunkresolve_icd10pcs_clinical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10pcs_clinical_en.html""&gt;resolve_chunk.icdo.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10pcs_clinical_en.html""&gt;chunkresolve_icdo_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_loinc_clinical_en.html""&gt;resolve_chunk.loinc&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_loinc_clinical_en.html""&gt;chunkresolve_loinc_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_cd_clinical_en.html""&gt;resolve_chunk.rxnorm.cd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_cd_clinical_en.html""&gt;chunkresolve_rxnorm_cd_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.rxnorm.in&lt;/td&gt;
&lt;td&gt;chunkresolve_rxnorm_in_clinical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.rxnorm.in_healthcare&lt;/td&gt;
&lt;td&gt;chunkresolve_rxnorm_in_healthcare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_sbd_clinical_en.html""&gt;resolve_chunk.rxnorm.sbd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_sbd_clinical_en.html""&gt;chunkresolve_rxnorm_sbd_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_scd_clinical_en.html""&gt;resolve_chunk.rxnorm.scd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_scd_clinical_en.html""&gt;chunkresolve_rxnorm_scd_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.rxnorm.scdc&lt;/td&gt;
&lt;td&gt;chunkresolve_rxnorm_scdc_clinical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.rxnorm.scdc_healthcare&lt;/td&gt;
&lt;td&gt;chunkresolve_rxnorm_scdc_healthcare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/06/24/chunkresolve_rxnorm_xsmall_clinical_en.html""&gt;resolve_chunk.rxnorm.xsmall.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/06/24/chunkresolve_rxnorm_xsmall_clinical_en.html""&gt;chunkresolve_rxnorm_xsmall_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/06/20/chunkresolve_snomed_findings_clinical_en.html""&gt;resolve_chunk.snomed.findings&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/06/20/chunkresolve_snomed_findings_clinical_en.html""&gt;chunkresolve_snomed_findings_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h1&gt;New Classifiers&lt;/h1&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;classify.icd10.clinical&lt;/td&gt;
&lt;td&gt;classifier_icd10cm_hcc_clinical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;classify.icd10.healthcare&lt;/td&gt;
&lt;td&gt;classifier_icd10cm_hcc_healthcare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_biobert_en.html""&gt;classify.ade.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_biobert_en.html""&gt;classifierdl_ade_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_clinicalbert_en.html""&gt;classify.ade.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_clinicalbert_en.html""&gt;classifierdl_ade_clinicalbert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_conversational_biobert_en.html""&gt;classify.ade.conversational&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_conversational_biobert_en.html""&gt;classifierdl_ade_conversational_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_biobert_en.html""&gt;classify.gender.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_biobert_en.html""&gt;classifierdl_gender_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_sbert_en.html""&gt;classify.gender.sbert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_sbert_en.html""&gt;classifierdl_gender_sbert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;classify.pico&lt;/td&gt;
&lt;td&gt;classifierdl_pico_biobert&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h1&gt;German Medical models&lt;/h1&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;[embed]&lt;/td&gt;
&lt;td&gt;w2v_cc_300d&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[embed.w2v]&lt;/td&gt;
&lt;td&gt;w2v_cc_300d&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[resolve_chunk]&lt;/td&gt;
&lt;td&gt;chunkresolve_ICD10GM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[resolve_chunk.icd10gm]&lt;/td&gt;
&lt;td&gt;chunkresolve_ICD10GM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;resolve_chunk.icd10gm.2021&lt;/td&gt;
&lt;td&gt;chunkresolve_ICD10GM_2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;med_ner.legal&lt;/td&gt;
&lt;td&gt;ner_legal&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;med_ner&lt;/td&gt;
&lt;td&gt;ner_healthcare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;med_ner.healthcare&lt;/td&gt;
&lt;td&gt;ner_healthcare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;med_ner.healthcare_slim&lt;/td&gt;
&lt;td&gt;ner_healthcare_slim&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;med_ner.traffic&lt;/td&gt;
&lt;td&gt;ner_traffic&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h1&gt;Spanish Medical models&lt;/h1&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_150d_es.html""&gt;embed.scielo.150d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_150d_es.html""&gt;embeddings_scielo_150d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_300d_es.html""&gt;embed.scielo.300d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_300d_es.html""&gt;embeddings_scielo_300d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_50d_es.html""&gt;embed.scielo.50d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_50d_es.html""&gt;embeddings_scielo_50d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_150d_es.html""&gt;embed.scielowiki.150d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_150d_es.html""&gt;embeddings_scielowiki_150d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_300d_es.html""&gt;embed.scielowiki.300d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_300d_es.html""&gt;embeddings_scielowiki_300d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_50d_es.html""&gt;embed.scielowiki.50d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_50d_es.html""&gt;embeddings_scielowiki_50d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_150d_es.html""&gt;embed.sciwiki.150d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_150d_es.html""&gt;embeddings_sciwiki_150d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_300d_es.html""&gt;embed.sciwiki.300d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_300d_es.html""&gt;embeddings_sciwiki_300d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_50d_es.html""&gt;embed.sciwiki.50d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_50d_es.html""&gt;embeddings_sciwiki_50d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html""&gt;med_ner&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html""&gt;ner_diag_proc&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_neoplasms_es.html""&gt;med_ner.neoplasm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_neoplasms_es.html""&gt;ner_neoplasms&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html""&gt;med_ner.diag_proc&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html""&gt;ner_diag_proc&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h1&gt;GPU Mode&lt;/h1&gt;

&lt;p&gt;You can now enable NLU GPU mode by setting &lt;code&gt;gpu=true&lt;/code&gt; while loading a model. I.e. &lt;code&gt;nlu.load(&amp;#39;train.sentiment&amp;#39; gpu=True)&lt;/code&gt; . If must resart you kernel, if you already loaded a nlu pipeline withouth GPU mode.&lt;/p&gt;

&lt;h1&gt;Output Level Relation&lt;/h1&gt;

&lt;p&gt;This new output level is used for relation extractors and will give you 1 row per relation extracted.&lt;/p&gt;

&lt;h1&gt;Bug fixes&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Fixed a bug that caused loading NLU models in offline mode not to work in some occasions&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;1 line Install NLU&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash&lt;/code&gt;&lt;/p&gt;

&lt;h1&gt;Install via PIP&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;! pip install nlu pyspark==3.0.1&lt;/code&gt;&lt;/p&gt;

&lt;h2&gt;Additional NLU ressources&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://nlu.johnsnowlabs.com/""&gt;NLU Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlu.johnsnowlabs.com/docs/en/notebooks""&gt;All NLU Tutorial Notebooks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlp.johnsnowlabs.com/learn#pythons-nlu-library""&gt;NLU Videos and Blogposts on NLU&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu""&gt;NLU on Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://join.slack.com/t/spark-nlp/shared_invite/zt-lutct9gm-kuUazcyFKhuGY3_0AMkxqA""&gt;Suggestions or Questions? Contact us in Slack!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5gvok,True,,CKL-IT,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n5gvok/200_state_of_the_art_medical_models_for_ner/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n5gvok/200_state_of_the_art_medical_models_for_ner/,66146,1620224017.0,0,,False,,,,,,,
,deeplearning,"Hi,

My family Whatsapp group is usually filled with various fake forward messages from the right-wing group (BJP), the whole world can see the result of their handling of the covid situation in india. Yet because of the forwards which are in all formats--text, edited videos, and even memes which are inaccurate deceive the perception of people and kind of make them dumb to put it frankly. Is there any DL system that I can build or anything that might help to tackle this problem?",t2_7d3q7c7x,False,,0,False,What kind of system can I build to filter political propaganda forward in Whatsapp groups?,[],r/deeplearning,False,6,,0,,False,t3_n61f9c,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620313500.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;My family Whatsapp group is usually filled with various fake forward messages from the right-wing group (BJP), the whole world can see the result of their handling of the covid situation in india. Yet because of the forwards which are in all formats--text, edited videos, and even memes which are inaccurate deceive the perception of people and kind of make them dumb to put it frankly. Is there any DL system that I can build or anything that might help to tackle this problem?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n61f9c,True,,Turbulent_Animator65,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/n61f9c/what_kind_of_system_can_i_build_to_filter/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n61f9c/what_kind_of_system_can_i_build_to_filter/,66146,1620284700.0,0,,False,,,,,,,
,deeplearning,"We are back with another fun Human-Computer Interaction tutorial using Computer Vision!

All of us have had those internet breakdown days where there's a lot of time on our hands. You might have stumbled upon chrome’s infamous Dino game that appears on chrome when the internet is not working. If not, try it out now with a new twist - our tutorial.

We use facial expressions to control the dinosaur in the game. The best part is you don't even have to touch the keyboard or mouse while playing the game because of the helpful pyautogui module.

Sounds fun? Jump or crouch to the link below :P

[https://learnopencv.com/playing-chromes-t-rex-game-with-facial-gestures/](https://learnopencv.com/playing-chromes-t-rex-game-with-facial-gestures/)

https://i.redd.it/xxluunp67gx61.gif",t2_cvc9f,False,,0,False,Playing Chrome’s T-Rex Game with Facial Gestures,[],r/deeplearning,False,6,,0,,False,t3_n61dlm,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620313296.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We are back with another fun Human-Computer Interaction tutorial using Computer Vision!&lt;/p&gt;

&lt;p&gt;All of us have had those internet breakdown days where there&amp;#39;s a lot of time on our hands. You might have stumbled upon chrome’s infamous Dino game that appears on chrome when the internet is not working. If not, try it out now with a new twist - our tutorial.&lt;/p&gt;

&lt;p&gt;We use facial expressions to control the dinosaur in the game. The best part is you don&amp;#39;t even have to touch the keyboard or mouse while playing the game because of the helpful pyautogui module.&lt;/p&gt;

&lt;p&gt;Sounds fun? Jump or crouch to the link below :P&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://learnopencv.com/playing-chromes-t-rex-game-with-facial-gestures/""&gt;https://learnopencv.com/playing-chromes-t-rex-game-with-facial-gestures/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://i.redd.it/xxluunp67gx61.gif""&gt;https://i.redd.it/xxluunp67gx61.gif&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n61dlm,True,,spmallick,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n61dlm/playing_chromes_trex_game_with_facial_gestures/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n61dlm/playing_chromes_trex_game_with_facial_gestures/,66146,1620284496.0,0,,False,,,"{'xxluunp67gx61': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 72, 'x': 108, 'u': 'https://preview.redd.it/xxluunp67gx61.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=ce5280036c14c4eb67125217be6d06cb2df68134'}, {'y': 144, 'x': 216, 'u': 'https://preview.redd.it/xxluunp67gx61.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=661fda296939675caf402fea4c5814da1b7748fc'}, {'y': 213, 'x': 320, 'u': 'https://preview.redd.it/xxluunp67gx61.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=ecfb6e2df7efd572038b1434b40def78f0401e58'}], 's': {'y': 400, 'gif': 'https://i.redd.it/xxluunp67gx61.gif', 'mp4': 'https://preview.redd.it/xxluunp67gx61.gif?format=mp4&amp;s=ceb8b0b0c60e22eab66dcc45ddb04d157c5dbb2f', 'x': 600}, 'id': 'xxluunp67gx61'}}",,,,
,deeplearning,,t2_44mbtmjy,False,,0,False,Mindblown 🤯🤯: Bring your Minecraft creation into the real world - generate photorealistic images of large 3D block worlds such as those created in Minecraft! (GANcraft),[],r/deeplearning,False,6,,0,,False,t3_n613qu,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1620312138.0,text,6,,,text,self.LatestInML,False,,,,,/r/LatestInML/comments/n611js/mindblown_bring_your_minecraft_creation_into_the/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n613qu,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n613qu/mindblown_bring_your_minecraft_creation_into_the/,all_ads,False,/r/LatestInML/comments/n611js/mindblown_bring_your_minecraft_creation_into_the/,66146,1620283338.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper and code](https://www.catalyzex.com/paper/arxiv:2104.07659)\n\nhttps://reddit.com/link/n611js/video/o50ki5hz3gx61/player\n\n👇 Free extension to get code for ML papers (❤️'d by Andrew Ng) Chrome: https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil\n\nFirefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Mindblown 🤯🤯: Bring your Minecraft creation into the real world - generate photorealistic images of large 3D block worlds such as those created in Minecraft! (GANcraft)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'o50ki5hz3gx61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/n611js/asset/o50ki5hz3gx61/DASHPlaylist.mpd?a=1626450095%2CZDkxZjE4ZjhiM2I1Nzc2NmE1NjFjN2JmMDZiZjA2NzQ3ZDQ5NWZmOGY4ZmI3MGIxNzUxYjJlMDNlM2RiNDMwZg%3D%3D&amp;v=1&amp;f=sd', 'x': 1280, 'y': 640, 'hlsUrl': 'https://v.redd.it/link/n611js/asset/o50ki5hz3gx61/HLSPlaylist.m3u8?a=1626450095%2CMjliZDdhNjljZTM4NmI4MjIxZWMzNGI5MTVjODU1OGM4MzQzMDRiMGZhNzVlZmM0OTVkYjE2ZWFjMmQzMDBjOQ%3D%3D&amp;v=1&amp;f=sd', 'id': 'o50ki5hz3gx61', 'isGif': False}}, 'name': 't3_n611js', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.8, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 24, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 24, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1620311899.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2104.07659""&gt;link to paper and code&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/n611js/video/o50ki5hz3gx61/player""&gt;https://reddit.com/link/n611js/video/o50ki5hz3gx61/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39;d by Andrew Ng) Chrome: &lt;a href=""https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'n611js', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/n611js/mindblown_bring_your_minecraft_creation_into_the/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/n611js/mindblown_bring_your_minecraft_creation_into_the/', 'subreddit_subscribers': 7049, 'created_utc': 1620283099.0, 'num_crossposts': 11, 'media': None, 'is_video': False}]",t3_n611js,,,,,
,deeplearning,"Dear all,

Have a peek at Computer Vision News of May!

Many articles about AI, Deep Learning and more...

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2021May/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2021-may-pdf/)

Dilbert on page 2. Free subscription on page 40.

Enjoy!

https://preview.redd.it/s4mapvy4zfx61.jpg?width=700&amp;format=pjpg&amp;auto=webp&amp;s=18cee43a192cb60a21be79caf182a7bcd3ee4c87",t2_x7alu,False,,0,False,Computer Vision News (with research and code!) - May 2021,[],r/deeplearning,False,6,,0,,False,t3_n60lxv,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620310099.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Dear all,&lt;/p&gt;

&lt;p&gt;Have a peek at Computer Vision News of May!&lt;/p&gt;

&lt;p&gt;Many articles about AI, Deep Learning and more...&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.rsipvision.com/ComputerVisionNews-2021May/""&gt;HTML5 version (recommended)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.rsipvision.com/computer-vision-news-2021-may-pdf/""&gt;PDF version&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Dilbert on page 2. Free subscription on page 40.&lt;/p&gt;

&lt;p&gt;Enjoy!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/s4mapvy4zfx61.jpg?width=700&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=18cee43a192cb60a21be79caf182a7bcd3ee4c87""&gt;https://preview.redd.it/s4mapvy4zfx61.jpg?width=700&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=18cee43a192cb60a21be79caf182a7bcd3ee4c87&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n60lxv,True,,Gletta,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n60lxv/computer_vision_news_with_research_and_code_may/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n60lxv/computer_vision_news_with_research_and_code_may/,66146,1620281299.0,0,,False,,,"{'s4mapvy4zfx61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 152, 'x': 108, 'u': 'https://preview.redd.it/s4mapvy4zfx61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e705bd3c461011ad2900d964fe8196abfe085dca'}, {'y': 305, 'x': 216, 'u': 'https://preview.redd.it/s4mapvy4zfx61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=96ae7daec593dac39433026bcc7670ff57afd0fc'}, {'y': 452, 'x': 320, 'u': 'https://preview.redd.it/s4mapvy4zfx61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b0f9a52cd7a3e36897bfd2261bd9507145e7688f'}, {'y': 904, 'x': 640, 'u': 'https://preview.redd.it/s4mapvy4zfx61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6af67f38869ee6c97cda7a62f830f377914ec649'}], 's': {'y': 989, 'x': 700, 'u': 'https://preview.redd.it/s4mapvy4zfx61.jpg?width=700&amp;format=pjpg&amp;auto=webp&amp;s=18cee43a192cb60a21be79caf182a7bcd3ee4c87'}, 'id': 's4mapvy4zfx61'}}",,,,
,deeplearning,"I am creating a RNN model for time series data, but I was confused about how to set it up because it is a 3-dimensional array. I understand it must be \[samples, time steps, and features\]. How do you choose the timesteps, what does this mean. Let's say I have a time series of 5000 days, and with 4 features. What would a time step of 1 mean rather than a time step of 10? I tried looking into this, but there are so many different definitions. I read that it is the number of iterations it is run, the amount of data that is used to predict a future time so if it was 1, it learns from 1 timestep and predicts one in the future, if it was 10 it learns from 10 timesteps and predicts 10 in the future. I am new to all of this so any input is much appreciated.",t2_1ijbhmfa,False,,0,False,Confusion about setting up input data for RNN,[],r/deeplearning,False,6,,0,,False,t3_n5ne4v,False,dark,0.67,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1620269318.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am creating a RNN model for time series data, but I was confused about how to set it up because it is a 3-dimensional array. I understand it must be [samples, time steps, and features]. How do you choose the timesteps, what does this mean. Let&amp;#39;s say I have a time series of 5000 days, and with 4 features. What would a time step of 1 mean rather than a time step of 10? I tried looking into this, but there are so many different definitions. I read that it is the number of iterations it is run, the amount of data that is used to predict a future time so if it was 1, it learns from 1 timestep and predicts one in the future, if it was 10 it learns from 10 timesteps and predicts 10 in the future. I am new to all of this so any input is much appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5ne4v,True,,Saen_OG,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n5ne4v/confusion_about_setting_up_input_data_for_rnn/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n5ne4v/confusion_about_setting_up_input_data_for_rnn/,66146,1620240518.0,0,,False,,,,,,,
,deeplearning,"I need a pre-trained model where I can input text documents (or fine-tune with) and have it answer  reading comprehension-type questions. Obviously, GPT-3 would be perfect for this, but I need it by tomorrow and don't think I'll receive login credentials to the API for at least another week. However, the task isn't all too complex, so I'm looking for a decent alternative that I can access quickly.

If I'm unable to find a reasonable pre-trained  Q&amp;A model in time, a semantic search model would be the next best option. I'm sure this could be done with some sort of fine-tuned BERT model, but due to my time crunch, I really need one already tuned towards semantic search capabilities.

Google Colab links would be ideal, but anything helps. Thanks!",t2_4w4u8ckq,False,,0,False,Document-Based Question Answering/Semantic Search,[],r/deeplearning,False,6,,0,,False,t3_n5wxla,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620296417.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I need a pre-trained model where I can input text documents (or fine-tune with) and have it answer  reading comprehension-type questions. Obviously, GPT-3 would be perfect for this, but I need it by tomorrow and don&amp;#39;t think I&amp;#39;ll receive login credentials to the API for at least another week. However, the task isn&amp;#39;t all too complex, so I&amp;#39;m looking for a decent alternative that I can access quickly.&lt;/p&gt;

&lt;p&gt;If I&amp;#39;m unable to find a reasonable pre-trained  Q&amp;amp;A model in time, a semantic search model would be the next best option. I&amp;#39;m sure this could be done with some sort of fine-tuned BERT model, but due to my time crunch, I really need one already tuned towards semantic search capabilities.&lt;/p&gt;

&lt;p&gt;Google Colab links would be ideal, but anything helps. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5wxla,True,,willspag,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n5wxla/documentbased_question_answeringsemantic_search/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n5wxla/documentbased_question_answeringsemantic_search/,66146,1620267617.0,0,,False,,,,,,,
,deeplearning,"A team led by Imperial College Professor and Twitter Chief Scientist Michael Bronstein publishes a paper that aims to geometrically unify the typical architectures of CNNs, GNNs, LSTMs, Transformers, etc. from the perspective of symmetry and invariance to build an ""Erlangen Programme"" for deep neural networks. 

Here is a quick read: [Twitter Tech Lead Michael Bronstein &amp; Team Leverage the Erlangen Programme to Establish the Geometric Foundations of Deep Learning.](https://syncedreview.com/2021/05/05/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-12/)

 The paper *Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges* is on [arXiv](https://arxiv.org/pdf/2104.13478.pdf).",t2_2fv4yodo,False,,0,False,[R] Twitter Tech Lead Michael Bronstein &amp; Team Leverage the Erlangen Programme to Establish the Geometric Foundations of Deep Learning,[],r/deeplearning,False,6,,0,,False,t3_n5iyzz,False,dark,0.75,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1620258261.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A team led by Imperial College Professor and Twitter Chief Scientist Michael Bronstein publishes a paper that aims to geometrically unify the typical architectures of CNNs, GNNs, LSTMs, Transformers, etc. from the perspective of symmetry and invariance to build an &amp;quot;Erlangen Programme&amp;quot; for deep neural networks. &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/05/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-12/""&gt;Twitter Tech Lead Michael Bronstein &amp;amp; Team Leverage the Erlangen Programme to Establish the Geometric Foundations of Deep Learning.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.13478.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5iyzz,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n5iyzz/r_twitter_tech_lead_michael_bronstein_team/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n5iyzz/r_twitter_tech_lead_michael_bronstein_team/,66146,1620229461.0,0,,False,,,,,,,
,deeplearning,,t2_4ba7h526,False,,0,False,"Easy, fast &amp; free option to generate parallel corpora",[],r/deeplearning,False,6,,0,,False,t3_n5jp4t,False,dark,0.81,,public,3,0,{},,False,[],"{'reddit_video': {'bitrate_kbps': 2400, 'fallback_url': 'https://v.redd.it/bv8lvv9ktbx61/DASH_720.mp4?source=fallback', 'height': 720, 'width': 1264, 'scrubber_media_url': 'https://v.redd.it/bv8lvv9ktbx61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/bv8lvv9ktbx61/DASHPlaylist.mpd?a=1626450095%2CNWQ3ZWIyYjhkYWRlMTU3MThlZjkyZTc5YTJlNjZmZjhmZTYyZDAzNDMwZWQxNjVmNjRmNDE0ZjMwNzkzNzIwZg%3D%3D&amp;v=1&amp;f=sd', 'duration': 54, 'hls_url': 'https://v.redd.it/bv8lvv9ktbx61/HLSPlaylist.m3u8?a=1626450095%2COTgzZmY2ZTg2ODI5YjY1ODFkOWI2MzRmMmYxZmQ3ZjBlYjFkYWMxZTkxYmI1N2I3NGU4MmEyYjZmOTRhOTUwMQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,3,,False,False,,False,,[],{},,False,,1620260060.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/bv8lvv9ktbx61,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5jp4t,True,,Meaveready,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n5jp4t/easy_fast_free_option_to_generate_parallel_corpora/,all_ads,False,https://v.redd.it/bv8lvv9ktbx61,66146,1620231260.0,1,"{'reddit_video': {'bitrate_kbps': 2400, 'fallback_url': 'https://v.redd.it/bv8lvv9ktbx61/DASH_720.mp4?source=fallback', 'height': 720, 'width': 1264, 'scrubber_media_url': 'https://v.redd.it/bv8lvv9ktbx61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/bv8lvv9ktbx61/DASHPlaylist.mpd?a=1626450095%2CNWQ3ZWIyYjhkYWRlMTU3MThlZjkyZTc5YTJlNjZmZjhmZTYyZDAzNDMwZWQxNjVmNjRmNDE0ZjMwNzkzNzIwZg%3D%3D&amp;v=1&amp;f=sd', 'duration': 54, 'hls_url': 'https://v.redd.it/bv8lvv9ktbx61/HLSPlaylist.m3u8?a=1626450095%2COTgzZmY2ZTg2ODI5YjY1ODFkOWI2MzRmMmYxZmQ3ZjBlYjFkYWMxZTkxYmI1N2I3NGU4MmEyYjZmOTRhOTUwMQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,,t2_62fy240h,False,,0,False,Generate Lego-based images and videos,[],r/deeplearning,False,6,,0,,False,t3_n5rcds,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1620279560.0,text,6,,,text,reddit.com,False,,,,,https://www.reddit.com/gallery/n5rcds,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5rcds,True,,fazeclan_mu,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n5rcds/generate_legobased_images_and_videos/,all_ads,False,https://www.reddit.com/gallery/n5rcds,66146,1620250760.0,0,,False,,,"{'h3bjt4oqbdx61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 81, 'x': 108, 'u': 'https://preview.redd.it/h3bjt4oqbdx61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c6242ab292f61b6f448541333333bb77d691b63d'}, {'y': 162, 'x': 216, 'u': 'https://preview.redd.it/h3bjt4oqbdx61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=43d1b12436d68f5fc5b571af599c0e160d5dc2f5'}, {'y': 241, 'x': 320, 'u': 'https://preview.redd.it/h3bjt4oqbdx61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=388abc73945ea43c32a2389a2088233d5c91f77c'}, {'y': 482, 'x': 640, 'u': 'https://preview.redd.it/h3bjt4oqbdx61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a6b40f23427aec8b2fa1e8c565616a8e6de0ebdf'}, {'y': 723, 'x': 960, 'u': 'https://preview.redd.it/h3bjt4oqbdx61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2ef6037e5608bff6e137a37b67e22fd8791dc101'}], 's': {'y': 780, 'x': 1035, 'u': 'https://preview.redd.it/h3bjt4oqbdx61.jpg?width=1035&amp;format=pjpg&amp;auto=webp&amp;s=2a827593acbde711d023abbf28447240e41135d4'}, 'id': 'h3bjt4oqbdx61'}, 'xj52kloqbdx61': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/xj52kloqbdx61.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=47dfe4934aeb6039b7b168ccb0bc61ae8b6811c3'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/xj52kloqbdx61.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=76515652b6a00d17529440c1d48a503c1f053016'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/xj52kloqbdx61.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=35a963d62aef4b61d73531b766cdf1a99ccdc401'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/xj52kloqbdx61.gif?width=640&amp;crop=smart&amp;format=png8&amp;s=0a913985bd9a78cb0f9d145d7628c72b76d7262f'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/xj52kloqbdx61.gif?width=960&amp;crop=smart&amp;format=png8&amp;s=43cd89fe83956c13580815beadf84b60eed99f8a'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/xj52kloqbdx61.gif?width=1080&amp;crop=smart&amp;format=png8&amp;s=c7cf9c99de7748083af81fc534dfbbc0ed00a1d2'}], 's': {'y': 720, 'gif': 'https://i.redd.it/xj52kloqbdx61.gif', 'mp4': 'https://preview.redd.it/xj52kloqbdx61.gif?format=mp4&amp;s=85d2a05153d68f260131d9c05ff9d72a65d1816c', 'x': 1280}, 'id': 'xj52kloqbdx61'}, 'qrhq28oqbdx61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 71, 'x': 108, 'u': 'https://preview.redd.it/qrhq28oqbdx61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=41f3ccaac734606e5e1bfa6d298098a96811717b'}, {'y': 143, 'x': 216, 'u': 'https://preview.redd.it/qrhq28oqbdx61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba86aa3ba3dbaf54abeb4e97c1abdd39a0ca3603'}, {'y': 212, 'x': 320, 'u': 'https://preview.redd.it/qrhq28oqbdx61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a48aceab32394c1b2906b7f9c548dae91c1b4243'}, {'y': 425, 'x': 640, 'u': 'https://preview.redd.it/qrhq28oqbdx61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d8b5f004bb645574ef9df6d562b66061f0ea4d76'}, {'y': 637, 'x': 960, 'u': 'https://preview.redd.it/qrhq28oqbdx61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=384773124f5343bf563ce68b5c15c4f40c0f90ae'}, {'y': 717, 'x': 1080, 'u': 'https://preview.redd.it/qrhq28oqbdx61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=db734682aedb827da388796cbdb813877bcfb23e'}], 's': {'y': 1365, 'x': 2055, 'u': 'https://preview.redd.it/qrhq28oqbdx61.jpg?width=2055&amp;format=pjpg&amp;auto=webp&amp;s=3cc0b0c8a2e23908d6fed480bf35608222e87e33'}, 'id': 'qrhq28oqbdx61'}, 'zzjhhjoqbdx61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/zzjhhjoqbdx61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=60425c0d682f23bc88f9a8e747404da5ff1460e7'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/zzjhhjoqbdx61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e4407cdb9ee207aaa0b89c2f535532818bcae4b5'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/zzjhhjoqbdx61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9b8d5abf0288e1d6d3c48204506af04e283ea766'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/zzjhhjoqbdx61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d58739457d415cbf564f28280d5eba2169a8ff4d'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/zzjhhjoqbdx61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f345ab7765b79f1c6cb216afd967f19d7aba5804'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/zzjhhjoqbdx61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=18e898bcf1f74c2d28d34f59582616d5c5f04490'}], 's': {'y': 1080, 'x': 1920, 'u': 'https://preview.redd.it/zzjhhjoqbdx61.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=fa6dd76b9b6c8d693ed3891d4a301ecc180c8bfc'}, 'id': 'zzjhhjoqbdx61'}, '0z90gjkqbdx61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 58, 'x': 108, 'u': 'https://preview.redd.it/0z90gjkqbdx61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=60c8b8a4578f013d55ea548cd5ff5a9c84413d80'}, {'y': 117, 'x': 216, 'u': 'https://preview.redd.it/0z90gjkqbdx61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b652ebce4c0ff5ea7e305e4e4bfc384f204aaf24'}, {'y': 174, 'x': 320, 'u': 'https://preview.redd.it/0z90gjkqbdx61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7f57a7c0964b131c5bbdb4e8c2e81d9c6452c37b'}, {'y': 349, 'x': 640, 'u': 'https://preview.redd.it/0z90gjkqbdx61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f7d2327f8ae43c2626b76c927d8c044431469001'}, {'y': 523, 'x': 960, 'u': 'https://preview.redd.it/0z90gjkqbdx61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=95e83ef513769671df42c9cabd68e8928e0ee556'}], 's': {'y': 540, 'x': 990, 'u': 'https://preview.redd.it/0z90gjkqbdx61.jpg?width=990&amp;format=pjpg&amp;auto=webp&amp;s=cbaabcaec8b047ba4a9e729760e215696fc5348a'}, 'id': '0z90gjkqbdx61'}, 'k5k828lqbdx61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 72, 'x': 108, 'u': 'https://preview.redd.it/k5k828lqbdx61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0a82f92cdad2f991d72426ebbe9d9b29d7db90fb'}, {'y': 144, 'x': 216, 'u': 'https://preview.redd.it/k5k828lqbdx61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c1e40de63deb486fe83c3dc8737709981d2bf09b'}, {'y': 213, 'x': 320, 'u': 'https://preview.redd.it/k5k828lqbdx61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4977b348d24ea336649cba0372ef707bef22e660'}, {'y': 426, 'x': 640, 'u': 'https://preview.redd.it/k5k828lqbdx61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=794a06ed259453a0dc3cbf4ef0f009573bc60c97'}, {'y': 640, 'x': 960, 'u': 'https://preview.redd.it/k5k828lqbdx61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e6af66fdde1157715a7261758fa3aa2ead16a008'}, {'y': 720, 'x': 1080, 'u': 'https://preview.redd.it/k5k828lqbdx61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dc50eb24b7e084792656095c6bfe26fb11e068c8'}], 's': {'y': 750, 'x': 1125, 'u': 'https://preview.redd.it/k5k828lqbdx61.jpg?width=1125&amp;format=pjpg&amp;auto=webp&amp;s=4fe76af97b67ea7d7848b2d1139f6badd9f5196d'}, 'id': 'k5k828lqbdx61'}, 'djvgx3oqbdx61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 67, 'x': 108, 'u': 'https://preview.redd.it/djvgx3oqbdx61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ae8c410557da1c5749751269834af7ce46684abc'}, {'y': 135, 'x': 216, 'u': 'https://preview.redd.it/djvgx3oqbdx61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dae311e5c035fc6f2e7c355d82048b6953a81f47'}, {'y': 200, 'x': 320, 'u': 'https://preview.redd.it/djvgx3oqbdx61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=155215bf5543e28c02316f1e85bd36601b3f6b18'}, {'y': 400, 'x': 640, 'u': 'https://preview.redd.it/djvgx3oqbdx61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9eeac01058c56489e9145c6037d7d0c7bc5fbb9e'}, {'y': 601, 'x': 960, 'u': 'https://preview.redd.it/djvgx3oqbdx61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=686f837a28c5ad90959e66697824e2a718c4d259'}, {'y': 676, 'x': 1080, 'u': 'https://preview.redd.it/djvgx3oqbdx61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ce6b801dd1fb18bbe27708df0b2a1c62c931ee81'}], 's': {'y': 1005, 'x': 1605, 'u': 'https://preview.redd.it/djvgx3oqbdx61.jpg?width=1605&amp;format=pjpg&amp;auto=webp&amp;s=d1a60d05a66b6fba1074cb31069d965bf4056d1a'}, 'id': 'djvgx3oqbdx61'}, 'oll1l3oqbdx61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/oll1l3oqbdx61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0948597bb686ea94428e71f0ab5a5be03efd8280'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/oll1l3oqbdx61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=154752828f8c2b6d48f65aed4242ef93bbd6d7d4'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/oll1l3oqbdx61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef0b7806d28a207014bfe016ce9fe549c3d85fd3'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/oll1l3oqbdx61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df0e7f77d8d6e25b0a6c2ab37313b07e16a97e31'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/oll1l3oqbdx61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fa8d4227a2a5ec67be4b6537ecc365c06969f049'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/oll1l3oqbdx61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5bf10b1e7a81c60a76fb58d491cdfb13520a7941'}], 's': {'y': 1080, 'x': 1920, 'u': 'https://preview.redd.it/oll1l3oqbdx61.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=8b9f520ccf9e825e704dec95c7bf1064eb16f0c8'}, 'id': 'oll1l3oqbdx61'}, '6rbcxzkqbdx61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 56, 'x': 108, 'u': 'https://preview.redd.it/6rbcxzkqbdx61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8540f68f808bcff7237ee06a6e08bddb70db9cd6'}, {'y': 113, 'x': 216, 'u': 'https://preview.redd.it/6rbcxzkqbdx61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ff8f23d349c6e8b4f3f74d11dfb3624ef51016f6'}, {'y': 168, 'x': 320, 'u': 'https://preview.redd.it/6rbcxzkqbdx61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4a69653ccd7a4fb348d8caba758c456f9ad65f18'}, {'y': 336, 'x': 640, 'u': 'https://preview.redd.it/6rbcxzkqbdx61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1e389a2b81e0998525ce250412c6ea34cf27558a'}, {'y': 504, 'x': 960, 'u': 'https://preview.redd.it/6rbcxzkqbdx61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=67c911de05089836f53dbff13f25e3a64f651cac'}, {'y': 567, 'x': 1080, 'u': 'https://preview.redd.it/6rbcxzkqbdx61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6e530664fb3f4426b6373e202b6d0c704ecbcd32'}], 's': {'y': 630, 'x': 1200, 'u': 'https://preview.redd.it/6rbcxzkqbdx61.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=429b5720461afe45d13abc380ba8a0052c796df2'}, 'id': '6rbcxzkqbdx61'}}",,,True,"{'items': [{'media_id': 'xj52kloqbdx61', 'id': 42909153}, {'media_id': 'k5k828lqbdx61', 'id': 42909154}, {'media_id': 'djvgx3oqbdx61', 'id': 42909155}, {'media_id': '6rbcxzkqbdx61', 'id': 42909156}, {'media_id': 'zzjhhjoqbdx61', 'id': 42909157}, {'media_id': 'h3bjt4oqbdx61', 'id': 42909158}, {'media_id': '0z90gjkqbdx61', 'id': 42909159}, {'media_id': 'oll1l3oqbdx61', 'id': 42909160}, {'media_id': 'qrhq28oqbdx61', 'id': 42909161}]}"
,deeplearning,,t2_c14wpji,False,,0,False,Train Your GAN With 1/10th of the Data! NVIDIA ADA Explained,[],r/deeplearning,False,6,,0,,False,t3_n5e6yg,False,dark,0.75,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,False,,1620244697.0,text,6,,,text,louisbouchard.ai,False,,,,,https://www.louisbouchard.ai/nvidia-ada/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5e6yg,True,,OnlyProggingForFun,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n5e6yg/train_your_gan_with_110th_of_the_data_nvidia_ada/,all_ads,False,https://www.louisbouchard.ai/nvidia-ada/,66146,1620215897.0,0,,False,,,,,,,
,deeplearning,,t2_44mbtmjy,False,,0,False,"Latest from FB and Max Planck Researchers: ""Our method can be used to directly drive a virtual character or visualise joint torques!""",[],r/deeplearning,False,6,,0,,False,t3_n5ozay,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1620273427.0,text,6,,,text,self.LatestInML,False,,,,,/r/LatestInML/comments/n5oxwf/latest_from_fb_and_max_planck_researchers_our/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5ozay,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n5ozay/latest_from_fb_and_max_planck_researchers_our/,all_ads,False,/r/LatestInML/comments/n5oxwf/latest_from_fb_and_max_planck_researchers_our/,66146,1620244627.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper](https://www.catalyzex.com/paper/arxiv:2105.01057)\n\nhttps://reddit.com/link/n5oxwf/video/ffm7xnxfqcx61/player\n\n👇 Free extension to get code for ML papers (❤️'d by Andrew Ng)\n\nChrome: https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil\n\nFirefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Latest from FB and Max Planck Researchers: ""Our method can be used to directly drive a virtual character or visualise joint torques!""', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'ffm7xnxfqcx61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/n5oxwf/asset/ffm7xnxfqcx61/DASHPlaylist.mpd?a=1626450095%2CZDFkYmI3OWJiMTlhZGQ2MmYyZWU4ODg2ODM0NzQwNGVmNDE3NTI3MzU2NDNiOTMxMWM3YmMyODFhNzAxMTJhMg%3D%3D&amp;v=1&amp;f=sd', 'x': 640, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/n5oxwf/asset/ffm7xnxfqcx61/HLSPlaylist.m3u8?a=1626450095%2CNGNkNjI0ZmY5ZGY2M2Y5NTAxNzU3YWZmMjcyZGI5MmIyNzYwNDk5MzAxNjQyY2E2MzQ2YzcyYTQ0YjBlOTgyNQ%3D%3D&amp;v=1&amp;f=sd', 'id': 'ffm7xnxfqcx61', 'isGif': False}}, 'name': 't3_n5oxwf', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1620273323.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2105.01057""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/n5oxwf/video/ffm7xnxfqcx61/player""&gt;https://reddit.com/link/n5oxwf/video/ffm7xnxfqcx61/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39;d by Andrew Ng)&lt;/p&gt;\n\n&lt;p&gt;Chrome: &lt;a href=""https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'n5oxwf', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/n5oxwf/latest_from_fb_and_max_planck_researchers_our/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/n5oxwf/latest_from_fb_and_max_planck_researchers_our/', 'subreddit_subscribers': 7049, 'created_utc': 1620244523.0, 'num_crossposts': 6, 'media': None, 'is_video': False}]",t3_n5oxwf,,,,,
,deeplearning,,t2_85wvbl2u,False,,0,False,My thoughts on Udacity's Deep Learning Nanodegree,[],r/deeplearning,False,6,,0,,False,t3_n5n2xl,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1620268515.0,text,6,,,text,onlinecourseing.com,False,,,,,https://onlinecourseing.com/review-deep-learning-nanodegree-from-udacity/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5n2xl,True,,Hawkeyee96,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n5n2xl/my_thoughts_on_udacitys_deep_learning_nanodegree/,all_ads,False,https://onlinecourseing.com/review-deep-learning-nanodegree-from-udacity/,66146,1620239715.0,0,,False,,,,,,,
,deeplearning,"In a recurrent neural network, for instance I need to determine the sentiment of the following sentence 'I was bored through most of the movie. '

Each word in the sentence will be passed as an input at various timestamps where the hidden layer output (state output) of the current timestamp is passed as an additional input for the successive timestamp. 

1. Whether the loss will be calculated at each time stamp followed by back propagation through time?
                              (OR)
2. The loss is calculated at the end of the last time stamp followed by backpropagation through time?",t2_4ulmt5ig,False,,0,False,At which step does the cost gets calculated in RNN,[],r/deeplearning,False,6,,0,,False,t3_n5ks34,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620262772.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In a recurrent neural network, for instance I need to determine the sentiment of the following sentence &amp;#39;I was bored through most of the movie. &amp;#39;&lt;/p&gt;

&lt;p&gt;Each word in the sentence will be passed as an input at various timestamps where the hidden layer output (state output) of the current timestamp is passed as an additional input for the successive timestamp. &lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Whether the loss will be calculated at each time stamp followed by back propagation through time?
                          (OR)&lt;/li&gt;
&lt;li&gt;The loss is calculated at the end of the last time stamp followed by backpropagation through time?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5ks34,True,,Night_Crawler7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n5ks34/at_which_step_does_the_cost_gets_calculated_in_rnn/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n5ks34/at_which_step_does_the_cost_gets_calculated_in_rnn/,66146,1620233972.0,0,,False,,,,,,,
,deeplearning,,t2_6k1mre3v,False,,0,False,Helping fetching waymo dataset,[],r/deeplearning,False,6,,0,,False,t3_n5jtoc,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1620260382.0,text,6,,,text,self.datasets,False,,,,,/r/datasets/comments/n5jscr/helping_fetching_waymo_dataset/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5jtoc,True,,sYou-suck,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n5jtoc/helping_fetching_waymo_dataset/,all_ads,False,/r/datasets/comments/n5jscr/helping_fetching_waymo_dataset/,66146,1620231582.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'datasets', 'selftext': ""I would like to use the waymo dataset for creating a bird's eye view of the frames.  \nThe whole dataset is very huge, that my local machine can't hold them.  \nI tried to take a part of a dataset and use in google colab. Yet the size exceeds colab's limit."", 'author_fullname': 't2_6k1mre3v', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Helping fetching waymo dataset', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/datasets', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'discussion', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_n5jscr', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1620260290.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.datasets', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I would like to use the waymo dataset for creating a bird&amp;#39;s eye view of the frames.&lt;br/&gt;\nThe whole dataset is very huge, that my local machine can&amp;#39;t hold them.&lt;br/&gt;\nI tried to take a part of a dataset and use in google colab. Yet the size exceeds colab&amp;#39;s limit.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '1df84e76-c2ca-11e6-bfd4-0e338549dab6', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r97t', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'n5jscr', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'sYou-suck', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/datasets/comments/n5jscr/helping_fetching_waymo_dataset/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/datasets/comments/n5jscr/helping_fetching_waymo_dataset/', 'subreddit_subscribers': 143564, 'created_utc': 1620231490.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_n5jscr,,,,,
,deeplearning,"
## 200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support in  NLU 3.0 Release and much more
We are incredibly excited to announce the release of `NLU 3.0.0` which makes most of John Snow Labs medical healthcare model available in just 1 line of code in NLU.
These models are the most accurate in their domains and highly scalable in Spark clusters.  
In addition, `Spark 3.0.X`  and `Spark 3.1.X ` is now supported, together with Python3.8

This is enabled by the amazing [Spark NLP3.0.1](https://nlp.johnsnowlabs.com/docs/en/release_notes#300) and [Spark NLP for Healthcare 3.0.1](https://nlp.johnsnowlabs.com/docs/en/licensed_release_notes#301) releases.

# New Features
- Over 200 new models for the `healthcare` domain
- 6 new classes of models, Assertion, Sentence/Chunk Resolvers, Relation Extractors, Medical NER models, De-Identificator Models
- Spark 3.0.X and 3.1.X support
- Python 3.8 Support
- New Output level `relation`
- 1 Line to install NLU  just run `!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash`
- [Various new EMR and Databricks versions supported](https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.0.0)
- GPU Mode, more then 600% speedup by enabling GPU mode.
- Authorized mode for licensed features

## New Documentation
- [NLU for Healthcare Examples](https://nlu.johnsnowlabs.com/docs/en/examples_hc#usage-examples-of-nluload)
- [Instrunctions to authorize your environment to use Licensed features](https://nlu.johnsnowlabs.com/docs/en/examples_hc#authorize-access-to-licensed-features-and-install-healthcare-dependencies)


## New Notebooks
- [Medical Named Entity Extraction (NER) notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/medical_named_entity_recognition/overview_medical_entity_recognizers.ipynb)
- [Relation extraction notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/relation_extraction/overview_relation.ipynb)
- [Entity Resolution overview notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/entity_resolution/entity_resolvers_overview.ipynb)
- [Assertion overview notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/assertion/assertion_overview.ipynb)
- [De-Identification overview notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/de_identification/DeIdentification_model_overview.ipynb)
- [Graph NLU tutorial](https://github.com/JohnSnowLabs/nlu/blob/3.0rc1/examples/webinars_conferences_etc/graph_ai_summit/Healthcare_Graph_NLU_COVID_Tigergraph.ipynb)


## AssertionDLModels

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [assert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html) | [assertion_dl](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html)                   |
| English  | [assert.biobert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html) | [assertion_dl_biobert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html)                   |
| English  | [assert.healthcare](https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html) | [assertion_dl_healthcare](https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html)                   |
| English  | [assert.large](https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html) | [assertion_dl_large](https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html)                   |

##  New Word Embeddings

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [embed.glove.clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html) | [embeddings_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html)                   |
| English  | [embed.glove.biovec](https://nlp.johnsnowlabs.com/2020/06/02/embeddings_biovec_en.html) | [embeddings_biovec](https://nlp.johnsnowlabs.com/2020/06/02/embeddings_biovec_en.html)                   |
| English  | [embed.glove.healthcare](https://nlp.johnsnowlabs.com/2020/03/26/embeddings_healthcare_en.html) | [embeddings_healthcare](https://nlp.johnsnowlabs.com/2020/03/26/embeddings_healthcare_en.html)                   |
| English  | [embed.glove.healthcare_100d](https://nlp.johnsnowlabs.com/2020/05/29/embeddings_healthcare_100d_en.html) | [embeddings_healthcare_100d](https://nlp.johnsnowlabs.com/2020/05/29/embeddings_healthcare_100d_en.html)                   |
| English  | en.embed.glove.icdoem | embeddings_icdoem          |
| English  | en.embed.glove.icdoem_2ng | embeddings_icdoem_2ng          |

## Sentence Entity resolvers

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | embed_sentence.biobert.mli | sbiobert_base_cased_mli          |
| English  | resolve | sbiobertresolve_cpt          |
| English  | resolve.cpt | sbiobertresolve_cpt          |
| English  | resolve.cpt.augmented | sbiobertresolve_cpt_augmented          |
| English  | resolve.cpt.procedures_augmented | sbiobertresolve_cpt_procedures_augmented          |
| English  | resolve.hcc.augmented | sbiobertresolve_hcc_augmented          |
| English  | [resolve.icd10cm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html) | [sbiobertresolve_icd10cm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html)                   |
| English  | [resolve.icd10cm.augmented](https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html) | [sbiobertresolve_icd10cm_augmented](https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html)                   |
| English  | [resolve.icd10cm.augmented_billable](https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html) | [sbiobertresolve_icd10cm_augmented_billable_hcc](https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html)                   |
| English  | [resolve.icd10pcs](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html) | [sbiobertresolve_icd10pcs](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html)                   |
| English  | [resolve.icdo](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html) | [sbiobertresolve_icdo](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html)                   |
| English  | [resolve.rxcui](https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html) | [sbiobertresolve_rxcui](https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html)                   |
| English  | [resolve.rxnorm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html) | [sbiobertresolve_rxnorm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html)                   |
| English  | [resolve.snomed](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html) | [sbiobertresolve_snomed_auxConcepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html)                   |
| English  | [resolve.snomed.aux_concepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html) | [sbiobertresolve_snomed_auxConcepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html)                   |
| English  | [resolve.snomed.aux_concepts_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html) | [sbiobertresolve_snomed_auxConcepts_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html)                   |
| English  | [resolve.snomed.findings](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html) | [sbiobertresolve_snomed_findings](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html)                   |
| English  | [resolve.snomed.findings_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html) | [sbiobertresolve_snomed_findings_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html)                   |

## RelationExtractionModel

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | relation.posology | posology_re          |
| English  | [relation](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html) | [redl_bodypart_direction_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html)                   |
| English  | [relation.bodypart.direction](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html) | [redl_bodypart_direction_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html)                   |
| English  | [relation.bodypart.problem](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_problem_biobert_en.html) | [redl_bodypart_problem_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_problem_biobert_en.html)                   |
| English  | [relation.bodypart.procedure](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_procedure_test_biobert_en.html) | [redl_bodypart_procedure_test_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_procedure_test_biobert_en.html)                   |
| English  | [relation.chemprot](https://nlp.johnsnowlabs.com/2021/02/04/redl_chemprot_biobert_en.html) | [redl_chemprot_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_chemprot_biobert_en.html)                   |
| English  | [relation.clinical](https://nlp.johnsnowlabs.com/2021/02/04/redl_clinical_biobert_en.html) | [redl_clinical_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_clinical_biobert_en.html)                   |
| English  | [relation.date](https://nlp.johnsnowlabs.com/2021/02/04/redl_date_clinical_biobert_en.htmls) | [redl_date_clinical_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_date_clinical_biobert_en.htmls)                   |
| English  | [relation.drug_drug_interaction](https://nlp.johnsnowlabs.com/2021/02/04/redl_drug_drug_interaction_biobert_en.html) | [redl_drug_drug_interaction_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_drug_drug_interaction_biobert_en.html)                   |
| English  | [relation.humen_phenotype_gene](https://nlp.johnsnowlabs.com/2021/02/04/redl_human_phenotype_gene_biobert_en.html) | [redl_human_phenotype_gene_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_human_phenotype_gene_biobert_en.html)                   |
| English  | [relation.temporal_events](https://nlp.johnsnowlabs.com/2021/02/04/redl_temporal_events_biobert_en.html) | [redl_temporal_events_biobert](https://nlp.johnsnowlabs.com/2021/02/04/redl_temporal_events_biobert_en.html)                   |



## NERDLModels

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
|English  | [med_ner.ade.clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinical_en.html) | [ner_ade_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinical_en.html)                   |
| English  | [med_ner.ade.clinical_bert](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinicalbert_en.html) | [ner_ade_clinicalbert](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinicalbert_en.html)                   |
| English  | [med_ner.ade.ade_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_healthcare_en.html) | [ner_ade_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_healthcare_en.html)                   |
| English  | [med_ner.anatomy](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_en.html) | [ner_anatomy](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_en.html)                   |
| English  | [med_ner.anatomy.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_anatomy_biobert_en.html) | [ner_anatomy_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_anatomy_biobert_en.html)                   |
| English  | [med_ner.anatomy.coarse](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html) | [ner_anatomy_coarse](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html)                   |
| English  | [med_ner.anatomy.coarse_biobert](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_biobert_en.html) | [ner_anatomy_coarse_biobert](https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_biobert_en.html)                   |
| English  | [med_ner.aspect_sentiment](https://nlp.johnsnowlabs.com/2021/03/31/ner_aspect_based_sentiment_en.html) | [ner_aspect_based_sentiment](https://nlp.johnsnowlabs.com/2021/03/31/ner_aspect_based_sentiment_en.html)                   |
| English  | [med_ner.bacterial_species](https://nlp.johnsnowlabs.com/2021/04/01/ner_bacterial_species_en.html) | [ner_bacterial_species](https://nlp.johnsnowlabs.com/2021/04/01/ner_bacterial_species_en.html)                   |
| English  | [med_ner.bionlp](https://nlp.johnsnowlabs.com/2021/03/31/ner_bionlp_en.html) | [ner_bionlp](https://nlp.johnsnowlabs.com/2021/03/31/ner_bionlp_en.html)                   |
| English  | [med_ner.bionlp.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_bionlp_biobert_en.html) | [ner_bionlp_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_bionlp_biobert_en.html)                   |
| English  | [med_ner.cancer](https://nlp.johnsnowlabs.com/2021/03/31/ner_cancer_genetics_en.html) | [ner_cancer_genetics](https://nlp.johnsnowlabs.com/2021/03/31/ner_cancer_genetics_en.html)                   |
| Englishs | [med_ner.cellular](https://nlp.johnsnowlabs.com/2021/03/31/ner_cellular_en.html) | [ner_cellular](https://nlp.johnsnowlabs.com/2021/03/31/ner_cellular_en.html)                   |
| English  | [med_ner.cellular.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_cellular_biobert_en.html) | [ner_cellular_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_cellular_biobert_en.html)                   |
| English  | [med_ner.chemicals](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemicals_en.html) | [ner_chemicals](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemicals_en.html)                   |
| English  | [med_ner.chemprot](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemprot_biobert_en.html) | [ner_chemprot_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_chemprot_biobert_en.html)           |
| English  | [med_ner.chemprot.clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_chemprot_clinical_en.html) | [ner_chemprot_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_chemprot_clinical_en.html)           |
| English  | [med_ner.clinical](https://nlp.johnsnowlabs.com/2020/01/30/ner_clinical_en.html) | [ner_clinical](https://nlp.johnsnowlabs.com/2020/01/30/ner_clinical_en.html)           |
| English  | [med_ner.clinical.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_clinical_biobert_en.html) | [ner_clinical_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_clinical_biobert_en.html)           |
| English  | med_ner.clinical.noncontrib | ner_clinical_noncontrib          |
| English  | [med_ner.diseases](https://nlp.johnsnowlabs.com/2021/03/31/ner_diseases_en.html) | [ner_diseases](https://nlp.johnsnowlabs.com/2021/03/31/ner_diseases_en.html)           |
| English  | [med_ner.diseases.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_biobert_en.html) | [ner_diseases_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_biobert_en.html)           |
| English  | [med_ner.diseases.large](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_large_en.html) | [ner_diseases_large](https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_large_en.html)           |
| English  | [med_ner.drugs](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_en.html) | [ner_drugs](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_en.html)           |
| English  | [med_ner.drugsgreedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_greedy_en.html) | [ner_drugs_greedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_greedy_en.html)           |
| English  | [med_ner.drugs.large](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_large_en.html) | [ner_drugs_large](https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_large_en.html)           |
| English  | [med_ner.events_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_biobert_en.html) | [ner_events_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_biobert_en.html)           |
| English  | [med_ner.events_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_events_clinical_en.html) | [ner_events_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_events_clinical_en.html)           |
| English  | [med_ner.events_healthcre](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_healthcare_en.html) | [ner_events_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_events_healthcare_en.html)           |
| English  | [med_ner.financial_contract](https://nlp.johnsnowlabs.com/2021/04/01/ner_financial_contract_en.html) | [ner_financial_contract](https://nlp.johnsnowlabs.com/2021/04/01/ner_financial_contract_en.html)           |
| English  | [med_ner.healthcare](https://nlp.johnsnowlabs.com/2021/03/31/ner_healthcare_de.html) | [ner_healthcare](https://nlp.johnsnowlabs.com/2021/03/31/ner_healthcare_de.html)           |
| English  | [med_ner.human_phenotype.gene_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_gene_biobert_en.html) | [ner_human_phenotype_gene_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_gene_biobert_en.html)           |
| English  | [med_ner.human_phenotype.gene_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html) | [ner_human_phenotype_gene_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html)           |
| English  | [med_ner.human_phenotype.go_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_go_biobert_en.html) | [ner_human_phenotype_go_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_go_biobert_en.html)           |
| English  | [med_ner.human_phenotype.go_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html) | [ner_human_phenotype_go_clinical](https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html)           |
| English  | [med_ner.jsl](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_en.html) | [ner_jsl](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_en.html)           |
| English  | [med_ner.jsl.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_biobert_en.html) | [ner_jsl_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_biobert_en.html)           |
| English  | [med_ner.jsl.enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_enriched_en.html) | [ner_jsl_enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_enriched_en.html)           |
| English  | [med_ner.jsl.enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_enriched_biobert_en.html) | [ner_jsl_enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_enriched_biobert_en.html)           |
| English  | [med_ner.measurements](https://nlp.johnsnowlabs.com/2021/04/01/ner_measurements_clinical_en.html) | [ner_measurements_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_measurements_clinical_en.html)           |
| English  | [med_ner.medmentions](https://nlp.johnsnowlabs.com/2021/04/01/ner_medmentions_coarse_en.html) | [ner_medmentions_coarse](https://nlp.johnsnowlabs.com/2021/04/01/ner_medmentions_coarse_en.html)           |
| English  | [med_ner.posology](https://nlp.johnsnowlabs.com/2020/04/15/ner_posology_en.html) | [ner_posology](https://nlp.johnsnowlabs.com/2020/04/15/ner_posology_en.html)           |
| English  | [med_ner.posology.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_biobert_en.html) | [ner_posology_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_biobert_en.html)           |
| English  | [med_ner.posology.greedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_greedy_en.html) | [ner_posology_greedy](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_greedy_en.html)           |
| English  | [med_ner.posology.healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_healthcare_en.html) | [ner_posology_healthcare](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_healthcare_en.html)           |
| English  | [med_ner.posology.large](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_large_en.html) | [ner_posology_large](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_large_en.html)           |
| English  | [med_ner.posology.large_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_large_biobert_en.html) | [ner_posology_large_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_large_biobert_en.html)           |
| English  | [med_ner.posology.small](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_small_en.html) | [ner_posology_small](https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_small_en.html)           |
| English  | [med_ner.radiology](https://nlp.johnsnowlabs.com/2021/03/31/ner_radiology_en.html) | [ner_radiology](https://nlp.johnsnowlabs.com/2021/03/31/ner_radiology_en.html)           |
| English  | [med_ner.radiology.wip_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_radiology_wip_clinical_en.html) | [ner_radiology_wip_clinical](https://nlp.johnsnowlabs.com/2021/04/01/ner_radiology_wip_clinical_en.html)           |
| English  | [med_ner.risk_factors](https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html) | [ner_risk_factors](https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html)           |
| English  | [med_ner.risk_factors.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_risk_factors_biobert_en.html) | [ner_risk_factors_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_risk_factors_biobert_en.html)           |
| English  | med_ner.i2b2 | nerdl_i2b2          |
| English  | [med_ner.tumour](https://nlp.johnsnowlabs.com/2021/04/01/nerdl_tumour_demo_en.html) | [nerdl_tumour_demo](https://nlp.johnsnowlabs.com/2021/04/01/nerdl_tumour_demo_en.html)           |
| English  | med_ner.jsl.wip.clinical | jsl_ner_wip_clinical          |
| English  | [med_ner.jsl.wip.clinical.greedy](https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html) | [jsl_ner_wip_greedy_clinical](https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html)           |
| English  | [med_ner.jsl.wip.clinical.modifier](https://nlp.johnsnowlabs.com/2021/04/01/jsl_ner_wip_modifier_clinical_en.html) | [jsl_ner_wip_modifier_clinical](https://nlp.johnsnowlabs.com/2021/04/01/jsl_ner_wip_modifier_clinical_en.html)           |
| English  | [med_ner.jsl.wip.clinical.rd](https://nlp.johnsnowlabs.com/2021/04/01/jsl_rd_ner_wip_greedy_clinical_en.html) | [jsl_rd_ner_wip_greedy_clinical](https://nlp.johnsnowlabs.com/2021/04/01/jsl_rd_ner_wip_greedy_clinical_en.html)           |


## De-Identification Models

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [med_ner.deid.augmented](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_augmented_en.html) | [ner_deid_augmented](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_augmented_en.html)           |
| English  | [med_ner.deid.biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_biobert_en.html) | [ner_deid_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_biobert_en.html)           |
| English  | [med_ner.deid.enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_enriched_en.html) | [ner_deid_enriched](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_enriched_en.html)           |
| English  | [med_ner.deid.enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_enriched_biobert_en.html) | [ner_deid_enriched_biobert](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_enriched_biobert_en.html)           |
| English  | [med_ner.deid.large](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_large_en.html) | [ner_deid_large](https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_large_en.html)           |
| English  | [med_ner.deid.sd](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_en.html) | [ner_deid_sd](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_en.html)           |
| English  | [med_ner.deid.sd_large](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_large_en.html) | [ner_deid_sd_large](https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_large_en.html)           |
| English  | med_ner.deid | nerdl_deid          |
| English  | med_ner.deid.synthetic | ner_deid_synthetic          |
| English  | [med_ner.deid.dl](https://nlp.johnsnowlabs.com/2021/03/31/ner_deidentify_dl_en.html) | [ner_deidentify_dl](https://nlp.johnsnowlabs.com/2021/03/31/ner_deidentify_dl_en.html)           |
| English  | [en.de_identify](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html) | [deidentify_rb](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html)           |
| English  | de_identify.rules | deid_rules          |
| English  | [de_identify.clinical](https://nlp.johnsnowlabs.com/2021/01/29/deidentify_enriched_clinical_en.html) | [deidentify_enriched_clinical](https://nlp.johnsnowlabs.com/2021/01/29/deidentify_enriched_clinical_en.html)           |
| English  | [de_identify.large](https://nlp.johnsnowlabs.com/2020/08/04/deidentify_large_en.html) | [deidentify_large](https://nlp.johnsnowlabs.com/2020/08/04/deidentify_large_en.html)           |
| English  | [de_identify.rb](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html) | [deidentify_rb](https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html)           |
| English  | de_identify.rb_no_regex | deidentify_rb_no_regex          |



# Chunk resolvers

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | [resolve_chunk.athena_conditions](https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html) | [chunkresolve_athena_conditions_healthcare](https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html)           |
| English  | [resolve_chunk.cpt_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_cpt_clinical_en.html) | [chunkresolve_cpt_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_cpt_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_clinical_en.html) | [chunkresolve_icd10cm_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.diseases_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_diseases_clinical_en.html) | [chunkresolve_icd10cm_diseases_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_diseases_clinical_en.html)           |
| English  | resolve_chunk.icd10cm.hcc_clinical | chunkresolve_icd10cm_hcc_clinical          |
| English  | resolve_chunk.icd10cm.hcc_healthcare | chunkresolve_icd10cm_hcc_healthcare          |
| English  | [resolve_chunk.icd10cm.injuries](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_injuries_clinical_en.html) | [chunkresolve_icd10cm_injuries_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_injuries_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.musculoskeletal](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_musculoskeletal_clinical_en.html) | [chunkresolve_icd10cm_musculoskeletal_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_musculoskeletal_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.neoplasms](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_neoplasms_clinical_en.html) | [chunkresolve_icd10cm_neoplasms_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_neoplasms_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.poison](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_poison_ext_clinical_en.html) | [chunkresolve_icd10cm_poison_ext_clinical](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_poison_ext_clinical_en.html)           |
| English  | [resolve_chunk.icd10cm.puerile](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_puerile_clinical_en.html) | [chunkresolve_icd10cm_puerile_clinical](https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_puerile_clinical_en.html)           |
| English  | resolve_chunk.icd10pcs.clinical | chunkresolve_icd10pcs_clinical          |
| English  | [resolve_chunk.icdo.clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10pcs_clinical_en.html) | [chunkresolve_icdo_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10pcs_clinical_en.html)           |
| English  | [resolve_chunk.loinc](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_loinc_clinical_en.html) | [chunkresolve_loinc_clinical](https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_loinc_clinical_en.html)           |
| English  | [resolve_chunk.rxnorm.cd](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_cd_clinical_en.html) | [chunkresolve_rxnorm_cd_clinical](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_cd_clinical_en.html)           |
| English  | resolve_chunk.rxnorm.in | chunkresolve_rxnorm_in_clinical          |
| English  | resolve_chunk.rxnorm.in_healthcare | chunkresolve_rxnorm_in_healthcare          |
| English  | [resolve_chunk.rxnorm.sbd](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_sbd_clinical_en.html) | [chunkresolve_rxnorm_sbd_clinical](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_sbd_clinical_en.html)           |
| English  | [resolve_chunk.rxnorm.scd](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_scd_clinical_en.html) | [chunkresolve_rxnorm_scd_clinical](https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_scd_clinical_en.html)           |
| English  | resolve_chunk.rxnorm.scdc | chunkresolve_rxnorm_scdc_clinical          |
| English  | resolve_chunk.rxnorm.scdc_healthcare | chunkresolve_rxnorm_scdc_healthcare          |
| English  | [resolve_chunk.rxnorm.xsmall.clinical](https://nlp.johnsnowlabs.com/2020/06/24/chunkresolve_rxnorm_xsmall_clinical_en.html) | [chunkresolve_rxnorm_xsmall_clinical](https://nlp.johnsnowlabs.com/2020/06/24/chunkresolve_rxnorm_xsmall_clinical_en.html)           |
| English  | [resolve_chunk.snomed.findings](https://nlp.johnsnowlabs.com/2020/06/20/chunkresolve_snomed_findings_clinical_en.html) | [chunkresolve_snomed_findings_clinical](https://nlp.johnsnowlabs.com/2020/06/20/chunkresolve_snomed_findings_clinical_en.html)           |


# New Classifiers

| Language | nlu.load() reference                                         | Spark NLP Model reference          |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| English  | classify.icd10.clinical | classifier_icd10cm_hcc_clinical          |
| English  | classify.icd10.healthcare | classifier_icd10cm_hcc_healthcare          |
| English  | [classify.ade.biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_biobert_en.html) | [classifierdl_ade_biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_biobert_en.html)           |
| English  | [classify.ade.clinical](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_clinicalbert_en.html) | [classifierdl_ade_clinicalbert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_clinicalbert_en.html)           |
| English  | [classify.ade.conversational](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_conversational_biobert_en.html) | [classifierdl_ade_conversational_biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_conversational_biobert_en.html)           |
| English  | [classify.gender.biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_biobert_en.html) | [classifierdl_gender_biobert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_biobert_en.html)           |
| English  | [classify.gender.sbert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_sbert_en.html) | [classifierdl_gender_sbert](https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_sbert_en.html)           |
| English  | classify.pico | classifierdl_pico_biobert          |


# German Medical models

| nlu.load() reference                                         | Spark NLP Model reference          |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [embed]    | w2v_cc_300d|
| [embed.w2v]    | w2v_cc_300d|
| [resolve_chunk]    | chunkresolve_ICD10GM|
| [resolve_chunk.icd10gm]    | chunkresolve_ICD10GM|
| resolve_chunk.icd10gm.2021    | chunkresolve_ICD10GM_2021|
| med_ner.legal   | ner_legal|
| med_ner    | ner_healthcare|
| med_ner.healthcare    | ner_healthcare|
| med_ner.healthcare_slim    | ner_healthcare_slim|
| med_ner.traffic    | ner_traffic|

# Spanish Medical models
| nlu.load() reference                                         | Spark NLP Model reference          |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [embed.scielo.150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_150d_es.html) | [embeddings_scielo_150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_150d_es.html)| 
| [embed.scielo.300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_300d_es.html)   | [embeddings_scielo_300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_300d_es.html)| 
| [embed.scielo.50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_50d_es.html)  | [embeddings_scielo_50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_50d_es.html)| 
| [embed.scielowiki.150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_150d_es.html)   | [embeddings_scielowiki_150d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_150d_es.html)| 
| [embed.scielowiki.300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_300d_es.html)   | [embeddings_scielowiki_300d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_300d_es.html)| 
| [embed.scielowiki.50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_50d_es.html)   | [embeddings_scielowiki_50d](https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_50d_es.html)| 
| [embed.sciwiki.150d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_150d_es.html)   | [embeddings_sciwiki_150d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_150d_es.html)| 
| [embed.sciwiki.300d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_300d_es.html)   | [embeddings_sciwiki_300d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_300d_es.html)| 
| [embed.sciwiki.50d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_50d_es.html)   | [embeddings_sciwiki_50d](https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_50d_es.html)| 
| [med_ner](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)   |  [ner_diag_proc](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)| 
| [med_ner.neoplasm](https://nlp.johnsnowlabs.com/2021/03/31/ner_neoplasms_es.html)  | [ner_neoplasms](https://nlp.johnsnowlabs.com/2021/03/31/ner_neoplasms_es.html)| 
| [med_ner.diag_proc](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)  | [ner_diag_proc](https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html)| 

# GPU Mode
You can now enable NLU GPU mode by setting `gpu=true` while loading a model. I.e. `nlu.load('train.sentiment' gpu=True)` . If must resart you kernel, if you already loaded a nlu pipeline withouth GPU mode.

# Output Level Relation
This new output level is used for relation extractors and will give you 1 row per relation extracted.


# Bug fixes
- Fixed a bug that caused loading NLU models in offline mode not to work in some occasions


# 1 line Install NLU
```!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash```

# Install via PIP 
```! pip install nlu pyspark==3.0.1```


## Additional NLU ressources

- [NLU Website](https://nlu.johnsnowlabs.com/)
- [All NLU Tutorial Notebooks](https://nlu.johnsnowlabs.com/docs/en/notebooks)
- [NLU Videos and Blogposts on NLU](https://nlp.johnsnowlabs.com/learn#pythons-nlu-library)
- [NLU on Github](https://github.com/JohnSnowLabs/nlu)
- [Suggestions or Questions? Contact us in Slack!](https://join.slack.com/t/spark-nlp/shared_invite/zt-lutct9gm-kuUazcyFKhuGY3_0AMkxqA)",t2_53n73cus,False,,0,False,"200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support - John Snow Labs NLU 3.0.0",[],r/deeplearning,False,6,,0,,False,t3_n5gusr,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620252751.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h2&gt;200+ State of the Art Medical Models for NER, Entity Resolution, Relation Extraction, Assertion, Spark 3 and Python 3.8 support in  NLU 3.0 Release and much more&lt;/h2&gt;

&lt;p&gt;We are incredibly excited to announce the release of &lt;code&gt;NLU 3.0.0&lt;/code&gt; which makes most of John Snow Labs medical healthcare model available in just 1 line of code in NLU.
These models are the most accurate in their domains and highly scalable in Spark clusters.&lt;br/&gt;
In addition, &lt;code&gt;Spark 3.0.X&lt;/code&gt;  and &lt;code&gt;Spark 3.1.X&lt;/code&gt; is now supported, together with Python3.8&lt;/p&gt;

&lt;p&gt;This is enabled by the amazing &lt;a href=""https://nlp.johnsnowlabs.com/docs/en/release_notes#300""&gt;Spark NLP3.0.1&lt;/a&gt; and &lt;a href=""https://nlp.johnsnowlabs.com/docs/en/licensed_release_notes#301""&gt;Spark NLP for Healthcare 3.0.1&lt;/a&gt; releases.&lt;/p&gt;

&lt;h1&gt;New Features&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Over 200 new models for the &lt;code&gt;healthcare&lt;/code&gt; domain&lt;/li&gt;
&lt;li&gt;6 new classes of models, Assertion, Sentence/Chunk Resolvers, Relation Extractors, Medical NER models, De-Identificator Models&lt;/li&gt;
&lt;li&gt;Spark 3.0.X and 3.1.X support&lt;/li&gt;
&lt;li&gt;Python 3.8 Support&lt;/li&gt;
&lt;li&gt;New Output level &lt;code&gt;relation&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;1 Line to install NLU  just run &lt;code&gt;!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/spark-nlp/releases/tag/3.0.0""&gt;Various new EMR and Databricks versions supported&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GPU Mode, more then 600% speedup by enabling GPU mode.&lt;/li&gt;
&lt;li&gt;Authorized mode for licensed features&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;New Documentation&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://nlu.johnsnowlabs.com/docs/en/examples_hc#usage-examples-of-nluload""&gt;NLU for Healthcare Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlu.johnsnowlabs.com/docs/en/examples_hc#authorize-access-to-licensed-features-and-install-healthcare-dependencies""&gt;Instrunctions to authorize your environment to use Licensed features&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;New Notebooks&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/medical_named_entity_recognition/overview_medical_entity_recognizers.ipynb""&gt;Medical Named Entity Extraction (NER) notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/relation_extraction/overview_relation.ipynb""&gt;Relation extraction notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/entity_resolution/entity_resolvers_overview.ipynb""&gt;Entity Resolution overview notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/assertion/assertion_overview.ipynb""&gt;Assertion overview notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/de_identification/DeIdentification_model_overview.ipynb""&gt;De-Identification overview notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu/blob/3.0rc1/examples/webinars_conferences_etc/graph_ai_summit/Healthcare_Graph_NLU_COVID_Tigergraph.ipynb""&gt;Graph NLU tutorial&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;AssertionDLModels&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html""&gt;assert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html""&gt;assertion_dl&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html""&gt;assert.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html""&gt;assertion_dl_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html""&gt;assert.healthcare&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html""&gt;assertion_dl_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html""&gt;assert.large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html""&gt;assertion_dl_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;New Word Embeddings&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html""&gt;embed.glove.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html""&gt;embeddings_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/06/02/embeddings_biovec_en.html""&gt;embed.glove.biovec&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/06/02/embeddings_biovec_en.html""&gt;embeddings_biovec&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/03/26/embeddings_healthcare_en.html""&gt;embed.glove.healthcare&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/03/26/embeddings_healthcare_en.html""&gt;embeddings_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/29/embeddings_healthcare_100d_en.html""&gt;embed.glove.healthcare_100d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/29/embeddings_healthcare_100d_en.html""&gt;embeddings_healthcare_100d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;en.embed.glove.icdoem&lt;/td&gt;
&lt;td&gt;embeddings_icdoem&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;en.embed.glove.icdoem_2ng&lt;/td&gt;
&lt;td&gt;embeddings_icdoem_2ng&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;Sentence Entity resolvers&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;embed_sentence.biobert.mli&lt;/td&gt;
&lt;td&gt;sbiobert_base_cased_mli&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve&lt;/td&gt;
&lt;td&gt;sbiobertresolve_cpt&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve.cpt&lt;/td&gt;
&lt;td&gt;sbiobertresolve_cpt&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve.cpt.augmented&lt;/td&gt;
&lt;td&gt;sbiobertresolve_cpt_augmented&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve.cpt.procedures_augmented&lt;/td&gt;
&lt;td&gt;sbiobertresolve_cpt_procedures_augmented&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve.hcc.augmented&lt;/td&gt;
&lt;td&gt;sbiobertresolve_hcc_augmented&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html""&gt;resolve.icd10cm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html""&gt;sbiobertresolve_icd10cm&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html""&gt;resolve.icd10cm.augmented&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html""&gt;sbiobertresolve_icd10cm_augmented&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html""&gt;resolve.icd10cm.augmented_billable&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html""&gt;sbiobertresolve_icd10cm_augmented_billable_hcc&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html""&gt;resolve.icd10pcs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html""&gt;sbiobertresolve_icd10pcs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html""&gt;resolve.icdo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html""&gt;sbiobertresolve_icdo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html""&gt;resolve.rxcui&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html""&gt;sbiobertresolve_rxcui&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html""&gt;resolve.rxnorm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html""&gt;sbiobertresolve_rxnorm&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html""&gt;resolve.snomed&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html""&gt;sbiobertresolve_snomed_auxConcepts&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html""&gt;resolve.snomed.aux_concepts&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html""&gt;sbiobertresolve_snomed_auxConcepts&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html""&gt;resolve.snomed.aux_concepts_int&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html""&gt;sbiobertresolve_snomed_auxConcepts_int&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html""&gt;resolve.snomed.findings&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html""&gt;sbiobertresolve_snomed_findings&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html""&gt;resolve.snomed.findings_int&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html""&gt;sbiobertresolve_snomed_findings_int&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;RelationExtractionModel&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;relation.posology&lt;/td&gt;
&lt;td&gt;posology_re&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html""&gt;relation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html""&gt;redl_bodypart_direction_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html""&gt;relation.bodypart.direction&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_direction_biobert_en.html""&gt;redl_bodypart_direction_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_problem_biobert_en.html""&gt;relation.bodypart.problem&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_problem_biobert_en.html""&gt;redl_bodypart_problem_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_procedure_test_biobert_en.html""&gt;relation.bodypart.procedure&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_bodypart_procedure_test_biobert_en.html""&gt;redl_bodypart_procedure_test_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_chemprot_biobert_en.html""&gt;relation.chemprot&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_chemprot_biobert_en.html""&gt;redl_chemprot_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_clinical_biobert_en.html""&gt;relation.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_clinical_biobert_en.html""&gt;redl_clinical_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_date_clinical_biobert_en.htmls""&gt;relation.date&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_date_clinical_biobert_en.htmls""&gt;redl_date_clinical_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_drug_drug_interaction_biobert_en.html""&gt;relation.drug_drug_interaction&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_drug_drug_interaction_biobert_en.html""&gt;redl_drug_drug_interaction_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_human_phenotype_gene_biobert_en.html""&gt;relation.humen_phenotype_gene&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_human_phenotype_gene_biobert_en.html""&gt;redl_human_phenotype_gene_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_temporal_events_biobert_en.html""&gt;relation.temporal_events&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/02/04/redl_temporal_events_biobert_en.html""&gt;redl_temporal_events_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;NERDLModels&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinical_en.html""&gt;med_ner.ade.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinical_en.html""&gt;ner_ade_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinicalbert_en.html""&gt;med_ner.ade.clinical_bert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_clinicalbert_en.html""&gt;ner_ade_clinicalbert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_healthcare_en.html""&gt;med_ner.ade.ade_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_ade_healthcare_en.html""&gt;ner_ade_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_en.html""&gt;med_ner.anatomy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_en.html""&gt;ner_anatomy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_anatomy_biobert_en.html""&gt;med_ner.anatomy.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_anatomy_biobert_en.html""&gt;ner_anatomy_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html""&gt;med_ner.anatomy.coarse&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_en.html""&gt;ner_anatomy_coarse&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_biobert_en.html""&gt;med_ner.anatomy.coarse_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_anatomy_coarse_biobert_en.html""&gt;ner_anatomy_coarse_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_aspect_based_sentiment_en.html""&gt;med_ner.aspect_sentiment&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_aspect_based_sentiment_en.html""&gt;ner_aspect_based_sentiment&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_bacterial_species_en.html""&gt;med_ner.bacterial_species&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_bacterial_species_en.html""&gt;ner_bacterial_species&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_bionlp_en.html""&gt;med_ner.bionlp&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_bionlp_en.html""&gt;ner_bionlp&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_bionlp_biobert_en.html""&gt;med_ner.bionlp.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_bionlp_biobert_en.html""&gt;ner_bionlp_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_cancer_genetics_en.html""&gt;med_ner.cancer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_cancer_genetics_en.html""&gt;ner_cancer_genetics&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Englishs&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_cellular_en.html""&gt;med_ner.cellular&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_cellular_en.html""&gt;ner_cellular&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_cellular_biobert_en.html""&gt;med_ner.cellular.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_cellular_biobert_en.html""&gt;ner_cellular_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_chemicals_en.html""&gt;med_ner.chemicals&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_chemicals_en.html""&gt;ner_chemicals&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_chemprot_biobert_en.html""&gt;med_ner.chemprot&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_chemprot_biobert_en.html""&gt;ner_chemprot_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_chemprot_clinical_en.html""&gt;med_ner.chemprot.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_chemprot_clinical_en.html""&gt;ner_chemprot_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/01/30/ner_clinical_en.html""&gt;med_ner.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/01/30/ner_clinical_en.html""&gt;ner_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_clinical_biobert_en.html""&gt;med_ner.clinical.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_clinical_biobert_en.html""&gt;ner_clinical_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;med_ner.clinical.noncontrib&lt;/td&gt;
&lt;td&gt;ner_clinical_noncontrib&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_diseases_en.html""&gt;med_ner.diseases&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_diseases_en.html""&gt;ner_diseases&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_biobert_en.html""&gt;med_ner.diseases.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_biobert_en.html""&gt;ner_diseases_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_large_en.html""&gt;med_ner.diseases.large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_diseases_large_en.html""&gt;ner_diseases_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_en.html""&gt;med_ner.drugs&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_en.html""&gt;ner_drugs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_greedy_en.html""&gt;med_ner.drugsgreedy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_greedy_en.html""&gt;ner_drugs_greedy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_large_en.html""&gt;med_ner.drugs.large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_drugs_large_en.html""&gt;ner_drugs_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_events_biobert_en.html""&gt;med_ner.events_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_events_biobert_en.html""&gt;ner_events_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_events_clinical_en.html""&gt;med_ner.events_clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_events_clinical_en.html""&gt;ner_events_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_events_healthcare_en.html""&gt;med_ner.events_healthcre&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_events_healthcare_en.html""&gt;ner_events_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_financial_contract_en.html""&gt;med_ner.financial_contract&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_financial_contract_en.html""&gt;ner_financial_contract&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_healthcare_de.html""&gt;med_ner.healthcare&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_healthcare_de.html""&gt;ner_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_gene_biobert_en.html""&gt;med_ner.human_phenotype.gene_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_gene_biobert_en.html""&gt;ner_human_phenotype_gene_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html""&gt;med_ner.human_phenotype.gene_clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_gene_clinical_en.html""&gt;ner_human_phenotype_gene_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_go_biobert_en.html""&gt;med_ner.human_phenotype.go_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_human_phenotype_go_biobert_en.html""&gt;ner_human_phenotype_go_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html""&gt;med_ner.human_phenotype.go_clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_human_phenotype_go_clinical_en.html""&gt;ner_human_phenotype_go_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_en.html""&gt;med_ner.jsl&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_en.html""&gt;ner_jsl&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_biobert_en.html""&gt;med_ner.jsl.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_biobert_en.html""&gt;ner_jsl_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_enriched_en.html""&gt;med_ner.jsl.enriched&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_jsl_enriched_en.html""&gt;ner_jsl_enriched&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_enriched_biobert_en.html""&gt;med_ner.jsl.enriched_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_jsl_enriched_biobert_en.html""&gt;ner_jsl_enriched_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_measurements_clinical_en.html""&gt;med_ner.measurements&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_measurements_clinical_en.html""&gt;ner_measurements_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_medmentions_coarse_en.html""&gt;med_ner.medmentions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_medmentions_coarse_en.html""&gt;ner_medmentions_coarse&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/04/15/ner_posology_en.html""&gt;med_ner.posology&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/04/15/ner_posology_en.html""&gt;ner_posology&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_biobert_en.html""&gt;med_ner.posology.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_biobert_en.html""&gt;ner_posology_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_greedy_en.html""&gt;med_ner.posology.greedy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_greedy_en.html""&gt;ner_posology_greedy&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_healthcare_en.html""&gt;med_ner.posology.healthcare&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_healthcare_en.html""&gt;ner_posology_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_large_en.html""&gt;med_ner.posology.large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_large_en.html""&gt;ner_posology_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_large_biobert_en.html""&gt;med_ner.posology.large_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_posology_large_biobert_en.html""&gt;ner_posology_large_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_small_en.html""&gt;med_ner.posology.small&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_posology_small_en.html""&gt;ner_posology_small&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_radiology_en.html""&gt;med_ner.radiology&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_radiology_en.html""&gt;ner_radiology&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_radiology_wip_clinical_en.html""&gt;med_ner.radiology.wip_clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_radiology_wip_clinical_en.html""&gt;ner_radiology_wip_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html""&gt;med_ner.risk_factors&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_risk_factors_en.html""&gt;ner_risk_factors&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_risk_factors_biobert_en.html""&gt;med_ner.risk_factors.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_risk_factors_biobert_en.html""&gt;ner_risk_factors_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;med_ner.i2b2&lt;/td&gt;
&lt;td&gt;nerdl_i2b2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/nerdl_tumour_demo_en.html""&gt;med_ner.tumour&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/nerdl_tumour_demo_en.html""&gt;nerdl_tumour_demo&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;med_ner.jsl.wip.clinical&lt;/td&gt;
&lt;td&gt;jsl_ner_wip_clinical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html""&gt;med_ner.jsl.wip.clinical.greedy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/jsl_ner_wip_clinical_en.html""&gt;jsl_ner_wip_greedy_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/jsl_ner_wip_modifier_clinical_en.html""&gt;med_ner.jsl.wip.clinical.modifier&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/jsl_ner_wip_modifier_clinical_en.html""&gt;jsl_ner_wip_modifier_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/jsl_rd_ner_wip_greedy_clinical_en.html""&gt;med_ner.jsl.wip.clinical.rd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/jsl_rd_ner_wip_greedy_clinical_en.html""&gt;jsl_rd_ner_wip_greedy_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;De-Identification Models&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_augmented_en.html""&gt;med_ner.deid.augmented&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_augmented_en.html""&gt;ner_deid_augmented&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_biobert_en.html""&gt;med_ner.deid.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_biobert_en.html""&gt;ner_deid_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_enriched_en.html""&gt;med_ner.deid.enriched&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_enriched_en.html""&gt;ner_deid_enriched&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_enriched_biobert_en.html""&gt;med_ner.deid.enriched_biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_enriched_biobert_en.html""&gt;ner_deid_enriched_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_large_en.html""&gt;med_ner.deid.large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deid_large_en.html""&gt;ner_deid_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_en.html""&gt;med_ner.deid.sd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_en.html""&gt;ner_deid_sd&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_large_en.html""&gt;med_ner.deid.sd_large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/01/ner_deid_sd_large_en.html""&gt;ner_deid_sd_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;med_ner.deid&lt;/td&gt;
&lt;td&gt;nerdl_deid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;med_ner.deid.synthetic&lt;/td&gt;
&lt;td&gt;ner_deid_synthetic&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deidentify_dl_en.html""&gt;med_ner.deid.dl&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_deidentify_dl_en.html""&gt;ner_deidentify_dl&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html""&gt;en.de_identify&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html""&gt;deidentify_rb&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;de_identify.rules&lt;/td&gt;
&lt;td&gt;deid_rules&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/29/deidentify_enriched_clinical_en.html""&gt;de_identify.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/29/deidentify_enriched_clinical_en.html""&gt;deidentify_enriched_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/08/04/deidentify_large_en.html""&gt;de_identify.large&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/08/04/deidentify_large_en.html""&gt;deidentify_large&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html""&gt;de_identify.rb&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2019/06/04/deidentify_rb_en.html""&gt;deidentify_rb&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;de_identify.rb_no_regex&lt;/td&gt;
&lt;td&gt;deidentify_rb_no_regex&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h1&gt;Chunk resolvers&lt;/h1&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html""&gt;resolve_chunk.athena_conditions&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html""&gt;chunkresolve_athena_conditions_healthcare&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_cpt_clinical_en.html""&gt;resolve_chunk.cpt_clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_cpt_clinical_en.html""&gt;chunkresolve_cpt_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_clinical_en.html""&gt;resolve_chunk.icd10cm.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_clinical_en.html""&gt;chunkresolve_icd10cm_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_diseases_clinical_en.html""&gt;resolve_chunk.icd10cm.diseases_clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_diseases_clinical_en.html""&gt;chunkresolve_icd10cm_diseases_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.icd10cm.hcc_clinical&lt;/td&gt;
&lt;td&gt;chunkresolve_icd10cm_hcc_clinical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.icd10cm.hcc_healthcare&lt;/td&gt;
&lt;td&gt;chunkresolve_icd10cm_hcc_healthcare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_injuries_clinical_en.html""&gt;resolve_chunk.icd10cm.injuries&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_injuries_clinical_en.html""&gt;chunkresolve_icd10cm_injuries_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_musculoskeletal_clinical_en.html""&gt;resolve_chunk.icd10cm.musculoskeletal&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_musculoskeletal_clinical_en.html""&gt;chunkresolve_icd10cm_musculoskeletal_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_neoplasms_clinical_en.html""&gt;resolve_chunk.icd10cm.neoplasms&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10cm_neoplasms_clinical_en.html""&gt;chunkresolve_icd10cm_neoplasms_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_poison_ext_clinical_en.html""&gt;resolve_chunk.icd10cm.poison&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_poison_ext_clinical_en.html""&gt;chunkresolve_icd10cm_poison_ext_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_puerile_clinical_en.html""&gt;resolve_chunk.icd10cm.puerile&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/04/28/chunkresolve_icd10cm_puerile_clinical_en.html""&gt;chunkresolve_icd10cm_puerile_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.icd10pcs.clinical&lt;/td&gt;
&lt;td&gt;chunkresolve_icd10pcs_clinical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10pcs_clinical_en.html""&gt;resolve_chunk.icdo.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_icd10pcs_clinical_en.html""&gt;chunkresolve_icdo_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_loinc_clinical_en.html""&gt;resolve_chunk.loinc&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/04/02/chunkresolve_loinc_clinical_en.html""&gt;chunkresolve_loinc_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_cd_clinical_en.html""&gt;resolve_chunk.rxnorm.cd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_cd_clinical_en.html""&gt;chunkresolve_rxnorm_cd_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.rxnorm.in&lt;/td&gt;
&lt;td&gt;chunkresolve_rxnorm_in_clinical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.rxnorm.in_healthcare&lt;/td&gt;
&lt;td&gt;chunkresolve_rxnorm_in_healthcare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_sbd_clinical_en.html""&gt;resolve_chunk.rxnorm.sbd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_sbd_clinical_en.html""&gt;chunkresolve_rxnorm_sbd_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_scd_clinical_en.html""&gt;resolve_chunk.rxnorm.scd&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/07/27/chunkresolve_rxnorm_scd_clinical_en.html""&gt;chunkresolve_rxnorm_scd_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.rxnorm.scdc&lt;/td&gt;
&lt;td&gt;chunkresolve_rxnorm_scdc_clinical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;resolve_chunk.rxnorm.scdc_healthcare&lt;/td&gt;
&lt;td&gt;chunkresolve_rxnorm_scdc_healthcare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/06/24/chunkresolve_rxnorm_xsmall_clinical_en.html""&gt;resolve_chunk.rxnorm.xsmall.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/06/24/chunkresolve_rxnorm_xsmall_clinical_en.html""&gt;chunkresolve_rxnorm_xsmall_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/06/20/chunkresolve_snomed_findings_clinical_en.html""&gt;resolve_chunk.snomed.findings&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/06/20/chunkresolve_snomed_findings_clinical_en.html""&gt;chunkresolve_snomed_findings_clinical&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h1&gt;New Classifiers&lt;/h1&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Language&lt;/th&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;classify.icd10.clinical&lt;/td&gt;
&lt;td&gt;classifier_icd10cm_hcc_clinical&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;classify.icd10.healthcare&lt;/td&gt;
&lt;td&gt;classifier_icd10cm_hcc_healthcare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_biobert_en.html""&gt;classify.ade.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_biobert_en.html""&gt;classifierdl_ade_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_clinicalbert_en.html""&gt;classify.ade.clinical&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_clinicalbert_en.html""&gt;classifierdl_ade_clinicalbert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_conversational_biobert_en.html""&gt;classify.ade.conversational&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_ade_conversational_biobert_en.html""&gt;classifierdl_ade_conversational_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_biobert_en.html""&gt;classify.gender.biobert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_biobert_en.html""&gt;classifierdl_gender_biobert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_sbert_en.html""&gt;classify.gender.sbert&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/01/21/classifierdl_gender_sbert_en.html""&gt;classifierdl_gender_sbert&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;classify.pico&lt;/td&gt;
&lt;td&gt;classifierdl_pico_biobert&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h1&gt;German Medical models&lt;/h1&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;[embed]&lt;/td&gt;
&lt;td&gt;w2v_cc_300d&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[embed.w2v]&lt;/td&gt;
&lt;td&gt;w2v_cc_300d&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[resolve_chunk]&lt;/td&gt;
&lt;td&gt;chunkresolve_ICD10GM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[resolve_chunk.icd10gm]&lt;/td&gt;
&lt;td&gt;chunkresolve_ICD10GM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;resolve_chunk.icd10gm.2021&lt;/td&gt;
&lt;td&gt;chunkresolve_ICD10GM_2021&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;med_ner.legal&lt;/td&gt;
&lt;td&gt;ner_legal&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;med_ner&lt;/td&gt;
&lt;td&gt;ner_healthcare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;med_ner.healthcare&lt;/td&gt;
&lt;td&gt;ner_healthcare&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;med_ner.healthcare_slim&lt;/td&gt;
&lt;td&gt;ner_healthcare_slim&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;med_ner.traffic&lt;/td&gt;
&lt;td&gt;ner_traffic&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h1&gt;Spanish Medical models&lt;/h1&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;nlu.load() reference&lt;/th&gt;
&lt;th&gt;Spark NLP Model reference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_150d_es.html""&gt;embed.scielo.150d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_150d_es.html""&gt;embeddings_scielo_150d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_300d_es.html""&gt;embed.scielo.300d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_300d_es.html""&gt;embeddings_scielo_300d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_50d_es.html""&gt;embed.scielo.50d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielo_50d_es.html""&gt;embeddings_scielo_50d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_150d_es.html""&gt;embed.scielowiki.150d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_150d_es.html""&gt;embeddings_scielowiki_150d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_300d_es.html""&gt;embed.scielowiki.300d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_300d_es.html""&gt;embeddings_scielowiki_300d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_50d_es.html""&gt;embed.scielowiki.50d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/26/embeddings_scielowiki_50d_es.html""&gt;embeddings_scielowiki_50d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_150d_es.html""&gt;embed.sciwiki.150d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_150d_es.html""&gt;embeddings_sciwiki_150d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_300d_es.html""&gt;embed.sciwiki.300d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_300d_es.html""&gt;embeddings_sciwiki_300d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_50d_es.html""&gt;embed.sciwiki.50d&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2020/05/27/embeddings_sciwiki_50d_es.html""&gt;embeddings_sciwiki_50d&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html""&gt;med_ner&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html""&gt;ner_diag_proc&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_neoplasms_es.html""&gt;med_ner.neoplasm&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_neoplasms_es.html""&gt;ner_neoplasms&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html""&gt;med_ner.diag_proc&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=""https://nlp.johnsnowlabs.com/2021/03/31/ner_diag_proc_es.html""&gt;ner_diag_proc&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h1&gt;GPU Mode&lt;/h1&gt;

&lt;p&gt;You can now enable NLU GPU mode by setting &lt;code&gt;gpu=true&lt;/code&gt; while loading a model. I.e. &lt;code&gt;nlu.load(&amp;#39;train.sentiment&amp;#39; gpu=True)&lt;/code&gt; . If must resart you kernel, if you already loaded a nlu pipeline withouth GPU mode.&lt;/p&gt;

&lt;h1&gt;Output Level Relation&lt;/h1&gt;

&lt;p&gt;This new output level is used for relation extractors and will give you 1 row per relation extracted.&lt;/p&gt;

&lt;h1&gt;Bug fixes&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Fixed a bug that caused loading NLU models in offline mode not to work in some occasions&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;1 line Install NLU&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;!wget https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh -O - | bash&lt;/code&gt;&lt;/p&gt;

&lt;h1&gt;Install via PIP&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;! pip install nlu pyspark==3.0.1&lt;/code&gt;&lt;/p&gt;

&lt;h2&gt;Additional NLU ressources&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://nlu.johnsnowlabs.com/""&gt;NLU Website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlu.johnsnowlabs.com/docs/en/notebooks""&gt;All NLU Tutorial Notebooks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://nlp.johnsnowlabs.com/learn#pythons-nlu-library""&gt;NLU Videos and Blogposts on NLU&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://github.com/JohnSnowLabs/nlu""&gt;NLU on Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://join.slack.com/t/spark-nlp/shared_invite/zt-lutct9gm-kuUazcyFKhuGY3_0AMkxqA""&gt;Suggestions or Questions? Contact us in Slack!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5gusr,True,,CKL-IT,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n5gusr/200_state_of_the_art_medical_models_for_ner/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n5gusr/200_state_of_the_art_medical_models_for_ner/,66146,1620223951.0,0,,False,,,,,,,
,deeplearning,"The gradient descent formula decreases the cost function.

W(new) = W(old) - partial derivative of the error with respect to W(old)

At all scenarios should I reduce the weight to achieve the global minima?

There might be few cases where I will descent from an negative slope right!! At that time I should increase the weights right!!",t2_4ulmt5ig,False,,0,False,Gradient Descent,[],r/deeplearning,False,6,,0,,False,t3_n5glhy,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1620228848.0,,[],{},,True,,1620252027.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The gradient descent formula decreases the cost function.&lt;/p&gt;

&lt;p&gt;W(new) = W(old) - partial derivative of the error with respect to W(old)&lt;/p&gt;

&lt;p&gt;At all scenarios should I reduce the weight to achieve the global minima?&lt;/p&gt;

&lt;p&gt;There might be few cases where I will descent from an negative slope right!! At that time I should increase the weights right!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5glhy,True,,Night_Crawler7,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/n5glhy/gradient_descent/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n5glhy/gradient_descent/,66146,1620223227.0,0,,False,,,,,,,
,deeplearning,"I have a github repo file implemented in colab (along with saved checkpoinrs). I want to upload this model to azure and develop a flask api to send in input, run the model, recieve the output. Any idea what all do I need to l learn or how do I go about this? Thank you!",t2_49con8xv,False,,0,False,Deployment using Azure,[],r/deeplearning,False,6,,0,,False,t3_n58wqs,False,dark,0.7,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1620223673.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a github repo file implemented in colab (along with saved checkpoinrs). I want to upload this model to azure and develop a flask api to send in input, run the model, recieve the output. Any idea what all do I need to l learn or how do I go about this? Thank you!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n58wqs,True,,berlin_1710,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/n58wqs/deployment_using_azure/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n58wqs/deployment_using_azure/,66146,1620194873.0,0,,False,,,,,,,
,deeplearning,,t2_40d0zt4s,False,,0,False,Deep Learning Using TensorFlow Keras,[],r/deeplearning,False,6,,0,,False,t3_n5ceh3,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1620237875.0,text,6,,,text,analyticsindiamag.com,False,,,,,https://analyticsindiamag.com/deep-learning-using-tensorflow-keras/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5ceh3,True,,analyticsindiam,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n5ceh3/deep_learning_using_tensorflow_keras/,all_ads,False,https://analyticsindiamag.com/deep-learning-using-tensorflow-keras/,66146,1620209075.0,0,,False,,,,,,,
,deeplearning,How to represent a feature matrix--a bag of words per document( I am working with Cora dataset). How can I track the document names? My question is whether I should keep them as a separate dictionary or should I find some sparse matrix that allows me to include the document names? How should I proceed?,t2_7d3q7c7x,False,,0,False,How to represent a feature matrix?,[],r/deeplearning,False,6,,0,,False,t3_n5ae3v,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620229368.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How to represent a feature matrix--a bag of words per document( I am working with Cora dataset). How can I track the document names? My question is whether I should keep them as a separate dictionary or should I find some sparse matrix that allows me to include the document names? How should I proceed?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5ae3v,True,,Turbulent_Animator65,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n5ae3v/how_to_represent_a_feature_matrix/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n5ae3v/how_to_represent_a_feature_matrix/,66146,1620200568.0,0,,False,,,,,,,
,deeplearning,"I've been training an urban scene dataset on PSPNet and DeepLabV3. I run both for 50 epochs, with around 1000 total image and mask pairs. My dataset split is 80% train, 5% val and 15% test. 

The test accuracies for both are consistently higher than the final validation accuracy at the 50th epoch. As I understand it, the test accuracy should actually be slightly smaller than the validation accuracy, or is this not true? I'm a bit confused as to whether I can trust my results. The primary performance metric this seems to be happening with is Mean Intersection Over Union (mIOU).",t2_8k0yg7k7,False,,0,False,Test accuracy higher than validation accuracy for semantic segmentation?,[],r/deeplearning,False,6,,0,,False,t3_n4sszm,False,dark,0.86,,public,14,0,{},,False,[],,False,False,,{},,False,14,,False,False,,False,,[],{},,True,,1620174980.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;ve been training an urban scene dataset on PSPNet and DeepLabV3. I run both for 50 epochs, with around 1000 total image and mask pairs. My dataset split is 80% train, 5% val and 15% test. &lt;/p&gt;

&lt;p&gt;The test accuracies for both are consistently higher than the final validation accuracy at the 50th epoch. As I understand it, the test accuracy should actually be slightly smaller than the validation accuracy, or is this not true? I&amp;#39;m a bit confused as to whether I can trust my results. The primary performance metric this seems to be happening with is Mean Intersection Over Union (mIOU).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n4sszm,True,,glampiggy,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/n4sszm/test_accuracy_higher_than_validation_accuracy_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n4sszm/test_accuracy_higher_than_validation_accuracy_for/,66146,1620146180.0,0,,False,,,,,,,
,deeplearning,,t2_44mbtmjy,False,,0,False,An agent trained in a world-on-rails learns to drive better than state-of-the-art imitation learning agents!,[],r/deeplearning,False,6,,0,,False,t3_n55txq,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1620212935.0,text,6,,,text,self.LatestInML,False,,,,,/r/LatestInML/comments/n55tag/an_agent_trained_in_a_worldonrails_learns_to/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n55txq,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n55txq/an_agent_trained_in_a_worldonrails_learns_to/,all_ads,False,/r/LatestInML/comments/n55tag/an_agent_trained_in_a_worldonrails_learns_to/,66146,1620184135.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper](https://www.catalyzex.com/paper/arxiv:2105.00636)\n\nhttps://reddit.com/link/n55tag/video/wrau2jvjx7x61/player\n\n👇 Free extension to get code for ML papers (❤️'d by Andrew Ng) Chrome: https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil\n\nFirefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'An agent trained in a world-on-rails learns to drive better than state-of-the-art imitation learning agents!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'wrau2jvjx7x61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/n55tag/asset/wrau2jvjx7x61/DASHPlaylist.mpd?a=1626450118%2CYjQ2MDc3MWM1OWQwYzcxNGUwYjY2Yjk4ODdkMTBlZmNhMzVmYmE3OWFkMDgyMWUzMWExZGEyM2RkNTYyZTU4Nw%3D%3D&amp;v=1&amp;f=sd', 'x': 640, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/n55tag/asset/wrau2jvjx7x61/HLSPlaylist.m3u8?a=1626450118%2CZmY2MTI0ODM3YTNkYTVjYjM0ZGE4NmY2MmNkMzIxODIyZWYyZTUwY2U1ZWM2NzMxN2RjZWQ0ZTM3Zjk0ZDRiYw%3D%3D&amp;v=1&amp;f=sd', 'id': 'wrau2jvjx7x61', 'isGif': False}}, 'name': 't3_n55tag', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.78, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1620212879.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2105.00636""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/n55tag/video/wrau2jvjx7x61/player""&gt;https://reddit.com/link/n55tag/video/wrau2jvjx7x61/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39;d by Andrew Ng) Chrome: &lt;a href=""https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'n55tag', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/n55tag/an_agent_trained_in_a_worldonrails_learns_to/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/n55tag/an_agent_trained_in_a_worldonrails_learns_to/', 'subreddit_subscribers': 7049, 'created_utc': 1620184079.0, 'num_crossposts': 5, 'media': None, 'is_video': False}]",t3_n55tag,,,,,
,deeplearning,"Hi all! Looking for theory insights on LSTMs here.

I have a table of contents extraction task, where the goal is to predict the hierarchy of a given list of titles (manually extracted visual and textual features). I modeled it as a seq2seq task (sequence of titles to sequence of depths in a tree) but it does not seem to work despite experimentation.

The question is: is this task an **abstract reasoning** task (too hard for LSTMs without a strong inductive bias)? Each individual title and title sequence is previously unseen by the network, and the network must learn to reason about similarities between titles (this title is similar to this one, so they must be at the same level). This looks like an abstract reasoning / generalization task (same high-level rules of matching titles, but different objects to match each time).

From a metric-learning point of view, this is doable (cluster titles using triplet-loss training and order them with some rule-based AI), but is it impossible for an LSTM to run all of this e2e? I am trying to search for similar problems in the literature (Relation Networks for instance), but still not sure if trying to apply standard deep learning seq2seq is useless here. In general, I'm trying to understand why standard sequential architectures would not be appropriate for abstract relationship reasoning tasks like these, and what is the state of research for these problems.

What usable deep learning tools are available today to tackle abstractions like these?",t2_aoh1qyhz,False,,0,False,Abstract reasoning with LSTMs,[],r/deeplearning,False,6,,0,,False,t3_n4jzt4,False,dark,0.91,,public,19,0,{},,False,[],,False,False,,{},,False,19,,False,False,,1620126308.0,,[],{},,True,,1620148650.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all! Looking for theory insights on LSTMs here.&lt;/p&gt;

&lt;p&gt;I have a table of contents extraction task, where the goal is to predict the hierarchy of a given list of titles (manually extracted visual and textual features). I modeled it as a seq2seq task (sequence of titles to sequence of depths in a tree) but it does not seem to work despite experimentation.&lt;/p&gt;

&lt;p&gt;The question is: is this task an &lt;strong&gt;abstract reasoning&lt;/strong&gt; task (too hard for LSTMs without a strong inductive bias)? Each individual title and title sequence is previously unseen by the network, and the network must learn to reason about similarities between titles (this title is similar to this one, so they must be at the same level). This looks like an abstract reasoning / generalization task (same high-level rules of matching titles, but different objects to match each time).&lt;/p&gt;

&lt;p&gt;From a metric-learning point of view, this is doable (cluster titles using triplet-loss training and order them with some rule-based AI), but is it impossible for an LSTM to run all of this e2e? I am trying to search for similar problems in the literature (Relation Networks for instance), but still not sure if trying to apply standard deep learning seq2seq is useless here. In general, I&amp;#39;m trying to understand why standard sequential architectures would not be appropriate for abstract relationship reasoning tasks like these, and what is the state of research for these problems.&lt;/p&gt;

&lt;p&gt;What usable deep learning tools are available today to tackle abstractions like these?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n4jzt4,True,,cataPhil,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/n4jzt4/abstract_reasoning_with_lstms/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n4jzt4/abstract_reasoning_with_lstms/,66146,1620119850.0,0,,False,,,,,,,
,deeplearning,"I am currently starting a DL project with a small group and want to define how we will manage and document experiments. I know about SaaS experiment trackers like weights and biases, but I'm not sure if we need such a service or if there are any more lightweight solutions out there that do the job just fine.

I could imagine a setup where I log hparams, metrics, git revision etc in a directory and render static html files from that, which could be hosted e.g. on github pages. 

What do you think is the most efficient approach? What are your experiences with both cloud/SaaS services and local/lightweight solutions?",t2_8l4bxoth,False,,0,False,Lightweight DL experiment management,[],r/deeplearning,False,6,,0,,False,t3_n4o19q,False,dark,0.8,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1620162831.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently starting a DL project with a small group and want to define how we will manage and document experiments. I know about SaaS experiment trackers like weights and biases, but I&amp;#39;m not sure if we need such a service or if there are any more lightweight solutions out there that do the job just fine.&lt;/p&gt;

&lt;p&gt;I could imagine a setup where I log hparams, metrics, git revision etc in a directory and render static html files from that, which could be hosted e.g. on github pages. &lt;/p&gt;

&lt;p&gt;What do you think is the most efficient approach? What are your experiences with both cloud/SaaS services and local/lightweight solutions?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n4o19q,True,,_Arsenie_Boca_,,10,True,all_ads,False,[],False,,/r/deeplearning/comments/n4o19q/lightweight_dl_experiment_management/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n4o19q/lightweight_dl_experiment_management/,66146,1620134031.0,0,,False,,,,,,,
,deeplearning,"I trained PSPNet and DeepLab from scratch and also using pre-trained backbones on a very specific urban scene dataset. The pre-trained backbone I used was ResNet, with weights downloaded from the PASCAL VOC12 dataset. I then trained both models without freezing any layers. My accuracy for the models from scratch proved to be higher than the models with pre-trained backbones. My dataset is relatively small; only 1000 images. 

Could this have happened because the PASCAL VOC12 dataset is too general when compared to the specific dataset I am working on, and has thus limited its learning ability? Or have I most likely done something wrong?",t2_8k0yg7k7,False,,0,False,Is it common for transfer learning to decrease the accuracy of a model?,[],r/deeplearning,False,6,,0,,False,t3_n4xou2,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620189753.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I trained PSPNet and DeepLab from scratch and also using pre-trained backbones on a very specific urban scene dataset. The pre-trained backbone I used was ResNet, with weights downloaded from the PASCAL VOC12 dataset. I then trained both models without freezing any layers. My accuracy for the models from scratch proved to be higher than the models with pre-trained backbones. My dataset is relatively small; only 1000 images. &lt;/p&gt;

&lt;p&gt;Could this have happened because the PASCAL VOC12 dataset is too general when compared to the specific dataset I am working on, and has thus limited its learning ability? Or have I most likely done something wrong?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n4xou2,True,,glampiggy,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n4xou2/is_it_common_for_transfer_learning_to_decrease/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n4xou2/is_it_common_for_transfer_learning_to_decrease/,66146,1620160953.0,0,,False,,,,,,,
,deeplearning,"Im doing a project and in need the dataset. I want to use Yolov4 to detect faces and then crop them to classify whether they are real faces or fake? 
So someone help me to convert the dataset to darknet-yolo txt files
THANKS!!!!",t2_5tjqypkb,False,,0,False,HELP ME!!! Convert Widerface dataset to Darknet-Yolo txt Format,[],r/deeplearning,False,6,,0,,False,t3_n5664f,False,dark,0.14,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620214023.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im doing a project and in need the dataset. I want to use Yolov4 to detect faces and then crop them to classify whether they are real faces or fake? 
So someone help me to convert the dataset to darknet-yolo txt files
THANKS!!!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n5664f,True,,Just-A-abnormal-Guy,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n5664f/help_me_convert_widerface_dataset_to_darknetyolo/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n5664f/help_me_convert_widerface_dataset_to_darknetyolo/,66146,1620185223.0,0,,False,,,,,,,
,deeplearning,,t2_44mbtmjy,False,,0,False,From MIT and Nvidia researchers: A controllable neural simulator that can generate high-fidelity real-world scenes!,[],r/deeplearning,False,6,,0,,False,t3_n4eiqn,False,dark,0.9,,public,14,0,{},,False,[],,False,False,,{},,False,14,,False,False,,False,,[],{},,False,,1620126105.0,text,6,,,text,self.LatestInML,False,,,,,/r/LatestInML/comments/n4eh0l/from_mit_and_nvidia_researchers_a_controllable/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n4eiqn,True,,MLtinkerer,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n4eiqn/from_mit_and_nvidia_researchers_a_controllable/,all_ads,False,/r/LatestInML/comments/n4eh0l/from_mit_and_nvidia_researchers_a_controllable/,66146,1620097305.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper](https://www.catalyzex.com/paper/arxiv:2104.15060)\n\nhttps://reddit.com/link/n4eh0l/video/akfms2f2r0x61/player\n\n👇 Free extension to get code for ML papers (❤️'d by Andrew Ng)\n\nChrome: https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil\n\nFirefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'From MIT and Nvidia researchers: A controllable neural simulator that can generate high-fidelity real-world scenes!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'akfms2f2r0x61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/n4eh0l/asset/akfms2f2r0x61/DASHPlaylist.mpd?a=1626450118%2CMTgwMzZlNmJjMTZiY2NmZjA2MGFjMzE5NjZhOGUxNzI3NzllZjMwZWQwZDA3NjUxZWJmMjQwM2E2NjQwOWM5ZA%3D%3D&amp;v=1&amp;f=sd', 'x': 580, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/n4eh0l/asset/akfms2f2r0x61/HLSPlaylist.m3u8?a=1626450118%2CMGY4MWU4NWFkYjU4MjhkMmEzYzJhOWUxMDc3Y2VhYzU2NTc4OWVjYzRiOTFlYzE5YWE4MjIzYjgzNGY1YWY0Yw%3D%3D&amp;v=1&amp;f=sd', 'id': 'akfms2f2r0x61', 'isGif': False}}, 'name': 't3_n4eh0l', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 44, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 44, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1620125954.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2104.15060""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/n4eh0l/video/akfms2f2r0x61/player""&gt;https://reddit.com/link/n4eh0l/video/akfms2f2r0x61/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39;d by Andrew Ng)&lt;/p&gt;\n\n&lt;p&gt;Chrome: &lt;a href=""https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'n4eh0l', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/n4eh0l/from_mit_and_nvidia_researchers_a_controllable/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/n4eh0l/from_mit_and_nvidia_researchers_a_controllable/', 'subreddit_subscribers': 7049, 'created_utc': 1620097154.0, 'num_crossposts': 10, 'media': None, 'is_video': False}]",t3_n4eh0l,,,,,
,deeplearning,"A research team from Huawei Noah’s Ark Lab and Tsinghua University proposes Extract Then Distill (ETD), a generic and flexible strategy for reusing teacher model parameters for efficient and effective task-agnostic distillation that can be applied to student models of any size. 

Here is a quick read: [Huawei &amp; Tsinghua U Method Boosts Task-Agnostic BERT Distillation Efficiency by Reusing Teacher Model Parameters.](https://syncedreview.com/2021/05/04/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-11/)

 The paper *Extract then Distill: Efficient and Effective Task-Agnostic BERT Distillation* is on [arXiv](https://arxiv.org/pdf/2104.11928.pdf).",t2_2fv4yodo,False,,0,False,[R] Huawei &amp; Tsinghua U Method Boosts Task-Agnostic BERT Distillation Efficiency by Reusing Teacher Model Parameters,[],r/deeplearning,False,6,,0,,False,t3_n4r1hj,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620170686.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Huawei Noah’s Ark Lab and Tsinghua University proposes Extract Then Distill (ETD), a generic and flexible strategy for reusing teacher model parameters for efficient and effective task-agnostic distillation that can be applied to student models of any size. &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/04/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-11/""&gt;Huawei &amp;amp; Tsinghua U Method Boosts Task-Agnostic BERT Distillation Efficiency by Reusing Teacher Model Parameters.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Extract then Distill: Efficient and Effective Task-Agnostic BERT Distillation&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.11928.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n4r1hj,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n4r1hj/r_huawei_tsinghua_u_method_boosts_taskagnostic/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n4r1hj/r_huawei_tsinghua_u_method_boosts_taskagnostic/,66146,1620141886.0,0,,False,,,,,,,
,deeplearning,,t2_5c8xe6bb,False,,0,False,Repalette: an image recoloring tool with GANs,[],r/deeplearning,False,6,,0,,False,t3_n4pcvb,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1620166512.0,text,6,,,text,self.unixporn,False,,,,,/r/unixporn/comments/n4o4n5/repalette_an_image_recoloring_tool/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n4pcvb,True,,danielgafni,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n4pcvb/repalette_an_image_recoloring_tool_with_gans/,all_ads,False,/r/unixporn/comments/n4o4n5/repalette_an_image_recoloring_tool/,66146,1620137712.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'unixporn', 'selftext': ""Hello, fellow ricers!\n\nYes, you can recolor images with this. To any color palette. Automatically. With ~~AI~~ deep neural networks. Firstly, a few screenshots:\n\n&amp;#x200B;\n\n[base](https://preview.redd.it/tu6wjwbe26x61.jpg?width=2560&amp;format=pjpg&amp;auto=webp&amp;s=c47b352ac4da815ba17e045ae3872eb8f6aac7da)\n\n&amp;#x200B;\n\n[recolored to green](https://preview.redd.it/8vbuhttf26x61.png?width=1448&amp;format=png&amp;auto=webp&amp;s=b818302acd6f2d9bbc552aef740886df63528403)\n\n&amp;#x200B;\n\n[recolored to yellow](https://preview.redd.it/f9d4me8h26x61.png?width=1450&amp;format=png&amp;auto=webp&amp;s=2d6c53a5108734f1b169dd694184ba3813be5158)\n\n&amp;#x200B;\n\n[base](https://preview.redd.it/00p9gvfi26x61.jpg?width=3200&amp;format=pjpg&amp;auto=webp&amp;s=55abbafebdfcc72b2723ed7ae1e74b3631e78a07)\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n[recolored to yellow and green](https://preview.redd.it/2qo7ttaj26x61.png?width=1290&amp;format=png&amp;auto=webp&amp;s=815e1d10db9583caf8fccf65f8fd3b43beabd2e9)\n\nAnd now lets talk about the actual thing  - [Repalette](https://github.com/danielgafni/repalette). During this autumn I've been working on a tool that would allow image recoloring to any given color palette. You know how hard it's to find wallpapers for the [Nord](https://www.nordtheme.com/) theme, right? :) Surprisingly, such tool doesn't exist. The available tools are simply changing the colorspace for all the pixels, or doing some other heuristics, which is not the ideal, of course. I wanted to create something that would work with any images and palettes. Obviously, this is a Deep Learning / Computer Vision problem. A neural network would be able to recolor images in a smart way, taking the context into account and maintaining a realistic look of the image. Fortunately, I've found a [paper](https://www.researchgate.net/publication/319277684_PaletteNet_Image_Recolorization_with_Given_Color_Palette) from 2017 about this very thing. So I've implemented this paper and made [Repalette](https://github.com/danielgafni/repalette).\n\nGood news - it works in some way. Bad news - I've only been able to finish the first of the two steps of the neural network training. GAN training has been very hard, and I also started working at a full time job, so I kinda stopped working on this project around January. A a result, the model output is far from ideal. It may ignore some colors, introduce too much of it's own color palette vision and sometimes produces visual artifacts. It works kinda ok if the chosen palette contains close colors (reddish tones, bluish tones, etc):\n\n&amp;#x200B;\n\nhttps://preview.redd.it/tk91apxk26x61.png?width=1650&amp;format=png&amp;auto=webp&amp;s=bed970acda9240106a53a5dc782cb61c6e7d9e77\n\n&amp;#x200B;\n\n[recolored to red](https://preview.redd.it/1a8sdgwl26x61.png?width=902&amp;format=png&amp;auto=webp&amp;s=c55fa1c4ea4abaa5ccc2211fcf89dc071750e4b0)\n\nThe results for more complex palettes might be unpredictable.\n\nNow I'm open-sourcing it for two reasons:\n\n1. I want you guys to be able to use it :)\n2. I hope someone with better knowledge of GANs can help me with finishing the NN training process.\n3. I hope someone with better knowledge of web programming will be able to make a better UI for the model.\n\nSo, anyway, right now the model produces kinda meh results, but they can be satisfying in some cases. You can easily use it with [Docker](https://docs.docker.com/engine/install/). Usage instructions:\n\n1. Install Docker.\n2. Pull the web application container:  \n`docker pull danielgafni/repalette:app`\n3. Run the pulled container:  \n`docker run -p 8000:8000 danielgafni/repalette:app`\n4. Open in your browser:  \nlocalhost:8000\n5. Boom! You can upload an image, select 6 colors (this is a hard limitation) for the color palette and recolor the image! You may want to play with the order of colors to achieve (if possible lol) the desirable result.\n\nThe web app is very basic, yet it does its job.\n\nI will be very happy if anyone here gets interested in the problem! Unfortunately, right now I can't continue the active development of Repalette (I'm simply too busy with different stuff IRL), but can easily maintain the repo, review PRs, etc.\n\nI believe, the state of the project is very close to be valuable for any /r/unixporn user. Imagine being able to use any wallpaper / image you like with your favorite color theme!\n\nRepository: [https://github.com/danielgafni/repalette](https://github.com/danielgafni/repalette)\n\nEdit: AS mentioned in the comments, tools like ImageGoNord are not very smart. Roughly speaking, they simply clip the image pixels to the closest color, which can harm the object borders or ruin gradients."", 'author_fullname': 't2_5c8xe6bb', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Repalette: an image recoloring tool', 'link_flair_richtext': [{'e': 'text', 't': 'Discussion'}], 'subreddit_name_prefixed': 'r/unixporn', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'1a8sdgwl26x61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 86, 'x': 108, 'u': 'https://preview.redd.it/1a8sdgwl26x61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=385ba072ca1f31aa226ec2020e2954babd349d1d'}, {'y': 173, 'x': 216, 'u': 'https://preview.redd.it/1a8sdgwl26x61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=718f9f09b9f68892adc8144dac1a049a9580434d'}, {'y': 257, 'x': 320, 'u': 'https://preview.redd.it/1a8sdgwl26x61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=73023a160de3c8e0f644742e42840ebea1d7fc33'}, {'y': 515, 'x': 640, 'u': 'https://preview.redd.it/1a8sdgwl26x61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5b579648bac3521319ebb5be4f2f194860ae36ce'}], 's': {'y': 726, 'x': 902, 'u': 'https://preview.redd.it/1a8sdgwl26x61.png?width=902&amp;format=png&amp;auto=webp&amp;s=c55fa1c4ea4abaa5ccc2211fcf89dc071750e4b0'}, 'id': '1a8sdgwl26x61'}, '8vbuhttf26x61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 63, 'x': 108, 'u': 'https://preview.redd.it/8vbuhttf26x61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=03aa7a01f8f316de6f6c20de28e38944e1de0df0'}, {'y': 126, 'x': 216, 'u': 'https://preview.redd.it/8vbuhttf26x61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=52fe825f38508d3ab3fc287b3d0655ec122723bc'}, {'y': 187, 'x': 320, 'u': 'https://preview.redd.it/8vbuhttf26x61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=294867b6e1f4d344968ea0d9ef1320f4de3749b0'}, {'y': 375, 'x': 640, 'u': 'https://preview.redd.it/8vbuhttf26x61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6780171f711926a6168f9495dfc9e7dca44d5b66'}, {'y': 563, 'x': 960, 'u': 'https://preview.redd.it/8vbuhttf26x61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8f3f21d3a387e8e8819e8545cbce23c1abda244d'}, {'y': 633, 'x': 1080, 'u': 'https://preview.redd.it/8vbuhttf26x61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=18fb555e3f363626585cdc946104f5609ae32ae3'}], 's': {'y': 850, 'x': 1448, 'u': 'https://preview.redd.it/8vbuhttf26x61.png?width=1448&amp;format=png&amp;auto=webp&amp;s=b818302acd6f2d9bbc552aef740886df63528403'}, 'id': '8vbuhttf26x61'}, '00p9gvfi26x61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/00p9gvfi26x61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5e77df9f100c93190b0fe680ed039287e33f2702'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/00p9gvfi26x61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7bf6c161e83d4fc01c8adfba477fd104578bd3b3'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/00p9gvfi26x61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b097225df65d28e32f3f55b61e98d21836d8dcff'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/00p9gvfi26x61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=020861f87e2ec4d74fbc3326265479f826986fb9'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/00p9gvfi26x61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e78f711c4da1a0053517f6225040516caacb9e58'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/00p9gvfi26x61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=01f2f2cac3f1b2c3b46aedbb18e4ef61082dfccd'}], 's': {'y': 1800, 'x': 3200, 'u': 'https://preview.redd.it/00p9gvfi26x61.jpg?width=3200&amp;format=pjpg&amp;auto=webp&amp;s=55abbafebdfcc72b2723ed7ae1e74b3631e78a07'}, 'id': '00p9gvfi26x61'}, 'f9d4me8h26x61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 67, 'x': 108, 'u': 'https://preview.redd.it/f9d4me8h26x61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=59d00d1fee68f0fd5fa41572289441981af26a01'}, {'y': 135, 'x': 216, 'u': 'https://preview.redd.it/f9d4me8h26x61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bd62025a1eb05ad97d49ad31849d25b454dcef34'}, {'y': 201, 'x': 320, 'u': 'https://preview.redd.it/f9d4me8h26x61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=18aa9086cfbdff4dcc28e4c3f144947159223b20'}, {'y': 402, 'x': 640, 'u': 'https://preview.redd.it/f9d4me8h26x61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f9b4aeecf1a5222a368d166f86e9114bd967e167'}, {'y': 603, 'x': 960, 'u': 'https://preview.redd.it/f9d4me8h26x61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6c0a4fb1eb8413fb615df9756adc46c2281cc3c0'}, {'y': 678, 'x': 1080, 'u': 'https://preview.redd.it/f9d4me8h26x61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=76ec6a0b00ab543e9a4f89636e93d28b85876de3'}], 's': {'y': 911, 'x': 1450, 'u': 'https://preview.redd.it/f9d4me8h26x61.png?width=1450&amp;format=png&amp;auto=webp&amp;s=2d6c53a5108734f1b169dd694184ba3813be5158'}, 'id': 'f9d4me8h26x61'}, '2qo7ttaj26x61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 76, 'x': 108, 'u': 'https://preview.redd.it/2qo7ttaj26x61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d81cff862af8834a2802989854840af9962997e4'}, {'y': 152, 'x': 216, 'u': 'https://preview.redd.it/2qo7ttaj26x61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a55686533a39e906b3b8e54a27bdb669b10bd55b'}, {'y': 225, 'x': 320, 'u': 'https://preview.redd.it/2qo7ttaj26x61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d84bcdaf886359994724bcdb5eeca9b7a7a8f3b8'}, {'y': 451, 'x': 640, 'u': 'https://preview.redd.it/2qo7ttaj26x61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f70ca98dccde1200666201d8b354fa2ebbc1f8a1'}, {'y': 677, 'x': 960, 'u': 'https://preview.redd.it/2qo7ttaj26x61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=cdb2c71303dd5cc295fdbd75bff77c067e11e868'}, {'y': 762, 'x': 1080, 'u': 'https://preview.redd.it/2qo7ttaj26x61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5f1adb5e732835e040e18bb34389224dcaface72'}], 's': {'y': 911, 'x': 1290, 'u': 'https://preview.redd.it/2qo7ttaj26x61.png?width=1290&amp;format=png&amp;auto=webp&amp;s=815e1d10db9583caf8fccf65f8fd3b43beabd2e9'}, 'id': '2qo7ttaj26x61'}, 'tu6wjwbe26x61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/tu6wjwbe26x61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=07196fdd32049db10dafb5c0e0c590988b238d02'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/tu6wjwbe26x61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=32110e4dc9a050dd9b585f9b97d79afd6a4445f2'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/tu6wjwbe26x61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5c5af017cdc6d7ab6951641db3ca78e336453146'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/tu6wjwbe26x61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c28da87eb24c97beca6b3e828661581e8b105e02'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/tu6wjwbe26x61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ee6bf0e051046c475462b16b197b5cd2282cfaec'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/tu6wjwbe26x61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2c7cf29c822ba885e09e4223663f92c0ca6825de'}], 's': {'y': 1441, 'x': 2560, 'u': 'https://preview.redd.it/tu6wjwbe26x61.jpg?width=2560&amp;format=pjpg&amp;auto=webp&amp;s=c47b352ac4da815ba17e045ae3872eb8f6aac7da'}, 'id': 'tu6wjwbe26x61'}, 'tk91apxk26x61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 70, 'x': 108, 'u': 'https://preview.redd.it/tk91apxk26x61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=52ba3159f1b37fe1176853a37bcbc11ebf5a021b'}, {'y': 140, 'x': 216, 'u': 'https://preview.redd.it/tk91apxk26x61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=134601113ea331c08bb7f2b64d52c8fb64e1a789'}, {'y': 207, 'x': 320, 'u': 'https://preview.redd.it/tk91apxk26x61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=20a1ad0f28671430757c03b639ced8f41db9f970'}, {'y': 415, 'x': 640, 'u': 'https://preview.redd.it/tk91apxk26x61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=9e20afa46bdefa42e701b89fb82730c2869eae75'}, {'y': 622, 'x': 960, 'u': 'https://preview.redd.it/tk91apxk26x61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1fb12cbd3981a243a3e727221d7ebf351611898f'}, {'y': 700, 'x': 1080, 'u': 'https://preview.redd.it/tk91apxk26x61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6fb80783053df15971dbfb469a6866c5a1ec8fe9'}], 's': {'y': 1070, 'x': 1650, 'u': 'https://preview.redd.it/tk91apxk26x61.png?width=1650&amp;format=png&amp;auto=webp&amp;s=bed970acda9240106a53a5dc782cb61c6e7d9e77'}, 'id': 'tk91apxk26x61'}}, 'name': 't3_n4o4n5', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.98, 'author_flair_background_color': '#f7f7f7', 'subreddit_type': 'public', 'ups': 44, 'total_awards_received': 2, 'media_embed': {}, 'author_flair_template_id': '9010013e-e63e-11e5-b3ef-0ecf3ab29885', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 44, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': 1620161561.0, 'author_flair_css_class': 'arch', 'author_flair_richtext': [{'a': ':Arch:', 'e': 'emoji', 'u': 'https://emoji.redditmedia.com/o81mrgvs8r711_t5_2sx2i/Arch'}], 'gildings': {'gid_1': 1}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1620163108.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'richtext', 'domain': 'self.unixporn', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, fellow ricers!&lt;/p&gt;\n\n&lt;p&gt;Yes, you can recolor images with this. To any color palette. Automatically. With &lt;del&gt;AI&lt;/del&gt; deep neural networks. Firstly, a few screenshots:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/tu6wjwbe26x61.jpg?width=2560&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=c47b352ac4da815ba17e045ae3872eb8f6aac7da""&gt;base&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/8vbuhttf26x61.png?width=1448&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b818302acd6f2d9bbc552aef740886df63528403""&gt;recolored to green&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/f9d4me8h26x61.png?width=1450&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2d6c53a5108734f1b169dd694184ba3813be5158""&gt;recolored to yellow&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/00p9gvfi26x61.jpg?width=3200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=55abbafebdfcc72b2723ed7ae1e74b3631e78a07""&gt;base&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/2qo7ttaj26x61.png?width=1290&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=815e1d10db9583caf8fccf65f8fd3b43beabd2e9""&gt;recolored to yellow and green&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And now lets talk about the actual thing  - &lt;a href=""https://github.com/danielgafni/repalette""&gt;Repalette&lt;/a&gt;. During this autumn I&amp;#39;ve been working on a tool that would allow image recoloring to any given color palette. You know how hard it&amp;#39;s to find wallpapers for the &lt;a href=""https://www.nordtheme.com/""&gt;Nord&lt;/a&gt; theme, right? :) Surprisingly, such tool doesn&amp;#39;t exist. The available tools are simply changing the colorspace for all the pixels, or doing some other heuristics, which is not the ideal, of course. I wanted to create something that would work with any images and palettes. Obviously, this is a Deep Learning / Computer Vision problem. A neural network would be able to recolor images in a smart way, taking the context into account and maintaining a realistic look of the image. Fortunately, I&amp;#39;ve found a &lt;a href=""https://www.researchgate.net/publication/319277684_PaletteNet_Image_Recolorization_with_Given_Color_Palette""&gt;paper&lt;/a&gt; from 2017 about this very thing. So I&amp;#39;ve implemented this paper and made &lt;a href=""https://github.com/danielgafni/repalette""&gt;Repalette&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Good news - it works in some way. Bad news - I&amp;#39;ve only been able to finish the first of the two steps of the neural network training. GAN training has been very hard, and I also started working at a full time job, so I kinda stopped working on this project around January. A a result, the model output is far from ideal. It may ignore some colors, introduce too much of it&amp;#39;s own color palette vision and sometimes produces visual artifacts. It works kinda ok if the chosen palette contains close colors (reddish tones, bluish tones, etc):&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/tk91apxk26x61.png?width=1650&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bed970acda9240106a53a5dc782cb61c6e7d9e77""&gt;https://preview.redd.it/tk91apxk26x61.png?width=1650&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bed970acda9240106a53a5dc782cb61c6e7d9e77&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/1a8sdgwl26x61.png?width=902&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c55fa1c4ea4abaa5ccc2211fcf89dc071750e4b0""&gt;recolored to red&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The results for more complex palettes might be unpredictable.&lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m open-sourcing it for two reasons:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I want you guys to be able to use it :)&lt;/li&gt;\n&lt;li&gt;I hope someone with better knowledge of GANs can help me with finishing the NN training process.&lt;/li&gt;\n&lt;li&gt;I hope someone with better knowledge of web programming will be able to make a better UI for the model.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;So, anyway, right now the model produces kinda meh results, but they can be satisfying in some cases. You can easily use it with &lt;a href=""https://docs.docker.com/engine/install/""&gt;Docker&lt;/a&gt;. Usage instructions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Install Docker.&lt;/li&gt;\n&lt;li&gt;Pull the web application container:&lt;br/&gt;\n&lt;code&gt;docker pull danielgafni/repalette:app&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Run the pulled container:&lt;br/&gt;\n&lt;code&gt;docker run -p 8000:8000 danielgafni/repalette:app&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;Open in your browser:&lt;br/&gt;\nlocalhost:8000&lt;/li&gt;\n&lt;li&gt;Boom! You can upload an image, select 6 colors (this is a hard limitation) for the color palette and recolor the image! You may want to play with the order of colors to achieve (if possible lol) the desirable result.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The web app is very basic, yet it does its job.&lt;/p&gt;\n\n&lt;p&gt;I will be very happy if anyone here gets interested in the problem! Unfortunately, right now I can&amp;#39;t continue the active development of Repalette (I&amp;#39;m simply too busy with different stuff IRL), but can easily maintain the repo, review PRs, etc.&lt;/p&gt;\n\n&lt;p&gt;I believe, the state of the project is very close to be valuable for any &lt;a href=""/r/unixporn""&gt;/r/unixporn&lt;/a&gt; user. Imagine being able to use any wallpaper / image you like with your favorite color theme!&lt;/p&gt;\n\n&lt;p&gt;Repository: &lt;a href=""https://github.com/danielgafni/repalette""&gt;https://github.com/danielgafni/repalette&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Edit: AS mentioned in the comments, tools like ImageGoNord are not very smart. Roughly speaking, they simply clip the image pixels to the closest color, which can harm the object borders or ruin gradients.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}], 'awarders': [], 'media_only': False, 'link_flair_template_id': '3ca0392e-016b-11e4-9698-12313b0ea137', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': ':Arch:', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2sx2i', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#5b92fa', 'id': 'n4o4n5', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'danielgafni', 'discussion_type': None, 'num_comments': 10, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/unixporn/comments/n4o4n5/repalette_an_image_recoloring_tool/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/unixporn/comments/n4o4n5/repalette_an_image_recoloring_tool/', 'subreddit_subscribers': 316293, 'created_utc': 1620134308.0, 'num_crossposts': 3, 'media': None, 'is_video': False}]",t3_n4o4n5,,,,,
,deeplearning,"This bundle of e-books is specially crafted for beginners. Everything from Python basics to the deployment of Machine Learning algorithms to production in one place.

What's included?

• Ultimate Guide to Machine Learning with Python e-book (PDF)

• Full Source Code with all examples from the book (Jupyter Notebooks)

Six additional bonus materials:

• Bonus #1: Python for Data Science (PDF + Full Source Code)

• Bonus #2: Mathematics for Machine Learning (PDF)

• Bonus #3: Guide to Data Analysis (PDF + Full Source Code)

• Bonus #4: Neural Networks Zoo (PDF)

• Bonus #5: Access to a private Discord Community

Visit the page to learn more: [https://rubikscode.net/ultimate-guide-to-machine-learning-with-python/](https://rubikscode.net/ultimate-guide-to-machine-learning-with-python/)

&amp;#x200B;

https://reddit.com/link/n4lgxy/video/3bk8d5t843x61/player",t2_2o7eaff,False,,0,False,Ultimate Guide to Machine Learning with Python (e-books bundle),[],r/deeplearning,False,6,,0,,False,t3_n4lgxy,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620154639.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This bundle of e-books is specially crafted for beginners. Everything from Python basics to the deployment of Machine Learning algorithms to production in one place.&lt;/p&gt;

&lt;p&gt;What&amp;#39;s included?&lt;/p&gt;

&lt;p&gt;• Ultimate Guide to Machine Learning with Python e-book (PDF)&lt;/p&gt;

&lt;p&gt;• Full Source Code with all examples from the book (Jupyter Notebooks)&lt;/p&gt;

&lt;p&gt;Six additional bonus materials:&lt;/p&gt;

&lt;p&gt;• Bonus #1: Python for Data Science (PDF + Full Source Code)&lt;/p&gt;

&lt;p&gt;• Bonus #2: Mathematics for Machine Learning (PDF)&lt;/p&gt;

&lt;p&gt;• Bonus #3: Guide to Data Analysis (PDF + Full Source Code)&lt;/p&gt;

&lt;p&gt;• Bonus #4: Neural Networks Zoo (PDF)&lt;/p&gt;

&lt;p&gt;• Bonus #5: Access to a private Discord Community&lt;/p&gt;

&lt;p&gt;Visit the page to learn more: &lt;a href=""https://rubikscode.net/ultimate-guide-to-machine-learning-with-python/""&gt;https://rubikscode.net/ultimate-guide-to-machine-learning-with-python/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://reddit.com/link/n4lgxy/video/3bk8d5t843x61/player""&gt;https://reddit.com/link/n4lgxy/video/3bk8d5t843x61/player&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n4lgxy,True,,RubiksCodeNMZ,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n4lgxy/ultimate_guide_to_machine_learning_with_python/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n4lgxy/ultimate_guide_to_machine_learning_with_python/,66146,1620125839.0,0,,False,,,"{'3bk8d5t843x61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/n4lgxy/asset/3bk8d5t843x61/DASHPlaylist.mpd?a=1626450118%2CNzA0YjlhYTlhZjBkYjdmMzEzODFkZWU0MTM3NTczNzFhMDBjY2NmM2RhMDI5MmM4YjIzYzA4MzE0MjFhOTQyZA%3D%3D&amp;v=1&amp;f=sd', 'x': 1920, 'y': 1080, 'hlsUrl': 'https://v.redd.it/link/n4lgxy/asset/3bk8d5t843x61/HLSPlaylist.m3u8?a=1626450118%2CNjRhNjkyYjhiZTBhMTNkNjkwNGJmZDYxYjAxOTUyMDYzNDdlMTUxMDEyNTg2MzY5YTg2NDQ5MmYxYTZkOGM1NQ%3D%3D&amp;v=1&amp;f=sd', 'id': '3bk8d5t843x61', 'isGif': False}}",,,,
,deeplearning,"Researchers from Carnegie Mellon University, the University of Texas at Austin and Facebook AI propose a novel paradigm to optimize widths for each CNN layer. The method is compatible across various width optimization algorithms and networks and achieves up to a 320x reduction in width optimization overhead without compromising top-1 accuracy on ImageNet.

Here is a quick read: [CMU, UT Austin &amp; Facebook’s CNN Layer Width Optimization Strategies Achieve 320x Overhead Reduction](https://syncedreview.com/2021/05/03/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-10/).

The paper *Width Transfer: On the (In)Variance of Width Optimization* is on [arXiv](https://arxiv.org/pdf/2104.13255.pdf).",t2_2fv4yodo,False,,0,False,"[R] CMU, UT Austin &amp; Facebook’s CNN Layer Width Optimization Strategies Achieve 320x Overhead Reduction",[],r/deeplearning,False,6,,0,,False,t3_n416ah,False,dark,0.86,,public,22,0,{},,False,[],,False,False,,{},,False,22,,False,False,,False,,[],{},,True,,1620089879.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Researchers from Carnegie Mellon University, the University of Texas at Austin and Facebook AI propose a novel paradigm to optimize widths for each CNN layer. The method is compatible across various width optimization algorithms and networks and achieves up to a 320x reduction in width optimization overhead without compromising top-1 accuracy on ImageNet.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/05/03/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-10/""&gt;CMU, UT Austin &amp;amp; Facebook’s CNN Layer Width Optimization Strategies Achieve 320x Overhead Reduction&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Width Transfer: On the (In)Variance of Width Optimization&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.13255.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n416ah,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n416ah/r_cmu_ut_austin_facebooks_cnn_layer_width/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n416ah/r_cmu_ut_austin_facebooks_cnn_layer_width/,66146,1620061079.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,"The AI Monthly Top 3 — April 2021: a curated list of the latest breakthroughs in AI in April 2021 with a clear video explanation, link to a more in-depth article, and references.",[],r/deeplearning,False,6,,0,,False,t3_n3ukyd,False,dark,0.89,,public,28,0,{},,False,[],,False,False,,{},,False,28,,False,False,,False,,[],{},,False,,1620073250.0,text,6,,,text,louisbouchard.ai,False,,,,,https://www.louisbouchard.ai/the-ai-monthly-top-3-april-2021/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3ukyd,True,,OnlyProggingForFun,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n3ukyd/the_ai_monthly_top_3_april_2021_a_curated_list_of/,all_ads,False,https://www.louisbouchard.ai/the-ai-monthly-top-3-april-2021/,66146,1620044450.0,0,,False,,,,,,,
,deeplearning,,t2_44mbtmjy,False,,0,False,Latest from Baidu researchers: Automatic video generation from audio or text,[],r/deeplearning,False,6,,0,,False,t3_n4fmjm,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1620130136.0,text,6,,,text,self.LatestInML,False,,,,,/r/LatestInML/comments/n4fgzr/latest_from_baidu_researchers_automatic_video/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n4fmjm,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n4fmjm/latest_from_baidu_researchers_automatic_video/,all_ads,False,/r/LatestInML/comments/n4fgzr/latest_from_baidu_researchers_automatic_video/,66146,1620101336.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper](https://www.catalyzex.com/paper/arxiv:2104.14631)\n\n&amp;#x200B;\n\nhttps://reddit.com/link/n4fgzr/video/486ad17v11x61/player\n\n👇 Free extension to get code for ML papers (❤️'d by Andrew Ng) Chrome: https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil Firefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Latest from Baidu researchers: Automatic video generation from audio or text', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'486ad17v11x61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/n4fgzr/asset/486ad17v11x61/DASHPlaylist.mpd?a=1626450118%2CNDI2NTE4MDkzYzE1YzhkYThiNzkwODUwYTQwNjhhM2U1ZDY4MGFiNDg1N2U2MDU0MjMzZTNmMGYzYmE5NTVjOQ%3D%3D&amp;v=1&amp;f=sd', 'x': 640, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/n4fgzr/asset/486ad17v11x61/HLSPlaylist.m3u8?a=1626450118%2CNTA4MzcxNTFhZWMxYWI4OTZmNWZiM2IxYWZiOTliNmU3YmI5NGNkODVmYzk2MWZkNGYwNTkxOTVhMDIxNzUzOA%3D%3D&amp;v=1&amp;f=sd', 'id': '486ad17v11x61', 'isGif': False}}, 'name': 't3_n4fgzr', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.88, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 1, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1620129581.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2104.14631""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/n4fgzr/video/486ad17v11x61/player""&gt;https://reddit.com/link/n4fgzr/video/486ad17v11x61/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39;d by Andrew Ng) Chrome: &lt;a href=""https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt; Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'n4fgzr', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/n4fgzr/latest_from_baidu_researchers_automatic_video/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/n4fgzr/latest_from_baidu_researchers_automatic_video/', 'subreddit_subscribers': 7049, 'created_utc': 1620100781.0, 'num_crossposts': 10, 'media': None, 'is_video': False}]",t3_n4fgzr,,,,,
,deeplearning,"I am currently trying to train a tiramisu model based on the densnet. Since my main target is background subtraction, I am trying to train with higher res images. But even importing 512x512 res images is causing major issues. I have a 32 gb ram. The ram gets easily filled when I load the data. It is causing memory issues. I am using an RTX 3080 and I cannot train the model with batch size more than 1. I previously used 800x800 res images for training and it crashed my video driver, and the video driver totally stopped working even after a restart. Then video driver had to be reinstalled once again. 


My doubts are:
 1. Is there any way to compress the image array and use it to train thr model?
2. Will data generator solve the problem?
3. How to train higher res images with larger batch sizes?
4. Will allowing model to train over night affect graphics card?",t2_1rnuy9v2,False,,0,False,Training 100 layer tiramisu model is causing memory issue and crashed my video driver. I am using tensorflow,[],r/deeplearning,False,6,,0,,False,t3_n47kix,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620105347.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am currently trying to train a tiramisu model based on the densnet. Since my main target is background subtraction, I am trying to train with higher res images. But even importing 512x512 res images is causing major issues. I have a 32 gb ram. The ram gets easily filled when I load the data. It is causing memory issues. I am using an RTX 3080 and I cannot train the model with batch size more than 1. I previously used 800x800 res images for training and it crashed my video driver, and the video driver totally stopped working even after a restart. Then video driver had to be reinstalled once again. &lt;/p&gt;

&lt;p&gt;My doubts are:
 1. Is there any way to compress the image array and use it to train thr model?
2. Will data generator solve the problem?
3. How to train higher res images with larger batch sizes?
4. Will allowing model to train over night affect graphics card?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n47kix,True,,baraths92,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/n47kix/training_100_layer_tiramisu_model_is_causing/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n47kix/training_100_layer_tiramisu_model_is_causing/,66146,1620076547.0,0,,False,,,,,,,
,deeplearning,,t2_u58vv,False,,0,False,"PCAVS - ""Deepfake"" with just audio",[],r/deeplearning,False,6,,0,,False,t3_n3m8t0,False,dark,0.92,,public,19,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6J_28OKeqLk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'You Only Need Audio To Deepfake Now! Might look slightly cursed tho [PCAVS]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6J_28OKeqLk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'bycloud', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6J_28OKeqLk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCgfe2ooZD3VJPB6aJAnuQng'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6J_28OKeqLk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n3m8t0', 'height': 200}",,False,19,,False,False,,False,,[],{},,False,,1620039054.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/6J_28OKeqLk,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3m8t0,True,,cloud_weather,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n3m8t0/pcavs_deepfake_with_just_audio/,all_ads,False,https://youtu.be/6J_28OKeqLk,66146,1620010254.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'You Only Need Audio To Deepfake Now! Might look slightly cursed tho [PCAVS]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6J_28OKeqLk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'bycloud', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6J_28OKeqLk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCgfe2ooZD3VJPB6aJAnuQng'}}",False,,,,,,,
,deeplearning,"# [An Image Is Worth 16X16 Words: Transformers For Image Recognition At Scale](https://t.me/casual_gan/33)

In this paper from late 2020 the authors propose a novel architecture that successfully applies transformers to the image classification task. The model is a transformer encoder that operates on flattened image patches. By pretraining on a very large image dataset the authors are able to show great results on a number of smaller datasets after finetuning the classifier on top of the transformer model. [More details](https://t.me/casual_gan/33).

[ViT model architecture overview](https://preview.redd.it/ajbvoi4h7yw61.png?width=1280&amp;format=png&amp;auto=webp&amp;s=bb47808c670907c3d7b7296152ab7875b7e5cba7)

[\[10 minute paper explanation\]](https://t.me/casual_gan/33) [\[Arxiv\]](https://arxiv.org/abs/2010.11929)",t2_hhio3,False,,0,False,[D] An Image Is Worth 16X16 Words: Transformers For Image Recognition At Scale - Vision Transformers explained!,[],r/deeplearning,False,6,,0,,False,t3_n43eyv,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620095161.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h1&gt;&lt;a href=""https://t.me/casual_gan/33""&gt;An Image Is Worth 16X16 Words: Transformers For Image Recognition At Scale&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;In this paper from late 2020 the authors propose a novel architecture that successfully applies transformers to the image classification task. The model is a transformer encoder that operates on flattened image patches. By pretraining on a very large image dataset the authors are able to show great results on a number of smaller datasets after finetuning the classifier on top of the transformer model. &lt;a href=""https://t.me/casual_gan/33""&gt;More details&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ajbvoi4h7yw61.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bb47808c670907c3d7b7296152ab7875b7e5cba7""&gt;ViT model architecture overview&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://t.me/casual_gan/33""&gt;[10 minute paper explanation]&lt;/a&gt; &lt;a href=""https://arxiv.org/abs/2010.11929""&gt;[Arxiv]&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n43eyv,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n43eyv/d_an_image_is_worth_16x16_words_transformers_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n43eyv/d_an_image_is_worth_16x16_words_transformers_for/,66146,1620066361.0,0,,False,,,"{'ajbvoi4h7yw61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 71, 'x': 108, 'u': 'https://preview.redd.it/ajbvoi4h7yw61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=95496e85e686efcf543df32fc59539737f447654'}, {'y': 142, 'x': 216, 'u': 'https://preview.redd.it/ajbvoi4h7yw61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c01705891529a1cf18fe65059201821e0858d093'}, {'y': 211, 'x': 320, 'u': 'https://preview.redd.it/ajbvoi4h7yw61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f1624cc200d4fd9d96e0b8cb4f681b3ce2335a73'}, {'y': 423, 'x': 640, 'u': 'https://preview.redd.it/ajbvoi4h7yw61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aa0df0fd78bf707fd4c4ebedc2fb22de347ddeed'}, {'y': 635, 'x': 960, 'u': 'https://preview.redd.it/ajbvoi4h7yw61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d537376e6ea7a83c3e0ced2c67d3e3ce3ee2f19c'}, {'y': 714, 'x': 1080, 'u': 'https://preview.redd.it/ajbvoi4h7yw61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=da037868c1e0f4b30ccd4f5304e9d5eacaf24211'}], 's': {'y': 847, 'x': 1280, 'u': 'https://preview.redd.it/ajbvoi4h7yw61.png?width=1280&amp;format=png&amp;auto=webp&amp;s=bb47808c670907c3d7b7296152ab7875b7e5cba7'}, 'id': 'ajbvoi4h7yw61'}}",,,,
,deeplearning,"I am building a classifier to differentiate between real faces and spoof faces,
I have tried to use a pretrained model (InceptionV3) in tensorflow but it's just stuck at epoch 1 for pretty long time and doesn't seem to do anything? Someone can take a look at my code and help me with it? Thanks

Link colab: https://colab.research.google.com/drive/1aIqkFVrflJOhGVE1uViMM_qLinq3AON6",t2_5tjqypkb,False,,0,False,Google colab doesn't seem to work with pretrained model in tensorflow,[],r/deeplearning,False,6,,0,,False,t3_n3phg5,False,dark,0.84,,public,9,0,{},,False,[],,False,False,,{},,False,9,,False,False,,1620024034.0,,[],{},,True,,1620051721.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am building a classifier to differentiate between real faces and spoof faces,
I have tried to use a pretrained model (InceptionV3) in tensorflow but it&amp;#39;s just stuck at epoch 1 for pretty long time and doesn&amp;#39;t seem to do anything? Someone can take a look at my code and help me with it? Thanks&lt;/p&gt;

&lt;p&gt;Link colab: &lt;a href=""https://colab.research.google.com/drive/1aIqkFVrflJOhGVE1uViMM_qLinq3AON6""&gt;https://colab.research.google.com/drive/1aIqkFVrflJOhGVE1uViMM_qLinq3AON6&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3phg5,True,,Just-A-abnormal-Guy,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/n3phg5/google_colab_doesnt_seem_to_work_with_pretrained/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n3phg5/google_colab_doesnt_seem_to_work_with_pretrained/,66146,1620022921.0,0,,False,,,,,,,
,deeplearning,"As part of our ML postgrad, we developed a tool for our lab that speeds up video labelling times by 15-20x using few-shot classification / human-in-the-loop input (e.g., a person labels a few frames and the algorithm handles the rest).

We’re looking for beta testers to help refine the platform to additional real-world use-cases. Besides early access to the platform, we’ll give any early testers free lifetime access once we launch.

Please fill out this form to get early access: [https://forms.gle/CGWd29xNv24Kwm1Y6](https://forms.gle/CGWd29xNv24Kwm1Y6)",t2_eedd5,False,,0,False,Hi r/deeplearning! We created an AI-assisted video annotation tool that speeds up labelling time by 17x - looking for BETA testers to help us refine web application,[],r/deeplearning,False,6,,0,,False,t3_n46t9t,False,dark,0.25,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620103455.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As part of our ML postgrad, we developed a tool for our lab that speeds up video labelling times by 15-20x using few-shot classification / human-in-the-loop input (e.g., a person labels a few frames and the algorithm handles the rest).&lt;/p&gt;

&lt;p&gt;We’re looking for beta testers to help refine the platform to additional real-world use-cases. Besides early access to the platform, we’ll give any early testers free lifetime access once we launch.&lt;/p&gt;

&lt;p&gt;Please fill out this form to get early access: &lt;a href=""https://forms.gle/CGWd29xNv24Kwm1Y6""&gt;https://forms.gle/CGWd29xNv24Kwm1Y6&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n46t9t,True,,_conquistador,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n46t9t/hi_rdeeplearning_we_created_an_aiassisted_video/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n46t9t/hi_rdeeplearning_we_created_an_aiassisted_video/,66146,1620074655.0,0,,False,,,,,,,
,deeplearning,"In case you are interested, Udacity offers [30 Days Free Access to their Nanodegrees](https://imp.i115008.net/c/2402645/788201/11298).

This includes Deep Learning and Machine Learning Nanodegrees.",t2_k9eg8,False,,0,False,30 Days Free Access to Machine Learning with PyTorch Nanodegree,[],r/deeplearning,False,6,,0,,False,t3_n3yy28,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620084497.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In case you are interested, Udacity offers &lt;a href=""https://imp.i115008.net/c/2402645/788201/11298""&gt;30 Days Free Access to their Nanodegrees&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This includes Deep Learning and Machine Learning Nanodegrees.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3yy28,True,,hiphop1987,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n3yy28/30_days_free_access_to_machine_learning_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n3yy28/30_days_free_access_to_machine_learning_with/,66146,1620055697.0,0,,False,,,,,,,
,deeplearning,,t2_6l105jav,False,,0,False,Machine Learning &amp; Deep Learning in Python &amp; R - free course from udemy,[],r/deeplearning,False,6,,0,,False,t3_n3ygvr,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1620083339.0,text,6,,,text,myfreeonlinecourses.com,False,,,,,https://www.myfreeonlinecourses.com/2021/02/100-off-machine-learning-deep-learning.html,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3ygvr,True,,Ordinary_Craft,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n3ygvr/machine_learning_deep_learning_in_python_r_free/,all_ads,False,https://www.myfreeonlinecourses.com/2021/02/100-off-machine-learning-deep-learning.html,66146,1620054539.0,0,,False,,,,,,,
,deeplearning,,t2_6xl4d3xe,False,,0,False,World-Models Architectures | From Autoregressive to State-Space Models,[],r/deeplearning,False,6,,0,,False,t3_n3trr1,False,dark,0.57,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/0MjI2NA_s4c?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'World-Models Architectures | From Autoregressive to State-Space Models (Model-Based RL)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/0MjI2NA_s4c?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Bits Of Deep Learning', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/0MjI2NA_s4c/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIUtWXPs66MFY-hOnETfqhg'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/0MjI2NA_s4c?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n3trr1', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1620070365.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/0MjI2NA_s4c,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3trr1,True,,BitsOfDL,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n3trr1/worldmodels_architectures_from_autoregressive_to/,all_ads,False,https://youtu.be/0MjI2NA_s4c,66146,1620041565.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'World-Models Architectures | From Autoregressive to State-Space Models (Model-Based RL)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/0MjI2NA_s4c?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Bits Of Deep Learning', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/0MjI2NA_s4c/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIUtWXPs66MFY-hOnETfqhg'}}",False,,,,,,,
,deeplearning,"Hello, I'm studying the SURF algorithm.

I have a question about the scale space in SURF.

please see the picture.

The scale of the first layer in the first octave starts from 0 and, the scale of the first layer in the ""second"" octave doesn't start from 0.

I don't know the reason.

please, Could you explain it?

https://preview.redd.it/5qyz5m6hwhw41.png?width=416&amp;format=png&amp;auto=webp&amp;s=e0d218e159a3ccad8aa1979abf581edcec7b9c40",t2_5omudkg3,False,,0,False,Question. Scale space in SURF(Speeded-Up Robust Features),[],r/deeplearning,False,6,,0,,False,t3_n3p5oi,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620050324.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I&amp;#39;m studying the SURF algorithm.&lt;/p&gt;

&lt;p&gt;I have a question about the scale space in SURF.&lt;/p&gt;

&lt;p&gt;please see the picture.&lt;/p&gt;

&lt;p&gt;The scale of the first layer in the first octave starts from 0 and, the scale of the first layer in the &amp;quot;second&amp;quot; octave doesn&amp;#39;t start from 0.&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t know the reason.&lt;/p&gt;

&lt;p&gt;please, Could you explain it?&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/5qyz5m6hwhw41.png?width=416&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e0d218e159a3ccad8aa1979abf581edcec7b9c40""&gt;https://preview.redd.it/5qyz5m6hwhw41.png?width=416&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e0d218e159a3ccad8aa1979abf581edcec7b9c40&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3p5oi,True,,Huge-Profile,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n3p5oi/question_scale_space_in_surfspeededup_robust/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n3p5oi/question_scale_space_in_surfspeededup_robust/,66146,1620021524.0,0,,False,,,,,,,
,deeplearning,"I have 3 conditional inputs based on which I have to create a conditional GAN. I've tried creating 3 embeddings and concatenating their outputs with the latent vector and using this as an input to the Generator. I used a Projection Style discriminator with 3 projections. The results aren't satisfactory so far. If you have any ideas, please share them and help me out.",t2_nix9yp7,False,,0,False,Need help to create a conditional GAN with multiple conditional inputs,[],r/deeplearning,False,6,,0,,False,t3_n3s1zq,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620063367.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have 3 conditional inputs based on which I have to create a conditional GAN. I&amp;#39;ve tried creating 3 embeddings and concatenating their outputs with the latent vector and using this as an input to the Generator. I used a Projection Style discriminator with 3 projections. The results aren&amp;#39;t satisfactory so far. If you have any ideas, please share them and help me out.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3s1zq,True,,safi_842,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n3s1zq/need_help_to_create_a_conditional_gan_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n3s1zq/need_help_to_create_a_conditional_gan_with/,66146,1620034567.0,0,,False,,,,,,,
,deeplearning,Any good resources on 3D CNN for Alzheimer detection from brain MRI? Like good introduction courses or readings? I'm working with my thesis about Alzheimer detection with CNN and want gain more knowledge about deep learning in neuroimaging. I'm new to NIFTI format and struggle to find good resources. The papers I find are often too advanced for me.,t2_4p0mrjeq,False,,0,False,Any resources on CNN for neuroimaging?,[],r/deeplearning,False,6,,0,,False,t3_n3fxna,False,dark,0.84,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1620018302.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Any good resources on 3D CNN for Alzheimer detection from brain MRI? Like good introduction courses or readings? I&amp;#39;m working with my thesis about Alzheimer detection with CNN and want gain more knowledge about deep learning in neuroimaging. I&amp;#39;m new to NIFTI format and struggle to find good resources. The papers I find are often too advanced for me.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3fxna,True,,Phenoomenall,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/n3fxna/any_resources_on_cnn_for_neuroimaging/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n3fxna/any_resources_on_cnn_for_neuroimaging/,66146,1619989502.0,0,,False,,,,,,,
,deeplearning," GPT-2 and recently, GPT-3 created a lot of hype when they were launched. However, it all started with the ""Improving Language Understanding by Generative Pre-Training"" paper which introduced the idea of GPT-1.

As a part of my Paper Notes series, I have gone through the paper and created a brief yet informative summary of the paper. It will take just take a few minutes to understand GPT-1 well. Check out the links below and happy reading!

Paper Summary - [Improving Language Understanding by Generative Pre-Training](https://shreyansh26.github.io/post/2021-05-02_language_understanding_generative_pretraining/)

Annotated Paper - [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf)",t2_5xzd9om,False,,0,False,GPT-1 - Annotated Paper + Paper Summary,[],r/deeplearning,False,6,,0,,False,t3_n3aeh5,False,dark,0.93,,public,24,1,{},,False,[],,False,False,,{},,False,24,,False,False,,False,,[],{},,True,,1620002708.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;GPT-2 and recently, GPT-3 created a lot of hype when they were launched. However, it all started with the &amp;quot;Improving Language Understanding by Generative Pre-Training&amp;quot; paper which introduced the idea of GPT-1.&lt;/p&gt;

&lt;p&gt;As a part of my Paper Notes series, I have gone through the paper and created a brief yet informative summary of the paper. It will take just take a few minutes to understand GPT-1 well. Check out the links below and happy reading!&lt;/p&gt;

&lt;p&gt;Paper Summary - &lt;a href=""https://shreyansh26.github.io/post/2021-05-02_language_understanding_generative_pretraining/""&gt;Improving Language Understanding by Generative Pre-Training&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Annotated Paper - &lt;a href=""https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf""&gt;https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/GPT1.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3aeh5,True,,shreyansh26,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n3aeh5/gpt1_annotated_paper_paper_summary/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n3aeh5/gpt1_annotated_paper_paper_summary/,66146,1619973908.0,0,,False,,,,,,,
,deeplearning,"Hi, recently I am extremely excited about the topic of single domain generalization in deep neural networks as I believe this could potentially make most DNN more deployable to different environments (ignoring the computational cost). And I would love to read more about this area! 

Just wondering if any of you have any amazing material to share!",t2_43k84clc,False,,0,False,What reading materials would you recommend for Domain Robustness or Domain Generalization,[],r/deeplearning,False,6,,0,,False,t3_n3iq9b,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620026910.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, recently I am extremely excited about the topic of single domain generalization in deep neural networks as I believe this could potentially make most DNN more deployable to different environments (ignoring the computational cost). And I would love to read more about this area! &lt;/p&gt;

&lt;p&gt;Just wondering if any of you have any amazing material to share!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3iq9b,True,,sam_is_me123,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n3iq9b/what_reading_materials_would_you_recommend_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n3iq9b/what_reading_materials_would_you_recommend_for/,66146,1619998110.0,0,,False,,,,,,,
,deeplearning,"I want to use masks generated by a semantic segmentation network as (additional) input for another network.

Currently I'm simply experimenting with a one-hot encoding of the masks, but it's quite wasteful for what is essentially quite sparse data. With eg. 30 different classes and an image shape of 256x256, the input shape of 30x256x256 is quite large. Are there any other suggested techniques for handling such a case? Really intersted in reading some paper who have looked at this issue.",t2_nr5ub,False,,0,False,What's some suggested methods for including semantic masks as inputs for CNNs?,[],r/deeplearning,False,6,,0,,False,t3_n3jz39,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1620003582.0,,[],{},,True,,1620031164.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to use masks generated by a semantic segmentation network as (additional) input for another network.&lt;/p&gt;

&lt;p&gt;Currently I&amp;#39;m simply experimenting with a one-hot encoding of the masks, but it&amp;#39;s quite wasteful for what is essentially quite sparse data. With eg. 30 different classes and an image shape of 256x256, the input shape of 30x256x256 is quite large. Are there any other suggested techniques for handling such a case? Really intersted in reading some paper who have looked at this issue.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3jz39,True,,Computor123,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n3jz39/whats_some_suggested_methods_for_including/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n3jz39/whats_some_suggested_methods_for_including/,66146,1620002364.0,0,,False,,,,,,,
,deeplearning,,t2_hkv9s,False,,0,False,LINE: Large-scale Information Network Embedding (Machine Learning with Graphs),[],r/deeplearning,False,6,,0,,False,t3_n31jei,False,dark,0.79,,public,16,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VuqvD3qp76M?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'LINE: Large-scale Information Network Embedding (Machine Learning with Graphs)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VuqvD3qp76M?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/VuqvD3qp76M/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VuqvD3qp76M?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n31jei', 'height': 200}",,False,16,,False,False,,False,,[],{},,False,,1619970041.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/VuqvD3qp76M,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n31jei,True,,prakhar21,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n31jei/line_largescale_information_network_embedding/,all_ads,False,https://youtu.be/VuqvD3qp76M,66146,1619941241.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'LINE: Large-scale Information Network Embedding (Machine Learning with Graphs)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/VuqvD3qp76M?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/VuqvD3qp76M/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}}",False,,,,,,,
,deeplearning,Giving a workshop about deep learning and looking for fun examples to let the students implement. Any ideas? Ideally not too hard as I want the students to train in class.,t2_5a18hnjt,False,,0,False,Fun teaching implementations examples,[],r/deeplearning,False,6,,0,,False,t3_n3bqwh,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1620006489.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Giving a workshop about deep learning and looking for fun examples to let the students implement. Any ideas? Ideally not too hard as I want the students to train in class.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3bqwh,True,,jimmyGij,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/n3bqwh/fun_teaching_implementations_examples/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n3bqwh/fun_teaching_implementations_examples/,66146,1619977689.0,0,,False,,,,,,,
,deeplearning,"Hello,

I don't know where to begin with but I would appreciate if some of you know some(books/pdfs/lessons) about deep learning image batch-related.

I always have been eager to make neural networks.

Thanks for reading, I appreciate it.",t2_73gppfa5,False,,0,False,Learning image related deep learning.,[],r/deeplearning,False,6,,0,,False,t3_n3fqbm,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620017701.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t know where to begin with but I would appreciate if some of you know some(books/pdfs/lessons) about deep learning image batch-related.&lt;/p&gt;

&lt;p&gt;I always have been eager to make neural networks.&lt;/p&gt;

&lt;p&gt;Thanks for reading, I appreciate it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3fqbm,True,,Duuuuuuuuuuh,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n3fqbm/learning_image_related_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n3fqbm/learning_image_related_deep_learning/,66146,1619988901.0,0,,False,,,,,,,
,deeplearning,"Hey guys! I have recently wrote simple tutorial on what a variational autoencoder (VAE) is and how to implement it with PyTorch. Feel free to have a look!

[https://taying-cheng.medium.com/building-a-convolutional-vae-in-pytorch-a0f54c947f71](https://taying-cheng.medium.com/building-a-convolutional-vae-in-pytorch-a0f54c947f71)",t2_jn2eq6v,False,,0,False,Building a convolutional variational autoencoder (VAE) in PyTorch,[],r/deeplearning,False,6,,0,,False,t3_n39j5x,False,dark,0.55,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1620000341.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys! I have recently wrote simple tutorial on what a variational autoencoder (VAE) is and how to implement it with PyTorch. Feel free to have a look!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://taying-cheng.medium.com/building-a-convolutional-vae-in-pytorch-a0f54c947f71""&gt;https://taying-cheng.medium.com/building-a-convolutional-vae-in-pytorch-a0f54c947f71&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n39j5x,True,,tt12343,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n39j5x/building_a_convolutional_variational_autoencoder/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n39j5x/building_a_convolutional_variational_autoencoder/,66146,1619971541.0,0,,False,,,,,,,
,deeplearning,,t2_5fsp2x6v,False,,0,False,CrossWeigh: Training NER with Imperfect Annotations | Research Papers Summary 016,[],r/deeplearning,False,6,,0,,False,t3_n3czdo,False,dark,0.6,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IXrwYWgnijQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'CrossWeigh: Training NER with Imperfect Annotations | Research Papers Summary 016', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IXrwYWgnijQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Ryan Ong', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/IXrwYWgnijQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/basketball10029508'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IXrwYWgnijQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n3czdo', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1620010084.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/IXrwYWgnijQ,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3czdo,True,,RyanAI100,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n3czdo/crossweigh_training_ner_with_imperfect/,all_ads,False,https://youtu.be/IXrwYWgnijQ,66146,1619981284.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'CrossWeigh: Training NER with Imperfect Annotations | Research Papers Summary 016', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IXrwYWgnijQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Ryan Ong', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/IXrwYWgnijQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/basketball10029508'}}",False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,Real scalpels + artificial intelligence | Robot Surgeon,[],r/deeplearning,False,6,,0,,False,t3_n3cu38,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Z28Cwniw8MI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Real scalpels + artificial intelligence | Robot Surgeon', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Z28Cwniw8MI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Z28Cwniw8MI/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Z28Cwniw8MI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n3cu38', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1620009667.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/Z28Cwniw8MI,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3cu38,True,,cmillionaire9,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n3cu38/real_scalpels_artificial_intelligence_robot/,all_ads,False,https://youtu.be/Z28Cwniw8MI,66146,1619980867.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Real scalpels + artificial intelligence | Robot Surgeon', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Z28Cwniw8MI?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Z28Cwniw8MI/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,,t2_16ce3y,False,,0,False,[D] Can anybody tell me which machine/deep learning algorithms are best for video chat and video streaming applications and why?,[],r/deeplearning,False,6,,0,,False,t3_n3genb,False,dark,0.38,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1620019647.0,text,6,,,text,self.deeplearning,False,,,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n3genb,True,,tsukuyomiii,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/n3genb/d_can_anybody_tell_me_which_machinedeep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n3genb/d_can_anybody_tell_me_which_machinedeep_learning/,66146,1619990847.0,0,,False,,,,,,,
,deeplearning,"Recently I started preparing to get a job as a Data Scientist &amp; I have been bashing my head for days to find preparatory resources.

For getting a software developer job there are resources like [geeksforgeeks](https://www.geeksforgeeks.org/), [leetcode](https://leetcode.com/), [freecodecamp](https://www.freecodecamp.org/), [cracking the coding interview](https://www.crackingthecodinginterview.com/), etc.

Which website, course, book do people follow to prepare for a job interview as a Data Scientist, ML engineer, or Research Scientist?",t2_hxicj,False,,0,False,Are there resources for Cracking the Machine Learning Interview?,[],r/deeplearning,False,6,,0,,False,t3_n2z9v6,False,dark,0.81,,public,10,0,{},,False,[],,False,False,,{},,False,10,,False,False,,False,,[],{},,True,,1619959494.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Recently I started preparing to get a job as a Data Scientist &amp;amp; I have been bashing my head for days to find preparatory resources.&lt;/p&gt;

&lt;p&gt;For getting a software developer job there are resources like &lt;a href=""https://www.geeksforgeeks.org/""&gt;geeksforgeeks&lt;/a&gt;, &lt;a href=""https://leetcode.com/""&gt;leetcode&lt;/a&gt;, &lt;a href=""https://www.freecodecamp.org/""&gt;freecodecamp&lt;/a&gt;, &lt;a href=""https://www.crackingthecodinginterview.com/""&gt;cracking the coding interview&lt;/a&gt;, etc.&lt;/p&gt;

&lt;p&gt;Which website, course, book do people follow to prepare for a job interview as a Data Scientist, ML engineer, or Research Scientist?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2z9v6,True,,kkkosariya,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/n2z9v6/are_there_resources_for_cracking_the_machine/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n2z9v6/are_there_resources_for_cracking_the_machine/,66146,1619930694.0,0,,False,,,,,,,
,deeplearning,,t2_6i9p8ofx,False,,0,False,Customer Satisfaction Prediction Using Machine Learning,[],r/deeplearning,False,6,,0,,False,t3_n39vdu,False,dark,0.25,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1620001251.0,text,6,,,text,paritosh-07.medium.com,False,,,,,https://paritosh-07.medium.com/customer-satisfaction-prediction-using-machine-learning-66240e032962,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n39vdu,True,,mlpoint,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n39vdu/customer_satisfaction_prediction_using_machine/,all_ads,False,https://paritosh-07.medium.com/customer-satisfaction-prediction-using-machine-learning-66240e032962,66146,1619972451.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,Infinite Nature: Fly into an image and explore it like a bird!,[],r/deeplearning,False,6,,0,,False,t3_n2j2aw,False,dark,0.96,,public,54,2,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/NIOt1HLV_Mo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Infinite Nature: Fly into an image and explore it like a bird!', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/NIOt1HLV_Mo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/NIOt1HLV_Mo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/NIOt1HLV_Mo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n2j2aw', 'height': 200}",,False,54,,False,False,,False,,[],{'gid_1': 1},,False,,1619906975.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/NIOt1HLV_Mo,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2j2aw,True,,OnlyProggingForFun,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/n2j2aw/infinite_nature_fly_into_an_image_and_explore_it/,all_ads,False,https://youtu.be/NIOt1HLV_Mo,66146,1619878175.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Infinite Nature: Fly into an image and explore it like a bird!', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/NIOt1HLV_Mo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/NIOt1HLV_Mo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg'}}",False,,,,,,,
,deeplearning,"I want to train a regression model that takes a time series as input and tries to predict the future value. The variance of the data in the whole dataset is high, so I apply a normalization step for each training batch.  The normalized ground truth is the ratio between the value to be predicted and the last measured value. However, in this way I obtain a very low variance of the output, as the values are highly concentrated around 1. This results in my network always predicting values close to 1. Is there a better strategy I could use?",t2_sm74p,False,,0,False,Regression training with very low output variance,[],r/deeplearning,False,6,,0,,False,t3_n32hzz,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619974661.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to train a regression model that takes a time series as input and tries to predict the future value. The variance of the data in the whole dataset is high, so I apply a normalization step for each training batch.  The normalized ground truth is the ratio between the value to be predicted and the last measured value. However, in this way I obtain a very low variance of the output, as the values are highly concentrated around 1. This results in my network always predicting values close to 1. Is there a better strategy I could use?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n32hzz,True,,fralbalbero,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n32hzz/regression_training_with_very_low_output_variance/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n32hzz/regression_training_with_very_low_output_variance/,66146,1619945861.0,0,,False,,,,,,,
,deeplearning,,t2_3hfyn6ef,False,,0,False,CV and DL methods for soccer training process analysis: detecting technical mistakes and reporting key performance indicators,[],r/deeplearning,False,6,,0,,False,t3_n2gj6g,False,dark,0.95,,public,20,0,{},,False,[],"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/h4vcnub7vhw61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/h4vcnub7vhw61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/h4vcnub7vhw61/DASHPlaylist.mpd?a=1626450128%2COTc2ZGMxMjk1ZTUyODMyOTkwMjZkM2NjYmUyMjlkNWQ1ODJlYWRhM2ViZmE4ODE4ZjcwNzU1NGFlNzdlMmY4Yw%3D%3D&amp;v=1&amp;f=sd', 'duration': 159, 'hls_url': 'https://v.redd.it/h4vcnub7vhw61/HLSPlaylist.m3u8?a=1626450128%2CMzVmN2ZiYzNlMjIwNTAxNzUxMWE2ZGQ2ZDg3NDg5Y2EwZTE0Mjk2M2MwMzMxMDg5Y2ViNzcyNWNiMGFhNWUwNg%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,20,,False,False,,False,,[],{},,False,,1619897375.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/h4vcnub7vhw61,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2gj6g,True,,yurykotlyarov,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n2gj6g/cv_and_dl_methods_for_soccer_training_process/,all_ads,False,https://v.redd.it/h4vcnub7vhw61,66146,1619868575.0,0,"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/h4vcnub7vhw61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/h4vcnub7vhw61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/h4vcnub7vhw61/DASHPlaylist.mpd?a=1626450128%2COTc2ZGMxMjk1ZTUyODMyOTkwMjZkM2NjYmUyMjlkNWQ1ODJlYWRhM2ViZmE4ODE4ZjcwNzU1NGFlNzdlMmY4Yw%3D%3D&amp;v=1&amp;f=sd', 'duration': 159, 'hls_url': 'https://v.redd.it/h4vcnub7vhw61/HLSPlaylist.m3u8?a=1626450128%2CMzVmN2ZiYzNlMjIwNTAxNzUxMWE2ZGQ2ZDg3NDg5Y2EwZTE0Mjk2M2MwMzMxMDg5Y2ViNzcyNWNiMGFhNWUwNg%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,"&amp;#x200B;

https://preview.redd.it/u08fg1hs8kw61.jpg?width=1750&amp;format=pjpg&amp;auto=webp&amp;s=58ccd2f8e67afb7749647ac14142e4cf3d6e2b10

**Paper:** [**https://arxiv.org/abs/2104.07788**](https://arxiv.org/abs/2104.07788)

**Github:** [**https://github.com/benedekrozemberczki/pytorch\_geometric\_temporal**](https://github.com/benedekrozemberczki/pytorch_geometric_temporal)",t2_hnxk25d,False,,0,False,PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models,[],r/deeplearning,False,6,,0,,False,t3_n2pj86,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619926295.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/u08fg1hs8kw61.jpg?width=1750&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=58ccd2f8e67afb7749647ac14142e4cf3d6e2b10""&gt;https://preview.redd.it/u08fg1hs8kw61.jpg?width=1750&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=58ccd2f8e67afb7749647ac14142e4cf3d6e2b10&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Paper:&lt;/strong&gt; &lt;a href=""https://arxiv.org/abs/2104.07788""&gt;&lt;strong&gt;https://arxiv.org/abs/2104.07788&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Github:&lt;/strong&gt; &lt;a href=""https://github.com/benedekrozemberczki/pytorch_geometric_temporal""&gt;&lt;strong&gt;https://github.com/benedekrozemberczki/pytorch_geometric_temporal&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2pj86,True,,benitorosenberg,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n2pj86/pytorch_geometric_temporal_spatiotemporal_signal/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n2pj86/pytorch_geometric_temporal_spatiotemporal_signal/,66146,1619897495.0,0,,False,,,"{'u08fg1hs8kw61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 37, 'x': 108, 'u': 'https://preview.redd.it/u08fg1hs8kw61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4c468baa930c32745073d7720ccf0929e520a3f1'}, {'y': 74, 'x': 216, 'u': 'https://preview.redd.it/u08fg1hs8kw61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba0aac259254e40dfe243bfbd7b08fb0e9f22ffa'}, {'y': 109, 'x': 320, 'u': 'https://preview.redd.it/u08fg1hs8kw61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=70422d4f10d7ab399408ef83e4d7194b908920c0'}, {'y': 219, 'x': 640, 'u': 'https://preview.redd.it/u08fg1hs8kw61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8cdda0797efd428d309b06f4c10381904326c94d'}, {'y': 329, 'x': 960, 'u': 'https://preview.redd.it/u08fg1hs8kw61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=089264bdd6e209faafe614601ef29f5e64169b02'}, {'y': 370, 'x': 1080, 'u': 'https://preview.redd.it/u08fg1hs8kw61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4d272bc673e4791a5dfa21e19948dc2ed7d030e4'}], 's': {'y': 600, 'x': 1750, 'u': 'https://preview.redd.it/u08fg1hs8kw61.jpg?width=1750&amp;format=pjpg&amp;auto=webp&amp;s=58ccd2f8e67afb7749647ac14142e4cf3d6e2b10'}, 'id': 'u08fg1hs8kw61'}}",,,,
,deeplearning,"I know the general method of training the encoder and decoder first, and then adding a classifier to the encoder and training that.

But are there any other techniques for training autoencoders for classification?",t2_4xhrybaz,False,,0,False,Are there any different methods of using autoencoders for classification?,[],r/deeplearning,False,6,,0,,False,t3_n2d357,False,dark,0.87,,public,11,0,{},,False,[],,False,False,,{},,False,11,,False,False,,False,,[],{},,True,,1619880828.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I know the general method of training the encoder and decoder first, and then adding a classifier to the encoder and training that.&lt;/p&gt;

&lt;p&gt;But are there any other techniques for training autoencoders for classification?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2d357,True,,banenvy,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/n2d357/are_there_any_different_methods_of_using/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n2d357/are_there_any_different_methods_of_using/,66146,1619852028.0,0,,False,,,,,,,
,deeplearning,"Hello! I want to train a model for a data set of 100k images ,What would be most efficient way of loading and training in PyTorch? I thought I should save images first in hdf5 format but I might not be able to do that as its a very large data set.Any suggestions ?",t2_6xrd6ojt,False,,0,False,Most efficient way of loading a 100k data set in PyTorch?,[],r/deeplearning,False,6,,0,,False,t3_n2jy04,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619909793.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello! I want to train a model for a data set of 100k images ,What would be most efficient way of loading and training in PyTorch? I thought I should save images first in hdf5 format but I might not be able to do that as its a very large data set.Any suggestions ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2jy04,True,,Awesome-355,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/n2jy04/most_efficient_way_of_loading_a_100k_data_set_in/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n2jy04/most_efficient_way_of_loading_a_100k_data_set_in/,66146,1619880993.0,0,,False,,,,,,,
,deeplearning," Since I've never been able to produce even anything close to something that looks like legit latte art, I decided to teach an IA to make it for me.

Unfortunately, they sure don't taste as good as the real deal.

https://preview.redd.it/n5wh7ffgqjw61.jpg?width=3000&amp;format=pjpg&amp;auto=webp&amp;s=178e0fc4ce6ccc6db70a03e2b7d31b5427c9490e",t2_466t0bl8,False,,0,False,Generated Latte Art,[],r/deeplearning,False,6,,0,,False,t3_n2nc06,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619919989.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Since I&amp;#39;ve never been able to produce even anything close to something that looks like legit latte art, I decided to teach an IA to make it for me.&lt;/p&gt;

&lt;p&gt;Unfortunately, they sure don&amp;#39;t taste as good as the real deal.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/n5wh7ffgqjw61.jpg?width=3000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=178e0fc4ce6ccc6db70a03e2b7d31b5427c9490e""&gt;https://preview.redd.it/n5wh7ffgqjw61.jpg?width=3000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=178e0fc4ce6ccc6db70a03e2b7d31b5427c9490e&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2nc06,True,,christophebolduc,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n2nc06/generated_latte_art/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n2nc06/generated_latte_art/,66146,1619891189.0,0,,False,,,"{'n5wh7ffgqjw61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 216, 'x': 108, 'u': 'https://preview.redd.it/n5wh7ffgqjw61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=09ef0d4430099ff6c0d84484e7cc763e515036b1'}, {'y': 432, 'x': 216, 'u': 'https://preview.redd.it/n5wh7ffgqjw61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c8c4cb4bf11b09cbab643d0ddaacd920c120faa'}, {'y': 640, 'x': 320, 'u': 'https://preview.redd.it/n5wh7ffgqjw61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=48edc63631c6a13021b45482c804c12ceeeeb5b6'}, {'y': 1280, 'x': 640, 'u': 'https://preview.redd.it/n5wh7ffgqjw61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9295e19390d1f0fe4f1c02c55a76943d74ec6be9'}, {'y': 1920, 'x': 960, 'u': 'https://preview.redd.it/n5wh7ffgqjw61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=3f235eb596c1f7e42938e70e5bd4266166302a9b'}, {'y': 2160, 'x': 1080, 'u': 'https://preview.redd.it/n5wh7ffgqjw61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5d2c53c417852291238ace36188c097c5f297a86'}], 's': {'y': 9000, 'x': 3000, 'u': 'https://preview.redd.it/n5wh7ffgqjw61.jpg?width=3000&amp;format=pjpg&amp;auto=webp&amp;s=178e0fc4ce6ccc6db70a03e2b7d31b5427c9490e'}, 'id': 'n5wh7ffgqjw61'}}",,,,
,deeplearning,"Hello folks,

I'm building a simple feedforward network for regression, the input data are multiple body dimension (discrete meaurements) and the target are a set of values that represent acoustical properties (this properties are known to be influenced from those body measurements).  


The problem: So far I didn't find any literature regarding this especific problem that implemented data augmentation. My plan is to use a range for each of these body parts as a data augmentation, but I'm not sure if it actually makes sense. 

I'll try to ilustrate my idea with an example: One of the measurements is the head width, so I'd estimate the associated error in measuring that feature (ie 1cm), after that I'd create 2 new samples for each data point, being the measured value +/- the associated error to the measurement. Does that makes any sense, do you have better ideas?",t2_xygmh,False,,0,False,"Data augmentation techniques for non-image, non-time series data?",[],r/deeplearning,False,6,,0,,False,t3_n2mz4y,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619918884.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello folks,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m building a simple feedforward network for regression, the input data are multiple body dimension (discrete meaurements) and the target are a set of values that represent acoustical properties (this properties are known to be influenced from those body measurements).  &lt;/p&gt;

&lt;p&gt;The problem: So far I didn&amp;#39;t find any literature regarding this especific problem that implemented data augmentation. My plan is to use a range for each of these body parts as a data augmentation, but I&amp;#39;m not sure if it actually makes sense. &lt;/p&gt;

&lt;p&gt;I&amp;#39;ll try to ilustrate my idea with an example: One of the measurements is the head width, so I&amp;#39;d estimate the associated error in measuring that feature (ie 1cm), after that I&amp;#39;d create 2 new samples for each data point, being the measured value +/- the associated error to the measurement. Does that makes any sense, do you have better ideas?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2mz4y,True,,repoflor,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n2mz4y/data_augmentation_techniques_for_nonimage_nontime/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n2mz4y/data_augmentation_techniques_for_nonimage_nontime/,66146,1619890084.0,0,,False,,,,,,,
,deeplearning,"

[View Poll](https://www.reddit.com/poll/n2hzw2)",t2_4hc3q18m,False,,0,False,"Do you use PyTorch, if yes do you use any of these high level libraries for faster experimentation?",[],r/deeplearning,False,6,,0,,False,t3_n2hzw2,False,dark,0.63,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619903246.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.reddit.com/poll/n2hzw2""&gt;View Poll&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2hzw2,True,,frankhart98,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n2hzw2/do_you_use_pytorch_if_yes_do_you_use_any_of_these/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n2hzw2/do_you_use_pytorch_if_yes_do_you_use_any_of_these/,66146,1619874446.0,0,,False,,,,,"{'user_won_amount': None, 'tournament_id': None, 'voting_end_timestamp': 1620479246662, 'options': [{'text': 'PyTorch Lightning', 'vote_count': 20, 'id': '7659801'}, {'text': 'PyTorch Ignite', 'vote_count': 3, 'id': '7659802'}, {'text': 'None', 'vote_count': 54, 'id': '7659803'}], 'user_selection': None, 'is_prediction': False, 'resolved_option_id': None, 'total_vote_count': 77, 'total_stake_amount': None}",,
,deeplearning,,t2_1bnhotlu,False,,0,False,Stacks for Deep Learning Resources,[],r/deeplearning,False,6,,0,,False,t3_n2ge6x,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1619896811.0,text,6,,,text,reddit.com,False,,,,,https://www.reddit.com/gallery/n2gd1b,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2ge6x,True,,skj8,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n2ge6x/stacks_for_deep_learning_resources/,all_ads,False,https://www.reddit.com/gallery/n2gd1b,66146,1619868011.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'u_kangerDev', 'selftext': '', 'author_fullname': 't2_a8m186fw', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'is_gallery': True, 'title': 'Stacks for Deep Learning Resources', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/kangerDev', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'ydzuk781thw61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 130, 'x': 108, 'u': 'https://preview.redd.it/ydzuk781thw61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=91dbb4c40abed16117d4b3505d8705324a81ea1c'}, {'y': 261, 'x': 216, 'u': 'https://preview.redd.it/ydzuk781thw61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bcc3c37a3088a29b8ff3390a873ca5ca102a65f1'}, {'y': 386, 'x': 320, 'u': 'https://preview.redd.it/ydzuk781thw61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9470ebd6070833ca1c416ca872955b478a7f90fc'}, {'y': 773, 'x': 640, 'u': 'https://preview.redd.it/ydzuk781thw61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ad5d63c95cbf1776fc4204caeba2c886fcf0bac1'}], 's': {'y': 933, 'x': 772, 'u': 'https://preview.redd.it/ydzuk781thw61.png?width=772&amp;format=png&amp;auto=webp&amp;s=0f4dc0e76ecce879544d68bd3986e900b81faa13'}, 'id': 'ydzuk781thw61'}, 'cwycrjr0thw61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 134, 'x': 108, 'u': 'https://preview.redd.it/cwycrjr0thw61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a46f2af3758b094da0edab805685412bfc766374'}, {'y': 268, 'x': 216, 'u': 'https://preview.redd.it/cwycrjr0thw61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=373ba00e485e9513e1d7580c990cbc4c54dc0717'}, {'y': 398, 'x': 320, 'u': 'https://preview.redd.it/cwycrjr0thw61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b90024d07e72f9d8564e134bf89a2b5dcd6acf2a'}, {'y': 796, 'x': 640, 'u': 'https://preview.redd.it/cwycrjr0thw61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aa8c45569f071f7320eaba51a6d0ff7cbb686f41'}], 's': {'y': 945, 'x': 759, 'u': 'https://preview.redd.it/cwycrjr0thw61.png?width=759&amp;format=png&amp;auto=webp&amp;s=4ca16373dd2d736c1badecbf682ad2308fdfb689'}, 'id': 'cwycrjr0thw61'}, '6v9qvlr0thw61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 133, 'x': 108, 'u': 'https://preview.redd.it/6v9qvlr0thw61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=da2713e1573673febf2fde38c6d46fbf0dc0e381'}, {'y': 267, 'x': 216, 'u': 'https://preview.redd.it/6v9qvlr0thw61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=44401fa90e72afae325a59b962b975ec89b5ff42'}, {'y': 396, 'x': 320, 'u': 'https://preview.redd.it/6v9qvlr0thw61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6f38dfb02859d0c6581236cfac0d22d0b371b3cb'}, {'y': 792, 'x': 640, 'u': 'https://preview.redd.it/6v9qvlr0thw61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7024db80f07b5adfba044cf5a26cad063933b865'}], 's': {'y': 935, 'x': 755, 'u': 'https://preview.redd.it/6v9qvlr0thw61.png?width=755&amp;format=png&amp;auto=webp&amp;s=a6a4c9261bc45674d6575257a1b840c34d1d46a3'}, 'id': '6v9qvlr0thw61'}, '0flqrgtyshw61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 119, 'x': 108, 'u': 'https://preview.redd.it/0flqrgtyshw61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=299680d08522343152065b504cded31c51945584'}, {'y': 238, 'x': 216, 'u': 'https://preview.redd.it/0flqrgtyshw61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ba83e74222365f49959b2f36653c22784bda9ce4'}, {'y': 353, 'x': 320, 'u': 'https://preview.redd.it/0flqrgtyshw61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=32b0777b26cb2188a41f625b65a0f9d4b278d4fa'}], 's': {'y': 610, 'x': 552, 'u': 'https://preview.redd.it/0flqrgtyshw61.png?width=552&amp;format=png&amp;auto=webp&amp;s=3716bb29262722ec6820fae85dc1b9f1d0cb7768'}, 'id': '0flqrgtyshw61'}}, 'name': 't3_n2gd1b', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'gallery_data': {'items': [{'caption': 'Deep Learning ', 'outbound_url': 'https://kanger.dev/stacks/deep-learning/', 'media_id': '0flqrgtyshw61', 'id': 42013386}, {'caption': 'Coursera Deep Learning Courses', 'outbound_url': 'https://kanger.dev/stack/coursera-deep-learning-courses/', 'media_id': '6v9qvlr0thw61', 'id': 42013387}, {'caption': 'DataCamp Deep Learning Courses', 'outbound_url': 'https://kanger.dev/stack/datacamp-deep-learning-courses/', 'media_id': 'cwycrjr0thw61', 'id': 42013388}, {'media_id': 'ydzuk781thw61', 'id': 42013389}]}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1619896675.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'reddit.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.reddit.com/gallery/n2gd1b', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3xavx7', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'n2gd1b', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'kangerDev', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_kangerDev/comments/n2gd1b/stacks_for_deep_learning_resources/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://www.reddit.com/gallery/n2gd1b', 'subreddit_subscribers': 0, 'created_utc': 1619867875.0, 'num_crossposts': 4, 'media': None, 'is_video': False}]",t3_n2gd1b,,,,,
,deeplearning,"A research team from NYU and Facebook proposes MDETR, an end-to-end modulated detector that identifies objects in images conditioned on a raw text query and is able to capture a long tail of visual concepts expressed in free-form text.

Here is a quick read: [Yann LeCun Team's Novel End-to-End Modulated Detector Captures Visual Concepts in Free-Form Text.](https://syncedreview.com/2021/04/30/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-9/)

 The paper *MDETR – Modulated Detection for End-to-End Multi-Modal Understanding* is on [arXiv](https://arxiv.org/pdf/2104.12763.pdf).",t2_2fv4yodo,False,,0,False,[R] Yann LeCun Team's Novel End-to-End Modulated Detector Captures Visual Concepts in Free-Form Text,[],r/deeplearning,False,6,,0,,False,t3_n1vatz,False,dark,0.94,,public,45,0,{},,False,[],,False,False,,{},,False,45,,False,False,,False,,[],{},,True,,1619822529.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from NYU and Facebook proposes MDETR, an end-to-end modulated detector that identifies objects in images conditioned on a raw text query and is able to capture a long tail of visual concepts expressed in free-form text.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/30/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-9/""&gt;Yann LeCun Team&amp;#39;s Novel End-to-End Modulated Detector Captures Visual Concepts in Free-Form Text.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;MDETR – Modulated Detection for End-to-End Multi-Modal Understanding&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.12763.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n1vatz,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n1vatz/r_yann_lecun_teams_novel_endtoend_modulated/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n1vatz/r_yann_lecun_teams_novel_endtoend_modulated/,66146,1619793729.0,0,,False,,,,,,,
,deeplearning,I want to learn the working of CNN algorithm for fake news detection. Please let me know how to learn it in detail.,t2_a6fb7599,False,,0,False,CNN Algorithm,[],r/deeplearning,False,6,,0,,False,t3_n2g45q,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619895615.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to learn the working of CNN algorithm for fake news detection. Please let me know how to learn it in detail.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2g45q,True,,erupasna401,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/n2g45q/cnn_algorithm/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n2g45q/cnn_algorithm/,66146,1619866815.0,0,,False,,,,,,,
,deeplearning,"[Deepl](https://www.deepl.com/translator) is by far my favorite translator on the internet. I use it almost daily since it allows to reformulate the translated sentences when you choose a term instead of the other.

Does anyone know how they achieve this feature? How would you name a feature like that? My guess was sentence reformulation or word suggestion.

Any tips on literature or open source projects would be greatly appreciated!",t2_abxnlmni,False,,0,False,How does Deepl achieve to reformulate sentences when changing a word?,[],r/deeplearning,False,6,,0,,False,t3_n2ero6,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619889129.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.deepl.com/translator""&gt;Deepl&lt;/a&gt; is by far my favorite translator on the internet. I use it almost daily since it allows to reformulate the translated sentences when you choose a term instead of the other.&lt;/p&gt;

&lt;p&gt;Does anyone know how they achieve this feature? How would you name a feature like that? My guess was sentence reformulation or word suggestion.&lt;/p&gt;

&lt;p&gt;Any tips on literature or open source projects would be greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2ero6,True,,drinnova,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n2ero6/how_does_deepl_achieve_to_reformulate_sentences/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n2ero6/how_does_deepl_achieve_to_reformulate_sentences/,66146,1619860329.0,0,,False,,,,,,,
,deeplearning,"On viewing the gradients of the prediction w.r.t the input, we see that some gradients are negative.

So do we just say that these inputs are inversely correlated to the final prediction?

I understand derivatives and slopes, and their significance, so idm anyone explaining it in detail with math. (Please do).

Edit: I am asking about the interpretation of negative gradients seen in saliency maps, where we take the derivative of the output w.r.t the input.

Edit 2: saliency maps: https://towardsdatascience.com/saliency-map-using-pytorch-68270fe45e80",t2_4xhrybaz,False,,0,False,How to interpret negative gradients?,[],r/deeplearning,False,6,,0,,False,t3_n2eqrp,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1619924762.0,,[],{},,True,,1619889003.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;On viewing the gradients of the prediction w.r.t the input, we see that some gradients are negative.&lt;/p&gt;

&lt;p&gt;So do we just say that these inputs are inversely correlated to the final prediction?&lt;/p&gt;

&lt;p&gt;I understand derivatives and slopes, and their significance, so idm anyone explaining it in detail with math. (Please do).&lt;/p&gt;

&lt;p&gt;Edit: I am asking about the interpretation of negative gradients seen in saliency maps, where we take the derivative of the output w.r.t the input.&lt;/p&gt;

&lt;p&gt;Edit 2: saliency maps: &lt;a href=""https://towardsdatascience.com/saliency-map-using-pytorch-68270fe45e80""&gt;https://towardsdatascience.com/saliency-map-using-pytorch-68270fe45e80&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n2eqrp,True,,banenvy,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/n2eqrp/how_to_interpret_negative_gradients/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n2eqrp/how_to_interpret_negative_gradients/,66146,1619860203.0,0,,False,,,,,,,
,deeplearning,"I am doing some work on face verification systems. I am trying to understand the concept of deep metric learning. I have come accross some losses like contrastive loss, triplet loss, angular softmax, etc. I am confused with how to use them.

I am currently using contrastive loss and triplet loss but I am not getting good results. How to prepare a proper dataset for training a network with these losses? I am required to have only two images per person in training set. 

If I am supposed to use Siamese networks, then how can I use losses like angulr softmax or softmax loss? Can anyone explain this to me? I am unable to understand this. 

For losses like Angular softmax or softmax loss, shall I be taking Image pairs like we do incase of contrastive loss ? If not then how do I implement this?

Please help, I am unable to understand this.",t2_7kuswl6f,False,,0,False,Doubts regarding deep metric learning.,[],r/deeplearning,False,6,,0,,False,t3_n244sx,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619847656.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am doing some work on face verification systems. I am trying to understand the concept of deep metric learning. I have come accross some losses like contrastive loss, triplet loss, angular softmax, etc. I am confused with how to use them.&lt;/p&gt;

&lt;p&gt;I am currently using contrastive loss and triplet loss but I am not getting good results. How to prepare a proper dataset for training a network with these losses? I am required to have only two images per person in training set. &lt;/p&gt;

&lt;p&gt;If I am supposed to use Siamese networks, then how can I use losses like angulr softmax or softmax loss? Can anyone explain this to me? I am unable to understand this. &lt;/p&gt;

&lt;p&gt;For losses like Angular softmax or softmax loss, shall I be taking Image pairs like we do incase of contrastive loss ? If not then how do I implement this?&lt;/p&gt;

&lt;p&gt;Please help, I am unable to understand this.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n244sx,True,,Abhrant_,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n244sx/doubts_regarding_deep_metric_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n244sx/doubts_regarding_deep_metric_learning/,66146,1619818856.0,0,,False,,,,,,,
,deeplearning,,t2_7pioyszg,False,,0,False,Flow Forecast TS version 0.956 released,[],r/deeplearning,False,6,,0,,False,t3_n22ziw,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1619844253.0,text,6,,,text,flow-forecast.atlassian.net,False,,,,,https://flow-forecast.atlassian.net/wiki/spaces/FF/pages/784826376/Flow+Forecast+Release+0.956,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n22ziw,True,,me341,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n22ziw/flow_forecast_ts_version_0956_released/,all_ads,False,https://flow-forecast.atlassian.net/wiki/spaces/FF/pages/784826376/Flow+Forecast+Release+0.956,66146,1619815453.0,0,,False,,,,,,,
,deeplearning,"I am trying to replicate the training of a Single Shot Detector (SSD) model, as in the original paper. A keras implementation has been provided in Tensorflow 1.x, which I have tried to convert to Tensorflow 2.x. This issue most likely is because of this said conversion, but I can't figure out why.

Notebook (to have context about error): [Colab Notebook](https://colab.research.google.com/drive/1VJ20NivditDQIHXULqn1GoYg3QfO0Tzs#scrollTo=ozAvLTKsvUTy) You will find this error towards the end of the notebook, where we are trying to fit the model.

Tensorflow V1 Keras code (original repo): [Github Repo](https://github.com/pierluigiferrari/ssd_keras)

Possible reasons for issue: [This Stackoverflow Thread](https://stackoverflow.com/questions/61586981/valueerror-layer-sequential-20-expects-1-inputs-but-it-received-2-input-tensor#) talks about a mismatch in structures accepted. While in tensorflow V1, a list was expected, in V2, a tuple is expected. Problem is, my code does not use a tuple of validation data for model.fit(), it uses a generator.",t2_8dndq1r4,False,,0,False,"ValueError: Layer model expects 1 input(s), but it received 2 input tensors. Help?",[],r/deeplearning,False,6,,0,,False,t3_n1p5q8,False,dark,0.72,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1619798473.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to replicate the training of a Single Shot Detector (SSD) model, as in the original paper. A keras implementation has been provided in Tensorflow 1.x, which I have tried to convert to Tensorflow 2.x. This issue most likely is because of this said conversion, but I can&amp;#39;t figure out why.&lt;/p&gt;

&lt;p&gt;Notebook (to have context about error): &lt;a href=""https://colab.research.google.com/drive/1VJ20NivditDQIHXULqn1GoYg3QfO0Tzs#scrollTo=ozAvLTKsvUTy""&gt;Colab Notebook&lt;/a&gt; You will find this error towards the end of the notebook, where we are trying to fit the model.&lt;/p&gt;

&lt;p&gt;Tensorflow V1 Keras code (original repo): &lt;a href=""https://github.com/pierluigiferrari/ssd_keras""&gt;Github Repo&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Possible reasons for issue: &lt;a href=""https://stackoverflow.com/questions/61586981/valueerror-layer-sequential-20-expects-1-inputs-but-it-received-2-input-tensor#""&gt;This Stackoverflow Thread&lt;/a&gt; talks about a mismatch in structures accepted. While in tensorflow V1, a list was expected, in V2, a tuple is expected. Problem is, my code does not use a tuple of validation data for model.fit(), it uses a generator.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n1p5q8,True,,redditnoob48,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n1p5q8/valueerror_layer_model_expects_1_inputs_but_it/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n1p5q8/valueerror_layer_model_expects_1_inputs_but_it/,66146,1619769673.0,0,,False,,,,,,,
,deeplearning,,t2_9xwzo9vx,False,,0,False,How AI Can Modify Images Without Photoshop (StyleCLIP Explained),[],r/deeplearning,False,6,,0,,False,t3_n1tx0i,False,dark,0.43,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/zm2Kym8YH3U?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How AI Can Modify Images Without Photoshop (StyleCLIP Explained)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/zm2Kym8YH3U?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Stochastic Machine', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/zm2Kym8YH3U/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCWAQ2jS_jftqV65hLtxPfLA'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/zm2Kym8YH3U?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n1tx0i', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1619818333.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/zm2Kym8YH3U,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n1tx0i,True,,Stochastic_Machine,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n1tx0i/how_ai_can_modify_images_without_photoshop/,all_ads,False,https://youtu.be/zm2Kym8YH3U,66146,1619789533.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How AI Can Modify Images Without Photoshop (StyleCLIP Explained)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/zm2Kym8YH3U?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Stochastic Machine', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/zm2Kym8YH3U/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCWAQ2jS_jftqV65hLtxPfLA'}}",False,,,,,,,
,deeplearning,,t2_8dh42jtc,False,,0,False,Neural style transfer changes style to the beat,[],r/deeplearning,False,6,,0,,False,t3_n1t8w8,False,dark,0.57,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/TYGsgMLsVu0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Lonely Cafe | Jazzy and Chill Lofi Hip Hop Mix | AI generated art', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/TYGsgMLsVu0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Deep Style Beats', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/TYGsgMLsVu0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCgDEhsKghkAsRklgopG4JxA'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/TYGsgMLsVu0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n1t8w8', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1619816155.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/TYGsgMLsVu0,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n1t8w8,True,,deep_style_beats,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n1t8w8/neural_style_transfer_changes_style_to_the_beat/,all_ads,False,https://youtu.be/TYGsgMLsVu0,66146,1619787355.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Lonely Cafe | Jazzy and Chill Lofi Hip Hop Mix | AI generated art', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/TYGsgMLsVu0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Deep Style Beats', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/TYGsgMLsVu0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCgDEhsKghkAsRklgopG4JxA'}}",False,,,,,,,
,deeplearning,"Hİ everybody,

Got a project for my deep learning class, I will try to build a neural net that summarizes news articles down to several options. I was amazed by autotldrbot so I decided on this [project.](https://project.It) It will shorten the article down to 1 sentence, 2 sentences, 3 sentences, 25% shortened and finally 50% shortened versions.

My priority is 1 sentence and 25% shortened ones however I plan to pick them by ranking the sentences, so I don't think there will be a problem if I successfully shorten it to one sentence. However, I got a problem here. To train this kind of network, do I need to prepare my own data? I haven't worked on text analytics before so I am a bit scared at this point. Is there any pre-prepared for this use case? I searched for it but I was unable to find anything (maybe I'm not using right keywords, who knows).

&amp;#x200B;

Any help is appreciated deeply, thanks for reading

&amp;#x200B;

edit: I have an idea about using tifu posts with tldr but I don't know if it would be great for this case",t2_6o57z4ff,False,,0,False,Data for news summarization network,[],r/deeplearning,False,6,,0,,False,t3_n1q9ss,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1619776512.0,,[],{},,True,,1619803771.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hİ everybody,&lt;/p&gt;

&lt;p&gt;Got a project for my deep learning class, I will try to build a neural net that summarizes news articles down to several options. I was amazed by autotldrbot so I decided on this &lt;a href=""https://project.It""&gt;project.&lt;/a&gt; It will shorten the article down to 1 sentence, 2 sentences, 3 sentences, 25% shortened and finally 50% shortened versions.&lt;/p&gt;

&lt;p&gt;My priority is 1 sentence and 25% shortened ones however I plan to pick them by ranking the sentences, so I don&amp;#39;t think there will be a problem if I successfully shorten it to one sentence. However, I got a problem here. To train this kind of network, do I need to prepare my own data? I haven&amp;#39;t worked on text analytics before so I am a bit scared at this point. Is there any pre-prepared for this use case? I searched for it but I was unable to find anything (maybe I&amp;#39;m not using right keywords, who knows).&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Any help is appreciated deeply, thanks for reading&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;edit: I have an idea about using tifu posts with tldr but I don&amp;#39;t know if it would be great for this case&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n1q9ss,True,,Skilinger,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n1q9ss/data_for_news_summarization_network/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n1q9ss/data_for_news_summarization_network/,66146,1619774971.0,0,,False,,,,,,,
,deeplearning,"IBM and ETH Zurich researchers make progress in reconciling neurophysiological insights with machine intelligence, proposing a novel biologically inspired optimizer for artificial (ANNs) and spiking neural networks (SNNs) that incorporates synaptic integration principles from biology. GRAPES (Group Responsibility for Adjusting the Propagation of Error Signals) leads to improvements in the training time convergence, accuracy and scalability of ANNs and SNNs. 

Here is a quick read: [Toward a New Generation of Neuromorphic Computing: IBM &amp; ETH Zurich's Biologically Inspired Optimizer Boosts FCNN and SNN Training.](https://syncedreview.com/2021/04/29/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-8/)

 The paper *Learning in Deep Neural Networks Using a Biologically Inspired Optimizer* is on [arXiv](https://arxiv.org/pdf/2104.11604.pdf).",t2_2fv4yodo,False,,0,False,[R] Toward a New Generation of Neuromorphic Computing: IBM &amp; ETH Zurich's Biologically Inspired Optimizer Boosts FCNN and SNN Training,[],r/deeplearning,False,6,,0,,False,t3_n17gpv,False,dark,0.93,,public,27,1,{},,False,[],,False,False,,{},,False,27,,False,False,,False,,[],{'gid_1': 1},,True,,1619740612.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;IBM and ETH Zurich researchers make progress in reconciling neurophysiological insights with machine intelligence, proposing a novel biologically inspired optimizer for artificial (ANNs) and spiking neural networks (SNNs) that incorporates synaptic integration principles from biology. GRAPES (Group Responsibility for Adjusting the Propagation of Error Signals) leads to improvements in the training time convergence, accuracy and scalability of ANNs and SNNs. &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/29/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-8/""&gt;Toward a New Generation of Neuromorphic Computing: IBM &amp;amp; ETH Zurich&amp;#39;s Biologically Inspired Optimizer Boosts FCNN and SNN Training.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Learning in Deep Neural Networks Using a Biologically Inspired Optimizer&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.11604.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n17gpv,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n17gpv/r_toward_a_new_generation_of_neuromorphic/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n17gpv/r_toward_a_new_generation_of_neuromorphic/,66146,1619711812.0,0,,False,,,,,,,
,deeplearning,"I am going through this kaggle article: https://www.kaggle.com/anantgupt/real-vs-fake-faces , in this article training model saved in spoffnet.h5 file, when i want to detect faces its giving wrong prediction, expert please help, it takes my lot of time and effort to upload datasets on my google drive. And after all of doing this i m still unable to detect desired results. Experts can you please look the training part.

Dataset: https://www.kaggle.com/xhlulu/140k-real-and-fake-faces",t2_7rmi111c,False,,0,False,Real Vs Fake Face Detection,[],r/deeplearning,False,6,,0,,False,t3_n1py17,False,dark,0.43,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619802208.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am going through this kaggle article: &lt;a href=""https://www.kaggle.com/anantgupt/real-vs-fake-faces""&gt;https://www.kaggle.com/anantgupt/real-vs-fake-faces&lt;/a&gt; , in this article training model saved in spoffnet.h5 file, when i want to detect faces its giving wrong prediction, expert please help, it takes my lot of time and effort to upload datasets on my google drive. And after all of doing this i m still unable to detect desired results. Experts can you please look the training part.&lt;/p&gt;

&lt;p&gt;Dataset: &lt;a href=""https://www.kaggle.com/xhlulu/140k-real-and-fake-faces""&gt;https://www.kaggle.com/xhlulu/140k-real-and-fake-faces&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n1py17,True,,ali-nawaz14,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n1py17/real_vs_fake_face_detection/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n1py17/real_vs_fake_face_detection/,66146,1619773408.0,0,,False,,,,,,,
,deeplearning,"# [EigenGAN Layer-Wise Eigen-Learning for GANs](https://t.me/casual_gan/31)

The authors propose a novel generator architecture that can intrinsically learn interpretable directions in the latent space in an unsupervised manner. Moreover each direction can be controlled in a straightforward way with a strength coefficient to directly influence the attributes such as gender, smile, pose, etc on the generated images.

[ Samples and architecture overview ](https://preview.redd.it/ck2z9r4i54w61.png?width=1280&amp;format=png&amp;auto=webp&amp;s=622109b2e13062cfe7b750b6418ab18309283858)

&amp;#x200B;

[ Direction traversal examples ](https://reddit.com/link/n1480t/video/uqf0j20k54w61/player)

Check out:

\[[5 minute paper explanation](https://t.me/casual_gan/31)\] \[[Arxiv](https://arxiv.org/pdf/2104.12476.pdf)\]",t2_hhio3,False,,0,False,"[D] Main ideas from ""EigenGAN Layer-Wise Eigen-Learning for GANs"" explained!",[],r/deeplearning,False,6,,0,,False,t3_n1480t,False,dark,0.78,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1619731311.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h1&gt;&lt;a href=""https://t.me/casual_gan/31""&gt;EigenGAN Layer-Wise Eigen-Learning for GANs&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;The authors propose a novel generator architecture that can intrinsically learn interpretable directions in the latent space in an unsupervised manner. Moreover each direction can be controlled in a straightforward way with a strength coefficient to directly influence the attributes such as gender, smile, pose, etc on the generated images.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ck2z9r4i54w61.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=622109b2e13062cfe7b750b6418ab18309283858""&gt; Samples and architecture overview &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://reddit.com/link/n1480t/video/uqf0j20k54w61/player""&gt; Direction traversal examples &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Check out:&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/31""&gt;5 minute paper explanation&lt;/a&gt;] [&lt;a href=""https://arxiv.org/pdf/2104.12476.pdf""&gt;Arxiv&lt;/a&gt;]&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n1480t,True,,KirillTheMunchKing,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/n1480t/d_main_ideas_from_eigengan_layerwise/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n1480t/d_main_ideas_from_eigengan_layerwise/,66146,1619702511.0,0,,False,,,"{'ck2z9r4i54w61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 51, 'x': 108, 'u': 'https://preview.redd.it/ck2z9r4i54w61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2ab07a2bde1005731b7f94ecfc7a05a2b307e86e'}, {'y': 103, 'x': 216, 'u': 'https://preview.redd.it/ck2z9r4i54w61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f2887230cd0914c7e00884ed61c385dff839351f'}, {'y': 153, 'x': 320, 'u': 'https://preview.redd.it/ck2z9r4i54w61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cffc62c836418c5b12089584beb3a69b705757f0'}, {'y': 307, 'x': 640, 'u': 'https://preview.redd.it/ck2z9r4i54w61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=59cc190d13e506622db84ba77001ed7e70a2ad67'}, {'y': 460, 'x': 960, 'u': 'https://preview.redd.it/ck2z9r4i54w61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7833e18511e2cd9ec720820e480cfc3a92a42205'}, {'y': 518, 'x': 1080, 'u': 'https://preview.redd.it/ck2z9r4i54w61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=794ae45bb68cebc3e58d698a2fe9d08284c84b5d'}], 's': {'y': 614, 'x': 1280, 'u': 'https://preview.redd.it/ck2z9r4i54w61.png?width=1280&amp;format=png&amp;auto=webp&amp;s=622109b2e13062cfe7b750b6418ab18309283858'}, 'id': 'ck2z9r4i54w61'}, 'uqf0j20k54w61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/n1480t/asset/uqf0j20k54w61/DASHPlaylist.mpd?a=1626450157%2CNGY2NTJlODllZDJjYmQ5NDMyYjFlOGQzMWY2OGRkMzhmOWIwMzRiZjBjMjVhMzVhMmIyYjM1MzBlMTFlM2UxZg%3D%3D&amp;v=1&amp;f=sd', 'x': 240, 'y': 240, 'hlsUrl': 'https://v.redd.it/link/n1480t/asset/uqf0j20k54w61/HLSPlaylist.m3u8?a=1626450157%2CMGZlMGVlMjcxMTYzNTlhM2NlOTIxYzVkYzQ5ZWZjY2ZlMzAyODU4ZGMxMmQ0ZjZmN2U2ZTUyZDUyMTg3YzVmYg%3D%3D&amp;v=1&amp;f=sd', 'id': 'uqf0j20k54w61', 'isGif': False}}",,,,
,deeplearning," 

https://preview.redd.it/rmxs5km7r6w61.jpg?width=930&amp;format=pjpg&amp;auto=webp&amp;s=fd5f36d2fdaa5a122057f0800a229e2b5b374e85

Directed Mask R-CNN searches for the objects in some pre-defined locations. This saves the model's time from looking for objects in the entire image.",t2_a8i2hluj,False,,0,False,Object Detection Using Directed Mask R-CNN With Keras,[],r/deeplearning,False,6,,0,,False,t3_n1fj52,False,dark,0.43,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619762788.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://preview.redd.it/rmxs5km7r6w61.jpg?width=930&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=fd5f36d2fdaa5a122057f0800a229e2b5b374e85""&gt;https://preview.redd.it/rmxs5km7r6w61.jpg?width=930&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=fd5f36d2fdaa5a122057f0800a229e2b5b374e85&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Directed Mask R-CNN searches for the objects in some pre-defined locations. This saves the model&amp;#39;s time from looking for objects in the entire image.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n1fj52,True,,ahmed26gad,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n1fj52/object_detection_using_directed_mask_rcnn_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n1fj52/object_detection_using_directed_mask_rcnn_with/,66146,1619733988.0,0,,False,,,"{'rmxs5km7r6w61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 53, 'x': 108, 'u': 'https://preview.redd.it/rmxs5km7r6w61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f8c6ca86cbb9e12cfe4ab72ed63c9c411b7945f6'}, {'y': 106, 'x': 216, 'u': 'https://preview.redd.it/rmxs5km7r6w61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0929fc029b1f08c6c51a6bd4f34e4e1143061774'}, {'y': 157, 'x': 320, 'u': 'https://preview.redd.it/rmxs5km7r6w61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ac5606163f473f8c3f79085132e7f7b2c629b115'}, {'y': 315, 'x': 640, 'u': 'https://preview.redd.it/rmxs5km7r6w61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f22f709715a3d1c5123dbc372b47732e85ef1d2'}], 's': {'y': 459, 'x': 930, 'u': 'https://preview.redd.it/rmxs5km7r6w61.jpg?width=930&amp;format=pjpg&amp;auto=webp&amp;s=fd5f36d2fdaa5a122057f0800a229e2b5b374e85'}, 'id': 'rmxs5km7r6w61'}}",,,,
,deeplearning,"I have some data, labelled in the style of instance segmentation intended for MaskRCNN. 

However, I may not be able to succeed with my small dataset in this domain. Are there any networks that can perform classification given the kind of data I have available?

Any ideas guys?",t2_12hur2,False,,0,False,Any networks that perform classification given data that was originally intended for MaskRCNN (instance segmentation),[],r/deeplearning,False,6,,0,,False,t3_n1djn2,False,dark,0.43,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619757233.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have some data, labelled in the style of instance segmentation intended for MaskRCNN. &lt;/p&gt;

&lt;p&gt;However, I may not be able to succeed with my small dataset in this domain. Are there any networks that can perform classification given the kind of data I have available?&lt;/p&gt;

&lt;p&gt;Any ideas guys?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n1djn2,True,,ShadowStormDrift,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n1djn2/any_networks_that_perform_classification_given/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n1djn2/any_networks_that_perform_classification_given/,66146,1619728433.0,0,,False,,,,,,,
,deeplearning,"Hi all, I'm doing a research deep learning project and i have a CNN to train with a quite big dataset of images.

My GTX 1060 can do this but it's a bit slow, so i'm looking for a cloud GPU provider that let me use a powerful GPU without the need to open a request to the provider (with AWS, Google Cloud, etc. you need to open a ticket to request a GPU and explain why you need that and for what you'll use it, and this procedure can take days).

Obviously i don't need an 8 GPU monster server, a good RTX Quadro or a 3080/3090 would be more than sufficient.

Thank you in advance",t2_maq919,False,,0,False,"Cloud GPU on-demand without request, ready to use",[],r/deeplearning,False,6,,0,,False,t3_n1bymk,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619752905.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I&amp;#39;m doing a research deep learning project and i have a CNN to train with a quite big dataset of images.&lt;/p&gt;

&lt;p&gt;My GTX 1060 can do this but it&amp;#39;s a bit slow, so i&amp;#39;m looking for a cloud GPU provider that let me use a powerful GPU without the need to open a request to the provider (with AWS, Google Cloud, etc. you need to open a ticket to request a GPU and explain why you need that and for what you&amp;#39;ll use it, and this procedure can take days).&lt;/p&gt;

&lt;p&gt;Obviously i don&amp;#39;t need an 8 GPU monster server, a good RTX Quadro or a 3080/3090 would be more than sufficient.&lt;/p&gt;

&lt;p&gt;Thank you in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n1bymk,True,,PierGiampiero,,17,True,all_ads,False,[],False,,/r/deeplearning/comments/n1bymk/cloud_gpu_ondemand_without_request_ready_to_use/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n1bymk/cloud_gpu_ondemand_without_request_ready_to_use/,66146,1619724105.0,0,,False,,,,,,,
,deeplearning,"Dear all, I'm relatively new to NLP and ML. Currently I'm working on projects in which I have to compare and score two audio clips. Original clip (single sentence) will be from movie character (animated or real) and in second clip human will try to mimic it. I have to come up with my model to determine similarly and score human clip out of 5.
Factors which I have considered to be used are:
1. Getting sentence from speech and comparing with original
2. Evaluating similarly from audio spectrogram (spectral centroid and zero crossing rate)
3. Identification of emotion from speech and using emotions embedding (assuming it's available on internet) to measure similarly (will probably use cosine similarly)
I couldn't come up with more factors. Can you please help me come up with new comparison factors or suggest how can I approach this problem in better way?
Thanking you in anticipation...",t2_7n480jd4,False,,0,False,Model to evaluate audio clips similarly,[],r/deeplearning,False,6,,0,,False,t3_n16rvn,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619738671.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Dear all, I&amp;#39;m relatively new to NLP and ML. Currently I&amp;#39;m working on projects in which I have to compare and score two audio clips. Original clip (single sentence) will be from movie character (animated or real) and in second clip human will try to mimic it. I have to come up with my model to determine similarly and score human clip out of 5.
Factors which I have considered to be used are:
1. Getting sentence from speech and comparing with original
2. Evaluating similarly from audio spectrogram (spectral centroid and zero crossing rate)
3. Identification of emotion from speech and using emotions embedding (assuming it&amp;#39;s available on internet) to measure similarly (will probably use cosine similarly)
I couldn&amp;#39;t come up with more factors. Can you please help me come up with new comparison factors or suggest how can I approach this problem in better way?
Thanking you in anticipation...&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n16rvn,True,,Drakshh,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/n16rvn/model_to_evaluate_audio_clips_similarly/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n16rvn/model_to_evaluate_audio_clips_similarly/,66146,1619709871.0,0,,False,,,,,,,
,deeplearning,,t2_3r02kqm0,False,,0,False,Pianist AI&gt; Optimization in progress: Level 4 / 7. Getting better day by day :),[],r/deeplearning,False,6,,0,,False,t3_n1bj9e,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KThI8y2E0dU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Level 4: Try 3', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KThI8y2E0dU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '[ The Pianist AI ]', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/KThI8y2E0dU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ThePianistAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KThI8y2E0dU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/n1bj9e', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1619751735.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/KThI8y2E0dU,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n1bj9e,True,,amin_mlm,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n1bj9e/pianist_ai_optimization_in_progress_level_4_7/,all_ads,False,https://youtu.be/KThI8y2E0dU,66146,1619722935.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Level 4: Try 3', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/KThI8y2E0dU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '[ The Pianist AI ]', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/KThI8y2E0dU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ThePianistAI'}}",False,,,,,,,
,deeplearning,"I have an exam coming up, and one of the problematic concepts I am having issues in understanding is backward propagation. There will be a question on my exam that involves calculating the gradient of a simple Neural Network, and I want to prepare for that. Can someone please point me to a resource that explains this?",t2_409owhnf,False,,0,False,How to calculate backward propagation in gradient descent,[],r/deeplearning,False,6,,0,,False,t3_n1am9j,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619749240.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have an exam coming up, and one of the problematic concepts I am having issues in understanding is backward propagation. There will be a question on my exam that involves calculating the gradient of a simple Neural Network, and I want to prepare for that. Can someone please point me to a resource that explains this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n1am9j,True,,destin95,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n1am9j/how_to_calculate_backward_propagation_in_gradient/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n1am9j/how_to_calculate_backward_propagation_in_gradient/,66146,1619720440.0,0,,False,,,,,,,
,deeplearning,"Hi,

I've been looking more into models for audio processing, and wondering if there are models that deal with separating different sounds. For example, there are a lot of models separating vocals from instrumentals, but I'm wondering if it's possible to separate sound effects, voice, and music from say the audio track of a video clip. I think it'd be an interesting illustration to show how different a movie might feel without say music or sound effects.

Thank you,",t2_iq6r6,False,,0,False,Model for sound separation?,[],r/deeplearning,False,6,,0,,False,t3_n18v4k,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619744392.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been looking more into models for audio processing, and wondering if there are models that deal with separating different sounds. For example, there are a lot of models separating vocals from instrumentals, but I&amp;#39;m wondering if it&amp;#39;s possible to separate sound effects, voice, and music from say the audio track of a video clip. I think it&amp;#39;d be an interesting illustration to show how different a movie might feel without say music or sound effects.&lt;/p&gt;

&lt;p&gt;Thank you,&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n18v4k,True,,rickypaipie,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n18v4k/model_for_sound_separation/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n18v4k/model_for_sound_separation/,66146,1619715592.0,0,,False,,,,,,,
,deeplearning,"Hey everyone, so I am working on building a script to calculate the TP/FP, AP, and mAP for my object detection model. I have read that when calculating the AP for each class it is advised to perform some type of interpolation to the Precision/Recall values in order to smooth out the PR Curve. I have decided to implement 11-Point Interpolation, however, after doing so my graph looks pretty weird. Attached is the graph for your visualization purposes. Any idea as to why the graph may be looking like this?

[PR Curve \/ 11-Pt PR Curve](https://preview.redd.it/db3o32of85w61.png?width=917&amp;format=png&amp;auto=webp&amp;s=ebb75194f50a1f2583c24e605400de67aa3ea6c4)

**Update\***

Disregard, I figured out that I was performing the 11-pt interpolation logic wrong. When selecting the precision value at each of the 11 evenly spaced recall values between 0 and 1 {0.0, 0.1, 0.2, ..., 1.0}, I was actually selecting the precision value based on the highest recall value within a given range (ie. 0.0 - 0.1). What I should have been doing was selecting the recall value based on the highest precision value. So I just flipped the logic lol. Here is an updated graph after I made the changes.

&amp;#x200B;

[PR Curve \/ 11-Pt PR Curve](https://preview.redd.it/b9u346t0j5w61.png?width=892&amp;format=png&amp;auto=webp&amp;s=c4ac50113c28152fe30d9de7e5ab9d530948d4aa)",t2_5z11vqgg,False,,0,False,11-Point Interpolation Question,[],r/deeplearning,False,6,,0,,False,t3_n18uyx,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1619719133.0,,[],{},,True,,1619744378.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey everyone, so I am working on building a script to calculate the TP/FP, AP, and mAP for my object detection model. I have read that when calculating the AP for each class it is advised to perform some type of interpolation to the Precision/Recall values in order to smooth out the PR Curve. I have decided to implement 11-Point Interpolation, however, after doing so my graph looks pretty weird. Attached is the graph for your visualization purposes. Any idea as to why the graph may be looking like this?&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/db3o32of85w61.png?width=917&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ebb75194f50a1f2583c24e605400de67aa3ea6c4""&gt;PR Curve / 11-Pt PR Curve&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update\&lt;/strong&gt;*&lt;/p&gt;

&lt;p&gt;Disregard, I figured out that I was performing the 11-pt interpolation logic wrong. When selecting the precision value at each of the 11 evenly spaced recall values between 0 and 1 {0.0, 0.1, 0.2, ..., 1.0}, I was actually selecting the precision value based on the highest recall value within a given range (ie. 0.0 - 0.1). What I should have been doing was selecting the recall value based on the highest precision value. So I just flipped the logic lol. Here is an updated graph after I made the changes.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/b9u346t0j5w61.png?width=892&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c4ac50113c28152fe30d9de7e5ab9d530948d4aa""&gt;PR Curve / 11-Pt PR Curve&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n18uyx,True,,brandonrussell757,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n18uyx/11point_interpolation_question/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n18uyx/11point_interpolation_question/,66146,1619715578.0,0,,False,,,"{'b9u346t0j5w61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 63, 'x': 108, 'u': 'https://preview.redd.it/b9u346t0j5w61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fae093ad4d10cbd76a8929d19ad2eda6ed6f69cf'}, {'y': 127, 'x': 216, 'u': 'https://preview.redd.it/b9u346t0j5w61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7db1b1cebcd1e0fe7a56d89b04a166120ab6207a'}, {'y': 189, 'x': 320, 'u': 'https://preview.redd.it/b9u346t0j5w61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7766d5474440d2b4c63d9e2752668b84975da12f'}, {'y': 378, 'x': 640, 'u': 'https://preview.redd.it/b9u346t0j5w61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=41326d7dbb14f1fd2bf57234fcfa31b43caf4b44'}], 's': {'y': 527, 'x': 892, 'u': 'https://preview.redd.it/b9u346t0j5w61.png?width=892&amp;format=png&amp;auto=webp&amp;s=c4ac50113c28152fe30d9de7e5ab9d530948d4aa'}, 'id': 'b9u346t0j5w61'}, 'db3o32of85w61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 63, 'x': 108, 'u': 'https://preview.redd.it/db3o32of85w61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cda7d14cfcc1f442d42ae023c550571a3f78cdd5'}, {'y': 126, 'x': 216, 'u': 'https://preview.redd.it/db3o32of85w61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4825476c84d264dc902ba22cfa4b5a5903be0122'}, {'y': 186, 'x': 320, 'u': 'https://preview.redd.it/db3o32of85w61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b766e921d4544bdd5f011b85f7a847795ad22885'}, {'y': 373, 'x': 640, 'u': 'https://preview.redd.it/db3o32of85w61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0cedda8d058e94c308ca0a9992362004a9152e22'}], 's': {'y': 535, 'x': 917, 'u': 'https://preview.redd.it/db3o32of85w61.png?width=917&amp;format=png&amp;auto=webp&amp;s=ebb75194f50a1f2583c24e605400de67aa3ea6c4'}, 'id': 'db3o32of85w61'}}",,,,
,deeplearning,"I'm trying to train a mask r cnn algorithm for object detection. Right now I have 21 classes with the corresponding annotations but my task is to detect only 13 of them, the other 8 classes should be recognize as background.

For the CustomConfig code part I tried to run the code setting the number of classes for the background with this three combinations:

* 1+13
* 8+13
* 9+13

But none of them worked.

    class CustomConfig(Config):
        """"""Configuration for training on the custom  dataset.
        Derives from the base Config class and overrides some values.
        """"""
        # Give the configuration a recognizable name
        NAME = ""object""
    
        # We use a GPU with 12GB memory, which can fit two images.
        # Adjust down if you use a smaller GPU.
        IMAGES_PER_GPU = 2
    
        # Number of classes (including background)
        NUM_CLASSES = 1 + 13
        # Number of training steps per epoch
        STEPS_PER_EPOCH = 10
    
        # Skip detections with &lt; 85% confidence
        DETECTION_MIN_CONFIDENCE = 0.85

The error that came out:

    ---&gt; 56  num_ids = [name_dict[a] for a in objects]
    KeyError: 'Class20'    (this class should be in the background)

Regarding the def load custom function I only added the 13 classes that I want to detect:

    class CustomDataset(utils.Dataset):
    
        def load_custom(self, dataset_dir, subset):
            """"""Load a subset of the Dog-Cat dataset.
            dataset_dir: Root directory of the dataset.
            subset: Subset to load: train or val
            """"""
            # Add classes. We have only one class to add.
            
            self.add_class(""object"", 1, ""01"")
            self.add_class(""object"", 2, ""02"")
            self.add_class(""object"", 3, "" 03"")
            self.add_class(""object"", 4, ""04"")
            self.add_class(""object"", 5, ""05"")
            self.add_class(""object"", 6, ""06"")
            self.add_class(""object"", 7, ""07"")
            self.add_class(""object"", 8, ""8"")
            self.add_class(""object"", 9, ""9"")
            self.add_class(""object"", 10, ""10"")
            self.add_class(""object"", 11, ""11"")
            self.add_class(""object"", 12, ""12"")
            self.add_class(""object"", 13, ""13"")
    
            # Train or validation dataset?
            assert subset in [""TRAIN"", ""TEST""]
            dataset_dir = os.path.join(dataset_dir, subset)
    
            annotations1 = json.load(open(os.path.join(dataset_dir, ""set_labelling.json"")))
            new_dict = {}
            
            for item in annotations1:
              name = item['filename'], item['Layer']
              new_dict[name] = item
            annotations = list(new_dict.values()) # don't need the dict key
    
            # Add images
            for a in annotations:
                polygons = [r['shape_attributes'] for r in a['region']]
                objects = [s['region_attribute']['name'] for s in a['region']]
                #print(polygons)
                print(""objects:"",objects)
                name_dict = {""01"": 1,
                              ""02"": 2,
                              ""03"": 3,
                              ""04"": 4,
                              ""05"": 5,
                              ""06"": 6,
                              ""07"": 7,
                              ""08"": 8,
                              ""09"": 9, 
                              ""10"": 10,
                              ""11"": 11, 
                              ""12"": 12, 
                              ""13"":13} 
               
                num_ids = [name_dict[a] for a in objects]
         
                
                print(""numids"",num_ids)
                image_path = os.path.join(dataset_dir, a['filename'])
                image = skimage.io.imread(image_path)
                height, width = image.shape[:2]
    
                self.add_image(
                    ""object"",  ## for a single class just add the name here
                    image_id=a['filename'],  # use file name as a unique image id
                    path=image_path,
                    width=width, height=height,
                    polygons=polygons,
                    num_ids=num_ids
                    )

I would not to delete the background classes annotations in the json file, so how can I handle this error?",t2_3zwz9769,False,,0,False,Mutiple backgrounds for object detection with mask r cnn,[],r/deeplearning,False,6,,0,,False,t3_n16uor,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619738885.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to train a mask r cnn algorithm for object detection. Right now I have 21 classes with the corresponding annotations but my task is to detect only 13 of them, the other 8 classes should be recognize as background.&lt;/p&gt;

&lt;p&gt;For the CustomConfig code part I tried to run the code setting the number of classes for the background with this three combinations:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1+13&lt;/li&gt;
&lt;li&gt;8+13&lt;/li&gt;
&lt;li&gt;9+13&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But none of them worked.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class CustomConfig(Config):
    &amp;quot;&amp;quot;&amp;quot;Configuration for training on the custom  dataset.
    Derives from the base Config class and overrides some values.
    &amp;quot;&amp;quot;&amp;quot;
    # Give the configuration a recognizable name
    NAME = &amp;quot;object&amp;quot;

    # We use a GPU with 12GB memory, which can fit two images.
    # Adjust down if you use a smaller GPU.
    IMAGES_PER_GPU = 2

    # Number of classes (including background)
    NUM_CLASSES = 1 + 13
    # Number of training steps per epoch
    STEPS_PER_EPOCH = 10

    # Skip detections with &amp;lt; 85% confidence
    DETECTION_MIN_CONFIDENCE = 0.85
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The error that came out:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;---&amp;gt; 56  num_ids = [name_dict[a] for a in objects]
KeyError: &amp;#39;Class20&amp;#39;    (this class should be in the background)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Regarding the def load custom function I only added the 13 classes that I want to detect:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class CustomDataset(utils.Dataset):

    def load_custom(self, dataset_dir, subset):
        &amp;quot;&amp;quot;&amp;quot;Load a subset of the Dog-Cat dataset.
        dataset_dir: Root directory of the dataset.
        subset: Subset to load: train or val
        &amp;quot;&amp;quot;&amp;quot;
        # Add classes. We have only one class to add.

        self.add_class(&amp;quot;object&amp;quot;, 1, &amp;quot;01&amp;quot;)
        self.add_class(&amp;quot;object&amp;quot;, 2, &amp;quot;02&amp;quot;)
        self.add_class(&amp;quot;object&amp;quot;, 3, &amp;quot; 03&amp;quot;)
        self.add_class(&amp;quot;object&amp;quot;, 4, &amp;quot;04&amp;quot;)
        self.add_class(&amp;quot;object&amp;quot;, 5, &amp;quot;05&amp;quot;)
        self.add_class(&amp;quot;object&amp;quot;, 6, &amp;quot;06&amp;quot;)
        self.add_class(&amp;quot;object&amp;quot;, 7, &amp;quot;07&amp;quot;)
        self.add_class(&amp;quot;object&amp;quot;, 8, &amp;quot;8&amp;quot;)
        self.add_class(&amp;quot;object&amp;quot;, 9, &amp;quot;9&amp;quot;)
        self.add_class(&amp;quot;object&amp;quot;, 10, &amp;quot;10&amp;quot;)
        self.add_class(&amp;quot;object&amp;quot;, 11, &amp;quot;11&amp;quot;)
        self.add_class(&amp;quot;object&amp;quot;, 12, &amp;quot;12&amp;quot;)
        self.add_class(&amp;quot;object&amp;quot;, 13, &amp;quot;13&amp;quot;)

        # Train or validation dataset?
        assert subset in [&amp;quot;TRAIN&amp;quot;, &amp;quot;TEST&amp;quot;]
        dataset_dir = os.path.join(dataset_dir, subset)

        annotations1 = json.load(open(os.path.join(dataset_dir, &amp;quot;set_labelling.json&amp;quot;)))
        new_dict = {}

        for item in annotations1:
          name = item[&amp;#39;filename&amp;#39;], item[&amp;#39;Layer&amp;#39;]
          new_dict[name] = item
        annotations = list(new_dict.values()) # don&amp;#39;t need the dict key

        # Add images
        for a in annotations:
            polygons = [r[&amp;#39;shape_attributes&amp;#39;] for r in a[&amp;#39;region&amp;#39;]]
            objects = [s[&amp;#39;region_attribute&amp;#39;][&amp;#39;name&amp;#39;] for s in a[&amp;#39;region&amp;#39;]]
            #print(polygons)
            print(&amp;quot;objects:&amp;quot;,objects)
            name_dict = {&amp;quot;01&amp;quot;: 1,
                          &amp;quot;02&amp;quot;: 2,
                          &amp;quot;03&amp;quot;: 3,
                          &amp;quot;04&amp;quot;: 4,
                          &amp;quot;05&amp;quot;: 5,
                          &amp;quot;06&amp;quot;: 6,
                          &amp;quot;07&amp;quot;: 7,
                          &amp;quot;08&amp;quot;: 8,
                          &amp;quot;09&amp;quot;: 9, 
                          &amp;quot;10&amp;quot;: 10,
                          &amp;quot;11&amp;quot;: 11, 
                          &amp;quot;12&amp;quot;: 12, 
                          &amp;quot;13&amp;quot;:13} 

            num_ids = [name_dict[a] for a in objects]


            print(&amp;quot;numids&amp;quot;,num_ids)
            image_path = os.path.join(dataset_dir, a[&amp;#39;filename&amp;#39;])
            image = skimage.io.imread(image_path)
            height, width = image.shape[:2]

            self.add_image(
                &amp;quot;object&amp;quot;,  ## for a single class just add the name here
                image_id=a[&amp;#39;filename&amp;#39;],  # use file name as a unique image id
                path=image_path,
                width=width, height=height,
                polygons=polygons,
                num_ids=num_ids
                )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I would not to delete the background classes annotations in the json file, so how can I handle this error?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n16uor,True,,Dario_Della,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n16uor/mutiple_backgrounds_for_object_detection_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n16uor/mutiple_backgrounds_for_object_detection_with/,66146,1619710085.0,0,,False,,,,,,,
,deeplearning,"Hi, all! Announcing Labelflow ( [https://www.labelflow.net/](https://www.labelflow.net/) ), the open source image labeling and dataset cleaning platform.

We are a team of 9 people with experience in image labeling and dataset curating to build quality datasets for deep learning.  We were frustrated by the amount of scripts required to move the data back and forth between tools, and by the lack of control over our data, especially when we have data that can’t easily be shared. 

So we started building Labelflow, an image labeling tool with all the bells and whistles, but with an open source backend that you can connect to your own data stack easily. Let me know what you think, and feel free to request early access to get up to 50% off when we release it in a few months!",t2_meeie,False,,0,False,"Announcing Labelflow, the open source image labeling and dataset cleaning platform.",[],r/deeplearning,False,6,,0,,False,t3_n0lan4,False,dark,1.0,,public,38,1,{},,False,[],,False,False,,{},,False,38,,False,False,,False,,[],{'gid_1': 1},,True,,1619663035.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, all! Announcing Labelflow ( &lt;a href=""https://www.labelflow.net/""&gt;https://www.labelflow.net/&lt;/a&gt; ), the open source image labeling and dataset cleaning platform.&lt;/p&gt;

&lt;p&gt;We are a team of 9 people with experience in image labeling and dataset curating to build quality datasets for deep learning.  We were frustrated by the amount of scripts required to move the data back and forth between tools, and by the lack of control over our data, especially when we have data that can’t easily be shared. &lt;/p&gt;

&lt;p&gt;So we started building Labelflow, an image labeling tool with all the bells and whistles, but with an open source backend that you can connect to your own data stack easily. Let me know what you think, and feel free to request early access to get up to 50% off when we release it in a few months!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n0lan4,True,,crubier,,12,True,all_ads,False,[],False,,/r/deeplearning/comments/n0lan4/announcing_labelflow_the_open_source_image/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n0lan4/announcing_labelflow_the_open_source_image/,66146,1619634235.0,0,,False,,,,,,,
,deeplearning,,t2_36bn18ys,False,,0,False,I want to learn deep learning! how do I start? I have learned python. Thanks!!!,[],r/deeplearning,False,6,,0,,False,t3_n16t37,False,dark,0.14,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619738760.0,text,6,,,text,self.deeplearning,False,,,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n16t37,True,,shai_the_god,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n16t37/i_want_to_learn_deep_learning_how_do_i_start_i/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n16t37/i_want_to_learn_deep_learning_how_do_i_start_i/,66146,1619709960.0,0,,False,,,,,,,
,deeplearning,"In today's blog post we will learn about [Variational Autoencoder in TensorFlow](https://click.convertkit-mail.com/mvu4o2qmr4u5hp8nqnfl/48hvh7u0nr53n8ax/aHR0cHM6Ly9sZWFybm9wZW5jdi5jb20vdmFyaWF0aW9uYWwtYXV0b2VuY29kZXItaW4tdGVuc29yZmxvdy8=). Before Generative Adversarial Network (GAN) was invented, there were other neural network architectures for Generative Modeling. Today we will take you back in time and discuss one of the most popular pre-GAN eras Deep Generative Model known as Variational Autoencoder.

If you have never heard about Variational Autoencoders, this is just the right post for you because we start from the very beginning and explain the concept with code. We are going to build on [Autoencoders](https://click.convertkit-mail.com/mvu4o2qmr4u5hp8nqnfl/wnh2h6ur3w5d3pi7/aHR0cHM6Ly9sZWFybm9wZW5jdi5jb20vYXV0b2VuY29kZXItaW4tdGVuc29yZmxvdy0yLWJlZ2lubmVycy1ndWlkZS8=) we covered last week, discuss the important ideas that make variational autoencoders different from plain vanilla autoencoders, and finally have fun experimenting with code, and two different datasets - Fashion MNIST &amp; Google Cartoon Dataset.

[https://learnopencv.com/variational-autoencoder-in-tensorflow/](https://click.convertkit-mail.com/mvu4o2qmr4u5hp8nqnfl/48hvh7u0nr53n8ax/aHR0cHM6Ly9sZWFybm9wZW5jdi5jb20vdmFyaWF0aW9uYWwtYXV0b2VuY29kZXItaW4tdGVuc29yZmxvdy8=)

and experiment with the code at the following link

[https://github.com/spmallick/learnopencv/tree/master/Variational-Autoencoder-TensorFlow](https://click.convertkit-mail.com/mvu4o2qmr4u5hp8nqnfl/reh8h9uqe02pelu2/aHR0cHM6Ly9naXRodWIuY29tL3NwbWFsbGljay9sZWFybm9wZW5jdi90cmVlL21hc3Rlci9WYXJpYXRpb25hbC1BdXRvZW5jb2Rlci1UZW5zb3JGbG93)

https://i.redd.it/9irvg48ei1w61.gif",t2_cvc9f,False,,0,False,Variational Autoencoder in TensorFlow,[],r/deeplearning,False,6,,0,,False,t3_n0ws91,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619699330.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In today&amp;#39;s blog post we will learn about &lt;a href=""https://click.convertkit-mail.com/mvu4o2qmr4u5hp8nqnfl/48hvh7u0nr53n8ax/aHR0cHM6Ly9sZWFybm9wZW5jdi5jb20vdmFyaWF0aW9uYWwtYXV0b2VuY29kZXItaW4tdGVuc29yZmxvdy8=""&gt;Variational Autoencoder in TensorFlow&lt;/a&gt;. Before Generative Adversarial Network (GAN) was invented, there were other neural network architectures for Generative Modeling. Today we will take you back in time and discuss one of the most popular pre-GAN eras Deep Generative Model known as Variational Autoencoder.&lt;/p&gt;

&lt;p&gt;If you have never heard about Variational Autoencoders, this is just the right post for you because we start from the very beginning and explain the concept with code. We are going to build on &lt;a href=""https://click.convertkit-mail.com/mvu4o2qmr4u5hp8nqnfl/wnh2h6ur3w5d3pi7/aHR0cHM6Ly9sZWFybm9wZW5jdi5jb20vYXV0b2VuY29kZXItaW4tdGVuc29yZmxvdy0yLWJlZ2lubmVycy1ndWlkZS8=""&gt;Autoencoders&lt;/a&gt; we covered last week, discuss the important ideas that make variational autoencoders different from plain vanilla autoencoders, and finally have fun experimenting with code, and two different datasets - Fashion MNIST &amp;amp; Google Cartoon Dataset.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://click.convertkit-mail.com/mvu4o2qmr4u5hp8nqnfl/48hvh7u0nr53n8ax/aHR0cHM6Ly9sZWFybm9wZW5jdi5jb20vdmFyaWF0aW9uYWwtYXV0b2VuY29kZXItaW4tdGVuc29yZmxvdy8=""&gt;https://learnopencv.com/variational-autoencoder-in-tensorflow/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;and experiment with the code at the following link&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://click.convertkit-mail.com/mvu4o2qmr4u5hp8nqnfl/reh8h9uqe02pelu2/aHR0cHM6Ly9naXRodWIuY29tL3NwbWFsbGljay9sZWFybm9wZW5jdi90cmVlL21hc3Rlci9WYXJpYXRpb25hbC1BdXRvZW5jb2Rlci1UZW5zb3JGbG93""&gt;https://github.com/spmallick/learnopencv/tree/master/Variational-Autoencoder-TensorFlow&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://i.redd.it/9irvg48ei1w61.gif""&gt;https://i.redd.it/9irvg48ei1w61.gif&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n0ws91,True,,spmallick,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n0ws91/variational_autoencoder_in_tensorflow/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n0ws91/variational_autoencoder_in_tensorflow/,66146,1619670530.0,0,,False,,,"{'9irvg48ei1w61': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/9irvg48ei1w61.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=de0e707a5d03ac8ee3f3bb9e1e640f3532393efd'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/9irvg48ei1w61.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=1f01f12e3bae7395545cea02521901acbd7e1436'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/9irvg48ei1w61.gif?width=320&amp;crop=smart&amp;format=png8&amp;s=98f8db042b1b6c89b10827cf794ecfee00748efd'}], 's': {'y': 338, 'gif': 'https://i.redd.it/9irvg48ei1w61.gif', 'mp4': 'https://preview.redd.it/9irvg48ei1w61.gif?format=mp4&amp;s=dbbe5148ebeaf96f9fdb8a0fc5040c4827a22b47', 'x': 600}, 'id': '9irvg48ei1w61'}}",,,,
,deeplearning,Hi everyone. I need help in real-time object detection on Jetson Nano. I trained a yolov3 model a while back and it is pretty accurate but gives a very low FPS of 0.223 on nano. I tried converting the model to tflite but that gives an even lower fps of 0.07. Please tell me how I can achieve real-time inference without any loss in accuracy?? Thanks in advance.,t2_7952ylao,False,,0,False,Real-time Object Detection on Jetson Nano,[],r/deeplearning,False,6,,0,,False,t3_n0wemr,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619697845.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone. I need help in real-time object detection on Jetson Nano. I trained a yolov3 model a while back and it is pretty accurate but gives a very low FPS of 0.223 on nano. I tried converting the model to tflite but that gives an even lower fps of 0.07. Please tell me how I can achieve real-time inference without any loss in accuracy?? Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n0wemr,True,,Intelligent-Fun-5311,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n0wemr/realtime_object_detection_on_jetson_nano/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n0wemr/realtime_object_detection_on_jetson_nano/,66146,1619669045.0,0,,False,,,,,,,
,deeplearning,"A research team from Google Research proposes small, fast, on-device disfluency detection models based on the BERT architecture. The smallest model size is only 1.3 MiB, representing a size reduction of two orders of magnitude and an inference latency reduction of a factor of eight compared to state-of-the-art BERT-based models.

Here is a quick read: [Google’s 1.3 MiB On-Device Model Brings High-Performance Disfluency Detection Down to Size.](https://syncedreview.com/2021/04/28/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-7/)

 The paper *Disfluency Detection with Unlabeled Data and Small BERT Models* is on [arXiv](https://arxiv.org/pdf/2104.10769.pdf).",t2_2fv4yodo,False,,0,False,[R] Google’s 1.3 MiB On-Device Model Brings High-Performance Disfluency Detection Down to Size,[],r/deeplearning,False,6,,0,,False,t3_n0iyuq,False,dark,0.86,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1619656779.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Google Research proposes small, fast, on-device disfluency detection models based on the BERT architecture. The smallest model size is only 1.3 MiB, representing a size reduction of two orders of magnitude and an inference latency reduction of a factor of eight compared to state-of-the-art BERT-based models.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/28/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-7/""&gt;Google’s 1.3 MiB On-Device Model Brings High-Performance Disfluency Detection Down to Size.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Disfluency Detection with Unlabeled Data and Small BERT Models&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.10769.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n0iyuq,True,,Yuqing7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/n0iyuq/r_googles_13_mib_ondevice_model_brings/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n0iyuq/r_googles_13_mib_ondevice_model_brings/,66146,1619627979.0,0,,False,,,,,,,
,deeplearning,"Geography   no bar -- but they should be okay with volunteers from any other   geographic location. I want to volunteer or work part time for a   non-profit who is working or researching on ML on things like fairness   and accountability. I have good tech background but I am not able to   find places where I can contribute and possibly research for social   cause.

Please don't recommend Allen AI because they only look for full time people and I can not move to USA.",t2_1v8k7bkx,False,,0,False,Are there non-profits who work on ML for social cause (fairness etc.) where I can work for a project and contribute?,[],r/deeplearning,False,6,,0,,False,t3_n0r3t7,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619679462.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Geography   no bar -- but they should be okay with volunteers from any other   geographic location. I want to volunteer or work part time for a   non-profit who is working or researching on ML on things like fairness   and accountability. I have good tech background but I am not able to   find places where I can contribute and possibly research for social   cause.&lt;/p&gt;

&lt;p&gt;Please don&amp;#39;t recommend Allen AI because they only look for full time people and I can not move to USA.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n0r3t7,True,,sideonion,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/n0r3t7/are_there_nonprofits_who_work_on_ml_for_social/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n0r3t7/are_there_nonprofits_who_work_on_ml_for_social/,66146,1619650662.0,0,,False,,,,,,,
,deeplearning,,t2_40d0zt4s,False,,0,False,Decoupling Software-Hardware Dependency In Deep Learning,[],r/deeplearning,False,6,,0,,False,t3_n0d145,False,dark,0.72,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,False,,1619639390.0,text,6,,,text,analyticsindiamag.com,False,,,,,https://analyticsindiamag.com/decoupling-hardware-software-dependency-deep-learning/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n0d145,True,,analyticsindiam,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n0d145/decoupling_softwarehardware_dependency_in_deep/,all_ads,False,https://analyticsindiamag.com/decoupling-hardware-software-dependency-deep-learning/,66146,1619610590.0,0,,False,,,,,,,
,deeplearning,"Hi, I have uploaded my first model to huggingface, a lonfgormer model for question answering on covid -19 data. You can find the source code [here](https://github.com/abhijithneilabraham/Covid-QA)

Give a star if you like the project, and also test it on the huggingface API, link given in readme.

&amp;#x200B;

https://preview.redd.it/mj8g7s0btwv61.png?width=822&amp;format=png&amp;auto=webp&amp;s=a3fc08d52ac3d351e8aad3ac64a1d6146beea008",t2_260way1u,False,,0,False,Question Answering on Covid-19 data.,[],r/deeplearning,False,6,,0,,False,t3_n0dy2m,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619642575.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I have uploaded my first model to huggingface, a lonfgormer model for question answering on covid -19 data. You can find the source code &lt;a href=""https://github.com/abhijithneilabraham/Covid-QA""&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Give a star if you like the project, and also test it on the huggingface API, link given in readme.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/mj8g7s0btwv61.png?width=822&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a3fc08d52ac3d351e8aad3ac64a1d6146beea008""&gt;https://preview.redd.it/mj8g7s0btwv61.png?width=822&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=a3fc08d52ac3d351e8aad3ac64a1d6146beea008&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n0dy2m,True,,abhijithneilabraham,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n0dy2m/question_answering_on_covid19_data/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n0dy2m/question_answering_on_covid19_data/,66146,1619613775.0,0,,False,,,"{'mj8g7s0btwv61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 101, 'x': 108, 'u': 'https://preview.redd.it/mj8g7s0btwv61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2bc0a958ebc06c58b41f151d91bb5f6e9497e0cb'}, {'y': 202, 'x': 216, 'u': 'https://preview.redd.it/mj8g7s0btwv61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f5a6a1b055fa3f03e98903545e2a79bf651edc87'}, {'y': 300, 'x': 320, 'u': 'https://preview.redd.it/mj8g7s0btwv61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b211781795cf47890695bb696493b9514d3f776a'}, {'y': 601, 'x': 640, 'u': 'https://preview.redd.it/mj8g7s0btwv61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=40ab359f2b2b0eb772f7a72e30749273b4b0533d'}], 's': {'y': 772, 'x': 822, 'u': 'https://preview.redd.it/mj8g7s0btwv61.png?width=822&amp;format=png&amp;auto=webp&amp;s=a3fc08d52ac3d351e8aad3ac64a1d6146beea008'}, 'id': 'mj8g7s0btwv61'}}",,,,
,deeplearning," 

Hi,

I need to avoid downloading the model from the web (due to restrictions on the machine installed).

This works, but downloads the model from the net

model = torch.hub.load('pytorch/vision:v0.9.0', 'deeplabv3\_resnet101', pretrained=True)

I have placed the \`.pth\` file and the \`hubconf.py\` file in the /tmp/ folder and changed my code to

model = torch.hub.load('/tmp/', 'deeplabv3\_resnet101', pretrained=True,s ource='local')

but to my surprise it still downloads the model from the internet. What am I doing wrong? How can I load the model locally.

Just to give you a bit more details, I'm doing all this in a Docker container which has a read-only volume at runtime, so that's why the download of new files fails.

thanks,

John",t2_4gojb,False,,0,False,How do I load a local model with torch.hub.load?,[],r/deeplearning,False,6,,0,,False,t3_n0fpm3,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619647986.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I need to avoid downloading the model from the web (due to restrictions on the machine installed).&lt;/p&gt;

&lt;p&gt;This works, but downloads the model from the net&lt;/p&gt;

&lt;p&gt;model = torch.hub.load(&amp;#39;pytorch/vision:v0.9.0&amp;#39;, &amp;#39;deeplabv3_resnet101&amp;#39;, pretrained=True)&lt;/p&gt;

&lt;p&gt;I have placed the `.pth` file and the `hubconf.py` file in the /tmp/ folder and changed my code to&lt;/p&gt;

&lt;p&gt;model = torch.hub.load(&amp;#39;/tmp/&amp;#39;, &amp;#39;deeplabv3_resnet101&amp;#39;, pretrained=True,s ource=&amp;#39;local&amp;#39;)&lt;/p&gt;

&lt;p&gt;but to my surprise it still downloads the model from the internet. What am I doing wrong? How can I load the model locally.&lt;/p&gt;

&lt;p&gt;Just to give you a bit more details, I&amp;#39;m doing all this in a Docker container which has a read-only volume at runtime, so that&amp;#39;s why the download of new files fails.&lt;/p&gt;

&lt;p&gt;thanks,&lt;/p&gt;

&lt;p&gt;John&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n0fpm3,True,,psd-dude,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/n0fpm3/how_do_i_load_a_local_model_with_torchhubload/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n0fpm3/how_do_i_load_a_local_model_with_torchhubload/,66146,1619619186.0,0,,False,,,,,,,
,deeplearning,"A research team from Microsoft Research and Peking University peeps into pretrained transformers and investigates how factual knowledge is stored, proposing a method to identify “knowledge neurons,” which can be utilized to explicitly update and erase facts.

Here is a quick read: [Microsoft &amp; Peking U Researchers Identify 'Knowledge Neurons' in Pretrained Transformers, Enabling Fact Editing.](https://syncedreview.com/2021/04/27/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-6/)

The paper *Knowledge Neurons in Pretrained Transformers* is on [arXiv](https://arxiv.org/pdf/2104.08696.pdf).",t2_2fv4yodo,False,,0,False,"[R] Microsoft &amp; Peking U Researchers Identify 'Knowledge Neurons' in Pretrained Transformers, Enabling Fact Editing",[],r/deeplearning,False,6,,0,,False,t3_mzshau,False,dark,0.95,,public,50,0,{},,False,[],,False,False,,{},,False,50,,False,False,,False,,[],{},,True,,1619570035.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Microsoft Research and Peking University peeps into pretrained transformers and investigates how factual knowledge is stored, proposing a method to identify “knowledge neurons,” which can be utilized to explicitly update and erase facts.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/27/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-6/""&gt;Microsoft &amp;amp; Peking U Researchers Identify &amp;#39;Knowledge Neurons&amp;#39; in Pretrained Transformers, Enabling Fact Editing.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Knowledge Neurons in Pretrained Transformers&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.08696.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mzshau,True,,Yuqing7,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mzshau/r_microsoft_peking_u_researchers_identify/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mzshau/r_microsoft_peking_u_researchers_identify/,66146,1619541235.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,"What has AI Brought to Computer Vision? We are still far from mimicking our vision system even with the current depth of our networks, but is that really the goal of our algorithms? Would it be better to use them as a tool to improve our weaknesses? What are these weaknesses, and their strengths",[],r/deeplearning,False,6,,0,,False,t3_n0dthv,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1619642150.0,text,6,,,text,louisbouchard.me,False,,,,,https://www.louisbouchard.me/ai-in-computer-vision/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n0dthv,True,,OnlyProggingForFun,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n0dthv/what_has_ai_brought_to_computer_vision_we_are/,all_ads,False,https://www.louisbouchard.me/ai-in-computer-vision/,66146,1619613350.0,0,,False,,,,,,,
,deeplearning," GitHub Link: [https://github.com/dhruvampanchal/AnoVAEGAN](https://github.com/dhruvampanchal/AnoVAEGAN)

I have been working on a research project. And I have to make a VAEGAN network for the same. I have made one with the help of a tutorial from the TF website. However, for some reason, the model keeps returning random noise images. I am not sure what's wrong.

Also, since this is a big network, I am running it on a high-performance computer. When I make a test run with around 20 images and 10 epochs, I get grey images, which I think is normal. However, when I train on 70,000 images, the model returns random noise from the first epoch and keeps returning the random noise for every epoch. I have trained the model for 35 epochs (14.5hrs of training) and there was no improvement.

I am using CelebA dataset which is cropped to only include the facial image of size 256x256.

I have to complete this in the next 4 days. Any help is appreciated.

Thank You.

(Left Image is input and Right is output) The expected result is the same face.",t2_35e3hz3w,False,,0,False,(HELP) VAEGAN producing only random noise images.,[],r/deeplearning,False,6,,0,,False,t3_n0dcpu,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619640532.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;GitHub Link: &lt;a href=""https://github.com/dhruvampanchal/AnoVAEGAN""&gt;https://github.com/dhruvampanchal/AnoVAEGAN&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have been working on a research project. And I have to make a VAEGAN network for the same. I have made one with the help of a tutorial from the TF website. However, for some reason, the model keeps returning random noise images. I am not sure what&amp;#39;s wrong.&lt;/p&gt;

&lt;p&gt;Also, since this is a big network, I am running it on a high-performance computer. When I make a test run with around 20 images and 10 epochs, I get grey images, which I think is normal. However, when I train on 70,000 images, the model returns random noise from the first epoch and keeps returning the random noise for every epoch. I have trained the model for 35 epochs (14.5hrs of training) and there was no improvement.&lt;/p&gt;

&lt;p&gt;I am using CelebA dataset which is cropped to only include the facial image of size 256x256.&lt;/p&gt;

&lt;p&gt;I have to complete this in the next 4 days. Any help is appreciated.&lt;/p&gt;

&lt;p&gt;Thank You.&lt;/p&gt;

&lt;p&gt;(Left Image is input and Right is output) The expected result is the same face.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n0dcpu,True,,dhruvampanchal,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n0dcpu/help_vaegan_producing_only_random_noise_images/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n0dcpu/help_vaegan_producing_only_random_noise_images/,66146,1619611732.0,0,,False,,,,,,,
,deeplearning,[https://haker88.medium.com/hands-on-tutorial-for-ai-implementation-in-manufacturing-part-1-55adff94d1e6?source=post\_stats\_page-------------------------------------](https://haker88.medium.com/hands-on-tutorial-for-ai-implementation-in-manufacturing-part-1-55adff94d1e6?source=post_stats_page-------------------------------------),t2_6piczfsr,False,,0,False,Deep learning implementation in Manufacturing Environment,[],r/deeplearning,False,6,,0,,False,t3_n0ccb7,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619636733.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://haker88.medium.com/hands-on-tutorial-for-ai-implementation-in-manufacturing-part-1-55adff94d1e6?source=post_stats_page-------------------------------------""&gt;https://haker88.medium.com/hands-on-tutorial-for-ai-implementation-in-manufacturing-part-1-55adff94d1e6?source=post_stats_page-------------------------------------&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n0ccb7,True,,International-Bath22,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n0ccb7/deep_learning_implementation_in_manufacturing/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n0ccb7/deep_learning_implementation_in_manufacturing/,66146,1619607933.0,0,,False,,,,,,,
,deeplearning,"I get a oom error, but i'm not sure if it is the reason for the tf.dataset or the model is too large. My code is as follows:

    dataset = tf.keras.preprocessing.image_dataset_from_directory(train_path, batch_size=64, image_size=(960,640))
    AUTOTUNE = tf.data.AUTOTUNE
    dataset = dataset.prefetch(AUTOTUNE)
    
    inp = tf.keras.layers.Input(shape=(960, 640, 3))
    
    x = tf.keras.layers.Lambda(lambda x: tf.keras.applications.resnet.preprocess_input(x))(inp)
    base_model = tf.keras.applications.ResNet50(
    include_top=False,
    weights='imagenet',
    input_shape=(960, 640, 3))
    
    x = base_model(x)
    x = tf.keras.layers.GlobalAvgPool2D()(x)
    x = tf.keras.layers.Dense(128, activation='relu')(x)
    outputs = tf.keras.layers.Dense(3)(x)
    model = tf.keras.models.Model(inp, outputs)
    
    model.compile(optimizer=tf.keras.optimizers.Adam(),
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])
    
    history = model.fit(dataset, epochs=1)

After the dataset is built, 14G GPU memory is used. if use follow code:

    tf.config.experimental.set_memory_growth(gpu, True)

dataset almost useless GPU memory.

Then, run [model.fit](https://model.fit), the GPU memory it uses increases rapidly until oom. If set batch\_size=16, model can fit, but I think 16G GPU memory is enough for training resnet50, is not?",t2_87416c69,False,,0,False,TF2.4 get oom error when training resnet50 with 16g GPU,[],r/deeplearning,False,6,,0,,False,t3_n0b153,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1619607291.0,,[],{},,True,,1619631196.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I get a oom error, but i&amp;#39;m not sure if it is the reason for the tf.dataset or the model is too large. My code is as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dataset = tf.keras.preprocessing.image_dataset_from_directory(train_path, batch_size=64, image_size=(960,640))
AUTOTUNE = tf.data.AUTOTUNE
dataset = dataset.prefetch(AUTOTUNE)

inp = tf.keras.layers.Input(shape=(960, 640, 3))

x = tf.keras.layers.Lambda(lambda x: tf.keras.applications.resnet.preprocess_input(x))(inp)
base_model = tf.keras.applications.ResNet50(
include_top=False,
weights=&amp;#39;imagenet&amp;#39;,
input_shape=(960, 640, 3))

x = base_model(x)
x = tf.keras.layers.GlobalAvgPool2D()(x)
x = tf.keras.layers.Dense(128, activation=&amp;#39;relu&amp;#39;)(x)
outputs = tf.keras.layers.Dense(3)(x)
model = tf.keras.models.Model(inp, outputs)

model.compile(optimizer=tf.keras.optimizers.Adam(),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=[&amp;#39;accuracy&amp;#39;])

history = model.fit(dataset, epochs=1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After the dataset is built, 14G GPU memory is used. if use follow code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tf.config.experimental.set_memory_growth(gpu, True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;dataset almost useless GPU memory.&lt;/p&gt;

&lt;p&gt;Then, run &lt;a href=""https://model.fit""&gt;model.fit&lt;/a&gt;, the GPU memory it uses increases rapidly until oom. If set batch_size=16, model can fit, but I think 16G GPU memory is enough for training resnet50, is not?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n0b153,True,,Puzzleheaded_Bar5880,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/n0b153/tf24_get_oom_error_when_training_resnet50_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n0b153/tf24_get_oom_error_when_training_resnet50_with/,66146,1619602396.0,0,,False,,,,,,,
,deeplearning,"I am an university student and currently our university has provided machines with GPU installed which can be called via SSH and do my training remotely from terminal.

I felt that it would have been really great if PyCharm (my IDE of preference) can connect directly to the remote terminal. I referred over Pycharm docs and saw that such a feature comes with the Professional Version. 

Does anyone have a workaround or maek-it-simpler tip for me ?",t2_5c8umwtu,False,,0,False,Connect Pycharm to remote terminal,[],r/deeplearning,False,6,,0,,False,t3_n019kt,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1619593945.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am an university student and currently our university has provided machines with GPU installed which can be called via SSH and do my training remotely from terminal.&lt;/p&gt;

&lt;p&gt;I felt that it would have been really great if PyCharm (my IDE of preference) can connect directly to the remote terminal. I referred over Pycharm docs and saw that such a feature comes with the Professional Version. &lt;/p&gt;

&lt;p&gt;Does anyone have a workaround or maek-it-simpler tip for me ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n019kt,True,,7pointsome1,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/n019kt/connect_pycharm_to_remote_terminal/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n019kt/connect_pycharm_to_remote_terminal/,66146,1619565145.0,0,,False,,,,,,,
,deeplearning,"Solving crystal structure with AlphaFold 2 is not enough, this is the next big thing for protein modeling. https://www.biorxiv.org/content/10.1101/2021.04.26.441401v1",t2_16q7y4zk,False,,0,False,Construction of a neural network energy function for protein physics,[],r/deeplearning,False,6,,0,,False,t3_n03by5,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619600679.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Solving crystal structure with AlphaFold 2 is not enough, this is the next big thing for protein modeling. &lt;a href=""https://www.biorxiv.org/content/10.1101/2021.04.26.441401v1""&gt;https://www.biorxiv.org/content/10.1101/2021.04.26.441401v1&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,n03by5,True,,erikxiong,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/n03by5/construction_of_a_neural_network_energy_function/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/n03by5/construction_of_a_neural_network_energy_function/,66146,1619571879.0,0,,False,,,,,,,
,deeplearning,"If you use the deep learning libraries, and particularly codebases built on top of them you will be sure to find schedules using learning rate warmup, and also likely decreasing eta during training.

What I am having trouble finding is good literature about the effects of these schedules, I don't see people reasoning about why to use them. Do you know of any literature that supports schedules, particularly warmup?

Thanks",t2_25qnmj39,False,,0,False,Literature on learning rate schedules/warmup,[],r/deeplearning,False,6,,0,,False,t3_mzlwqv,False,dark,0.84,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1619550122.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;If you use the deep learning libraries, and particularly codebases built on top of them you will be sure to find schedules using learning rate warmup, and also likely decreasing eta during training.&lt;/p&gt;

&lt;p&gt;What I am having trouble finding is good literature about the effects of these schedules, I don&amp;#39;t see people reasoning about why to use them. Do you know of any literature that supports schedules, particularly warmup?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mzlwqv,True,,HolidayWallaby,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mzlwqv/literature_on_learning_rate_scheduleswarmup/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mzlwqv/literature_on_learning_rate_scheduleswarmup/,66146,1619521322.0,0,,False,,,,,,,
,deeplearning,"So I have studied and experimented with both deep NNs and markov nets. I am trying to build a generative model that can also work in reverse. What I want to do is to be able to do is the reverse of this generative process in terms of inputs and outputs which would become a Classification task. I've looked into DBNs or Deep Boltzmann/Belief Networks, where even though its a bit of old tech it have to power to truly learn from a generative model and then can also be used to classify/predict the inputs given the outputs. But for these it uses completely different ground rules, for eg uses energy minimization as loss function as compared to a convex optimization problem in deep ANNs. I am having difficulty understanding the math behind DBNs which relates to the question. Where do I start? Bayesian nets? I want to delve into the mathematics, as I found I learn way more from the equations than I do when someone tries to explain things to me in a hand wavey manner. Any help would be Nice. Thank you.

&amp;#x200B;

Edit: If instead of DBN let me know if I can do the same thing using a bidrectional RNN type architecture. i.e. to infer the probability of the inputs given the input. Also for my generative model I am using a Conditional generative model where instead of plain noise I am, along with the noise also giving it some input/context. I want to do the reverse to basically get the most likely context given something it have learn to generate. ",t2_be316iu7,False,,0,False,Where Can I learn about Boltzmann Machines from scratch??,[],r/deeplearning,False,6,,0,,False,t3_mzunrt,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,1619547078.0,,[],{},,True,,1619575624.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So I have studied and experimented with both deep NNs and markov nets. I am trying to build a generative model that can also work in reverse. What I want to do is to be able to do is the reverse of this generative process in terms of inputs and outputs which would become a Classification task. I&amp;#39;ve looked into DBNs or Deep Boltzmann/Belief Networks, where even though its a bit of old tech it have to power to truly learn from a generative model and then can also be used to classify/predict the inputs given the outputs. But for these it uses completely different ground rules, for eg uses energy minimization as loss function as compared to a convex optimization problem in deep ANNs. I am having difficulty understanding the math behind DBNs which relates to the question. Where do I start? Bayesian nets? I want to delve into the mathematics, as I found I learn way more from the equations than I do when someone tries to explain things to me in a hand wavey manner. Any help would be Nice. Thank you.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Edit: If instead of DBN let me know if I can do the same thing using a bidrectional RNN type architecture. i.e. to infer the probability of the inputs given the input. Also for my generative model I am using a Conditional generative model where instead of plain noise I am, along with the noise also giving it some input/context. I want to do the reverse to basically get the most likely context given something it have learn to generate. &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mzunrt,True,,protienbudspromax,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/mzunrt/where_can_i_learn_about_boltzmann_machines_from/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mzunrt/where_can_i_learn_about_boltzmann_machines_from/,66146,1619546824.0,0,,False,,,,,,,
,deeplearning,"Hi,

I'm looking for a Deep Learning Tutor for at least the next 2 months to start right away (virtual). The language and framework used would be Python and PyTorch and topics would include: multilayer perceptrons, convolutional neural networks, generative adversarial models, recurrent models and NLP.

I would pay handsomely for this position, of course.

If interested, please get back to me as soon as possible. Thanks!

PS - I am in the European time zone.",t2_bslmvsix,False,,0,False,Deep Learning Tutor,[],r/deeplearning,False,6,,0,,False,t3_mzo0kt,False,dark,0.87,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1619557520.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m looking for a Deep Learning Tutor for at least the next 2 months to start right away (virtual). The language and framework used would be Python and PyTorch and topics would include: multilayer perceptrons, convolutional neural networks, generative adversarial models, recurrent models and NLP.&lt;/p&gt;

&lt;p&gt;I would pay handsomely for this position, of course.&lt;/p&gt;

&lt;p&gt;If interested, please get back to me as soon as possible. Thanks!&lt;/p&gt;

&lt;p&gt;PS - I am in the European time zone.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mzo0kt,True,,JustAnEngineer6,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mzo0kt/deep_learning_tutor/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mzo0kt/deep_learning_tutor/,66146,1619528720.0,0,,False,,,,,,,
,deeplearning,,t2_66dqvlke,False,,0,False,Graph Convolutional Networks in Videos and 3D Point Clouds - Dr. Ali Thabet - Link to free zoom lecture by the author in comments,[],r/deeplearning,False,6,,0,,False,t3_mzs21j,False,dark,1.0,,public,2,1,{},,False,[],,True,False,,{},,False,2,,False,False,,False,,[],{'gid_1': 1},,False,,1619568922.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/2at5mkuqqqv61.png,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mzs21j,True,,dataskml,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mzs21j/graph_convolutional_networks_in_videos_and_3d/,all_ads,False,https://i.redd.it/2at5mkuqqqv61.png,66146,1619540122.0,0,,False,,,,,,,
,deeplearning,"I have a use case where I am supposed to use different tree bark cross section images like this:

&amp;#x200B;

[example image](https://preview.redd.it/uux881kk5rv61.jpg?width=487&amp;format=pjpg&amp;auto=webp&amp;s=b10d4e52da4fe5e4ce471b4a5e2a97216a6e73e0)

The goal is to have a CNN model to recognize the tree bark and then predict the tree from to which it belongs to? Do you have any such dataset/similar problem into which I can look into?

&amp;#x200B;

Thanks!",t2_2mmql89p,False,,0,False,Tree bark cross-section - CNN,[],r/deeplearning,False,6,,0,,False,t3_mzu0y9,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619574016.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a use case where I am supposed to use different tree bark cross section images like this:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/uux881kk5rv61.jpg?width=487&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b10d4e52da4fe5e4ce471b4a5e2a97216a6e73e0""&gt;example image&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The goal is to have a CNN model to recognize the tree bark and then predict the tree from to which it belongs to? Do you have any such dataset/similar problem into which I can look into?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mzu0y9,True,,grid_world,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mzu0y9/tree_bark_crosssection_cnn/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mzu0y9/tree_bark_crosssection_cnn/,66146,1619545216.0,0,,False,,,"{'uux881kk5rv61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 71, 'x': 108, 'u': 'https://preview.redd.it/uux881kk5rv61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4bafbcb641572aac770829f53d16607b1813b0c8'}, {'y': 143, 'x': 216, 'u': 'https://preview.redd.it/uux881kk5rv61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=81fe78c1cd940b8b9fba8e0f76738cd8685fe4e3'}, {'y': 212, 'x': 320, 'u': 'https://preview.redd.it/uux881kk5rv61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4effd81205b27f812c6b0bafe4a9c95e46a40fcb'}], 's': {'y': 323, 'x': 487, 'u': 'https://preview.redd.it/uux881kk5rv61.jpg?width=487&amp;format=pjpg&amp;auto=webp&amp;s=b10d4e52da4fe5e4ce471b4a5e2a97216a6e73e0'}, 'id': 'uux881kk5rv61'}}",,,,
,deeplearning,"Hi, I am recently introducing myself to Deep learning and I've reading some book. Aside from machine vision and natural language processing, I am interested on other applications, and I was wondering if you could create a deep neural network capable of analyzing processes, but in a different way from assembly (which from my understanding, is done through machine learning), but rather some project like introduction of a new workflow or the process of training employees for qualification in some software.
I know the question may be weird, but as a beginner, I am interested in understanding the capabilities of deep learning. Hope someone can help me out with this.
I thank you beforehand for reading this",t2_895aqwj2,False,,0,False,Can deep learning be used to evaluate projects?,[],r/deeplearning,False,6,,0,,False,t3_mzsh7a,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619570028.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I am recently introducing myself to Deep learning and I&amp;#39;ve reading some book. Aside from machine vision and natural language processing, I am interested on other applications, and I was wondering if you could create a deep neural network capable of analyzing processes, but in a different way from assembly (which from my understanding, is done through machine learning), but rather some project like introduction of a new workflow or the process of training employees for qualification in some software.
I know the question may be weird, but as a beginner, I am interested in understanding the capabilities of deep learning. Hope someone can help me out with this.
I thank you beforehand for reading this&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mzsh7a,True,,Demon__snake,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mzsh7a/can_deep_learning_be_used_to_evaluate_projects/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mzsh7a/can_deep_learning_be_used_to_evaluate_projects/,66146,1619541228.0,0,,False,,,,,,,
,deeplearning,"I am very beginners in deep learning world.
one thing that I couldn't know correctly is why a deep learning layer have many neurons if all the neurons are doing the same thing. they all receives the same numbers as their input.",t2_aqsb7ant,False,,0,False,deep learning neurons related silly question,[],r/deeplearning,False,6,,0,,False,t3_mzryti,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619568681.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am very beginners in deep learning world.
one thing that I couldn&amp;#39;t know correctly is why a deep learning layer have many neurons if all the neurons are doing the same thing. they all receives the same numbers as their input.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mzryti,True,,ehsan_sarshar_,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mzryti/deep_learning_neurons_related_silly_question/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mzryti/deep_learning_neurons_related_silly_question/,66146,1619539881.0,0,,False,,,,,,,
,deeplearning,"A research team from Google and the University of California, Berkeley calculates the energy use and carbon footprint of large-scale models T5, Meena, GShard, Switch Transformer and GPT-3, and identifies methods and publication guidelines that could help reduce their CO2e footprint.

Here is a quick read: [Google and UC Berkeley Propose Green Strategies for Large Neural Network Training](https://syncedreview.com/2021/04/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-5/).

The paper *Carbon Emissions and Large Neural Network Training* is on [arXiv](https://arxiv.org/ftp/arxiv/papers/2104/2104.10350.pdf).",t2_2fv4yodo,False,,0,False,[R] Google and UC Berkeley Propose Green Strategies for Large Neural Network Training,[],r/deeplearning,False,6,,0,,False,t3_mz1v2c,False,dark,0.96,,public,56,0,{},,False,[],,False,False,,{},,False,56,,False,False,,False,,[],{},,True,,1619483903.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Google and the University of California, Berkeley calculates the energy use and carbon footprint of large-scale models T5, Meena, GShard, Switch Transformer and GPT-3, and identifies methods and publication guidelines that could help reduce their CO2e footprint.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-5/""&gt;Google and UC Berkeley Propose Green Strategies for Large Neural Network Training&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Carbon Emissions and Large Neural Network Training&lt;/em&gt; is on &lt;a href=""https://arxiv.org/ftp/arxiv/papers/2104/2104.10350.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mz1v2c,True,,Yuqing7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mz1v2c/r_google_and_uc_berkeley_propose_green_strategies/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mz1v2c/r_google_and_uc_berkeley_propose_green_strategies/,66146,1619455103.0,0,,False,,,,,,,
,deeplearning,"Hello everyone! I'm about to start a side project in the data science field, but I don't know how to find a problem that needs to be solved. Can anyone show me the way that you implied whenever starting new a new side project?",t2_69zez810,False,,0,False,[D] How to find a problem to solve?,[],r/deeplearning,False,6,,0,,False,t3_mzkafz,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619543272.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone! I&amp;#39;m about to start a side project in the data science field, but I don&amp;#39;t know how to find a problem that needs to be solved. Can anyone show me the way that you implied whenever starting new a new side project?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mzkafz,True,,authorwong31,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mzkafz/d_how_to_find_a_problem_to_solve/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mzkafz/d_how_to_find_a_problem_to_solve/,66146,1619514472.0,0,,False,,,,,,,
,deeplearning,,t2_12gbh3,False,,0,False,[R] EigenGAN: Layer-Wise Eigen-Learning for GANs,[],r/deeplearning,False,6,,0,,False,t3_mzevkh,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1619520832.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/mzelum/r_eigengan_layerwise_eigenlearning_for_gans/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mzevkh,True,,LynnHoHZL,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mzevkh/r_eigengan_layerwise_eigenlearning_for_gans/,all_ads,False,/r/MachineLearning/comments/mzelum/r_eigengan_layerwise_eigenlearning_for_gans/,66146,1619492032.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'We post the paper and code of our new work EigenGAN which unsupervisedly learns hierarchical interpretable dimensions for GANs. Welcome to discuss.\n\nPaper: [https://arxiv.org/pdf/2104.12476.pdf](https://arxiv.org/pdf/2104.12476.pdf)\n\nCode: [https://github.com/LynnHo/EigenGAN-Tensorflow](https://github.com/LynnHo/EigenGAN-Tensorflow)\n\n&amp;#x200B;\n\n[Gender](https://i.redd.it/81csinpunmv61.gif)\n\n[Pose \\(Yaw\\)](https://i.redd.it/kf84ko6comv61.gif)\n\n&amp;#x200B;\n\n[Painting Style](https://i.redd.it/zncv9a3lomv61.gif)\n\n[Hue](https://i.redd.it/dl13laanomv61.gif)', 'author_fullname': 't2_12gbh3', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R] EigenGAN: Layer-Wise Eigen-Learning for GANs', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'81csinpunmv61': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/81csinpunmv61.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=9f3de7838028105e40802aa10e58be8311e19071'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/81csinpunmv61.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=b970ff1659652b775e8989c5cdcd5f4fd0ef55f9'}], 's': {'y': 313, 'gif': 'https://i.redd.it/81csinpunmv61.gif', 'mp4': 'https://preview.redd.it/81csinpunmv61.gif?format=mp4&amp;s=63de7eb92c3128fb775b26cb82aee8190dd3a132', 'x': 313}, 'id': '81csinpunmv61'}, 'zncv9a3lomv61': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/zncv9a3lomv61.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=b38b541a9a4fe01fad8cdb0d32c733829a173bb2'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/zncv9a3lomv61.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=7dcac56ccbc1759aedf02a9c0fdbdec2dab8c52d'}], 's': {'y': 313, 'gif': 'https://i.redd.it/zncv9a3lomv61.gif', 'mp4': 'https://preview.redd.it/zncv9a3lomv61.gif?format=mp4&amp;s=8fe4f981d412053f001b34248cf1c5991be92c4e', 'x': 313}, 'id': 'zncv9a3lomv61'}, 'kf84ko6comv61': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/kf84ko6comv61.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=a775dc8f470f713f821b16a0002c027b55a7df6a'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/kf84ko6comv61.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=4c2c0a9da6288010842a40bb6b76120d4b4ab0ab'}], 's': {'y': 313, 'gif': 'https://i.redd.it/kf84ko6comv61.gif', 'mp4': 'https://preview.redd.it/kf84ko6comv61.gif?format=mp4&amp;s=ddc81ef679470773a56fcb52cbecce60c0a3e0d1', 'x': 313}, 'id': 'kf84ko6comv61'}, 'dl13laanomv61': {'status': 'valid', 'e': 'AnimatedImage', 'm': 'image/gif', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/dl13laanomv61.gif?width=108&amp;crop=smart&amp;format=png8&amp;s=2acdb3f421efde0c82493294bbceed73a413b805'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/dl13laanomv61.gif?width=216&amp;crop=smart&amp;format=png8&amp;s=48eeb1da829a93054f44ebd4f2176ea28d7e663f'}], 's': {'y': 313, 'gif': 'https://i.redd.it/dl13laanomv61.gif', 'mp4': 'https://preview.redd.it/dl13laanomv61.gif?format=mp4&amp;s=c1274b7002a2550637320b13a1ff9753711e6763', 'x': 313}, 'id': 'dl13laanomv61'}}, 'name': 't3_mzelum', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.83, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 31, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 31, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': 1619501801.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1619519898.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We post the paper and code of our new work EigenGAN which unsupervisedly learns hierarchical interpretable dimensions for GANs. Welcome to discuss.&lt;/p&gt;\n\n&lt;p&gt;Paper: &lt;a href=""https://arxiv.org/pdf/2104.12476.pdf""&gt;https://arxiv.org/pdf/2104.12476.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Code: &lt;a href=""https://github.com/LynnHo/EigenGAN-Tensorflow""&gt;https://github.com/LynnHo/EigenGAN-Tensorflow&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://i.redd.it/81csinpunmv61.gif""&gt;Gender&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://i.redd.it/kf84ko6comv61.gif""&gt;Pose (Yaw)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://i.redd.it/zncv9a3lomv61.gif""&gt;Painting Style&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://i.redd.it/dl13laanomv61.gif""&gt;Hue&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mzelum', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'LynnHoHZL', 'discussion_type': None, 'num_comments': 17, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/mzelum/r_eigengan_layerwise_eigenlearning_for_gans/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/mzelum/r_eigengan_layerwise_eigenlearning_for_gans/', 'subreddit_subscribers': 1931389, 'created_utc': 1619491098.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_mzelum,,,,,
,deeplearning,,t2_auwgbh53,False,,0,False,Search images with text - An Open-Source project for cross-modal search,[],r/deeplearning,False,6,,0,,False,t3_mynzph,False,dark,0.94,,public,61,2,{},,False,[],,True,False,,{},,False,61,,False,True,,False,,[],{},,False,,1619434374.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/c79an1xcmfv61.jpg,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 200, 'id': 'award_1703f934-cf44-40cc-a96d-3729d0b48262', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=16&amp;height=16&amp;auto=webp&amp;s=e3adc32e42cf534e27afea719ff932b1ce797cfd', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=32&amp;height=32&amp;auto=webp&amp;s=08542909c94777e870c41a35413bce688ca2fd6c', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=48&amp;height=48&amp;auto=webp&amp;s=4d85746d584b5494087da3561944d6d241f57674', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=64&amp;height=64&amp;auto=webp&amp;s=fd7683c8de2839998a432e7e53e1e06d66c35ad3', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=128&amp;height=128&amp;auto=webp&amp;s=a750da7a573bb231bd863be9725abece0332b828', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'My kindergarten teacher, my cat, my mom, and you.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': ""I'd Like to Thank..."", 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=16&amp;height=16&amp;auto=webp&amp;s=e3adc32e42cf534e27afea719ff932b1ce797cfd', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=32&amp;height=32&amp;auto=webp&amp;s=08542909c94777e870c41a35413bce688ca2fd6c', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=48&amp;height=48&amp;auto=webp&amp;s=4d85746d584b5494087da3561944d6d241f57674', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=64&amp;height=64&amp;auto=webp&amp;s=fd7683c8de2839998a432e7e53e1e06d66c35ad3', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png?width=128&amp;height=128&amp;auto=webp&amp;s=a750da7a573bb231bd863be9725abece0332b828', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/8ad2jffnclf41_Thanks.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mynzph,True,,opensourcecolumbus,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/mynzph/search_images_with_text_an_opensource_project_for/,all_ads,False,https://i.redd.it/c79an1xcmfv61.jpg,66146,1619405574.0,1,,False,,,,,,,
,deeplearning,,t2_9lexstvu,False,,0,False,"[R] Google-Workshop: Conceptual Understanding of Deep Learning, May 17. Join Us.",[],r/deeplearning,False,6,,0,,False,t3_mz3bnr,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1619487707.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/myalnv/r_googleworkshop_conceptual_understanding_of_deep/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mz3bnr,True,,Rina-Panigrahy,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mz3bnr/r_googleworkshop_conceptual_understanding_of_deep/,all_ads,False,/r/MachineLearning/comments/myalnv/r_googleworkshop_conceptual_understanding_of_deep/,66146,1619458907.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Please join us for a virtual Google workshop on “[Conceptual Understanding of Deep Learning](https://sites.google.com/view/conceptualdlworkshop/home)”\xa0\n\n**When**:\xa0May 17th 9am-4pm PST.\xa0\n\n**Where**: [Live over Youtube](https://www.youtube.com/watch?v=g5DGBWjiULQ),\n\n**Goal:** How does the Brain/Mind (perhaps even an artificial one) work at an algorithmic level? While deep learning has produced tremendous technological strides in recent decades, there is an unsettling feeling of a lack of “conceptual” understanding of why it works and to what extent it will work in the current form. The goal of the workshop is to bring together theorists and practitioners to develop an understanding of the right algorithmic view of deep learning, characterizing the class of functions that can be learned, coming up with the right learning architecture that may (provably) learn multiple functions, concepts and remember them over time as humans do, theoretical understanding of language, logic, RL, meta learning and lifelong learning.\n\nThe speakers and panelists include **Turing award** winners Geoffrey Hinton, Leslie Valiant, and Godel Prize winner Christos Papadimitriou ([full-details](https://sites.google.com/corp/view/conceptualdlworkshop/home)).\xa0 \xa0\n\n**Panel Discussion:** There will also be a panel discussion on the fundamental question of “**Is there a mathematical model for the Mind**?”. We will explore basic questions such as “Is there a provable algorithm that captures the essential capabilities of the mind?”, “How do we remember complex phenomena?”, “How is a knowledge graph created automatically?”, “How do we learn new concepts, function and action hierarchies over time?” and “Why do human decisions seem so interpretable?”\n\nTwitter:[ \\#ConceptualDLWorkshop](https://twitter.com/search?q=%23ConceptualDLWorkshop&amp;src=recent_search_click). Please  [Retweet](https://twitter.com/rinapy/status/1384311169519788032).Hope to see you there!\n\nRina Panigrahy\n\n([http://theory.stanford.edu/\\~rinap](http://theory.stanford.edu/~rinap))', 'author_fullname': 't2_9lexstvu', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R] Google-Workshop: Conceptual Understanding of Deep Learning, May 17. Join Us.', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_myalnv', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.88, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 41, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 41, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': 1619407310.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1619393446.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Please join us for a virtual Google workshop on “&lt;a href=""https://sites.google.com/view/conceptualdlworkshop/home""&gt;Conceptual Understanding of Deep Learning&lt;/a&gt;”\xa0&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;When&lt;/strong&gt;:\xa0May 17th 9am-4pm PST.\xa0&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Where&lt;/strong&gt;: &lt;a href=""https://www.youtube.com/watch?v=g5DGBWjiULQ""&gt;Live over Youtube&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt; How does the Brain/Mind (perhaps even an artificial one) work at an algorithmic level? While deep learning has produced tremendous technological strides in recent decades, there is an unsettling feeling of a lack of “conceptual” understanding of why it works and to what extent it will work in the current form. The goal of the workshop is to bring together theorists and practitioners to develop an understanding of the right algorithmic view of deep learning, characterizing the class of functions that can be learned, coming up with the right learning architecture that may (provably) learn multiple functions, concepts and remember them over time as humans do, theoretical understanding of language, logic, RL, meta learning and lifelong learning.&lt;/p&gt;\n\n&lt;p&gt;The speakers and panelists include &lt;strong&gt;Turing award&lt;/strong&gt; winners Geoffrey Hinton, Leslie Valiant, and Godel Prize winner Christos Papadimitriou (&lt;a href=""https://sites.google.com/corp/view/conceptualdlworkshop/home""&gt;full-details&lt;/a&gt;).\xa0 \xa0&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Panel Discussion:&lt;/strong&gt; There will also be a panel discussion on the fundamental question of “&lt;strong&gt;Is there a mathematical model for the Mind&lt;/strong&gt;?”. We will explore basic questions such as “Is there a provable algorithm that captures the essential capabilities of the mind?”, “How do we remember complex phenomena?”, “How is a knowledge graph created automatically?”, “How do we learn new concepts, function and action hierarchies over time?” and “Why do human decisions seem so interpretable?”&lt;/p&gt;\n\n&lt;p&gt;Twitter:&lt;a href=""https://twitter.com/search?q=%23ConceptualDLWorkshop&amp;amp;src=recent_search_click""&gt; #ConceptualDLWorkshop&lt;/a&gt;. Please  &lt;a href=""https://twitter.com/rinapy/status/1384311169519788032""&gt;Retweet&lt;/a&gt;.Hope to see you there!&lt;/p&gt;\n\n&lt;p&gt;Rina Panigrahy&lt;/p&gt;\n\n&lt;p&gt;(&lt;a href=""http://theory.stanford.edu/%7Erinap""&gt;http://theory.stanford.edu/~rinap&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'myalnv', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Rina-Panigrahy', 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/myalnv/r_googleworkshop_conceptual_understanding_of_deep/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/myalnv/r_googleworkshop_conceptual_understanding_of_deep/', 'subreddit_subscribers': 1931389, 'created_utc': 1619364646.0, 'num_crossposts': 4, 'media': None, 'is_video': False}]",t3_myalnv,,,,,
,deeplearning,,t2_hkv9s,False,,0,False,Aspect-based Document Similarity for Research Papers (Research Paper Walkthrough),[],r/deeplearning,False,6,,0,,False,t3_myueo4,False,dark,0.88,,public,6,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/ZO6QWG7-Ye0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Aspect-based Document Similarity for Research Papers (Research Paper Walkthrough)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/ZO6QWG7-Ye0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/ZO6QWG7-Ye0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/ZO6QWG7-Ye0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/myueo4', 'height': 200}",,False,6,,False,False,,False,,[],{},,False,,1619460908.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/ZO6QWG7-Ye0,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,myueo4,True,,prakhar21,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/myueo4/aspectbased_document_similarity_for_research/,all_ads,False,https://youtu.be/ZO6QWG7-Ye0,66146,1619432108.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Aspect-based Document Similarity for Research Papers (Research Paper Walkthrough)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/ZO6QWG7-Ye0?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/ZO6QWG7-Ye0/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}}",False,,,,,,,
,deeplearning,"Hello all,

I am working with a neural net model project for school research team and as I was observing my models predictions, I've noticed some error prompting to empty tensors as seen in the images bellow:

https://preview.redd.it/0djkrrz3djv61.png?width=1622&amp;format=png&amp;auto=webp&amp;s=0c7ac2062daccf4681daa5fec89c48f4377635f7

&amp;#x200B;

https://preview.redd.it/1u6pbya5djv61.png?width=1330&amp;format=png&amp;auto=webp&amp;s=990969c83d7b58eff140d7525e3b77c9545068da

&amp;#x200B;

https://preview.redd.it/yc4gwu66djv61.png?width=2238&amp;format=png&amp;auto=webp&amp;s=ff06cb15df14c986c39058500fb150f614b61f94

You can see that the code stops processing where the highlighted empty tensor is and I am not sure how to go about fixing this problem. If anyone in this wonderful community can help it would mean a lot to my research progress.

&amp;#x200B;

Thank you all very much!",t2_9cq8fw1e,False,,0,False,what to do fix empty tensor error in neural net?,[],r/deeplearning,False,6,,0,,False,t3_mz09xs,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619479710.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all,&lt;/p&gt;

&lt;p&gt;I am working with a neural net model project for school research team and as I was observing my models predictions, I&amp;#39;ve noticed some error prompting to empty tensors as seen in the images bellow:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/0djkrrz3djv61.png?width=1622&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0c7ac2062daccf4681daa5fec89c48f4377635f7""&gt;https://preview.redd.it/0djkrrz3djv61.png?width=1622&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0c7ac2062daccf4681daa5fec89c48f4377635f7&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/1u6pbya5djv61.png?width=1330&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=990969c83d7b58eff140d7525e3b77c9545068da""&gt;https://preview.redd.it/1u6pbya5djv61.png?width=1330&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=990969c83d7b58eff140d7525e3b77c9545068da&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/yc4gwu66djv61.png?width=2238&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ff06cb15df14c986c39058500fb150f614b61f94""&gt;https://preview.redd.it/yc4gwu66djv61.png?width=2238&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ff06cb15df14c986c39058500fb150f614b61f94&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can see that the code stops processing where the highlighted empty tensor is and I am not sure how to go about fixing this problem. If anyone in this wonderful community can help it would mean a lot to my research progress.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you all very much!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mz09xs,True,,memgamemotron,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mz09xs/what_to_do_fix_empty_tensor_error_in_neural_net/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mz09xs/what_to_do_fix_empty_tensor_error_in_neural_net/,66146,1619450910.0,0,,False,,,"{'0djkrrz3djv61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 44, 'x': 108, 'u': 'https://preview.redd.it/0djkrrz3djv61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cb523d85ad06dac2ccb2948adf6cfea7b92f8664'}, {'y': 89, 'x': 216, 'u': 'https://preview.redd.it/0djkrrz3djv61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9c2077e0ba2b5a01206e9356996bc77a9d1fb849'}, {'y': 132, 'x': 320, 'u': 'https://preview.redd.it/0djkrrz3djv61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7d64023b7dff677d6dd640e10349643d970eaf54'}, {'y': 264, 'x': 640, 'u': 'https://preview.redd.it/0djkrrz3djv61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5aece7e77c70d725ca39437b0de0f1cb97de60a2'}, {'y': 396, 'x': 960, 'u': 'https://preview.redd.it/0djkrrz3djv61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=feaa30279cf2631a3045bc82c266bd8778f456b6'}, {'y': 446, 'x': 1080, 'u': 'https://preview.redd.it/0djkrrz3djv61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=770dd462c0bb96bb91e784f47cf73ededd219036'}], 's': {'y': 670, 'x': 1622, 'u': 'https://preview.redd.it/0djkrrz3djv61.png?width=1622&amp;format=png&amp;auto=webp&amp;s=0c7ac2062daccf4681daa5fec89c48f4377635f7'}, 'id': '0djkrrz3djv61'}, '1u6pbya5djv61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 115, 'x': 108, 'u': 'https://preview.redd.it/1u6pbya5djv61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=77ef5ca3969988a5090e8446ef868eff35fb297f'}, {'y': 231, 'x': 216, 'u': 'https://preview.redd.it/1u6pbya5djv61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8560592ca2ae02d9ea651aae10ff1bbde84f431e'}, {'y': 342, 'x': 320, 'u': 'https://preview.redd.it/1u6pbya5djv61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=90a95bfe7c91dc48485719f474ff1e57bf0ce5b7'}, {'y': 685, 'x': 640, 'u': 'https://preview.redd.it/1u6pbya5djv61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6b0c67ec755d18279f1df4c6d59fd470760e7ca9'}, {'y': 1027, 'x': 960, 'u': 'https://preview.redd.it/1u6pbya5djv61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3e7f12578da6459a4d00f2f86673f26fa02a253d'}, {'y': 1156, 'x': 1080, 'u': 'https://preview.redd.it/1u6pbya5djv61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cb7a7f9fa6443bf3a23c4f7f0ccdf3dc05dfd46b'}], 's': {'y': 1424, 'x': 1330, 'u': 'https://preview.redd.it/1u6pbya5djv61.png?width=1330&amp;format=png&amp;auto=webp&amp;s=990969c83d7b58eff140d7525e3b77c9545068da'}, 'id': '1u6pbya5djv61'}, 'yc4gwu66djv61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 49, 'x': 108, 'u': 'https://preview.redd.it/yc4gwu66djv61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0cb2ad116dcabf2906aaee926116b5386421f637'}, {'y': 99, 'x': 216, 'u': 'https://preview.redd.it/yc4gwu66djv61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=26725a4caa1a71c1223a1400494b1e5b254b2fbd'}, {'y': 147, 'x': 320, 'u': 'https://preview.redd.it/yc4gwu66djv61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b22c238d707e6b52bab0913aaef0625b5cd283c6'}, {'y': 295, 'x': 640, 'u': 'https://preview.redd.it/yc4gwu66djv61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=992b39c6af86c0c72cbbf7c3a5c7717012880cd8'}, {'y': 442, 'x': 960, 'u': 'https://preview.redd.it/yc4gwu66djv61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8cdccb6c8f66f4570e1b33e03fb8307f09dd3619'}, {'y': 498, 'x': 1080, 'u': 'https://preview.redd.it/yc4gwu66djv61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=db7fb091c0aae50624021813b68c73ff33b4e8aa'}], 's': {'y': 1032, 'x': 2238, 'u': 'https://preview.redd.it/yc4gwu66djv61.png?width=2238&amp;format=png&amp;auto=webp&amp;s=ff06cb15df14c986c39058500fb150f614b61f94'}, 'id': 'yc4gwu66djv61'}}",,,,
,deeplearning,"Shuffle Attention is probably the closest attention mechanism to achieving the right balance between computational overhead and performance boost. The SA-Net paper provides solid significant results along with a good background intuition to support the design choices. 

This article gives a comprehensive and comprehensible summary of the ICASSP paper titled ""SA-Net: Shuffle Attention for Deep Convolutional Neural Networks."" The paper proposes a novel attention mechanism known as ***Shuffle Attention***, which can be used in conventional backbones to improve performance at a minimal computational cost. PyTorch code included. 

Article link: [https://blog.paperspace.com/shuffle-attention-sanet/](https://blog.paperspace.com/shuffle-attention-sanet/)",t2_15en0l,False,,0,False,[Article] Shuffle Attention Mechanism Explained (SA-Net),[],r/deeplearning,False,6,,0,,False,t3_myzcqt,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619477304.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Shuffle Attention is probably the closest attention mechanism to achieving the right balance between computational overhead and performance boost. The SA-Net paper provides solid significant results along with a good background intuition to support the design choices. &lt;/p&gt;

&lt;p&gt;This article gives a comprehensive and comprehensible summary of the ICASSP paper titled &amp;quot;SA-Net: Shuffle Attention for Deep Convolutional Neural Networks.&amp;quot; The paper proposes a novel attention mechanism known as &lt;strong&gt;&lt;em&gt;Shuffle Attention&lt;/em&gt;&lt;/strong&gt;, which can be used in conventional backbones to improve performance at a minimal computational cost. PyTorch code included. &lt;/p&gt;

&lt;p&gt;Article link: &lt;a href=""https://blog.paperspace.com/shuffle-attention-sanet/""&gt;https://blog.paperspace.com/shuffle-attention-sanet/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,myzcqt,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/myzcqt/article_shuffle_attention_mechanism_explained/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/myzcqt/article_shuffle_attention_mechanism_explained/,66146,1619448504.0,0,,False,,,,,,,
,deeplearning,,t2_23p1xh,False,,0,False,[P] Entity Embed: fuzzy and scalable Entity Resolution using Approximate Nearest Neighbors,[],r/deeplearning,False,6,,0,,False,t3_myygki,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1619474802.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/myydgs/p_entity_embed_fuzzy_and_scalable_entity/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,myygki,True,,flaviojuvenal,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/myygki/p_entity_embed_fuzzy_and_scalable_entity/,all_ads,False,/r/MachineLearning/comments/myydgs/p_entity_embed_fuzzy_and_scalable_entity/,66146,1619446002.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': ""[https://github.com/vintasoftware/entity-embed](https://github.com/vintasoftware/entity-embed)\n\nEntity Embed is based on and is a special case of the [AutoBlock model described by Amazon](https://www.amazon.science/publications/autoblock-a-hands-off-blocking-framework-for-entity-matching).\n\nIt allows you to transform entities like companies, products, etc. into vectors to support **scalable Record Linkage / Entity Resolution using Approximate Nearest Neighbors.**\n\nUsing Entity Embed, you can train a deep learning model to transform records into vectors in an N-dimensional embedding space. Thanks to a contrastive loss, those vectors are organized to keep similar records close and dissimilar records far apart in this embedding space. Embedding records enables [scalable ANN search](http://ann-benchmarks.com/index.html), which means finding thousands of candidate duplicate pairs of records per second per CPU.\n\nThis is the first Deep Learning project we launch. Hope it's useful! Please feel free to reach me with feedbacks."", 'author_fullname': 't2_23p1xh', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[P] Entity Embed: fuzzy and scalable Entity Resolution using Approximate Nearest Neighbors', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_myydgs', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.78, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1619474563.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://github.com/vintasoftware/entity-embed""&gt;https://github.com/vintasoftware/entity-embed&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Entity Embed is based on and is a special case of the &lt;a href=""https://www.amazon.science/publications/autoblock-a-hands-off-blocking-framework-for-entity-matching""&gt;AutoBlock model described by Amazon&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;It allows you to transform entities like companies, products, etc. into vectors to support &lt;strong&gt;scalable Record Linkage / Entity Resolution using Approximate Nearest Neighbors.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Using Entity Embed, you can train a deep learning model to transform records into vectors in an N-dimensional embedding space. Thanks to a contrastive loss, those vectors are organized to keep similar records close and dissimilar records far apart in this embedding space. Embedding records enables &lt;a href=""http://ann-benchmarks.com/index.html""&gt;scalable ANN search&lt;/a&gt;, which means finding thousands of candidate duplicate pairs of records per second per CPU.&lt;/p&gt;\n\n&lt;p&gt;This is the first Deep Learning project we launch. Hope it&amp;#39;s useful! Please feel free to reach me with feedbacks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'myydgs', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'flaviojuvenal', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/myydgs/p_entity_embed_fuzzy_and_scalable_entity/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/myydgs/p_entity_embed_fuzzy_and_scalable_entity/', 'subreddit_subscribers': 1931389, 'created_utc': 1619445763.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_myydgs,,,,,
,deeplearning,"an intuition of what is ""neural variational inference learns to model the posterior probability"".

is there also something called VI learning for prior probability? and when would we use it?",t2_30pk81od,False,,0,False,"Can someone explaine what does ""neural variational inference learns to model the posterior probability""",[],r/deeplearning,False,6,,0,,False,t3_myxkiu,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619472213.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;an intuition of what is &amp;quot;neural variational inference learns to model the posterior probability&amp;quot;.&lt;/p&gt;

&lt;p&gt;is there also something called VI learning for prior probability? and when would we use it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,myxkiu,True,,untitledtotitled,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/myxkiu/can_someone_explaine_what_does_neural_variational/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/myxkiu/can_someone_explaine_what_does_neural_variational/,66146,1619443413.0,0,,False,,,,,,,
,deeplearning,"Hello all,

I am a currently pursuing my Phd in deep learning. Problem is that I having a serious trouble in finding a non-explored topic. Whenever I come up with an idea, I see that it has been done many times in the literature. I come up with another idea, the same again, again, and again...

Honestly I am getting a bit hopeless at the moment and I definitely don't want to drop my Phd. 

How do you find interesting and non-explored topics in deep learning ?

Any tip would be much appreciated. Thanks in advance.",t2_4hr82phs,False,,0,False,Finding a subject to work on for Phd thesis,[],r/deeplearning,False,6,,0,,False,t3_mywven,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619470086.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all,&lt;/p&gt;

&lt;p&gt;I am a currently pursuing my Phd in deep learning. Problem is that I having a serious trouble in finding a non-explored topic. Whenever I come up with an idea, I see that it has been done many times in the literature. I come up with another idea, the same again, again, and again...&lt;/p&gt;

&lt;p&gt;Honestly I am getting a bit hopeless at the moment and I definitely don&amp;#39;t want to drop my Phd. &lt;/p&gt;

&lt;p&gt;How do you find interesting and non-explored topics in deep learning ?&lt;/p&gt;

&lt;p&gt;Any tip would be much appreciated. Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mywven,True,,divisionby-zero,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/mywven/finding_a_subject_to_work_on_for_phd_thesis/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mywven/finding_a_subject_to_work_on_for_phd_thesis/,66146,1619441286.0,0,,False,,,,,,,
,deeplearning,,t2_9s825cre,False,,0,False,PerceptionRNN component of Waymo's ChauffeurNet predicts the trajectory of other cars. Here visualized in red is the past &amp; in green is the predicted future.,[],r/deeplearning,False,6,,0,,False,t3_myq9rc,False,dark,0.83,,public,4,0,{},,False,[],,True,False,,{},,False,4,,False,False,,False,,[],{},,False,,1619442992.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/cs5gxjist3v41,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,myq9rc,True,,perletzoo,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/myq9rc/perceptionrnn_component_of_waymos_chauffeurnet/,all_ads,False,https://v.redd.it/cs5gxjist3v41,66146,1619414192.0,0,,False,,,,,,,
,deeplearning,"As part of an internship, I have to build a biomedical knowledge graph from textual data, to do this I have to go through the tasks of named entity extraction and relation extraction as well as coreference resolution using BERT variant models. My problem is the availability of fine tune data for the three tasks.

Is there any open access datasets that I can use to fine tune my models in the three previous tasks in the biomedical domain?",t2_55lweil3,False,,0,False,Biomedical datasets suggestions for fine tuning Bert variant models on three tasks,[],r/deeplearning,False,6,,0,,False,t3_mywp2d,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619469502.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As part of an internship, I have to build a biomedical knowledge graph from textual data, to do this I have to go through the tasks of named entity extraction and relation extraction as well as coreference resolution using BERT variant models. My problem is the availability of fine tune data for the three tasks.&lt;/p&gt;

&lt;p&gt;Is there any open access datasets that I can use to fine tune my models in the three previous tasks in the biomedical domain?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mywp2d,True,,theweirdinstruction,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mywp2d/biomedical_datasets_suggestions_for_fine_tuning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mywp2d/biomedical_datasets_suggestions_for_fine_tuning/,66146,1619440702.0,0,,False,,,,,,,
,deeplearning,"Hi,

I am planning to build a Deep Learning server based on SuperMicro SYS-4029GP-TRT. And supported GPU's are

  \- RTX 4000

  \- RTX 5000

  \- RTX 6000

  \- RTX 8000

  \- A40

Which one is the best choice for deep learning training workloads. Essentially I will work on DRL tasks.",t2_7jhfzse,False,,0,False,I need help to choose the best GPU for deep learning.,[],r/deeplearning,False,6,,0,,False,t3_myvqvp,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619466200.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I am planning to build a Deep Learning server based on SuperMicro SYS-4029GP-TRT. And supported GPU&amp;#39;s are&lt;/p&gt;

&lt;p&gt;- RTX 4000&lt;/p&gt;

&lt;p&gt;- RTX 5000&lt;/p&gt;

&lt;p&gt;- RTX 6000&lt;/p&gt;

&lt;p&gt;- RTX 8000&lt;/p&gt;

&lt;p&gt;- A40&lt;/p&gt;

&lt;p&gt;Which one is the best choice for deep learning training workloads. Essentially I will work on DRL tasks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,myvqvp,True,,btahtaci,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/myvqvp/i_need_help_to_choose_the_best_gpu_for_deep/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/myvqvp/i_need_help_to_choose_the_best_gpu_for_deep/,66146,1619437400.0,0,,False,,,,,,,
,deeplearning,"The fastai Deep Learning Certificate  with the University of SAN FRANCISCO , is now free in Github

Course content covers an introduction to deep learning, fastai, and PyTorch.

fastai is a layered API for deep learning

fastbook project: [https://github.com/fastai/fastbook](https://github.com/fastai/fastbook)

Course: [https://www.usfca.edu/data-institute/certificates/deep-learning-part-one](https://www.usfca.edu/data-institute/certificates/deep-learning-part-one)

Added on 26 April:

The university certificate is worth 2K

but you can get all the python code/ ipynb  files free in the github link

fastbook project: [https://github.com/fastai/fastbook](https://github.com/fastai/fastbook)

Most of us are more keen on learning than the certificate, so thought this would be useful

The course link is to get some context to course outline/details.",t2_bivzwee,False,,0,False,Deep Learning Certificate -University of SAN FRANCISCO by FastAI (Jeremy Howard),[],r/deeplearning,False,6,,0,,False,t3_my64sd,False,dark,0.92,,public,61,0,{},,False,[],,False,False,,{},,False,61,,False,False,,False,,[],{},,True,,1619377675.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The fastai Deep Learning Certificate  with the University of SAN FRANCISCO , is now free in Github&lt;/p&gt;

&lt;p&gt;Course content covers an introduction to deep learning, fastai, and PyTorch.&lt;/p&gt;

&lt;p&gt;fastai is a layered API for deep learning&lt;/p&gt;

&lt;p&gt;fastbook project: &lt;a href=""https://github.com/fastai/fastbook""&gt;https://github.com/fastai/fastbook&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Course: &lt;a href=""https://www.usfca.edu/data-institute/certificates/deep-learning-part-one""&gt;https://www.usfca.edu/data-institute/certificates/deep-learning-part-one&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Added on 26 April:&lt;/p&gt;

&lt;p&gt;The university certificate is worth 2K&lt;/p&gt;

&lt;p&gt;but you can get all the python code/ ipynb  files free in the github link&lt;/p&gt;

&lt;p&gt;fastbook project: &lt;a href=""https://github.com/fastai/fastbook""&gt;https://github.com/fastai/fastbook&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Most of us are more keen on learning than the certificate, so thought this would be useful&lt;/p&gt;

&lt;p&gt;The course link is to get some context to course outline/details.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,my64sd,True,,QuackSK,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/my64sd/deep_learning_certificate_university_of_san/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/my64sd/deep_learning_certificate_university_of_san/,66146,1619348875.0,0,,False,,,,,,,
,deeplearning,,t2_2o7eaff,False,,0,False,Machine Learning with ML.NET - Sentiment Analysis,[],r/deeplearning,False,6,,0,,False,t3_mysgu5,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1619452468.0,text,6,,,text,rubikscode.net,False,,,,,https://rubikscode.net/2021/04/26/machine-learning-with-ml-net-sentiment-analysis/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mysgu5,True,,RubiksCodeNMZ,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mysgu5/machine_learning_with_mlnet_sentiment_analysis/,all_ads,False,https://rubikscode.net/2021/04/26/machine-learning-with-ml-net-sentiment-analysis/,66146,1619423668.0,0,,False,,,,,,,
,deeplearning,"So i'm trying to schedule an appointment for something.
Sadly all appointments are booked forever.
That is thanks to corporate agencies, who book all the appointments and are now selling them for profits!
I can snatch an appointment if it gets canceled but I need to be quick to beat them.
I made an auto clicker pattern that refreshes the site and scrolls through the calendar in the website up to 1 year from now, refreshes the page and so on forever.
Problem is i need to stare at the screen while this happens because i dont know machine learning.
Once an appintment frees up, the day on the calendar changes color.
Is it possible to make/use a program that will notify me when that happens so i can go back to my computer and book that appointment?
Thanks in advance folks",t2_auaoga15,False,,0,False,How do i beat those corporate agencies!?,[],r/deeplearning,False,6,,0,,False,t3_mywp3h,False,dark,0.29,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619469506.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So i&amp;#39;m trying to schedule an appointment for something.
Sadly all appointments are booked forever.
That is thanks to corporate agencies, who book all the appointments and are now selling them for profits!
I can snatch an appointment if it gets canceled but I need to be quick to beat them.
I made an auto clicker pattern that refreshes the site and scrolls through the calendar in the website up to 1 year from now, refreshes the page and so on forever.
Problem is i need to stare at the screen while this happens because i dont know machine learning.
Once an appintment frees up, the day on the calendar changes color.
Is it possible to make/use a program that will notify me when that happens so i can go back to my computer and book that appointment?
Thanks in advance folks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mywp3h,True,,AccordingSet5162,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mywp3h/how_do_i_beat_those_corporate_agencies/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mywp3h/how_do_i_beat_those_corporate_agencies/,66146,1619440706.0,0,,False,,,,,,,
,deeplearning,"GPU: RTX 3080

My path followed are as follows-:

1. I installed cuda\_11.3.0\_465.89\_win10
2. Then I downloaded the cudnn-11.3-windows-x64-v8.2.0.53 and set its path in env variable
3. Downloaded Visual Studio C++ 2017 and every related C++ library.
4. Created an env with Python 3.6 and installed TensorFlow GPU v2.4.1
5. And when tested with print(tf.test.is\_gpu\_available()) it returns false.

&amp;#x200B;

[Detailed Error](https://preview.redd.it/q66zsj8xfev61.png?width=1920&amp;format=png&amp;auto=webp&amp;s=c71a3618606a27b3219d0080fffa29c152052709)

&amp;#x200B;

(myenv) C:\\Windows\\system32&gt;python

Python 3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) \[MSC v.1916 64 bit (AMD64)\] on win32

Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

\&gt;&gt;&gt; import tensorflow

2021-04-26 03:42:11.038896: I tensorflow/stream\_executor/platform/default/dso\_loader.cc:49\] Successfully opened dynamic library cudart64\_110.dll

\&gt;&gt;&gt; exit()

&amp;#x200B;

(myenv) C:\\Windows\\system32&gt;python

Python 3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) \[MSC v.1916 64 bit (AMD64)\] on win32

Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

\&gt;&gt;&gt; import tensorflow as tf

2021-04-26 03:43:31.712130: I tensorflow/stream\_executor/platform/default/dso\_loader.cc:49\] Successfully opened dynamic library cudart64\_110.dll

\&gt;&gt;&gt; print(tf.test.is\_gpu\_available())

WARNING:tensorflow:From &lt;stdin&gt;:1: is\_gpu\_available (from tensorflow.python.framework.test\_util) is deprecated and will be removed in a future version.

Instructions for updating:

Use \`tf.config.list\_physical\_devices('GPU')\` instead.

2021-04-26 03:44:00.053496: I tensorflow/core/platform/cpu\_feature\_guard.cc:142\] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2

To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.

2021-04-26 03:44:00.056043: I tensorflow/stream\_executor/platform/default/dso\_loader.cc:49\] Successfully opened dynamic library nvcuda.dll

2021-04-26 03:44:00.075230: I tensorflow/core/common\_runtime/gpu/gpu\_device.cc:1720\] Found device 0 with properties:

pciBusID: 0000:2d:00.0 name: NVIDIA GeForce RTX 3080 computeCapability: 8.6

coreClock: 1.8GHz coreCount: 68 deviceMemorySize: 10.00GiB deviceMemoryBandwidth: 707.88GiB/s

2021-04-26 03:44:00.075336: I tensorflow/stream\_executor/platform/default/dso\_loader.cc:49\] Successfully opened dynamic library cudart64\_110.dll

2021-04-26 03:44:00.469809: I tensorflow/stream\_executor/platform/default/dso\_loader.cc:49\] Successfully opened dynamic library cublas64\_11.dll

2021-04-26 03:44:00.469895: I tensorflow/stream\_executor/platform/default/dso\_loader.cc:49\] Successfully opened dynamic library cublasLt64\_11.dll

2021-04-26 03:44:00.703672: I tensorflow/stream\_executor/platform/default/dso\_loader.cc:49\] Successfully opened dynamic library cufft64\_10.dll

2021-04-26 03:44:00.731218: I tensorflow/stream\_executor/platform/default/dso\_loader.cc:49\] Successfully opened dynamic library curand64\_10.dll

2021-04-26 03:44:00.731871: W tensorflow/stream\_executor/platform/default/dso\_loader.cc:60\] Could not load dynamic library 'cusolver64\_10.dll'; dlerror: cusolver64\_10.dll not found

2021-04-26 03:44:00.918279: I tensorflow/stream\_executor/platform/default/dso\_loader.cc:49\] Successfully opened dynamic library cusparse64\_11.dll

2021-04-26 03:44:00.933772: I tensorflow/stream\_executor/platform/default/dso\_loader.cc:49\] Successfully opened dynamic library cudnn64\_8.dll

2021-04-26 03:44:00.933848: W tensorflow/core/common\_runtime/gpu/gpu\_device.cc:1757\] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at [https://www.tensorflow.org/install/gpu](https://www.tensorflow.org/install/gpu) for how to download and setup the required libraries for your platform.

Skipping registering GPU devices...

2021-04-26 03:44:01.007572: I tensorflow/core/common\_runtime/gpu/gpu\_device.cc:1261\] Device interconnect StreamExecutor with strength 1 edge matrix:

2021-04-26 03:44:01.007645: I tensorflow/core/common\_runtime/gpu/gpu\_device.cc:1267\]      0

2021-04-26 03:44:01.008385: I tensorflow/core/common\_runtime/gpu/gpu\_device.cc:1280\] 0:   N

2021-04-26 03:44:01.008763: I tensorflow/compiler/jit/xla\_gpu\_device.cc:99\] Not creating XLA devices, tf\_xla\_enable\_xla\_devices not set

False

&amp;#x200B;

What should I do?",t2_7hgg4h0v,False,,0,False,Unable to detect RTX 3080 by Tensorflow (tensorflow_gpu-2.4.1) with cudnn-11.3-windows-x64-v8.2.0.53 and cuda_11.3.0_465.89_win10,[],r/deeplearning,False,6,,0,,False,t3_myjtiu,False,dark,0.85,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1619420145.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;GPU: RTX 3080&lt;/p&gt;

&lt;p&gt;My path followed are as follows-:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;I installed cuda_11.3.0_465.89_win10&lt;/li&gt;
&lt;li&gt;Then I downloaded the cudnn-11.3-windows-x64-v8.2.0.53 and set its path in env variable&lt;/li&gt;
&lt;li&gt;Downloaded Visual Studio C++ 2017 and every related C++ library.&lt;/li&gt;
&lt;li&gt;Created an env with Python 3.6 and installed TensorFlow GPU v2.4.1&lt;/li&gt;
&lt;li&gt;And when tested with print(tf.test.is_gpu_available()) it returns false.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/q66zsj8xfev61.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c71a3618606a27b3219d0080fffa29c152052709""&gt;Detailed Error&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;(myenv) C:\Windows\system32&amp;gt;python&lt;/p&gt;

&lt;p&gt;Python 3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)] on win32&lt;/p&gt;

&lt;p&gt;Type &amp;quot;help&amp;quot;, &amp;quot;copyright&amp;quot;, &amp;quot;credits&amp;quot; or &amp;quot;license&amp;quot; for more information.&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; import tensorflow&lt;/p&gt;

&lt;p&gt;2021-04-26 03:42:11.038896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; exit()&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;(myenv) C:\Windows\system32&amp;gt;python&lt;/p&gt;

&lt;p&gt;Python 3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)] on win32&lt;/p&gt;

&lt;p&gt;Type &amp;quot;help&amp;quot;, &amp;quot;copyright&amp;quot;, &amp;quot;credits&amp;quot; or &amp;quot;license&amp;quot; for more information.&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; import tensorflow as tf&lt;/p&gt;

&lt;p&gt;2021-04-26 03:43:31.712130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll&lt;/p&gt;

&lt;p&gt;&amp;gt;&amp;gt;&amp;gt; print(tf.test.is_gpu_available())&lt;/p&gt;

&lt;p&gt;WARNING:tensorflow:From &amp;lt;stdin&amp;gt;:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.&lt;/p&gt;

&lt;p&gt;Instructions for updating:&lt;/p&gt;

&lt;p&gt;Use `tf.config.list_physical_devices(&amp;#39;GPU&amp;#39;)` instead.&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:00.053496: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2&lt;/p&gt;

&lt;p&gt;To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:00.056043: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:00.075230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:&lt;/p&gt;

&lt;p&gt;pciBusID: 0000:2d:00.0 name: NVIDIA GeForce RTX 3080 computeCapability: 8.6&lt;/p&gt;

&lt;p&gt;coreClock: 1.8GHz coreCount: 68 deviceMemorySize: 10.00GiB deviceMemoryBandwidth: 707.88GiB/s&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:00.075336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:00.469809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:00.469895: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:00.703672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:00.731218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:00.731871: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library &amp;#39;cusolver64_10.dll&amp;#39;; dlerror: cusolver64_10.dll not found&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:00.918279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:00.933772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:00.933848: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at &lt;a href=""https://www.tensorflow.org/install/gpu""&gt;https://www.tensorflow.org/install/gpu&lt;/a&gt; for how to download and setup the required libraries for your platform.&lt;/p&gt;

&lt;p&gt;Skipping registering GPU devices...&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:01.007572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:01.007645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:01.008385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N&lt;/p&gt;

&lt;p&gt;2021-04-26 03:44:01.008763: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set&lt;/p&gt;

&lt;p&gt;False&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;What should I do?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,myjtiu,True,,-JuliusSeizure,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/myjtiu/unable_to_detect_rtx_3080_by_tensorflow/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/myjtiu/unable_to_detect_rtx_3080_by_tensorflow/,66146,1619391345.0,0,,False,,,"{'q66zsj8xfev61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 56, 'x': 108, 'u': 'https://preview.redd.it/q66zsj8xfev61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6e98725b7d444975112f582b75160b51f33da51f'}, {'y': 112, 'x': 216, 'u': 'https://preview.redd.it/q66zsj8xfev61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1c51a81f6fd117648b248b97c6126e45eb356732'}, {'y': 166, 'x': 320, 'u': 'https://preview.redd.it/q66zsj8xfev61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6cb8473ff06d117326a2fc37fe49afd8a946f470'}, {'y': 333, 'x': 640, 'u': 'https://preview.redd.it/q66zsj8xfev61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=afb98e8c86e9ec20092810ea710de2b30a2399fe'}, {'y': 499, 'x': 960, 'u': 'https://preview.redd.it/q66zsj8xfev61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=df13c436236aabc023bc276fb55e7e7c0aca4d09'}, {'y': 561, 'x': 1080, 'u': 'https://preview.redd.it/q66zsj8xfev61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1fc81b8c5db62f8724ded4f435cf070cc0495cfb'}], 's': {'y': 999, 'x': 1920, 'u': 'https://preview.redd.it/q66zsj8xfev61.png?width=1920&amp;format=png&amp;auto=webp&amp;s=c71a3618606a27b3219d0080fffa29c152052709'}, 'id': 'q66zsj8xfev61'}}",,,,
,deeplearning,,t2_7rkqf607,False,,0,False,[Project] DataTap provides droplets ( containers for datasets) to make working on popular deep learning datasets easy.,[],r/deeplearning,False,6,,0,,False,t3_myqyv4,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1619445944.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/myqyls/project_datatap_provides_droplets_containers_for/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,myqyv4,True,,Shoulder_Feeling,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/myqyv4/project_datatap_provides_droplets_containers_for/,all_ads,False,/r/MachineLearning/comments/myqyls/project_datatap_provides_droplets_containers_for/,66146,1619417144.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': 'Excited to share [DataTap](https://www.datatap.dev), An open-source dataset management tool that makes it easy to ""containerize"" datasets to let you  focus on machine learning not data ops.  DataTap lets you build data set droplets ( think of a droplet as a docker container for data ).  A droplet encapsulates a dataset that can then easily be used , imported, shared across different teams and projects.\n\nEach Data Droplet consists for 2 items\n\n* **Droplet Template**, similar to a docker file this specifies the dataset schema\n* **Dataset annotations, metadata and media** (this is typically images / videos / rich media )\n\nLearn more about how you can start using this here [https://github.com/zensors/datatap-python](https://github.com/zensors/datatap-python)\n\nMany machine learning projects use proprietary data formats that require tools and utilities to be re-written from scratch to accommodate them. Not only does this slow down development substantially, but it also increases the probability that developers introduce bugs in the very code that validates models’ performance.\n\nAs part of dataTap’s efforts to allow machine learning engineers to focus only on the machine learning itself, we introduced an open-source data interchange format called Droplet. The data container format, called “annotation,” provides a standardized way to describe what is in an image. DataTap is designed to be the data platform for Software 2.0. Machine learning on reach media like images , audio or video needs a special data pipeline to version and manage data much like there are MLOps tools to version and manage models\n\nCurrently the project has common datasets available that you can download or stream with 3 lines of code.\n\n* coco\n* Open-Imagees\n* AI food Dataset\n* Large Person Dataset\n* Combined Vehicles Dataset\n\nSee the full list \n\n[https://app.datatap.dev/databases/1b81ec5a-b880-4cf4-ba67-86e301cada9e](https://app.datatap.dev/databases/1b81ec5a-b880-4cf4-ba67-86e301cada9e)\n\nRequest Your own to be added in or use the open source tools to import data into the droplet format using this example\n\n[https://zensors.typeform.com/to/WXo3ZlSN](https://zensors.typeform.com/to/WXo3ZlSN)', 'author_fullname': 't2_7rkqf607', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[Project] DataTap provides droplets ( containers for datasets) to make working on popular deep learning datasets easy.', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_myqyls', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.8, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1619445914.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Excited to share &lt;a href=""https://www.datatap.dev""&gt;DataTap&lt;/a&gt;, An open-source dataset management tool that makes it easy to &amp;quot;containerize&amp;quot; datasets to let you  focus on machine learning not data ops.  DataTap lets you build data set droplets ( think of a droplet as a docker container for data ).  A droplet encapsulates a dataset that can then easily be used , imported, shared across different teams and projects.&lt;/p&gt;\n\n&lt;p&gt;Each Data Droplet consists for 2 items&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Droplet Template&lt;/strong&gt;, similar to a docker file this specifies the dataset schema&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Dataset annotations, metadata and media&lt;/strong&gt; (this is typically images / videos / rich media )&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Learn more about how you can start using this here &lt;a href=""https://github.com/zensors/datatap-python""&gt;https://github.com/zensors/datatap-python&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Many machine learning projects use proprietary data formats that require tools and utilities to be re-written from scratch to accommodate them. Not only does this slow down development substantially, but it also increases the probability that developers introduce bugs in the very code that validates models’ performance.&lt;/p&gt;\n\n&lt;p&gt;As part of dataTap’s efforts to allow machine learning engineers to focus only on the machine learning itself, we introduced an open-source data interchange format called Droplet. The data container format, called “annotation,” provides a standardized way to describe what is in an image. DataTap is designed to be the data platform for Software 2.0. Machine learning on reach media like images , audio or video needs a special data pipeline to version and manage data much like there are MLOps tools to version and manage models&lt;/p&gt;\n\n&lt;p&gt;Currently the project has common datasets available that you can download or stream with 3 lines of code.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;coco&lt;/li&gt;\n&lt;li&gt;Open-Imagees&lt;/li&gt;\n&lt;li&gt;AI food Dataset&lt;/li&gt;\n&lt;li&gt;Large Person Dataset&lt;/li&gt;\n&lt;li&gt;Combined Vehicles Dataset&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;See the full list &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://app.datatap.dev/databases/1b81ec5a-b880-4cf4-ba67-86e301cada9e""&gt;https://app.datatap.dev/databases/1b81ec5a-b880-4cf4-ba67-86e301cada9e&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Request Your own to be added in or use the open source tools to import data into the droplet format using this example&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://zensors.typeform.com/to/WXo3ZlSN""&gt;https://zensors.typeform.com/to/WXo3ZlSN&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'myqyls', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Shoulder_Feeling', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/myqyls/project_datatap_provides_droplets_containers_for/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/myqyls/project_datatap_provides_droplets_containers_for/', 'subreddit_subscribers': 1931389, 'created_utc': 1619417114.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_myqyls,,,,,
,deeplearning,"Not sure if this is the appropriate community, but I ran across something called a Synology Deep Learning NVR surveillance system. I’d love to get something like this, but can’t seem to find any available. Are there alternatives to a system like this? (An AI / Deep Learning NVR system that I could connect POE cameras to). Perhaps one could be made by leveraging existing code on GitHub and a home server? Maybe?",t2_bm8fj8l5,False,,0,False,Deep learning NVR Systems,[],r/deeplearning,False,6,,0,,False,t3_mym6sx,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619428024.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Not sure if this is the appropriate community, but I ran across something called a Synology Deep Learning NVR surveillance system. I’d love to get something like this, but can’t seem to find any available. Are there alternatives to a system like this? (An AI / Deep Learning NVR system that I could connect POE cameras to). Perhaps one could be made by leveraging existing code on GitHub and a home server? Maybe?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mym6sx,True,,WoodenWallaby6128,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mym6sx/deep_learning_nvr_systems/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mym6sx/deep_learning_nvr_systems/,66146,1619399224.0,0,,False,,,,,,,
,deeplearning,,t2_5fsp2x6v,False,,0,False,BERTweet (SOTA) for Named Entity Recognition in Social Media | Research Papers Summary 015,[],r/deeplearning,False,6,,0,,False,t3_myf8n0,False,dark,0.76,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/npxjcPhFLKE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'BERTweet (SOTA) for Named Entity Recognition in Social Media | Research Papers Summary 015', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/npxjcPhFLKE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Ryan Ong', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/npxjcPhFLKE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/basketball10029508'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/npxjcPhFLKE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/myf8n0', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1619406785.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/npxjcPhFLKE,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,myf8n0,True,,RyanAI100,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/myf8n0/bertweet_sota_for_named_entity_recognition_in/,all_ads,False,https://youtu.be/npxjcPhFLKE,66146,1619377985.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'BERTweet (SOTA) for Named Entity Recognition in Social Media | Research Papers Summary 015', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/npxjcPhFLKE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Ryan Ong', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/npxjcPhFLKE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/basketball10029508'}}",False,,,,,,,
,deeplearning,"Hello guys, how're you? I'm building a CNN and I must achieve &gt;=70% of accuracy, but I can´t do it over 0.5052, Could you help me please?",t2_4x0pvqtn,False,,0,False,Summary of my CNN,[],r/deeplearning,False,6,,0,,False,t3_mygl5z,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619410562.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello guys, how&amp;#39;re you? I&amp;#39;m building a CNN and I must achieve &amp;gt;=70% of accuracy, but I can´t do it over 0.5052, Could you help me please?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mygl5z,True,,fabiojr6,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mygl5z/summary_of_my_cnn/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mygl5z/summary_of_my_cnn/,66146,1619381762.0,0,,False,,,,,,,
,deeplearning,"Hey there,

I am wondering, say I got a trained DNN model that performs image classification as intended. What hardware is needed to run this model in real-time for video feed? Let's say 1920x1080 resolution videos for 24fps. During the execution, the model is not supposed to be further trained or tested at all.

Would it be possible to run this kind of model on a raspberry pi or does the execution of the model alone require an extensive GPU, CPU, RAM? What are the hardware requirements?

Edit: Thanks a lot to everyone! Your comments helped me a lot to think about my problem, the requirements and to evaluate the best way to achieve it.",t2_69srzkcq,False,,0,False,Hardware Requirements for real time classification?,[],r/deeplearning,False,6,,0,,False,t3_my2nc9,False,dark,0.82,,public,10,0,{},,False,[],,False,False,,{},,False,10,,False,False,,1619512202.0,,[],{},,True,,1619361641.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there,&lt;/p&gt;

&lt;p&gt;I am wondering, say I got a trained DNN model that performs image classification as intended. What hardware is needed to run this model in real-time for video feed? Let&amp;#39;s say 1920x1080 resolution videos for 24fps. During the execution, the model is not supposed to be further trained or tested at all.&lt;/p&gt;

&lt;p&gt;Would it be possible to run this kind of model on a raspberry pi or does the execution of the model alone require an extensive GPU, CPU, RAM? What are the hardware requirements?&lt;/p&gt;

&lt;p&gt;Edit: Thanks a lot to everyone! Your comments helped me a lot to think about my problem, the requirements and to evaluate the best way to achieve it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,my2nc9,True,,Dunkin_1,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/my2nc9/hardware_requirements_for_real_time_classification/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/my2nc9/hardware_requirements_for_real_time_classification/,66146,1619332841.0,0,,False,,,,,,,
,deeplearning,,t2_a88krsgs,False,,0,False,"[P] An introduction to PyKale https://github.com/pykale/pykale​, a PyTorch library that provides a unified pipeline-based API for knowledge-aware multimodal learning and transfer learning on graphs, images, texts, and videos to accelerate interdisciplinary research. Welcome feedback/contribution!",[],r/deeplearning,False,6,,0,,False,t3_mxu9oe,False,dark,0.86,,public,19,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/i5BYdMfbpMQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Introduction to PyKale, a library for knowledge-aware machine learning from multiple sources', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/i5BYdMfbpMQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Haiping Lu', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/i5BYdMfbpMQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/HaipingLu'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/i5BYdMfbpMQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mxu9oe', 'height': 200}",,False,19,,False,False,,False,,[],{},,False,,1619331051.0,text,6,,,text,youtube.com,False,,,,,https://youtube.com/watch?v=i5BYdMfbpMQ&amp;feature=share,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mxu9oe,True,,haipinglu,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mxu9oe/p_an_introduction_to_pykale/,all_ads,False,https://youtube.com/watch?v=i5BYdMfbpMQ&amp;feature=share,66146,1619302251.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Introduction to PyKale, a library for knowledge-aware machine learning from multiple sources', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/i5BYdMfbpMQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Haiping Lu', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/i5BYdMfbpMQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/HaipingLu'}}",False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '', 'author_fullname': 't2_a88krsgs', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[P] An introduction to PyKale https://github.com/pykale/pykale\u200b, a PyTorch library that provides a unified pipeline-based API for knowledge-aware multimodal learning and transfer learning on graphs, images, texts, and videos to accelerate interdisciplinary research. Welcome feedback/contribution!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mxtra6', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.84, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 30, 'total_awards_received': 0, 'media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/i5BYdMfbpMQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Introduction to PyKale, a library for knowledge-aware machine learning from multiple sources', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/i5BYdMfbpMQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Haiping Lu', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/i5BYdMfbpMQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/HaipingLu'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/i5BYdMfbpMQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mxtra6', 'height': 200}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 30, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1619329497.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtube.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://youtube.com/watch?v=i5BYdMfbpMQ&amp;feature=share', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mxtra6', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'haipinglu', 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/mxtra6/p_an_introduction_to_pykale/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://youtube.com/watch?v=i5BYdMfbpMQ&amp;feature=share', 'subreddit_subscribers': 1931389, 'created_utc': 1619300697.0, 'num_crossposts': 6, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Introduction to PyKale, a library for knowledge-aware machine learning from multiple sources', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/i5BYdMfbpMQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Haiping Lu', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/i5BYdMfbpMQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/HaipingLu'}}, 'is_video': False}]",t3_mxtra6,,,,,
,deeplearning,Is there any inbuilt library to perform Siamese network end to end??,t2_brb65ewe,False,,0,False,Doubt in a project,[],r/deeplearning,False,6,,0,,False,t3_mycax7,False,dark,0.25,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619398450.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is there any inbuilt library to perform Siamese network end to end??&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mycax7,True,,ml_quester,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mycax7/doubt_in_a_project/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mycax7/doubt_in_a_project/,66146,1619369650.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,Deep Nets: What have they ever done for Vision?,[],r/deeplearning,False,6,,0,,False,t3_my6svk,False,dark,0.43,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/GhPDNzAVNDk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Deep Nets: What have they ever done for Vision?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/GhPDNzAVNDk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/GhPDNzAVNDk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/GhPDNzAVNDk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/my6svk', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1619380482.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/GhPDNzAVNDk,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,my6svk,True,,OnlyProggingForFun,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/my6svk/deep_nets_what_have_they_ever_done_for_vision/,all_ads,False,https://youtu.be/GhPDNzAVNDk,66146,1619351682.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Deep Nets: What have they ever done for Vision?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/GhPDNzAVNDk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/GhPDNzAVNDk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,,,,,,,
,deeplearning,"I have a medical imaging dataset with 1000 labelled images and 5 classes. It is a multi-label classification problem, i.e. each sample can belong to multiple classes. Could I use MAML to learn to solve this one image classification task, or does MAML not make any sense because I only have one task?

Additionally, if I can use MAML, how would I set up the problem? Because it is a multi-label classification problem, do I treat each class as a separate task?

Thanks!",t2_15mvad,False,,0,False,MAML for Few-Shot Learning,[],r/deeplearning,False,6,,0,,False,t3_mxv5nz,False,dark,0.9,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1619333854.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a medical imaging dataset with 1000 labelled images and 5 classes. It is a multi-label classification problem, i.e. each sample can belong to multiple classes. Could I use MAML to learn to solve this one image classification task, or does MAML not make any sense because I only have one task?&lt;/p&gt;

&lt;p&gt;Additionally, if I can use MAML, how would I set up the problem? Because it is a multi-label classification problem, do I treat each class as a separate task?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mxv5nz,True,,alkaway,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/mxv5nz/maml_for_fewshot_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mxv5nz/maml_for_fewshot_learning/,66146,1619305054.0,0,,False,,,,,,,
,deeplearning,There seems to be so many variations across frameworks like pytorch tensorflow sklearb are there any rules of thumb?,t2_803tnh3u,False,,0,False,How do you remember the size of tensor you need for a specific problem?,[],r/deeplearning,False,6,,0,,False,t3_my3ukm,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619367397.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;There seems to be so many variations across frameworks like pytorch tensorflow sklearb are there any rules of thumb?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,my3ukm,True,,Striking_Exchange659,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/my3ukm/how_do_you_remember_the_size_of_tensor_you_need/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/my3ukm/how_do_you_remember_the_size_of_tensor_you_need/,66146,1619338597.0,0,,False,,,,,,,
,deeplearning,,t2_3r02kqm0,False,,0,False,Artificial intelligence composer (The Pianist AI) - Level 4: Try 2,[],r/deeplearning,False,6,,0,,False,t3_mxowt5,False,dark,0.75,,public,10,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pTc3yTu-KCU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Level 4: Try 2', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pTc3yTu-KCU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '[ The Pianist AI ]', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/pTc3yTu-KCU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ThePianistAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pTc3yTu-KCU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mxowt5', 'height': 200}",,False,10,,False,False,,False,,[],{},,False,,1619315065.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/pTc3yTu-KCU,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mxowt5,True,,amin_mlm,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mxowt5/artificial_intelligence_composer_the_pianist_ai/,all_ads,False,https://youtu.be/pTc3yTu-KCU,66146,1619286265.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Level 4: Try 2', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pTc3yTu-KCU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '[ The Pianist AI ]', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/pTc3yTu-KCU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ThePianistAI'}}",False,,,,,,,
,deeplearning,"# Generating Diverse High-Fidelity Images with VQ-VAE-2

The authors propose a novel hierarchical encoder-decoder model with discrete latent vectors that uses an autoregressive prior (PixelCNN) to sample diverse high quality samples.

[Here are some examples from the model](https://preview.redd.it/vmzcaympi4v61.png?width=1785&amp;format=png&amp;auto=webp&amp;s=0efb60478dcaf9947870d2281ab8db0adf9a920a)

\[[5 minute paper explanation](https://t.me/casual_gan/30)\] \[[Arxiv](https://arxiv.org/pdf/1906.00446.pdf)\]",t2_hhio3,False,,0,False,[D] Generating Diverse High-Fidelity Images with VQ-VAE-2 - Awesome discrete latent representations!,[],r/deeplearning,False,6,,0,,False,t3_mxk1j4,False,dark,0.86,,public,10,0,{},,False,[],,False,False,,{},,False,10,,False,False,,False,,[],{},,True,,1619299916.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h1&gt;Generating Diverse High-Fidelity Images with VQ-VAE-2&lt;/h1&gt;

&lt;p&gt;The authors propose a novel hierarchical encoder-decoder model with discrete latent vectors that uses an autoregressive prior (PixelCNN) to sample diverse high quality samples.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/vmzcaympi4v61.png?width=1785&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0efb60478dcaf9947870d2281ab8db0adf9a920a""&gt;Here are some examples from the model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/30""&gt;5 minute paper explanation&lt;/a&gt;] [&lt;a href=""https://arxiv.org/pdf/1906.00446.pdf""&gt;Arxiv&lt;/a&gt;]&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mxk1j4,True,,KirillTheMunchKing,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mxk1j4/d_generating_diverse_highfidelity_images_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mxk1j4/d_generating_diverse_highfidelity_images_with/,66146,1619271116.0,0,,False,,,"{'vmzcaympi4v61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 35, 'x': 108, 'u': 'https://preview.redd.it/vmzcaympi4v61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bb950d90660a7856f82a037834b5b5631e34c4f9'}, {'y': 71, 'x': 216, 'u': 'https://preview.redd.it/vmzcaympi4v61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b082cac5f16eee5435076ee6755957acb688cdc'}, {'y': 106, 'x': 320, 'u': 'https://preview.redd.it/vmzcaympi4v61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3752b3689e14fef5ad906defe3b2a9b7f6964d83'}, {'y': 212, 'x': 640, 'u': 'https://preview.redd.it/vmzcaympi4v61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd92ce056d954c36f8cda9ef86f1d801ee1f8c7a'}, {'y': 319, 'x': 960, 'u': 'https://preview.redd.it/vmzcaympi4v61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=dccefd0149025b90ccdcb728a7fdaf74a1664f21'}, {'y': 359, 'x': 1080, 'u': 'https://preview.redd.it/vmzcaympi4v61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9884262b613a988a14140b2560b7e0d5e5a2f697'}], 's': {'y': 594, 'x': 1785, 'u': 'https://preview.redd.it/vmzcaympi4v61.png?width=1785&amp;format=png&amp;auto=webp&amp;s=0efb60478dcaf9947870d2281ab8db0adf9a920a'}, 'id': 'vmzcaympi4v61'}}",,,,
,deeplearning,"I am using a ResNet-18 coded as follows:

    
    class ResidualBlock(nn.Module):
        '''
        Residual Block within a ResNet CNN model
        '''
        def __init__(self, input_channels, num_channels, 
                     use_1x1_conv = False, strides = 1):
            # super(ResidualBlock, self).__init__()
            super().__init__()
         
            self.conv1 = nn.Conv2d(
                in_channels = input_channels, out_channels = num_channels,
                kernel_size = 3, padding = 1, stride = strides,
                bias = False
                )
            self.bn1 = nn.BatchNorm2d(num_features = num_channels)
            
            self.conv2 = nn.Conv2d(
                in_channels = num_channels, out_channels = num_channels,
                kernel_size = 3, padding = 1, stride = 1,
                bias = False
                )
            self.bn2 = nn.BatchNorm2d(num_features = num_channels)
            
            if use_1x1_conv:
                self.conv3 = nn.Conv2d(
                    in_channels = input_channels, out_channels = num_channels,
                    kernel_size = 1, stride = strides
                    )
                self.bn3 = nn.BatchNorm2d(num_features = num_channels)
            else:
                self.conv3 = None
            
            self.relu = nn.ReLU(inplace = True)
    
            self.initialize_weights()
            
        
        def forward(self, X):
            Y = F.relu(self.bn1(self.conv1(X)))
            Y = self.bn2(self.conv2(Y))
            
            if self.conv3:
                X = self.bn3(self.conv3(X))
                # print(f""X.shape due to 1x1: {X.shape} &amp; Y.shape = {Y.shape}"")
            else:
                # print(f""X.shape without 1x1: {X.shape} &amp; Y.shape = {Y.shape}"")
                pass
            
            Y += X
            return F.relu(Y)
        
        
        def shape_computation(self, X):
            Y = self.conv1(X)
            print(f""self.conv1(X).shape: {Y.shape}"")
            Y = self.conv2(Y)
            print(f""self.conv2(X).shape: {Y.shape}"")
            
            if self.conv3:
                h = self.conv3(X)
                print(f""self.conv3(X).shape: {h.shape}"")
        
    
        def initialize_weights(self):
            for m in self.modules():
                # print(m)
                if isinstance(m, nn.Conv2d):
                    nn.init.kaiming_uniform_(m.weight)
    
                    '''
                    # Do not initialize bias (due to batchnorm)-
                    if m.bias is not None:
                        nn.init.constant_(m.bias, 0)
                    '''
                
                elif isinstance(m, nn.BatchNorm2d):
                    # Standard initialization for batch normalization-
                    nn.init.constant_(m.weight, 1)
                    nn.init.constant_(m.bias, 0)
    
                elif isinstance(m, nn.Linear):
                    nn.init.kaiming_normal_(m.weight)
                    nn.init.constant_(m.bias, 0)
    
    b0 = nn.Sequential(
        nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),
        nn.BatchNorm2d(num_features = 64),
        nn.ReLU())
    
    def create_resnet_block(input_filters, output_filters, num_residuals, first_block = False):
        # Python list to hold the created ResNet blocks-
        resnet_blk = []
        
        for i in range(num_residuals):
            if i == 0 and first_block:
                resnet_blk.append(ResidualBlock(input_channels = input_filters, num_channels = output_filters, use_1x1_conv = True, strides = 2))
            else:
                resnet_blk.append(ResidualBlock(input_channels = output_filters, num_channels = output_filters, use_1x1_conv = False, strides = 1))
        
        return resnet_blk
    
    b1 = nn.Sequential(*create_resnet_block(input_filters = 64, output_filters = 64, num_residuals = 2, first_block = True))
    
    b2 = nn.Sequential(*create_resnet_block(input_filters = 64, output_filters = 128, num_residuals = 2, first_block = True))
    
    b3 = nn.Sequential(*create_resnet_block(input_filters = 128, output_filters = 256, num_residuals = 2, first_block = True))
    
    b4 = nn.Sequential(*create_resnet_block(input_filters = 256, output_filters = 512, num_residuals = 2, first_block = True))
    
    # Initialize a ResNet-18 CNN model-
    model = nn.Sequential(
        b0, b1, b2, b3, b4,
        nn.AdaptiveAvgPool2d(output_size = (1, 1)),
        nn.Flatten(),
        nn.Linear(in_features = 512, out_features = 10))

The layer names are now as follows:

    for layer_name, param in trained_model.named_parameters():
        print(f""layer name: {layer_name} has {param.shape}"")
    

&gt;layer name: 0.0.weight has torch.Size(\[64, 3, 3, 3\])  
&gt;  
&gt;layer name: 0.0.bias has torch.Size(\[64\])  
&gt;  
&gt;layer name: 0.1.weight has torch.Size(\[64\])  
&gt;  
&gt;layer name: 0.1.bias has torch.Size(\[64\])  
&gt;  
&gt;layer name: 1.0.conv1.weight has torch.Size(\[64, 64, 3, 3\])  
&gt;  
&gt;layer name: 1.0.bn1.weight has torch.Size(\[64\])  
&gt;  
&gt;layer name: 1.0.bn1.bias has torch.Size(\[64\])  
&gt;  
&gt;layer name: 1.0.conv2.weight has torch.Size(\[64, 64, 3, 3\])  
&gt;  
&gt;layer name: 1.0.bn2.weight has torch.Size(\[64\])  
&gt;  
&gt;layer name: 1.0.bn2.bias has torch.Size(\[64\])  
&gt;  
&gt;layer name: 1.0.conv3.weight has torch.Size(\[64, 64, 1, 1\])  
&gt;  
&gt;layer name: 1.0.conv3.bias has torch.Size(\[64\])  
&gt;  
&gt;layer name: 1.0.bn3.weight has torch.Size(\[64\])  
&gt;  
&gt;layer name: 1.0.bn3.bias has torch.Size(\[64\])  
&gt;  
&gt;layer name: 1.1.conv1.weight has torch.Size(\[64, 64, 3, 3\])  
&gt;  
&gt;layer name: 1.1.bn1.weight has torch.Size(\[64\])  
&gt;  
&gt;layer name: 1.1.bn1.bias has torch.Size(\[64\])  
&gt;  
&gt;layer name: 1.1.conv2.weight has torch.Size(\[64, 64, 3, 3\])  
&gt;  
&gt;layer name: 1.1.bn2.weight has torch.Size(\[64\])  
&gt;  
&gt;layer name: 1.1.bn2.bias has torch.Size(\[64\])  
&gt;  
&gt;layer name: 2.0.conv1.weight has torch.Size(\[128, 64, 3, 3\])  
&gt;  
&gt;layer name: 2.0.bn1.weight has torch.Size(\[128\])  
&gt;  
&gt;layer name: 2.0.bn1.bias has torch.Size(\[128\])  
&gt;  
&gt;layer name: 2.0.conv2.weight has torch.Size(\[128, 128, 3, 3\])  
&gt;  
&gt;layer name: 2.0.bn2.weight has torch.Size(\[128\])  
&gt;  
&gt;layer name: 2.0.bn2.bias has torch.Size(\[128\])  
&gt;  
&gt;layer name: 2.0.conv3.weight has torch.Size(\[128, 64, 1, 1\])  
&gt;  
&gt;layer name: 2.0.conv3.bias has torch.Size(\[128\])  
&gt;  
&gt;layer name: 2.0.bn3.weight has torch.Size(\[128\])  
&gt;  
&gt;layer name: 2.0.bn3.bias has torch.Size(\[128\])  
&gt;  
&gt;layer name: 2.1.conv1.weight has torch.Size(\[128, 128, 3, 3\])  
&gt;  
&gt;layer name: 2.1.bn1.weight has torch.Size(\[128\])  
&gt;  
&gt;layer name: 2.1.bn1.bias has torch.Size(\[128\])  
&gt;  
&gt;layer name: 2.1.conv2.weight has torch.Size(\[128, 128, 3, 3\])  
&gt;  
&gt;layer name: 2.1.bn2.weight has torch.Size(\[128\])  
&gt;  
&gt;layer name: 2.1.bn2.bias has torch.Size(\[128\])  
&gt;  
&gt;layer name: 3.0.conv1.weight has torch.Size(\[256, 128, 3, 3\])  
&gt;  
&gt;layer name: 3.0.bn1.weight has torch.Size(\[256\])  
&gt;  
&gt;layer name: 3.0.bn1.bias has torch.Size(\[256\])  
&gt;  
&gt;layer name: 3.0.conv2.weight has torch.Size(\[256, 256, 3, 3\])  
&gt;  
&gt;layer name: 3.0.bn2.weight has torch.Size(\[256\])  
&gt;  
&gt;layer name: 3.0.bn2.bias has torch.Size(\[256\])  
&gt;  
&gt;layer name: 3.0.conv3.weight has torch.Size(\[256, 128, 1, 1\])  
&gt;  
&gt;layer name: 3.0.conv3.bias has torch.Size(\[256\])  
&gt;  
&gt;layer name: 3.0.bn3.weight has torch.Size(\[256\])  
&gt;  
&gt;layer name: 3.0.bn3.bias has torch.Size(\[256\])  
&gt;  
&gt;layer name: 3.1.conv1.weight has torch.Size(\[256, 256, 3, 3\])  
&gt;  
&gt;layer name: 3.1.bn1.weight has torch.Size(\[256\])  
&gt;  
&gt;layer name: 3.1.bn1.bias has torch.Size(\[256\])  
&gt;  
&gt;layer name: 3.1.conv2.weight has torch.Size(\[256, 256, 3, 3\])  
&gt;  
&gt;layer name: 3.1.bn2.weight has torch.Size(\[256\])  
&gt;  
&gt;layer name: 3.1.bn2.bias has torch.Size(\[256\])  
&gt;  
&gt;layer name: 4.0.conv1.weight has torch.Size(\[512, 256, 3, 3\])  
&gt;  
&gt;layer name: 4.0.bn1.weight has torch.Size(\[512\])  
&gt;  
&gt;layer name: 4.0.bn1.bias has torch.Size(\[512\])  
&gt;  
&gt;layer name: 4.0.conv2.weight has torch.Size(\[512, 512, 3, 3\])  
&gt;  
&gt;layer name: 4.0.bn2.weight has torch.Size(\[512\])  
&gt;  
&gt;layer name: 4.0.bn2.bias has torch.Size(\[512\])  
&gt;  
&gt;layer name: 4.0.conv3.weight has torch.Size(\[512, 256, 1, 1\])  
&gt;  
&gt;layer name: 4.0.conv3.bias has torch.Size(\[512\])  
&gt;  
&gt;layer name: 4.0.bn3.weight has torch.Size(\[512\])  
&gt;  
&gt;layer name: 4.0.bn3.bias has torch.Size(\[512\])  
&gt;  
&gt;layer name: 4.1.conv1.weight has torch.Size(\[512, 512, 3, 3\])  
&gt;  
&gt;layer name: 4.1.bn1.weight has torch.Size(\[512\])  
&gt;  
&gt;layer name: 4.1.bn1.bias has torch.Size(\[512\])  
&gt;  
&gt;layer name: 4.1.conv2.weight has torch.Size(\[512, 512, 3, 3\])  
&gt;  
&gt;layer name: 4.1.bn2.weight has torch.Size(\[512\])  
&gt;  
&gt;layer name: 4.1.bn2.bias has torch.Size(\[512\])  
&gt;  
&gt;layer name: 7.weight has torch.Size(\[10, 512\])  
&gt;  
&gt;layer name: 7.bias has torch.Size(\[10\])

&amp;#x200B;

In order to prune this model, I am referring to [PyTorch pruning tutorial](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#inspect-a-module). It's mentioned here that to prune a module/layer, use the following code:

&amp;#x200B;

    parameters_to_prune = (
        (model.conv1, 'weight'),
        (model.conv2, 'weight'),
        (model.fc1, 'weight'),
        (model.fc2, 'weight'),
        (model.fc3, 'weight'),
    )

But for the code above, the modules/layers no longer have this naming convention. For example, to prune the first conv layer of this model:

&gt;layer name: 0.0.weight has torch.Size(\[64, 3, 3, 3\])

&amp;#x200B;

on trying the following code:

    prune.random_unstructured(model.0.0, name = 'weight', amount = 0.3)

It gives me the error:

&gt;prune.random\_unstructured(trained\_model.0.0, name = 'weight', amount = 0.3)  
&gt;  
&gt;\^  
&gt;  
&gt;SyntaxError: invalid syntax

How do I handle this?",t2_2mmql89p,False,,0,False,Accessing modules - PyTorch ResNet-18,[],r/deeplearning,False,6,,0,,False,t3_mxlqsr,False,dark,0.63,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619305513.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am using a ResNet-18 coded as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class ResidualBlock(nn.Module):
    &amp;#39;&amp;#39;&amp;#39;
    Residual Block within a ResNet CNN model
    &amp;#39;&amp;#39;&amp;#39;
    def __init__(self, input_channels, num_channels, 
                 use_1x1_conv = False, strides = 1):
        # super(ResidualBlock, self).__init__()
        super().__init__()

        self.conv1 = nn.Conv2d(
            in_channels = input_channels, out_channels = num_channels,
            kernel_size = 3, padding = 1, stride = strides,
            bias = False
            )
        self.bn1 = nn.BatchNorm2d(num_features = num_channels)

        self.conv2 = nn.Conv2d(
            in_channels = num_channels, out_channels = num_channels,
            kernel_size = 3, padding = 1, stride = 1,
            bias = False
            )
        self.bn2 = nn.BatchNorm2d(num_features = num_channels)

        if use_1x1_conv:
            self.conv3 = nn.Conv2d(
                in_channels = input_channels, out_channels = num_channels,
                kernel_size = 1, stride = strides
                )
            self.bn3 = nn.BatchNorm2d(num_features = num_channels)
        else:
            self.conv3 = None

        self.relu = nn.ReLU(inplace = True)

        self.initialize_weights()


    def forward(self, X):
        Y = F.relu(self.bn1(self.conv1(X)))
        Y = self.bn2(self.conv2(Y))

        if self.conv3:
            X = self.bn3(self.conv3(X))
            # print(f&amp;quot;X.shape due to 1x1: {X.shape} &amp;amp; Y.shape = {Y.shape}&amp;quot;)
        else:
            # print(f&amp;quot;X.shape without 1x1: {X.shape} &amp;amp; Y.shape = {Y.shape}&amp;quot;)
            pass

        Y += X
        return F.relu(Y)


    def shape_computation(self, X):
        Y = self.conv1(X)
        print(f&amp;quot;self.conv1(X).shape: {Y.shape}&amp;quot;)
        Y = self.conv2(Y)
        print(f&amp;quot;self.conv2(X).shape: {Y.shape}&amp;quot;)

        if self.conv3:
            h = self.conv3(X)
            print(f&amp;quot;self.conv3(X).shape: {h.shape}&amp;quot;)


    def initialize_weights(self):
        for m in self.modules():
            # print(m)
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_uniform_(m.weight)

                &amp;#39;&amp;#39;&amp;#39;
                # Do not initialize bias (due to batchnorm)-
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
                &amp;#39;&amp;#39;&amp;#39;

            elif isinstance(m, nn.BatchNorm2d):
                # Standard initialization for batch normalization-
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

            elif isinstance(m, nn.Linear):
                nn.init.kaiming_normal_(m.weight)
                nn.init.constant_(m.bias, 0)

b0 = nn.Sequential(
    nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),
    nn.BatchNorm2d(num_features = 64),
    nn.ReLU())

def create_resnet_block(input_filters, output_filters, num_residuals, first_block = False):
    # Python list to hold the created ResNet blocks-
    resnet_blk = []

    for i in range(num_residuals):
        if i == 0 and first_block:
            resnet_blk.append(ResidualBlock(input_channels = input_filters, num_channels = output_filters, use_1x1_conv = True, strides = 2))
        else:
            resnet_blk.append(ResidualBlock(input_channels = output_filters, num_channels = output_filters, use_1x1_conv = False, strides = 1))

    return resnet_blk

b1 = nn.Sequential(*create_resnet_block(input_filters = 64, output_filters = 64, num_residuals = 2, first_block = True))

b2 = nn.Sequential(*create_resnet_block(input_filters = 64, output_filters = 128, num_residuals = 2, first_block = True))

b3 = nn.Sequential(*create_resnet_block(input_filters = 128, output_filters = 256, num_residuals = 2, first_block = True))

b4 = nn.Sequential(*create_resnet_block(input_filters = 256, output_filters = 512, num_residuals = 2, first_block = True))

# Initialize a ResNet-18 CNN model-
model = nn.Sequential(
    b0, b1, b2, b3, b4,
    nn.AdaptiveAvgPool2d(output_size = (1, 1)),
    nn.Flatten(),
    nn.Linear(in_features = 512, out_features = 10))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The layer names are now as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for layer_name, param in trained_model.named_parameters():
    print(f&amp;quot;layer name: {layer_name} has {param.shape}&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;layer name: 0.0.weight has torch.Size([64, 3, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 0.0.bias has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 0.1.weight has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 0.1.bias has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 1.0.conv1.weight has torch.Size([64, 64, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 1.0.bn1.weight has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 1.0.bn1.bias has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 1.0.conv2.weight has torch.Size([64, 64, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 1.0.bn2.weight has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 1.0.bn2.bias has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 1.0.conv3.weight has torch.Size([64, 64, 1, 1])  &lt;/p&gt;

&lt;p&gt;layer name: 1.0.conv3.bias has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 1.0.bn3.weight has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 1.0.bn3.bias has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 1.1.conv1.weight has torch.Size([64, 64, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 1.1.bn1.weight has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 1.1.bn1.bias has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 1.1.conv2.weight has torch.Size([64, 64, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 1.1.bn2.weight has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 1.1.bn2.bias has torch.Size([64])  &lt;/p&gt;

&lt;p&gt;layer name: 2.0.conv1.weight has torch.Size([128, 64, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 2.0.bn1.weight has torch.Size([128])  &lt;/p&gt;

&lt;p&gt;layer name: 2.0.bn1.bias has torch.Size([128])  &lt;/p&gt;

&lt;p&gt;layer name: 2.0.conv2.weight has torch.Size([128, 128, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 2.0.bn2.weight has torch.Size([128])  &lt;/p&gt;

&lt;p&gt;layer name: 2.0.bn2.bias has torch.Size([128])  &lt;/p&gt;

&lt;p&gt;layer name: 2.0.conv3.weight has torch.Size([128, 64, 1, 1])  &lt;/p&gt;

&lt;p&gt;layer name: 2.0.conv3.bias has torch.Size([128])  &lt;/p&gt;

&lt;p&gt;layer name: 2.0.bn3.weight has torch.Size([128])  &lt;/p&gt;

&lt;p&gt;layer name: 2.0.bn3.bias has torch.Size([128])  &lt;/p&gt;

&lt;p&gt;layer name: 2.1.conv1.weight has torch.Size([128, 128, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 2.1.bn1.weight has torch.Size([128])  &lt;/p&gt;

&lt;p&gt;layer name: 2.1.bn1.bias has torch.Size([128])  &lt;/p&gt;

&lt;p&gt;layer name: 2.1.conv2.weight has torch.Size([128, 128, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 2.1.bn2.weight has torch.Size([128])  &lt;/p&gt;

&lt;p&gt;layer name: 2.1.bn2.bias has torch.Size([128])  &lt;/p&gt;

&lt;p&gt;layer name: 3.0.conv1.weight has torch.Size([256, 128, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 3.0.bn1.weight has torch.Size([256])  &lt;/p&gt;

&lt;p&gt;layer name: 3.0.bn1.bias has torch.Size([256])  &lt;/p&gt;

&lt;p&gt;layer name: 3.0.conv2.weight has torch.Size([256, 256, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 3.0.bn2.weight has torch.Size([256])  &lt;/p&gt;

&lt;p&gt;layer name: 3.0.bn2.bias has torch.Size([256])  &lt;/p&gt;

&lt;p&gt;layer name: 3.0.conv3.weight has torch.Size([256, 128, 1, 1])  &lt;/p&gt;

&lt;p&gt;layer name: 3.0.conv3.bias has torch.Size([256])  &lt;/p&gt;

&lt;p&gt;layer name: 3.0.bn3.weight has torch.Size([256])  &lt;/p&gt;

&lt;p&gt;layer name: 3.0.bn3.bias has torch.Size([256])  &lt;/p&gt;

&lt;p&gt;layer name: 3.1.conv1.weight has torch.Size([256, 256, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 3.1.bn1.weight has torch.Size([256])  &lt;/p&gt;

&lt;p&gt;layer name: 3.1.bn1.bias has torch.Size([256])  &lt;/p&gt;

&lt;p&gt;layer name: 3.1.conv2.weight has torch.Size([256, 256, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 3.1.bn2.weight has torch.Size([256])  &lt;/p&gt;

&lt;p&gt;layer name: 3.1.bn2.bias has torch.Size([256])  &lt;/p&gt;

&lt;p&gt;layer name: 4.0.conv1.weight has torch.Size([512, 256, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 4.0.bn1.weight has torch.Size([512])  &lt;/p&gt;

&lt;p&gt;layer name: 4.0.bn1.bias has torch.Size([512])  &lt;/p&gt;

&lt;p&gt;layer name: 4.0.conv2.weight has torch.Size([512, 512, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 4.0.bn2.weight has torch.Size([512])  &lt;/p&gt;

&lt;p&gt;layer name: 4.0.bn2.bias has torch.Size([512])  &lt;/p&gt;

&lt;p&gt;layer name: 4.0.conv3.weight has torch.Size([512, 256, 1, 1])  &lt;/p&gt;

&lt;p&gt;layer name: 4.0.conv3.bias has torch.Size([512])  &lt;/p&gt;

&lt;p&gt;layer name: 4.0.bn3.weight has torch.Size([512])  &lt;/p&gt;

&lt;p&gt;layer name: 4.0.bn3.bias has torch.Size([512])  &lt;/p&gt;

&lt;p&gt;layer name: 4.1.conv1.weight has torch.Size([512, 512, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 4.1.bn1.weight has torch.Size([512])  &lt;/p&gt;

&lt;p&gt;layer name: 4.1.bn1.bias has torch.Size([512])  &lt;/p&gt;

&lt;p&gt;layer name: 4.1.conv2.weight has torch.Size([512, 512, 3, 3])  &lt;/p&gt;

&lt;p&gt;layer name: 4.1.bn2.weight has torch.Size([512])  &lt;/p&gt;

&lt;p&gt;layer name: 4.1.bn2.bias has torch.Size([512])  &lt;/p&gt;

&lt;p&gt;layer name: 7.weight has torch.Size([10, 512])  &lt;/p&gt;

&lt;p&gt;layer name: 7.bias has torch.Size([10])&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;In order to prune this model, I am referring to &lt;a href=""https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#inspect-a-module""&gt;PyTorch pruning tutorial&lt;/a&gt;. It&amp;#39;s mentioned here that to prune a module/layer, use the following code:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;parameters_to_prune = (
    (model.conv1, &amp;#39;weight&amp;#39;),
    (model.conv2, &amp;#39;weight&amp;#39;),
    (model.fc1, &amp;#39;weight&amp;#39;),
    (model.fc2, &amp;#39;weight&amp;#39;),
    (model.fc3, &amp;#39;weight&amp;#39;),
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But for the code above, the modules/layers no longer have this naming convention. For example, to prune the first conv layer of this model:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;layer name: 0.0.weight has torch.Size([64, 3, 3, 3])&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;on trying the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;prune.random_unstructured(model.0.0, name = &amp;#39;weight&amp;#39;, amount = 0.3)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It gives me the error:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;prune.random_unstructured(trained_model.0.0, name = &amp;#39;weight&amp;#39;, amount = 0.3)  &lt;/p&gt;

&lt;p&gt;^  &lt;/p&gt;

&lt;p&gt;SyntaxError: invalid syntax&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;How do I handle this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mxlqsr,True,,grid_world,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mxlqsr/accessing_modules_pytorch_resnet18/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mxlqsr/accessing_modules_pytorch_resnet18/,66146,1619276713.0,0,,False,,,,,,,
,deeplearning,"Hey, all

I have been trying to understand the PyTorch sine wave example given here: [example](https://github.com/pytorch/examples/tree/master/time_sequence_prediction)

It took me some time to digest what actually is happening and how the input/output pair is made in this.  
They have used LBFGS and have fed all the batches at once which might not be feasible in every case, thus I was trying to implement the same example using batched way and using Adam Optimizer.

I have also tweaked the Model structure a bit, now my model is like this:

    class Sequence(nn.Module):
        def __init__(self):
            super(Sequence, self).__init__()
            self.lstm1 = nn.LSTMCell(1, 50) #only 1 feature in input, 51 is no of features in hidden_state
            self.lstm2 = nn.LSTMCell(50, 50) #prev cell outputs 51, so this input is 51, and it outputs 51 (hidden_dim)
            self.linear = nn.Linear(50, 36) #takes 51 dim to predict 1 value
            self.relu = nn.ReLU()
            self.linear2 = nn.Linear(36, 24)
            self.linear3 = nn.Linear(24, 1)
            
        def forward(self, input, future = 0):
            outputs = []
            h_t = torch.zeros(input.size(0), 50, dtype = torch.double) #shape is 97x51 (batch,hidden_size)
            c_t = torch.zeros(input.size(0), 50, dtype = torch.double) #shape is 97x51 (batch,hidden_size)
            h_t2 = torch.zeros(input.size(0), 50, dtype = torch.double)
            c_t2 = torch.zeros(input.size(0), 50, dtype = torch.double)
            
            #hidden state and cell state are set to 0 in every new ""batch"" of examples
            
            for input_t in input.split(1, dim = 1): # input_t is of shape [batch_size,1], loop always runs for 999 times
                h_t, c_t = self.lstm1(input_t, (h_t, c_t))
                h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
                output = self.linear3(self.relu(self.linear2(self.relu(self.linear(h_t2))))) #output is of shape [batch_size, 1], for every time step t, output has (t+1)th value prediction for all sine waves
                outputs += [output]
            for i in range(future):
                h_t, c_t = self.lstm1(output, (h_t, c_t)) #
                h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
                output = self.linear3(self.relu(self.linear2(self.relu(self.linear(h_t2)))))
                #output = self.linear(h_t2)
                outputs += [output]
            outputs = torch.cat(outputs, dim = 1) #concat predictions across all timesteps from t1 to t999, and future
            return outputs

Optimizer:

`optim = torch.optim.Adam(seq.parameters(), lr = 0.08)`

Dataset:

    class seqDS(Dataset):
        def __init__(self, x, y):
            self.x = x
            self.y = y
            self.len = x.shape[0]
        def __getitem__(self, idx):
            return self.x[idx], self.y[idx]
        def __len__(self):
            return self.len
        
    ds = seqDS(input, target)

Loader:

`train_loader = DataLoader(ds, shuffle = False, batch_size = 16)`

Training Loop:

    for i in range(50):
        loss = 0.0
        num_len = 0
        seq.train()
        for x,y in train_loader:
            batch_size = x.shape[0]
            y_pred = seq(x)
            optim.zero_grad()
            loss = criterion(y_pred, y)
            loss.backward()
            optim.step()
            num_len += batch_size
            loss += (batch_size * loss.item())
        loss = loss / (num_len)
        print(f""Epoch {i+1}, Loss: {loss}"")
        
        with torch.no_grad():
            future = 1000
            pred = seq(test_input, future=future)
            loss = criterion(pred[:, :-future], test_target)
            print('test loss:', loss.item())
            print(""=========================="")
            y = pred.detach().numpy()
        
        plt.figure(figsize=(30,10))
        plt.title('Predict future values for time sequences\n(Dashlines are predicted values)', fontsize=30)
        plt.xlabel('x', fontsize=20)
        plt.ylabel('y', fontsize=20)
        plt.xticks(fontsize=20)
        plt.yticks(fontsize=20)
        def draw(yi, color):
            plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)
            plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)
        draw(y[0], 'r')
        draw(y[1], 'g')
        draw(y[2], 'b')
        plt.savefig('predict%d.pdf'%i)
        plt.close()

Now, as you can see from this plot below, the results are very disappointing and the model is not able to predict future values properly and even is not very accurate on predicting test set values that have the real ground truth labels.

I really want to go deep into this and understand what is actually happening and how can I fix this, LSTM is supposed to have a memory element due to cell state that’s what I know, and since the cell state used at time t = 0 is propagated to time t = 999, why it's still failing to predict the sine wave values for future times (after t = 1000) on the test set data?

Thank you so much for your time.

&amp;#x200B;

&amp;#x200B;

[Results](https://preview.redd.it/y4m3b9b1pyu61.png?width=1918&amp;format=png&amp;auto=webp&amp;s=778f99bb13fd97c3b31fb43f260526b7f0d251aa)",t2_lp891,False,,0,False,Pytorch LSTM: Sine Wave Prediction using Adam and batches,[],r/deeplearning,False,6,,0,,False,t3_mx13sf,False,dark,0.97,,public,21,0,{},,False,[],,False,False,,{},,False,21,,False,False,,False,,[],{},,True,,1619229441.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey, all&lt;/p&gt;

&lt;p&gt;I have been trying to understand the PyTorch sine wave example given here: &lt;a href=""https://github.com/pytorch/examples/tree/master/time_sequence_prediction""&gt;example&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It took me some time to digest what actually is happening and how the input/output pair is made in this.&lt;br/&gt;
They have used LBFGS and have fed all the batches at once which might not be feasible in every case, thus I was trying to implement the same example using batched way and using Adam Optimizer.&lt;/p&gt;

&lt;p&gt;I have also tweaked the Model structure a bit, now my model is like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Sequence(nn.Module):
    def __init__(self):
        super(Sequence, self).__init__()
        self.lstm1 = nn.LSTMCell(1, 50) #only 1 feature in input, 51 is no of features in hidden_state
        self.lstm2 = nn.LSTMCell(50, 50) #prev cell outputs 51, so this input is 51, and it outputs 51 (hidden_dim)
        self.linear = nn.Linear(50, 36) #takes 51 dim to predict 1 value
        self.relu = nn.ReLU()
        self.linear2 = nn.Linear(36, 24)
        self.linear3 = nn.Linear(24, 1)

    def forward(self, input, future = 0):
        outputs = []
        h_t = torch.zeros(input.size(0), 50, dtype = torch.double) #shape is 97x51 (batch,hidden_size)
        c_t = torch.zeros(input.size(0), 50, dtype = torch.double) #shape is 97x51 (batch,hidden_size)
        h_t2 = torch.zeros(input.size(0), 50, dtype = torch.double)
        c_t2 = torch.zeros(input.size(0), 50, dtype = torch.double)

        #hidden state and cell state are set to 0 in every new &amp;quot;batch&amp;quot; of examples

        for input_t in input.split(1, dim = 1): # input_t is of shape [batch_size,1], loop always runs for 999 times
            h_t, c_t = self.lstm1(input_t, (h_t, c_t))
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear3(self.relu(self.linear2(self.relu(self.linear(h_t2))))) #output is of shape [batch_size, 1], for every time step t, output has (t+1)th value prediction for all sine waves
            outputs += [output]
        for i in range(future):
            h_t, c_t = self.lstm1(output, (h_t, c_t)) #
            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))
            output = self.linear3(self.relu(self.linear2(self.relu(self.linear(h_t2)))))
            #output = self.linear(h_t2)
            outputs += [output]
        outputs = torch.cat(outputs, dim = 1) #concat predictions across all timesteps from t1 to t999, and future
        return outputs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Optimizer:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;optim = torch.optim.Adam(seq.parameters(), lr = 0.08)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Dataset:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class seqDS(Dataset):
    def __init__(self, x, y):
        self.x = x
        self.y = y
        self.len = x.shape[0]
    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]
    def __len__(self):
        return self.len

ds = seqDS(input, target)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Loader:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;train_loader = DataLoader(ds, shuffle = False, batch_size = 16)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Training Loop:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in range(50):
    loss = 0.0
    num_len = 0
    seq.train()
    for x,y in train_loader:
        batch_size = x.shape[0]
        y_pred = seq(x)
        optim.zero_grad()
        loss = criterion(y_pred, y)
        loss.backward()
        optim.step()
        num_len += batch_size
        loss += (batch_size * loss.item())
    loss = loss / (num_len)
    print(f&amp;quot;Epoch {i+1}, Loss: {loss}&amp;quot;)

    with torch.no_grad():
        future = 1000
        pred = seq(test_input, future=future)
        loss = criterion(pred[:, :-future], test_target)
        print(&amp;#39;test loss:&amp;#39;, loss.item())
        print(&amp;quot;==========================&amp;quot;)
        y = pred.detach().numpy()

    plt.figure(figsize=(30,10))
    plt.title(&amp;#39;Predict future values for time sequences\n(Dashlines are predicted values)&amp;#39;, fontsize=30)
    plt.xlabel(&amp;#39;x&amp;#39;, fontsize=20)
    plt.ylabel(&amp;#39;y&amp;#39;, fontsize=20)
    plt.xticks(fontsize=20)
    plt.yticks(fontsize=20)
    def draw(yi, color):
        plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)
        plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + &amp;#39;:&amp;#39;, linewidth = 2.0)
    draw(y[0], &amp;#39;r&amp;#39;)
    draw(y[1], &amp;#39;g&amp;#39;)
    draw(y[2], &amp;#39;b&amp;#39;)
    plt.savefig(&amp;#39;predict%d.pdf&amp;#39;%i)
    plt.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, as you can see from this plot below, the results are very disappointing and the model is not able to predict future values properly and even is not very accurate on predicting test set values that have the real ground truth labels.&lt;/p&gt;

&lt;p&gt;I really want to go deep into this and understand what is actually happening and how can I fix this, LSTM is supposed to have a memory element due to cell state that’s what I know, and since the cell state used at time t = 0 is propagated to time t = 999, why it&amp;#39;s still failing to predict the sine wave values for future times (after t = 1000) on the test set data?&lt;/p&gt;

&lt;p&gt;Thank you so much for your time.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/y4m3b9b1pyu61.png?width=1918&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=778f99bb13fd97c3b31fb43f260526b7f0d251aa""&gt;Results&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mx13sf,True,,Rohit901,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mx13sf/pytorch_lstm_sine_wave_prediction_using_adam_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mx13sf/pytorch_lstm_sine_wave_prediction_using_adam_and/,66146,1619200641.0,0,,False,,,"{'y4m3b9b1pyu61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 36, 'x': 108, 'u': 'https://preview.redd.it/y4m3b9b1pyu61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9fea871d961029de0d5c58f0e0070cfaa77caf2f'}, {'y': 72, 'x': 216, 'u': 'https://preview.redd.it/y4m3b9b1pyu61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=578313ee97f0ab5543fb8611106f9971a73df1ed'}, {'y': 107, 'x': 320, 'u': 'https://preview.redd.it/y4m3b9b1pyu61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6bdbd43fd21726e6d62c6d50237a94de68d2537d'}, {'y': 214, 'x': 640, 'u': 'https://preview.redd.it/y4m3b9b1pyu61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a7a2f23950319828209b51d6c53ff39cfeac95d7'}, {'y': 321, 'x': 960, 'u': 'https://preview.redd.it/y4m3b9b1pyu61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0df04f9b25ed2806ba8a0e1860c3b154e6b7a683'}, {'y': 361, 'x': 1080, 'u': 'https://preview.redd.it/y4m3b9b1pyu61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d1e85922f9a33ec679fef928a837a8635c958471'}], 's': {'y': 642, 'x': 1918, 'u': 'https://preview.redd.it/y4m3b9b1pyu61.png?width=1918&amp;format=png&amp;auto=webp&amp;s=778f99bb13fd97c3b31fb43f260526b7f0d251aa'}, 'id': 'y4m3b9b1pyu61'}}",,,,
,deeplearning,I wanna know the benefits in fine-tuning BERT for sentiment analysis instead of training my own LSTM structure. Thanks.,t2_b4brgrl5,False,,0,False,Fine-tuning BERT instead of training my own LSTM for sentiment analysis,[],r/deeplearning,False,6,,0,,False,t3_mx1k7i,False,dark,0.79,,public,11,0,{},,False,[],,False,False,,{},,False,11,,False,False,,False,,[],{},,True,,1619230663.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I wanna know the benefits in fine-tuning BERT for sentiment analysis instead of training my own LSTM structure. Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mx1k7i,True,,Testost3r0ne,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mx1k7i/finetuning_bert_instead_of_training_my_own_lstm/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mx1k7i/finetuning_bert_instead_of_training_my_own_lstm/,66146,1619201863.0,0,,False,,,,,,,
,deeplearning,"I plan to purchase a new laptop (Dell G5 15 SE) which has the RX 5600M GPU. However,  on a lot of forums I read that Deep Learning on AMD GPUs is a pain due to them not being supported by CUDA. I'm unable to get more knowledge about his issue and whether it can be solved or no, so any kind of consult would be appreciated.",t2_5j70u6vu,False,,0,False,How problematic is doing deep learning on an AMD GPU,[],r/deeplearning,False,6,,0,,False,t3_mx4ujt,False,dark,0.87,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1619240021.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I plan to purchase a new laptop (Dell G5 15 SE) which has the RX 5600M GPU. However,  on a lot of forums I read that Deep Learning on AMD GPUs is a pain due to them not being supported by CUDA. I&amp;#39;m unable to get more knowledge about his issue and whether it can be solved or no, so any kind of consult would be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mx4ujt,True,,diontrevorc,,14,True,all_ads,False,[],False,,/r/deeplearning/comments/mx4ujt/how_problematic_is_doing_deep_learning_on_an_amd/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mx4ujt/how_problematic_is_doing_deep_learning_on_an_amd/,66146,1619211221.0,0,,False,,,,,,,
,deeplearning,"Hello everyone,

Due to covid and bitcoin price of GPU's are increased a lot. So, I have compiled PyTorch, Magma, and Torchvision especially for Cuda Compute Capability 3.0 GPU's. It was for my friend's laptop but I thought it would be good to share. In addition, it is also possible to install OpenCV from conda-forge at the same time (I removed jpeg&lt;=9b dependency constraint)

You can install the packages in an empty environment with this command. Make sure packages are pulling from modwalker channel.

`conda install -c modwalker -c conda-forge pytorch magma-cuda101 torchvision opencv`

Output of `torch.__config__.show()` :

        PyTorch built with:
          - GCC 7.3
          - C++ Version: 201402
          - Intel(R) Math Kernel Library Version 2020.0.4 Product Build 20200917 for Intel(R) 64 architecture applications
          - Intel
          - Intel(R) Math Kernel Library Version 2020.0.4 Product Build 20200917 for Intel(R) 64 architecture applications
          - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
          - OpenMP 201511 (a.k.a. OpenMP 4.5)
          - NNPACK is enabled
          - CPU capability usage: AVX2
          - CUDA Runtime 10.1
          - NVCC architecture flags: -gencode;arch=compute_30,code=sm_30
          - CuDNN 7.6.5
          - Magma 2.5.2
          - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=1, USE_CUDNN=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,

I also tried to prepare a guide but it is not clear and many file modifications are needed: [https://github.com/salihmarangoz/UbuntuTweaks/blob/18.04/docs/InstallAnaconda/conda\_pytorch.md](https://github.com/salihmarangoz/UbuntuTweaks/blob/18.04/docs/InstallAnaconda/conda_pytorch.md)",t2_4wuj99q2,False,,0,False,"PyTorch 1.8.1 Conda Package for Linux, Cuda 10.1, Cuda Compute Capability 3.0 (old GPU's)",[],r/deeplearning,False,6,,0,,False,t3_mwsvw0,False,dark,0.91,,public,28,0,{},,False,[],,False,False,,{},,False,28,,False,False,,1619215981.0,,[],{},,True,,1619205084.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;Due to covid and bitcoin price of GPU&amp;#39;s are increased a lot. So, I have compiled PyTorch, Magma, and Torchvision especially for Cuda Compute Capability 3.0 GPU&amp;#39;s. It was for my friend&amp;#39;s laptop but I thought it would be good to share. In addition, it is also possible to install OpenCV from conda-forge at the same time (I removed jpeg&amp;lt;=9b dependency constraint)&lt;/p&gt;

&lt;p&gt;You can install the packages in an empty environment with this command. Make sure packages are pulling from modwalker channel.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;conda install -c modwalker -c conda-forge pytorch magma-cuda101 torchvision opencv&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Output of &lt;code&gt;torch.__config__.show()&lt;/code&gt; :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    PyTorch built with:
      - GCC 7.3
      - C++ Version: 201402
      - Intel(R) Math Kernel Library Version 2020.0.4 Product Build 20200917 for Intel(R) 64 architecture applications
      - Intel
      - Intel(R) Math Kernel Library Version 2020.0.4 Product Build 20200917 for Intel(R) 64 architecture applications
      - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)
      - OpenMP 201511 (a.k.a. OpenMP 4.5)
      - NNPACK is enabled
      - CPU capability usage: AVX2
      - CUDA Runtime 10.1
      - NVCC architecture flags: -gencode;arch=compute_30,code=sm_30
      - CuDNN 7.6.5
      - Magma 2.5.2
      - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=1, USE_CUDNN=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I also tried to prepare a guide but it is not clear and many file modifications are needed: &lt;a href=""https://github.com/salihmarangoz/UbuntuTweaks/blob/18.04/docs/InstallAnaconda/conda_pytorch.md""&gt;https://github.com/salihmarangoz/UbuntuTweaks/blob/18.04/docs/InstallAnaconda/conda_pytorch.md&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwsvw0,True,,sutlusalca,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mwsvw0/pytorch_181_conda_package_for_linux_cuda_101_cuda/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mwsvw0/pytorch_181_conda_package_for_linux_cuda_101_cuda/,66146,1619176284.0,0,,False,,,,,,,
,deeplearning,"Given the following conditions:
- I have images which all contain an object of interest
- the 2D pixel coordinates of 4 boundary points of the object are known (training data)
- there is only one type of object which I want to find, say a painting on a wall

Is it possible to use a neural net structure which has convolution layers in the start which then ends in one final layer which outputs the coordinates of the corner points of the object? 

I have a feeling that a conv net wouldn't be able to do this since it is more used for classification than for locating the boundary points of an object. 

Just to be clear , all training and test images contain the object , the problem that needs to be solved is: find a mapping from the image, to the 4 coordinates giving the location of the corners of the object.",t2_dt78jv2,False,,0,False,Question about CNNs,[],r/deeplearning,False,6,,0,,False,t3_mx9dcd,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619254682.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Given the following conditions:
- I have images which all contain an object of interest
- the 2D pixel coordinates of 4 boundary points of the object are known (training data)
- there is only one type of object which I want to find, say a painting on a wall&lt;/p&gt;

&lt;p&gt;Is it possible to use a neural net structure which has convolution layers in the start which then ends in one final layer which outputs the coordinates of the corner points of the object? &lt;/p&gt;

&lt;p&gt;I have a feeling that a conv net wouldn&amp;#39;t be able to do this since it is more used for classification than for locating the boundary points of an object. &lt;/p&gt;

&lt;p&gt;Just to be clear , all training and test images contain the object , the problem that needs to be solved is: find a mapping from the image, to the 4 coordinates giving the location of the corners of the object.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mx9dcd,True,,10rth0d0x,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mx9dcd/question_about_cnns/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mx9dcd/question_about_cnns/,66146,1619225882.0,0,,False,,,,,,,
,deeplearning,"Object detection models like Faster R-CNN and Mask R-CNN generate thousands of region proposals, where typically only a handful of objects might exist. Sometimes it's easier if you can help guide these models to the correct areas of interest.

In this tutorial we'll show how you can do just that, with full Python code included. Directed Mask R-CNN allows you to specify regions where the model should look for objects. Reducing the number of region proposals that the model processes reduces the computational time of the model.

Topics covered in this tutorial include:

1. Overview of the R-CNN Model
2. Region Proposals
3. Manipulating Regions Produced by the Region Proposal Network (RPN)
4. Directed Mask R-CNN
5. References

Tutorial link: [https://blog.paperspace.com/object-detection-directed-mask-r-cnn-keras/](https://blog.paperspace.com/object-detection-directed-mask-r-cnn-keras/)",t2_15en0l,False,,0,False,[Tutorial] How to Implement Directed Mask R-CNN with Keras,[],r/deeplearning,False,6,,0,,False,t3_mwzjvj,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1619225222.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Object detection models like Faster R-CNN and Mask R-CNN generate thousands of region proposals, where typically only a handful of objects might exist. Sometimes it&amp;#39;s easier if you can help guide these models to the correct areas of interest.&lt;/p&gt;

&lt;p&gt;In this tutorial we&amp;#39;ll show how you can do just that, with full Python code included. Directed Mask R-CNN allows you to specify regions where the model should look for objects. Reducing the number of region proposals that the model processes reduces the computational time of the model.&lt;/p&gt;

&lt;p&gt;Topics covered in this tutorial include:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Overview of the R-CNN Model&lt;/li&gt;
&lt;li&gt;Region Proposals&lt;/li&gt;
&lt;li&gt;Manipulating Regions Produced by the Region Proposal Network (RPN)&lt;/li&gt;
&lt;li&gt;Directed Mask R-CNN&lt;/li&gt;
&lt;li&gt;References&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Tutorial link: &lt;a href=""https://blog.paperspace.com/object-detection-directed-mask-r-cnn-keras/""&gt;https://blog.paperspace.com/object-detection-directed-mask-r-cnn-keras/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwzjvj,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mwzjvj/tutorial_how_to_implement_directed_mask_rcnn_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mwzjvj/tutorial_how_to_implement_directed_mask_rcnn_with/,66146,1619196422.0,0,,False,,,,,,,
,deeplearning,,t2_6dro04fq,False,,0,False,"""I've never met this man in my life""",[],r/deeplearning,False,6,,0,,False,t3_mw2ro8,False,dark,0.96,,public,286,0,{},,False,[],,True,False,,{},,False,286,,False,True,,False,,[],{},,False,,1619120127.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/jzyej8k9opu61.jpg,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mw2ro8,True,,alexein777,,18,True,all_ads,False,[],False,,/r/deeplearning/comments/mw2ro8/ive_never_met_this_man_in_my_life/,all_ads,False,https://i.redd.it/jzyej8k9opu61.jpg,66146,1619091327.0,0,,False,,,,,,,
,deeplearning,,t2_8dh42jtc,False,,0,False,Deep learning generated art changes with the music,[],r/deeplearning,False,6,,0,,False,t3_mx072m,False,dark,0.67,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/7al5umMwprc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Spring Mood | Lofi Hip Hop | AI generated art', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/7al5umMwprc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Deep Style Beats', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/7al5umMwprc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCgDEhsKghkAsRklgopG4JxA'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/7al5umMwprc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mx072m', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1619226972.0,text,6,,,text,youtube.com,False,,,,,https://youtube.com/watch?v=7al5umMwprc&amp;feature=share,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mx072m,True,,deep_style_beats,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mx072m/deep_learning_generated_art_changes_with_the_music/,all_ads,False,https://youtube.com/watch?v=7al5umMwprc&amp;feature=share,66146,1619198172.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Spring Mood | Lofi Hip Hop | AI generated art', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/7al5umMwprc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Deep Style Beats', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/7al5umMwprc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCgDEhsKghkAsRklgopG4JxA'}}",False,,,,,,,
,deeplearning,"Hey all 
I had recently borrowed by brothers macbook air 2017 edition 
Its new

But as gpu isn’t there in mac 
How do u guys work on mac 
On running large datasets the mac is getting up heated and fans sound are high
And ut takes a hell lot of time to process


Any suggestions 
Or can any mac user solve this 
Thanks in advance !!!
Please help",t2_7re0ejya,False,,0,False,DL in MacOS,[],r/deeplearning,False,6,,0,,False,t3_mwzbqw,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619224615.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey all 
I had recently borrowed by brothers macbook air 2017 edition 
Its new&lt;/p&gt;

&lt;p&gt;But as gpu isn’t there in mac 
How do u guys work on mac 
On running large datasets the mac is getting up heated and fans sound are high
And ut takes a hell lot of time to process&lt;/p&gt;

&lt;p&gt;Any suggestions 
Or can any mac user solve this 
Thanks in advance !!!
Please help&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwzbqw,True,,Notbot_18,,16,True,all_ads,False,[],False,,/r/deeplearning/comments/mwzbqw/dl_in_macos/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mwzbqw/dl_in_macos/,66146,1619195815.0,0,,False,,,,,,,
,deeplearning,"A research team from McGill University, Mila - Quebec AI Institute and Facebook AI proposes novel metrics and perturbation functions to detect, quantify and compare trade-offs between robustness and faithfulness in NMT systems, both on the corpus level and with particular examples.

Here is a quick read: [Facebook AI, McGill U &amp; Mila Promote 'Translationese' to Boost NMT System Faithfulness.](https://syncedreview.com/2021/04/23/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-4/)

 The paper *Sometimes We Want Translationese* is on [arXiv](https://arxiv.org/pdf/2104.07623.pdf).",t2_2fv4yodo,False,,0,False,"[R] Facebook AI, McGill U &amp; Mila Promote 'Translationese' to Boost NMT System Faithfulness",[],r/deeplearning,False,6,,0,,False,t3_mwy5fd,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619221424.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from McGill University, Mila - Quebec AI Institute and Facebook AI proposes novel metrics and perturbation functions to detect, quantify and compare trade-offs between robustness and faithfulness in NMT systems, both on the corpus level and with particular examples.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/23/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-4/""&gt;Facebook AI, McGill U &amp;amp; Mila Promote &amp;#39;Translationese&amp;#39; to Boost NMT System Faithfulness.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Sometimes We Want Translationese&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.07623.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwy5fd,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mwy5fd/r_facebook_ai_mcgill_u_mila_promote/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mwy5fd/r_facebook_ai_mcgill_u_mila_promote/,66146,1619192624.0,0,,False,,,,,,,
,deeplearning,,t2_12wlg9,False,,0,False,"Yannic Kilcher - Adversarial Examples, AI Bias &amp; Memes | Podcast #49",[],r/deeplearning,False,6,,0,,False,t3_mwwkoo,False,dark,0.44,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Htc8FPd02Yw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Yannic Kilcher - Adversarial Examples, AI Bias &amp; Memes | Podcast #49', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Htc8FPd02Yw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Jousef Murad', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Htc8FPd02Yw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/TheEngiineer'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Htc8FPd02Yw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mwwkoo', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1619217113.0,text,6,,,text,youtube.com,False,,,,,https://youtube.com/watch?v=Htc8FPd02Yw,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwwkoo,True,,g-x91,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mwwkoo/yannic_kilcher_adversarial_examples_ai_bias_memes/,all_ads,False,https://youtube.com/watch?v=Htc8FPd02Yw,66146,1619188313.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Yannic Kilcher - Adversarial Examples, AI Bias &amp; Memes | Podcast #49', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Htc8FPd02Yw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Jousef Murad', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Htc8FPd02Yw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/TheEngiineer'}}",False,,,,,,,
,deeplearning,"Anyone here completed any data science boot camps from Metis, flatiron, brain station, general assembly and others? I’m looking to see if these are legit and if they’ve helped you land a job in data science after completing the boot camps. They advertise a 92% hire rate from top tech companies, so curious if anyone can contribute any thoughts.",t2_9cq8fw1e,False,,0,False,Data science and ML bootcamp credibility check,[],r/deeplearning,False,6,,0,,False,t3_mwuvdr,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619212108.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Anyone here completed any data science boot camps from Metis, flatiron, brain station, general assembly and others? I’m looking to see if these are legit and if they’ve helped you land a job in data science after completing the boot camps. They advertise a 92% hire rate from top tech companies, so curious if anyone can contribute any thoughts.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwuvdr,True,,memgamemotron,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mwuvdr/data_science_and_ml_bootcamp_credibility_check/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mwuvdr/data_science_and_ml_bootcamp_credibility_check/,66146,1619183308.0,0,,False,,,,,,,
,deeplearning,"I will be starting project a on time series anomaly detection. Is there any good book based on time series.
Any recommendation would be highly appreciated.",t2_14xp3pns,False,,0,False,Books for time series?,[],r/deeplearning,False,6,,0,,False,t3_mwr6cd,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619197667.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I will be starting project a on time series anomaly detection. Is there any good book based on time series.
Any recommendation would be highly appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwr6cd,True,,holybitchkiller,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mwr6cd/books_for_time_series/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mwr6cd/books_for_time_series/,66146,1619168867.0,0,,False,,,,,,,
,deeplearning,"I am trying to use the ResNet50 network in order to perform the task of image classification for cats and dogs. However after trying a few example, it seems that the model is able to predict the image without any training. I thought the whole point of the model was to train it on a set of images with the correct labels, and then test it on the rest of the images. Or did I misunderstand..",t2_2muvh5aa,False,,0,False,What does it mean to train a pretrained model (ResNet50)?,[],r/deeplearning,False,6,,0,,False,t3_mwqbef,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619193680.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to use the ResNet50 network in order to perform the task of image classification for cats and dogs. However after trying a few example, it seems that the model is able to predict the image without any training. I thought the whole point of the model was to train it on a set of images with the correct labels, and then test it on the rest of the images. Or did I misunderstand..&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwqbef,True,,highwiz10,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mwqbef/what_does_it_mean_to_train_a_pretrained_model/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mwqbef/what_does_it_mean_to_train_a_pretrained_model/,66146,1619164880.0,0,,False,,,,,,,
,deeplearning,"I'm a complete noob at neural networks, yet am very interested in its use of generating music.

**So I have a few questions:**

1. What is currently highest accomplishment in terms of neural AI generating music? Seems like it's ""lost tapes of the 27th club"". Apparently they used Google AI generate new Amy Winehouse and Hendrix songs. I can no longer find those songs on Youtube, maybe because of copyright issues.

Where should I start to learn more about this AI, its ramifications, use and how to use it to generate songs on my own? Are there any guides for this?

2. When do you expect AI will have reached level where average person will be able to pay for processing power to run AI that would generate new music based on their ""favourite"" playlist and would generate music that is actually AS GOOD or BETTER than the originals?

2. What affect do you think AI will have on the composer, music industry in general?

Any resources on this, learning courses, tutorials specifically in regards to music generation by AI, please share :)",t2_8lcrnf72,False,,0,False,What is the current status of using Neural Networks to compose music? And future?,[],r/deeplearning,False,6,,0,,False,t3_mwpzzq,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619192191.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m a complete noob at neural networks, yet am very interested in its use of generating music.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;So I have a few questions:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;What is currently highest accomplishment in terms of neural AI generating music? Seems like it&amp;#39;s &amp;quot;lost tapes of the 27th club&amp;quot;. Apparently they used Google AI generate new Amy Winehouse and Hendrix songs. I can no longer find those songs on Youtube, maybe because of copyright issues.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Where should I start to learn more about this AI, its ramifications, use and how to use it to generate songs on my own? Are there any guides for this?&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;When do you expect AI will have reached level where average person will be able to pay for processing power to run AI that would generate new music based on their &amp;quot;favourite&amp;quot; playlist and would generate music that is actually AS GOOD or BETTER than the originals?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What affect do you think AI will have on the composer, music industry in general?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Any resources on this, learning courses, tutorials specifically in regards to music generation by AI, please share :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwpzzq,True,,WallStreetVids,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mwpzzq/what_is_the_current_status_of_using_neural/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mwpzzq/what_is_the_current_status_of_using_neural/,66146,1619163391.0,0,,False,,,,,,,
,deeplearning,"I'm building a budget workstation and the current option is between the 3060 with 12GB of VRAM vs the 3070 with 8GB. 

I'm doing my thesis in Graph Neural Networks and I'm worried the 8GB of VRAM on the 3070 won't be enough for the GNNs. I am unsure how to estimate size of the model because I haven't started training it and therefore do not know the number of layers. 

I would really appreciate any assistance in making this decision because I'd be able to move forward in my thesis.",t2_86r2a3qf,False,,0,False,RTX 3060 vs RTX 3070 For GNNs,[],r/deeplearning,False,6,,0,,False,t3_mwryzo,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619201305.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m building a budget workstation and the current option is between the 3060 with 12GB of VRAM vs the 3070 with 8GB. &lt;/p&gt;

&lt;p&gt;I&amp;#39;m doing my thesis in Graph Neural Networks and I&amp;#39;m worried the 8GB of VRAM on the 3070 won&amp;#39;t be enough for the GNNs. I am unsure how to estimate size of the model because I haven&amp;#39;t started training it and therefore do not know the number of layers. &lt;/p&gt;

&lt;p&gt;I would really appreciate any assistance in making this decision because I&amp;#39;d be able to move forward in my thesis.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwryzo,True,,soicyboii,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mwryzo/rtx_3060_vs_rtx_3070_for_gnns/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mwryzo/rtx_3060_vs_rtx_3070_for_gnns/,66146,1619172505.0,0,,False,,,,,,,
,deeplearning,,t2_966w1giy,False,,0,False,Data Cleaning Processes using Pandas (for textual datasets),[],r/deeplearning,False,6,,0,,False,t3_mwvnxx,False,dark,0.25,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1619214535.0,text,6,,,text,medium.com,False,,,,,https://medium.com/analytics-vidhya/data-cleaning-101-b3d29223f256,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwvnxx,True,,SahilFruitwala,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mwvnxx/data_cleaning_processes_using_pandas_for_textual/,all_ads,False,https://medium.com/analytics-vidhya/data-cleaning-101-b3d29223f256,66146,1619185735.0,0,,False,,,,,,,
,deeplearning,,t2_4h10zbbc,False,,0,False,How do convolutional neural networks works. Short summary article on convolutional neural networks.,[],r/deeplearning,False,6,,0,,False,t3_mwo453,False,dark,0.29,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1619184148.0,text,6,,,text,codeperfectplus.herokuapp.com,False,,,,,https://codeperfectplus.herokuapp.com/how-do-convolutional-neural-networks-work,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwo453,True,,perfect9015,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mwo453/how_do_convolutional_neural_networks_works_short/,all_ads,False,https://codeperfectplus.herokuapp.com/how-do-convolutional-neural-networks-work,66146,1619155348.0,0,,False,,,,,,,
,deeplearning,Hello I wanted to know if anyone knows where I can find a Google Coral. I need it for a personal project but I can't find it anywhere... Thanks for your help! See you soon!,t2_2zm0tksr,False,,0,False,Where can I find a Google Coral?,[],r/deeplearning,False,6,,0,,False,t3_mwgmd2,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1619159367.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello I wanted to know if anyone knows where I can find a Google Coral. I need it for a personal project but I can&amp;#39;t find it anywhere... Thanks for your help! See you soon!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwgmd2,True,,jijoi124,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/mwgmd2/where_can_i_find_a_google_coral/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mwgmd2/where_can_i_find_a_google_coral/,66146,1619130567.0,0,,False,,,,,,,
,deeplearning,"In this course I will teach you 8 agents including:

· Space Invaders Agent using Keras-RL

· Autonomous Taxi using Q-Learning built from scratch

· Flappy Bird Agent using Deep Q Network that we build from scratch

· Mario Agent using Deep Q Network that we build from scratch

· A reinforcement Learning S&amp;P 500 stock trading agent that is rewarded with making money off the stock market!

· Another Reinforcement Learning Stock Trading Agent using 89 different Technical indicators (you can pair these to make a lot of money off the stock market 😉) 

· 3 Car agents that learn to maneuver roundabouts, parking lots, &amp; merge onto a highway

The only thing you need to know is Python! If you are interested in cutting edge technology, then this is the course for you! Check it out! 

[https://www.udemy.com/course/practical-reinforcement-learning/?couponCode=150336130778173C0A71](https://www.udemy.com/course/practical-reinforcement-learning/?couponCode=150336130778173C0A71)",t2_823gdb34,False,,0,False,"Hello World!!! I built a Course on Udemy where I teach you how to build 8 reinforcement learning agents in environments like Mario, Flappy Bird, Stocks and Much More!! You only need to know Python! (FREE FOR LIMITED TIME)",[],r/deeplearning,False,6,,0,,False,t3_mvqqes,False,dark,0.8,,public,47,0,{},,False,[],,False,False,,{},,False,47,,False,False,,False,,[],{},,True,,1619071718.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In this course I will teach you 8 agents including:&lt;/p&gt;

&lt;p&gt;· Space Invaders Agent using Keras-RL&lt;/p&gt;

&lt;p&gt;· Autonomous Taxi using Q-Learning built from scratch&lt;/p&gt;

&lt;p&gt;· Flappy Bird Agent using Deep Q Network that we build from scratch&lt;/p&gt;

&lt;p&gt;· Mario Agent using Deep Q Network that we build from scratch&lt;/p&gt;

&lt;p&gt;· A reinforcement Learning S&amp;amp;P 500 stock trading agent that is rewarded with making money off the stock market!&lt;/p&gt;

&lt;p&gt;· Another Reinforcement Learning Stock Trading Agent using 89 different Technical indicators (you can pair these to make a lot of money off the stock market 😉) &lt;/p&gt;

&lt;p&gt;· 3 Car agents that learn to maneuver roundabouts, parking lots, &amp;amp; merge onto a highway&lt;/p&gt;

&lt;p&gt;The only thing you need to know is Python! If you are interested in cutting edge technology, then this is the course for you! Check it out! &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.udemy.com/course/practical-reinforcement-learning/?couponCode=150336130778173C0A71""&gt;https://www.udemy.com/course/practical-reinforcement-learning/?couponCode=150336130778173C0A71&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mvqqes,True,,samboylansajous,,10,True,all_ads,False,[],False,,/r/deeplearning/comments/mvqqes/hello_world_i_built_a_course_on_udemy_where_i/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mvqqes/hello_world_i_built_a_course_on_udemy_where_i/,66146,1619042918.0,0,,False,,,,,,,
,deeplearning,"Sharing now open source: [https://github.com/diffgram/diffgram](https://github.com/diffgram/diffgram)

This has been something I (Anthony) have been working on for the last 2+ years in closed source. Recently we have grown to be a small team.

What makes Diffgram different? We list some [benefits here](https://github.com/diffgram/diffgram#benefits) but if I had to pick one thing, it's that it's a complete system. You can be up and running [in 2 minutes](https://youtu.be/y0LE7QPXxE0) on docker. And scale to ""big tech co"" level on multiple [k8s clusters.](https://diffgram.readme.io/docs/open-installation-production)

Over time, the goal is continue to define all the abstractions needed to smoothly work with data in anyway you desire on any system. This goes far beyond UI customizations, or specific speed up approach implementations, and really is a complete ""all in one"" system.

Please star it! Share it with friends - and would love to hear any feedback [we started a small chat channel here.](https://discord.com/invite/f5pf6UZHQT) 

https://preview.redd.it/wgu79njruru61.png?width=3385&amp;format=png&amp;auto=webp&amp;s=0fec5173efc1dccbae1fe384372cd7b2357309d2",t2_gqrm8m9,False,,0,False,Diffgram - New Open Annotation Platform,[],r/deeplearning,False,6,,0,,False,t3_mwbz2w,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619146732.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Sharing now open source: &lt;a href=""https://github.com/diffgram/diffgram""&gt;https://github.com/diffgram/diffgram&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This has been something I (Anthony) have been working on for the last 2+ years in closed source. Recently we have grown to be a small team.&lt;/p&gt;

&lt;p&gt;What makes Diffgram different? We list some &lt;a href=""https://github.com/diffgram/diffgram#benefits""&gt;benefits here&lt;/a&gt; but if I had to pick one thing, it&amp;#39;s that it&amp;#39;s a complete system. You can be up and running &lt;a href=""https://youtu.be/y0LE7QPXxE0""&gt;in 2 minutes&lt;/a&gt; on docker. And scale to &amp;quot;big tech co&amp;quot; level on multiple &lt;a href=""https://diffgram.readme.io/docs/open-installation-production""&gt;k8s clusters.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Over time, the goal is continue to define all the abstractions needed to smoothly work with data in anyway you desire on any system. This goes far beyond UI customizations, or specific speed up approach implementations, and really is a complete &amp;quot;all in one&amp;quot; system.&lt;/p&gt;

&lt;p&gt;Please star it! Share it with friends - and would love to hear any feedback &lt;a href=""https://discord.com/invite/f5pf6UZHQT""&gt;we started a small chat channel here.&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/wgu79njruru61.png?width=3385&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0fec5173efc1dccbae1fe384372cd7b2357309d2""&gt;https://preview.redd.it/wgu79njruru61.png?width=3385&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0fec5173efc1dccbae1fe384372cd7b2357309d2&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mwbz2w,True,,diffgram-anthony,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mwbz2w/diffgram_new_open_annotation_platform/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mwbz2w/diffgram_new_open_annotation_platform/,66146,1619117932.0,0,,False,,,"{'wgu79njruru61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 49, 'x': 108, 'u': 'https://preview.redd.it/wgu79njruru61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=68f32153f2c2fb70b5a3f1e04dfbe8ba34fb84bf'}, {'y': 98, 'x': 216, 'u': 'https://preview.redd.it/wgu79njruru61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=375ee02da5efa370be9c7aedb72b1617eeff9285'}, {'y': 146, 'x': 320, 'u': 'https://preview.redd.it/wgu79njruru61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b92054a1ba33b5500c11d4230c713313d5e91357'}, {'y': 292, 'x': 640, 'u': 'https://preview.redd.it/wgu79njruru61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7ad6875b9b381aa8ee1f438e9d6fd86523ccfae8'}, {'y': 439, 'x': 960, 'u': 'https://preview.redd.it/wgu79njruru61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=37b3a80970220659302ddde880faa7d19e340679'}, {'y': 494, 'x': 1080, 'u': 'https://preview.redd.it/wgu79njruru61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=91a81957d0d11fd60501aac38b12d84d444c6082'}], 's': {'y': 1549, 'x': 3385, 'u': 'https://preview.redd.it/wgu79njruru61.png?width=3385&amp;format=png&amp;auto=webp&amp;s=0fec5173efc1dccbae1fe384372cd7b2357309d2'}, 'id': 'wgu79njruru61'}}",,,,
,deeplearning,"Hello everyone! If you're interested in applying deep learning to medical imaging, check my tutorial.  


In this video, I'll show you how you can build a deep learning model to detect Pneumonia directly from chest X-Ray Images.  


I'll walk you through the end-to-end process of building, evaluating and testing a convolutional neural network to accomplish this classification task - the model might not be optimal, but the underlying code is a good baseline that you can tweak and improve.  


If you have little to no experience with PyTorch or computer vision, you can definitely check this video to learn more about these topics.

[https://youtu.be/XI49ACP71Ck](https://youtu.be/XI49ACP71Ck)",t2_10lnxu,False,,0,False,Detecting Pneumonia from Chest X-Ray images with PyTorch,[],r/deeplearning,False,6,,0,,False,t3_mw4d86,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619125757.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone! If you&amp;#39;re interested in applying deep learning to medical imaging, check my tutorial.  &lt;/p&gt;

&lt;p&gt;In this video, I&amp;#39;ll show you how you can build a deep learning model to detect Pneumonia directly from chest X-Ray Images.  &lt;/p&gt;

&lt;p&gt;I&amp;#39;ll walk you through the end-to-end process of building, evaluating and testing a convolutional neural network to accomplish this classification task - the model might not be optimal, but the underlying code is a good baseline that you can tweak and improve.  &lt;/p&gt;

&lt;p&gt;If you have little to no experience with PyTorch or computer vision, you can definitely check this video to learn more about these topics.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://youtu.be/XI49ACP71Ck""&gt;https://youtu.be/XI49ACP71Ck&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mw4d86,True,,ahmedbesbes,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mw4d86/detecting_pneumonia_from_chest_xray_images_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mw4d86/detecting_pneumonia_from_chest_xray_images_with/,66146,1619096957.0,0,,False,,,,,,,
,deeplearning,"An IBM research team proposes four multilingual adversarial attack strategies and attacks seven languages in a zero-shot setting on large multilingual pretrained language models (e.g. MBERT), reducing average performance by up to 85.6 percent.

Here is a quick read: [Are Multilingual Language Models Fragile? IBM Adversarial Attack Strategies Cut MBERT QA Performance by 85%](https://syncedreview.com/2021/04/22/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-3/).

The paper *Are Multilingual BERT Models Robust? A Case Study on Adversarial Attacks for Multilingual Question Answering*  is on [arXiv](https://arxiv.org/pdf/2104.07646.pdf).",t2_2fv4yodo,False,,0,False,[R] Are Multilingual Language Models Fragile? IBM Adversarial Attack Strategies Cut MBERT QA Performance by 85%,[],r/deeplearning,False,6,,0,,False,t3_mw8vpl,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619138391.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;An IBM research team proposes four multilingual adversarial attack strategies and attacks seven languages in a zero-shot setting on large multilingual pretrained language models (e.g. MBERT), reducing average performance by up to 85.6 percent.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/22/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-3/""&gt;Are Multilingual Language Models Fragile? IBM Adversarial Attack Strategies Cut MBERT QA Performance by 85%&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Are Multilingual BERT Models Robust? A Case Study on Adversarial Attacks for Multilingual Question Answering&lt;/em&gt;  is on &lt;a href=""https://arxiv.org/pdf/2104.07646.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mw8vpl,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mw8vpl/r_are_multilingual_language_models_fragile_ibm/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mw8vpl/r_are_multilingual_language_models_fragile_ibm/,66146,1619109591.0,0,,False,,,,,,,
,deeplearning,"Dear all,

Have a peek at Computer Vision News of April!

Many articles about AI, Deep Learning and more...

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2021April/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2021-april-pdf/)

This is a festive edition celebrating the 5 years of the magazine, with more than 4.5 million pageviews.

If you never took the time to read it, maybe this is the right time.

Free subscription on page 58.

Enjoy!

https://preview.redd.it/inxa146hgpu61.jpg?width=400&amp;format=pjpg&amp;auto=webp&amp;s=71082364fac89791f9d2a5f1cb983cff0184e9aa",t2_x7alu,False,,0,False,Computer Vision News (with research and code!) - April 2021,[],r/deeplearning,False,6,,0,,False,t3_mw24ky,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619117563.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Dear all,&lt;/p&gt;

&lt;p&gt;Have a peek at Computer Vision News of April!&lt;/p&gt;

&lt;p&gt;Many articles about AI, Deep Learning and more...&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.rsipvision.com/ComputerVisionNews-2021April/""&gt;HTML5 version (recommended)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.rsipvision.com/computer-vision-news-2021-april-pdf/""&gt;PDF version&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is a festive edition celebrating the 5 years of the magazine, with more than 4.5 million pageviews.&lt;/p&gt;

&lt;p&gt;If you never took the time to read it, maybe this is the right time.&lt;/p&gt;

&lt;p&gt;Free subscription on page 58.&lt;/p&gt;

&lt;p&gt;Enjoy!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/inxa146hgpu61.jpg?width=400&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=71082364fac89791f9d2a5f1cb983cff0184e9aa""&gt;https://preview.redd.it/inxa146hgpu61.jpg?width=400&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=71082364fac89791f9d2a5f1cb983cff0184e9aa&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mw24ky,True,,Gletta,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mw24ky/computer_vision_news_with_research_and_code_april/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mw24ky/computer_vision_news_with_research_and_code_april/,66146,1619088763.0,0,,False,,,"{'inxa146hgpu61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 152, 'x': 108, 'u': 'https://preview.redd.it/inxa146hgpu61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=79af09ac2b173eeb2313f87c3d0cfbe4c7241244'}, {'y': 305, 'x': 216, 'u': 'https://preview.redd.it/inxa146hgpu61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=232e098acba3a8c57b99fccee5e9eaf7d6cb095f'}, {'y': 452, 'x': 320, 'u': 'https://preview.redd.it/inxa146hgpu61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f84a181246025d524dc883286c0e379aae53acdd'}], 's': {'y': 565, 'x': 400, 'u': 'https://preview.redd.it/inxa146hgpu61.jpg?width=400&amp;format=pjpg&amp;auto=webp&amp;s=71082364fac89791f9d2a5f1cb983cff0184e9aa'}, 'id': 'inxa146hgpu61'}}",,,,
,deeplearning,"I made a fun little artificial life simulation based on the game Snake. The snakes have a neural network with weights and biases optimized through a genetic algorithm. They don't perform gradient descent at the moment.

So far they've learned to follow their noses, which is great. But I've run into a mystery. When they get old, they start to go only forward, stop avoiding obstacles, run into something, and die:

[https://www.youtube.com/watch?v=EsrxioWsQD8](https://www.youtube.com/watch?v=EsrxioWsQD8)

Additional hours of evolution have not improved things. Any ideas why this is happening?

# More details

**Network architecture:**

Vision -&gt; Conv -&gt; MaxPool -&gt; Conv -&gt; (Concatenate with smell, other senses, and previous recurrent output) -&gt; FC -&gt; FC -&gt; Output action evaluations and recurrent values

(I use swish activation functions between layers except for the final layer, which uses sigmoid).

The action evaluation with the highest value is the action that will be performed.

**Available snake actions are:**

* Stay still
* Move forward
* Move right
* Move left
* Move forward and lay an egg if possible

**Senses:**

* Smell one square to the left, right, and forward (visualized by the hazy squares)
* Vision (7x7 centered at head)
* Body length (increased by eating apples or eggs)
* Energy level (increased by eating; decreased by existing, moving, or laying eggs)

Note that they don't have a sense of age, nor do they need one since they have no age-related changes in gameplay (other than increased length, which they already have a sense for).

I've already tried removing their sense of body length, and their behavior didn't change much, so that's not what's killing them. It may have something to do with the recurrent connections. Vanilla RNNs have problems with exploding gradients, but since they're not performing gradient descent, I didn't think this would be a problem.

It is, possibly, an evolved trait to avoid taking resources from progeny, but I think this would require many population boom and bust cycles, which I haven't seen.

Also, I'm using half-precision floats for performance reasons, if that could be a factor (underflow, overflow).

I would like them to grow long so that their world becomes more dynamic and competitive (if a snake runs into others, it dies).

Thoughts?

(Live stream at [https://www.twitch.tv/domokato](https://www.twitch.tv/domokato) if you want to collect more observational data).",t2_10dam3,False,,0,False,Check out my snakes and tell me why they are dying,[],r/deeplearning,False,6,,0,,False,t3_mvp6ws,False,dark,0.87,,public,11,0,{},,False,[],,False,False,,{},,False,11,,False,False,,1619039580.0,,[],{},,True,,1619067235.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I made a fun little artificial life simulation based on the game Snake. The snakes have a neural network with weights and biases optimized through a genetic algorithm. They don&amp;#39;t perform gradient descent at the moment.&lt;/p&gt;

&lt;p&gt;So far they&amp;#39;ve learned to follow their noses, which is great. But I&amp;#39;ve run into a mystery. When they get old, they start to go only forward, stop avoiding obstacles, run into something, and die:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=EsrxioWsQD8""&gt;https://www.youtube.com/watch?v=EsrxioWsQD8&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Additional hours of evolution have not improved things. Any ideas why this is happening?&lt;/p&gt;

&lt;h1&gt;More details&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Network architecture:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Vision -&amp;gt; Conv -&amp;gt; MaxPool -&amp;gt; Conv -&amp;gt; (Concatenate with smell, other senses, and previous recurrent output) -&amp;gt; FC -&amp;gt; FC -&amp;gt; Output action evaluations and recurrent values&lt;/p&gt;

&lt;p&gt;(I use swish activation functions between layers except for the final layer, which uses sigmoid).&lt;/p&gt;

&lt;p&gt;The action evaluation with the highest value is the action that will be performed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Available snake actions are:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Stay still&lt;/li&gt;
&lt;li&gt;Move forward&lt;/li&gt;
&lt;li&gt;Move right&lt;/li&gt;
&lt;li&gt;Move left&lt;/li&gt;
&lt;li&gt;Move forward and lay an egg if possible&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Senses:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Smell one square to the left, right, and forward (visualized by the hazy squares)&lt;/li&gt;
&lt;li&gt;Vision (7x7 centered at head)&lt;/li&gt;
&lt;li&gt;Body length (increased by eating apples or eggs)&lt;/li&gt;
&lt;li&gt;Energy level (increased by eating; decreased by existing, moving, or laying eggs)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that they don&amp;#39;t have a sense of age, nor do they need one since they have no age-related changes in gameplay (other than increased length, which they already have a sense for).&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve already tried removing their sense of body length, and their behavior didn&amp;#39;t change much, so that&amp;#39;s not what&amp;#39;s killing them. It may have something to do with the recurrent connections. Vanilla RNNs have problems with exploding gradients, but since they&amp;#39;re not performing gradient descent, I didn&amp;#39;t think this would be a problem.&lt;/p&gt;

&lt;p&gt;It is, possibly, an evolved trait to avoid taking resources from progeny, but I think this would require many population boom and bust cycles, which I haven&amp;#39;t seen.&lt;/p&gt;

&lt;p&gt;Also, I&amp;#39;m using half-precision floats for performance reasons, if that could be a factor (underflow, overflow).&lt;/p&gt;

&lt;p&gt;I would like them to grow long so that their world becomes more dynamic and competitive (if a snake runs into others, it dies).&lt;/p&gt;

&lt;p&gt;Thoughts?&lt;/p&gt;

&lt;p&gt;(Live stream at &lt;a href=""https://www.twitch.tv/domokato""&gt;https://www.twitch.tv/domokato&lt;/a&gt; if you want to collect more observational data).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mvp6ws,True,,domokato,,13,True,all_ads,False,[],False,,/r/deeplearning/comments/mvp6ws/check_out_my_snakes_and_tell_me_why_they_are_dying/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mvp6ws/check_out_my_snakes_and_tell_me_why_they_are_dying/,66146,1619038435.0,0,,False,,,,,,,
,deeplearning,,t2_8dh42jtc,False,,0,False,Style transfer changes art with the music,[],r/deeplearning,False,6,,0,,False,t3_mvw64r,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/LOdpa3Ua4kM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Coffee and Chill | Lofi Hip Hop | AI generated art', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/LOdpa3Ua4kM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Deep Style Beats', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/LOdpa3Ua4kM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCgDEhsKghkAsRklgopG4JxA'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/LOdpa3Ua4kM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mvw64r', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1619090244.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/LOdpa3Ua4kM,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mvw64r,True,,deep_style_beats,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mvw64r/style_transfer_changes_art_with_the_music/,all_ads,False,https://youtu.be/LOdpa3Ua4kM,66146,1619061444.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Coffee and Chill | Lofi Hip Hop | AI generated art', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/LOdpa3Ua4kM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Deep Style Beats', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/LOdpa3Ua4kM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCgDEhsKghkAsRklgopG4JxA'}}",False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,Will Transformers Replace CNNs in Computer Vision?,[],r/deeplearning,False,6,,0,,False,t3_mvdrkg,False,dark,0.8,,public,18,0,{},,False,[],,False,False,,{},,False,18,,False,False,,False,,[],{},,False,,1619033879.0,text,6,,,text,pub.towardsai.net,False,,,,,https://pub.towardsai.net/will-transformers-replace-cnns-in-computer-vision-55657a196833,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mvdrkg,True,,OnlyProggingForFun,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mvdrkg/will_transformers_replace_cnns_in_computer_vision/,all_ads,False,https://pub.towardsai.net/will-transformers-replace-cnns-in-computer-vision-55657a196833,66146,1619005079.0,0,,False,,,,,,,
,deeplearning,,t2_auwgbh53,False,,0,False,"Framework to build deep-learning powered search. Supports semantic text, image, audio, video and gif search.",[],r/deeplearning,False,6,,0,,False,t3_mvujl1,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,True,,False,,[],{},,False,,1619084377.0,text,6,,,text,github.com,False,,,,,https://github.com/jina-ai/jina,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mvujl1,True,,opensourcecolumbus,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mvujl1/framework_to_build_deeplearning_powered_search/,all_ads,False,https://github.com/jina-ai/jina,66146,1619055577.0,0,,False,,,,,,,
,deeplearning,"Just wanted to [share a blog post](https://medium.com/distributed-computing-with-ray/attention-nets-and-more-with-rllibs-trajectory-view-api-d326339a6e65) about two new features now stable in [RLlib](https://docs.ray.io/en/master/rllib.html): Support for Attention networks as custom models, and the “trajectory view API” ([RLlib](https://docs.ray.io/en/master/rllib.html) is a popular reinforcement learning library that is part of the open-source [Ray project](https://github.com/ray-project/ray)).",t2_sswdj,False,,0,False,Attention Nets and More with RLlib’s Trajectory View API,[],r/deeplearning,False,6,,0,,False,t3_mvlk0s,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1619057134.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just wanted to &lt;a href=""https://medium.com/distributed-computing-with-ray/attention-nets-and-more-with-rllibs-trajectory-view-api-d326339a6e65""&gt;share a blog post&lt;/a&gt; about two new features now stable in &lt;a href=""https://docs.ray.io/en/master/rllib.html""&gt;RLlib&lt;/a&gt;: Support for Attention networks as custom models, and the “trajectory view API” (&lt;a href=""https://docs.ray.io/en/master/rllib.html""&gt;RLlib&lt;/a&gt; is a popular reinforcement learning library that is part of the open-source &lt;a href=""https://github.com/ray-project/ray""&gt;Ray project&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mvlk0s,True,,mgalarny,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mvlk0s/attention_nets_and_more_with_rllibs_trajectory/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mvlk0s/attention_nets_and_more_with_rllibs_trajectory/,66146,1619028334.0,0,,False,,,,,,,
,deeplearning,"I am checking the CV accuracy using 10-folds. I used Stratified K-Fold to ensure the subsamples are balanced. However on 3 folds the val acc is 92%, on 3 it is 53% and on the rest it is 50%.

Why could this be happening?

Is this normal?

I am pretty sure there is nothing wrong with the code.",t2_4xhrybaz,False,,0,False,Stratified K-Fold cross validation accuracy at every fold is very different. Why?,[],r/deeplearning,False,6,,0,,False,t3_mvo8z8,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1619037286.0,,[],{},,True,,1619064555.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am checking the CV accuracy using 10-folds. I used Stratified K-Fold to ensure the subsamples are balanced. However on 3 folds the val acc is 92%, on 3 it is 53% and on the rest it is 50%.&lt;/p&gt;

&lt;p&gt;Why could this be happening?&lt;/p&gt;

&lt;p&gt;Is this normal?&lt;/p&gt;

&lt;p&gt;I am pretty sure there is nothing wrong with the code.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mvo8z8,True,,banenvy,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/mvo8z8/stratified_kfold_cross_validation_accuracy_at/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mvo8z8/stratified_kfold_cross_validation_accuracy_at/,66146,1619035755.0,0,,False,,,,,,,
,deeplearning,,t2_50i7d,False,,0,False,"Journey to the center of the neuron, how understanding the difference between artificial and biological neurons may give us clues about how to move towards a more flexible kind of artificial intelligence",[],r/deeplearning,False,6,,0,,False,t3_mvicxv,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1619048364.0,text,6,,,text,towardsdatascience.com,False,,,,,https://towardsdatascience.com/journey-to-the-center-of-the-neuron-c614bfee3f9,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mvicxv,True,,javismiles,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mvicxv/journey_to_the_center_of_the_neuron_how/,all_ads,False,https://towardsdatascience.com/journey-to-the-center-of-the-neuron-c614bfee3f9,66146,1619019564.0,0,,False,,,,,,,
,deeplearning,"We are excited to announce the release of the [ColTraIn HBFP Training Emulator](https://github.com/parsa-epfl/HBFPEmulator).

[HBFP](https://papers.nips.cc/paper/2018/file/6a9aeddfc689c1d0e3b9ccc3ab651bc5-Paper.pdf) offers the **accuracy** of 32-bit floating-point with the numeric and silicon density of 8-bit fixed-point for a wide variety of models (ResNet, WideResNet, DenseNet, AlexNet, LSTM, and BERT). We foresee HBFP laying the foundation for accurate training algorithms running on accelerators with an order of magnitude denser arithmetic than conventional or novel floating-point based platforms. The ColTraIn emulator repository includes several example DNN models including CNNs, LSTMs and BERT for both HBFP and a reference FP32 baseline.   
Check out the ColTraIn emulator at [https://github.com/parsa-epfl/HBFPEmulator](https://github.com/parsa-epfl/HBFPEmulator) or visit our website at [https://parsa.epfl.ch/coltrain/](https://parsa.epfl.ch/coltrain/) for more information!",t2_bn0pam6o,False,,0,False,ColTraIn Hybrid Block Floating-Point (HBFP) Training Emulator,[],r/deeplearning,False,6,,0,,False,t3_mvn0ja,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619061110.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We are excited to announce the release of the &lt;a href=""https://github.com/parsa-epfl/HBFPEmulator""&gt;ColTraIn HBFP Training Emulator&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://papers.nips.cc/paper/2018/file/6a9aeddfc689c1d0e3b9ccc3ab651bc5-Paper.pdf""&gt;HBFP&lt;/a&gt; offers the &lt;strong&gt;accuracy&lt;/strong&gt; of 32-bit floating-point with the numeric and silicon density of 8-bit fixed-point for a wide variety of models (ResNet, WideResNet, DenseNet, AlexNet, LSTM, and BERT). We foresee HBFP laying the foundation for accurate training algorithms running on accelerators with an order of magnitude denser arithmetic than conventional or novel floating-point based platforms. The ColTraIn emulator repository includes several example DNN models including CNNs, LSTMs and BERT for both HBFP and a reference FP32 baseline.&lt;br/&gt;
Check out the ColTraIn emulator at &lt;a href=""https://github.com/parsa-epfl/HBFPEmulator""&gt;https://github.com/parsa-epfl/HBFPEmulator&lt;/a&gt; or visit our website at &lt;a href=""https://parsa.epfl.ch/coltrain/""&gt;https://parsa.epfl.ch/coltrain/&lt;/a&gt; for more information!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mvn0ja,True,,SimlaBurcu,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mvn0ja/coltrain_hybrid_block_floatingpoint_hbfp_training/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mvn0ja/coltrain_hybrid_block_floatingpoint_hbfp_training/,66146,1619032310.0,0,,False,,,,,,,
,deeplearning,"# [Training Generative Adversarial Networks with Limited Data](https://t.me/casual_gan/28)

The authors propose а novel method to train a StyleGAN on a small dataset (few thousand images) without overfitting. They achieve high visual quality of generated images by introducing a set of adaptive discriminator augmentations that stabilize training with limited data. More details [here](https://t.me/casual_gan/28).

[StyleGAN-2](https://preview.redd.it/v89mq58ygju61.png?width=1280&amp;format=png&amp;auto=webp&amp;s=480d6e58ba910829cd48b5a73b0363ba6fe8cfac)

 In case you are not familiar with the paper, read it [here](https://t.me/casual_gan/28).",t2_hhio3,False,,0,False,[R] Training Generative Adversarial Networks with Limited Data,[],r/deeplearning,False,6,,0,,False,t3_mvh70d,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1619045040.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h1&gt;&lt;a href=""https://t.me/casual_gan/28""&gt;Training Generative Adversarial Networks with Limited Data&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;The authors propose а novel method to train a StyleGAN on a small dataset (few thousand images) without overfitting. They achieve high visual quality of generated images by introducing a set of adaptive discriminator augmentations that stabilize training with limited data. More details &lt;a href=""https://t.me/casual_gan/28""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/v89mq58ygju61.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=480d6e58ba910829cd48b5a73b0363ba6fe8cfac""&gt;StyleGAN-2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In case you are not familiar with the paper, read it &lt;a href=""https://t.me/casual_gan/28""&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mvh70d,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mvh70d/r_training_generative_adversarial_networks_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mvh70d/r_training_generative_adversarial_networks_with/,66146,1619016240.0,0,,False,,,"{'v89mq58ygju61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 58, 'x': 108, 'u': 'https://preview.redd.it/v89mq58ygju61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=03def34d23e8253e4535571f921eb24d3f4b38d8'}, {'y': 117, 'x': 216, 'u': 'https://preview.redd.it/v89mq58ygju61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5de6a65a24244034283e36f91b11161e6a283b17'}, {'y': 174, 'x': 320, 'u': 'https://preview.redd.it/v89mq58ygju61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd458ff445f5862a14dd107dc6f34da3c769e43a'}, {'y': 349, 'x': 640, 'u': 'https://preview.redd.it/v89mq58ygju61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=cd2fbf38273470840f5933d594f7230512ceb6f5'}, {'y': 524, 'x': 960, 'u': 'https://preview.redd.it/v89mq58ygju61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=6db7a4622bf71701142eb2d35fc49bdf1437e800'}, {'y': 589, 'x': 1080, 'u': 'https://preview.redd.it/v89mq58ygju61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=545637a18d32e27921cd7de3693c519aa278fe7a'}], 's': {'y': 699, 'x': 1280, 'u': 'https://preview.redd.it/v89mq58ygju61.png?width=1280&amp;format=png&amp;auto=webp&amp;s=480d6e58ba910829cd48b5a73b0363ba6fe8cfac'}, 'id': 'v89mq58ygju61'}}",,,,
,deeplearning,"A research team from UC Berkeley and Carnegie Mellon University proposes a task-agnostic reinforcement learning method that reduces the task-specific engineering required for domain randomization of both visual and dynamics parameters.

Here is a quick read: [Pieter Abbeel Team Proposes Task-Agnostic RL Method to Auto-Tune Simulations to the Real World](https://syncedreview.com/2021/04/21/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-2/).

The paper Auto-Tuned Sim-to-Real Transfer is on [arXiv](https://arxiv.org/pdf/2104.07662.pdf).",t2_2fv4yodo,False,,0,False,[R] Pieter Abbeel Team Proposes Task-Agnostic RL Method to Auto-Tune Simulations to the Real World,[],r/deeplearning,False,6,,0,,False,t3_mvkqis,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619054877.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from UC Berkeley and Carnegie Mellon University proposes a task-agnostic reinforcement learning method that reduces the task-specific engineering required for domain randomization of both visual and dynamics parameters.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/21/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-2/""&gt;Pieter Abbeel Team Proposes Task-Agnostic RL Method to Auto-Tune Simulations to the Real World&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The paper Auto-Tuned Sim-to-Real Transfer is on &lt;a href=""https://arxiv.org/pdf/2104.07662.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mvkqis,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mvkqis/r_pieter_abbeel_team_proposes_taskagnostic_rl/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mvkqis/r_pieter_abbeel_team_proposes_taskagnostic_rl/,66146,1619026077.0,0,,False,,,,,,,
,deeplearning,,t2_2elywrfx,False,,0,False,Neural net trained to predict what other half of an image a face should look like given the first half as input either split vertically or horizontally (and it’s fairly accurate),[],r/deeplearning,False,6,,0,,False,t3_mutjhg,False,dark,0.96,,public,87,0,{},,False,[],,False,False,,{},,False,87,,False,False,,False,,[],{},,False,,1618963057.0,text,6,,,text,reddit.com,False,,,,,https://www.reddit.com/gallery/mutjhg,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mutjhg,True,,Extra-most-best,,14,True,all_ads,False,[],False,,/r/deeplearning/comments/mutjhg/neural_net_trained_to_predict_what_other_half_of/,all_ads,False,https://www.reddit.com/gallery/mutjhg,66146,1618934257.0,1,,False,,,"{'1sbng1q7pcu61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 81, 'x': 108, 'u': 'https://preview.redd.it/1sbng1q7pcu61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=134cabfbf80e89e2b145c8f7955d424f388ce112'}, {'y': 162, 'x': 216, 'u': 'https://preview.redd.it/1sbng1q7pcu61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8647b7ed5437915e30b4b1d418c5f39d1b0ed9a3'}, {'y': 240, 'x': 320, 'u': 'https://preview.redd.it/1sbng1q7pcu61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a7f5a9cbd6e1470e673510be7b42da0f6c328592'}, {'y': 480, 'x': 640, 'u': 'https://preview.redd.it/1sbng1q7pcu61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=220097899dc2112b32a4a24b5ee1248b549ef615'}], 's': {'y': 480, 'x': 640, 'u': 'https://preview.redd.it/1sbng1q7pcu61.jpg?width=640&amp;format=pjpg&amp;auto=webp&amp;s=b42ae9f4ace6fac237e9f8febe20804c2b3b4dc1'}, 'id': '1sbng1q7pcu61'}, 'y5pgdqp7pcu61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 81, 'x': 108, 'u': 'https://preview.redd.it/y5pgdqp7pcu61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=abde2b86cbd0be3a8b6a0b6d9bc56690db1f1563'}, {'y': 162, 'x': 216, 'u': 'https://preview.redd.it/y5pgdqp7pcu61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1f30e53eaef161d5c9d4ecc483bab87007a1ec29'}, {'y': 240, 'x': 320, 'u': 'https://preview.redd.it/y5pgdqp7pcu61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0f794adcc022cdcb111e03846ed81fb32789f6cb'}, {'y': 480, 'x': 640, 'u': 'https://preview.redd.it/y5pgdqp7pcu61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0cc30b40c6ecce4e3d3e7c418c25adeea58e65ca'}], 's': {'y': 480, 'x': 640, 'u': 'https://preview.redd.it/y5pgdqp7pcu61.jpg?width=640&amp;format=pjpg&amp;auto=webp&amp;s=72a440e55f412f0a6c4b48b07418817545d8f104'}, 'id': 'y5pgdqp7pcu61'}}",,,True,"{'items': [{'media_id': 'y5pgdqp7pcu61', 'id': 39910437}, {'media_id': '1sbng1q7pcu61', 'id': 39910438}]}"
,deeplearning,"I need to use KL Divergence as my loss for a multi-label classification problem with 5 classes (Eqn. 6 of this [paper](https://arxiv.org/pdf/2005.02231.pdf)). I have soft ground truth targets from a teacher network of the form \[0.99, 0.01, 0.99, 0.1, 0.1\] for each sample (since its a multi-label problem, a sample can belong to multiple classes), and predictions which are five probabilities that *don’t* sum up to 1.

How can the KL divergence be computed? It seems like nn.KLDivLoss() expects the probabilities to add up to 1 – otherwise, I get a negative loss.",t2_15mvad,False,,0,False,KL Divergence for Multi-Label Classification,[],r/deeplearning,False,6,,0,,False,t3_mv6m84,False,dark,0.87,,public,11,0,{},,False,[],,False,False,,{},,False,11,,False,False,,False,,[],{},,True,,1619001861.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I need to use KL Divergence as my loss for a multi-label classification problem with 5 classes (Eqn. 6 of this &lt;a href=""https://arxiv.org/pdf/2005.02231.pdf""&gt;paper&lt;/a&gt;). I have soft ground truth targets from a teacher network of the form [0.99, 0.01, 0.99, 0.1, 0.1] for each sample (since its a multi-label problem, a sample can belong to multiple classes), and predictions which are five probabilities that &lt;em&gt;don’t&lt;/em&gt; sum up to 1.&lt;/p&gt;

&lt;p&gt;How can the KL divergence be computed? It seems like nn.KLDivLoss() expects the probabilities to add up to 1 – otherwise, I get a negative loss.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mv6m84,True,,alkaway,,12,True,all_ads,False,[],False,,/r/deeplearning/comments/mv6m84/kl_divergence_for_multilabel_classification/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mv6m84/kl_divergence_for_multilabel_classification/,66146,1618973061.0,0,,False,,,,,,,
,deeplearning,"So the title is not really giving much information about my problem. Sorry about that but I couldn't find something short to describe it.

I'm currently trying to come with a neural network which will receive a window of images in a video and predict if there is a specific event which occurs.

To elaborate more about what kind of video/data I'm talking about, I will give a short explanation:

I'm working with cellular(biology cells) data, videos of them. The task which I am currently facing is taking labeled data of cells which are going to undergo an event of ""fusion"". Meaning they will start ""disappearing"". I want to use deep learning to detect those events in real time and apply something to the cell(does not need to concern any of you).

I have background in deep learning but can't find a good, state of the art, suitable solution to my problem(I'm not really sure what's state of the art or not but don't want to be wasting my time on toy examples that have no chance of working in the real world).

Will a simple LSTM net will do the trick? If so, how can I train my model to say whether there is an event or not. In other words what will be the target? Simply ones and zeros(indicating there is an event or not)?

I'm not really sure what path to take since there is too many complex information on the internet. Hoping someone can give me some advice :)",t2_85iwoyzm,False,,0,False,Detecting specific events in videos using Deep learning,[],r/deeplearning,False,6,,0,,False,t3_mvg9m8,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619042361.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So the title is not really giving much information about my problem. Sorry about that but I couldn&amp;#39;t find something short to describe it.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m currently trying to come with a neural network which will receive a window of images in a video and predict if there is a specific event which occurs.&lt;/p&gt;

&lt;p&gt;To elaborate more about what kind of video/data I&amp;#39;m talking about, I will give a short explanation:&lt;/p&gt;

&lt;p&gt;I&amp;#39;m working with cellular(biology cells) data, videos of them. The task which I am currently facing is taking labeled data of cells which are going to undergo an event of &amp;quot;fusion&amp;quot;. Meaning they will start &amp;quot;disappearing&amp;quot;. I want to use deep learning to detect those events in real time and apply something to the cell(does not need to concern any of you).&lt;/p&gt;

&lt;p&gt;I have background in deep learning but can&amp;#39;t find a good, state of the art, suitable solution to my problem(I&amp;#39;m not really sure what&amp;#39;s state of the art or not but don&amp;#39;t want to be wasting my time on toy examples that have no chance of working in the real world).&lt;/p&gt;

&lt;p&gt;Will a simple LSTM net will do the trick? If so, how can I train my model to say whether there is an event or not. In other words what will be the target? Simply ones and zeros(indicating there is an event or not)?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m not really sure what path to take since there is too many complex information on the internet. Hoping someone can give me some advice :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mvg9m8,True,,Swimming_Weird_5495,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mvg9m8/detecting_specific_events_in_videos_using_deep/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mvg9m8/detecting_specific_events_in_videos_using_deep/,66146,1619013561.0,0,,False,,,,,,,
,deeplearning,"I'm reading through stylegan code along with the paper and there is one thing that doesn't make sense to me.

Say we have a real image A, B.

As I understand it, during training the generator will create a fake image close to A from a ""random"" noise vector z1.

Likewise, the generator will create a fake image close to B from another random noise vector z2.

&amp;#x200B;

But what I don't understand is the random vector z.

What if in the next iteration z2 was sampled as initial latent vector and the genrator is guided to create a fake image of A instead of B as it did in the past?

Am I missing something?",t2_g7e0ajf,False,,0,False,question with stylegan,[],r/deeplearning,False,6,,0,,False,t3_mv8uex,False,dark,0.84,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1619010952.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m reading through stylegan code along with the paper and there is one thing that doesn&amp;#39;t make sense to me.&lt;/p&gt;

&lt;p&gt;Say we have a real image A, B.&lt;/p&gt;

&lt;p&gt;As I understand it, during training the generator will create a fake image close to A from a &amp;quot;random&amp;quot; noise vector z1.&lt;/p&gt;

&lt;p&gt;Likewise, the generator will create a fake image close to B from another random noise vector z2.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;But what I don&amp;#39;t understand is the random vector z.&lt;/p&gt;

&lt;p&gt;What if in the next iteration z2 was sampled as initial latent vector and the genrator is guided to create a fake image of A instead of B as it did in the past?&lt;/p&gt;

&lt;p&gt;Am I missing something?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mv8uex,True,,chadrick-kwag,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mv8uex/question_with_stylegan/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mv8uex/question_with_stylegan/,66146,1618982152.0,0,,False,,,,,,,
,deeplearning,"I want to create a very simple neural network, but I’ve never created a neural network before. I have the conceptual design nearly down, but I don’t know how to implement it. Hoping someone here can point me in the right direction.

Allow me to explain it:

1. Start with a fully connected RNN.
2. Arrange the neurons in layers (preferably in an autoencoder pattern).
3. Remove all connections to other cells in the same layer, including the self-connection.
4. Create a time delay for the connections based on how many layers away the target is.
5. When a layer is activated force a constant, small percentage of the cells to be on. In other words, the activation function must take the entire layer into account so that the top \~5% of activated cells really become active.
6. Notice in the image below the thinning of the line when weights are applied to further away layers. That is meant to represent that I think a cell from layer 0 should have more confidence about its predictions (weights) on layer 1, in the very next timestep than it does for predictions made on the last layer, 4 timesteps in the future. So for that further-away layer, its weights should be smaller so it has less of an effect than nearby layers, and it should readjust those weights more slowly. 
7. Speaking of updating the weights, I don't want to use traditional backpropagation. Instead, I want the error applied continually. In other words, a weight from layer 0 to layer 1 is a prediction that this cell will fire or not, we'll get immediate feedback on that weight as the active cells become immediately observable after the weights are applied. However, a weight from layer 0 to layer 2, is a prediction that that cell will fire after a timestep. When a timestep passes we can then readjust that weight. and should do so more gradually than the connection between two immediately adjacent layers. (I’m really not sure how to balance all this so the rate at which we more gradually apply errors is proportional to the effect the longer running connections have - maybe you have some ideas?)

[conceptual design](https://preview.redd.it/jblp02zdeeu61.png?width=444&amp;format=png&amp;auto=webp&amp;s=3a9a511dde07df29ff1d21b4e2311f8f43bc56a8)

 **Anyway, thanks for any help or direction you can offer me!**

PS. If you’re curious as to the motivation behind this design, I’m going to attempt to use it in a sensorimotor context. It’s organized into layers so there’s a 2-way directionality to the information flow in it. The diagram only shows connections of one cell, on one side of the network, but it's recurrent so there are connections going backward as well.

One side, perhaps the left side, can be thought of as sensory input data, the other side can be thought of as motor output data. The weights act as predictions of activation, predictions of what the rest of the network will predict will happen. Therefore, it is my intuition that the network will begin to mirror the causal relationships in the external environment that the sensorimotor agent explores. 

So it’s really as if there are two feed-forward networks readjusting the weights for each other: the sensory network and the motor network. The sensory network is saying, “given that I see this input, I will predict this transformation and motor output.” While at the same time the motor network is saying, “given this most recent motor activation, I will predict this sensory input as a result of the encoded causal structure of the world.” Of course, this is the absolute simplest implementation of the idea, so even if it works it won’t be very powerful, but it's a start.

Thanks for your help!",t2_13e4kt,False,,0,False,Can you make this in TensorFlow or PyTorch? (AGI sketch),[],r/deeplearning,False,6,,0,,False,t3_mv1pbt,False,dark,0.81,,public,9,0,{},,False,[],,False,False,,{},,False,9,,False,False,,False,,[],{},,True,,1618985221.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to create a very simple neural network, but I’ve never created a neural network before. I have the conceptual design nearly down, but I don’t know how to implement it. Hoping someone here can point me in the right direction.&lt;/p&gt;

&lt;p&gt;Allow me to explain it:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Start with a fully connected RNN.&lt;/li&gt;
&lt;li&gt;Arrange the neurons in layers (preferably in an autoencoder pattern).&lt;/li&gt;
&lt;li&gt;Remove all connections to other cells in the same layer, including the self-connection.&lt;/li&gt;
&lt;li&gt;Create a time delay for the connections based on how many layers away the target is.&lt;/li&gt;
&lt;li&gt;When a layer is activated force a constant, small percentage of the cells to be on. In other words, the activation function must take the entire layer into account so that the top ~5% of activated cells really become active.&lt;/li&gt;
&lt;li&gt;Notice in the image below the thinning of the line when weights are applied to further away layers. That is meant to represent that I think a cell from layer 0 should have more confidence about its predictions (weights) on layer 1, in the very next timestep than it does for predictions made on the last layer, 4 timesteps in the future. So for that further-away layer, its weights should be smaller so it has less of an effect than nearby layers, and it should readjust those weights more slowly. &lt;/li&gt;
&lt;li&gt;Speaking of updating the weights, I don&amp;#39;t want to use traditional backpropagation. Instead, I want the error applied continually. In other words, a weight from layer 0 to layer 1 is a prediction that this cell will fire or not, we&amp;#39;ll get immediate feedback on that weight as the active cells become immediately observable after the weights are applied. However, a weight from layer 0 to layer 2, is a prediction that that cell will fire after a timestep. When a timestep passes we can then readjust that weight. and should do so more gradually than the connection between two immediately adjacent layers. (I’m really not sure how to balance all this so the rate at which we more gradually apply errors is proportional to the effect the longer running connections have - maybe you have some ideas?)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/jblp02zdeeu61.png?width=444&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3a9a511dde07df29ff1d21b4e2311f8f43bc56a8""&gt;conceptual design&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Anyway, thanks for any help or direction you can offer me!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;PS. If you’re curious as to the motivation behind this design, I’m going to attempt to use it in a sensorimotor context. It’s organized into layers so there’s a 2-way directionality to the information flow in it. The diagram only shows connections of one cell, on one side of the network, but it&amp;#39;s recurrent so there are connections going backward as well.&lt;/p&gt;

&lt;p&gt;One side, perhaps the left side, can be thought of as sensory input data, the other side can be thought of as motor output data. The weights act as predictions of activation, predictions of what the rest of the network will predict will happen. Therefore, it is my intuition that the network will begin to mirror the causal relationships in the external environment that the sensorimotor agent explores. &lt;/p&gt;

&lt;p&gt;So it’s really as if there are two feed-forward networks readjusting the weights for each other: the sensory network and the motor network. The sensory network is saying, “given that I see this input, I will predict this transformation and motor output.” While at the same time the motor network is saying, “given this most recent motor activation, I will predict this sensory input as a result of the encoded causal structure of the world.” Of course, this is the absolute simplest implementation of the idea, so even if it works it won’t be very powerful, but it&amp;#39;s a start.&lt;/p&gt;

&lt;p&gt;Thanks for your help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mv1pbt,True,,Stack3,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mv1pbt/can_you_make_this_in_tensorflow_or_pytorch_agi/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mv1pbt/can_you_make_this_in_tensorflow_or_pytorch_agi/,66146,1618956421.0,1,,False,,,"{'jblp02zdeeu61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 85, 'x': 108, 'u': 'https://preview.redd.it/jblp02zdeeu61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=24019d1ecd03358e3d0b7522ffb4e8e94c001c62'}, {'y': 171, 'x': 216, 'u': 'https://preview.redd.it/jblp02zdeeu61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=73e599d13f92b8b705e485ba962fbeca2015f604'}, {'y': 254, 'x': 320, 'u': 'https://preview.redd.it/jblp02zdeeu61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=114e4eb6f8b33494ded9bc2d58499b57aec97121'}], 's': {'y': 353, 'x': 444, 'u': 'https://preview.redd.it/jblp02zdeeu61.png?width=444&amp;format=png&amp;auto=webp&amp;s=3a9a511dde07df29ff1d21b4e2311f8f43bc56a8'}, 'id': 'jblp02zdeeu61'}}",,,,
,deeplearning,,t2_jsn8x,False,,0,False,Higher Order Recurrent Space-Time Transformer,[],r/deeplearning,False,6,,0,,False,t3_mv9vze,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1619015890.0,text,6,,,text,arxiv.org,False,,,,,https://arxiv.org/abs/2104.08665,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mv9vze,True,,zepmck,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mv9vze/higher_order_recurrent_spacetime_transformer/,all_ads,False,https://arxiv.org/abs/2104.08665,66146,1618987090.0,0,,False,,,,,,,
,deeplearning,"Hi community, I was wondering about using Transformers in time series tasks.

Knowing that transformers use attention, and that attention block accepts Key Value and Query in NLP tasks, what will be the input schema for time series problem ?

&amp;#x200B;

Can we even talk about key value and queries in that case ? 

&amp;#x200B;

thank you",t2_7l9ti89m,False,,0,False,Using attention mechanism in time series,[],r/deeplearning,False,6,,0,,False,t3_mv5hz6,False,dark,0.79,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1618997733.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi community, I was wondering about using Transformers in time series tasks.&lt;/p&gt;

&lt;p&gt;Knowing that transformers use attention, and that attention block accepts Key Value and Query in NLP tasks, what will be the input schema for time series problem ?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Can we even talk about key value and queries in that case ? &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mv5hz6,True,,rayanaay,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mv5hz6/using_attention_mechanism_in_time_series/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mv5hz6/using_attention_mechanism_in_time_series/,66146,1618968933.0,0,,False,,,,,,,
,deeplearning," Instead of optimizing say,

f(x) = y\_groundtruth\_i - y\_predicted\_i

Can we take an average of the ground truths, say

f(x) = ( (y\_groundtruth\_i+1 - y\_predicted\_i) + (y\_groundtruth\_i - y\_predicted\_i) ) / 2

This is basically to improve adjacent image similarity in an algorithm


Has this been done before? Thanks!",t2_452sjdrq,False,,0,False,Loss function that involves one input and multiple ground truths,[],r/deeplearning,False,6,,0,,False,t3_mv96wt,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1619012558.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Instead of optimizing say,&lt;/p&gt;

&lt;p&gt;f(x) = y_groundtruth_i - y_predicted_i&lt;/p&gt;

&lt;p&gt;Can we take an average of the ground truths, say&lt;/p&gt;

&lt;p&gt;f(x) = ( (y_groundtruth_i+1 - y_predicted_i) + (y_groundtruth_i - y_predicted_i) ) / 2&lt;/p&gt;

&lt;p&gt;This is basically to improve adjacent image similarity in an algorithm&lt;/p&gt;

&lt;p&gt;Has this been done before? Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mv96wt,True,,vulnerablebeast,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mv96wt/loss_function_that_involves_one_input_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mv96wt/loss_function_that_involves_one_input_and/,66146,1618983758.0,0,,False,,,,,,,
,deeplearning,,t2_u58vv,False,,0,False,StyleGAN2 + CLIP = StyleCLIP: You Describe &amp; AI Photoshops Faces For You,[],r/deeplearning,False,6,,0,,False,t3_muisan,False,dark,0.9,,public,72,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/d1OET63Ulwc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'You Describe &amp; AI Photoshops Faces For You [StyleCLIP]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/d1OET63Ulwc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'bycloud', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/d1OET63Ulwc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/bycloudAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/d1OET63Ulwc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/muisan', 'height': 200}",,False,72,,False,False,,False,,[],{},,False,,1618922413.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/d1OET63Ulwc,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,muisan,True,,cloud_weather,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/muisan/stylegan2_clip_styleclip_you_describe_ai/,all_ads,False,https://youtu.be/d1OET63Ulwc,66146,1618893613.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'You Describe &amp; AI Photoshops Faces For You [StyleCLIP]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/d1OET63Ulwc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'bycloud', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/d1OET63Ulwc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/bycloudAI'}}",False,,,,,,,
,deeplearning,,t2_9re2o3wq,False,,0,False,Joker - Harley Quinn Deepfake // Side by Side comparison,[],r/deeplearning,False,6,,0,,False,t3_mux98a,False,dark,0.83,,public,4,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/58LJ17eY8Lc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Mr. J loves Harley - Side by Side Comparison [ Joker Deepfake ]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/58LJ17eY8Lc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Louzy Kreations', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/58LJ17eY8Lc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/louzykreations'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/58LJ17eY8Lc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mux98a', 'height': 200}",,False,4,,False,False,,False,,[],{},,False,,1618972944.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/58LJ17eY8Lc,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mux98a,True,,Onyx0805,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mux98a/joker_harley_quinn_deepfake_side_by_side/,all_ads,False,https://youtu.be/58LJ17eY8Lc,66146,1618944144.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Mr. J loves Harley - Side by Side Comparison [ Joker Deepfake ]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/58LJ17eY8Lc?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Louzy Kreations', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/58LJ17eY8Lc/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/louzykreations'}}",False,,,,,,,
,deeplearning,"I am creating a binary classification CNN model and although my model  accuracy comes out to be 92%, accuracy according to the classification report as well as the confusion matrix comes out to be 53% .

What could I be doing wrong in my deep learning model ?",t2_688iioo7,False,,0,False,[D] not getting desired classification accuracy in CNN model,[],r/deeplearning,False,6,,0,,False,t3_muw1rr,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618969722.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am creating a binary classification CNN model and although my model  accuracy comes out to be 92%, accuracy according to the classification report as well as the confusion matrix comes out to be 53% .&lt;/p&gt;

&lt;p&gt;What could I be doing wrong in my deep learning model ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,muw1rr,True,,Harsh_62,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/muw1rr/d_not_getting_desired_classification_accuracy_in/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/muw1rr/d_not_getting_desired_classification_accuracy_in/,66146,1618940922.0,0,,False,,,,,,,
,deeplearning,"Autoencoders have many interesting applications: Compressing data for a faster transfer, denoising an image, dimensionality reduction, image segmentation, image inpainting, and many more.  


In today's post, we discuss all you need to know about an Autoencoder, discuss its objective function, and learn to reconstruct some of the most famous datasets such as Fashion-MNIST in the TensorFlow v2.0 framework with detailed code explanation.  


As a bonus, we perform various experiments. We exploit the trained Autoencoder's latent space. We conclude by summing why simple Autoencoders are not Generative in nature.  


[https://learnopencv.com/autoencoder-in-tensorflow-2-beginners-guide/](https://learnopencv.com/autoencoder-in-tensorflow-2-beginners-guide/) 

https://preview.redd.it/3b01788medu61.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=35646927114cd01e5e80e2ffb4c23198a4b87ce5",t2_cvc9f,False,,0,False,Autoencoder in TensorFlow 2: Beginner’s Guide,[],r/deeplearning,False,6,,0,,False,t3_muwr71,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1618971609.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Autoencoders have many interesting applications: Compressing data for a faster transfer, denoising an image, dimensionality reduction, image segmentation, image inpainting, and many more.  &lt;/p&gt;

&lt;p&gt;In today&amp;#39;s post, we discuss all you need to know about an Autoencoder, discuss its objective function, and learn to reconstruct some of the most famous datasets such as Fashion-MNIST in the TensorFlow v2.0 framework with detailed code explanation.  &lt;/p&gt;

&lt;p&gt;As a bonus, we perform various experiments. We exploit the trained Autoencoder&amp;#39;s latent space. We conclude by summing why simple Autoencoders are not Generative in nature.  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://learnopencv.com/autoencoder-in-tensorflow-2-beginners-guide/""&gt;https://learnopencv.com/autoencoder-in-tensorflow-2-beginners-guide/&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/3b01788medu61.jpg?width=600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=35646927114cd01e5e80e2ffb4c23198a4b87ce5""&gt;https://preview.redd.it/3b01788medu61.jpg?width=600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=35646927114cd01e5e80e2ffb4c23198a4b87ce5&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,muwr71,True,,spmallick,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/muwr71/autoencoder_in_tensorflow_2_beginners_guide/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/muwr71/autoencoder_in_tensorflow_2_beginners_guide/,66146,1618942809.0,0,,False,,,"{'3b01788medu61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/3b01788medu61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=449ed2d35fbcbcdc0cffe703a427c173c90b8879'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/3b01788medu61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=66ae79c6cbca2050b52664230d49cdcf6bc0be4f'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/3b01788medu61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ebdd68118f3d501e5435ea8bc0e3d3d044789f8a'}], 's': {'y': 338, 'x': 600, 'u': 'https://preview.redd.it/3b01788medu61.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=35646927114cd01e5e80e2ffb4c23198a4b87ce5'}, 'id': '3b01788medu61'}}",,,,
,deeplearning,"&amp;#x200B;

https://preview.redd.it/brplwikk4bu61.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=722c8249d3097a6f7f2b9373d6f3ff9250a70504

Interview questions can sometimes get a bit tougher to answer. That’s why Wissenhive presented this blog named ‘[Top 50 Deep Learning Interview Questions](https://www.wissenhive.com/blogs/top-50-deep-learning-interview-questions-and-answers)’ while putting together the most asked interview questions with answers by industry experts and professionals.",t2_8hgl59ev,False,,0,False,Top 50 Deep Learning Interview Questions And Answers,[],r/deeplearning,False,6,,0,,False,t3_munjq5,False,dark,0.83,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1618944043.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/brplwikk4bu61.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=722c8249d3097a6f7f2b9373d6f3ff9250a70504""&gt;https://preview.redd.it/brplwikk4bu61.jpg?width=1200&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=722c8249d3097a6f7f2b9373d6f3ff9250a70504&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Interview questions can sometimes get a bit tougher to answer. That’s why Wissenhive presented this blog named ‘&lt;a href=""https://www.wissenhive.com/blogs/top-50-deep-learning-interview-questions-and-answers""&gt;Top 50 Deep Learning Interview Questions&lt;/a&gt;’ while putting together the most asked interview questions with answers by industry experts and professionals.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,munjq5,True,,Wissenhive,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/munjq5/top_50_deep_learning_interview_questions_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/munjq5/top_50_deep_learning_interview_questions_and/,66146,1618915243.0,0,,False,,,"{'brplwikk4bu61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/brplwikk4bu61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8148a15ca3f42ca0dafcec6666bfab9ba1abc5f0'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/brplwikk4bu61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=04c051c6d8105eedade1903518375286faa16334'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/brplwikk4bu61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=75a4318f85a9c500b41f4c127d8b633e4096c224'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/brplwikk4bu61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8e9462cf9d583578ca8eee751ae94b4eb9b5b0bf'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/brplwikk4bu61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ac30b3ac0c26dc1588697f08ad680687e296d1ce'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/brplwikk4bu61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f519ee88095bccf3fa6d21ac9f52dc198389bc0d'}], 's': {'y': 675, 'x': 1200, 'u': 'https://preview.redd.it/brplwikk4bu61.jpg?width=1200&amp;format=pjpg&amp;auto=webp&amp;s=722c8249d3097a6f7f2b9373d6f3ff9250a70504'}, 'id': 'brplwikk4bu61'}}",,,,
,deeplearning,"A research team from Rice University, IBM and USC combine compressed sensing, non-convex optimization and acceleration techniques to introduce a new algorithm — Momentum Inspired Factored Gradient Descent (MiFGD) — that pushes QST beyond current capabilities.

Here is a quick read: [Rice University, IBM &amp; USC Study Pushes Quantum State Tomography Beyond Current Computation Capabilities](https://syncedreview.com/2021/04/20/rice-university-ibm-usc-study-pushes-quantum-state-tomography-beyond-current-computation-capabilities/).

The paper *Fast Quantum State Reconstruction via Accelerated Non-Convex Programming* is on [arXiv](https://arxiv.org/pdf/2104.07006.pdf).",t2_2fv4yodo,False,,0,False,"[R] Rice University, IBM &amp; USC Study Pushes Quantum State Tomography Beyond Current Computation Capabilities",[],r/deeplearning,False,6,,0,,False,t3_mut9qt,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1618962332.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Rice University, IBM and USC combine compressed sensing, non-convex optimization and acceleration techniques to introduce a new algorithm — Momentum Inspired Factored Gradient Descent (MiFGD) — that pushes QST beyond current capabilities.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/20/rice-university-ibm-usc-study-pushes-quantum-state-tomography-beyond-current-computation-capabilities/""&gt;Rice University, IBM &amp;amp; USC Study Pushes Quantum State Tomography Beyond Current Computation Capabilities&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Fast Quantum State Reconstruction via Accelerated Non-Convex Programming&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.07006.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mut9qt,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mut9qt/r_rice_university_ibm_usc_study_pushes_quantum/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mut9qt/r_rice_university_ibm_usc_study_pushes_quantum/,66146,1618933532.0,0,,False,,,,,,,
,deeplearning,"I'm working on a multiclass semantic segmentation dataset with around `1000 images` and I was wondering how do you determine what the best `train/test/split` is for your dataset without going into complicated/time-consuming territory with cross-validation etc. 

I know that `80/20` is a common split, so would something like `80/5/15` be ideal for a dataset of this size? Or would a dataset of this size be fine with something like a `60/24/16` (i.e. 60 train and then a further 60/40 on the remaining test/val data). 

Bit confused here so advice from someone with greater experience would be very helpful. Cheers.",t2_8k0yg7k7,False,,0,False,What is the best train/test/val split?,[],r/deeplearning,False,6,,0,,False,t3_mus5l7,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1618959332.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m working on a multiclass semantic segmentation dataset with around &lt;code&gt;1000 images&lt;/code&gt; and I was wondering how do you determine what the best &lt;code&gt;train/test/split&lt;/code&gt; is for your dataset without going into complicated/time-consuming territory with cross-validation etc. &lt;/p&gt;

&lt;p&gt;I know that &lt;code&gt;80/20&lt;/code&gt; is a common split, so would something like &lt;code&gt;80/5/15&lt;/code&gt; be ideal for a dataset of this size? Or would a dataset of this size be fine with something like a &lt;code&gt;60/24/16&lt;/code&gt; (i.e. 60 train and then a further 60/40 on the remaining test/val data). &lt;/p&gt;

&lt;p&gt;Bit confused here so advice from someone with greater experience would be very helpful. Cheers.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mus5l7,True,,glampiggy,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mus5l7/what_is_the_best_traintestval_split/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mus5l7/what_is_the_best_traintestval_split/,66146,1618930532.0,0,,False,,,,,,,
,deeplearning,"I couldn't find a labeled text dataset to do emotions classification (Joy, Sadness, Anger ...) In French language. So, I thought about translating an English Dataset (labelled) to French and train a model on it.

Is it a good idea, or can the translation cause some kind of bias? Any suggestions or ideas?",t2_4e8fnhye,False,,0,False,French text emotion classification,[],r/deeplearning,False,6,,0,,False,t3_mul033,False,dark,1.0,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1618931912.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I couldn&amp;#39;t find a labeled text dataset to do emotions classification (Joy, Sadness, Anger ...) In French language. So, I thought about translating an English Dataset (labelled) to French and train a model on it.&lt;/p&gt;

&lt;p&gt;Is it a good idea, or can the translation cause some kind of bias? Any suggestions or ideas?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mul033,True,,spopgg3,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mul033/french_text_emotion_classification/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mul033/french_text_emotion_classification/,66146,1618903112.0,0,,False,,,,,,,
,deeplearning,"I'm training a custom object detector using Keras on my GTX 1660 Super. I use Ubuntu 20.04. During the training, I have noticed the temperature reach 70-80 C. I don't know if that's normal or will it damage my GPU in the long run if I keep training more?

Also I don't have any extra fans, just the ones with the graphics card and my case is actually pretty airy. Should I be investing in more fans it it's a problem?

I'm sorry if that's a very noob question, I just got started with deep learning with gpu :)",t2_65zulcar,False,,0,False,GPU heats up during training.,[],r/deeplearning,False,6,,0,,False,t3_mulesk,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618933944.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m training a custom object detector using Keras on my GTX 1660 Super. I use Ubuntu 20.04. During the training, I have noticed the temperature reach 70-80 C. I don&amp;#39;t know if that&amp;#39;s normal or will it damage my GPU in the long run if I keep training more?&lt;/p&gt;

&lt;p&gt;Also I don&amp;#39;t have any extra fans, just the ones with the graphics card and my case is actually pretty airy. Should I be investing in more fans it it&amp;#39;s a problem?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m sorry if that&amp;#39;s a very noob question, I just got started with deep learning with gpu :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mulesk,True,,TheSimonRoy,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mulesk/gpu_heats_up_during_training/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mulesk/gpu_heats_up_during_training/,66146,1618905144.0,0,,False,,,,,,,
,deeplearning,,t2_7rkqf607,False,,0,False,Stream popular deep learning datasets into pytorch with just 3 lines of code,[],r/deeplearning,False,6,,0,,False,t3_mujjmu,False,dark,0.83,,public,4,0,{},,False,[],,True,False,,{},,False,4,,False,False,,False,,[],{},,False,,1618925486.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/vmw1dflel9u61.gif,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mujjmu,True,,Shoulder_Feeling,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mujjmu/stream_popular_deep_learning_datasets_into/,all_ads,False,https://i.redd.it/vmw1dflel9u61.gif,66146,1618896686.0,0,,False,,,,,,,
,deeplearning,,t2_3r02kqm0,False,,0,False,The Pianist AI: Optimization Progress = Level 4 Try 1,[],r/deeplearning,False,6,,0,,False,t3_mun0sc,False,dark,1.0,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oGQW54v8nck?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Level 4: Try 1', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oGQW54v8nck?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '[ The Pianist AI ]', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/oGQW54v8nck/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ThePianistAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oGQW54v8nck?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mun0sc', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1618941731.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/oGQW54v8nck,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mun0sc,True,,amin_mlm,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mun0sc/the_pianist_ai_optimization_progress_level_4_try_1/,all_ads,False,https://youtu.be/oGQW54v8nck,66146,1618912931.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Level 4: Try 1', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oGQW54v8nck?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '[ The Pianist AI ]', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/oGQW54v8nck/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ThePianistAI'}}",False,,,,,,,
,deeplearning,"Hi

Is there any book that teaches Pix2Pix netwe=roks in a very structured and good way?

Like Chollet's books on deep learning.

I want to learn pix2pix, but I was not able to find a reliable, good source. Any help will be appreciated.",t2_8a7rf9yb,False,,0,False,learn Pix2Pix in a book,[],r/deeplearning,False,6,,0,,False,t3_mumbpp,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1618938502.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi&lt;/p&gt;

&lt;p&gt;Is there any book that teaches Pix2Pix netwe=roks in a very structured and good way?&lt;/p&gt;

&lt;p&gt;Like Chollet&amp;#39;s books on deep learning.&lt;/p&gt;

&lt;p&gt;I want to learn pix2pix, but I was not able to find a reliable, good source. Any help will be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mumbpp,True,,AromaticCustomer7765,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mumbpp/learn_pix2pix_in_a_book/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mumbpp/learn_pix2pix_in_a_book/,66146,1618909702.0,0,,False,,,,,,,
,deeplearning,I am aware of Soft actor-critic and Advantage Weighted Actor-Critic (AWAC). Is there any algorithm published in a research paper or otherwise demonstrated to outperform AWAC?,t2_4md9jqrc,False,,0,False,Best Reinforcement Learning Algorithm?,[],r/deeplearning,False,6,,0,,False,t3_mubnm3,False,dark,0.9,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1618898265.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am aware of Soft actor-critic and Advantage Weighted Actor-Critic (AWAC). Is there any algorithm published in a research paper or otherwise demonstrated to outperform AWAC?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mubnm3,True,,nitinkulkarnigamer,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/mubnm3/best_reinforcement_learning_algorithm/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mubnm3/best_reinforcement_learning_algorithm/,66146,1618869465.0,0,,False,,,,,,,
,deeplearning,,t2_2p1g2k3,False,,0,False,Robust Subspace Recovery Layer for anomaly detection in PyTorch,[],r/deeplearning,False,6,,0,,False,t3_muk3tt,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1618927936.0,text,6,,,text,zablo.net,False,,,,,https://zablo.net/blog/post/robust-space-recovery-rsrlayer-pytorch/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,muk3tt,True,,marrrcin,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/muk3tt/robust_subspace_recovery_layer_for_anomaly/,all_ads,False,https://zablo.net/blog/post/robust-space-recovery-rsrlayer-pytorch/,66146,1618899136.0,0,,False,,,,,,,
,deeplearning,"I’ve led over 20 AI workshops teaching engineers the basics in AI systems and getting them to the point where they can implement the start of the art systems available. It is a fantastic experience to teach deep learning in China and help build the skills of 1000’s engineers. While I might have been the teacher, I ended up learning a lot myself about the state of china’s AI field. 

[Here are the top five things I picked up while teaching in China.](https://www.educateai.org/5-things-i-learned-teaching-deep-learning-in-china/)",t2_33ikrfmw,False,,0,False,[D] 5 Things I Learned Teaching Deep Learning in China,[],r/deeplearning,False,6,,0,,False,t3_mty5x3,False,dark,0.83,,public,25,0,{},,False,[],,False,False,,{},,False,25,,False,False,,False,,[],{},,True,,1618858892.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve led over 20 AI workshops teaching engineers the basics in AI systems and getting them to the point where they can implement the start of the art systems available. It is a fantastic experience to teach deep learning in China and help build the skills of 1000’s engineers. While I might have been the teacher, I ended up learning a lot myself about the state of china’s AI field. &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.educateai.org/5-things-i-learned-teaching-deep-learning-in-china/""&gt;Here are the top five things I picked up while teaching in China.&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mty5x3,True,,cdossman,,14,True,all_ads,False,[],False,,/r/deeplearning/comments/mty5x3/d_5_things_i_learned_teaching_deep_learning_in/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mty5x3/d_5_things_i_learned_teaching_deep_learning_in/,66146,1618830092.0,0,,False,,,,,,,
,deeplearning,,t2_tcz0hi9,False,,0,False,Coursera offering paid courses for free until 30/4,[],r/deeplearning,False,6,,0,,False,t3_mu0m88,False,dark,0.86,,public,16,0,{},,False,[],,False,False,,{},,False,16,,False,False,,False,,[],{},,False,,1618867745.0,text,6,,,text,onlinecoursesgalore-com.cdn.ampproject.org,False,,,,,https://onlinecoursesgalore-com.cdn.ampproject.org/c/s/onlinecoursesgalore.com/coursera-free-courses/amp/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mu0m88,True,,poonddetatte,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mu0m88/coursera_offering_paid_courses_for_free_until_304/,all_ads,False,https://onlinecoursesgalore-com.cdn.ampproject.org/c/s/onlinecoursesgalore.com/coursera-free-courses/amp/,66146,1618838945.0,0,,False,,,,,,,
,deeplearning,"GANs have taken the world of machine learning by storm by creating new images and texts based on only a collection of examples. As you may already know, GANs can even generate human faces from scratch. The faces generated do not belong to any person, alive or dead, yet they are astoundingly realistic.

This article gives a complete guide to understanding GANs, how they work, and example code using PyTorch.

Topics covered include:

* Introduction to GANs
* Understanding Generative and Discriminative Models
* Types of Generative Models
   * Variational Autoencoders (VAE)
   * Generative Adversarial Networks (GANs)
* Discriminators
* Generators
* In-depth Understanding of Training
* Applications
* Conclusion

Article link: [https://blog.paperspace.com/complete-guide-to-gans/](https://blog.paperspace.com/complete-guide-to-gans/)

Comments and discussion encouraged!",t2_15en0l,False,,0,False,[Article] Complete Guide to GANs,[],r/deeplearning,False,6,,0,,False,t3_mu58up,False,dark,0.67,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1618880759.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;GANs have taken the world of machine learning by storm by creating new images and texts based on only a collection of examples. As you may already know, GANs can even generate human faces from scratch. The faces generated do not belong to any person, alive or dead, yet they are astoundingly realistic.&lt;/p&gt;

&lt;p&gt;This article gives a complete guide to understanding GANs, how they work, and example code using PyTorch.&lt;/p&gt;

&lt;p&gt;Topics covered include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Introduction to GANs&lt;/li&gt;
&lt;li&gt;Understanding Generative and Discriminative Models&lt;/li&gt;
&lt;li&gt;Types of Generative Models

&lt;ul&gt;
&lt;li&gt;Variational Autoencoders (VAE)&lt;/li&gt;
&lt;li&gt;Generative Adversarial Networks (GANs)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Discriminators&lt;/li&gt;
&lt;li&gt;Generators&lt;/li&gt;
&lt;li&gt;In-depth Understanding of Training&lt;/li&gt;
&lt;li&gt;Applications&lt;/li&gt;
&lt;li&gt;Conclusion&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Article link: &lt;a href=""https://blog.paperspace.com/complete-guide-to-gans/""&gt;https://blog.paperspace.com/complete-guide-to-gans/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Comments and discussion encouraged!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mu58up,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mu58up/article_complete_guide_to_gans/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mu58up/article_complete_guide_to_gans/,66146,1618851959.0,0,,False,,,,,,,
,deeplearning,"What would you guys suggest as the best online resource for getting started with Deep Learning? Looking for something that is comprehensive, encompasses majority of the concepts and includes a good explanation of the math.",t2_5fexn06w,False,,0,False,Best resource to learn Deep Learning,[],r/deeplearning,False,6,,0,,False,t3_mtut6l,False,dark,0.86,,public,15,0,{},,False,[],,False,False,,{},,False,15,,False,False,,False,,[],{},,True,,1618843139.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What would you guys suggest as the best online resource for getting started with Deep Learning? Looking for something that is comprehensive, encompasses majority of the concepts and includes a good explanation of the math.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mtut6l,True,,Substantial-East1107,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/mtut6l/best_resource_to_learn_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mtut6l/best_resource_to_learn_deep_learning/,66146,1618814339.0,0,,False,,,,,,,
,deeplearning,"A research team from DeepMind introduces Anakin and Sebulba, two architectures that demonstrate reinforcement learning platforms based on TPUs can efficiently deliver exceptional performance at scale and with low cost.

Here is a quick read: [DeepMind 'Podracer' TPU-Based RL Frameworks Deliver Exceptional Performance at Low Cost](https://syncedreview.com/2021/04/19/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost/).

The paper *Podracer Architectures for Scalable Reinforcement Learning* is on [arXiv](https://arxiv.org/pdf/2104.06272.pdf).",t2_2fv4yodo,False,,0,False,[N] DeepMind 'Podracer' TPU-Based RL Frameworks Deliver Exceptional Performance at Low Cost,[],r/deeplearning,False,6,,0,,False,t3_mu4eh4,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618878436.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from DeepMind introduces Anakin and Sebulba, two architectures that demonstrate reinforcement learning platforms based on TPUs can efficiently deliver exceptional performance at scale and with low cost.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/19/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost/""&gt;DeepMind &amp;#39;Podracer&amp;#39; TPU-Based RL Frameworks Deliver Exceptional Performance at Low Cost&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Podracer Architectures for Scalable Reinforcement Learning&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.06272.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mu4eh4,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mu4eh4/n_deepmind_podracer_tpubased_rl_frameworks/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mu4eh4/n_deepmind_podracer_tpubased_rl_frameworks/,66146,1618849636.0,0,,False,,,,,,,
,deeplearning,"I am interested in neural network pruning and have read research papers like: ""Learning both Weights and Connections for Efficient Neural networks"" by Han et al, ""The Lottery Ticket Hypothesis"" by Frankle et al, etc.

All of these papers use some form of iterative pruning, where each iterative pruning round prunes p% of the smallest magnitude weights either globally or in a layer-wise manner for CNNs like VGG, ResNet, etc.

Can you point me towards similar papers using one-shot pruning instead?


Thanks !",t2_2mmql89p,False,,0,False,One-shot pruning papers,[],r/deeplearning,False,6,,0,,False,t3_mtudbs,False,dark,0.94,,public,13,0,{},,False,[],,False,False,,{},,False,13,,False,False,,False,,[],{},,True,,1618841105.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am interested in neural network pruning and have read research papers like: &amp;quot;Learning both Weights and Connections for Efficient Neural networks&amp;quot; by Han et al, &amp;quot;The Lottery Ticket Hypothesis&amp;quot; by Frankle et al, etc.&lt;/p&gt;

&lt;p&gt;All of these papers use some form of iterative pruning, where each iterative pruning round prunes p% of the smallest magnitude weights either globally or in a layer-wise manner for CNNs like VGG, ResNet, etc.&lt;/p&gt;

&lt;p&gt;Can you point me towards similar papers using one-shot pruning instead?&lt;/p&gt;

&lt;p&gt;Thanks !&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mtudbs,True,,grid_world,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mtudbs/oneshot_pruning_papers/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mtudbs/oneshot_pruning_papers/,66146,1618812305.0,0,,False,,,,,,,
,deeplearning,"How do I start learning DL? This answer has to be in the context of an 14 year old. Yep. 

I am interested in PyTorch and have tried learning it a little not getting too far. I substantial PyTorch experience.

Thanks!",t2_8y369d0l,False,,0,False,I know this is over asked but hear me out...,[],r/deeplearning,False,6,,0,,False,t3_mub54w,False,dark,0.25,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618896787.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How do I start learning DL? This answer has to be in the context of an 14 year old. Yep. &lt;/p&gt;

&lt;p&gt;I am interested in PyTorch and have tried learning it a little not getting too far. I substantial PyTorch experience.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mub54w,True,,TheOracle2212,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/mub54w/i_know_this_is_over_asked_but_hear_me_out/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mub54w/i_know_this_is_over_asked_but_hear_me_out/,66146,1618867987.0,0,,False,,,,,,,
,deeplearning,"Hello,

I have a few hundred txt documents, each containing a few sentences about someone's history with substance abuse.

Based on 2 types of substances, I am trying to go through each file and collect the frequencies of 4 entities: **status** (e.g., past, current, none), **method** (e.g., inhale, chew), **amount** (e.g., 2 packs, 3-4 glasses), and **frequency** (e.g., a day).

Example txt file: ""He does not use tobacco. He sometimes drinks wine. He does not use drugs ever.""

**My dilemma:** again, I need to scrape the frequencies of these entities (essentially attributes of some type of substance abuse), ***but the wording/sentence structure varies a lot*** \--&gt; the **status** entity, for example, could see 'past', 'currently', 'still', 'sometimes', 'on weekends', 'back in 1984', etc... just a whole lot of things. I think I need to employ some NLP technique to classify/annotate this stuff but I am not sure how. **Any ideas?**

Thank you so much for your consideration.",t2_2ich5u4y,False,,0,False,NLP/Scraping Help :c,[],r/deeplearning,False,6,,0,,False,t3_mtvuqe,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1618848262.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I have a few hundred txt documents, each containing a few sentences about someone&amp;#39;s history with substance abuse.&lt;/p&gt;

&lt;p&gt;Based on 2 types of substances, I am trying to go through each file and collect the frequencies of 4 entities: &lt;strong&gt;status&lt;/strong&gt; (e.g., past, current, none), &lt;strong&gt;method&lt;/strong&gt; (e.g., inhale, chew), &lt;strong&gt;amount&lt;/strong&gt; (e.g., 2 packs, 3-4 glasses), and &lt;strong&gt;frequency&lt;/strong&gt; (e.g., a day).&lt;/p&gt;

&lt;p&gt;Example txt file: &amp;quot;He does not use tobacco. He sometimes drinks wine. He does not use drugs ever.&amp;quot;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;My dilemma:&lt;/strong&gt; again, I need to scrape the frequencies of these entities (essentially attributes of some type of substance abuse), &lt;strong&gt;&lt;em&gt;but the wording/sentence structure varies a lot&lt;/em&gt;&lt;/strong&gt; --&amp;gt; the &lt;strong&gt;status&lt;/strong&gt; entity, for example, could see &amp;#39;past&amp;#39;, &amp;#39;currently&amp;#39;, &amp;#39;still&amp;#39;, &amp;#39;sometimes&amp;#39;, &amp;#39;on weekends&amp;#39;, &amp;#39;back in 1984&amp;#39;, etc... just a whole lot of things. I think I need to employ some NLP technique to classify/annotate this stuff but I am not sure how. &lt;strong&gt;Any ideas?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Thank you so much for your consideration.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mtvuqe,True,,Stutoucan12,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mtvuqe/nlpscraping_help_c/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mtvuqe/nlpscraping_help_c/,66146,1618819462.0,0,,False,,,,,,,
,deeplearning,,t2_bk0t2z6a,False,,0,False,Image &amp; Video Background Removal Using Deep Learning,[],r/deeplearning,False,6,,0,,False,t3_mtaygk,False,dark,0.99,,public,123,0,{},,False,[],"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/gbelvs630xt61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/gbelvs630xt61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/gbelvs630xt61/DASHPlaylist.mpd?a=1626450219%2CZTk1MmU3YzhjNzZjMGExMGM3YTYwY2ZiYTdhODJkNzQ4MTcwOGIyZDA1MmU1NzlkMjZiYTUzNGY5OTQ5N2MzYQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 28, 'hls_url': 'https://v.redd.it/gbelvs630xt61/HLSPlaylist.m3u8?a=1626450219%2CM2Q3YmRiOWMxMDBhZWFmMGQyOTc5Njc3MjE4YmJhODk1MDJkYmEzMzg0ZTczMjU0ZmU4NmQ4YWVjMWQzOGM2OQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,123,,False,False,,False,,[],{},,False,,1618773556.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/gbelvs630xt61,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mtaygk,True,,nkapp,,10,True,all_ads,False,[],False,,/r/deeplearning/comments/mtaygk/image_video_background_removal_using_deep_learning/,all_ads,False,https://v.redd.it/gbelvs630xt61,66146,1618744756.0,0,"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/gbelvs630xt61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/gbelvs630xt61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/gbelvs630xt61/DASHPlaylist.mpd?a=1626450219%2CZTk1MmU3YzhjNzZjMGExMGM3YTYwY2ZiYTdhODJkNzQ4MTcwOGIyZDA1MmU1NzlkMjZiYTUzNGY5OTQ5N2MzYQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 28, 'hls_url': 'https://v.redd.it/gbelvs630xt61/HLSPlaylist.m3u8?a=1626450219%2CM2Q3YmRiOWMxMDBhZWFmMGQyOTc5Njc3MjE4YmJhODk1MDJkYmEzMzg0ZTczMjU0ZmU4NmQ4YWVjMWQzOGM2OQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,,t2_2o7eaff,False,,0,False,Machine Learning with ML.NET - NLP with BERT,[],r/deeplearning,False,6,,0,,False,t3_mtv9lc,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1618845286.0,text,6,,,text,rubikscode.net,False,,,,,https://rubikscode.net/2021/04/19/machine-learning-with-ml-net-nlp-with-bert/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mtv9lc,True,,RubiksCodeNMZ,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mtv9lc/machine_learning_with_mlnet_nlp_with_bert/,all_ads,False,https://rubikscode.net/2021/04/19/machine-learning-with-ml-net-nlp-with-bert/,66146,1618816486.0,0,,False,,,,,,,
,deeplearning,"Hi. I am new to the deep learning and I am trying to train a UNet model on my computer. My GPU is AMD Radeon RX550, which has 4 GB of dedicated memory and 8GB of shared one. When I try training the model on my GPU using DirectML, shared memory hits around 7 GB and my screen freezes constantly, e.g. it seems like the windowing system doesn't updates the screen properly. Note that my GPU usage is not 100% or anything like that, it changes around 0% and 80% very rapidly. CPU is also not a bottleneck. I wonder if any of you had a similar problem or have any idea about the reason of the problem? Thanks.",t2_8snumths,False,,0,False,Screen freezes constantly while training an UNet on GPU,[],r/deeplearning,False,6,,0,,False,t3_mtoeir,False,dark,0.81,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,True,,False,,[],{},,True,,1618818128.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi. I am new to the deep learning and I am trying to train a UNet model on my computer. My GPU is AMD Radeon RX550, which has 4 GB of dedicated memory and 8GB of shared one. When I try training the model on my GPU using DirectML, shared memory hits around 7 GB and my screen freezes constantly, e.g. it seems like the windowing system doesn&amp;#39;t updates the screen properly. Note that my GPU usage is not 100% or anything like that, it changes around 0% and 80% very rapidly. CPU is also not a bottleneck. I wonder if any of you had a similar problem or have any idea about the reason of the problem? Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mtoeir,True,,oilaba,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mtoeir/screen_freezes_constantly_while_training_an_unet/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mtoeir/screen_freezes_constantly_while_training_an_unet/,66146,1618789328.0,0,,False,,,,,,,
,deeplearning,"Hey guys, I have a GTX 1660 Super 6GB RAM and I'm trying to train a YoloV3 model for custom object detection. 

The training almost always crashes because CUDA ran out of memory. Is there a solution for this, can my goy run this?",t2_65zulcar,False,,0,False,Training YoloV3 always crashes.,[],r/deeplearning,False,6,,0,,False,t3_mtrdf7,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1618828899.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, I have a GTX 1660 Super 6GB RAM and I&amp;#39;m trying to train a YoloV3 model for custom object detection. &lt;/p&gt;

&lt;p&gt;The training almost always crashes because CUDA ran out of memory. Is there a solution for this, can my goy run this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mtrdf7,True,,TheSimonRoy,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mtrdf7/training_yolov3_always_crashes/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mtrdf7/training_yolov3_always_crashes/,66146,1618800099.0,0,,False,,,,,,,
,deeplearning,,t2_5fsp2x6v,False,,0,False,A Rigorous Study on Pretrained Model for NER | Research Papers Summary 014,[],r/deeplearning,False,6,,0,,False,t3_mtiyuf,False,dark,1.0,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/rL6FvknTdKw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'A Rigorous Study on Pretrained Model for NER | Research Papers Summary 014', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/rL6FvknTdKw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Ryan Ong', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/rL6FvknTdKw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/basketball10029508'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/rL6FvknTdKw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mtiyuf', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1618801003.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/rL6FvknTdKw,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mtiyuf,True,,RyanAI100,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mtiyuf/a_rigorous_study_on_pretrained_model_for_ner/,all_ads,False,https://youtu.be/rL6FvknTdKw,66146,1618772203.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'A Rigorous Study on Pretrained Model for NER | Research Papers Summary 014', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/rL6FvknTdKw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Ryan Ong', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/rL6FvknTdKw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/basketball10029508'}}",False,,,,,,,
,deeplearning,,t2_9mch2m14,False,,0,False,What happens when we die?,[],r/deeplearning,False,6,,0,,False,t3_mtnib7,False,dark,0.17,,public,0,0,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/ciOQ6AZIcy4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'What happens when we die?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/ciOQ6AZIcy4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Give Me Five', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/ciOQ6AZIcy4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/GiveMeFive-GMF'}}",False,False,,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/ciOQ6AZIcy4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mtnib7', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1618815133.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/ciOQ6AZIcy4,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mtnib7,True,,NickWaddell88,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mtnib7/what_happens_when_we_die/,all_ads,False,https://youtu.be/ciOQ6AZIcy4,66146,1618786333.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'What happens when we die?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/ciOQ6AZIcy4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Give Me Five', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/ciOQ6AZIcy4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/GiveMeFive-GMF'}}",False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,Implementing DeepMind's DQN from scratch! | Project Update,[],r/deeplearning,False,6,,0,,False,t3_mtfuz5,False,dark,0.57,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/DrOp_MQGn9o?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Implementing DeepMind's DQN from scratch! | Project Update"", 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/DrOp_MQGn9o?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/DrOp_MQGn9o/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/DrOp_MQGn9o?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mtfuz5', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1618791356.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/DrOp_MQGn9o,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mtfuz5,True,,gordicaleksa,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mtfuz5/implementing_deepminds_dqn_from_scratch_project/,all_ads,False,https://youtu.be/DrOp_MQGn9o,66146,1618762556.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Implementing DeepMind's DQN from scratch! | Project Update"", 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/DrOp_MQGn9o?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/DrOp_MQGn9o/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,"Hey there,

after trying and looking around a lot I have more and more the feeling that what I want to do is not possible.


My task sounds simple: Find circles in an image including position and radius, one label: `(x_i, y_i, r_i)`. (the coordinates are of course local for the image crop)

Now as far as I can tell having just these three outputs of a neural network for an image is called ""multi-output regression"". And that is very well possible. However my problem ist slightly different: My data can contain either _no circle_ at all or _several circles_. 

Which is what I would call ""multi-label regression"".
So instead of always getting out excatly three values, I need to get out a list with any number of the 3-tuple from above: `[(x_1, y_1, r_1), ...]`.

I know that for multi-label classification you can convert the labels into 1-hot encoding. So I thought I can do the same here but that does not work here for several reasons. One of which is: What would my last layer even be? In multi-class encoding it is just one for each category and you just don't use a softmax and then use a threshold for each category to get out which ones are good enough. But here? No idea.

So far I have been done a lot of my stuff on pytorch/fastai and find it very ergonomic.


At this point however, I am really discouraged, every time I try googling for it I cannot find anything close to what I am doing. Either it's about classification or it is multi-output regression. (Not multi-label AND multi-output regression)

Any help or pointer is greatly appreciated!",t2_8m2os,False,,0,False,Is multi-label regression even possible?,[],r/deeplearning,False,6,,0,,False,t3_mta4vq,False,dark,0.75,,public,2,3,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{'gid_1': 2},,True,,1618769547.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey there,&lt;/p&gt;

&lt;p&gt;after trying and looking around a lot I have more and more the feeling that what I want to do is not possible.&lt;/p&gt;

&lt;p&gt;My task sounds simple: Find circles in an image including position and radius, one label: &lt;code&gt;(x_i, y_i, r_i)&lt;/code&gt;. (the coordinates are of course local for the image crop)&lt;/p&gt;

&lt;p&gt;Now as far as I can tell having just these three outputs of a neural network for an image is called &amp;quot;multi-output regression&amp;quot;. And that is very well possible. However my problem ist slightly different: My data can contain either &lt;em&gt;no circle&lt;/em&gt; at all or &lt;em&gt;several circles&lt;/em&gt;. &lt;/p&gt;

&lt;p&gt;Which is what I would call &amp;quot;multi-label regression&amp;quot;.
So instead of always getting out excatly three values, I need to get out a list with any number of the 3-tuple from above: &lt;code&gt;[(x_1, y_1, r_1), ...]&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I know that for multi-label classification you can convert the labels into 1-hot encoding. So I thought I can do the same here but that does not work here for several reasons. One of which is: What would my last layer even be? In multi-class encoding it is just one for each category and you just don&amp;#39;t use a softmax and then use a threshold for each category to get out which ones are good enough. But here? No idea.&lt;/p&gt;

&lt;p&gt;So far I have been done a lot of my stuff on pytorch/fastai and find it very ergonomic.&lt;/p&gt;

&lt;p&gt;At this point however, I am really discouraged, every time I try googling for it I cannot find anything close to what I am doing. Either it&amp;#39;s about classification or it is multi-output regression. (Not multi-label AND multi-output regression)&lt;/p&gt;

&lt;p&gt;Any help or pointer is greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 2, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mta4vq,True,,yoyoyomama1,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/mta4vq/is_multilabel_regression_even_possible/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mta4vq/is_multilabel_regression_even_possible/,66146,1618740747.0,0,,False,,,,,,,
,deeplearning,,t2_8dpf89w7,False,,0,False,*Semantic* Video Search with OpenAI’s CLIP Neural Network (link in comments!),[],r/deeplearning,False,6,,0,,False,t3_msrsc4,False,dark,0.99,,public,65,4,{},,False,[],,True,False,,{},,False,65,,False,False,,False,,[],{'gid_1': 2},,False,,1618698667.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/as278qmzuqt61.gif,,False,False,False,False,False,"[{'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 20, 'id': 'award_5eac457f-ebac-449b-93a7-eb17b557f03c', 'penny_donate': 0, 'award_sub_type': 'PREMIUM', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=16&amp;height=16&amp;auto=webp&amp;s=bc61b528b8d075c26a3d0f2ad3d9e42259c51cbe', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=32&amp;height=32&amp;auto=webp&amp;s=d576c9a19ed29ca5624333239dbde289a146930b', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=48&amp;height=48&amp;auto=webp&amp;s=da1e45654f5acfb6be44fa07c168ad6420796f56', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=64&amp;height=64&amp;auto=webp&amp;s=677455ac05c563b5585f76e52ee96354f1430799', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=128&amp;height=128&amp;auto=webp&amp;s=25a3b6021a92685b01883fb3d947d2959a75d8b3', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you follow your heart, love is the answer', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'LOVE!', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=16&amp;height=16&amp;auto=webp&amp;s=bc61b528b8d075c26a3d0f2ad3d9e42259c51cbe', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=32&amp;height=32&amp;auto=webp&amp;s=d576c9a19ed29ca5624333239dbde289a146930b', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=48&amp;height=48&amp;auto=webp&amp;s=da1e45654f5acfb6be44fa07c168ad6420796f56', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=64&amp;height=64&amp;auto=webp&amp;s=677455ac05c563b5585f76e52ee96354f1430799', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png?width=128&amp;height=128&amp;auto=webp&amp;s=25a3b6021a92685b01883fb3d947d2959a75d8b3', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/j3azv69qjfn51_LOVE.png'}, {'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 2, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}, {'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,msrsc4,True,,designer1one,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/msrsc4/semantic_video_search_with_openais_clip_neural/,all_ads,False,https://i.redd.it/as278qmzuqt61.gif,66146,1618669867.0,0,,False,,,,,,,
,deeplearning,"This is my homework, we were asked to build a neural network for Binary classification, but the dataset only has 31 patterns and each data has 20 columns. Is there any advice for this small dataset task?",t2_6dydfryy,False,,0,False,how two train a neural network for a Binary classification with a small dataset?,[],r/deeplearning,False,6,,0,,False,t3_mtbckg,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618775331.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is my homework, we were asked to build a neural network for Binary classification, but the dataset only has 31 patterns and each data has 20 columns. Is there any advice for this small dataset task?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mtbckg,True,,pppfly,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mtbckg/how_two_train_a_neural_network_for_a_binary/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mtbckg/how_two_train_a_neural_network_for_a_binary/,66146,1618746531.0,0,,False,,,,,,,
,deeplearning,,t2_44mbtmjy,False,,0,False,"[P] Browse the web as usual and you'll start seeing code buttons appear next to papers everywhere. (Google, ArXiv, Twitter, Scholar, Github, and other websites). One of the fastest-growing browser extensions built for the AI/ML community :)",[],r/deeplearning,False,6,,0,,False,t3_mt0ifz,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1618727070.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/mt0eku/p_browse_the_web_as_usual_and_youll_start_seeing/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mt0ifz,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mt0ifz/p_browse_the_web_as_usual_and_youll_start_seeing/,all_ads,False,/r/MachineLearning/comments/mt0eku/p_browse_the_web_as_usual_and_youll_start_seeing/,66146,1618698270.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '[removed]', 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': ""[P] Browse the web as usual and you'll start seeing code buttons appear next to papers everywhere. (Google, ArXiv, Twitter, Scholar, Github, and other websites). One of the fastest-growing browser extensions built for the AI/ML community :)"", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'four', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mt0eku', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.8, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Project', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1618726690.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': 'moderator', 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mt0eku', 'is_robot_indexable': False, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/mt0eku/p_browse_the_web_as_usual_and_youll_start_seeing/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/mt0eku/p_browse_the_web_as_usual_and_youll_start_seeing/', 'subreddit_subscribers': 1931393, 'created_utc': 1618697890.0, 'num_crossposts': 11, 'media': None, 'is_video': False}]",t3_mt0eku,,,,,
,deeplearning,,t2_a8i2hluj,False,,0,False,The Genetic Algorithm and Deep Learning Play Snake: https://youtu.be/3bhP7zulFfY,[],r/deeplearning,False,6,,0,,False,t3_msl4xl,False,dark,0.94,,public,44,0,{},,False,[],"{'reddit_video': {'bitrate_kbps': 1200, 'fallback_url': 'https://v.redd.it/4oahxw8aaot61/DASH_480.mp4?source=fallback', 'height': 427, 'width': 854, 'scrubber_media_url': 'https://v.redd.it/4oahxw8aaot61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/4oahxw8aaot61/DASHPlaylist.mpd?a=1626450219%2CZDQ4YjJlOTRhZGRlMGRkMGVjOTI1NGE4MTlkNDZiZjU0MTZlOTg1YTRmMGRiMDc4MDU5NWJiYmU4ZWI5NjY4Zg%3D%3D&amp;v=1&amp;f=sd', 'duration': 21, 'hls_url': 'https://v.redd.it/4oahxw8aaot61/HLSPlaylist.m3u8?a=1626450219%2CYmQ2ZTkzNmRkZWY5MTNmNDQzODIwNGM2MjkwOWJiZDFiNjkxNGZjMGQ1YmQ4MjBiNWQ5MGYxZTcwYjZjMDI2NA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,44,,False,False,,False,,[],{},,False,,1618667494.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/4oahxw8aaot61,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,msl4xl,True,,ahmed26gad,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/msl4xl/the_genetic_algorithm_and_deep_learning_play/,all_ads,False,https://v.redd.it/4oahxw8aaot61,66146,1618638694.0,1,"{'reddit_video': {'bitrate_kbps': 1200, 'fallback_url': 'https://v.redd.it/4oahxw8aaot61/DASH_480.mp4?source=fallback', 'height': 427, 'width': 854, 'scrubber_media_url': 'https://v.redd.it/4oahxw8aaot61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/4oahxw8aaot61/DASHPlaylist.mpd?a=1626450219%2CZDQ4YjJlOTRhZGRlMGRkMGVjOTI1NGE4MTlkNDZiZjU0MTZlOTg1YTRmMGRiMDc4MDU5NWJiYmU4ZWI5NjY4Zg%3D%3D&amp;v=1&amp;f=sd', 'duration': 21, 'hls_url': 'https://v.redd.it/4oahxw8aaot61/HLSPlaylist.m3u8?a=1626450219%2CYmQ2ZTkzNmRkZWY5MTNmNDQzODIwNGM2MjkwOWJiZDFiNjkxNGZjMGQ1YmQ4MjBiNWQ5MGYxZTcwYjZjMDI2NA%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,,t2_1ffz9tjt,False,,0,False,AI agent plays Chrome Dino,[],r/deeplearning,False,6,,0,,False,t3_msv79u,False,dark,0.99,,public,5,0,{},,False,[],"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/zrxa2xkjsrt61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/zrxa2xkjsrt61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/zrxa2xkjsrt61/DASHPlaylist.mpd?a=1626450219%2CNDQyOWQ2ODE1YmRjZTgzNjQ2OWU4NTQ5ODE2YzczNjEwZDZjNGUwMjFiNDhjMTY3ZTI3OTllNjA2YWZjNjdmYw%3D%3D&amp;v=1&amp;f=sd', 'duration': 113, 'hls_url': 'https://v.redd.it/zrxa2xkjsrt61/HLSPlaylist.m3u8?a=1626450219%2CNDU5MjExY2Q1MGRhZjU4NGEyMGUxYTk0YTgzYjUwZDk3YWJhMGQ4NzNmZDk3ODc3YmFhOWU5NzUxN2Y1MDE5ZQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,5,,False,False,,False,,[],{},,False,,1618709946.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/zrxa2xkjsrt61,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,msv79u,True,,1991viet,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/msv79u/ai_agent_plays_chrome_dino/,all_ads,False,https://v.redd.it/zrxa2xkjsrt61,66146,1618681146.0,0,"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/zrxa2xkjsrt61/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/zrxa2xkjsrt61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/zrxa2xkjsrt61/DASHPlaylist.mpd?a=1626450219%2CNDQyOWQ2ODE1YmRjZTgzNjQ2OWU4NTQ5ODE2YzczNjEwZDZjNGUwMjFiNDhjMTY3ZTI3OTllNjA2YWZjNjdmYw%3D%3D&amp;v=1&amp;f=sd', 'duration': 113, 'hls_url': 'https://v.redd.it/zrxa2xkjsrt61/HLSPlaylist.m3u8?a=1626450219%2CNDU5MjExY2Q1MGRhZjU4NGEyMGUxYTk0YTgzYjUwZDk3YWJhMGQ4NzNmZDk3ODc3YmFhOWU5NzUxN2Y1MDE5ZQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,"Create 3D Models from Images! AI and Game Development, Design... GANverse3D &amp; NVIDIA Omniverse",[],r/deeplearning,False,6,,0,,False,t3_msphcs,False,dark,1.0,,public,5,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/dvjwRBZ3Hnw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Create 3D Models from Images! AI and Game Development, Design... GANverse3D &amp; NVIDIA Omniverse', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/dvjwRBZ3Hnw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/dvjwRBZ3Hnw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/dvjwRBZ3Hnw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/msphcs', 'height': 200}",,False,5,,False,False,,False,,[],{},,False,,1618689855.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/dvjwRBZ3Hnw,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,msphcs,True,,OnlyProggingForFun,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/msphcs/create_3d_models_from_images_ai_and_game/,all_ads,False,https://youtu.be/dvjwRBZ3Hnw,66146,1618661055.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Create 3D Models from Images! AI and Game Development, Design... GANverse3D &amp; NVIDIA Omniverse', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/dvjwRBZ3Hnw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/dvjwRBZ3Hnw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,,,,,,,
,deeplearning,"Hi guys 
Am a medical student whose very interested in DL and ML in general 
I've been wanting to create a brain tumors classification software with localization for a while now
I finished Andrew Ng's machine learning and his deep learning specialization 
Also finished part 1 of deep learning for coders by fastai 
I wrote some small projects of my own but nothing that fancy
I have -imho- somewhat a strong foundation but still need abit more practical knowledge.
My learning has been very sparsed 
With some stuff about OpenCV as well.
Can someone please guide me as to what should I focus on to gain enough basics to be able to build my classification system from the grounds up.
Should I keep using fastai or dig deeper into pytorch?
Also, can I build my classification system using OpenCV? 

Sorry for newbie questions -

Any help is highly appreciated",t2_5gxgp8ma,False,,0,False,Application of deep learning for medicine (Guidance needed),[],r/deeplearning,False,6,,0,,False,t3_msyd0a,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618719871.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys 
Am a medical student whose very interested in DL and ML in general 
I&amp;#39;ve been wanting to create a brain tumors classification software with localization for a while now
I finished Andrew Ng&amp;#39;s machine learning and his deep learning specialization 
Also finished part 1 of deep learning for coders by fastai 
I wrote some small projects of my own but nothing that fancy
I have -imho- somewhat a strong foundation but still need abit more practical knowledge.
My learning has been very sparsed 
With some stuff about OpenCV as well.
Can someone please guide me as to what should I focus on to gain enough basics to be able to build my classification system from the grounds up.
Should I keep using fastai or dig deeper into pytorch?
Also, can I build my classification system using OpenCV? &lt;/p&gt;

&lt;p&gt;Sorry for newbie questions -&lt;/p&gt;

&lt;p&gt;Any help is highly appreciated&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,msyd0a,True,,hhhhhxDD,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/msyd0a/application_of_deep_learning_for_medicine/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/msyd0a/application_of_deep_learning_for_medicine/,66146,1618691071.0,0,,False,,,,,,,
,deeplearning,Shared some things I learned using MTurk and hope it helps you build custom deep learning datasets for your projects going forward. [Check it out here](https://www.educateai.org/how-i-created-a-40000-labeled-audio-dataset-in-4-hours-of-work-and-500/),t2_33ikrfmw,False,,0,False,"How I Created a 40,000 Labeled Audio Dataset in 4 Hours of Work and $500",[],r/deeplearning,False,6,,0,,False,t3_msk9z2,False,dark,0.95,,public,16,0,{},,False,[],,False,False,,{},,False,16,,False,False,,False,,[],{},,True,,1618663658.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Shared some things I learned using MTurk and hope it helps you build custom deep learning datasets for your projects going forward. &lt;a href=""https://www.educateai.org/how-i-created-a-40000-labeled-audio-dataset-in-4-hours-of-work-and-500/""&gt;Check it out here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,msk9z2,True,,cdossman,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/msk9z2/how_i_created_a_40000_labeled_audio_dataset_in_4/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/msk9z2/how_i_created_a_40000_labeled_audio_dataset_in_4/,66146,1618634858.0,0,,False,,,,,,,
,deeplearning,"I'm fairly new to deep learning and I'm particularly struggling with the input/output dimensions between each layer.  I'm constantly getting incorrect dimension errors when compiling my models.  Does anyone have a good resource to make sense of all the layer inputs/outputs?  

I'm constantly viewing model summary and visualizing the model using ""plot\_model()"" but I'm still struggling to debut my code when presented with an incorrect dimension error.",t2_fvyvwj1,False,,0,False,Making Sense of Model.Summary(),[],r/deeplearning,False,6,,0,,False,t3_msx9s6,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1618716393.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m fairly new to deep learning and I&amp;#39;m particularly struggling with the input/output dimensions between each layer.  I&amp;#39;m constantly getting incorrect dimension errors when compiling my models.  Does anyone have a good resource to make sense of all the layer inputs/outputs?  &lt;/p&gt;

&lt;p&gt;I&amp;#39;m constantly viewing model summary and visualizing the model using &amp;quot;plot_model()&amp;quot; but I&amp;#39;m still struggling to debut my code when presented with an incorrect dimension error.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,msx9s6,True,,Kmysiak,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/msx9s6/making_sense_of_modelsummary/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/msx9s6/making_sense_of_modelsummary/,66146,1618687593.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,AI turns Minecraft into a realistic world !,[],r/deeplearning,False,6,,0,,False,t3_ms95ib,False,dark,0.96,,public,50,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/8-qU5_ozTu4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI turns Minecraft into a realistic world !', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/8-qU5_ozTu4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/8-qU5_ozTu4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/8-qU5_ozTu4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ms95ib', 'height': 200}",,False,50,,False,False,,False,,[],{},,False,,1618625891.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/8-qU5_ozTu4,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms95ib,True,,cmillionaire9,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/ms95ib/ai_turns_minecraft_into_a_realistic_world/,all_ads,False,https://youtu.be/8-qU5_ozTu4,66146,1618597091.0,5,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI turns Minecraft into a realistic world !', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/8-qU5_ozTu4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/8-qU5_ozTu4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,"Hello everyone,

I hope you are doing well.

I need to create 3 deep learning models based on a dataset. I am not able to do it, do you know where I can fin help and tell me what is the average price for that service?

Thank you",t2_am55ed55,False,,0,False,"Need help, cration of a deep learning model",[],r/deeplearning,False,6,,0,,False,t3_mso4e0,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1618682994.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I hope you are doing well.&lt;/p&gt;

&lt;p&gt;I need to create 3 deep learning models based on a dataset. I am not able to do it, do you know where I can fin help and tell me what is the average price for that service?&lt;/p&gt;

&lt;p&gt;Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mso4e0,True,,AZ4400,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/mso4e0/need_help_cration_of_a_deep_learning_model/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mso4e0/need_help_cration_of_a_deep_learning_model/,66146,1618654194.0,0,,False,,,,,,,
,deeplearning,,t2_57lwtxcm,False,,0,False,Batch Normalization Help,[],r/deeplearning,False,6,,0,,False,t3_mso0oo,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1618682433.0,text,6,,,text,self.learnmachinelearning,False,,,,,/r/learnmachinelearning/comments/mskjr1/batch_normalization/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mso0oo,True,,bacocololo,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mso0oo/batch_normalization_help/,all_ads,False,/r/learnmachinelearning/comments/mskjr1/batch_normalization/,66146,1618653633.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': 'Hello \nDo we need to normalize data with sklearn, if we add just after the input layer a Batchnormalization layer in an ANN ?\nthanks', 'author_fullname': 't2_57lwtxcm', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Batch normalization', 'link_flair_richtext': [{'e': 'text', 't': 'Question'}], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mskjr1', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Question', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': 1618636289.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1618664837.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnmachinelearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello \nDo we need to normalize data with sklearn, if we add just after the input layer a Batchnormalization layer in an ANN ?\nthanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'ec81b8ee-accf-11e9-b8f8-0ebea2df7d78', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ffb000', 'id': 'mskjr1', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'bacocololo', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/mskjr1/batch_normalization/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnmachinelearning/comments/mskjr1/batch_normalization/', 'subreddit_subscribers': 232337, 'created_utc': 1618636037.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_mskjr1,,,,,
,deeplearning,"A research team from ETH Zurich leverages existing spike-based learning circuits to propose a biologically plausible architecture that is highly successful in classifying distinct and complex spatio-temporal spike patterns. The work contributes to the design of ultra-low-power mixed-signal neuromorphic processing systems capable of distinguishing spatio-temporal patterns in spiking activity.

Here is a quick read: [ETH Zurich Leverages Spiking Neural Networks To Build Ultra-Low-Power Neuromorphic Processors](https://syncedreview.com/2021/04/16/eth-zurich-leverages-spiking-neural-networks-to-build-ultra-low-power-neuromorphic-processors/).

The paper An Error-Propagation Spiking Neural Network Compatible With Neuromorphic Processors is on [arXiv](https://arxiv.org/pdf/2104.05241.pdf).",t2_2fv4yodo,False,,0,False,[N] ETH Zurich Leverages Spiking Neural Networks To Build Ultra-Low-Power Neuromorphic Processors,[],r/deeplearning,False,6,,0,,False,t3_ms78rl,False,dark,0.87,,public,24,0,{},,False,[],,False,False,,{},,False,24,,False,False,,False,,[],{},,True,,1618620421.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from ETH Zurich leverages existing spike-based learning circuits to propose a biologically plausible architecture that is highly successful in classifying distinct and complex spatio-temporal spike patterns. The work contributes to the design of ultra-low-power mixed-signal neuromorphic processing systems capable of distinguishing spatio-temporal patterns in spiking activity.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/16/eth-zurich-leverages-spiking-neural-networks-to-build-ultra-low-power-neuromorphic-processors/""&gt;ETH Zurich Leverages Spiking Neural Networks To Build Ultra-Low-Power Neuromorphic Processors&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The paper An Error-Propagation Spiking Neural Network Compatible With Neuromorphic Processors is on &lt;a href=""https://arxiv.org/pdf/2104.05241.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms78rl,True,,Yuqing7,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/ms78rl/n_eth_zurich_leverages_spiking_neural_networks_to/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ms78rl/n_eth_zurich_leverages_spiking_neural_networks_to/,66146,1618591621.0,0,,False,,,,,,,
,deeplearning,,t2_13p32d,False,,0,False,speaker diarization for literary texts?,[],r/deeplearning,False,6,,0,,False,t3_msnv9e,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1618681623.0,text,6,,,text,self.learnmachinelearning,False,,,,,/r/learnmachinelearning/comments/mrmaym/equivalent_to_speaker_diarization_for_books/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,msnv9e,True,,tim_gabie,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/msnv9e/speaker_diarization_for_literary_texts/,all_ads,False,/r/learnmachinelearning/comments/mrmaym/equivalent_to_speaker_diarization_for_books/,66146,1618652823.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': ""I want to segment a novel based on which character in the novel said what. e.g. listing all text the character in the novel called Peter said.\n\n I think of it as the NLP equivalent for speaker diarization. I couldn't find papers on this yet. Anyone has a hint for me what I have to search for to find more about this topic?"", 'author_fullname': 't2_13p32d', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'equivalent to speaker diarization for books?', 'link_flair_richtext': [{'e': 'text', 't': 'Question'}], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mrmaym', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Question', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1618544223.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnmachinelearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to segment a novel based on which character in the novel said what. e.g. listing all text the character in the novel called Peter said.&lt;/p&gt;\n\n&lt;p&gt;I think of it as the NLP equivalent for speaker diarization. I couldn&amp;#39;t find papers on this yet. Anyone has a hint for me what I have to search for to find more about this topic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'ec81b8ee-accf-11e9-b8f8-0ebea2df7d78', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ffb000', 'id': 'mrmaym', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'tim_gabie', 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/mrmaym/equivalent_to_speaker_diarization_for_books/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnmachinelearning/comments/mrmaym/equivalent_to_speaker_diarization_for_books/', 'subreddit_subscribers': 232337, 'created_utc': 1618515423.0, 'num_crossposts': 4, 'media': None, 'is_video': False}]",t3_mrmaym,,,,,
,deeplearning,"As titled. 

sublime text is just an example of many possible code editors. It can be replaced with any other possible editors you are using.",t2_5hs4exo8,False,,0,False,Mac Users: Do you prefer PyCharm or (terminal+sublime text) when training/testing deep learning projects?,[],r/deeplearning,False,6,,0,,False,t3_msn751,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1618677992.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;As titled. &lt;/p&gt;

&lt;p&gt;sublime text is just an example of many possible code editors. It can be replaced with any other possible editors you are using.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,msn751,True,,zmWang0574,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/msn751/mac_users_do_you_prefer_pycharm_or/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/msn751/mac_users_do_you_prefer_pycharm_or/,66146,1618649192.0,0,,False,,,,,,,
,deeplearning,"Hey guys, I am trying to recreate results of “The Lottery Ticket  Hypothesis” by Frankle et al. They are using CIFAR-10 which has 50K  training images. Using a batch size = 64 gives 781 iterations/steps in  one epoch.

For VGG-18 &amp; ResNet-18, the authors propose the following learning rate schedule

1. Linear learning rate warmup for first k = 7813 steps from 0.0 to 0.1

&amp;#x200B;

After 10 epochs or 7813 training steps, the learning rate schedule is as follows-

1. For the next 21094 training steps (or, 27 epochs), use a learning rate of 0.1
2. For the next 13282 training steps (or, 17 epochs), use a learning rate of 0.01
3. For any remaining training steps, use a learning rate of 0.001

I have implemented this in TensorFlow2 as follows:

    from typing import Callable, List, Optional, Union
    
    class WarmUp(tf.keras.optimizers.schedules.LearningRateSchedule):
        """"""
        Applies a warmup schedule on a given learning rate decay schedule.
        Args:
            initial_learning_rate (:obj:`float`):
                The initial learning rate for the schedule after the warmup (so this will be the learning rate at the end
                of the warmup).            
            decay_schedule_fn (:obj:`Callable`):
                The schedule function to apply after the warmup for the rest of training.        
            warmup_steps (:obj:`int`):
                The number of steps for the warmup part of training.        
            power (:obj:`float`, `optional`, defaults to 1):
                The power to use for the polynomial warmup (defaults is a linear warmup).        
            name (:obj:`str`, `optional`):
                Optional name prefix for the returned tensors during the schedule.
        """"""
        def __init__(
            self,
            initial_learning_rate: float,
            decay_schedule_fn: Callable,
            warmup_steps: int,
            power: float = 1.0,
            name: str = None,
        ):
            super().__init__()
            self.initial_learning_rate = initial_learning_rate
            self.warmup_steps = warmup_steps
            self.power = power
            self.decay_schedule_fn = decay_schedule_fn
            self.name = name
    
        def __call__(self, step):
            with tf.name_scope(self.name or ""WarmUp"") as name:
                # Implements polynomial warmup. i.e., if global_step &lt; warmup_steps, the
                # learning rate will be `global_step/num_warmup_steps * init_lr`.
                global_step_float = tf.cast(step, tf.float32)
                warmup_steps_float = tf.cast(self.warmup_steps, tf.float32)
                warmup_percent_done = global_step_float / warmup_steps_float
                warmup_learning_rate = self.initial_learning_rate * tf.math.pow(warmup_percent_done, self.power)
                return tf.cond(
                    global_step_float &lt; warmup_steps_float,
                    lambda: warmup_learning_rate,
                    lambda: self.decay_schedule_fn(step - self.warmup_steps),
                    name=name,
                )
    
        def get_config(self):
            return {
                ""initial_learning_rate"": self.initial_learning_rate,
                ""decay_schedule_fn"": self.decay_schedule_fn,
                ""warmup_steps"": self.warmup_steps,
                ""power"": self.power,
                ""name"": self.name,
            }
    
    boundaries = [21093, 34376]
    values = [0.1, 0.01, 0.001]
    learning_rate_fn = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values)
    warmup_shcedule = WarmUp(initial_learning_rate = 0.1, decay_schedule_fn = learning_rate_fn, warmup_steps = 7813)
    optimizer = tf.keras.optimizers.SGD(learning_rate = warmup_shcedule, momentum = 0.9, decay = 0.0, nesterov = False)

I then train model using “tf.GradientTape” and view the learning rate as follows:

    optimizer._decayed_lr('float32').numpy()

The resulting learning during the 60 epochs of training can be viewed:

&amp;#x200B;

https://preview.redd.it/5epu9n8y3pt61.png?width=559&amp;format=png&amp;auto=webp&amp;s=0b190b02b1a348e81da03cbbb9bb4e66d9e0ef2d

You can access the complete code [here](https://github.com/arjun-majumdar/CNN_Classifications/blob/master/VGG18_Train_from_scratch-LR_Warmup_%26_Step_Decay.ipynb). Since I am new to PyTorch, can you show me how I can achieve the same learning rate scheduler in torch?

Thanks",t2_2mmql89p,False,,0,False,Learning rate scheduler,[],r/deeplearning,False,6,,0,,False,t3_msn3jw,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1618677449.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, I am trying to recreate results of “The Lottery Ticket  Hypothesis” by Frankle et al. They are using CIFAR-10 which has 50K  training images. Using a batch size = 64 gives 781 iterations/steps in  one epoch.&lt;/p&gt;

&lt;p&gt;For VGG-18 &amp;amp; ResNet-18, the authors propose the following learning rate schedule&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Linear learning rate warmup for first k = 7813 steps from 0.0 to 0.1&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;After 10 epochs or 7813 training steps, the learning rate schedule is as follows-&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;For the next 21094 training steps (or, 27 epochs), use a learning rate of 0.1&lt;/li&gt;
&lt;li&gt;For the next 13282 training steps (or, 17 epochs), use a learning rate of 0.01&lt;/li&gt;
&lt;li&gt;For any remaining training steps, use a learning rate of 0.001&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I have implemented this in TensorFlow2 as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from typing import Callable, List, Optional, Union

class WarmUp(tf.keras.optimizers.schedules.LearningRateSchedule):
    &amp;quot;&amp;quot;&amp;quot;
    Applies a warmup schedule on a given learning rate decay schedule.
    Args:
        initial_learning_rate (:obj:`float`):
            The initial learning rate for the schedule after the warmup (so this will be the learning rate at the end
            of the warmup).            
        decay_schedule_fn (:obj:`Callable`):
            The schedule function to apply after the warmup for the rest of training.        
        warmup_steps (:obj:`int`):
            The number of steps for the warmup part of training.        
        power (:obj:`float`, `optional`, defaults to 1):
            The power to use for the polynomial warmup (defaults is a linear warmup).        
        name (:obj:`str`, `optional`):
            Optional name prefix for the returned tensors during the schedule.
    &amp;quot;&amp;quot;&amp;quot;
    def __init__(
        self,
        initial_learning_rate: float,
        decay_schedule_fn: Callable,
        warmup_steps: int,
        power: float = 1.0,
        name: str = None,
    ):
        super().__init__()
        self.initial_learning_rate = initial_learning_rate
        self.warmup_steps = warmup_steps
        self.power = power
        self.decay_schedule_fn = decay_schedule_fn
        self.name = name

    def __call__(self, step):
        with tf.name_scope(self.name or &amp;quot;WarmUp&amp;quot;) as name:
            # Implements polynomial warmup. i.e., if global_step &amp;lt; warmup_steps, the
            # learning rate will be `global_step/num_warmup_steps * init_lr`.
            global_step_float = tf.cast(step, tf.float32)
            warmup_steps_float = tf.cast(self.warmup_steps, tf.float32)
            warmup_percent_done = global_step_float / warmup_steps_float
            warmup_learning_rate = self.initial_learning_rate * tf.math.pow(warmup_percent_done, self.power)
            return tf.cond(
                global_step_float &amp;lt; warmup_steps_float,
                lambda: warmup_learning_rate,
                lambda: self.decay_schedule_fn(step - self.warmup_steps),
                name=name,
            )

    def get_config(self):
        return {
            &amp;quot;initial_learning_rate&amp;quot;: self.initial_learning_rate,
            &amp;quot;decay_schedule_fn&amp;quot;: self.decay_schedule_fn,
            &amp;quot;warmup_steps&amp;quot;: self.warmup_steps,
            &amp;quot;power&amp;quot;: self.power,
            &amp;quot;name&amp;quot;: self.name,
        }

boundaries = [21093, 34376]
values = [0.1, 0.01, 0.001]
learning_rate_fn = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values)
warmup_shcedule = WarmUp(initial_learning_rate = 0.1, decay_schedule_fn = learning_rate_fn, warmup_steps = 7813)
optimizer = tf.keras.optimizers.SGD(learning_rate = warmup_shcedule, momentum = 0.9, decay = 0.0, nesterov = False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I then train model using “tf.GradientTape” and view the learning rate as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;optimizer._decayed_lr(&amp;#39;float32&amp;#39;).numpy()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The resulting learning during the 60 epochs of training can be viewed:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/5epu9n8y3pt61.png?width=559&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b190b02b1a348e81da03cbbb9bb4e66d9e0ef2d""&gt;https://preview.redd.it/5epu9n8y3pt61.png?width=559&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0b190b02b1a348e81da03cbbb9bb4e66d9e0ef2d&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can access the complete code &lt;a href=""https://github.com/arjun-majumdar/CNN_Classifications/blob/master/VGG18_Train_from_scratch-LR_Warmup_%26_Step_Decay.ipynb""&gt;here&lt;/a&gt;. Since I am new to PyTorch, can you show me how I can achieve the same learning rate scheduler in torch?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,msn3jw,True,,grid_world,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/msn3jw/learning_rate_scheduler/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/msn3jw/learning_rate_scheduler/,66146,1618648649.0,0,,False,,,"{'5epu9n8y3pt61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 84, 'x': 108, 'u': 'https://preview.redd.it/5epu9n8y3pt61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=bc517b6c6ecaca8032be8eb28511cb5ed03ca252'}, {'y': 169, 'x': 216, 'u': 'https://preview.redd.it/5epu9n8y3pt61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=1999173360c1a9267d8b61410b961c99a34812e5'}, {'y': 250, 'x': 320, 'u': 'https://preview.redd.it/5epu9n8y3pt61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=cbd42d6a19303ec6f6521518fa4dfb815b2bed9e'}], 's': {'y': 438, 'x': 559, 'u': 'https://preview.redd.it/5epu9n8y3pt61.png?width=559&amp;format=png&amp;auto=webp&amp;s=0b190b02b1a348e81da03cbbb9bb4e66d9e0ef2d'}, 'id': '5epu9n8y3pt61'}}",,,,
,deeplearning,"Hi, I'm a frontend web developer lacking a computer science background, but three years as a full-time dev has given me confidence I can take on bigger things if I commit to learning them.

I'm interested in learning to write software that can look at a detailed box score from a sports game and then write a pretty good article about what happened in that game. 

Assuming I have the skills to scrape box scores/data and feed that into an app, what do I need to focus on learning from here? Not only do I need to identify relevant data to present in the article, I will also need to integrate that data into normal sounding English language phrases that make sense in the context they appear. Plus probably a million things I'm not considering.

Any advice or guidance on a learning path forward is greatly appreciated!",t2_48db9wox,False,,0,False,I want to develop some fairly specific skills - can you help me understand my learning path?,[],r/deeplearning,False,6,,0,,False,t3_msgqcf,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618649800.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I&amp;#39;m a frontend web developer lacking a computer science background, but three years as a full-time dev has given me confidence I can take on bigger things if I commit to learning them.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m interested in learning to write software that can look at a detailed box score from a sports game and then write a pretty good article about what happened in that game. &lt;/p&gt;

&lt;p&gt;Assuming I have the skills to scrape box scores/data and feed that into an app, what do I need to focus on learning from here? Not only do I need to identify relevant data to present in the article, I will also need to integrate that data into normal sounding English language phrases that make sense in the context they appear. Plus probably a million things I&amp;#39;m not considering.&lt;/p&gt;

&lt;p&gt;Any advice or guidance on a learning path forward is greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,msgqcf,True,,snack0verflow,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/msgqcf/i_want_to_develop_some_fairly_specific_skills_can/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/msgqcf/i_want_to_develop_some_fairly_specific_skills_can/,66146,1618621000.0,0,,False,,,,,,,
,deeplearning,,t2_8xofg64y,False,,0,False,Using Machine Learning to Mind Control a Flamethrower,[],r/deeplearning,False,6,,0,,False,t3_ms9yid,False,dark,0.69,,public,5,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Y4YidkzHzRk?start=1&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Using Machine Learning to Mind Control a Flamethrower', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Y4YidkzHzRk?start=1&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Nathaniel F.', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Y4YidkzHzRk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYhOJb3wdimx_ApVBBRVP_w'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Y4YidkzHzRk?start=1&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ms9yid', 'height': 200}",,False,5,,False,False,,False,,[],{},,False,,1618628293.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=Y4YidkzHzRk&amp;t=1s,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms9yid,True,,NathanielF478,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ms9yid/using_machine_learning_to_mind_control_a/,all_ads,False,https://www.youtube.com/watch?v=Y4YidkzHzRk&amp;t=1s,66146,1618599493.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Using Machine Learning to Mind Control a Flamethrower', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Y4YidkzHzRk?start=1&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Nathaniel F.', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Y4YidkzHzRk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYhOJb3wdimx_ApVBBRVP_w'}}",False,,,,,,,
,deeplearning,"An overview of Unet architectures for semantic segmentation and biomedical image segmentation

A U-shaped architecture consists of a specific encoder-decoder  scheme: The encoder reduces the spatial dimensions in every layer and  increases the channels. On the other hand, the decoder increases the  spatial dims while reducing the channels. The tensor that is passed in  the decoder is usually called bottleneck. In the end, the spatial dims  are restored to make a prediction for each pixel in the input image.  These kinds of models are extremely utilized in real-world applications.  

This article aims to explore the Unet architectures that stood the test of time.

Link: [https://theaisummer.com/unet-architectures/](https://theaisummer.com/unet-architectures/)",t2_5zc2ef2h,False,,0,False,[D] - An overview of Unet architectures for semantic segmentation and biomedical image segmentation,[],r/deeplearning,False,6,,0,,False,t3_ms6ik5,False,dark,0.84,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1618618375.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;An overview of Unet architectures for semantic segmentation and biomedical image segmentation&lt;/p&gt;

&lt;p&gt;A U-shaped architecture consists of a specific encoder-decoder  scheme: The encoder reduces the spatial dimensions in every layer and  increases the channels. On the other hand, the decoder increases the  spatial dims while reducing the channels. The tensor that is passed in  the decoder is usually called bottleneck. In the end, the spatial dims  are restored to make a prediction for each pixel in the input image.  These kinds of models are extremely utilized in real-world applications.  &lt;/p&gt;

&lt;p&gt;This article aims to explore the Unet architectures that stood the test of time.&lt;/p&gt;

&lt;p&gt;Link: &lt;a href=""https://theaisummer.com/unet-architectures/""&gt;https://theaisummer.com/unet-architectures/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms6ik5,True,,black0017,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/ms6ik5/d_an_overview_of_unet_architectures_for_semantic/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ms6ik5/d_an_overview_of_unet_architectures_for_semantic/,66146,1618589575.0,0,,False,,,,,,,
,deeplearning,"A research team from NVIDIA, Stanford University and Microsoft Research propose a novel pipeline parallelism approach that improves throughput by more than 10 percent with a comparable memory footprint, showing such strategies can achieve high aggregate throughput while training models with up to a trillion parameters.

Here is a quick read: [NVIDIA, Stanford &amp; Microsoft Propose Efficient Trillion-Parameter Language Model Training on GPU Clusters](https://syncedreview.com/2021/04/15/nvidia-stanford-microsoft-propose-efficient-trillion-parameter-language-model-training-on-gpu-clusters/).

The paper *Efficient Large-Scale Language Model Training on GPU Clusters* is on [arXiv](https://arxiv.org/pdf/2104.04473.pdf).",t2_2fv4yodo,False,,0,False,"[N] NVIDIA, Stanford &amp; Microsoft Propose Efficient Trillion-Parameter Language Model Training on GPU Clusters",[],r/deeplearning,False,6,,0,,False,t3_mrus8v,False,dark,0.96,,public,32,0,{},,False,[],,False,False,,{},,False,32,,False,False,,False,,[],{},,True,,1618572093.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from NVIDIA, Stanford University and Microsoft Research propose a novel pipeline parallelism approach that improves throughput by more than 10 percent with a comparable memory footprint, showing such strategies can achieve high aggregate throughput while training models with up to a trillion parameters.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/15/nvidia-stanford-microsoft-propose-efficient-trillion-parameter-language-model-training-on-gpu-clusters/""&gt;NVIDIA, Stanford &amp;amp; Microsoft Propose Efficient Trillion-Parameter Language Model Training on GPU Clusters&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Efficient Large-Scale Language Model Training on GPU Clusters&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.04473.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mrus8v,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mrus8v/n_nvidia_stanford_microsoft_propose_efficient/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mrus8v/n_nvidia_stanford_microsoft_propose_efficient/,66146,1618543293.0,0,,False,,,,,,,
,deeplearning,"Can someone help me download datasets for optical flow benchmarks like flying chairs, kitti, sintel etc. Their webpages provide horribly slow download speeds like 70KB/s while the file size is in order of GB's. Is someone aware of any mirror site or torrent for these datasets?",t2_6ne1es5c,False,,0,False,Optical Flow Datasets,[],r/deeplearning,False,6,,0,,False,t3_ms8e40,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618623708.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can someone help me download datasets for optical flow benchmarks like flying chairs, kitti, sintel etc. Their webpages provide horribly slow download speeds like 70KB/s while the file size is in order of GB&amp;#39;s. Is someone aware of any mirror site or torrent for these datasets?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms8e40,True,,johnMcClane034,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ms8e40/optical_flow_datasets/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ms8e40/optical_flow_datasets/,66146,1618594908.0,0,,False,,,,,,,
,deeplearning,,t2_66dqvlke,False,,0,False,Compositional Zero-Shot Learning - Dr. Massimiliano Mancini (CVPR 2021) - Link to free zoom lecture by the author in comments,[],r/deeplearning,False,6,,0,,False,t3_ms7vnt,False,dark,0.75,,public,2,0,{},,False,[],,True,False,,{},,False,2,,False,False,,False,,[],{},,False,,1618622235.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/k7qmv9opjkt61.png,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms7vnt,True,,dataskml,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ms7vnt/compositional_zeroshot_learning_dr_massimiliano/,all_ads,False,https://i.redd.it/k7qmv9opjkt61.png,66146,1618593435.0,0,,False,,,,,,,
,deeplearning,"I want to perform a classification task using the features extracted from encoder .My question is since reconstruction using autoencoder and classification are two very different task, Can feature extracted using a pretrained encoder of a U-net be used for classification tasks?",t2_8lq1hd30,False,,0,False,[D] Are auto-encoder(say U-net) features good for transfer learning?,[],r/deeplearning,False,6,,0,,False,t3_ms4gly,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618612509.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to perform a classification task using the features extracted from encoder .My question is since reconstruction using autoencoder and classification are two very different task, Can feature extracted using a pretrained encoder of a U-net be used for classification tasks?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms4gly,True,,kaiser_17,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/ms4gly/d_are_autoencodersay_unet_features_good_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ms4gly/d_are_autoencodersay_unet_features_good_for/,66146,1618583709.0,0,,False,,,,,,,
,deeplearning,"A research team from ETH and UC Berkeley proposes a Deep Reward Learning by Simulating the Past (Deep RLSP) algorithm that represents rewards directly as a linear combination of features learned through self-supervised representation learning and enables agents to simulate human actions backwards in time to infer what they must have done.

Here is a quick read: [ETH Zurich &amp; UC Berkeley Method Automates Deep Reward-Learning by Simulating the Past](https://syncedreview.com/2021/04/14/eth-zurich-uc-berkeley-method-automates-deep-reward-learning-by-simulating-the-past/).

The paper Learning What To Do by Simulating the Past is on [arXiv](https://arxiv.org/pdf/2104.03946.pdf).",t2_2fv4yodo,False,,0,False,[N] ETH Zurich &amp; UC Berkeley Method Automates Deep Reward-Learning by Simulating the Past,[],r/deeplearning,False,6,,0,,False,t3_ms5lzo,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618615861.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from ETH and UC Berkeley proposes a Deep Reward Learning by Simulating the Past (Deep RLSP) algorithm that represents rewards directly as a linear combination of features learned through self-supervised representation learning and enables agents to simulate human actions backwards in time to infer what they must have done.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/14/eth-zurich-uc-berkeley-method-automates-deep-reward-learning-by-simulating-the-past/""&gt;ETH Zurich &amp;amp; UC Berkeley Method Automates Deep Reward-Learning by Simulating the Past&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The paper Learning What To Do by Simulating the Past is on &lt;a href=""https://arxiv.org/pdf/2104.03946.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms5lzo,True,,Yuqing7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ms5lzo/n_eth_zurich_uc_berkeley_method_automates_deep/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ms5lzo/n_eth_zurich_uc_berkeley_method_automates_deep/,66146,1618587061.0,0,,False,,,,,,,
,deeplearning,"Trying to understand few things from this:

1. Where do you source GPU computing from?
2. Do you run interactive sessions to train your models or do you create pipelines to automate training?
3. How frequent and long are your training sessions?",t2_waeap,False,,0,False,Where and how do you train your models?,[],r/deeplearning,False,6,,0,,False,t3_ms0cwa,False,dark,0.67,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1618597700.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Trying to understand few things from this:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Where do you source GPU computing from?&lt;/li&gt;
&lt;li&gt;Do you run interactive sessions to train your models or do you create pipelines to automate training?&lt;/li&gt;
&lt;li&gt;How frequent and long are your training sessions?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms0cwa,True,,fgp121,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/ms0cwa/where_and_how_do_you_train_your_models/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ms0cwa/where_and_how_do_you_train_your_models/,66146,1618568900.0,0,,False,,,,,,,
,deeplearning,"# [Spatially-Adaptive Pixelwise Networks for Fast Image Translation](https://t.me/casual_gan/27)

The authors propose а novel architecture for efficient high resolution image to image translation. At the core of the method is a pixel-wise model with spatially varying parameters that are predicted by a convolutional network from a low-resolution version of the input. Reportedly, an 18x speedup is achieved over baseline methods with a similar visual quality. More details [here](https://t.me/casual_gan/27).

https://preview.redd.it/clka5yifpkt61.png?width=1169&amp;format=png&amp;auto=webp&amp;s=0f0ad20441a407701ae45f1ec4b4c68488c6d343

 If you are not familiar with the paper check it out over [here](https://t.me/casual_gan/27).",t2_hhio3,False,,0,False,[R] Spatially-Adaptive Pixelwise Networks for Fast Image Translation (ASAPNet) by Shaham et al. - Explained,[],r/deeplearning,False,6,,0,,False,t3_ms8jg8,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1618624143.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;h1&gt;&lt;a href=""https://t.me/casual_gan/27""&gt;Spatially-Adaptive Pixelwise Networks for Fast Image Translation&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;The authors propose а novel architecture for efficient high resolution image to image translation. At the core of the method is a pixel-wise model with spatially varying parameters that are predicted by a convolutional network from a low-resolution version of the input. Reportedly, an 18x speedup is achieved over baseline methods with a similar visual quality. More details &lt;a href=""https://t.me/casual_gan/27""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/clka5yifpkt61.png?width=1169&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0f0ad20441a407701ae45f1ec4b4c68488c6d343""&gt;https://preview.redd.it/clka5yifpkt61.png?width=1169&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0f0ad20441a407701ae45f1ec4b4c68488c6d343&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you are not familiar with the paper check it out over &lt;a href=""https://t.me/casual_gan/27""&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms8jg8,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ms8jg8/r_spatiallyadaptive_pixelwise_networks_for_fast/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ms8jg8/r_spatiallyadaptive_pixelwise_networks_for_fast/,66146,1618595343.0,0,,False,,,"{'clka5yifpkt61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 129, 'x': 108, 'u': 'https://preview.redd.it/clka5yifpkt61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=edf4593ea5ecfecf3b78667601f4846d25c2f96f'}, {'y': 259, 'x': 216, 'u': 'https://preview.redd.it/clka5yifpkt61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a210f742a8c13857ac5e9a1db1fbe7717d794d33'}, {'y': 385, 'x': 320, 'u': 'https://preview.redd.it/clka5yifpkt61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d753aeca60c2980d3ae97ff1805a7d02d2a0e270'}, {'y': 770, 'x': 640, 'u': 'https://preview.redd.it/clka5yifpkt61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b858bd264e326898f9a63378b9566e5287f4c4c0'}, {'y': 1155, 'x': 960, 'u': 'https://preview.redd.it/clka5yifpkt61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ed4df192f9debfbea418a78ee0e3eeaa68f183c6'}, {'y': 1299, 'x': 1080, 'u': 'https://preview.redd.it/clka5yifpkt61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9296e5955fbf11d51153b50ace36f06b78f2dad3'}], 's': {'y': 1407, 'x': 1169, 'u': 'https://preview.redd.it/clka5yifpkt61.png?width=1169&amp;format=png&amp;auto=webp&amp;s=0f0ad20441a407701ae45f1ec4b4c68488c6d343'}, 'id': 'clka5yifpkt61'}}",,,,
,deeplearning,"I have implemented ""Unstructured Global absolute magnitude"" pruning using ""torch.nn.utils.prune"" with LeNet-5 trained on MNIST with iterative pruning. You can refer to the code [here](https://github.com/arjun-majumdar/CNN_Classifications/blob/master/Global_Pruning-LeNet5.ipynb).

Let me know your comments.",t2_2mmql89p,False,,0,False,PyTorch Pruning,[],r/deeplearning,False,6,,0,,False,t3_ms83ss,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618622892.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have implemented &amp;quot;Unstructured Global absolute magnitude&amp;quot; pruning using &amp;quot;torch.nn.utils.prune&amp;quot; with LeNet-5 trained on MNIST with iterative pruning. You can refer to the code &lt;a href=""https://github.com/arjun-majumdar/CNN_Classifications/blob/master/Global_Pruning-LeNet5.ipynb""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let me know your comments.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms83ss,True,,grid_world,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ms83ss/pytorch_pruning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ms83ss/pytorch_pruning/,66146,1618594092.0,0,,False,,,,,,,
,deeplearning,"I have a question.. 

I've got an Asus Nvidia 2070 powered laptop and an older Asus one with Nvidia 870 - 2 laptops, as well as an 1050 TI Nvidia PC. I want to be able to train deep learning tensorflow and pytorch computer vision and NLP models faster.

 What is the best choice to allow for optimally training simultaneously  on those separate, multiple GPU machines - Horovod, Airflow, Matlab or something else? Thanks in advance!",t2_7esxmrdf,False,,0,False,Multiple GPU powered machines training,[],r/deeplearning,False,6,,0,,False,t3_ms1icy,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1618586897.0,,[],{},,True,,1618602664.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a question.. &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve got an Asus Nvidia 2070 powered laptop and an older Asus one with Nvidia 870 - 2 laptops, as well as an 1050 TI Nvidia PC. I want to be able to train deep learning tensorflow and pytorch computer vision and NLP models faster.&lt;/p&gt;

&lt;p&gt;What is the best choice to allow for optimally training simultaneously  on those separate, multiple GPU machines - Horovod, Airflow, Matlab or something else? Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms1icy,True,,SubstantialAct3274,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ms1icy/multiple_gpu_powered_machines_training/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ms1icy/multiple_gpu_powered_machines_training/,66146,1618573864.0,0,,False,,,,,,,
,deeplearning,,t2_8kfikfqa,False,,0,False,*Great New Video*⚡💥THE POWER OF WORDS 🔥(Cursing Yourself)🔥 Expressions That Make You Weak,[],r/deeplearning,False,6,,0,,False,t3_msbies,False,dark,0.14,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/GMQqfCSe7AM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': '⚡💥THE POWER OF WORDS 🔥(Cursing Yourself)🔥 Expressions That Make You Weak and Cursed', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/GMQqfCSe7AM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'BadBoyD Masculinity TV', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/GMQqfCSe7AM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BadBoyDTV'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/GMQqfCSe7AM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/msbies', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1618632979.0,text,6,,,text,youtube.com,False,,,,,https://youtube.com/watch?v=GMQqfCSe7AM&amp;feature=share,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,msbies,True,,Gill_Boldberg1,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/msbies/great_new_videothe_power_of_words_cursing/,all_ads,False,https://youtube.com/watch?v=GMQqfCSe7AM&amp;feature=share,66146,1618604179.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': '⚡💥THE POWER OF WORDS 🔥(Cursing Yourself)🔥 Expressions That Make You Weak and Cursed', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/GMQqfCSe7AM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'BadBoyD Masculinity TV', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/GMQqfCSe7AM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/BadBoyDTV'}}",False,,,,,,,
,deeplearning,,t2_6l105jav,False,,0,False,Machine Learning &amp; Deep Learning in Python &amp; R -free course from udemy,[],r/deeplearning,False,6,,0,,False,t3_ms15lb,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1618601204.0,text,6,,,text,myfreeonlinecourses.com,False,,,,,https://www.myfreeonlinecourses.com/2021/02/100-off-machine-learning-deep-learning.html,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ms15lb,True,,Ordinary_Craft,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ms15lb/machine_learning_deep_learning_in_python_r_free/,all_ads,False,https://www.myfreeonlinecourses.com/2021/02/100-off-machine-learning-deep-learning.html,66146,1618572404.0,0,,False,,,,,,,
,deeplearning,"Hi, recenty I started to do some experiments with pix2pix GAN. The problem is that in the output of generator I can see visible lines as on the picture I attached.

Generator output -&gt; [https://imgur.com/a/Fi3CRfY](https://imgur.com/a/Fi3CRfY)

It looks like picture is divided into smaller squares. I did not modified overrall architecture and I am using 256x256x3 images as real sample and 256x256x3 edges as input to Generator. Thanks for you help.

Architecture I was inspired by -&gt; [https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/pix2pix/pix2pix.py](https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/pix2pix/pix2pix.py)",t2_6y28tayp,False,,0,False,GAN pix2pix strange artifacts,[],r/deeplearning,False,6,,0,,False,t3_mrzlgv,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1618565444.0,,[],{},,True,,1618594060.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, recenty I started to do some experiments with pix2pix GAN. The problem is that in the output of generator I can see visible lines as on the picture I attached.&lt;/p&gt;

&lt;p&gt;Generator output -&amp;gt; &lt;a href=""https://imgur.com/a/Fi3CRfY""&gt;https://imgur.com/a/Fi3CRfY&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It looks like picture is divided into smaller squares. I did not modified overrall architecture and I am using 256x256x3 images as real sample and 256x256x3 edges as input to Generator. Thanks for you help.&lt;/p&gt;

&lt;p&gt;Architecture I was inspired by -&amp;gt; &lt;a href=""https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/pix2pix/pix2pix.py""&gt;https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/pix2pix/pix2pix.py&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mrzlgv,True,,hreso52,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/mrzlgv/gan_pix2pix_strange_artifacts/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mrzlgv/gan_pix2pix_strange_artifacts/,66146,1618565260.0,0,,False,,,,True,,,
,deeplearning,"Hello ! 
I’m reaching out for some help here :)

Here is the problem: I have big 3D images (Medical Scans) that I resampled to 512*512*1024.

Overall, each file weighs about 3GB (2 channels with the size above). But I’ve seen in littérature that I must try to aim for a batch-size of minimum 2. Which would create 6GB of data per batch. This might be too much for a GPU to handle (or does it ?).

So I might need to do patch training. Meaning that I can slice up volumes of 128*128*256 and perform a training on that.

However, I’m anxious that training on patches The network will loose the general understanding of the body. And will see only part of organs.

What do you guys think about my problem, should I go for a patch training ? Can I hope that my Unet will still be able to perform well ? (It’s a tumor detection problem)

Thanks to you all :)",t2_92m269w6,False,,0,False,How does Patch Training work ?,[],r/deeplearning,False,6,,0,,False,t3_mrqiyp,False,dark,1.0,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1618557135.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello ! 
I’m reaching out for some help here :)&lt;/p&gt;

&lt;p&gt;Here is the problem: I have big 3D images (Medical Scans) that I resampled to 512&lt;em&gt;512&lt;/em&gt;1024.&lt;/p&gt;

&lt;p&gt;Overall, each file weighs about 3GB (2 channels with the size above). But I’ve seen in littérature that I must try to aim for a batch-size of minimum 2. Which would create 6GB of data per batch. This might be too much for a GPU to handle (or does it ?).&lt;/p&gt;

&lt;p&gt;So I might need to do patch training. Meaning that I can slice up volumes of 128&lt;em&gt;128&lt;/em&gt;256 and perform a training on that.&lt;/p&gt;

&lt;p&gt;However, I’m anxious that training on patches The network will loose the general understanding of the body. And will see only part of organs.&lt;/p&gt;

&lt;p&gt;What do you guys think about my problem, should I go for a patch training ? Can I hope that my Unet will still be able to perform well ? (It’s a tumor detection problem)&lt;/p&gt;

&lt;p&gt;Thanks to you all :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mrqiyp,True,,PositiveElectro,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/mrqiyp/how_does_patch_training_work/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mrqiyp/how_does_patch_training_work/,66146,1618528335.0,0,,False,,,,,,,
,deeplearning,"Hi! I'm looking for some help with the project I'm working on.

It's a  simple image-to-image translation project. I want to create a UI for that model. The project was built using PyTorch.I'm looking for a very simple UI just to demonstrate like selecting an image from the left side and showing the resulting image on the right side.

Any suggestions? Are there any broiler plate codes?",t2_94b3qz8q,False,,0,False,Simple UI for deep learning model,[],r/deeplearning,False,6,,0,,False,t3_mrxrxe,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1618556572.0,,[],{},,True,,1618585096.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! I&amp;#39;m looking for some help with the project I&amp;#39;m working on.&lt;/p&gt;

&lt;p&gt;It&amp;#39;s a  simple image-to-image translation project. I want to create a UI for that model. The project was built using PyTorch.I&amp;#39;m looking for a very simple UI just to demonstrate like selecting an image from the left side and showing the resulting image on the right side.&lt;/p&gt;

&lt;p&gt;Any suggestions? Are there any broiler plate codes?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mrxrxe,True,,aselsiriwardena,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mrxrxe/simple_ui_for_deep_learning_model/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mrxrxe/simple_ui_for_deep_learning_model/,66146,1618556296.0,0,,False,,,,,,,
,deeplearning,"Hi everyone, I am currently reading Least Square GAN [paper](https://arxiv.org/abs/1611.04076). But, I cannot interpret the one of the its figures.

&amp;#x200B;

[fig. 1](https://preview.redd.it/cm2hs30s3et61.jpg?width=1707&amp;format=pjpg&amp;auto=webp&amp;s=b154d4969b7373dbf7de129dc681b9d02901c11e)

Its caption goes like this:

&gt;Figure 1: Illustration of different behaviors of two loss functions. (a): Decision boundaries of two loss functions. Note that the decision boundary should go across the real data distribution for a successful GANs learning. Otherwise, the learning process is saturated. (b): Decision boundary of the sigmoid cross entropy loss function. It gets very small errors for the fake samples (in magenta) for updateing G as they are on the correct side of the decision boundary. (c): Decision boundary of the least squares loss function. It penalize the fake samples (in magenta), and as a result, it forces the generator to generate samples toward decision boundary.

I already knew the vanilla GAN structure. But I could not understand why decision boundary looks like this. Also, how are they different? Any help will be appreciated.

Edit: I am not sure this is the right place to ask. If so, sorry for inconvenience.",t2_gl6rlz5,False,,0,False,Decision boundary figure in Least square GAN paper,[],r/deeplearning,False,6,,0,,False,t3_mrmcv8,False,dark,0.83,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,1618516121.0,,[],{},,True,,1618544385.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, I am currently reading Least Square GAN &lt;a href=""https://arxiv.org/abs/1611.04076""&gt;paper&lt;/a&gt;. But, I cannot interpret the one of the its figures.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/cm2hs30s3et61.jpg?width=1707&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b154d4969b7373dbf7de129dc681b9d02901c11e""&gt;fig. 1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Its caption goes like this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Figure 1: Illustration of different behaviors of two loss functions. (a): Decision boundaries of two loss functions. Note that the decision boundary should go across the real data distribution for a successful GANs learning. Otherwise, the learning process is saturated. (b): Decision boundary of the sigmoid cross entropy loss function. It gets very small errors for the fake samples (in magenta) for updateing G as they are on the correct side of the decision boundary. (c): Decision boundary of the least squares loss function. It penalize the fake samples (in magenta), and as a result, it forces the generator to generate samples toward decision boundary.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I already knew the vanilla GAN structure. But I could not understand why decision boundary looks like this. Also, how are they different? Any help will be appreciated.&lt;/p&gt;

&lt;p&gt;Edit: I am not sure this is the right place to ask. If so, sorry for inconvenience.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mrmcv8,True,,tandir_boy,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mrmcv8/decision_boundary_figure_in_least_square_gan_paper/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mrmcv8/decision_boundary_figure_in_least_square_gan_paper/,66146,1618515585.0,0,,False,,,"{'cm2hs30s3et61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 33, 'x': 108, 'u': 'https://preview.redd.it/cm2hs30s3et61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=26a3f6ff4885a73591259fbb4699091ceeff5279'}, {'y': 66, 'x': 216, 'u': 'https://preview.redd.it/cm2hs30s3et61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5deaf39a0d1ca4d7bb0656130a566630c39dc35a'}, {'y': 98, 'x': 320, 'u': 'https://preview.redd.it/cm2hs30s3et61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=56a0a8737963948891bcaa9cb2bfd157ab4edaa7'}, {'y': 197, 'x': 640, 'u': 'https://preview.redd.it/cm2hs30s3et61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=68cffa1525ce66eadf5d4c15fae019783786285c'}, {'y': 296, 'x': 960, 'u': 'https://preview.redd.it/cm2hs30s3et61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a800713c89e2ae0f02e8989e32ccb84ca5812b77'}, {'y': 334, 'x': 1080, 'u': 'https://preview.redd.it/cm2hs30s3et61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=88daabcd35b30d04b770c2eafcbb25a17528ba02'}], 's': {'y': 528, 'x': 1707, 'u': 'https://preview.redd.it/cm2hs30s3et61.jpg?width=1707&amp;format=pjpg&amp;auto=webp&amp;s=b154d4969b7373dbf7de129dc681b9d02901c11e'}, 'id': 'cm2hs30s3et61'}}",,,,
,deeplearning,"Hi everyone,

&amp;#x200B;

I am interested in the optimization of algorithms, especially machine learning algorithms. I am looking to use both hardware and software optimizations in my Ph.D. 

&amp;#x200B;

I have started with machine learning for specific data of trajectory optimization, and I am looking forward to finding applications that are currently not very saturated and a lot of work can be done in them. And the applications where the possibility of application is solely dependent currently dependant on the optimization. i.e. the applications are time expensive, and for implementation, they need an optimized solution.

&amp;#x200B;

Please share your knowledge and suggestions for me.

&amp;#x200B;

Best Regards,

\-Ali Hassaan Mughal",t2_3evq31oz,False,,0,False,PhD Student in Computer Science [Need help in research/topics],[],r/deeplearning,False,6,,0,,False,t3_mruvy1,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618572469.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am interested in the optimization of algorithms, especially machine learning algorithms. I am looking to use both hardware and software optimizations in my Ph.D. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I have started with machine learning for specific data of trajectory optimization, and I am looking forward to finding applications that are currently not very saturated and a lot of work can be done in them. And the applications where the possibility of application is solely dependent currently dependant on the optimization. i.e. the applications are time expensive, and for implementation, they need an optimized solution.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Please share your knowledge and suggestions for me.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Best Regards,&lt;/p&gt;

&lt;p&gt;-Ali Hassaan Mughal&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mruvy1,True,,Alihassaanmughal,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mruvy1/phd_student_in_computer_science_need_help_in/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mruvy1/phd_student_in_computer_science_need_help_in/,66146,1618543669.0,0,,False,,,,,,,
,deeplearning,"A research team from Google Brain and New York University says the Natural Language Understanding (NLU) evaluation system is ""broken"" and proposes four criteria for improving NLU benchmarks.

Here is a quick read: [Google Brain &amp; NYU Guidelines Address ‘Broken’ NLU Benchmarking](https://syncedreview.com/2021/04/13/google-brain-nyu-guidelines-address-broken-nlu-benchmarking/).

The paper *What Will it Take to Fix Benchmarking in Natural Language Understanding?* is on [arXiv](https://arxiv.org/pdf/2104.02145.pdf).",t2_2fv4yodo,False,,0,False,[N] Google Brain &amp; NYU Guidelines Address ‘Broken’ NLU Benchmarking,[],r/deeplearning,False,6,,0,,False,t3_mrt6rv,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618566421.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Google Brain and New York University says the Natural Language Understanding (NLU) evaluation system is &amp;quot;broken&amp;quot; and proposes four criteria for improving NLU benchmarks.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/13/google-brain-nyu-guidelines-address-broken-nlu-benchmarking/""&gt;Google Brain &amp;amp; NYU Guidelines Address ‘Broken’ NLU Benchmarking&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;What Will it Take to Fix Benchmarking in Natural Language Understanding?&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.02145.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mrt6rv,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mrt6rv/n_google_brain_nyu_guidelines_address_broken_nlu/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mrt6rv/n_google_brain_nyu_guidelines_address_broken_nlu/,66146,1618537621.0,0,,False,,,,,,,
,deeplearning,"Hey Guys &amp; Gals,

While trying to implement different SOTA research papers, I had a roadblock in terms of finding working code for different **learning rate: decay, warmup &amp; schedules** (piece-wise decay, step decay, exponential decay, etc.). Therefore, I created a Jupyter Notebook implementing these concepts using TensorFlow 2.4, Python3.8 specifically for **custom training loops with tf.GradientTape** since most of the tutorials/blogs only show ""[model.fit](https://model.fit)()"" method. The code can be accessed [here](https://github.com/arjun-majumdar/CNN_Classifications/blob/master/LeNet_300_100-Learning_Rate_Decays_and_Scheduler.ipynb).

Let me know your thoughts/feedback",t2_2mmql89p,False,,0,False,"Learning Rate: Decay, Warmup &amp; Scheduler",[],r/deeplearning,False,6,,0,,False,t3_mrcpzu,False,dark,0.77,,public,9,0,{},,False,[],,False,False,,{},,False,9,,False,False,,False,,[],{},,True,,1618515110.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey Guys &amp;amp; Gals,&lt;/p&gt;

&lt;p&gt;While trying to implement different SOTA research papers, I had a roadblock in terms of finding working code for different &lt;strong&gt;learning rate: decay, warmup &amp;amp; schedules&lt;/strong&gt; (piece-wise decay, step decay, exponential decay, etc.). Therefore, I created a Jupyter Notebook implementing these concepts using TensorFlow 2.4, Python3.8 specifically for &lt;strong&gt;custom training loops with tf.GradientTape&lt;/strong&gt; since most of the tutorials/blogs only show &amp;quot;&lt;a href=""https://model.fit""&gt;model.fit&lt;/a&gt;()&amp;quot; method. The code can be accessed &lt;a href=""https://github.com/arjun-majumdar/CNN_Classifications/blob/master/LeNet_300_100-Learning_Rate_Decays_and_Scheduler.ipynb""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let me know your thoughts/feedback&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mrcpzu,True,,grid_world,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mrcpzu/learning_rate_decay_warmup_scheduler/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mrcpzu/learning_rate_decay_warmup_scheduler/,66146,1618486310.0,0,,False,,,,,,,
,deeplearning,,t2_2gxkjoj2,False,,0,False,How difficult is it to get accepted into DLRL or any other summer schools for AI?,[],r/deeplearning,False,6,,0,,False,t3_mrdrcm,False,dark,0.7,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1618519011.0,text,6,,,text,self.deeplearning,False,,,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mrdrcm,True,,anush1905,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mrdrcm/how_difficult_is_it_to_get_accepted_into_dlrl_or/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mrdrcm/how_difficult_is_it_to_get_accepted_into_dlrl_or/,66146,1618490211.0,0,,False,,,,,,,
,deeplearning," This guide is intended for anyone having zero or a small background in programming, maths, and machine learning. There is no specific order to follow, but a classic path would be from top to bottom. If you don't like reading books, skip it, if you don't want to follow an online course, you can skip it as well. There is not a single way to become a machine learning expert and with motivation, you can absolutely achieve it. 

**The video**: https://youtu.be/RirEw-uaS\_8?list=PLO4GrDnQanVfb6Ins6up1xScJHl8YuwPQ

**The complete article**: [https://pub.towardsai.net/start-machine-learning-in-2020-become-an-expert-from-nothing-for-free-f31587630cf7](https://pub.towardsai.net/start-machine-learning-in-2020-become-an-expert-from-nothing-for-free-f31587630cf7)

**All the links on GitHub**: [https://github.com/louisfb01/start-machine-learning-in-2020](https://github.com/louisfb01/start-machine-learning-in-2020)

Artificial is a fantastic field, but it goes extremely fast. Don't miss out on the most important and exciting news by joining great communities, people, newsletters, and more you can all find in this guide!",t2_c14wpji,False,,0,False,A Complete Roadmap for Beginners in Machine Learning in 2021+ many valuable resources for any data scientist / AI workers or enthusiasts + how to stay up-to-date with news,[],r/deeplearning,False,6,,0,,False,t3_mqovsq,False,dark,0.93,,public,73,0,{},,False,[],,False,False,,{},,False,73,,False,False,,False,,[],{},,True,,1618429775.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This guide is intended for anyone having zero or a small background in programming, maths, and machine learning. There is no specific order to follow, but a classic path would be from top to bottom. If you don&amp;#39;t like reading books, skip it, if you don&amp;#39;t want to follow an online course, you can skip it as well. There is not a single way to become a machine learning expert and with motivation, you can absolutely achieve it. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The video&lt;/strong&gt;: &lt;a href=""https://youtu.be/RirEw-uaS%5C_8?list=PLO4GrDnQanVfb6Ins6up1xScJHl8YuwPQ""&gt;https://youtu.be/RirEw-uaS\_8?list=PLO4GrDnQanVfb6Ins6up1xScJHl8YuwPQ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The complete article&lt;/strong&gt;: &lt;a href=""https://pub.towardsai.net/start-machine-learning-in-2020-become-an-expert-from-nothing-for-free-f31587630cf7""&gt;https://pub.towardsai.net/start-machine-learning-in-2020-become-an-expert-from-nothing-for-free-f31587630cf7&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;All the links on GitHub&lt;/strong&gt;: &lt;a href=""https://github.com/louisfb01/start-machine-learning-in-2020""&gt;https://github.com/louisfb01/start-machine-learning-in-2020&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Artificial is a fantastic field, but it goes extremely fast. Don&amp;#39;t miss out on the most important and exciting news by joining great communities, people, newsletters, and more you can all find in this guide!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mqovsq,True,,OnlyProggingForFun,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mqovsq/a_complete_roadmap_for_beginners_in_machine/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mqovsq/a_complete_roadmap_for_beginners_in_machine/,66146,1618400975.0,0,,False,,,,,,,
,deeplearning,,t2_kj0nv,False,,0,False,TTS: Text-to-Speech for All. Open-sourced by Mozilla,[],r/deeplearning,False,6,,0,,False,t3_mqws9a,False,dark,0.84,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,False,,1618453807.0,text,6,,,text,github.com,False,,,,,https://github.com/mozilla/TTS,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mqws9a,True,,binaryfor,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mqws9a/tts_texttospeech_for_all_opensourced_by_mozilla/,all_ads,False,https://github.com/mozilla/TTS,66146,1618425007.0,0,,False,,,,,,,
,deeplearning,"Beginners to artificial neural networks (ANNs) are likely to ask some questions. Some of these questions include:

* What is the number of hidden layers to use? 
* How many hidden neurons in each hidden layer? 
* What is the purpose of using hidden layers/neurons? 
* Is increasing the number of hidden layers/neurons always gives better results? 

I am pleased to tell we could answer such questions. To be clear, answering such questions might be too complex if the problem being solved is complicated. 

By the end of this article, you could at least get the idea of how these questions are answered and be able to test yourself based on simple examples.

[https://www.linkedin.com/pulse/beginners-ask-how-many-hidden-layersneurons-use-artificial-ahmed-gad](https://www.linkedin.com/pulse/beginners-ask-how-many-hidden-layersneurons-use-artificial-ahmed-gad/)",t2_a8i2hluj,False,,0,False,Beginners Ask “How Many Hidden Layers/Neurons to Use in Artificial Neural Networks?”,[],r/deeplearning,False,6,,0,,False,t3_mr7kav,False,dark,0.44,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618489845.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Beginners to artificial neural networks (ANNs) are likely to ask some questions. Some of these questions include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What is the number of hidden layers to use? &lt;/li&gt;
&lt;li&gt;How many hidden neurons in each hidden layer? &lt;/li&gt;
&lt;li&gt;What is the purpose of using hidden layers/neurons? &lt;/li&gt;
&lt;li&gt;Is increasing the number of hidden layers/neurons always gives better results? &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I am pleased to tell we could answer such questions. To be clear, answering such questions might be too complex if the problem being solved is complicated. &lt;/p&gt;

&lt;p&gt;By the end of this article, you could at least get the idea of how these questions are answered and be able to test yourself based on simple examples.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.linkedin.com/pulse/beginners-ask-how-many-hidden-layersneurons-use-artificial-ahmed-gad/""&gt;https://www.linkedin.com/pulse/beginners-ask-how-many-hidden-layersneurons-use-artificial-ahmed-gad&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mr7kav,True,,ahmed26gad,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mr7kav/beginners_ask_how_many_hidden_layersneurons_to/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mr7kav/beginners_ask_how_many_hidden_layersneurons_to/,66146,1618461045.0,0,,False,,,,,,,
,deeplearning,"This is entirely subjective, and I’m sure some computer geniuses have spoken about this before, but I’d figure I’d ask it on here. It’d be interesting to see what you guys think about this.

Deep learning, machine learning, ANNs, CNNs, blah blah blah have all been designed with the human brain in mind. We have several “neurones” that are fully connected to each-other, just like in the human brain.

Why are we trying to replicate how the human brain thinks? All of us don’t have a CPU inside our head, the way that our brains work is tailored to us, humans. So why don’t we attempt to come up with a way that is tailored to computers.

Obviously this is much easier said than done, and results from our current neural networks are incredibly good/promising.

I suppose that brings up another issue, if we somehow were to create an architecture that allows computers to “think” in their own way, and create a NN architecture that is tailored to a computer’s hardware, would it be more efficient/accurate than the typical architecture at the moment?

Furthermore if we did create this perfect way in which computers could think, would that eventually lead to sentience?

Welp, that’s my two cents of the day, ittd be interesting to see what you guys think &lt;3",t2_5ja8gxzk,False,,0,False,Are we approaching deep learning in the right way?,[],r/deeplearning,False,6,,0,,False,t3_mrclew,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618514581.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is entirely subjective, and I’m sure some computer geniuses have spoken about this before, but I’d figure I’d ask it on here. It’d be interesting to see what you guys think about this.&lt;/p&gt;

&lt;p&gt;Deep learning, machine learning, ANNs, CNNs, blah blah blah have all been designed with the human brain in mind. We have several “neurones” that are fully connected to each-other, just like in the human brain.&lt;/p&gt;

&lt;p&gt;Why are we trying to replicate how the human brain thinks? All of us don’t have a CPU inside our head, the way that our brains work is tailored to us, humans. So why don’t we attempt to come up with a way that is tailored to computers.&lt;/p&gt;

&lt;p&gt;Obviously this is much easier said than done, and results from our current neural networks are incredibly good/promising.&lt;/p&gt;

&lt;p&gt;I suppose that brings up another issue, if we somehow were to create an architecture that allows computers to “think” in their own way, and create a NN architecture that is tailored to a computer’s hardware, would it be more efficient/accurate than the typical architecture at the moment?&lt;/p&gt;

&lt;p&gt;Furthermore if we did create this perfect way in which computers could think, would that eventually lead to sentience?&lt;/p&gt;

&lt;p&gt;Welp, that’s my two cents of the day, ittd be interesting to see what you guys think &amp;lt;3&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mrclew,True,,kaffafel,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mrclew/are_we_approaching_deep_learning_in_the_right_way/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mrclew/are_we_approaching_deep_learning_in_the_right_way/,66146,1618485781.0,1,,False,,,,,,,
,deeplearning,"I am using TensorFlow 2.4.1 and Python3.8 for Computer Vision based CNN models such as VGG-18, ResNet-18/34, etc. My question is specific to weight decay declaration. There are two ways of defining it:

1. The first is by declaring it for each layer using 'kernel\_regularizer' parameter for 'Conv2D' layer
2. The second is by using 'decay' parameter in TF SGD optimizer

Example codes are:

        weight_decay = 0.0005
        Conv2D(
            filters = 64, kernel_size = (3, 3),
            activation='relu', kernel_initializer = tf.initializers.he_normal(),
            strides = (1, 1), padding = 'same',
            kernel_regularizer = regularizers.l2(weight_decay),
        )
        # NOTE: this 'kernel_regularizer' parameter is used for all of the conv layers in ResNet-18/34 and VGG-18 models
        
        optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01, decay = lr_decay, momentum = 0.9)

My question is:

1. Are these two techniques for using weight decay doing the same thing? If yes, then shouldn't only one be used to avoid redundancy (correct me if I am wrong or missing something)
2. If not, does using both of these weight decay techniques add twice the weight decay? Because too much of regularization would push even the helpful weights towards zero and therefore in essence, any model will not learn the desired function.

&amp;#x200B;

I did some reading and have the following code:

    # Time-Based Decay Learning Rate-
    optimizer = tf.keras.optimizers.SGD(lr = 0.1, momentum = 0.0, decay = 1e-3, nesterov = False)
    
    # Specify parameters for SGD optimizer-
    lr = 0.1
    decay = 1e-3
    iterations = 0
    
    # Python list to contain updated learning rates-
    lr_vals = [0.1]
    
    for epoch in range(20):
        iterations += 938
        # Keras code for SGD updates the LR by a decreasing factor in each epoch-
        lr *= (1 / (1 + decay * iterations))
        lr_vals.append(lr)

This gives the following visualizing of time-based decaying LR:

&amp;#x200B;

[time-based decaying learning rate](https://preview.redd.it/ya827k6ht9t61.png?width=551&amp;format=png&amp;auto=webp&amp;s=c17497b3159b2c779928dcba0ff89210f5090c64)

However, when I am training the LeNet-300-100 dense neural network (for toy experiment purposes), I don't see the LR being updated according the visualization above-

&amp;#x200B;

&gt;Epoch 1, Loss: 0.3352, Accuracy: 90.4300, Test Loss: 0.2053, Test Accuracy: 93.820000, LR: 0.100000, Current step value: 938  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.20531702041625977  
&gt;  
&gt;  
&gt;  
&gt;Epoch 2, Loss: 0.1685, Accuracy: 95.1367, Test Loss: 0.1488, Test Accuracy: 95.510002, LR: 0.100000, Current step value: 1876  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.14881522953510284  
&gt;  
&gt;  
&gt;  
&gt;Epoch 3, Loss: 0.1329, Accuracy: 96.1867, Test Loss: 0.1270, Test Accuracy: 96.120003, LR: 0.100000, Current step value: 2814  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.1270475536584854  
&gt;  
&gt;  
&gt;  
&gt;Epoch 4, Loss: 0.1145, Accuracy: 96.7350, Test Loss: 0.1157, Test Accuracy: 96.470001, LR: 0.100000, Current step value: 3752  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.11567071080207825  
&gt;  
&gt;  
&gt;  
&gt;Epoch 5, Loss: 0.1023, Accuracy: 97.1100, Test Loss: 0.1059, Test Accuracy: 96.669998, LR: 0.100000, Current step value: 4690  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.10592607408761978  
&gt;  
&gt;  
&gt;  
&gt;Epoch 6, Loss: 0.0937, Accuracy: 97.3183, Test Loss: 0.1045, Test Accuracy: 96.750000, LR: 0.100000, Current step value: 5628  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.10449975728988647  
&gt;  
&gt;  
&gt;  
&gt;Epoch 7, Loss: 0.0878, Accuracy: 97.5150, Test Loss: 0.0981, Test Accuracy: 97.070000, LR: 0.100000, Current step value: 6566  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.09813469648361206  
&gt;  
&gt;  
&gt;  
&gt;Epoch 8, Loss: 0.0826, Accuracy: 97.6533, Test Loss: 0.0952, Test Accuracy: 97.190002, LR: 0.100000, Current step value: 7504  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.0952112227678299  
&gt;  
&gt;  
&gt;  
&gt;Epoch 9, Loss: 0.0783, Accuracy: 97.7833, Test Loss: 0.0927, Test Accuracy: 97.059998, LR: 0.100000, Current step value: 8442  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.09270542114973068  
&gt;  
&gt;  
&gt;  
&gt;Epoch 10, Loss: 0.0750, Accuracy: 97.9000, Test Loss: 0.0894, Test Accuracy: 97.250000, LR: 0.100000, Current step value: 9380  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.08944202959537506  
&gt;  
&gt;  
&gt;  
&gt;Epoch 11, Loss: 0.0720, Accuracy: 98.0017, Test Loss: 0.0879, Test Accuracy: 97.279999, LR: 0.100000, Current step value: 10318  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.08790954947471619  
&gt;  
&gt;  
&gt;  
&gt;Epoch 12, Loss: 0.0695, Accuracy: 98.0833, Test Loss: 0.0867, Test Accuracy: 97.349998, LR: 0.100000, Current step value: 11256  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.08665674924850464  
&gt;  
&gt;  
&gt;  
&gt;Epoch 13, Loss: 0.0673, Accuracy: 98.1400, Test Loss: 0.0853, Test Accuracy: 97.399994, LR: 0.100000, Current step value: 12194  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.08529020845890045  
&gt;  
&gt;  
&gt;  
&gt;Epoch 14, Loss: 0.0653, Accuracy: 98.2117, Test Loss: 0.0849, Test Accuracy: 97.399994, LR: 0.100000, Current step value: 13132  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;  
&gt;  
&gt;Epoch 15, Loss: 0.0635, Accuracy: 98.2917, Test Loss: 0.0825, Test Accuracy: 97.500000, LR: 0.100000, Current step value: 14070  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.08248205482959747  
&gt;  
&gt;  
&gt;  
&gt;Epoch 16, Loss: 0.0618, Accuracy: 98.3517, Test Loss: 0.0816, Test Accuracy: 97.559998, LR: 0.100000, Current step value: 15008  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;  
&gt;  
&gt;Epoch 17, Loss: 0.0605, Accuracy: 98.3950, Test Loss: 0.0812, Test Accuracy: 97.509995, LR: 0.100000, Current step value: 15946  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.08115129172801971  
&gt;  
&gt;  
&gt;  
&gt;Epoch 18, Loss: 0.0590, Accuracy: 98.4583, Test Loss: 0.0804, Test Accuracy: 97.559998, LR: 0.100000, Current step value: 16884  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;  
&gt;  
&gt;Epoch 19, Loss: 0.0580, Accuracy: 98.4767, Test Loss: 0.0793, Test Accuracy: 97.589996, LR: 0.100000, Current step value: 17822  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.07925574481487274  
&gt;  
&gt;  
&gt;  
&gt;Epoch 20, Loss: 0.0569, Accuracy: 98.5117, Test Loss: 0.0789, Test Accuracy: 97.589996, LR: 0.100000, Current step value: 18760  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;  
&gt;  
&gt;Epoch 21, Loss: 0.0558, Accuracy: 98.5483, Test Loss: 0.0785, Test Accuracy: 97.659996, LR: 0.100000, Current step value: 19698  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;  
&gt;  
&gt;Epoch 22, Loss: 0.0548, Accuracy: 98.6083, Test Loss: 0.0778, Test Accuracy: 97.649994, LR: 0.100000, Current step value: 20636  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.07779469341039658  
&gt;  
&gt;  
&gt;  
&gt;Epoch 23, Loss: 0.0540, Accuracy: 98.6300, Test Loss: 0.0781, Test Accuracy: 97.629997, LR: 0.100000, Current step value: 21574  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;  
&gt;  
&gt;Epoch 24, Loss: 0.0531, Accuracy: 98.6200, Test Loss: 0.0770, Test Accuracy: 97.639999, LR: 0.100000, Current step value: 22512  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;  
&gt;  
&gt;Epoch 25, Loss: 0.0523, Accuracy: 98.6717, Test Loss: 0.0763, Test Accuracy: 97.659996, LR: 0.100000, Current step value: 23450  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.07629416137933731  
&gt;  
&gt;  
&gt;  
&gt;Epoch 26, Loss: 0.0516, Accuracy: 98.7133, Test Loss: 0.0755, Test Accuracy: 97.709999, LR: 0.100000, Current step value: 24388  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;  
&gt;  
&gt;Epoch 27, Loss: 0.0508, Accuracy: 98.7017, Test Loss: 0.0756, Test Accuracy: 97.669998, LR: 0.100000, Current step value: 25326  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;  
&gt;  
&gt;Epoch 28, Loss: 0.0502, Accuracy: 98.7400, Test Loss: 0.0747, Test Accuracy: 97.769997, LR: 0.100000, Current step value: 26264  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;Saving model with lowest val\_loss = 0.0746833011507988  
&gt;  
&gt;  
&gt;  
&gt;Epoch 29, Loss: 0.0496, Accuracy: 98.7533, Test Loss: 0.0746, Test Accuracy: 97.719994, LR: 0.100000, Current step value: 27202  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;  
&gt;  
&gt;Epoch 30, Loss: 0.0489, Accuracy: 98.7800, Test Loss: 0.0744, Test Accuracy: 97.779999, LR: 0.100000, Current step value: 28140  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;  
&gt;  
&gt;Epoch 31, Loss: 0.0485, Accuracy: 98.8167, Test Loss: 0.0744, Test Accuracy: 97.729996, LR: 0.100000, Current step value: 29078  
&gt;  
&gt;Total number of trainable parameters = 266610  
&gt;  
&gt;'EarlyStopping' called!

&amp;#x200B;

As you can see, the model trained for 30 epochs but has the same constant LR = 0.1

Why is this mismatch?",t2_2mmql89p,False,,0,False,TensorFlow SGD decay parameter,[],r/deeplearning,False,6,,0,,False,t3_mqufzc,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1618463741.0,,[],{},,True,,1618447128.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am using TensorFlow 2.4.1 and Python3.8 for Computer Vision based CNN models such as VGG-18, ResNet-18/34, etc. My question is specific to weight decay declaration. There are two ways of defining it:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The first is by declaring it for each layer using &amp;#39;kernel_regularizer&amp;#39; parameter for &amp;#39;Conv2D&amp;#39; layer&lt;/li&gt;
&lt;li&gt;The second is by using &amp;#39;decay&amp;#39; parameter in TF SGD optimizer&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Example codes are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    weight_decay = 0.0005
    Conv2D(
        filters = 64, kernel_size = (3, 3),
        activation=&amp;#39;relu&amp;#39;, kernel_initializer = tf.initializers.he_normal(),
        strides = (1, 1), padding = &amp;#39;same&amp;#39;,
        kernel_regularizer = regularizers.l2(weight_decay),
    )
    # NOTE: this &amp;#39;kernel_regularizer&amp;#39; parameter is used for all of the conv layers in ResNet-18/34 and VGG-18 models

    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01, decay = lr_decay, momentum = 0.9)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My question is:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Are these two techniques for using weight decay doing the same thing? If yes, then shouldn&amp;#39;t only one be used to avoid redundancy (correct me if I am wrong or missing something)&lt;/li&gt;
&lt;li&gt;If not, does using both of these weight decay techniques add twice the weight decay? Because too much of regularization would push even the helpful weights towards zero and therefore in essence, any model will not learn the desired function.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I did some reading and have the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Time-Based Decay Learning Rate-
optimizer = tf.keras.optimizers.SGD(lr = 0.1, momentum = 0.0, decay = 1e-3, nesterov = False)

# Specify parameters for SGD optimizer-
lr = 0.1
decay = 1e-3
iterations = 0

# Python list to contain updated learning rates-
lr_vals = [0.1]

for epoch in range(20):
    iterations += 938
    # Keras code for SGD updates the LR by a decreasing factor in each epoch-
    lr *= (1 / (1 + decay * iterations))
    lr_vals.append(lr)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This gives the following visualizing of time-based decaying LR:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ya827k6ht9t61.png?width=551&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c17497b3159b2c779928dcba0ff89210f5090c64""&gt;time-based decaying learning rate&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However, when I am training the LeNet-300-100 dense neural network (for toy experiment purposes), I don&amp;#39;t see the LR being updated according the visualization above-&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Epoch 1, Loss: 0.3352, Accuracy: 90.4300, Test Loss: 0.2053, Test Accuracy: 93.820000, LR: 0.100000, Current step value: 938  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.20531702041625977  &lt;/p&gt;

&lt;p&gt;Epoch 2, Loss: 0.1685, Accuracy: 95.1367, Test Loss: 0.1488, Test Accuracy: 95.510002, LR: 0.100000, Current step value: 1876  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.14881522953510284  &lt;/p&gt;

&lt;p&gt;Epoch 3, Loss: 0.1329, Accuracy: 96.1867, Test Loss: 0.1270, Test Accuracy: 96.120003, LR: 0.100000, Current step value: 2814  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.1270475536584854  &lt;/p&gt;

&lt;p&gt;Epoch 4, Loss: 0.1145, Accuracy: 96.7350, Test Loss: 0.1157, Test Accuracy: 96.470001, LR: 0.100000, Current step value: 3752  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.11567071080207825  &lt;/p&gt;

&lt;p&gt;Epoch 5, Loss: 0.1023, Accuracy: 97.1100, Test Loss: 0.1059, Test Accuracy: 96.669998, LR: 0.100000, Current step value: 4690  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.10592607408761978  &lt;/p&gt;

&lt;p&gt;Epoch 6, Loss: 0.0937, Accuracy: 97.3183, Test Loss: 0.1045, Test Accuracy: 96.750000, LR: 0.100000, Current step value: 5628  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.10449975728988647  &lt;/p&gt;

&lt;p&gt;Epoch 7, Loss: 0.0878, Accuracy: 97.5150, Test Loss: 0.0981, Test Accuracy: 97.070000, LR: 0.100000, Current step value: 6566  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.09813469648361206  &lt;/p&gt;

&lt;p&gt;Epoch 8, Loss: 0.0826, Accuracy: 97.6533, Test Loss: 0.0952, Test Accuracy: 97.190002, LR: 0.100000, Current step value: 7504  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.0952112227678299  &lt;/p&gt;

&lt;p&gt;Epoch 9, Loss: 0.0783, Accuracy: 97.7833, Test Loss: 0.0927, Test Accuracy: 97.059998, LR: 0.100000, Current step value: 8442  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.09270542114973068  &lt;/p&gt;

&lt;p&gt;Epoch 10, Loss: 0.0750, Accuracy: 97.9000, Test Loss: 0.0894, Test Accuracy: 97.250000, LR: 0.100000, Current step value: 9380  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.08944202959537506  &lt;/p&gt;

&lt;p&gt;Epoch 11, Loss: 0.0720, Accuracy: 98.0017, Test Loss: 0.0879, Test Accuracy: 97.279999, LR: 0.100000, Current step value: 10318  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.08790954947471619  &lt;/p&gt;

&lt;p&gt;Epoch 12, Loss: 0.0695, Accuracy: 98.0833, Test Loss: 0.0867, Test Accuracy: 97.349998, LR: 0.100000, Current step value: 11256  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.08665674924850464  &lt;/p&gt;

&lt;p&gt;Epoch 13, Loss: 0.0673, Accuracy: 98.1400, Test Loss: 0.0853, Test Accuracy: 97.399994, LR: 0.100000, Current step value: 12194  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.08529020845890045  &lt;/p&gt;

&lt;p&gt;Epoch 14, Loss: 0.0653, Accuracy: 98.2117, Test Loss: 0.0849, Test Accuracy: 97.399994, LR: 0.100000, Current step value: 13132  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Epoch 15, Loss: 0.0635, Accuracy: 98.2917, Test Loss: 0.0825, Test Accuracy: 97.500000, LR: 0.100000, Current step value: 14070  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.08248205482959747  &lt;/p&gt;

&lt;p&gt;Epoch 16, Loss: 0.0618, Accuracy: 98.3517, Test Loss: 0.0816, Test Accuracy: 97.559998, LR: 0.100000, Current step value: 15008  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Epoch 17, Loss: 0.0605, Accuracy: 98.3950, Test Loss: 0.0812, Test Accuracy: 97.509995, LR: 0.100000, Current step value: 15946  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.08115129172801971  &lt;/p&gt;

&lt;p&gt;Epoch 18, Loss: 0.0590, Accuracy: 98.4583, Test Loss: 0.0804, Test Accuracy: 97.559998, LR: 0.100000, Current step value: 16884  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Epoch 19, Loss: 0.0580, Accuracy: 98.4767, Test Loss: 0.0793, Test Accuracy: 97.589996, LR: 0.100000, Current step value: 17822  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.07925574481487274  &lt;/p&gt;

&lt;p&gt;Epoch 20, Loss: 0.0569, Accuracy: 98.5117, Test Loss: 0.0789, Test Accuracy: 97.589996, LR: 0.100000, Current step value: 18760  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Epoch 21, Loss: 0.0558, Accuracy: 98.5483, Test Loss: 0.0785, Test Accuracy: 97.659996, LR: 0.100000, Current step value: 19698  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Epoch 22, Loss: 0.0548, Accuracy: 98.6083, Test Loss: 0.0778, Test Accuracy: 97.649994, LR: 0.100000, Current step value: 20636  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.07779469341039658  &lt;/p&gt;

&lt;p&gt;Epoch 23, Loss: 0.0540, Accuracy: 98.6300, Test Loss: 0.0781, Test Accuracy: 97.629997, LR: 0.100000, Current step value: 21574  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Epoch 24, Loss: 0.0531, Accuracy: 98.6200, Test Loss: 0.0770, Test Accuracy: 97.639999, LR: 0.100000, Current step value: 22512  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Epoch 25, Loss: 0.0523, Accuracy: 98.6717, Test Loss: 0.0763, Test Accuracy: 97.659996, LR: 0.100000, Current step value: 23450  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.07629416137933731  &lt;/p&gt;

&lt;p&gt;Epoch 26, Loss: 0.0516, Accuracy: 98.7133, Test Loss: 0.0755, Test Accuracy: 97.709999, LR: 0.100000, Current step value: 24388  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Epoch 27, Loss: 0.0508, Accuracy: 98.7017, Test Loss: 0.0756, Test Accuracy: 97.669998, LR: 0.100000, Current step value: 25326  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Epoch 28, Loss: 0.0502, Accuracy: 98.7400, Test Loss: 0.0747, Test Accuracy: 97.769997, LR: 0.100000, Current step value: 26264  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Saving model with lowest val_loss = 0.0746833011507988  &lt;/p&gt;

&lt;p&gt;Epoch 29, Loss: 0.0496, Accuracy: 98.7533, Test Loss: 0.0746, Test Accuracy: 97.719994, LR: 0.100000, Current step value: 27202  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Epoch 30, Loss: 0.0489, Accuracy: 98.7800, Test Loss: 0.0744, Test Accuracy: 97.779999, LR: 0.100000, Current step value: 28140  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;Epoch 31, Loss: 0.0485, Accuracy: 98.8167, Test Loss: 0.0744, Test Accuracy: 97.729996, LR: 0.100000, Current step value: 29078  &lt;/p&gt;

&lt;p&gt;Total number of trainable parameters = 266610  &lt;/p&gt;

&lt;p&gt;&amp;#39;EarlyStopping&amp;#39; called!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;As you can see, the model trained for 30 epochs but has the same constant LR = 0.1&lt;/p&gt;

&lt;p&gt;Why is this mismatch?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mqufzc,True,,grid_world,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/mqufzc/tensorflow_sgd_decay_parameter/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mqufzc/tensorflow_sgd_decay_parameter/,66146,1618418328.0,0,,False,,,"{'ya827k6ht9t61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 83, 'x': 108, 'u': 'https://preview.redd.it/ya827k6ht9t61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d7811656d0fdcc7da30c682c36d05bc1eb27b7dd'}, {'y': 166, 'x': 216, 'u': 'https://preview.redd.it/ya827k6ht9t61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=f608cac2d0b74e9873e9c5ae1c11d255b25c1a37'}, {'y': 246, 'x': 320, 'u': 'https://preview.redd.it/ya827k6ht9t61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=04bb62e523c31d907ff70858aa57cb6a5affe9de'}], 's': {'y': 425, 'x': 551, 'u': 'https://preview.redd.it/ya827k6ht9t61.png?width=551&amp;format=png&amp;auto=webp&amp;s=c17497b3159b2c779928dcba0ff89210f5090c64'}, 'id': 'ya827k6ht9t61'}}",,,,
,deeplearning,,t2_lp163,False,,0,False,Yann LeCun — Self supervised learning and uncertainty representation,[],r/deeplearning,False,6,,0,,False,t3_mq6zq4,False,dark,0.95,,public,71,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/D9SBRVLb6Yw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Yann LeCun (Facebook) - Self supervised learning and uncertainty representation,', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/D9SBRVLb6Yw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Fondation Hadamard', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/D9SBRVLb6Yw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCltyfO-_afrhOm8OqWpcSSA'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/D9SBRVLb6Yw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mq6zq4', 'height': 200}",,False,71,,False,False,,False,,[],{},,False,,1618363361.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=D9SBRVLb6Yw,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mq6zq4,True,,Itoka,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mq6zq4/yann_lecun_self_supervised_learning_and/,all_ads,False,https://www.youtube.com/watch?v=D9SBRVLb6Yw,66146,1618334561.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Yann LeCun (Facebook) - Self supervised learning and uncertainty representation,', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/D9SBRVLb6Yw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Fondation Hadamard', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/D9SBRVLb6Yw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCltyfO-_afrhOm8OqWpcSSA'}}",False,,,,,,,
,deeplearning,,t2_3c73i5qb,False,,0,False,[D] Prof. Jürgen Schmidhuber's GTC21 Talk if full of how his inventions helped almost every other major invention in Deep Learning. Thoughts?,[],r/deeplearning,False,6,,0,,False,t3_mqnq01,False,dark,1.0,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1618424765.0,text,6,,,text,self.deeplearning,False,,,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mqnq01,True,,uchiha_indra,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mqnq01/d_prof_jürgen_schmidhubers_gtc21_talk_if_full_of/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mqnq01/d_prof_jürgen_schmidhubers_gtc21_talk_if_full_of/,66146,1618395965.0,0,,False,,,,,,,
,deeplearning,"This article breaks down a novel form of channel attention called the Style Recalibration Module (SRM), an improvement on the popular Squeeze-and-Excitation Networks (full PyTorch code included).

Topics covered include:

1. Why Should You Consider Channel Attention Mechanisms?
2. SRM Motivation
3. Main Contributions
4. Style Recalibration Module (SRM)  
a. Style Pooling  
b. Style Integration  
c. Complexity  
d. Comparison with SENets  
e. Comparison with ECANets
5. Code
6. Results
7. Critical Comments
8. Conclusion

Article link: [https://blog.paperspace.com/srm-channel-attention/](https://blog.paperspace.com/srm-channel-attention/)",t2_15en0l,False,,0,False,[Article] SRM Channel Attention Explained,[],r/deeplearning,False,6,,0,,False,t3_mqtj1y,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618444565.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This article breaks down a novel form of channel attention called the Style Recalibration Module (SRM), an improvement on the popular Squeeze-and-Excitation Networks (full PyTorch code included).&lt;/p&gt;

&lt;p&gt;Topics covered include:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Why Should You Consider Channel Attention Mechanisms?&lt;/li&gt;
&lt;li&gt;SRM Motivation&lt;/li&gt;
&lt;li&gt;Main Contributions&lt;/li&gt;
&lt;li&gt;Style Recalibration Module (SRM)&lt;br/&gt;
a. Style Pooling&lt;br/&gt;
b. Style Integration&lt;br/&gt;
c. Complexity&lt;br/&gt;
d. Comparison with SENets&lt;br/&gt;
e. Comparison with ECANets&lt;/li&gt;
&lt;li&gt;Code&lt;/li&gt;
&lt;li&gt;Results&lt;/li&gt;
&lt;li&gt;Critical Comments&lt;/li&gt;
&lt;li&gt;Conclusion&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Article link: &lt;a href=""https://blog.paperspace.com/srm-channel-attention/""&gt;https://blog.paperspace.com/srm-channel-attention/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mqtj1y,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mqtj1y/article_srm_channel_attention_explained/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mqtj1y/article_srm_channel_attention_explained/,66146,1618415765.0,0,,False,,,,,,,
,deeplearning,I have two types of images and I want to train a CNN model that classifies between these two but I have no labels for these images guide me with this any reference or methodology that I can follow.,t2_awhu0kdx,False,,0,False,Any reference or idea about how to train unsupervised CNN model ?,[],r/deeplearning,False,6,,0,,False,t3_mqjwdz,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618406506.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have two types of images and I want to train a CNN model that classifies between these two but I have no labels for these images guide me with this any reference or methodology that I can follow.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mqjwdz,True,,Aaryan_Ashok,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/mqjwdz/any_reference_or_idea_about_how_to_train/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mqjwdz/any_reference_or_idea_about_how_to_train/,66146,1618377706.0,0,,False,,,,,,,
,deeplearning,"Just found out I was chosen to review an autonomous vehicle for a major company in the bay area next week. Im a current MS Data Science student, so needless to say I'm excited. I have some questions I'd like to ask regarding their lidar sensors and also some tensorflow/deep learning questions. If you were in my position, what would you like to know?",t2_beih1mvz,False,,0,False,Opportunity to review a level 4 autonomous vehicle,[],r/deeplearning,False,6,,0,,False,t3_mqknm6,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1618382307.0,,[],{},,True,,1618409937.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just found out I was chosen to review an autonomous vehicle for a major company in the bay area next week. Im a current MS Data Science student, so needless to say I&amp;#39;m excited. I have some questions I&amp;#39;d like to ask regarding their lidar sensors and also some tensorflow/deep learning questions. If you were in my position, what would you like to know?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mqknm6,True,,oh_hey_dude_,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/mqknm6/opportunity_to_review_a_level_4_autonomous_vehicle/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mqknm6/opportunity_to_review_a_level_4_autonomous_vehicle/,66146,1618381137.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,Real-time recognition of handwritten math functions and drawing their graphs,[],r/deeplearning,False,6,,0,,False,t3_mpx8tt,False,dark,0.94,,public,57,0,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/jcoB61viBnk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'height': 200}",,False,[],"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'Real-time recognition of handwritten math functions and drawing their graphs | Augmented Reality', 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/jcoB61viBnk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'version': '1.0', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/jcoB61viBnk/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}, 'type': 'youtube.com'}",False,False,,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/jcoB61viBnk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mpx8tt', 'height': 200}",,False,57,,False,False,,False,,[],{},,False,,1618327053.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/jcoB61viBnk,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpx8tt,True,,cmillionaire9,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mpx8tt/realtime_recognition_of_handwritten_math/,all_ads,False,https://youtu.be/jcoB61viBnk,66146,1618298253.0,0,"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'Real-time recognition of handwritten math functions and drawing their graphs | Augmented Reality', 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/jcoB61viBnk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'version': '1.0', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/jcoB61viBnk/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}, 'type': 'youtube.com'}",False,,,,,,,
,deeplearning,"Hey

I have a college project, recognising handwritten digits using feedback fully connected neural network. It should be implemented without libs like tensorflow and such. It has two hidden layers.

We have to use SDG, back-propagation and vectorization. (And MNIST dataset)

We use IEEE introduction to computational intelligence as textbook. I have a few days to implement the project but our textbook is quite verbose and I really don't know which parts of the book are needed to be read to implement this project.

So is there any textbook chapter, lecture slide, video or any resource to help me understand the big picture and start coding?",t2_40ofuvyl,False,,0,False,Need resources help me implement handwritten digit recognition,[],r/deeplearning,False,6,,0,,False,t3_mqbhnf,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618376478.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey&lt;/p&gt;

&lt;p&gt;I have a college project, recognising handwritten digits using feedback fully connected neural network. It should be implemented without libs like tensorflow and such. It has two hidden layers.&lt;/p&gt;

&lt;p&gt;We have to use SDG, back-propagation and vectorization. (And MNIST dataset)&lt;/p&gt;

&lt;p&gt;We use IEEE introduction to computational intelligence as textbook. I have a few days to implement the project but our textbook is quite verbose and I really don&amp;#39;t know which parts of the book are needed to be read to implement this project.&lt;/p&gt;

&lt;p&gt;So is there any textbook chapter, lecture slide, video or any resource to help me understand the big picture and start coding?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mqbhnf,True,,fiveMop,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mqbhnf/need_resources_help_me_implement_handwritten/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mqbhnf/need_resources_help_me_implement_handwritten/,66146,1618347678.0,0,,False,,,,,,,
,deeplearning,"
Hello,

I am developing an extractive text summarizer for french language, I would like to explore the self-attention mechanism to see at which linguistic patterns it looks to by generating a heat map or? Any help?",t2_9e6mmc22,False,,0,False,At which linguistic patterns and features attention heads of BERT look to ?,[],r/deeplearning,False,6,,0,,False,t3_mq3r1o,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618354048.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I am developing an extractive text summarizer for french language, I would like to explore the self-attention mechanism to see at which linguistic patterns it looks to by generating a heat map or? Any help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mq3r1o,True,,Ok_Inspection_5208,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mq3r1o/at_which_linguistic_patterns_and_features/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mq3r1o/at_which_linguistic_patterns_and_features/,66146,1618325248.0,0,,False,,,,,,,
,deeplearning,"[Designing an Encoder for StyleGAN Image Manipulation](https://t.me/casual_gan/25)  


This architecture is the go to for StyleGAN inverion and image editing at the moment. The authors build on the ideas proposed in [pSp](https://t.me/casual_gan/16) and generalize the proposed method beyond the face domain. Moreover, the proposed method achieves a balance between the reconstruction quality of the images and the ability to edit them. More info [here](https://t.me/casual_gan/25)!  


[Encoders for editing \(e4\)](https://preview.redd.it/53fjhjvvazs61.png?width=1280&amp;format=png&amp;auto=webp&amp;s=dc40c36d47b0cfe110893cd00c3c70250fac671f)

P.s. In case you are not familiar with the paper, check it out [here](https://t.me/casual_gan/25)!",t2_hhio3,False,,0,False,[R] Designing an Encoder for StyleGAN Image Manipulation - Explained,[],r/deeplearning,False,6,,0,,False,t3_mq7kjm,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1618337825.0,,[],{},,True,,1618365013.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://t.me/casual_gan/25""&gt;Designing an Encoder for StyleGAN Image Manipulation&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;This architecture is the go to for StyleGAN inverion and image editing at the moment. The authors build on the ideas proposed in &lt;a href=""https://t.me/casual_gan/16""&gt;pSp&lt;/a&gt; and generalize the proposed method beyond the face domain. Moreover, the proposed method achieves a balance between the reconstruction quality of the images and the ability to edit them. More info &lt;a href=""https://t.me/casual_gan/25""&gt;here&lt;/a&gt;!  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/53fjhjvvazs61.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dc40c36d47b0cfe110893cd00c3c70250fac671f""&gt;Encoders for editing (e4)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;P.s. In case you are not familiar with the paper, check it out &lt;a href=""https://t.me/casual_gan/25""&gt;here&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mq7kjm,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mq7kjm/r_designing_an_encoder_for_stylegan_image/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mq7kjm/r_designing_an_encoder_for_stylegan_image/,66146,1618336213.0,0,,False,,,"{'53fjhjvvazs61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 47, 'x': 108, 'u': 'https://preview.redd.it/53fjhjvvazs61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=42e699c9fbac83389cb8a0fcfba58c134975dadd'}, {'y': 95, 'x': 216, 'u': 'https://preview.redd.it/53fjhjvvazs61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=efc034c516e897dbc0c35354c2a5364568c871ea'}, {'y': 140, 'x': 320, 'u': 'https://preview.redd.it/53fjhjvvazs61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=67b043bb16a47ff31d3770ec2059f2686cb584da'}, {'y': 281, 'x': 640, 'u': 'https://preview.redd.it/53fjhjvvazs61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f513ee214c8adcdc9a39554017b12202aa87890f'}, {'y': 422, 'x': 960, 'u': 'https://preview.redd.it/53fjhjvvazs61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2719dd9157f1cbc75ae4a9b4cf46a00fcc6d66f3'}, {'y': 475, 'x': 1080, 'u': 'https://preview.redd.it/53fjhjvvazs61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4a60eb060faf267b9ce06fd3db603bd7f6f7367d'}], 's': {'y': 563, 'x': 1280, 'u': 'https://preview.redd.it/53fjhjvvazs61.png?width=1280&amp;format=png&amp;auto=webp&amp;s=dc40c36d47b0cfe110893cd00c3c70250fac671f'}, 'id': '53fjhjvvazs61'}}",,,,
,deeplearning,"Hello everyone,

I have about two weeks to come up with a research idea for my dissertation. It has to be related to machine learning, modeling etc.

I'm a kind of person, that likes data science in general. Most of the topics sound really interesting to me. Obviously, I'd like to do something ambitious but not too ambitious for one person. 

What are the research questions, that I could address in let's say 50 pages? I was thinking about mapping MARS, but I cannot do that since there is no too much data available for ordinary people. Other idea was to create an AI trading algorithm.",t2_569zlfoq,False,,0,False,Any good ideas for a 50 page research?,[],r/deeplearning,False,6,,0,,False,t3_mq73ge,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618363663.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;I have about two weeks to come up with a research idea for my dissertation. It has to be related to machine learning, modeling etc.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m a kind of person, that likes data science in general. Most of the topics sound really interesting to me. Obviously, I&amp;#39;d like to do something ambitious but not too ambitious for one person. &lt;/p&gt;

&lt;p&gt;What are the research questions, that I could address in let&amp;#39;s say 50 pages? I was thinking about mapping MARS, but I cannot do that since there is no too much data available for ordinary people. Other idea was to create an AI trading algorithm.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mq73ge,True,,Thomas9719,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mq73ge/any_good_ideas_for_a_50_page_research/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mq73ge/any_good_ideas_for_a_50_page_research/,66146,1618334863.0,0,,False,,,,,,,
,deeplearning,"Hello deeplearners,

I ran some model fitting performance benchmarks on a [3D (medical) image segmentation UNET](https://github.com/MIC-DKFZ/nnUNet/) on various cloud providers and I am flabbergasted by the very low performance of V100 and A100 machines on [vast.ai](https://vast.ai).

On Azure and Google cloud, an epoch of the model I want to train took **~190s** on a V100; but it took ~400s on vast.ai (20 cores of Xeon Gold 6148); and **~370s** on a A100 (16 cores AMD EPYC 7452). On the other hand, GTX 3090 perf on vast.ai was on par with the perf of other GTX 3090 I had access to (~340s, 16 cores of AMD Ryzen Threadripper, no further precision on the CPU model).

Does someone has a theory to explain this underwhelming performance of the Tesla GPUs on vast.ai? I don't think the GPUs were starving, by watching nvidia-smi and htop output; but these things can be subtle... Maybe the machines I rented were ""cheating"" and announcing a Tesla GPU when they in fact had older ones? I guess it could be possible to manipulate the kernel host is such way...",t2_gqe7k,False,,0,False,"Underwhelming performance of Tesla V100 and A100 in vast.ai, why?",[],r/deeplearning,False,6,,0,,False,t3_mq0a0j,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,1618323419.0,,[],{},,True,,1618341977.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello deeplearners,&lt;/p&gt;

&lt;p&gt;I ran some model fitting performance benchmarks on a &lt;a href=""https://github.com/MIC-DKFZ/nnUNet/""&gt;3D (medical) image segmentation UNET&lt;/a&gt; on various cloud providers and I am flabbergasted by the very low performance of V100 and A100 machines on &lt;a href=""https://vast.ai""&gt;vast.ai&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;On Azure and Google cloud, an epoch of the model I want to train took &lt;strong&gt;~190s&lt;/strong&gt; on a V100; but it took ~400s on vast.ai (20 cores of Xeon Gold 6148); and &lt;strong&gt;~370s&lt;/strong&gt; on a A100 (16 cores AMD EPYC 7452). On the other hand, GTX 3090 perf on vast.ai was on par with the perf of other GTX 3090 I had access to (~340s, 16 cores of AMD Ryzen Threadripper, no further precision on the CPU model).&lt;/p&gt;

&lt;p&gt;Does someone has a theory to explain this underwhelming performance of the Tesla GPUs on vast.ai? I don&amp;#39;t think the GPUs were starving, by watching nvidia-smi and htop output; but these things can be subtle... Maybe the machines I rented were &amp;quot;cheating&amp;quot; and announcing a Tesla GPU when they in fact had older ones? I guess it could be possible to manipulate the kernel host is such way...&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mq0a0j,True,,nicocool84,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mq0a0j/underwhelming_performance_of_tesla_v100_and_a100/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mq0a0j/underwhelming_performance_of_tesla_v100_and_a100/,66146,1618313177.0,0,,False,,,,,,,
,deeplearning,,t2_683tvs22,False,,0,False,AI generates Cars from the movie,[],r/deeplearning,False,6,,0,,False,t3_mq4z9t,False,dark,0.67,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fDh-qcbIxtU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI generates Cars from Radiator Springs [15.046 Views]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fDh-qcbIxtU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/fDh-qcbIxtU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fDh-qcbIxtU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mq4z9t', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1618357673.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/fDh-qcbIxtU,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mq4z9t,True,,N2AI,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mq4z9t/ai_generates_cars_from_the_movie/,all_ads,False,https://youtu.be/fDh-qcbIxtU,66146,1618328873.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI generates Cars from Radiator Springs [15.046 Views]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fDh-qcbIxtU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'N2AI', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/fDh-qcbIxtU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCIkA_Pi0VWSABdyAnmildpg'}}",False,,,,,,,
,deeplearning,,t2_9xwzo9vx,False,,0,False,Using StyleGAN2-ADA and Pixel2Style2Pixel to turn my sketches in to realistic people,[],r/deeplearning,False,6,,0,,False,t3_mpf6qd,False,dark,0.91,,public,51,1,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oRRtSYxGf6w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Using AI to Turn My Sketches into High Quality Realistic People', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oRRtSYxGf6w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Stochastic Machine', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/oRRtSYxGf6w/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCWAQ2jS_jftqV65hLtxPfLA'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oRRtSYxGf6w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mpf6qd', 'height': 200}",,False,51,,False,False,,False,,[],{},,False,,1618267031.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/oRRtSYxGf6w,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpf6qd,True,,Stochastic_Machine,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/mpf6qd/using_stylegan2ada_and_pixel2style2pixel_to_turn/,all_ads,False,https://youtu.be/oRRtSYxGf6w,66146,1618238231.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Using AI to Turn My Sketches into High Quality Realistic People', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oRRtSYxGf6w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Stochastic Machine', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/oRRtSYxGf6w/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCWAQ2jS_jftqV65hLtxPfLA'}}",False,,,,,,,
,deeplearning,"In today's blog, we will go over the details of the OpenCV DNN module. In 2017, OpenCV entered into the Deep Learning domain by introducing a Deep Neural Network module, now popularly known as the ""OpenCV DNN"" module. Not only is this module super simple to install it also offers support to almost all frameworks like PyTorch, TensorFlow and the generic format - ONNX. In this blog, we will compare the performance of the OpenCV DNN module with PyTorch and TensorFlow for image classification and object detection tasks. We will also see how to use pre-trained models for real-time inference on Intel CPU using the OpenCV DNN module.  


[https://learnopencv.com/deep-learning-with-opencvs-dnn-module-a-definitive-guide/](https://learnopencv.com/deep-learning-with-opencvs-dnn-module-a-definitive-guide/)

https://preview.redd.it/zftljwyvfws61.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=84a67c4a236466ab51e800bbfc5f87367dd074c1",t2_cvc9f,False,,0,False,Deep Learning with OpenCV’s DNN Module,[],r/deeplearning,False,6,,0,,False,t3_mpxwe8,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618330367.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In today&amp;#39;s blog, we will go over the details of the OpenCV DNN module. In 2017, OpenCV entered into the Deep Learning domain by introducing a Deep Neural Network module, now popularly known as the &amp;quot;OpenCV DNN&amp;quot; module. Not only is this module super simple to install it also offers support to almost all frameworks like PyTorch, TensorFlow and the generic format - ONNX. In this blog, we will compare the performance of the OpenCV DNN module with PyTorch and TensorFlow for image classification and object detection tasks. We will also see how to use pre-trained models for real-time inference on Intel CPU using the OpenCV DNN module.  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://learnopencv.com/deep-learning-with-opencvs-dnn-module-a-definitive-guide/""&gt;https://learnopencv.com/deep-learning-with-opencvs-dnn-module-a-definitive-guide/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/zftljwyvfws61.jpg?width=600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=84a67c4a236466ab51e800bbfc5f87367dd074c1""&gt;https://preview.redd.it/zftljwyvfws61.jpg?width=600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=84a67c4a236466ab51e800bbfc5f87367dd074c1&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpxwe8,True,,spmallick,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mpxwe8/deep_learning_with_opencvs_dnn_module/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mpxwe8/deep_learning_with_opencvs_dnn_module/,66146,1618301567.0,0,,False,,,"{'zftljwyvfws61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 72, 'x': 108, 'u': 'https://preview.redd.it/zftljwyvfws61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8cc05bf4ca051cb9d140340ba2e6d07a86741b8e'}, {'y': 144, 'x': 216, 'u': 'https://preview.redd.it/zftljwyvfws61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=28e58e12d45c3584fbef87ab81d0377de12abf13'}, {'y': 213, 'x': 320, 'u': 'https://preview.redd.it/zftljwyvfws61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=cdf88cd01b11cb2752279276443a7984b63afe32'}], 's': {'y': 400, 'x': 600, 'u': 'https://preview.redd.it/zftljwyvfws61.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=84a67c4a236466ab51e800bbfc5f87367dd074c1'}, 'id': 'zftljwyvfws61'}}",,,,
,deeplearning,"I just bought a new laptop without OS. I wonder if it is necessary to install linux OS to my personal computer for easy usage of deep learning tools ? Because I saw there is linux kernel in docker. What i understood is that using linux in docker is not different than installing linux to personal computer, even much better. If there is no difference, i would like to install w10. What do you suggest?",t2_bibnzo96,False,,0,False,Linux on PC vs Docker on Pc,[],r/deeplearning,False,6,,0,,False,t3_mpxvjn,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618330239.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I just bought a new laptop without OS. I wonder if it is necessary to install linux OS to my personal computer for easy usage of deep learning tools ? Because I saw there is linux kernel in docker. What i understood is that using linux in docker is not different than installing linux to personal computer, even much better. If there is no difference, i would like to install w10. What do you suggest?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpxvjn,True,,deeplearningman45,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/mpxvjn/linux_on_pc_vs_docker_on_pc/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mpxvjn/linux_on_pc_vs_docker_on_pc/,66146,1618301439.0,0,,False,,,,,,,
,deeplearning,"In this podcast we will talk about the following:

\-&gt; How and when Bounding box and segmentation is used for People detection?  
\-&gt; The six major technical terms required to understand People Detection accuracy metrics  
\-&gt; When to use average precision and mean average precision?  
\-&gt; Three demo scenarios where the accuracy metrics are implemented and discussed

[https://www.linkedin.com/posts/alphonse-raj-david\_machinelearning-artificialintelligence-computervision-activity-6787699010389065728-K3ve](https://www.linkedin.com/posts/alphonse-raj-david_machinelearning-artificialintelligence-computervision-activity-6787699010389065728-K3ve)",t2_8xrdtnfi,False,,0,False,New Podcast Release: How to identify which metrics should be used to assess the accuracy of a people detection solution?,[],r/deeplearning,False,6,,0,,False,t3_mq0n33,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1618343483.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In this podcast we will talk about the following:&lt;/p&gt;

&lt;p&gt;-&amp;gt; How and when Bounding box and segmentation is used for People detection?&lt;br/&gt;
-&amp;gt; The six major technical terms required to understand People Detection accuracy metrics&lt;br/&gt;
-&amp;gt; When to use average precision and mean average precision?&lt;br/&gt;
-&amp;gt; Three demo scenarios where the accuracy metrics are implemented and discussed&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.linkedin.com/posts/alphonse-raj-david_machinelearning-artificialintelligence-computervision-activity-6787699010389065728-K3ve""&gt;https://www.linkedin.com/posts/alphonse-raj-david_machinelearning-artificialintelligence-computervision-activity-6787699010389065728-K3ve&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mq0n33,True,,EdgeAI_CV_Fanatic,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mq0n33/new_podcast_release_how_to_identify_which_metrics/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mq0n33/new_podcast_release_how_to_identify_which_metrics/,66146,1618314683.0,0,,False,,,,,,,
,deeplearning,,t2_6e83b,False,,0,False,Nvidia announces some interesting new hardware for us coming soon.,[],r/deeplearning,False,6,,0,,False,t3_mpmpwc,False,dark,0.9,,public,14,0,{},,False,[],,False,False,,{},,False,14,,False,False,,False,,[],{},,False,,1618288446.0,text,6,,,text,theverge.com,False,,,,,https://www.theverge.com/circuitbreaker/2021/4/12/22380065/nvidia-grace-cpu-arm-data-center-ai-hpc,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpmpwc,True,,Mortoc,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mpmpwc/nvidia_announces_some_interesting_new_hardware/,all_ads,False,https://www.theverge.com/circuitbreaker/2021/4/12/22380065/nvidia-grace-cpu-arm-data-center-ai-hpc,66146,1618259646.0,0,,False,,,,,,,
,deeplearning,,t2_95bbwn26,False,,0,False,Python package to train a Conditional GAN with ~1 line of code,[],r/deeplearning,False,6,,0,,False,t3_mpwuv9,False,dark,0.63,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1618325215.0,text,6,,,text,github.com,False,,,,,https://github.com/PraneetNeuro/Conditional-Generative-Adversarial-Network,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpwuv9,True,,Imaginary-Berry-6165,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mpwuv9/python_package_to_train_a_conditional_gan_with_1/,all_ads,False,https://github.com/PraneetNeuro/Conditional-Generative-Adversarial-Network,66146,1618296415.0,0,,False,,,,,,,
,deeplearning,"Hello!

I’m a fourth-year undergraduate at UC Berkeley. I'm working on identifying what people living with diabetes think about autonomous devices used as a part of managing their risk of developing diabetic retinopathy.

*If you have 10 minutes to spare, please participate in my survey (approved by a UC Berkeley Interdisciplinary Studies Advisor):* [*https://berkeley.qualtrics.com/jfe/form/SV\_bI9TKOdwtAVycaG*](https://berkeley.qualtrics.com/jfe/form/SV_bI9TKOdwtAVycaG)

**All adults who have been diagnosed with diabetes for at least a year can participate, so please share the link with any friends and family who are eligible!**

If you want to know more, please don't hesitate to reach out!

Thank you for your help!",t2_3fzszgod,False,,0,False,[Research] autonomous devices in managing diabetic retinopathy,[],r/deeplearning,False,6,,0,,False,t3_mptq5o,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618311664.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello!&lt;/p&gt;

&lt;p&gt;I’m a fourth-year undergraduate at UC Berkeley. I&amp;#39;m working on identifying what people living with diabetes think about autonomous devices used as a part of managing their risk of developing diabetic retinopathy.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If you have 10 minutes to spare, please participate in my survey (approved by a UC Berkeley Interdisciplinary Studies Advisor):&lt;/em&gt; &lt;a href=""https://berkeley.qualtrics.com/jfe/form/SV_bI9TKOdwtAVycaG""&gt;&lt;em&gt;https://berkeley.qualtrics.com/jfe/form/SV_bI9TKOdwtAVycaG&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;All adults who have been diagnosed with diabetes for at least a year can participate, so please share the link with any friends and family who are eligible!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If you want to know more, please don&amp;#39;t hesitate to reach out!&lt;/p&gt;

&lt;p&gt;Thank you for your help!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mptq5o,True,,iowanative_24,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mptq5o/research_autonomous_devices_in_managing_diabetic/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mptq5o/research_autonomous_devices_in_managing_diabetic/,66146,1618282864.0,0,,False,,,,,,,
,deeplearning,,t2_66dim,False,,0,False,Object detection - suppressing busy/bad regions of image: will simply covering with white noise work?,[],r/deeplearning,False,6,,0,,False,t3_mpo4cf,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1618292534.0,text,6,,,text,reddit.com,False,,,,,https://www.reddit.com/gallery/mpo4cf,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpo4cf,True,,munkeegutz,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mpo4cf/object_detection_suppressing_busybad_regions_of/,all_ads,False,https://www.reddit.com/gallery/mpo4cf,66146,1618263734.0,0,,False,,,"{'z5lg16x8bts61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 81, 'x': 108, 'u': 'https://preview.redd.it/z5lg16x8bts61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2c41513f6167ac0e3b1bd3bc3aad7b1171e46283'}, {'y': 162, 'x': 216, 'u': 'https://preview.redd.it/z5lg16x8bts61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a3b7fa99fda9e4a72b6902d6b4282fe652a4f26'}, {'y': 240, 'x': 320, 'u': 'https://preview.redd.it/z5lg16x8bts61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=87e13a1fcb1aea3f6fbc1c95eb1b194a92742b14'}, {'y': 480, 'x': 640, 'u': 'https://preview.redd.it/z5lg16x8bts61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7d46152f1f2c2b435336124bd6f53a9e2d8c7b3c'}, {'y': 720, 'x': 960, 'u': 'https://preview.redd.it/z5lg16x8bts61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=e4465c6bfa651fad71dfd1c3510e588316c3d5a4'}, {'y': 810, 'x': 1080, 'u': 'https://preview.redd.it/z5lg16x8bts61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f2301f56fc72afd4f5de129355a4b75294a50a40'}], 's': {'y': 1440, 'x': 1920, 'u': 'https://preview.redd.it/z5lg16x8bts61.png?width=1920&amp;format=png&amp;auto=webp&amp;s=306d1b76de3e824edc6896c8543d985629dea8bb'}, 'id': 'z5lg16x8bts61'}, 'ibtdx6x8bts61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 81, 'x': 108, 'u': 'https://preview.redd.it/ibtdx6x8bts61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a8484288e1ff96e1708e94ba10f0cc126ad64769'}, {'y': 162, 'x': 216, 'u': 'https://preview.redd.it/ibtdx6x8bts61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e5cec8cd95d836bf95fd52d71685fbe00ac9c4ff'}, {'y': 240, 'x': 320, 'u': 'https://preview.redd.it/ibtdx6x8bts61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7325cca4fbe1754c904669ed8bf89e360182f19a'}, {'y': 480, 'x': 640, 'u': 'https://preview.redd.it/ibtdx6x8bts61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b7d6c40fb89e4a1b56aee5f1a8643aef7eaa2b70'}, {'y': 720, 'x': 960, 'u': 'https://preview.redd.it/ibtdx6x8bts61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=93455da474289f4b807a1e41b90ed86136c964bf'}, {'y': 810, 'x': 1080, 'u': 'https://preview.redd.it/ibtdx6x8bts61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5d69ec6a92094c69e5494741a0c5b52037d6ebac'}], 's': {'y': 1440, 'x': 1920, 'u': 'https://preview.redd.it/ibtdx6x8bts61.png?width=1920&amp;format=png&amp;auto=webp&amp;s=9b282afe40b72c51cdb896199e1c6c811ca163be'}, 'id': 'ibtdx6x8bts61'}}",,,True,"{'items': [{'media_id': 'ibtdx6x8bts61', 'id': 38460592}, {'media_id': 'z5lg16x8bts61', 'id': 38460593}]}"
,deeplearning," I'm trying to understand the YOLO object detection algorithm from the [official paper by Redmon et al.](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf)   and having difficulties correlating the architecture explanation with   the provided figure. I'm familiar with CNN's but haven't read a lot of   papers before.

Some doubts I'm having are:

* Where are the 24 CNNs?
* In the first layer, how is a stride of 7x7x64 possible on a 448x448x3? (shouldn't they have the same channel/depth value?)

I'm   probably misinterpreting the notations used while describing NN   architectures. I would highly appreciate if someone could help me out in   understanding its overall architecture from the attached image.

The explanation given in the paper for this architecture is as follows:

&gt;Our   detection network has 24 convolutional layers followed by 2 fully   connected layers. Alternating 1 × 1 convolutional layers reduce the   features space from preceding layers. We pretrain the convolutional   layers on the ImageNet classiﬁcation task at half the resolution (224 ×   224 input image) and then double the resolution for detection.

&amp;#x200B;

[Architecture given in the paper](https://preview.redd.it/84zf4ir6zrs61.png?width=809&amp;format=png&amp;auto=webp&amp;s=81805cbaa4eab8184a15debfd42fc03c83e30d66)",t2_4pzf8phg,False,,0,False,Help with understanding the YOLO (You Only Look Once) Architecture.,[],r/deeplearning,False,6,,0,,False,t3_mpif7o,False,dark,0.88,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1618276336.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to understand the YOLO object detection algorithm from the &lt;a href=""https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf""&gt;official paper by Redmon et al.&lt;/a&gt;   and having difficulties correlating the architecture explanation with   the provided figure. I&amp;#39;m familiar with CNN&amp;#39;s but haven&amp;#39;t read a lot of   papers before.&lt;/p&gt;

&lt;p&gt;Some doubts I&amp;#39;m having are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Where are the 24 CNNs?&lt;/li&gt;
&lt;li&gt;In the first layer, how is a stride of 7x7x64 possible on a 448x448x3? (shouldn&amp;#39;t they have the same channel/depth value?)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;#39;m   probably misinterpreting the notations used while describing NN   architectures. I would highly appreciate if someone could help me out in   understanding its overall architecture from the attached image.&lt;/p&gt;

&lt;p&gt;The explanation given in the paper for this architecture is as follows:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Our   detection network has 24 convolutional layers followed by 2 fully   connected layers. Alternating 1 × 1 convolutional layers reduce the   features space from preceding layers. We pretrain the convolutional   layers on the ImageNet classiﬁcation task at half the resolution (224 ×   224 input image) and then double the resolution for detection.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/84zf4ir6zrs61.png?width=809&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=81805cbaa4eab8184a15debfd42fc03c83e30d66""&gt;Architecture given in the paper&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpif7o,True,,d0esthismatter,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mpif7o/help_with_understanding_the_yolo_you_only_look/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mpif7o/help_with_understanding_the_yolo_you_only_look/,66146,1618247536.0,0,,False,,,"{'84zf4ir6zrs61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 46, 'x': 108, 'u': 'https://preview.redd.it/84zf4ir6zrs61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=654b51941b83a22df1109021ef12b18134d4127b'}, {'y': 92, 'x': 216, 'u': 'https://preview.redd.it/84zf4ir6zrs61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d38a3fe48ad5d462726427d83c5bbbb0431ada64'}, {'y': 137, 'x': 320, 'u': 'https://preview.redd.it/84zf4ir6zrs61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c8110b6a617510890e3c7bcc637b3ab1cb5c898f'}, {'y': 274, 'x': 640, 'u': 'https://preview.redd.it/84zf4ir6zrs61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b0e47e1d6f9b2fc5bb349b0dd0424957cbd73ff0'}], 's': {'y': 347, 'x': 809, 'u': 'https://preview.redd.it/84zf4ir6zrs61.png?width=809&amp;format=png&amp;auto=webp&amp;s=81805cbaa4eab8184a15debfd42fc03c83e30d66'}, 'id': '84zf4ir6zrs61'}}",,,,
,deeplearning,"A research team from IBM introduces two systems for predicting information type: The TypeSuggest module, an unsupervised system designed to generate types for a set of seed query terms input by the user; and an Answer Type prediction module for predicting the correct answer type for user-provided questions.

Here is a quick read: [IBM’s Type Prediction Systems Eliminate Need for Manual Annotations on Knowledge Graphs](https://syncedreview.com/2021/04/12/deepmind-microsoft-allen-ai-uw-researchers-convert-pretrained-transformers-into-rnns-lowering-memory-cost-while-retaining-high-accuracy-2/)

The paper *Type Prediction Systems* is on [arXiv](https://arxiv.org/pdf/2104.01207.pdf).",t2_6and1wb4,False,,0,False,IBM’s Type Prediction Systems Eliminate Need for Manual Annotations on Knowledge Graphs,[],r/deeplearning,False,6,,0,,False,t3_mpk63f,False,dark,1.0,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1618281258.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from IBM introduces two systems for predicting information type: The TypeSuggest module, an unsupervised system designed to generate types for a set of seed query terms input by the user; and an Answer Type prediction module for predicting the correct answer type for user-provided questions.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/12/deepmind-microsoft-allen-ai-uw-researchers-convert-pretrained-transformers-into-rnns-lowering-memory-cost-while-retaining-high-accuracy-2/""&gt;IBM’s Type Prediction Systems Eliminate Need for Manual Annotations on Knowledge Graphs&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Type Prediction Systems&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2104.01207.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpk63f,True,,eecloudsee,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mpk63f/ibms_type_prediction_systems_eliminate_need_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mpk63f/ibms_type_prediction_systems_eliminate_need_for/,66146,1618252458.0,0,,False,,,,,,,
,deeplearning,"Hello,

I'm using BERT language model for predicting mental health issues. Later, I'll be using more language models for comparison. The dataset is big and the whole computation requires GPUs which I don't have. I was wondering if there's any quick way to make a training cluster with multiple CPU based computers to make training faster. I'm no knowledge of distributed computing so idk how to proceed with this. Do you guys have any idea?

Thanks.",t2_8s1tooht,False,,0,False,Deep learning on multiple computers,[],r/deeplearning,False,6,,0,,False,t3_mpgx5y,False,dark,1.0,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1618272088.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I&amp;#39;m using BERT language model for predicting mental health issues. Later, I&amp;#39;ll be using more language models for comparison. The dataset is big and the whole computation requires GPUs which I don&amp;#39;t have. I was wondering if there&amp;#39;s any quick way to make a training cluster with multiple CPU based computers to make training faster. I&amp;#39;m no knowledge of distributed computing so idk how to proceed with this. Do you guys have any idea?&lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpgx5y,True,,rapchickk,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mpgx5y/deep_learning_on_multiple_computers/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mpgx5y/deep_learning_on_multiple_computers/,66146,1618243288.0,0,,False,,,,,,,
,deeplearning,"I hope someone can help me here. I have trained two models for different classification tasks that need to run either at the same time or one after another. The input for both models is the same image. The way I want it to work is as follows:

1. Load both models in the \_\_init\_\_ function
2. Get all images in a for loop
3. Every iteration in the loop preprocess (cropping and normalizing) the current image and predict it with both models
4.  After predicting the image both models should save the image in the related folders

The problem is that the model first loaded predicts everything as intended, but the second loaded model always predicts one class. When I run the models in separate scripts everything works fine. So there is an issue in loading them in one script. I researched a little and find that multiple predictions are harder because the GPU allocates its whole memory for one model. So I found this: [https://github.com/keras-team/keras/issues/8538#issuecomment-358720718](https://github.com/keras-team/keras/issues/8538#issuecomment-358720718)

&amp;#x200B;

But when I try it with the graphs it doesn't work and I get this error:

`tensorflow.python.framework.errors_impl.InvalidArgumentError: Node 'training/Adam/gradients/dropout_5/cond_grad/StatelessIf': Connecting to invalid output 1 of source node dropout_5/cond which has 1 outputs. Try using tf.compat.v1.experimental.output_all_intermediates(True).`

My code looks as follows:

`files = os.listdir(input_dir)`

`image_files = [os.path.join(input_dir, f) for f in files if f.endswith("".jpg"")]`

`total = 0`

`good_parts_cnt = 0`

`bad_parts_cnt = 0`

&amp;#x200B;

`scratch_model = 0`

`broen_edge_model = 0`

&amp;#x200B;

`for i in range(len(image_files)):`

`start_time = time.time()`

`total += 1`

`img_input = cv2.imread(image_files[i])`

`#crop out region of interest (die)`

`crop_image = img_input[self.y:self.y + self.height, self.x:self.x + self.width].copy()  # Makes a copy of file`

`#normalizing images before processing further`

`temp = cv2.normalize(crop_image, None, 0, 255, norm_type=cv2.NORM_MINMAX)`

`#get height and width of cropped image`

`h, w = crop_image.shape[0:2]`

&amp;#x200B;

`#copy cropped image`

`blacked_image = temp.copy()`

`#black out text in the middle of the die`

`blacked_image[27:h - 27, 27:w - 27] = 0`

&amp;#x200B;

`scratch_input_image = np.expand_dims(temp, axis=0)`

`#scratch_input_image = scratch_input_image.astype('float32') / 255`

&amp;#x200B;

`broken_edge_input_image = np.expand_dims(blacked_image, axis=0)`

`#broken_edge_input_image = broken_edge_input_image.astype('float32') / 255`

&amp;#x200B;

`#cv2.imshow(""scratch image"", scratch_input_image)`

`#cv2.imshow(""broken edge image"", broken_edge_input_image)`

`#cv2.waitKey(0)`

&amp;#x200B;

`graph1 = Graph()`

`with graph1.as_default():`

`session1 = Session()`

`with session1.as_default():`

`scratch_model = load_model(""C:\\Users\\but\\PycharmProjects\\OpticalDieInspection\\ScratchModel.h5"")`

`output_scratch = scratch_model.predict(scratch_input_image)`

&amp;#x200B;

`graph2 = Graph()`

`with graph2.as_default():`

`session2 = Session()`

`with session2.as_default():`

`broken_edge_model = load_model(""C:\\Users\\but\\PycharmProjects\\OpticalDieInspection\\brokenEdgeModel.h5"")`

`output_broken_edge = broken_edge_model.predict(broken_edge_input_image)`

&amp;#x200B;

Do you know how to solve this or have any idea how to do it otherwise?",t2_ovssbud,False,,0,False,How do I predict with two models at the same time in Keras?,[],r/deeplearning,False,6,,0,,False,t3_mpanux,False,dark,0.85,,public,9,0,{},,False,[],,False,False,,{},,False,9,,False,False,,False,,[],{},,True,,1618250389.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I hope someone can help me here. I have trained two models for different classification tasks that need to run either at the same time or one after another. The input for both models is the same image. The way I want it to work is as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Load both models in the __init__ function&lt;/li&gt;
&lt;li&gt;Get all images in a for loop&lt;/li&gt;
&lt;li&gt;Every iteration in the loop preprocess (cropping and normalizing) the current image and predict it with both models&lt;/li&gt;
&lt;li&gt; After predicting the image both models should save the image in the related folders&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The problem is that the model first loaded predicts everything as intended, but the second loaded model always predicts one class. When I run the models in separate scripts everything works fine. So there is an issue in loading them in one script. I researched a little and find that multiple predictions are harder because the GPU allocates its whole memory for one model. So I found this: &lt;a href=""https://github.com/keras-team/keras/issues/8538#issuecomment-358720718""&gt;https://github.com/keras-team/keras/issues/8538#issuecomment-358720718&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;But when I try it with the graphs it doesn&amp;#39;t work and I get this error:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tensorflow.python.framework.errors_impl.InvalidArgumentError: Node &amp;#39;training/Adam/gradients/dropout_5/cond_grad/StatelessIf&amp;#39;: Connecting to invalid output 1 of source node dropout_5/cond which has 1 outputs. Try using tf.compat.v1.experimental.output_all_intermediates(True).&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;My code looks as follows:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;files = os.listdir(input_dir)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;image_files = [os.path.join(input_dir, f) for f in files if f.endswith(&amp;quot;.jpg&amp;quot;)]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;total = 0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;good_parts_cnt = 0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;bad_parts_cnt = 0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;scratch_model = 0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;broen_edge_model = 0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;for i in range(len(image_files)):&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;start_time = time.time()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;total += 1&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;img_input = cv2.imread(image_files[i])&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;#crop out region of interest (die)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;crop_image = img_input[self.y:self.y + self.height, self.x:self.x + self.width].copy()  # Makes a copy of file&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;#normalizing images before processing further&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;temp = cv2.normalize(crop_image, None, 0, 255, norm_type=cv2.NORM_MINMAX)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;#get height and width of cropped image&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;h, w = crop_image.shape[0:2]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;#copy cropped image&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;blacked_image = temp.copy()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;#black out text in the middle of the die&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;blacked_image[27:h - 27, 27:w - 27] = 0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;scratch_input_image = np.expand_dims(temp, axis=0)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;#scratch_input_image = scratch_input_image.astype(&amp;#39;float32&amp;#39;) / 255&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;broken_edge_input_image = np.expand_dims(blacked_image, axis=0)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;#broken_edge_input_image = broken_edge_input_image.astype(&amp;#39;float32&amp;#39;) / 255&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;#cv2.imshow(&amp;quot;scratch image&amp;quot;, scratch_input_image)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;#cv2.imshow(&amp;quot;broken edge image&amp;quot;, broken_edge_input_image)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;#cv2.waitKey(0)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;graph1 = Graph()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;with graph1.as_default():&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;session1 = Session()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;with session1.as_default():&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;scratch_model = load_model(&amp;quot;C:\\Users\\but\\PycharmProjects\\OpticalDieInspection\\ScratchModel.h5&amp;quot;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;output_scratch = scratch_model.predict(scratch_input_image)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;graph2 = Graph()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;with graph2.as_default():&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;session2 = Session()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;with session2.as_default():&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;broken_edge_model = load_model(&amp;quot;C:\\Users\\but\\PycharmProjects\\OpticalDieInspection\\brokenEdgeModel.h5&amp;quot;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;output_broken_edge = broken_edge_model.predict(broken_edge_input_image)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Do you know how to solve this or have any idea how to do it otherwise?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpanux,True,,NECben,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/mpanux/how_do_i_predict_with_two_models_at_the_same_time/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mpanux/how_do_i_predict_with_two_models_at_the_same_time/,66146,1618221589.0,0,,False,,,,,,,
,deeplearning,,t2_7ini7,False,,0,False,[2102.11600] ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks,[],r/deeplearning,False,6,,0,,False,t3_mpftzq,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1618268943.0,text,6,,,text,arxiv.org,False,,,,,https://arxiv.org/abs/2102.11600,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpftzq,True,,evanatyourservice,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mpftzq/210211600_asam_adaptive_sharpnessaware/,all_ads,False,https://arxiv.org/abs/2102.11600,66146,1618240143.0,0,,False,,,,,,,
,deeplearning,"I have troubles setting up my GPU Server with Lambda Labs and I kept getting connection fail while launching jupyter notebook on ubuntu. 

I am trying to run my image classifier with ResNet50 or DenseNet. I have already incurred $5 trying to setup. Appreciate if anyone can help me on this.",t2_174108,False,,0,False,"Need help with setting up Lambda Labs with Keras, Tensorflow and Jupyter notebook.",[],r/deeplearning,False,6,,0,,False,t3_mpg2a7,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1618269607.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have troubles setting up my GPU Server with Lambda Labs and I kept getting connection fail while launching jupyter notebook on ubuntu. &lt;/p&gt;

&lt;p&gt;I am trying to run my image classifier with ResNet50 or DenseNet. I have already incurred $5 trying to setup. Appreciate if anyone can help me on this.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpg2a7,True,,GunsproisReal,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mpg2a7/need_help_with_setting_up_lambda_labs_with_keras/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mpg2a7/need_help_with_setting_up_lambda_labs_with_keras/,66146,1618240807.0,0,,False,,,,,,,
,deeplearning,,t2_6l105jav,False,,0,False,Deep Learning with TensorFlow - free course from udemy,[],r/deeplearning,False,6,,0,,False,t3_movew1,False,dark,0.84,,public,34,2,{},,False,[],,False,False,,{},,False,34,,False,False,,False,,[],{},,False,,1618191888.0,text,6,,,text,myfreeonlinecourses.com,False,,,,,https://www.myfreeonlinecourses.com/2021/04/100-off-deep-learning-with-tensorflow.html,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}, {'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,movew1,True,,Ordinary_Craft,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/movew1/deep_learning_with_tensorflow_free_course_from/,all_ads,False,https://www.myfreeonlinecourses.com/2021/04/100-off-deep-learning-with-tensorflow.html,66146,1618163088.0,0,,False,,,,,,,
,deeplearning,,t2_7r192xsf,False,,0,False,Video demo of weight initialization techniques,[],r/deeplearning,False,6,,0,,False,t3_mp5zyg,False,dark,0.81,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1618227148.0,text,6,,,text,7-hiddenlayers.com,False,,,,,https://7-hiddenlayers.com/weight-initialization-techniques/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mp5zyg,True,,Less-Requirement9910,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mp5zyg/video_demo_of_weight_initialization_techniques/,all_ads,False,https://7-hiddenlayers.com/weight-initialization-techniques/,66146,1618198348.0,0,,False,,,,,,,
,deeplearning,,t2_2o7eaff,False,,0,False,Machine Learning With ML.NET - Evaluation Metrics,[],r/deeplearning,False,6,,0,,False,t3_mp96y8,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1618242935.0,text,6,,,text,rubikscode.net,False,,,,,https://rubikscode.net/2021/04/12/machine-learning-with-ml-net-evaluation-metrics/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mp96y8,True,,RubiksCodeNMZ,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mp96y8/machine_learning_with_mlnet_evaluation_metrics/,all_ads,False,https://rubikscode.net/2021/04/12/machine-learning-with-ml-net-evaluation-metrics/,66146,1618214135.0,0,,False,,,,,,,
,deeplearning,"Guys! I'm conducting a session on hands-on neural networks with pytorch.

I'm planning to cover how to code a neural network and add/edit layers and check the results. Feel free to join the session

  
[https://onehotml.com/meeting/5a8ec53b-5fe6-4587-ae63-58ef7a47f5cd](https://onehotml.com/meeting/5a8ec53b-5fe6-4587-ae63-58ef7a47f5cd)

&amp;#x200B;

This is on 18th April 4:00PM -5:00PM IST",t2_5nnna2ug,False,,0,False,Session on Neural networks handson,[],r/deeplearning,False,6,,0,,False,t3_mp8ejs,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618238598.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Guys! I&amp;#39;m conducting a session on hands-on neural networks with pytorch.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m planning to cover how to code a neural network and add/edit layers and check the results. Feel free to join the session&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://onehotml.com/meeting/5a8ec53b-5fe6-4587-ae63-58ef7a47f5cd""&gt;https://onehotml.com/meeting/5a8ec53b-5fe6-4587-ae63-58ef7a47f5cd&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;This is on 18th April 4:00PM -5:00PM IST&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mp8ejs,True,,Spirited-Material465,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mp8ejs/session_on_neural_networks_handson/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mp8ejs/session_on_neural_networks_handson/,66146,1618209798.0,0,,False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,Learn Egyptian Arabic: Ramadan in Egypt,[],r/deeplearning,False,6,,0,,False,t3_mpbzan,False,dark,0.38,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/74yr_pNTbhk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Learn Egyptian Arabic: Ramadan in Egypt :)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/74yr_pNTbhk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/74yr_pNTbhk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/74yr_pNTbhk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mpbzan', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1618256205.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/74yr_pNTbhk,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mpbzan,True,,Community-Of-Babel,,1,False,all_ads,False,[],False,,/r/deeplearning/comments/mpbzan/learn_egyptian_arabic_ramadan_in_egypt/,all_ads,False,https://youtu.be/74yr_pNTbhk,66146,1618227405.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Learn Egyptian Arabic: Ramadan in Egypt :)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/74yr_pNTbhk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/74yr_pNTbhk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}",False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Learn Egyptian Arabic: Ramadan in Egypt', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mpbyj6', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 1, 'total_awards_received': 0, 'media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/74yr_pNTbhk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'Learn Egyptian Arabic: Ramadan in Egypt :)', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/74yr_pNTbhk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/74yr_pNTbhk/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}, 'type': 'youtube.com'}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/74yr_pNTbhk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mpbyj6', 'height': 200}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1618256116.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtu.be', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://youtu.be/74yr_pNTbhk', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mpbyj6', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/mpbyj6/learn_egyptian_arabic_ramadan_in_egypt/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://youtu.be/74yr_pNTbhk', 'subreddit_subscribers': 0, 'created_utc': 1618227316.0, 'num_crossposts': 4, 'media': {'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'Learn Egyptian Arabic: Ramadan in Egypt :)', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/74yr_pNTbhk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/74yr_pNTbhk/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}, 'type': 'youtube.com'}, 'is_video': False}]",t3_mpbyj6,,,,,
,deeplearning,,t2_265t3i5h,False,,0,False,9 Tensorflow Courses to learn Online,[],r/deeplearning,False,6,,0,,False,t3_mp5zz5,False,dark,0.29,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1618227150.0,text,6,,,text,mltut.com,False,,,,,https://www.mltut.com/best-tensorflow-courses-certifications-online/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mp5zz5,True,,MlTut,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mp5zz5/9_tensorflow_courses_to_learn_online/,all_ads,False,https://www.mltut.com/best-tensorflow-courses-certifications-online/,66146,1618198350.0,0,,False,,,,,,,
,deeplearning,,t2_5fsp2x6v,False,,0,False,NER for Social Media Texts with Semantic Augmentation | Research Papers Summary 013,[],r/deeplearning,False,6,,0,,False,t3_mow3xr,False,dark,0.6,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FmnbBL0ems8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'NER for Social Media Texts with Semantic Augmentation | Research Papers Summary 013', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FmnbBL0ems8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'Ryan Ong', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/FmnbBL0ems8/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/basketball10029508'}, 'type': 'youtube.com'}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FmnbBL0ems8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mow3xr', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1618193925.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/FmnbBL0ems8,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mow3xr,True,,RyanAI100,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mow3xr/ner_for_social_media_texts_with_semantic/,all_ads,False,https://youtu.be/FmnbBL0ems8,66146,1618165125.0,0,"{'oembed': {'provider_url': 'https://www.youtube.com/', 'title': 'NER for Social Media Texts with Semantic Augmentation | Research Papers Summary 013', 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FmnbBL0ems8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'version': '1.0', 'author_name': 'Ryan Ong', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/FmnbBL0ems8/hqdefault.jpg', 'type': 'video', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/basketball10029508'}, 'type': 'youtube.com'}",False,,,,,,,
,deeplearning,,t2_a7i59xms,False,,0,False,Growing neural cellular automata in PyTorch,[],r/deeplearning,False,6,,0,,False,t3_mo8lua,False,dark,0.92,,public,32,1,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/21ACbWoF2Oo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Growing neural cellular automata in PyTorch', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/21ACbWoF2Oo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'mildlyoverfitted', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/21ACbWoF2Oo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/mildlyoverfitted'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/21ACbWoF2Oo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mo8lua', 'height': 200}",,False,32,,False,False,,False,,[],{},,False,,1618103115.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/21ACbWoF2Oo,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mo8lua,True,,mildlyoverfitted,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mo8lua/growing_neural_cellular_automata_in_pytorch/,all_ads,False,https://youtu.be/21ACbWoF2Oo,66146,1618074315.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Growing neural cellular automata in PyTorch', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/21ACbWoF2Oo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'mildlyoverfitted', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/21ACbWoF2Oo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/mildlyoverfitted'}}",False,,,,,,,
,deeplearning,"Most of the research work related to neural network pruning revolves around iterative pruning ever the general idea is to prune p% of connections per iterative round either locally or globally, structured vs. unstructured. A common criterion is absolute magnitude weight based pruning (Han et al. 2015).

Since this is an iterative pruning technique, the number of such rounds are large.

Is there some other pruning technique to overcome this shortcoming? It's kind of trying to identify the important connections before the entire training process.",t2_2mmql89p,False,,0,False,Finding important connections,[],r/deeplearning,False,6,,0,,False,t3_mo8muz,False,dark,0.89,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,True,,1618103197.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Most of the research work related to neural network pruning revolves around iterative pruning ever the general idea is to prune p% of connections per iterative round either locally or globally, structured vs. unstructured. A common criterion is absolute magnitude weight based pruning (Han et al. 2015).&lt;/p&gt;

&lt;p&gt;Since this is an iterative pruning technique, the number of such rounds are large.&lt;/p&gt;

&lt;p&gt;Is there some other pruning technique to overcome this shortcoming? It&amp;#39;s kind of trying to identify the important connections before the entire training process.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mo8muz,True,,grid_world,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mo8muz/finding_important_connections/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mo8muz/finding_important_connections/,66146,1618074397.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,From Amputee to Cyborg with this AI-Powered Hand! 🦾[Nguyen &amp; Drealan et al. (2021)],[],r/deeplearning,False,6,,0,,False,t3_mo43xn,False,dark,0.8,,public,9,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/wNBrCRzlbVw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'From Amputee to Cyborg with this AI-Powered Hand! 🦾', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/wNBrCRzlbVw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/wNBrCRzlbVw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/wNBrCRzlbVw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mo43xn', 'height': 200}",,False,9,,False,False,,False,,[],{},,False,,1618087867.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/wNBrCRzlbVw,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mo43xn,True,,OnlyProggingForFun,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mo43xn/from_amputee_to_cyborg_with_this_aipowered_hand/,all_ads,False,https://youtu.be/wNBrCRzlbVw,66146,1618059067.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'From Amputee to Cyborg with this AI-Powered Hand! 🦾', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/wNBrCRzlbVw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/wNBrCRzlbVw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,,,,,,,
,deeplearning,,t2_3z8a2x6g,False,,0,False,Event extraction from transcript,[],r/deeplearning,False,6,,0,,False,t3_moc3pa,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1618114367.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/moc0zc/r_techniques_for_nlp_event_extraction_from_large/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,moc3pa,True,,i_kurt_i,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/moc3pa/event_extraction_from_transcript/,all_ads,False,/r/MachineLearning/comments/moc0zc/r_techniques_for_nlp_event_extraction_from_large/,66146,1618085567.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '[removed]', 'author_fullname': 't2_3z8a2x6g', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R] Techniques for NLP event extraction from large text of commentator speech from football match?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_moc0zc', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1618114113.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': 'moderator', 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'moc0zc', 'is_robot_indexable': False, 'report_reasons': None, 'author': 'i_kurt_i', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/moc0zc/r_techniques_for_nlp_event_extraction_from_large/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/moc0zc/r_techniques_for_nlp_event_extraction_from_large/', 'subreddit_subscribers': 1931397, 'created_utc': 1618085313.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_moc0zc,,,,,
,deeplearning,"Hi community, 

I am planning on buying a deep learning workstation (pre-built) since there RTX 3090 are sold-out. It is for research in vision and language. 

I've been looking at different places, Lambda, Bizon and Titan. 

My idea is to just buy 1 3090 card for now, and add more later. Which of the 3 sellers do you recommend and why? I am not an expert on hardware at all, and I would like some help. Are there any other sellers that you might consider?

Within titan computers ([https://www.titancomputers.com/AI-Deep-Learning-Machine-Learning-s/1150.htm](https://www.titancomputers.com/AI-Deep-Learning-Machine-Learning-s/1150.htm)) halfway through that page there are some options. I am considering either S375 or S599 models. Adding 1 rtx3090 adds to \~$7000, and Bizon G3000 with similar specs (less cpu cores) is around $7300. 

I have some other questions, like what CPU is actually good (and how many cores I need) for the purposes of DL research with 1 (and potentially 2 GPUs) and also whether I would need  a RAID controller for PCIe NVMe SSDs or not. 

Lambda seems a bit more expensive at this point, and I don't see the option to select just 1 GPU. It is an expensive purchase, so I would like to be sure about what I buy. 

Any help would be appreciated!

Thanks!",t2_bgeeett5,False,,0,False,Deep learning workstation comparative Lambda VS Bizon VS TitanComputers,[],r/deeplearning,False,6,,0,,False,t3_mo8iv4,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618102874.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi community, &lt;/p&gt;

&lt;p&gt;I am planning on buying a deep learning workstation (pre-built) since there RTX 3090 are sold-out. It is for research in vision and language. &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve been looking at different places, Lambda, Bizon and Titan. &lt;/p&gt;

&lt;p&gt;My idea is to just buy 1 3090 card for now, and add more later. Which of the 3 sellers do you recommend and why? I am not an expert on hardware at all, and I would like some help. Are there any other sellers that you might consider?&lt;/p&gt;

&lt;p&gt;Within titan computers (&lt;a href=""https://www.titancomputers.com/AI-Deep-Learning-Machine-Learning-s/1150.htm""&gt;https://www.titancomputers.com/AI-Deep-Learning-Machine-Learning-s/1150.htm&lt;/a&gt;) halfway through that page there are some options. I am considering either S375 or S599 models. Adding 1 rtx3090 adds to ~$7000, and Bizon G3000 with similar specs (less cpu cores) is around $7300. &lt;/p&gt;

&lt;p&gt;I have some other questions, like what CPU is actually good (and how many cores I need) for the purposes of DL research with 1 (and potentially 2 GPUs) and also whether I would need  a RAID controller for PCIe NVMe SSDs or not. &lt;/p&gt;

&lt;p&gt;Lambda seems a bit more expensive at this point, and I don&amp;#39;t see the option to select just 1 GPU. It is an expensive purchase, so I would like to be sure about what I buy. &lt;/p&gt;

&lt;p&gt;Any help would be appreciated!&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mo8iv4,True,,perceptron_1,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mo8iv4/deep_learning_workstation_comparative_lambda_vs/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mo8iv4/deep_learning_workstation_comparative_lambda_vs/,66146,1618074074.0,0,,False,,,,,,,
,deeplearning,"In this tutorial we'll prepare Raspberry Pi (RPi) to run a TFLite model for classifying images. After that, the TFLite version of the MobileNet model will be downloaded and used for making predictions on-device.

[https://blog.paperspace.com/tensorflow-lite-raspberry-pi](https://blog.paperspace.com/tensorflow-lite-raspberry-pi/)",t2_a8i2hluj,False,,0,False,Run TensorFlow Lite Models on Raspberry Pi,[],r/deeplearning,False,6,,0,,False,t3_mnw5nf,False,dark,0.8,,public,12,0,{},,False,[],,False,False,,{},,False,12,,False,False,,False,,[],{},,True,,1618050267.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In this tutorial we&amp;#39;ll prepare Raspberry Pi (RPi) to run a TFLite model for classifying images. After that, the TFLite version of the MobileNet model will be downloaded and used for making predictions on-device.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://blog.paperspace.com/tensorflow-lite-raspberry-pi/""&gt;https://blog.paperspace.com/tensorflow-lite-raspberry-pi&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnw5nf,True,,ahmed26gad,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mnw5nf/run_tensorflow_lite_models_on_raspberry_pi/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mnw5nf/run_tensorflow_lite_models_on_raspberry_pi/,66146,1618021467.0,0,,False,,,,,,,
,deeplearning,"A research team from Technical University of Munich, Google, Nvidia and LMU München proposes CodeTrans, an encoder-decoder transformer model which achieves state-of-the-art performance on six tasks in the software engineering domain, including Code Documentation Generation, Source Code Summarization, Code Comment Generation, etc.

Here is a quick read: [TUM, Google, Nvidia &amp; LMU München's CodeTrans Pretrained Models Crack Source Code Tasks With SOTA Performance](https://syncedreview.com/2021/04/09/tum-google-nvidia-lmu-munchens-codetrans-pretrained-models-crack-source-code-tasks-with-sota-performance/)

The CodeTrans code is available on the project [GitHub](https://github.com/agemagician/CodeTrans). The paper *CodeTrans: Towards Cracking the Language of Silicone’s Code Through Self-Supervised Deep Learning and High Performance Computing* is on [arXiv](https://arxiv.org/ftp/arxiv/papers/2104/2104.02443.pdf).",t2_2fv4yodo,False,,0,False,"[N] TUM, Google, Nvidia &amp; LMU München's CodeTrans Pretrained Models Crack Source Code Tasks With SOTA Performance",[],r/deeplearning,False,6,,0,,False,t3_mnltdk,False,dark,0.96,,public,44,2,{},,False,[],,False,False,,{},,False,44,,False,False,,False,,[],{},,True,,1618016763.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Technical University of Munich, Google, Nvidia and LMU München proposes CodeTrans, an encoder-decoder transformer model which achieves state-of-the-art performance on six tasks in the software engineering domain, including Code Documentation Generation, Source Code Summarization, Code Comment Generation, etc.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/04/09/tum-google-nvidia-lmu-munchens-codetrans-pretrained-models-crack-source-code-tasks-with-sota-performance/""&gt;TUM, Google, Nvidia &amp;amp; LMU München&amp;#39;s CodeTrans Pretrained Models Crack Source Code Tasks With SOTA Performance&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The CodeTrans code is available on the project &lt;a href=""https://github.com/agemagician/CodeTrans""&gt;GitHub&lt;/a&gt;. The paper &lt;em&gt;CodeTrans: Towards Cracking the Language of Silicone’s Code Through Self-Supervised Deep Learning and High Performance Computing&lt;/em&gt; is on &lt;a href=""https://arxiv.org/ftp/arxiv/papers/2104/2104.02443.pdf""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 2, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnltdk,True,,Yuqing7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mnltdk/n_tum_google_nvidia_lmu_münchens_codetrans/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mnltdk/n_tum_google_nvidia_lmu_münchens_codetrans/,66146,1617987963.0,0,,False,,,,,,,
,deeplearning,"I'm trying to use confusion matrix on my first NN and to illustrate how it has performed I wanted to use a confusion matrix. 

The part that I was unsure about is what or where exactly is my actual and predicted values stored after I train a model. I'm having trouble finding these two to feed it to a confusion matrix.",t2_3umx4xf7,False,,0,False,Confusion matrix to test Neural Nets?,[],r/deeplearning,False,6,,0,,False,t3_mo4lqk,False,dark,0.43,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618089775.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to use confusion matrix on my first NN and to illustrate how it has performed I wanted to use a confusion matrix. &lt;/p&gt;

&lt;p&gt;The part that I was unsure about is what or where exactly is my actual and predicted values stored after I train a model. I&amp;#39;m having trouble finding these two to feed it to a confusion matrix.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mo4lqk,True,,Sholkon,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/mo4lqk/confusion_matrix_to_test_neural_nets/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mo4lqk/confusion_matrix_to_test_neural_nets/,66146,1618060975.0,0,,False,,,,,,,
,deeplearning,"I am a deep learning beginner, buying a new HP Pavilion laptop. I don't expect to use it locally for much of DL tasks, most of the stuff I will be doing on cloud. I am confused between 2 HP laptops, one with Nvidia MX 450 2 GB graphics vs the other with integrated Intel Iris Xe graphics. While latter is cheaper, I was wondering if there are any benefits of Nvidia MX 450 in the laptop with regards to deep learning requirements, worth spending a tad more on former one?

I don't want any other laptop recommendations, only if Nvidia mx 450 has any added benefits over Iris Xe for DL.",t2_758757g0,False,,0,False,Nvidia Geforce MX450 vs integrated Intel Iris Xe Graphics for DL,[],r/deeplearning,False,6,,0,,False,t3_mnucz0,False,dark,0.9,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,1618046529.0,,[],{},,True,,1618043462.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a deep learning beginner, buying a new HP Pavilion laptop. I don&amp;#39;t expect to use it locally for much of DL tasks, most of the stuff I will be doing on cloud. I am confused between 2 HP laptops, one with Nvidia MX 450 2 GB graphics vs the other with integrated Intel Iris Xe graphics. While latter is cheaper, I was wondering if there are any benefits of Nvidia MX 450 in the laptop with regards to deep learning requirements, worth spending a tad more on former one?&lt;/p&gt;

&lt;p&gt;I don&amp;#39;t want any other laptop recommendations, only if Nvidia mx 450 has any added benefits over Iris Xe for DL.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnucz0,True,,MusicalCakehole,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/mnucz0/nvidia_geforce_mx450_vs_integrated_intel_iris_xe/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mnucz0/nvidia_geforce_mx450_vs_integrated_intel_iris_xe/,66146,1618014662.0,0,,False,,,,,,,
,deeplearning,"Hi, everyone!

I'm a future PhD student, whose topic will be DL. I find this area of ML really fascinating.

 I know there are tons of very talented students and researchers who are working in the field. My question is, what would you think are the most crowded sub-fields of DL? My first guess is transformers. Other options might include Few-Shot Learning, Zero-Shot Learning, self-supervised learning, domain adaptation, graph neural nets, etc.

I'm aware of how competitive this field is in general, and I'm set to work hard towards contributing to it. But as a new student, I'd like to be in a field that doesn't have ALL the attention right now, as it might be difficult to keep track (specially in view of tech giants who publish papers everyday 😅).

Thanks in advance!",t2_56lj6uum,False,,0,False,Are there sub-areas of DL that are more crowded than others?,[],r/deeplearning,False,6,,0,,False,t3_mnn50a,False,dark,0.84,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1618020631.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, everyone!&lt;/p&gt;

&lt;p&gt;I&amp;#39;m a future PhD student, whose topic will be DL. I find this area of ML really fascinating.&lt;/p&gt;

&lt;p&gt;I know there are tons of very talented students and researchers who are working in the field. My question is, what would you think are the most crowded sub-fields of DL? My first guess is transformers. Other options might include Few-Shot Learning, Zero-Shot Learning, self-supervised learning, domain adaptation, graph neural nets, etc.&lt;/p&gt;

&lt;p&gt;I&amp;#39;m aware of how competitive this field is in general, and I&amp;#39;m set to work hard towards contributing to it. But as a new student, I&amp;#39;d like to be in a field that doesn&amp;#39;t have ALL the attention right now, as it might be difficult to keep track (specially in view of tech giants who publish papers everyday 😅).&lt;/p&gt;

&lt;p&gt;Thanks in advance!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnn50a,True,,Historical-Carpenter,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mnn50a/are_there_subareas_of_dl_that_are_more_crowded/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mnn50a/are_there_subareas_of_dl_that_are_more_crowded/,66146,1617991831.0,0,,False,,,,,,,
,deeplearning,"Hello everybody. I am looking for a deep learning book or free course that doesn't assume any math background beyond high school math. I understand the mathematics behind fully connected layers pretty well (completed the first one and a half courses in Andrew NG's deep learning specialization) so I am looking for a book to expand into convolutional or recurrent networks, so that I can build my own without any libraries. Are there any resources or books that you recommend?",t2_77x7ml6a,False,,0,False,Deep learning book that makes no assumptions beyond an understanding of high school math?,[],r/deeplearning,False,6,,0,,False,t3_mntlhb,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618040680.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everybody. I am looking for a deep learning book or free course that doesn&amp;#39;t assume any math background beyond high school math. I understand the mathematics behind fully connected layers pretty well (completed the first one and a half courses in Andrew NG&amp;#39;s deep learning specialization) so I am looking for a book to expand into convolutional or recurrent networks, so that I can build my own without any libraries. Are there any resources or books that you recommend?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mntlhb,True,,TheAnonymous123456,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/mntlhb/deep_learning_book_that_makes_no_assumptions/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mntlhb/deep_learning_book_that_makes_no_assumptions/,66146,1618011880.0,0,,False,,,,,,,
,deeplearning,,t2_4h10zbbc,False,,0,False,Object Detection tutorial using Mask Rcnn on Label annotations,[],r/deeplearning,False,6,,0,,False,t3_mnwd6w,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1618051077.0,text,6,,,text,codeperfectplus.herokuapp.com,False,,,,,http://codeperfectplus.herokuapp.com/mask-rcnn-implementation-for-image-segmentation,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnwd6w,True,,perfect9015,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mnwd6w/object_detection_tutorial_using_mask_rcnn_on/,all_ads,False,http://codeperfectplus.herokuapp.com/mask-rcnn-implementation-for-image-segmentation,66146,1618022277.0,0,,False,,,,,,,
,deeplearning,"https://www.nvidia.com/en-us/gtc/?ncid=GTCS21-NVKASMITH[GTC 2021 Free Registration ](https://www.nvidia.com/en-us/gtc/?ncid=GTCS21-NVKASMITH)

Sign up folks, it’s FREE, amazing talks and a key note you won’t want to miss!",t2_1fvukqe9,False,,0,False,"NVIDIA GTC 2021, Free registration",[],r/deeplearning,False,6,,0,,False,t3_mno575,False,dark,1.0,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1618023596.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.nvidia.com/en-us/gtc/?ncid=GTCS21-NVKASMITH%5BGTC""&gt;https://www.nvidia.com/en-us/gtc/?ncid=GTCS21-NVKASMITH[GTC&lt;/a&gt; 2021 Free Registration ](&lt;a href=""https://www.nvidia.com/en-us/gtc/?ncid=GTCS21-NVKASMITH""&gt;https://www.nvidia.com/en-us/gtc/?ncid=GTCS21-NVKASMITH&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Sign up folks, it’s FREE, amazing talks and a key note you won’t want to miss!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mno575,True,,kaleb7589,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mno575/nvidia_gtc_2021_free_registration/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mno575/nvidia_gtc_2021_free_registration/,66146,1617994796.0,0,,False,,,,,,,
,deeplearning,,t2_avhf82y5,False,,0,False,DeepFaceLab: A Pre-Packaged Alternative DIY Deep Fakes,[],r/deeplearning,False,6,,0,,False,t3_mno46s,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1618023511.0,text,6,,,text,codeproject.com,False,,,,,https://www.codeproject.com/Articles/5298031/DeepFaceLab-A-Pre-Packaged-Alternative-DIY-Deep-Fa,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mno46s,True,,SUMtimesICode,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mno46s/deepfacelab_a_prepackaged_alternative_diy_deep/,all_ads,False,https://www.codeproject.com/Articles/5298031/DeepFaceLab-A-Pre-Packaged-Alternative-DIY-Deep-Fa,66146,1617994711.0,0,,False,,,,,,,
,deeplearning,"This tutorial gives a step-by-step guide to implementing an RNN model (encoder-decoder sequence-to-sequence with attention mechanism) for French to English translation using Keras.

Additional topics covered include:

* The Problem With Sequence-to-Sequence Models for Neural Machine Translation
* An Introduction to Attention Mechanisms
* Categories of Attention Mechanisms
* Applications of Attention Mechanisms
* Neural Machine Translation Using an RNN With Attention Mechanism (Keras)

Tutorial link: [https://blog.paperspace.com/seq-to-seq-attention-mechanism-keras/](https://blog.paperspace.com/seq-to-seq-attention-mechanism-keras/)

Run all of the code on a free GPU: [https://ml-showcase.paperspace.com/projects/neural-machine-translation-with-keras](https://ml-showcase.paperspace.com/projects/neural-machine-translation-with-keras)",t2_15en0l,False,,0,False,[Tutorial] Attention Mechanisms in Recurrent Neural Networks (RNNs) With Keras,[],r/deeplearning,False,6,,0,,False,t3_mnirs2,False,dark,0.78,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1618008373.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This tutorial gives a step-by-step guide to implementing an RNN model (encoder-decoder sequence-to-sequence with attention mechanism) for French to English translation using Keras.&lt;/p&gt;

&lt;p&gt;Additional topics covered include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The Problem With Sequence-to-Sequence Models for Neural Machine Translation&lt;/li&gt;
&lt;li&gt;An Introduction to Attention Mechanisms&lt;/li&gt;
&lt;li&gt;Categories of Attention Mechanisms&lt;/li&gt;
&lt;li&gt;Applications of Attention Mechanisms&lt;/li&gt;
&lt;li&gt;Neural Machine Translation Using an RNN With Attention Mechanism (Keras)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tutorial link: &lt;a href=""https://blog.paperspace.com/seq-to-seq-attention-mechanism-keras/""&gt;https://blog.paperspace.com/seq-to-seq-attention-mechanism-keras/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Run all of the code on a free GPU: &lt;a href=""https://ml-showcase.paperspace.com/projects/neural-machine-translation-with-keras""&gt;https://ml-showcase.paperspace.com/projects/neural-machine-translation-with-keras&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnirs2,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mnirs2/tutorial_attention_mechanisms_in_recurrent_neural/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mnirs2/tutorial_attention_mechanisms_in_recurrent_neural/,66146,1617979573.0,0,,False,,,,,,,
,deeplearning,Or are Data Analysts using them in their job? (Please don't get offended if you are one. It's an honest question.),t2_85gp9ukf,False,,0,False,Are Data Analysts still necessary with the rise of deep learning neural networks?,[],r/deeplearning,False,6,,0,,False,t3_mnrsnn,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1618035224.0,,[],{},,True,,1618034634.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Or are Data Analysts using them in their job? (Please don&amp;#39;t get offended if you are one. It&amp;#39;s an honest question.)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnrsnn,True,,Immortal_Di,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/mnrsnn/are_data_analysts_still_necessary_with_the_rise/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mnrsnn/are_data_analysts_still_necessary_with_the_rise/,66146,1618005834.0,0,,False,,,,,,,
,deeplearning,"AI systems are widely adopted in several real-world industries for decision-making. Despite their essential roles in numerous tasks, many studies show that such systems are frequently prone to biases resulting in discrimination against individuals based on racial and gender characteristics.

A team of researchers from MIT-IBM Watson AI Lab, the University of Michigan, and ShanghaiTech University has explored ways to detect biases and increase individual fairness in ML models. 

Full Summary: [https://www.marktechpost.com/2021/04/09/researchers-from-mit-ibm-watson-ai-lab-the-university-of-michigan-and-shanghaitech-university-study-ways-to-detect-biases-and-increase-machine-learning-ml-models-individual-fairness/](https://www.marktechpost.com/2021/04/09/researchers-from-mit-ibm-watson-ai-lab-the-university-of-michigan-and-shanghaitech-university-study-ways-to-detect-biases-and-increase-machine-learning-ml-models-individual-fairness/) 

Paper 1: https://arxiv.org/pdf/2103.16714.pdf

Paper 2: https://arxiv.org/pdf/2103.16785.pdf",t2_4wudjgid,False,,0,False,"Researchers From MIT-IBM Watson AI Lab, the University of Michigan, and ShanghaiTech University Study Ways to Detect Biases and Increase Machine Learning (ML) model’s Individual Fairness",[],r/deeplearning,False,6,,0,,False,t3_mnka2j,False,dark,0.83,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1618012558.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;AI systems are widely adopted in several real-world industries for decision-making. Despite their essential roles in numerous tasks, many studies show that such systems are frequently prone to biases resulting in discrimination against individuals based on racial and gender characteristics.&lt;/p&gt;

&lt;p&gt;A team of researchers from MIT-IBM Watson AI Lab, the University of Michigan, and ShanghaiTech University has explored ways to detect biases and increase individual fairness in ML models. &lt;/p&gt;

&lt;p&gt;Full Summary: &lt;a href=""https://www.marktechpost.com/2021/04/09/researchers-from-mit-ibm-watson-ai-lab-the-university-of-michigan-and-shanghaitech-university-study-ways-to-detect-biases-and-increase-machine-learning-ml-models-individual-fairness/""&gt;https://www.marktechpost.com/2021/04/09/researchers-from-mit-ibm-watson-ai-lab-the-university-of-michigan-and-shanghaitech-university-study-ways-to-detect-biases-and-increase-machine-learning-ml-models-individual-fairness/&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Paper 1: &lt;a href=""https://arxiv.org/pdf/2103.16714.pdf""&gt;https://arxiv.org/pdf/2103.16714.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Paper 2: &lt;a href=""https://arxiv.org/pdf/2103.16785.pdf""&gt;https://arxiv.org/pdf/2103.16785.pdf&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnka2j,True,,techsucker,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mnka2j/researchers_from_mitibm_watson_ai_lab_the/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mnka2j/researchers_from_mitibm_watson_ai_lab_the/,66146,1617983758.0,0,,False,,,,,,,
,deeplearning,,t2_a8i2hluj,False,,0,False,From Scratch: How to Build a Neural Network and Calculate its Gradients? Solution is Presented as a Chemical Structure!,[],r/deeplearning,False,6,,0,,False,t3_mn5zwd,False,dark,0.8,,public,46,0,{},,False,[],,False,False,,{},,False,46,,False,False,,False,,[],{},,False,,1617958667.0,text,6,,,text,reddit.com,False,,,,,https://www.reddit.com/gallery/mn5zwd,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mn5zwd,True,,ahmed26gad,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mn5zwd/from_scratch_how_to_build_a_neural_network_and/,all_ads,False,https://www.reddit.com/gallery/mn5zwd,66146,1617929867.0,0,,False,,,"{'193mdcwgq1s61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 144, 'x': 108, 'u': 'https://preview.redd.it/193mdcwgq1s61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6aa3ec0f610887a6c974ab8b8c12534a3ff75278'}, {'y': 288, 'x': 216, 'u': 'https://preview.redd.it/193mdcwgq1s61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3057d1eeb296abaf19feff95a6ccffd5e6544b99'}, {'y': 426, 'x': 320, 'u': 'https://preview.redd.it/193mdcwgq1s61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b42dc2e588dcd428c3918b6b2293c8df80a7897b'}, {'y': 853, 'x': 640, 'u': 'https://preview.redd.it/193mdcwgq1s61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=22be662d8c8181539934cb2ef9546396004f2663'}], 's': {'y': 1032, 'x': 774, 'u': 'https://preview.redd.it/193mdcwgq1s61.jpg?width=774&amp;format=pjpg&amp;auto=webp&amp;s=3cb610d0093a78ba0e733e94d8e6e19ad63f942f'}, 'id': '193mdcwgq1s61'}, 'tw1sgcwgq1s61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 81, 'x': 108, 'u': 'https://preview.redd.it/tw1sgcwgq1s61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a64c39abb05c250708815264aa285872e4c59bec'}, {'y': 162, 'x': 216, 'u': 'https://preview.redd.it/tw1sgcwgq1s61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=777392181617ca4d1ef416f3d8f982c59730540e'}, {'y': 240, 'x': 320, 'u': 'https://preview.redd.it/tw1sgcwgq1s61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b00604b1cdd1d8292c83d74e7e76732f8e7c0e35'}, {'y': 480, 'x': 640, 'u': 'https://preview.redd.it/tw1sgcwgq1s61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5b11663b0717e58c7db936f2f082799b4c9b8ea'}, {'y': 720, 'x': 960, 'u': 'https://preview.redd.it/tw1sgcwgq1s61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=959d2c93d68268f8546ed967fee0aa7d0a68d97e'}], 's': {'y': 774, 'x': 1032, 'u': 'https://preview.redd.it/tw1sgcwgq1s61.jpg?width=1032&amp;format=pjpg&amp;auto=webp&amp;s=fb4a26ef454e21b0052985aa426a4520bfefe80c'}, 'id': 'tw1sgcwgq1s61'}}",,,True,"{'items': [{'caption': 'Calculating the Gradients of a Neural Network from Scratch: Solution is Presented as a Chemical Structure! ', 'outbound_url': 'https://www.amazon.com/Introduction-Learning-Neural-Networks-PythonTM/dp/0323909337', 'media_id': 'tw1sgcwgq1s61', 'id': 37728037}, {'caption': 'Ahmed FG and Fatima EJ, Introduction to Deep Learning and Neural Networks with Python™: A Practical Guide, 978-0323909334, Academic Press, 2020', 'outbound_url': 'https://www.amazon.com/Introduction-Learning-Neural-Networks-PythonTM/dp/0323909337', 'media_id': '193mdcwgq1s61', 'id': 37728038}]}"
,deeplearning,"Estoy trabajando con una red de clasificación de texto, el problema que es que tengo un margen de error aproximado del 50%, en otras palabras se podría decir que todavía ahí duda de lo que clasifica si es correcto o no, es por ello que necesito que entrenarlo para mejorar eso margen de error, algún consejo de como o que tipo de entrenamiento le doy a la red.

es una red tipo perceptrón multicapa.",t2_9pskn6un,False,,0,False,Consejo o ayuda,[],r/deeplearning,False,6,,0,,False,t3_mnnbhl,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618021166.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Estoy trabajando con una red de clasificación de texto, el problema que es que tengo un margen de error aproximado del 50%, en otras palabras se podría decir que todavía ahí duda de lo que clasifica si es correcto o no, es por ello que necesito que entrenarlo para mejorar eso margen de error, algún consejo de como o que tipo de entrenamiento le doy a la red.&lt;/p&gt;

&lt;p&gt;es una red tipo perceptrón multicapa.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnnbhl,True,,Desperate_Complex483,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mnnbhl/consejo_o_ayuda/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mnnbhl/consejo_o_ayuda/,66146,1617992366.0,0,,False,,,,,,,
,deeplearning,"Hello, I'm using UNet within the ArcGIS environment for landscape classification on an RGB image. I'd like to know how UNet is classifying the image, i.e., what are the RGB values it's searching for to differentiate between a building and a road. This is so that I can perturb those values and test for sensitivity to the different channels.

Thanks!",t2_13i6cn,False,,0,False,Extract RGB Classification Values from UNet,[],r/deeplearning,False,6,,0,,False,t3_mnh7aj,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1618003726.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, I&amp;#39;m using UNet within the ArcGIS environment for landscape classification on an RGB image. I&amp;#39;d like to know how UNet is classifying the image, i.e., what are the RGB values it&amp;#39;s searching for to differentiate between a building and a road. This is so that I can perturb those values and test for sensitivity to the different channels.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnh7aj,True,,jwolstenholme,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/mnh7aj/extract_rgb_classification_values_from_unet/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mnh7aj/extract_rgb_classification_values_from_unet/,66146,1617974926.0,0,,False,,,,,,,
,deeplearning,"[ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement](https://t.me/casual_gan/24)

A great idea to improve StyleGAN inversion for complex real images that builds on top of the recent e4e and pSp papers.

The authors propose a fast iterative method of image inversion into the latent space of a pretrained StyleGAN generator that acheives SOTA quality at a lower inference time. The core idea is to start from the average latent vector in W+ and predict an offset that would make the generated image look more like the target, then repeat this step with the new image and latent vector as the starting point. With the proposed approach a good inversion can be obtained in about 10 steps. More details [here](https://t.me/casual_gan/24)

[The inversions are awesome!](https://preview.redd.it/rkad9gw3c6s61.png?width=1106&amp;format=png&amp;auto=webp&amp;s=6108190507c1804eebb90366b4dfeb6c69764291)

P.S. In case you are not familiar with the paper check it out [here](https://t.me/casual_gan/24):",t2_hhio3,False,,0,False,[R] ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement - Explained,[],r/deeplearning,False,6,,0,,False,t3_mnky1y,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1617985937.0,,[],{},,True,,1618014358.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://t.me/casual_gan/24""&gt;ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A great idea to improve StyleGAN inversion for complex real images that builds on top of the recent e4e and pSp papers.&lt;/p&gt;

&lt;p&gt;The authors propose a fast iterative method of image inversion into the latent space of a pretrained StyleGAN generator that acheives SOTA quality at a lower inference time. The core idea is to start from the average latent vector in W+ and predict an offset that would make the generated image look more like the target, then repeat this step with the new image and latent vector as the starting point. With the proposed approach a good inversion can be obtained in about 10 steps. More details &lt;a href=""https://t.me/casual_gan/24""&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/rkad9gw3c6s61.png?width=1106&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6108190507c1804eebb90366b4dfeb6c69764291""&gt;The inversions are awesome!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;P.S. In case you are not familiar with the paper check it out &lt;a href=""https://t.me/casual_gan/24""&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnky1y,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mnky1y/r_restyle_a_residualbased_stylegan_encoder_via/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mnky1y/r_restyle_a_residualbased_stylegan_encoder_via/,66146,1617985558.0,0,,False,,,"{'rkad9gw3c6s61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 124, 'x': 108, 'u': 'https://preview.redd.it/rkad9gw3c6s61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1bcb873b7bb0c913fb1e23202a1b09a1609d6e78'}, {'y': 249, 'x': 216, 'u': 'https://preview.redd.it/rkad9gw3c6s61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=3fc24c7e94bb08fda4cc8838939cf9de50612258'}, {'y': 370, 'x': 320, 'u': 'https://preview.redd.it/rkad9gw3c6s61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=63ce4d55a55b93fa7ff3b863c5ee41cc9cde31b2'}, {'y': 740, 'x': 640, 'u': 'https://preview.redd.it/rkad9gw3c6s61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ca785a70023d9f87a6f3698e20bf9a600d7e04e3'}, {'y': 1111, 'x': 960, 'u': 'https://preview.redd.it/rkad9gw3c6s61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=74eb9d80d03002b46c740c1f4f9b68a3bc496a57'}, {'y': 1249, 'x': 1080, 'u': 'https://preview.redd.it/rkad9gw3c6s61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ddb29126b766b282a21e450bb35e245e48eaab4b'}], 's': {'y': 1280, 'x': 1106, 'u': 'https://preview.redd.it/rkad9gw3c6s61.png?width=1106&amp;format=png&amp;auto=webp&amp;s=6108190507c1804eebb90366b4dfeb6c69764291'}, 'id': 'rkad9gw3c6s61'}}",,,,
,deeplearning,,t2_a8i2hluj,False,,0,False,Keras + PyGAD: Train Keras Models using the Genetic Algorithm: https://github.com/ahmedfgad/KerasGA,[],r/deeplearning,False,6,,0,,False,t3_mnaatl,False,dark,0.81,,public,6,0,{},,False,[],,True,False,,{},,False,6,,False,False,,False,,[],{},,False,,1617974457.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/24kf2v2l13s61.jpg,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnaatl,True,,ahmed26gad,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mnaatl/keras_pygad_train_keras_models_using_the_genetic/,all_ads,False,https://i.redd.it/24kf2v2l13s61.jpg,66146,1617945657.0,0,,False,,,,,,,
,deeplearning,,t2_af77i18u,False,,0,False,Real Learning and future of (AI and neuroscience),[],r/deeplearning,False,6,,0,,False,t3_mnjm1k,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1618010716.0,text,6,,,text,self.artificial,False,,,,,/r/artificial/comments/mni53y/real_learning_and_future_of_ai_and_neuroscience/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mnjm1k,True,,LooksForFuture,,0,False,all_ads,False,[],False,,/r/deeplearning/comments/mnjm1k/real_learning_and_future_of_ai_and_neuroscience/,all_ads,False,/r/artificial/comments/mni53y/real_learning_and_future_of_ai_and_neuroscience/,66146,1617981916.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'artificial', 'selftext': ""Hi. Recently a teenager has invented a new AI system which can change the world of AI and neuroscience. This new system is called Real Learning. Real Learning can learn faster than current AI systems and in the future, it will learn faster than human brain. Real Learning has real neurons and doesn't only use statistics functions like machine learning and deep learning. Real Learning has new strong algorithms which can help it to learn only in one epoch. RL (Real Learning) can also improve its neural network and create new neurons.\n\nIf you've been interested about Real Learning, visit [this](http://blog.niknami.com/post/real-learning) page for more information about Real Learning."", 'author_fullname': 't2_af77i18u', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Real Learning and future of (AI and neuroscience)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/artificial', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'news', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mni53y', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.33, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'News', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1618006539.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.artificial', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi. Recently a teenager has invented a new AI system which can change the world of AI and neuroscience. This new system is called Real Learning. Real Learning can learn faster than current AI systems and in the future, it will learn faster than human brain. Real Learning has real neurons and doesn&amp;#39;t only use statistics functions like machine learning and deep learning. Real Learning has new strong algorithms which can help it to learn only in one epoch. RL (Real Learning) can also improve its neural network and create new neurons.&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve been interested about Real Learning, visit &lt;a href=""http://blog.niknami.com/post/real-learning""&gt;this&lt;/a&gt; page for more information about Real Learning.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': 'confidence', 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'da8f11a8-82c9-11e3-8303-12313d01b5d1', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qhfb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ffd635', 'id': 'mni53y', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'LooksForFuture', 'discussion_type': None, 'num_comments': 13, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/artificial/comments/mni53y/real_learning_and_future_of_ai_and_neuroscience/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/artificial/comments/mni53y/real_learning_and_future_of_ai_and_neuroscience/', 'subreddit_subscribers': 142746, 'created_utc': 1617977739.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_mni53y,,,,,
,deeplearning,"Hello, 

Can anyone recommend me online or offline tools that increase image resolution of large files using machine learning algorithms? I found many on the web, but I specifically need to enlarge input images of 200 MP which I couldn't do. Thank you.

&amp;#x200B;

Regards",t2_3sunofqd,False,,0,False,Increase image resolution with AI,[],r/deeplearning,False,6,,0,,False,t3_mni3g6,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1618006398.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello, &lt;/p&gt;

&lt;p&gt;Can anyone recommend me online or offline tools that increase image resolution of large files using machine learning algorithms? I found many on the web, but I specifically need to enlarge input images of 200 MP which I couldn&amp;#39;t do. Thank you.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Regards&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mni3g6,True,,Yagshemash88,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mni3g6/increase_image_resolution_with_ai/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mni3g6/increase_image_resolution_with_ai/,66146,1617977598.0,0,,False,,,,,,,
,deeplearning,"Hey guys, I am looking for neural network pruning tutorials/implementations.

I looked into [torch.nn.utils.prune](https://pytorch.org/docs/master/generated/torch.nn.utils.prune.global_unstructured.html) module but it doesn't present an end-to-end example and the [code](https://github.com/arjun-majumdar/Neural_Network_Pruning/blob/main/Iterative_Pruning_LeNet300_PyTorch.ipynb) that I came up with doesn't seem to work.

Help?",t2_2mmql89p,False,,0,False,Pruning tutorial,[],r/deeplearning,False,6,,0,,False,t3_mndfzh,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1617989019.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey guys, I am looking for neural network pruning tutorials/implementations.&lt;/p&gt;

&lt;p&gt;I looked into &lt;a href=""https://pytorch.org/docs/master/generated/torch.nn.utils.prune.global_unstructured.html""&gt;torch.nn.utils.prune&lt;/a&gt; module but it doesn&amp;#39;t present an end-to-end example and the &lt;a href=""https://github.com/arjun-majumdar/Neural_Network_Pruning/blob/main/Iterative_Pruning_LeNet300_PyTorch.ipynb""&gt;code&lt;/a&gt; that I came up with doesn&amp;#39;t seem to work.&lt;/p&gt;

&lt;p&gt;Help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mndfzh,True,,grid_world,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mndfzh/pruning_tutorial/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mndfzh/pruning_tutorial/,66146,1617960219.0,0,,False,,,,,,,
,deeplearning,,t2_4ba14,False,,0,False,"Axon is out! A deep learning library for Elixir, built on Nx.",[],r/deeplearning,False,6,,0,,False,t3_mn7zwz,False,dark,1.0,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,False,,1617965591.0,text,6,,,text,seanmoriarity.com,False,,,,,https://seanmoriarity.com/2021/04/08/axon-deep-learning-in-elixir/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mn7zwz,True,,cigrainger,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mn7zwz/axon_is_out_a_deep_learning_library_for_elixir/,all_ads,False,https://seanmoriarity.com/2021/04/08/axon-deep-learning-in-elixir/,66146,1617936791.0,0,,False,,,,,,,
,deeplearning,"I apologize in advance if this is not the right place to ask this. I am wondering if there is an online resource, similar to [https://app.runwayml.com/](https://app.runwayml.com/) that allows for DNN based interpolation between 2 frames. More specifically I would like to input an image at instance 0 and an image at instance T and specify a number of frames or duration and would like the network to generate the missing frames such as to create an animation.",t2_9yw71raz,False,,0,False,Is there an online Neural Network that allows to create missing frames between 2 input images?,[],r/deeplearning,False,6,,0,,False,t3_mne3uo,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617992177.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I apologize in advance if this is not the right place to ask this. I am wondering if there is an online resource, similar to &lt;a href=""https://app.runwayml.com/""&gt;https://app.runwayml.com/&lt;/a&gt; that allows for DNN based interpolation between 2 frames. More specifically I would like to input an image at instance 0 and an image at instance T and specify a number of frames or duration and would like the network to generate the missing frames such as to create an animation.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mne3uo,True,,vikare06,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mne3uo/is_there_an_online_neural_network_that_allows_to/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mne3uo/is_there_an_online_neural_network_that_allows_to/,66146,1617963377.0,0,,False,,,,,,,
,deeplearning,,t2_f2rfy,False,,0,False,CPU algorithm trains deep neural nets up to 15 times faster than top GPU trainers,[],r/deeplearning,False,6,,0,,False,t3_mmuqmp,False,dark,0.79,,public,22,0,{},,False,[],,False,False,,{},,False,22,,False,False,,False,,[],{},,False,,1617925897.0,text,6,,,text,techxplore.com,False,,,,,https://techxplore.com/news/2021-04-rice-intel-optimize-ai-commodity.html,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmuqmp,True,,keghn,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/mmuqmp/cpu_algorithm_trains_deep_neural_nets_up_to_15/,all_ads,False,https://techxplore.com/news/2021-04-rice-intel-optimize-ai-commodity.html,66146,1617897097.0,0,,False,,,,,,,
,deeplearning,"Graph neural  networks are a super hot topic but kind of niche.

I  created  this detailed blog-post to understand them with absolutely  zero background on graph theory, no crazy  math, no buzzwords, and  arbitrary concepts.

Just basic machine-deep learning and you will build your first graph neural network from scratch!

Link: [https://theaisummer.com/graph-convolutional-networks/](https://theaisummer.com/graph-convolutional-networks/)

Let me know what you think!

Cheers,",t2_5zc2ef2h,False,,0,False,How Graph Neural Networks (GNN) work: introduction to graph convolutions from scratch,[],r/deeplearning,False,6,,0,,False,t3_mmn709,False,dark,0.97,,public,83,0,{},,False,[],,False,False,,{},,False,83,,False,False,,False,,[],{},,True,,1617898929.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Graph neural  networks are a super hot topic but kind of niche.&lt;/p&gt;

&lt;p&gt;I  created  this detailed blog-post to understand them with absolutely  zero background on graph theory, no crazy  math, no buzzwords, and  arbitrary concepts.&lt;/p&gt;

&lt;p&gt;Just basic machine-deep learning and you will build your first graph neural network from scratch!&lt;/p&gt;

&lt;p&gt;Link: &lt;a href=""https://theaisummer.com/graph-convolutional-networks/""&gt;https://theaisummer.com/graph-convolutional-networks/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let me know what you think!&lt;/p&gt;

&lt;p&gt;Cheers,&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmn709,True,,black0017,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/mmn709/how_graph_neural_networks_gnn_work_introduction/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmn709/how_graph_neural_networks_gnn_work_introduction/,66146,1617870129.0,0,,False,,,,,,,
,deeplearning,"I have some numpy arrays that I'd like to use to construct a tf.Dataset object. [This](https://www.tensorflow.org/tutorials/load_data/numpy) tutorial goes into how this can be done, but assumes that the entire numpy array dataset can fit into memory, which is not the case for me.

My current workaround loads a chunk of the dataset, trains, loads another chunk of the dataset, trains, etc. but as you can imagine, this is quite slow. Any ideas?",t2_15mvad,False,,0,False,tf.Dataset with NumPy arrays,[],r/deeplearning,False,6,,0,,False,t3_mn4e99,False,dark,0.83,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1617953331.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have some numpy arrays that I&amp;#39;d like to use to construct a tf.Dataset object. &lt;a href=""https://www.tensorflow.org/tutorials/load_data/numpy""&gt;This&lt;/a&gt; tutorial goes into how this can be done, but assumes that the entire numpy array dataset can fit into memory, which is not the case for me.&lt;/p&gt;

&lt;p&gt;My current workaround loads a chunk of the dataset, trains, loads another chunk of the dataset, trains, etc. but as you can imagine, this is quite slow. Any ideas?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mn4e99,True,,alkaway,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mn4e99/tfdataset_with_numpy_arrays/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mn4e99/tfdataset_with_numpy_arrays/,66146,1617924531.0,0,,False,,,,,,,
,deeplearning,,t2_15f606,False,,0,False,Text Generation Using Recurrent Neural Networks,[],r/deeplearning,False,6,,0,,False,t3_mn2cu6,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1617947169.0,text,6,,,text,arcalan.medium.com,False,,,,,https://arcalan.medium.com/text-generation-using-recurrent-neural-networks-806f271870c4,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mn2cu6,True,,Arsalan26666,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mn2cu6/text_generation_using_recurrent_neural_networks/,all_ads,False,https://arcalan.medium.com/text-generation-using-recurrent-neural-networks-806f271870c4,66146,1617918369.0,0,,False,,,,,,,
,deeplearning,"Can you virtually remove a face mask to see what a person looks like underneath? STRV Machine Learning team proves it’s possible via an image inpainting-based ML solution. Here’s exactly how we approached the problem — from the preconditions to the implementation, results, and future improvements:   

[Mask2Face: How We Built AI That Shows the Face Beneath the Mask](https://www.strv.com/blog/mask2face-how-we-built-ai-that-shows-face-beneath-mask-engineering)

And here is the link to the project on GitHub: [https://github.com/strvcom/strv-ml-mask2face](https://github.com/strvcom/strv-ml-mask2face)",t2_c8xq4,False,,0,False,Mask2Face: How We Built AI That Shows the Face Beneath the Mask,[],r/deeplearning,False,6,,0,,False,t3_mmvv6c,False,dark,0.67,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1617929059.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can you virtually remove a face mask to see what a person looks like underneath? STRV Machine Learning team proves it’s possible via an image inpainting-based ML solution. Here’s exactly how we approached the problem — from the preconditions to the implementation, results, and future improvements:   &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://www.strv.com/blog/mask2face-how-we-built-ai-that-shows-face-beneath-mask-engineering""&gt;Mask2Face: How We Built AI That Shows the Face Beneath the Mask&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And here is the link to the project on GitHub: &lt;a href=""https://github.com/strvcom/strv-ml-mask2face""&gt;https://github.com/strvcom/strv-ml-mask2face&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmvv6c,True,,lukasus,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mmvv6c/mask2face_how_we_built_ai_that_shows_the_face/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmvv6c/mask2face_how_we_built_ai_that_shows_the_face/,66146,1617900259.0,0,,False,,,,,,,
,deeplearning,"We're really excited about our latest video breaking down fundamental topics in machine learning. 

Researcher Ahmed Gad explains basic machine learning metrics: the confusion matrix, accuracy, precision, and recall.  

https://youtu.be/\_y-peoToPj0",t2_15en0l,False,,0,False,"[Video] Machine learning metrics explained: the Confusion Matrix, Accuracy, Precision, and Recall",[],r/deeplearning,False,6,,0,,False,t3_mmr4qu,False,dark,0.75,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1617915228.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We&amp;#39;re really excited about our latest video breaking down fundamental topics in machine learning. &lt;/p&gt;

&lt;p&gt;Researcher Ahmed Gad explains basic machine learning metrics: the confusion matrix, accuracy, precision, and recall.  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://youtu.be/%5C_y-peoToPj0""&gt;https://youtu.be/\_y-peoToPj0&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmr4qu,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mmr4qu/video_machine_learning_metrics_explained_the/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmr4qu/video_machine_learning_metrics_explained_the/,66146,1617886428.0,1,,False,,,,,,,
,deeplearning,"I need a council I am programming a network of classification and I need that it is learned while it is classifying, but I can not understand this concept well some advice.

&amp;#x200B;

This already classifies but I need to improve that mistake of error.",t2_9pskn6un,False,,0,False,TIP,[],r/deeplearning,False,6,,0,,False,t3_mmvgat,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1617927880.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I need a council I am programming a network of classification and I need that it is learned while it is classifying, but I can not understand this concept well some advice.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;This already classifies but I need to improve that mistake of error.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmvgat,True,,Desperate_Complex483,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mmvgat/tip/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmvgat/tip/,66146,1617899080.0,0,,False,,,,,,,
,deeplearning,,t2_xmo60,False,,0,False,Trained StyleGAN2-Ada on Naruto characters and hooked it up to Lucid Sonic Dreams. Here is the trippy result.,[],r/deeplearning,False,6,,0,,False,t3_mmr381,False,dark,0.75,,public,4,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/NYBrQDKSAmE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Naruto Lucid Sonic Dreams (StyleGAN2 AI)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/NYBrQDKSAmE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Stochastic Machine', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/NYBrQDKSAmE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCWAQ2jS_jftqV65hLtxPfLA'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/NYBrQDKSAmE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mmr381', 'height': 200}",,False,4,,False,False,,False,,[],{},,False,,1617915084.0,text,6,,,text,youtube.com,False,,,,,https://youtube.com/watch?v=NYBrQDKSAmE&amp;feature=share,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmr381,True,,Ziinxx,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mmr381/trained_stylegan2ada_on_naruto_characters_and/,all_ads,False,https://youtube.com/watch?v=NYBrQDKSAmE&amp;feature=share,66146,1617886284.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Naruto Lucid Sonic Dreams (StyleGAN2 AI)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/NYBrQDKSAmE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Stochastic Machine', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/NYBrQDKSAmE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCWAQ2jS_jftqV65hLtxPfLA'}}",False,,,,,,,
,deeplearning,,t2_1wi1cv4l,False,,0,False,"Deep learning in Golang, has anybody used this?",[],r/deeplearning,False,6,,0,,False,t3_mmvg3g,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1617927863.0,text,6,,,text,gorgonia.org,False,,,,,https://gorgonia.org/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmvg3g,True,,ConfidentMushroom,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mmvg3g/deep_learning_in_golang_has_anybody_used_this/,all_ads,False,https://gorgonia.org/,66146,1617899063.0,0,,False,,,,,,,
,deeplearning,"I was reading this [paper](https://arxiv.org/pdf/1805.00932.pdf) put out by a group of researchers at Facebook where they found that using a softmax and CE loss function during  training led to improved results over sigmoid + BCE. During training they change the one-hot label vector such that each '1' is divided by the  number of labels for the given image (e.g. from \[0, 1, 1, 0\] to \[0, 0.5,  0.5, 0\]).

However, they do not mention how this could then be used in the  inference stage, because the required threshold for selecting the  correct labels is not clear and would theoretically need to be set based upon the expected number of labels for the image (which is information which wouldn't be available at inference).

Ha anyone else read this paper or have an idea how this would work?",t2_26couetb,False,,0,False,Anyone have experience using Softmax in multi-label classification,[],r/deeplearning,False,6,,0,,False,t3_mmmg5i,False,dark,0.79,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1617895508.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was reading this &lt;a href=""https://arxiv.org/pdf/1805.00932.pdf""&gt;paper&lt;/a&gt; put out by a group of researchers at Facebook where they found that using a softmax and CE loss function during  training led to improved results over sigmoid + BCE. During training they change the one-hot label vector such that each &amp;#39;1&amp;#39; is divided by the  number of labels for the given image (e.g. from [0, 1, 1, 0] to [0, 0.5,  0.5, 0]).&lt;/p&gt;

&lt;p&gt;However, they do not mention how this could then be used in the  inference stage, because the required threshold for selecting the  correct labels is not clear and would theoretically need to be set based upon the expected number of labels for the image (which is information which wouldn&amp;#39;t be available at inference).&lt;/p&gt;

&lt;p&gt;Ha anyone else read this paper or have an idea how this would work?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmmg5i,True,,StrasJam,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mmmg5i/anyone_have_experience_using_softmax_in/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmmg5i/anyone_have_experience_using_softmax_in/,66146,1617866708.0,0,,False,,,,,,,
,deeplearning,,t2_a8i2hluj,False,,0,False,"Get started with confusion matrix, know why it is named so, and when to use accuracy, recall, or precision: https://youtu.be/_y-peoToPj0",[],r/deeplearning,False,6,,0,,False,t3_mmtj7z,False,dark,0.33,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1617922421.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/ipzb7m2uqyr61.jpg,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmtj7z,True,,ahmed26gad,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mmtj7z/get_started_with_confusion_matrix_know_why_it_is/,all_ads,False,https://i.redd.it/ipzb7m2uqyr61.jpg,66146,1617893621.0,0,,False,,,,,,,
,deeplearning,"I am referring to [https://www.amazon.co.uk/Fundamentals-Deep-Learning-Next-Generation-Intelligence-ebook/dp/B0728KKXWB](https://www.amazon.co.uk/Fundamentals-Deep-Learning-Next-Generation-Intelligence-ebook/dp/B0728KKXWB/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;qid=1617891426&amp;sr=8-1)

Is this current.

Any real alternative around?

Thanks",t2_hypv0,False,,0,False,Is Fundamentals of Deep Learning current?,[],r/deeplearning,False,6,,0,,False,t3_mmsw4p,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617920569.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am referring to &lt;a href=""https://www.amazon.co.uk/Fundamentals-Deep-Learning-Next-Generation-Intelligence-ebook/dp/B0728KKXWB/ref=tmm_kin_swatch_0?_encoding=UTF8&amp;amp;qid=1617891426&amp;amp;sr=8-1""&gt;https://www.amazon.co.uk/Fundamentals-Deep-Learning-Next-Generation-Intelligence-ebook/dp/B0728KKXWB&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Is this current.&lt;/p&gt;

&lt;p&gt;Any real alternative around?&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmsw4p,True,,aspublic,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mmsw4p/is_fundamentals_of_deep_learning_current/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmsw4p/is_fundamentals_of_deep_learning_current/,66146,1617891769.0,0,,False,,,,,,,
,deeplearning,,t2_82tley41,False,,0,False,"A survey on ""Design Smells in Deep Learning Programs""",[],r/deeplearning,False,6,,0,,False,t3_mmsk44,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1617919610.0,text,6,,,text,self.deeplearning,False,,,,,/r/deeplearning/comments/mfqf4g/a_survey_on_design_smells_in_deep_learning/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmsk44,True,,aminnikanjam,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mmsk44/a_survey_on_design_smells_in_deep_learning/,all_ads,False,/r/deeplearning/comments/mfqf4g/a_survey_on_design_smells_in_deep_learning/,66146,1617890810.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'deeplearning', 'selftext': ' Our research group (SWAT Lab., Polytechnique Montréal under supervision of Prof. Foutse Khomh) is conducting a survey on “Design Smells in Deep Learning Programs”. We have prepared an online survey that takes around 5-10 minutes to complete asking about relevance and severity of observed design issues in DL programs. \n\nWe are looking for participants who have a strong background and experience in research/ development of Deep Learning programs (specially convolutional networks-CNNs). Please feel free to participate if you find yourself eligible. Moreover, you could kindly share this survey with colleagues/friends who you consider eligible to participate.\n\nThe results of this survey will be publicly accessible through arXiv.org in anonymized form. At no point in the survey will we ask you for your name, and we will not be logging your IP address to allow anonymity. If you would like to know more about this study, feel free to contact us with your questions.\n\nLink: [https://forms.gle/Yedpq3Dx8tAoxYkL8](https://forms.gle/Yedpq3Dx8tAoxYkL8)\n\nWe really appreciate your time and support!\n\nBest regards,\n\nAmin Nikanjam (amin.nikanjam@polymtl.ca),\n\nFoutse Khomh\n\nSWAT Lab., Polytechnique Montréal, Montréal, Canada, [http://swat.polymtl.ca/](http://swat.polymtl.ca/)', 'author_fullname': 't2_82tley41', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'A survey on ""Design Smells in Deep Learning Programs""', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/deeplearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mfqf4g', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.9, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 16, 'total_awards_received': 1, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 16, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1617055923.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.deeplearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Our research group (SWAT Lab., Polytechnique Montréal under supervision of Prof. Foutse Khomh) is conducting a survey on “Design Smells in Deep Learning Programs”. We have prepared an online survey that takes around 5-10 minutes to complete asking about relevance and severity of observed design issues in DL programs. &lt;/p&gt;\n\n&lt;p&gt;We are looking for participants who have a strong background and experience in research/ development of Deep Learning programs (specially convolutional networks-CNNs). Please feel free to participate if you find yourself eligible. Moreover, you could kindly share this survey with colleagues/friends who you consider eligible to participate.&lt;/p&gt;\n\n&lt;p&gt;The results of this survey will be publicly accessible through arXiv.org in anonymized form. At no point in the survey will we ask you for your name, and we will not be logging your IP address to allow anonymity. If you would like to know more about this study, feel free to contact us with your questions.&lt;/p&gt;\n\n&lt;p&gt;Link: &lt;a href=""https://forms.gle/Yedpq3Dx8tAoxYkL8""&gt;https://forms.gle/Yedpq3Dx8tAoxYkL8&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We really appreciate your time and support!&lt;/p&gt;\n\n&lt;p&gt;Best regards,&lt;/p&gt;\n\n&lt;p&gt;Amin Nikanjam (&lt;a href=""mailto:amin.nikanjam@polymtl.ca""&gt;amin.nikanjam@polymtl.ca&lt;/a&gt;),&lt;/p&gt;\n\n&lt;p&gt;Foutse Khomh&lt;/p&gt;\n\n&lt;p&gt;SWAT Lab., Polytechnique Montréal, Montréal, Canada, &lt;a href=""http://swat.polymtl.ca/""&gt;http://swat.polymtl.ca/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2t5eh', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mfqf4g', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'aminnikanjam', 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/deeplearning/comments/mfqf4g/a_survey_on_design_smells_in_deep_learning/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/deeplearning/comments/mfqf4g/a_survey_on_design_smells_in_deep_learning/', 'subreddit_subscribers': 66146, 'created_utc': 1617027123.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_mfqf4g,,,,,
,deeplearning,"Hello,

I  would like to apply an self-attention mechanism on a multichannel audio  spectrogram, so a 3D tensor. In the [original Transformer paper](https://arxiv.org/abs/1706.03762),  self-attention is applied on vector (embedded words) within a kind of  temporal sequence. On my multichannel spectrogram, I would like to apply  self-attention both on the temporal and frequency axes, so that the  analyzed vectors are ""through"" the channel axes.

On tensorflow.keras MultiHeadAttention layer, there is a *attention\_axes* parameter  which seems to be interested for my problem, because I could set it up  to something like (2,3) and hope attention will be applied on the wanted  dimensions. However I don't understand how it works since it's  different from the original Transformer paper, and I don't find any  relevant paper addressing self-attention in several dimensions in the  same manner.

Also the source code doesn't help me, the algorithm is split into several sub-modules which are not self-explanatory to me.

Any insights would be precious!

Thanks a lot",t2_1530mn,False,,0,False,"How does multi-head attention on ""multiple attention axes"" works ?",[],r/deeplearning,False,6,,0,,False,t3_mmmw1j,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,1617869011.0,,[],{},,True,,1617897554.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello,&lt;/p&gt;

&lt;p&gt;I  would like to apply an self-attention mechanism on a multichannel audio  spectrogram, so a 3D tensor. In the &lt;a href=""https://arxiv.org/abs/1706.03762""&gt;original Transformer paper&lt;/a&gt;,  self-attention is applied on vector (embedded words) within a kind of  temporal sequence. On my multichannel spectrogram, I would like to apply  self-attention both on the temporal and frequency axes, so that the  analyzed vectors are &amp;quot;through&amp;quot; the channel axes.&lt;/p&gt;

&lt;p&gt;On tensorflow.keras MultiHeadAttention layer, there is a &lt;em&gt;attention_axes&lt;/em&gt; parameter  which seems to be interested for my problem, because I could set it up  to something like (2,3) and hope attention will be applied on the wanted  dimensions. However I don&amp;#39;t understand how it works since it&amp;#39;s  different from the original Transformer paper, and I don&amp;#39;t find any  relevant paper addressing self-attention in several dimensions in the  same manner.&lt;/p&gt;

&lt;p&gt;Also the source code doesn&amp;#39;t help me, the algorithm is split into several sub-modules which are not self-explanatory to me.&lt;/p&gt;

&lt;p&gt;Any insights would be precious!&lt;/p&gt;

&lt;p&gt;Thanks a lot&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmmw1j,True,,peehay,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mmmw1j/how_does_multihead_attention_on_multiple/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmmw1j/how_does_multihead_attention_on_multiple/,66146,1617868754.0,0,,False,,,,,,,
,deeplearning,"in object detection where multiple objects are detected,

images have objects that appear frequently together.

like (soccer ball, shoes) 

or

(dog, frisbee), etc.

&amp;#x200B;

is there an academic name for this kind of bias?

I'm wondering how to deal with this kind of bias",t2_g7e0ajf,False,,0,False,is there a word for this kind of bias?,[],r/deeplearning,False,6,,0,,False,t3_mmmo5y,False,dark,1.0,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1617896541.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;in object detection where multiple objects are detected,&lt;/p&gt;

&lt;p&gt;images have objects that appear frequently together.&lt;/p&gt;

&lt;p&gt;like (soccer ball, shoes) &lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;(dog, frisbee), etc.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;is there an academic name for this kind of bias?&lt;/p&gt;

&lt;p&gt;I&amp;#39;m wondering how to deal with this kind of bias&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmmo5y,True,,chadrick-kwag,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mmmo5y/is_there_a_word_for_this_kind_of_bias/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmmo5y/is_there_a_word_for_this_kind_of_bias/,66146,1617867741.0,0,,False,,,,,,,
,deeplearning,"Here is a video explaining the idea of the normalizatoi free nets paper ""NF-Nets"" titled ""High-Performance Large-Scale Image Recognition Without Normalization"". Hope its useful: [https://youtu.be/AzKFgjrbR2o](https://youtu.be/AzKFgjrbR2o)",t2_5ikz6ji0,False,,0,False,Video explaining Normalization Free or NF-Nets paper,[],r/deeplearning,False,6,,0,,False,t3_mmrvcb,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617917541.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Here is a video explaining the idea of the normalizatoi free nets paper &amp;quot;NF-Nets&amp;quot; titled &amp;quot;High-Performance Large-Scale Image Recognition Without Normalization&amp;quot;. Hope its useful: &lt;a href=""https://youtu.be/AzKFgjrbR2o""&gt;https://youtu.be/AzKFgjrbR2o&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmrvcb,True,,Combination-Fun,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mmrvcb/video_explaining_normalization_free_or_nfnets/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmrvcb/video_explaining_normalization_free_or_nfnets/,66146,1617888741.0,0,,False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,The most important prepositions in Arabic!🤩,[],r/deeplearning,False,6,,0,,False,t3_mn2z3c,False,dark,0.22,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1617948939.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/r6xfz0bkx0s61.jpg,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mn2z3c,True,,Community-Of-Babel,,0,False,all_ads,False,[],False,,/r/deeplearning/comments/mn2z3c/the_most_important_prepositions_in_arabic/,all_ads,False,https://i.redd.it/r6xfz0bkx0s61.jpg,66146,1617920139.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'The most important prepositions in Arabic!🤩', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mn2yfr', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1617948886.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/r6xfz0bkx0s61.jpg', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mn2yfr', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/mn2yfr/the_most_important_prepositions_in_arabic/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://i.redd.it/r6xfz0bkx0s61.jpg', 'subreddit_subscribers': 0, 'created_utc': 1617920086.0, 'num_crossposts': 3, 'media': None, 'is_video': False}]",t3_mn2yfr,,,,,
,deeplearning,"Hi
Is a Variational autoencoder with only mean without log variance dimension is equivalent to a standard auroencoder ?
In other term is the latent space of an autoencoder is calibrated on the mean ?
Thanks",t2_57lwtxcm,False,,0,False,Vae and autoencoder,[],r/deeplearning,False,6,,0,,False,t3_mmmswx,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1617897157.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi
Is a Variational autoencoder with only mean without log variance dimension is equivalent to a standard auroencoder ?
In other term is the latent space of an autoencoder is calibrated on the mean ?
Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmmswx,True,,bacocololo,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mmmswx/vae_and_autoencoder/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmmswx/vae_and_autoencoder/,66146,1617868357.0,0,,False,,,,,,,
,deeplearning,"Making valid assumptions about the future is one of our biggest challenges nowadays. Besides various approaches in the past like recurrent structures or convolutional networks the transformer neural network is a rather recent algorithm specialized in analyzing and predicting sequences. The self-attention mechanism is one of transformer's central features. It comprises superior properties for sequence modeling and therefore solves several shortcomings detected in former algorithms. The transformer structure enjoys growing popularity for Natural Language Processing tasks or for timeseries predictions.

Just want to share a brief explanation video about it, i've been working intensively on this topic for the last 2 years, feel free to ask questions! Link: [https://www.youtube.com/watch?v=HcYKTsq4v0w](https://www.youtube.com/watch?v=HcYKTsq4v0w)",t2_adilo96a,False,,0,False,Transformer Neural Networks - Attention is all you need!!,[],r/deeplearning,False,6,,0,,False,t3_mmotnb,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617906453.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Making valid assumptions about the future is one of our biggest challenges nowadays. Besides various approaches in the past like recurrent structures or convolutional networks the transformer neural network is a rather recent algorithm specialized in analyzing and predicting sequences. The self-attention mechanism is one of transformer&amp;#39;s central features. It comprises superior properties for sequence modeling and therefore solves several shortcomings detected in former algorithms. The transformer structure enjoys growing popularity for Natural Language Processing tasks or for timeseries predictions.&lt;/p&gt;

&lt;p&gt;Just want to share a brief explanation video about it, i&amp;#39;ve been working intensively on this topic for the last 2 years, feel free to ask questions! Link: &lt;a href=""https://www.youtube.com/watch?v=HcYKTsq4v0w""&gt;https://www.youtube.com/watch?v=HcYKTsq4v0w&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmotnb,True,,OptimizationGeek,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mmotnb/transformer_neural_networks_attention_is_all_you/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmotnb/transformer_neural_networks_attention_is_all_you/,66146,1617877653.0,0,,False,,,,,,,
,deeplearning,"Baidu Brain, a Chinese core AI technology engine, announces the release of PaddlePaddle 2.0. PaddlePaddle (PArallel Distributed Deep LEarning)) is an open-sourced AI platform released by Baidu Brain in 2016 to apply deep learning(DL) to many products at Baidu, such as NLP (Natural Language Processing), translation, and image processing.

PaddlePaddle’s latest version has features like dynamic (computational) graphs, a new API system, distributed training for trillion-parameter models, and better hardware support.

Summary: [https://www.marktechpost.com/2021/04/07/baidu-releases-paddlepaddle-2-0-its-deep-learning-platform-with-new-features-including-dynamic-graphs-reorganized-apis/](https://www.marktechpost.com/2021/04/07/baidu-releases-paddlepaddle-2-0-its-deep-learning-platform-with-new-features-including-dynamic-graphs-reorganized-apis/) 

API Documentation: [https://www.paddlepaddle.org.cn/documentation/docs/en/api/index\_en.html](https://www.paddlepaddle.org.cn/documentation/docs/en/api/index_en.html) 

GitHub: [https://github.com/PaddlePaddle](https://github.com/PaddlePaddle) 

Gitee: [https://gitee.com/paddlepaddle](https://gitee.com/paddlepaddle)",t2_4wudjgid,False,,0,False,"Baidu Releases ‘PaddlePaddle’ 2.0, Its Deep Learning Platform, With New Features Including Dynamic Graphs, Reorganized APIs (Documentation, Github link included)",[],r/deeplearning,False,6,,0,,False,t3_mm571y,False,dark,0.93,,public,29,0,{},,False,[],,False,False,,{},,False,29,,False,False,,False,,[],{},,True,,1617839637.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Baidu Brain, a Chinese core AI technology engine, announces the release of PaddlePaddle 2.0. PaddlePaddle (PArallel Distributed Deep LEarning)) is an open-sourced AI platform released by Baidu Brain in 2016 to apply deep learning(DL) to many products at Baidu, such as NLP (Natural Language Processing), translation, and image processing.&lt;/p&gt;

&lt;p&gt;PaddlePaddle’s latest version has features like dynamic (computational) graphs, a new API system, distributed training for trillion-parameter models, and better hardware support.&lt;/p&gt;

&lt;p&gt;Summary: &lt;a href=""https://www.marktechpost.com/2021/04/07/baidu-releases-paddlepaddle-2-0-its-deep-learning-platform-with-new-features-including-dynamic-graphs-reorganized-apis/""&gt;https://www.marktechpost.com/2021/04/07/baidu-releases-paddlepaddle-2-0-its-deep-learning-platform-with-new-features-including-dynamic-graphs-reorganized-apis/&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;API Documentation: &lt;a href=""https://www.paddlepaddle.org.cn/documentation/docs/en/api/index_en.html""&gt;https://www.paddlepaddle.org.cn/documentation/docs/en/api/index_en.html&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;GitHub: &lt;a href=""https://github.com/PaddlePaddle""&gt;https://github.com/PaddlePaddle&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Gitee: &lt;a href=""https://gitee.com/paddlepaddle""&gt;https://gitee.com/paddlepaddle&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mm571y,True,,techsucker,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mm571y/baidu_releases_paddlepaddle_20_its_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mm571y/baidu_releases_paddlepaddle_20_its_deep_learning/,66146,1617810837.0,0,,False,,,,,,,
,deeplearning,"My AWS EC2 instance Ubuntu server is always showing killed on my Deep Learning model, what should I do here",t2_6bg8t97l,False,,0,False,My Deep Learning model showing killed on my Ubuntu server,[],r/deeplearning,False,6,,0,,False,t3_mmo6aw,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617903556.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My AWS EC2 instance Ubuntu server is always showing killed on my Deep Learning model, what should I do here&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmo6aw,True,,CulturalAfternoon306,,10,True,all_ads,False,[],False,,/r/deeplearning/comments/mmo6aw/my_deep_learning_model_showing_killed_on_my/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmo6aw/my_deep_learning_model_showing_killed_on_my/,66146,1617874756.0,0,,False,,,,,,,
,deeplearning,"I'm tackling a project where I am collecting the data (no relevant public dataset avail), where no labels are possible. Only manual labeling seems to be an option.

I've labeled somed myself but.. it is only a handful.

&amp;#x200B;

I was looking into active learning to somehow make annotations more effectively and continuously update the model performance.

&amp;#x200B;

But someone tells me in this case it would be better to look into zero/few shot learning and ditch with active learning since it is a dying field.

I active learning really dying out?

I think active learning and few shot learning can both somehow work together but hmm..

anyone tried two approaches and experienced that few shot works better than active learning?",t2_g7e0ajf,False,,0,False,is active learning a dying field?,[],r/deeplearning,False,6,,0,,False,t3_mmnsce,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617901704.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m tackling a project where I am collecting the data (no relevant public dataset avail), where no labels are possible. Only manual labeling seems to be an option.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve labeled somed myself but.. it is only a handful.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I was looking into active learning to somehow make annotations more effectively and continuously update the model performance.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;But someone tells me in this case it would be better to look into zero/few shot learning and ditch with active learning since it is a dying field.&lt;/p&gt;

&lt;p&gt;I active learning really dying out?&lt;/p&gt;

&lt;p&gt;I think active learning and few shot learning can both somehow work together but hmm..&lt;/p&gt;

&lt;p&gt;anyone tried two approaches and experienced that few shot works better than active learning?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmnsce,True,,chadrick-kwag,,16,True,all_ads,False,[],False,,/r/deeplearning/comments/mmnsce/is_active_learning_a_dying_field/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmnsce/is_active_learning_a_dying_field/,66146,1617872904.0,0,,False,,,,,,,
,deeplearning,,t2_hkv9s,False,,0,False,GlossBERT: BERT for Word Sense Disambiguation with Gloss Knowledge (Research Paper Walkthrough),[],r/deeplearning,False,6,,0,,False,t3_mmmp6z,False,dark,0.67,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/EMDax4OH_ps?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'GlossBERT: BERT for Word Sense Disambiguation with Gloss Knowledge (Research Paper Walkthrough)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/EMDax4OH_ps?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/EMDax4OH_ps/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/EMDax4OH_ps?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mmmp6z', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1617896683.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/EMDax4OH_ps,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmmp6z,True,,prakhar21,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mmmp6z/glossbert_bert_for_word_sense_disambiguation_with/,all_ads,False,https://youtu.be/EMDax4OH_ps,66146,1617867883.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'GlossBERT: BERT for Word Sense Disambiguation with Gloss Knowledge (Research Paper Walkthrough)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/EMDax4OH_ps?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/EMDax4OH_ps/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}}",False,,,,,,,
,deeplearning,"There will be speakers from major companies (Google, Microsoft, AWS, IBM, Uber, etc) as well as leading academic institutions (UC Berkeley, CMU)

Register now: [http://anyscale.com/ray-summit](http://anyscale.com/ray-summit)",t2_sswdj,False,,0,False,Free Scalable ML/DL and Python Conference (Ray Summit),[],r/deeplearning,False,6,,0,,False,t3_mmduvd,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1617863938.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;There will be speakers from major companies (Google, Microsoft, AWS, IBM, Uber, etc) as well as leading academic institutions (UC Berkeley, CMU)&lt;/p&gt;

&lt;p&gt;Register now: &lt;a href=""http://anyscale.com/ray-summit""&gt;http://anyscale.com/ray-summit&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mmduvd,True,,mgalarny,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mmduvd/free_scalable_mldl_and_python_conference_ray/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mmduvd/free_scalable_mldl_and_python_conference_ray/,66146,1617835138.0,0,,False,,,,,,,
,deeplearning,I have found many deep art programs which mix images together through online servers. Why are there no x86 standalone versions of these kinds of programs on SourceForge and GitHub? Don't the libraries run easily on an x86 PC?,t2_ix5yd3w,False,,0,False,Standalone VS networked Deep Art programs,[],r/deeplearning,False,6,,0,,False,t3_mm9r6l,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1617852151.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have found many deep art programs which mix images together through online servers. Why are there no x86 standalone versions of these kinds of programs on SourceForge and GitHub? Don&amp;#39;t the libraries run easily on an x86 PC?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mm9r6l,True,,MegavirusOfDoom,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mm9r6l/standalone_vs_networked_deep_art_programs/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mm9r6l/standalone_vs_networked_deep_art_programs/,66146,1617823351.0,0,,False,,,,,,,
,deeplearning,,t2_arb9m8cw,False,,0,False,Generating multi-instrumental piano music using tracker music,[],r/deeplearning,False,6,,0,,False,t3_mm5fn4,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1617840280.0,text,6,,,text,modmusicgen.com,False,,,,,https://modmusicgen.com/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mm5fn4,True,,bjourne-ml,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mm5fn4/generating_multiinstrumental_piano_music_using/,all_ads,False,https://modmusicgen.com/,66146,1617811480.0,0,,False,,,,,,,
,deeplearning,I have around 50k images to be annotated for segmentation task. Any idea on how to get it annotated?,t2_wf21e9r,False,,0,False,How to get image dataset annotated? Any idea?,[],r/deeplearning,False,6,,0,,False,t3_mm6wzg,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1617844354.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have around 50k images to be annotated for segmentation task. Any idea on how to get it annotated?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mm6wzg,True,,ayvin_tech,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mm6wzg/how_to_get_image_dataset_annotated_any_idea/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mm6wzg/how_to_get_image_dataset_annotated_any_idea/,66146,1617815554.0,0,,False,,,,,,,
,deeplearning,"I have been trying to read up about model optimization for runtime and have not stumbled upon some source which is very comprehensive and teaches with examples as well. 

There are some very useful examples on the pytorch website, but I was looking for something more comprehensive and with coding examples. Is there some MOOC around this topic or any other source or book. It would be incredibly helpful for me.",t2_lebv4,False,,0,False,Model Optimization - quantization and pruning,[],r/deeplearning,False,6,,0,,False,t3_mlxvoa,False,dark,0.89,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,1617788397.0,,[],{},,True,,1617814436.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been trying to read up about model optimization for runtime and have not stumbled upon some source which is very comprehensive and teaches with examples as well. &lt;/p&gt;

&lt;p&gt;There are some very useful examples on the pytorch website, but I was looking for something more comprehensive and with coding examples. Is there some MOOC around this topic or any other source or book. It would be incredibly helpful for me.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mlxvoa,True,,agupta12,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mlxvoa/model_optimization_quantization_and_pruning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mlxvoa/model_optimization_quantization_and_pruning/,66146,1617785636.0,0,,False,,,,,,,
,deeplearning,"Hi everybody,

In  the last few years, I spent a lot of time working on automate business processes of big companies and seeing rising interest in DU topic (especially in the Key Information Extraction field). Therefore, I  create a list [https://github.com/tstanislawek/awesome-document-understanding](https://github.com/tstanislawek/awesome-document-understanding) of resources to make easier to track all the papers out there which are relevant to this topic.",t2_2cmm0re0,False,,0,False,[P] Curated List of Document Understanding (DU) Papers &amp; Resources.,[],r/deeplearning,False,6,,0,,False,t3_mm6qhm,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1617815670.0,,[],{},,True,,1617843870.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everybody,&lt;/p&gt;

&lt;p&gt;In  the last few years, I spent a lot of time working on automate business processes of big companies and seeing rising interest in DU topic (especially in the Key Information Extraction field). Therefore, I  create a list &lt;a href=""https://github.com/tstanislawek/awesome-document-understanding""&gt;https://github.com/tstanislawek/awesome-document-understanding&lt;/a&gt; of resources to make easier to track all the papers out there which are relevant to this topic.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mm6qhm,True,,tstanislawek,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mm6qhm/p_curated_list_of_document_understanding_du/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mm6qhm/p_curated_list_of_document_understanding_du/,66146,1617815070.0,0,,False,,,,,,,
,deeplearning,"I'm about to bought a cheat nvidia k80 for my robotics protect and y need to train it and in order to do it I'm supposed to have a better computer than my laptop and the mathlab on cloud is not comfortable to me and the new graphics cards of nvidia are extremely expensive at the time,I need to know if it's a good idea to buy the k80 or if exist another option.",t2_7d0c8j7a,False,,0,False,"Is the nvidia k80 compatible whit the neural modules of mathlab for training a robot in simulink, I'm a student, don't be rough :')",[],r/deeplearning,False,6,,0,,False,t3_mm4ka4,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617837891.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m about to bought a cheat nvidia k80 for my robotics protect and y need to train it and in order to do it I&amp;#39;m supposed to have a better computer than my laptop and the mathlab on cloud is not comfortable to me and the new graphics cards of nvidia are extremely expensive at the time,I need to know if it&amp;#39;s a good idea to buy the k80 or if exist another option.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mm4ka4,True,,MR_QUBIT-04,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mm4ka4/is_the_nvidia_k80_compatible_whit_the_neural/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mm4ka4/is_the_nvidia_k80_compatible_whit_the_neural/,66146,1617809091.0,0,,False,,,,,,,
,deeplearning,,t2_66dqvlke,False,,0,False,Learning Controls through Structure for Generating Handwriting and Images - Link to free zoom lecture by the authors in comments,[],r/deeplearning,False,6,,0,,False,t3_mlxfts,False,dark,0.67,,public,2,0,{},,False,[],,True,False,,{},,False,2,,False,False,,False,,[],{},,False,,1617812278.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/ronsf7pcnpr61.png,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mlxfts,True,,dataskml,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mlxfts/learning_controls_through_structure_for/,all_ads,False,https://i.redd.it/ronsf7pcnpr61.png,66146,1617783478.0,0,,False,,,,,,,
,deeplearning,,t2_50i7d,False,,0,False,Exploring the future artificial intelligent architectures in a unique format between two spacecraft and with A.I expert Andrés Torrubia (spanish),[],r/deeplearning,False,6,,0,,False,t3_mm1ssu,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QP5JQk0szwg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Andrés Torrubia: del GPT-3 a la inteligencia artificial general  | Beyond by Javier Ideami (Spanish)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QP5JQk0szwg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Javier ideami', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/QP5JQk0szwg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/ideami'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QP5JQk0szwg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mm1ssu', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1617830069.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=QP5JQk0szwg,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mm1ssu,True,,javismiles,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mm1ssu/exploring_the_future_artificial_intelligent/,all_ads,False,https://www.youtube.com/watch?v=QP5JQk0szwg,66146,1617801269.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Andrés Torrubia: del GPT-3 a la inteligencia artificial general  | Beyond by Javier Ideami (Spanish)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QP5JQk0szwg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Javier ideami', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/QP5JQk0szwg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/ideami'}}",False,,,,,,,
,deeplearning,"Question 1: Is GAN related to machine learning or Deep Learning?
Question 2: I am unable to understand the term ""distribution of input variables"" using in DL,ML tutorials.",t2_1kg0azgm,False,,0,False,Distribution of input variables,[],r/deeplearning,False,6,,0,,False,t3_mlzpax,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617822639.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Question 1: Is GAN related to machine learning or Deep Learning?
Question 2: I am unable to understand the term &amp;quot;distribution of input variables&amp;quot; using in DL,ML tutorials.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mlzpax,True,,iqrarehman76,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mlzpax/distribution_of_input_variables/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mlzpax/distribution_of_input_variables/,66146,1617793839.0,0,,False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,Let's learn the names of some foods in Gulf Arabic!😍,[],r/deeplearning,False,6,,0,,False,t3_mm9z8u,False,dark,0.18,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1617852777.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/xgezodfmzsr61.jpg,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mm9z8u,True,,Community-Of-Babel,,1,False,all_ads,False,[],False,,/r/deeplearning/comments/mm9z8u/lets_learn_the_names_of_some_foods_in_gulf_arabic/,all_ads,False,https://i.redd.it/xgezodfmzsr61.jpg,66146,1617823977.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': ""Let's learn the names of some foods in Gulf Arabic!😍"", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mm9yis', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.66, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1617852723.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/xgezodfmzsr61.jpg', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mm9yis', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/mm9yis/lets_learn_the_names_of_some_foods_in_gulf_arabic/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://i.redd.it/xgezodfmzsr61.jpg', 'subreddit_subscribers': 0, 'created_utc': 1617823923.0, 'num_crossposts': 4, 'media': None, 'is_video': False}]",t3_mm9yis,,,,,
,deeplearning,"Given the increasing memory and storage requirements of modern machine learning and deep learning models, the topic of neural network compression is as prevalent as ever. One classic and popular method of reducing memory and computational costs is neural network pruning.

This article covers what pruning is, how it works, different pruning methods, and how to evaluate them.

Article link: [https://blog.paperspace.com/neural-network-pruning-explained/](https://blog.paperspace.com/neural-network-pruning-explained/)",t2_15en0l,False,,0,False,[Article] Neural Network Pruning Explained,[],r/deeplearning,False,6,,0,,False,t3_mldew6,False,dark,0.85,,public,24,0,{},,False,[],,False,False,,{},,False,24,,False,False,,False,,[],{},,True,,1617749481.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Given the increasing memory and storage requirements of modern machine learning and deep learning models, the topic of neural network compression is as prevalent as ever. One classic and popular method of reducing memory and computational costs is neural network pruning.&lt;/p&gt;

&lt;p&gt;This article covers what pruning is, how it works, different pruning methods, and how to evaluate them.&lt;/p&gt;

&lt;p&gt;Article link: &lt;a href=""https://blog.paperspace.com/neural-network-pruning-explained/""&gt;https://blog.paperspace.com/neural-network-pruning-explained/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mldew6,True,,hellopaperspace,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mldew6/article_neural_network_pruning_explained/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mldew6/article_neural_network_pruning_explained/,66146,1617720681.0,0,,False,,,,,,,
,deeplearning,,t2_9heuzjgb,False,,0,False,"[D] AI/ML Researcher/Engineers who were raised in developing countries and are currently working in developed countries or went back home, How can your AI/ML research and technical skills be used in the country you were raised in?",[],r/deeplearning,False,6,,0,,False,t3_mlht2t,False,dark,0.74,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,False,,1617761195.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/miberb/d_aiml_researcherengineers_who_were_raised_in/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mlht2t,True,,Difficult-You-3756,,1,False,all_ads,False,[],False,,/r/deeplearning/comments/mlht2t/d_aiml_researcherengineers_who_were_raised_in/,all_ads,False,/r/MachineLearning/comments/miberb/d_aiml_researcherengineers_who_were_raised_in/,66146,1617732395.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '[deleted]', 'user_reports': [], 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[D] AI/ML Researcher/Engineers who were raised in developing countries and are currently working in developed countries or went back home, How can your AI/ML research and technical skills be used in the country you were raised in?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'one', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_miberb', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.92, 'author_flair_background_color': '', 'subreddit_type': 'public', 'ups': 99, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 99, 'approved_by': None, 'is_created_from_ads_ui': False, 'thumbnail': '', 'edited': 1617332465.0, 'author_flair_css_class': None, 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1617361003.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': 'deleted', 'banned_by': None, 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'miberb', 'is_robot_indexable': False, 'stickied': False, 'author': '[deleted]', 'discussion_type': None, 'num_comments': 49, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_flair_text_color': 'dark', 'permalink': '/r/MachineLearning/comments/miberb/d_aiml_researcherengineers_who_were_raised_in/', 'parent_whitelist_status': 'all_ads', 'report_reasons': None, 'url': 'https://www.reddit.com/r/MachineLearning/comments/miberb/d_aiml_researcherengineers_who_were_raised_in/', 'subreddit_subscribers': 1931405, 'created_utc': 1617332203.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_miberb,,,,,
,deeplearning,"I want to recognize characters from a blurred or cut-out (some characters are visible and some are blurred or cut-out for example ""MA 1008"" in this image 100 is clearly visible but 8 is blurred or cut-out). How i achieve this in deep learning.",t2_7rmi111c,False,,0,False,Recognize Character from Blurred Images,[],r/deeplearning,False,6,,0,,False,t3_mlupkm,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617800500.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to recognize characters from a blurred or cut-out (some characters are visible and some are blurred or cut-out for example &amp;quot;MA 1008&amp;quot; in this image 100 is clearly visible but 8 is blurred or cut-out). How i achieve this in deep learning.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mlupkm,True,,ali-nawaz14,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mlupkm/recognize_character_from_blurred_images/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mlupkm/recognize_character_from_blurred_images/,66146,1617771700.0,0,,False,,,,,,,
,deeplearning,"Hi there,

I want to extract some specific information from invoices, like the date, amount and vendor name.

I already have written an OCR pipeline, that helps me to extract the text from an invoice and bounding boxes for every word.  
But how do I go from there?

My goal is to have my own neural network, that I can train and use for my uses. So far I found CUTIE and a lot other approaches, that use regex to solve the problem (regex is not an option for my usecase).

Thanks upfront for your suggestions!",t2_bahljozv,False,,0,False,Extract informations from invoices with machine learning,[],r/deeplearning,False,6,,0,,False,t3_mlkw9y,False,dark,0.68,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1617769580.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi there,&lt;/p&gt;

&lt;p&gt;I want to extract some specific information from invoices, like the date, amount and vendor name.&lt;/p&gt;

&lt;p&gt;I already have written an OCR pipeline, that helps me to extract the text from an invoice and bounding boxes for every word.&lt;br/&gt;
But how do I go from there?&lt;/p&gt;

&lt;p&gt;My goal is to have my own neural network, that I can train and use for my uses. So far I found CUTIE and a lot other approaches, that use regex to solve the problem (regex is not an option for my usecase).&lt;/p&gt;

&lt;p&gt;Thanks upfront for your suggestions!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mlkw9y,True,,TurboWelder,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/mlkw9y/extract_informations_from_invoices_with_machine/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mlkw9y/extract_informations_from_invoices_with_machine/,66146,1617740780.0,0,,False,,,,,,,
,deeplearning,"Join us on April 13th at 11 am ET to hear about Grid.ai and PyTorch Lightning's latest innovations with our CEO and Founder William Falcon and Thomas Chaton, Research Engineering Manager. This discussion is excellent for AI researchers, machine learning engineers, and data scientists looking for new ways to accelerate and improve their current AI model training process. Leave with tangible strategies, new tools, and great ideas.

Register now and submit any questions you have for William and Thomas!  
[https://zoom.us/webinar/register/1016176774118/WN\_yW66h71HSz-MXWNGAu6OOg](https://zoom.us/webinar/register/1016176774118/WN_yW66h71HSz-MXWNGAu6OOg)",t2_b7wyqo3d,False,,0,False,Latest Innovations with Grid.ai and PyTorch Lightning,[],r/deeplearning,False,6,,0,,False,t3_mloka0,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617779629.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Join us on April 13th at 11 am ET to hear about Grid.ai and PyTorch Lightning&amp;#39;s latest innovations with our CEO and Founder William Falcon and Thomas Chaton, Research Engineering Manager. This discussion is excellent for AI researchers, machine learning engineers, and data scientists looking for new ways to accelerate and improve their current AI model training process. Leave with tangible strategies, new tools, and great ideas.&lt;/p&gt;

&lt;p&gt;Register now and submit any questions you have for William and Thomas!&lt;br/&gt;
&lt;a href=""https://zoom.us/webinar/register/1016176774118/WN_yW66h71HSz-MXWNGAu6OOg""&gt;https://zoom.us/webinar/register/1016176774118/WN_yW66h71HSz-MXWNGAu6OOg&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mloka0,True,,Grid_AI,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mloka0/latest_innovations_with_gridai_and_pytorch/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mloka0/latest_innovations_with_gridai_and_pytorch/,66146,1617750829.0,0,,False,,,,,,,
,deeplearning,,t2_1568ks,False,,0,False,Adversarial machine learning: The underrated threat of data poisoning,[],r/deeplearning,False,6,,0,,False,t3_mlgb9i,False,dark,0.71,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1617757188.0,text,6,,,text,bdtechtalks.com,False,,,,,https://bdtechtalks.com/2021/04/05/machine-learning-data-poisoning-2/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mlgb9i,True,,bendee983,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mlgb9i/adversarial_machine_learning_the_underrated/,all_ads,False,https://bdtechtalks.com/2021/04/05/machine-learning-data-poisoning-2/,66146,1617728388.0,0,,False,,,,,,,
,deeplearning,"Hi, I have a dataset of 8M rows with 7 numerical features (hearing test audiogram data) and was tasked with predicting 4 variables based on 3. This is how the provided dataset looks like (used fake numbers). Does anyone know what model/approach is the best? I'm thinking Neural Network given the size.. but also have never used multiple independent AND dependent variables before... Any and all pointers are appreciated!! 

&amp;#x200B;

https://preview.redd.it/v1ok5tlaplr61.png?width=781&amp;format=png&amp;auto=webp&amp;s=3955dd1ad2f7d8de6cbc67070835e0c7d3fcd1c5",t2_4okx2lwr,False,,0,False,Predicting Four Variables Using Three Variables,[],r/deeplearning,False,6,,0,,False,t3_mlj1fu,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617764505.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I have a dataset of 8M rows with 7 numerical features (hearing test audiogram data) and was tasked with predicting 4 variables based on 3. This is how the provided dataset looks like (used fake numbers). Does anyone know what model/approach is the best? I&amp;#39;m thinking Neural Network given the size.. but also have never used multiple independent AND dependent variables before... Any and all pointers are appreciated!! &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/v1ok5tlaplr61.png?width=781&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3955dd1ad2f7d8de6cbc67070835e0c7d3fcd1c5""&gt;https://preview.redd.it/v1ok5tlaplr61.png?width=781&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3955dd1ad2f7d8de6cbc67070835e0c7d3fcd1c5&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mlj1fu,True,,lalopark,,13,True,all_ads,False,[],False,,/r/deeplearning/comments/mlj1fu/predicting_four_variables_using_three_variables/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mlj1fu/predicting_four_variables_using_three_variables/,66146,1617735705.0,0,,False,,,"{'v1ok5tlaplr61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 13, 'x': 108, 'u': 'https://preview.redd.it/v1ok5tlaplr61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=29f83f59c07e267c14ffe366b040e2a5d1a84f29'}, {'y': 26, 'x': 216, 'u': 'https://preview.redd.it/v1ok5tlaplr61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=63ff96da3ae1686abf2340e332d3b5b01bd738d9'}, {'y': 39, 'x': 320, 'u': 'https://preview.redd.it/v1ok5tlaplr61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f77308e95a610a0c1cf6c5de7a0dfc55b33b6ccf'}, {'y': 79, 'x': 640, 'u': 'https://preview.redd.it/v1ok5tlaplr61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=495eab9da5775eae34dfa8e059651acbdc7fd071'}], 's': {'y': 97, 'x': 781, 'u': 'https://preview.redd.it/v1ok5tlaplr61.png?width=781&amp;format=png&amp;auto=webp&amp;s=3955dd1ad2f7d8de6cbc67070835e0c7d3fcd1c5'}, 'id': 'v1ok5tlaplr61'}}",,,,
,deeplearning,,t2_4mpathim,False,,0,False,BikiniGAN!!,[],r/deeplearning,False,6,,0,,False,t3_mkr0nh,False,dark,0.8,,public,94,0,{},,False,[],,True,False,,{},,False,94,,False,False,,False,,[],{},,False,,1617675152.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/arowv28e5er61,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mkr0nh,True,,willowill5,,13,True,all_ads,False,[],False,,/r/deeplearning/comments/mkr0nh/bikinigan/,all_ads,False,https://v.redd.it/arowv28e5er61,66146,1617646352.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'NFT', 'selftext': '[deleted]', 'user_reports': [], 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'My AI-Generated Model NFT', 'link_flair_richtext': [{'e': 'text', 't': 'NFT'}], 'subreddit_name_prefixed': 'r/NFT', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mkq90f', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.65, 'author_flair_background_color': '', 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': True, 'secure_media': {'reddit_video': {'bitrate_kbps': 1200, 'fallback_url': 'https://v.redd.it/arowv28e5er61/DASH_480.mp4?source=fallback', 'height': 480, 'width': 480, 'scrubber_media_url': 'https://v.redd.it/arowv28e5er61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/arowv28e5er61/DASHPlaylist.mpd?a=1626450633%2CZGYxY2ZmM2ZkODhhY2RiYTAwZTcyYTYyZTQ1YWU2OTRiMzUxMzUzZjVkNTMxZWFlZGI3ZWQyYzE4Mzk0YzZiZQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 23, 'hls_url': 'https://v.redd.it/arowv28e5er61/HLSPlaylist.m3u8?a=1626450633%2CZTM4NDMxMTg5MmVjYjU0MmJmNjJiMzEyYTJkMGI5MDVmNmVkMWI4MDNmYTE5OGI0MTc4MmY3MGJkOGJmYTUwMQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'NFT', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1617673114.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': 'deleted', 'banned_by': None, 'domain': 'v.redd.it', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://v.redd.it/arowv28e5er61', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '0a4855d6-797a-11eb-a13e-0edc94fc7501', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3bx7j', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ffb000', 'id': 'mkq90f', 'is_robot_indexable': False, 'report_reasons': None, 'author': '[deleted]', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_flair_text_color': 'dark', 'permalink': '/r/NFT/comments/mkq90f/my_aigenerated_model_nft/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://v.redd.it/arowv28e5er61', 'subreddit_subscribers': 85704, 'created_utc': 1617644314.0, 'num_crossposts': 2, 'media': {'reddit_video': {'bitrate_kbps': 1200, 'fallback_url': 'https://v.redd.it/arowv28e5er61/DASH_480.mp4?source=fallback', 'height': 480, 'width': 480, 'scrubber_media_url': 'https://v.redd.it/arowv28e5er61/DASH_96.mp4', 'dash_url': 'https://v.redd.it/arowv28e5er61/DASHPlaylist.mpd?a=1626450633%2CZGYxY2ZmM2ZkODhhY2RiYTAwZTcyYTYyZTQ1YWU2OTRiMzUxMzUzZjVkNTMxZWFlZGI3ZWQyYzE4Mzk0YzZiZQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 23, 'hls_url': 'https://v.redd.it/arowv28e5er61/HLSPlaylist.m3u8?a=1626450633%2CZTM4NDMxMTg5MmVjYjU0MmJmNjJiMzEyYTJkMGI5MDVmNmVkMWI4MDNmYTE5OGI0MTc4MmY3MGJkOGJmYTUwMQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}, 'is_video': True}]",t3_mkq90f,,,,,
,deeplearning,"The paper that started the whole NeRF hype train last year:

The authors use a sparse set of views of a scene from different angles and positions in combination with a differentiable rendering engine to optimize a multi-layer perceptron (one per scene) that predicts the color and density of points in the scene from their coordinate and a viewing direction. Once trained, the model can render the  learned scene from an arbitrary viewpoint in space with incredible level of detail and occlusion effects.  More details [here](https://t.me/casual_gan/22).  


https://reddit.com/link/mlfyvy/video/z3jie5f02lr61/player

P.S. In case you are not familiar with the paper check it out [here](https://t.me/casual_gan/22):",t2_hhio3,False,,0,False,[R] NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis - Explained,[],r/deeplearning,False,6,,0,,False,t3_mlfyvy,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1617727873.0,,[],{},,True,,1617756251.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The paper that started the whole NeRF hype train last year:&lt;/p&gt;

&lt;p&gt;The authors use a sparse set of views of a scene from different angles and positions in combination with a differentiable rendering engine to optimize a multi-layer perceptron (one per scene) that predicts the color and density of points in the scene from their coordinate and a viewing direction. Once trained, the model can render the  learned scene from an arbitrary viewpoint in space with incredible level of detail and occlusion effects.  More details &lt;a href=""https://t.me/casual_gan/22""&gt;here&lt;/a&gt;.  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://reddit.com/link/mlfyvy/video/z3jie5f02lr61/player""&gt;https://reddit.com/link/mlfyvy/video/z3jie5f02lr61/player&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;P.S. In case you are not familiar with the paper check it out &lt;a href=""https://t.me/casual_gan/22""&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mlfyvy,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mlfyvy/r_nerf_representing_scenes_as_neural_radiance/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mlfyvy/r_nerf_representing_scenes_as_neural_radiance/,66146,1617727451.0,0,,False,,,"{'z3jie5f02lr61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/mlfyvy/asset/z3jie5f02lr61/DASHPlaylist.mpd?a=1626450633%2CYzcwODBlMjM5NDk5ZTFlY2I4MTc5YzQxNjFlOWJmZmI2MGU0ZDc5MjA0ZTU1MmM2MDVlNzNkZGEyYmYwOGEwNw%3D%3D&amp;v=1&amp;f=sd', 'x': 1280, 'y': 489, 'hlsUrl': 'https://v.redd.it/link/mlfyvy/asset/z3jie5f02lr61/HLSPlaylist.m3u8?a=1626450633%2CMjA5OGJkZWJmM2Y3MDc0OTc3NDI3NmM0ZGM2ZjY3YjI5NDAzMDY4YWNiODY5MzI5NjdhNjdiNGNiYzNlMjNmMw%3D%3D&amp;v=1&amp;f=sd', 'id': 'z3jie5f02lr61', 'isGif': False}}",,,,
,deeplearning,"Ever wondered how robots navigate autonomously, grasp different objects or avoid collisions while moving? Using stereo vision-based depth estimation is a standard method for such applications.  


In this post, we discuss classical methods for stereo matching and depth perception. We explain depth perception using a stereo camera and OpenCV. We have also shared the code in Python and C++ for hands-on learning!  


[https://learnopencv.com/depth-perception-using-stereo-camera-python-c/](https://learnopencv.com/depth-perception-using-stereo-camera-python-c/)

https://preview.redd.it/gpy5562s9jr61.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=ea865977076e9636bba6191eab46168b70248e5c",t2_cvc9f,False,,0,False,Depth perception using stereo camera (Python/C++),[],r/deeplearning,False,6,,0,,False,t3_ml8wed,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617735091.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Ever wondered how robots navigate autonomously, grasp different objects or avoid collisions while moving? Using stereo vision-based depth estimation is a standard method for such applications.  &lt;/p&gt;

&lt;p&gt;In this post, we discuss classical methods for stereo matching and depth perception. We explain depth perception using a stereo camera and OpenCV. We have also shared the code in Python and C++ for hands-on learning!  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://learnopencv.com/depth-perception-using-stereo-camera-python-c/""&gt;https://learnopencv.com/depth-perception-using-stereo-camera-python-c/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/gpy5562s9jr61.jpg?width=600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ea865977076e9636bba6191eab46168b70248e5c""&gt;https://preview.redd.it/gpy5562s9jr61.jpg?width=600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=ea865977076e9636bba6191eab46168b70248e5c&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ml8wed,True,,spmallick,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ml8wed/depth_perception_using_stereo_camera_pythonc/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ml8wed/depth_perception_using_stereo_camera_pythonc/,66146,1617706291.0,0,,False,,,"{'gpy5562s9jr61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 72, 'x': 108, 'u': 'https://preview.redd.it/gpy5562s9jr61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fec6cfc03332bc92ddc2f25c2a091330c78589ab'}, {'y': 144, 'x': 216, 'u': 'https://preview.redd.it/gpy5562s9jr61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6d5b9e74fec58549d1dd45e4827c1358dccd6ec6'}, {'y': 213, 'x': 320, 'u': 'https://preview.redd.it/gpy5562s9jr61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=36196d4f186b3280e19c48f5f446315db35ff6f1'}], 's': {'y': 400, 'x': 600, 'u': 'https://preview.redd.it/gpy5562s9jr61.jpg?width=600&amp;format=pjpg&amp;auto=webp&amp;s=ea865977076e9636bba6191eab46168b70248e5c'}, 'id': 'gpy5562s9jr61'}}",,,,
,deeplearning,"Hello all,
Has anyone faced the issue of reproducing the same results for independent trials using TF?

I have already used all the tricks mentioned in stack overflow like setting seeds for numpy and TF and python hash seed. I even used shuffle as false between the epochs. Still the results are not consistent.

However training the model using a CPU and tricks above can give same results. It is only that gpu operations are non deterministic. I understand one can do averaging over multiple trials. However the standard deviation of accuracy over the multiple trials is around 2% which is feel is quite high.

This problem is more of an issue when we try to compare models and data augmentation strategies.

Has anyone faced such issues? How did you deal with it?",t2_196qpvtw,False,,0,False,Reproducible result in TF 2,[],r/deeplearning,False,6,,0,,False,t3_ml5nkm,False,dark,0.5,,public,0,1,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617720732.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello all,
Has anyone faced the issue of reproducing the same results for independent trials using TF?&lt;/p&gt;

&lt;p&gt;I have already used all the tricks mentioned in stack overflow like setting seeds for numpy and TF and python hash seed. I even used shuffle as false between the epochs. Still the results are not consistent.&lt;/p&gt;

&lt;p&gt;However training the model using a CPU and tricks above can give same results. It is only that gpu operations are non deterministic. I understand one can do averaging over multiple trials. However the standard deviation of accuracy over the multiple trials is around 2% which is feel is quite high.&lt;/p&gt;

&lt;p&gt;This problem is more of an issue when we try to compare models and data augmentation strategies.&lt;/p&gt;

&lt;p&gt;Has anyone faced such issues? How did you deal with it?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ml5nkm,True,,federerking,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ml5nkm/reproducible_result_in_tf_2/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ml5nkm/reproducible_result_in_tf_2/,66146,1617691932.0,0,,False,,,,,,,
,deeplearning,"Hi, so up until now, while training new models in CV, I would select parameters that were mentioned in papers, and 98% of the time the model would converge well.

Now that I am using grid search, that too on a heavy model like GAT, how do I decide the essential parameters like layers and attention heads? How do I decide the values of other parameters like feature dropout, attention dropout?

What's the right way to identify the hyperparameters for large models?

So, I am using random initialization of node embeddings for graph classification.",t2_4xhrybaz,False,,0,False,How to select the right number of layers and heads for GAT models?,[],r/deeplearning,False,6,,0,,False,t3_mkwqd1,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1617690637.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, so up until now, while training new models in CV, I would select parameters that were mentioned in papers, and 98% of the time the model would converge well.&lt;/p&gt;

&lt;p&gt;Now that I am using grid search, that too on a heavy model like GAT, how do I decide the essential parameters like layers and attention heads? How do I decide the values of other parameters like feature dropout, attention dropout?&lt;/p&gt;

&lt;p&gt;What&amp;#39;s the right way to identify the hyperparameters for large models?&lt;/p&gt;

&lt;p&gt;So, I am using random initialization of node embeddings for graph classification.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mkwqd1,True,,banenvy,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mkwqd1/how_to_select_the_right_number_of_layers_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mkwqd1/how_to_select_the_right_number_of_layers_and/,66146,1617661837.0,0,,False,,,,,,,
,deeplearning,"i currently try to build a deeplearing app using javafx as gui and python for training and testing a CNN model. but i dont know what to do ?, how to combine java and python as one, can javafx call python for using train model or just python as gui too. i need help. (sry for my english)",t2_14mb56,False,,0,False,should i use java as gui or use just use python as gui and training and testing model,[],r/deeplearning,False,6,,0,,False,t3_mku4vv,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,1617654896.0,,[],{},,True,,1617683464.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;i currently try to build a deeplearing app using javafx as gui and python for training and testing a CNN model. but i dont know what to do ?, how to combine java and python as one, can javafx call python for using train model or just python as gui too. i need help. (sry for my english)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mku4vv,True,,zidane1298,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mku4vv/should_i_use_java_as_gui_or_use_just_use_python/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mku4vv/should_i_use_java_as_gui_or_use_just_use_python/,66146,1617654664.0,0,,False,,,,,,,
,deeplearning,Tips to help you boost your DL model accuracy [DL performance cheat sheet](https://www.educateai.org/deep-learning-performance-cheat-sheet/?fbclid=IwAR3sEsEE4P5q-oEGCsAemywjYpHZs89SjPJeVD-UFI6bgx7JGS1G1HHVRcw),t2_33ikrfmw,False,,0,False,[D] Deep Learning Performance Cheat Sheet,[],r/deeplearning,False,6,,0,,False,t3_mkd9lg,False,dark,0.88,,public,33,0,{},,False,[],,False,False,,{},,False,33,,False,False,,False,,[],{},,True,,1617628338.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Tips to help you boost your DL model accuracy &lt;a href=""https://www.educateai.org/deep-learning-performance-cheat-sheet/?fbclid=IwAR3sEsEE4P5q-oEGCsAemywjYpHZs89SjPJeVD-UFI6bgx7JGS1G1HHVRcw""&gt;DL performance cheat sheet&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mkd9lg,True,,cdossman,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mkd9lg/d_deep_learning_performance_cheat_sheet/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mkd9lg/d_deep_learning_performance_cheat_sheet/,66146,1617599538.0,0,,False,,,,,,,
,deeplearning,,t2_dacoq,False,,0,False,The Annotated TabNet,[],r/deeplearning,False,6,,0,,False,t3_mkwh3o,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1617689904.0,text,6,,,text,sachinruk.github.io,False,,,,,https://sachinruk.github.io/blog/tensorflow/2021/04/05/Tabnet_From_Scratch.html,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mkwh3o,True,,themathstudent,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mkwh3o/the_annotated_tabnet/,all_ads,False,https://sachinruk.github.io/blog/tensorflow/2021/04/05/Tabnet_From_Scratch.html,66146,1617661104.0,0,,False,,,,,,,
,deeplearning,,t2_2o7eaff,False,,0,False,Machine Learning with ML.NET - Object detection with YOLO,[],r/deeplearning,False,6,,0,,False,t3_mktnpp,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1617682163.0,text,6,,,text,rubikscode.net,False,,,,,https://rubikscode.net/2021/04/05/machine-learning-with-ml-net-object-detection-with-yolo/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mktnpp,True,,RubiksCodeNMZ,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mktnpp/machine_learning_with_mlnet_object_detection_with/,all_ads,False,https://rubikscode.net/2021/04/05/machine-learning-with-ml-net-object-detection-with-yolo/,66146,1617653363.0,0,,False,,,,,,,
,deeplearning,"I was reading about the [Fast RCNN](https://arxiv.org/abs/1504.08083) for object detection. From what I understand, it uses pre-computed ROI's (using selective search) and uses these to predict the bounding box offsets and uses smooth L1 loss to refine these and get closer to the ground truth boxes.

The paper states the following about the ROI's

\`\`\`

While training, R / N (ROI's) for each image (N=2,R=128) are taken where N are the images per mini batch. Among the ROI's chosen, around 25% of them are taken that have IOU more than 0.5 (foreground) and the remaining (called background) that have IOU between 0.1 and 0.5.

\`\`\`

My question here is, are these ROI's similar to bounding boxes and if not, in what way are they different?

Any help would be appreciated. Thanks!",t2_7n4roggm,False,,0,False,What is the difference between ROI and bounding box?,[],r/deeplearning,False,6,,0,,False,t3_mkgsoh,False,dark,0.88,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1617644222.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I was reading about the &lt;a href=""https://arxiv.org/abs/1504.08083""&gt;Fast RCNN&lt;/a&gt; for object detection. From what I understand, it uses pre-computed ROI&amp;#39;s (using selective search) and uses these to predict the bounding box offsets and uses smooth L1 loss to refine these and get closer to the ground truth boxes.&lt;/p&gt;

&lt;p&gt;The paper states the following about the ROI&amp;#39;s&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;While training, R / N (ROI&amp;#39;s) for each image (N=2,R=128) are taken where N are the images per mini batch. Among the ROI&amp;#39;s chosen, around 25% of them are taken that have IOU more than 0.5 (foreground) and the remaining (called background) that have IOU between 0.1 and 0.5.&lt;/p&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;My question here is, are these ROI&amp;#39;s similar to bounding boxes and if not, in what way are they different?&lt;/p&gt;

&lt;p&gt;Any help would be appreciated. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mkgsoh,True,,Public-Drag1602,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mkgsoh/what_is_the_difference_between_roi_and_bounding/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mkgsoh/what_is_the_difference_between_roi_and_bounding/,66146,1617615422.0,0,,False,,,,,,,
,deeplearning,"I am using TensorFlow version: 2.3.0 and Python3. I am experimenting in Quantizing a pruned and trained Conv-2 CNN model. The model architecture is: conv -&gt; conv -&gt; max pool -&gt; dense -&gt; dense -&gt; output for CIFAR-10. You can see the Jupyter-notebook [here](https://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/blob/master/Conv2_Quantization_Experiments.ipynb).

The pruned and trained model is stored in the variable ""pruned\_model"". Steps used for quantization are as follows:

        # Save the entire pruned and saved model-
        pruned_model.save(""Conv2_Pruned"")
        
        # Dynamic range quantization-
        converter = tf.lite.TFLiteConverter.from_saved_model(""Conv2_Pruned"")
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        tflite_quant_model = converter.convert()
        
        
        def representative_data_gen():
            # for inp_val, _ in test_dataset.take(1):
            for inp_val, _ in test_dataset.batch(1).take(100):
                # Model has only one input so each data point has one element.
                yield [inp_val]
        
        
        import pathlib
        
        # Quantization  using integer with float fallback-
        converter = tf.lite.TFLiteConverter.from_saved_model(""Conv2_Pruned"")
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        converter.representative_dataset = representative_data_gen
        
        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
        
        # DON'T USE THE FOLLOWING 2 LINES-
        # converter.inference_input_type = tf.int8  # or tf.uint8
        # converter.inference_output_type = tf.int8  # or tf.uint8
        
        tflite_quant_model = converter.convert()

&amp;#x200B;

This last line gives the following error:

&gt;**---------------------------------------------------------------------------** **RuntimeError**                              Traceback (most recent call last) **&lt;ipython-input-38-c58f3e8dc480&gt;** in &lt;module&gt;      14 **# converter.inference\_output\_type = tf.int8  # or tf.uint8**      15 **---&gt; 16** tflite\_quant\_model **=** converter\*\*.**convert**()\*\* **\~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py** in convert\*\*(self)\*\*    1074         Invalid quantization parameters\*\*.\*\*    1075     """""" **-&gt; 1076** **return** super\*\*(**TFLiteConverterV2**,\*\* self\*\*).**convert**()\*\*    1077    1078 **\~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py** in convert\*\*(self)\*\*     897           graph=frozen\_func.graph)     898 **--&gt; 899     return super(TFLiteFrozenGraphConverterV2,**     900                  self).convert(graph\_def, input\_tensors, output\_tensors)     901 **\~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py** in convert\*\*(self, graph\_def, input\_tensors, output\_tensors)\*\*     636         self.inference\_input\_type, self.inference\_output\_type)     637 **if** calibrate\_and\_quantize\*\*:\*\* **--&gt; 638** result **=** self\*\*.**\_calibrate\_quantize\_model**(**result**,\*\* **\*\*flags)**     639     640 **if** self\*\*.**\_experimental\_sparsify\_model**:\*\* **\~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py** in \_calibrate\_quantize\_model\*\*(self, result, inference\_input\_type, inference\_output\_type, activations\_type, allow\_float)\*\*     448 **return** \_mlir\_quantize\*\*(**calibrated**)\*\*     449 **else:** **--&gt; 450       return calibrate\_quantize.calibrate\_and\_quantize(**     451           self\*\*.**representative\_dataset**.**input\_gen**,\*\* inference\_input\_type\*\*,\*\*     452           inference\_output\_type, allow\_float, activations\_type)  **\~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\lite\\python\\optimize\\calibrator.py** in calibrate\_and\_quantize\*\*(self, dataset\_gen, input\_type, output\_type, allow\_float, activations\_type, resize\_input)\*\*      89         initialized **=** **True**      90 **if** resize\_input\*\*:\*\* **---&gt; 91** self\*\*.**\_calibrator**.**Prepare**(\[**list**(**s**.**shape**)\*\* **for** s **in** sample\*\*\])\*\*      92 **else:**      93           self\*\*.**\_calibrator**.**Prepare**()\*\* **RuntimeError**: tensorflow/lite/kernels/conv.cc:313 input-&gt;dims-&gt;size != 4 (5 != 4)Node number 0 (CONV\_2D) failed to prepare.

&amp;#x200B;

I first experimented with LeNet-300-100 using MNIST and this error wasn't existing for it.

&amp;#x200B;

Help?",t2_2mmql89p,False,,0,False,TensorFlow Lite: RuntimeError,[],r/deeplearning,False,6,,0,,False,t3_mkqnz9,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617674243.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am using TensorFlow version: 2.3.0 and Python3. I am experimenting in Quantizing a pruned and trained Conv-2 CNN model. The model architecture is: conv -&amp;gt; conv -&amp;gt; max pool -&amp;gt; dense -&amp;gt; dense -&amp;gt; output for CIFAR-10. You can see the Jupyter-notebook &lt;a href=""https://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/blob/master/Conv2_Quantization_Experiments.ipynb""&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The pruned and trained model is stored in the variable &amp;quot;pruned_model&amp;quot;. Steps used for quantization are as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    # Save the entire pruned and saved model-
    pruned_model.save(&amp;quot;Conv2_Pruned&amp;quot;)

    # Dynamic range quantization-
    converter = tf.lite.TFLiteConverter.from_saved_model(&amp;quot;Conv2_Pruned&amp;quot;)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]

    tflite_quant_model = converter.convert()


    def representative_data_gen():
        # for inp_val, _ in test_dataset.take(1):
        for inp_val, _ in test_dataset.batch(1).take(100):
            # Model has only one input so each data point has one element.
            yield [inp_val]


    import pathlib

    # Quantization  using integer with float fallback-
    converter = tf.lite.TFLiteConverter.from_saved_model(&amp;quot;Conv2_Pruned&amp;quot;)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = representative_data_gen

    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

    # DON&amp;#39;T USE THE FOLLOWING 2 LINES-
    # converter.inference_input_type = tf.int8  # or tf.uint8
    # converter.inference_output_type = tf.int8  # or tf.uint8

    tflite_quant_model = converter.convert()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;This last line gives the following error:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;---------------------------------------------------------------------------&lt;/strong&gt; &lt;strong&gt;RuntimeError&lt;/strong&gt;                              Traceback (most recent call last) &lt;strong&gt;&amp;lt;ipython-input-38-c58f3e8dc480&amp;gt;&lt;/strong&gt; in &amp;lt;module&amp;gt;      14 &lt;strong&gt;# converter.inference_output_type = tf.int8  # or tf.uint8&lt;/strong&gt;      15 &lt;strong&gt;---&amp;gt; 16&lt;/strong&gt; tflite_quant_model &lt;strong&gt;=&lt;/strong&gt; converter**.&lt;strong&gt;convert&lt;/strong&gt;()** &lt;strong&gt;~\anaconda3\envs\tf\lib\site-packages\tensorflow\lite\python\lite.py&lt;/strong&gt; in convert**(self)**    1074         Invalid quantization parameters**.**    1075     &amp;quot;&amp;quot;&amp;quot; &lt;strong&gt;-&amp;gt; 1076&lt;/strong&gt; &lt;strong&gt;return&lt;/strong&gt; super**(&lt;strong&gt;TFLiteConverterV2&lt;/strong&gt;,** self**).&lt;strong&gt;convert&lt;/strong&gt;()**    1077    1078 &lt;strong&gt;~\anaconda3\envs\tf\lib\site-packages\tensorflow\lite\python\lite.py&lt;/strong&gt; in convert**(self)**     897           graph=frozen_func.graph)     898 &lt;strong&gt;--&amp;gt; 899     return super(TFLiteFrozenGraphConverterV2,&lt;/strong&gt;     900                  self).convert(graph_def, input_tensors, output_tensors)     901 &lt;strong&gt;~\anaconda3\envs\tf\lib\site-packages\tensorflow\lite\python\lite.py&lt;/strong&gt; in convert**(self, graph_def, input_tensors, output_tensors)**     636         self.inference_input_type, self.inference_output_type)     637 &lt;strong&gt;if&lt;/strong&gt; calibrate_and_quantize**:** &lt;strong&gt;--&amp;gt; 638&lt;/strong&gt; result &lt;strong&gt;=&lt;/strong&gt; self**.&lt;strong&gt;_calibrate_quantize_model&lt;/strong&gt;(&lt;strong&gt;result&lt;/strong&gt;,** &lt;strong&gt;**flags)&lt;/strong&gt;     639     640 &lt;strong&gt;if&lt;/strong&gt; self**.&lt;strong&gt;_experimental_sparsify_model&lt;/strong&gt;:** &lt;strong&gt;~\anaconda3\envs\tf\lib\site-packages\tensorflow\lite\python\lite.py&lt;/strong&gt; in _calibrate_quantize_model**(self, result, inference_input_type, inference_output_type, activations_type, allow_float)**     448 &lt;strong&gt;return&lt;/strong&gt; _mlir_quantize**(&lt;strong&gt;calibrated&lt;/strong&gt;)**     449 &lt;strong&gt;else:&lt;/strong&gt; &lt;strong&gt;--&amp;gt; 450       return calibrate_quantize.calibrate_and_quantize(&lt;/strong&gt;     451           self**.&lt;strong&gt;representative_dataset&lt;/strong&gt;.&lt;strong&gt;input_gen&lt;/strong&gt;,** inference_input_type**,**     452           inference_output_type, allow_float, activations_type)  &lt;strong&gt;~\anaconda3\envs\tf\lib\site-packages\tensorflow\lite\python\optimize\calibrator.py&lt;/strong&gt; in calibrate_and_quantize**(self, dataset_gen, input_type, output_type, allow_float, activations_type, resize_input)**      89         initialized &lt;strong&gt;=&lt;/strong&gt; &lt;strong&gt;True&lt;/strong&gt;      90 &lt;strong&gt;if&lt;/strong&gt; resize_input**:** &lt;strong&gt;---&amp;gt; 91&lt;/strong&gt; self**.&lt;strong&gt;_calibrator&lt;/strong&gt;.&lt;strong&gt;Prepare&lt;/strong&gt;([&lt;strong&gt;list&lt;/strong&gt;(&lt;strong&gt;s&lt;/strong&gt;.&lt;strong&gt;shape&lt;/strong&gt;)** &lt;strong&gt;for&lt;/strong&gt; s &lt;strong&gt;in&lt;/strong&gt; sample**])**      92 &lt;strong&gt;else:&lt;/strong&gt;      93           self**.&lt;strong&gt;_calibrator&lt;/strong&gt;.&lt;strong&gt;Prepare&lt;/strong&gt;()** &lt;strong&gt;RuntimeError&lt;/strong&gt;: tensorflow/lite/kernels/conv.cc:313 input-&amp;gt;dims-&amp;gt;size != 4 (5 != 4)Node number 0 (CONV_2D) failed to prepare.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I first experimented with LeNet-300-100 using MNIST and this error wasn&amp;#39;t existing for it.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Help?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mkqnz9,True,,grid_world,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mkqnz9/tensorflow_lite_runtimeerror/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mkqnz9/tensorflow_lite_runtimeerror/,66146,1617645443.0,0,,False,,,,,,,
,deeplearning,"We’ve been seeing a surge in the requests for Fuzzy Matching/Logic techniques. We tried to learn more about these techniques and the implementation process and have written about it. We have also covered some complex scenarios and their solution.  


Here’s a detailed view on the concept, its utility, and the implementation: [https://nanonets.com/blog/fuzzy-matching-fuzzy-logic/](https://nanonets.com/blog/fuzzy-matching-fuzzy-logic/)  


Can anyone share their experience on implementing Fuzzy Matching in their product or solution?",t2_13ggwo57,False,,0,False,"Fuzzy Matching/Logic - Concept, Utility, Implementation, and Complex Scenarios",[],r/deeplearning,False,6,,0,,False,t3_mkgpc8,False,dark,0.84,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1617643811.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We’ve been seeing a surge in the requests for Fuzzy Matching/Logic techniques. We tried to learn more about these techniques and the implementation process and have written about it. We have also covered some complex scenarios and their solution.  &lt;/p&gt;

&lt;p&gt;Here’s a detailed view on the concept, its utility, and the implementation: &lt;a href=""https://nanonets.com/blog/fuzzy-matching-fuzzy-logic/""&gt;https://nanonets.com/blog/fuzzy-matching-fuzzy-logic/&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;Can anyone share their experience on implementing Fuzzy Matching in their product or solution?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mkgpc8,True,,nanonets,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mkgpc8/fuzzy_matchinglogic_concept_utility/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mkgpc8/fuzzy_matchinglogic_concept_utility/,66146,1617615011.0,0,,False,,,,,,,
,deeplearning,"Hi, 

I've searched this info but could only find discussions in forums from 2019 or 2020 prior to the new AMD releases last year (november, december 2020).  From what I found in those previous post, it seems that Intel has more compatibility with the general deep learning toolkit. Has that changed? Does AMD have more compatibility now? Which option is better? 

Thanks in advance",t2_70olr5va,False,,0,False,AMD or Intel for a deep learning PC build?,[],r/deeplearning,False,6,,0,,False,t3_mkla53,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617659779.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve searched this info but could only find discussions in forums from 2019 or 2020 prior to the new AMD releases last year (november, december 2020).  From what I found in those previous post, it seems that Intel has more compatibility with the general deep learning toolkit. Has that changed? Does AMD have more compatibility now? Which option is better? &lt;/p&gt;

&lt;p&gt;Thanks in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mkla53,True,,MisterInfluence,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mkla53/amd_or_intel_for_a_deep_learning_pc_build/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mkla53/amd_or_intel_for_a_deep_learning_pc_build/,66146,1617630979.0,0,,False,,,,,,,
,deeplearning,which deep learning techniques apply to recognize characters from bounding box of license plate no,t2_7rmi111c,False,,0,False,Character Recognition from license plate,[],r/deeplearning,False,6,,0,,False,t3_mkj6t0,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617653428.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;which deep learning techniques apply to recognize characters from bounding box of license plate no&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mkj6t0,True,,ali-nawaz14,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mkj6t0/character_recognition_from_license_plate/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mkj6t0/character_recognition_from_license_plate/,66146,1617624628.0,0,,False,,,,,,,
,deeplearning,"Which can also be extended to flowers, fruits and other plant features or animals

Thanks in advance

\-Newbiee",t2_4sc4zlvc,False,,0,False,Which algorithm suits leaf segmentation well for detection and identification?,[],r/deeplearning,False,6,,0,,False,t3_mkhjrq,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617647463.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Which can also be extended to flowers, fruits and other plant features or animals&lt;/p&gt;

&lt;p&gt;Thanks in advance&lt;/p&gt;

&lt;p&gt;-Newbiee&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mkhjrq,True,,AeroManny,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mkhjrq/which_algorithm_suits_leaf_segmentation_well_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mkhjrq/which_algorithm_suits_leaf_segmentation_well_for/,66146,1617618663.0,0,,False,,,,,,,
,deeplearning,,t2_52xen1nv,False,,0,False,"Formal Reasoning, Program Synthesis: automated mathematical formalization and exploration as a first step toward AGI | Machine Learning Street Talk | Christian Szegedy",[],r/deeplearning,False,6,,0,,False,t3_mjy95t,False,dark,0.9,,public,25,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/ehNGGYFO6ms?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': '#50 Christian Szegedy - Formal Reasoning, Program Synthesis', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/ehNGGYFO6ms?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Machine Learning Street Talk', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/ehNGGYFO6ms/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/MachineLearningStreetTalk'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/ehNGGYFO6ms?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mjy95t', 'height': 200}",,False,25,,False,False,,False,,[],{},,False,,1617578565.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=ehNGGYFO6ms,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mjy95t,True,,pentin0,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mjy95t/formal_reasoning_program_synthesis_automated/,all_ads,False,https://www.youtube.com/watch?v=ehNGGYFO6ms,66146,1617549765.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': '#50 Christian Szegedy - Formal Reasoning, Program Synthesis', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/ehNGGYFO6ms?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Machine Learning Street Talk', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/ehNGGYFO6ms/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/MachineLearningStreetTalk'}}",False,"[{'approved_at_utc': None, 'subreddit': 'agi', 'selftext': '', 'author_fullname': 't2_52xen1nv', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Formal Reasoning, Program Synthesis: automated mathematical formalization and exploration as a first step toward AGI | Machine Learning Street Talk | Christian Szegedy', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/agi', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mjy3jv', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.96, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 21, 'total_awards_received': 1, 'media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/ehNGGYFO6ms?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': '#50 Christian Szegedy - Formal Reasoning, Program Synthesis', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/ehNGGYFO6ms?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Machine Learning Street Talk', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/ehNGGYFO6ms/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/MachineLearningStreetTalk'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/ehNGGYFO6ms?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mjy3jv', 'height': 200}, 'link_flair_text': None, 'can_mod_post': False, 'score': 21, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {'gid_1': 1}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1617578067.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtube.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.youtube.com/watch?v=ehNGGYFO6ms', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2qh8n', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mjy3jv', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'pentin0', 'discussion_type': None, 'num_comments': 13, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/agi/comments/mjy3jv/formal_reasoning_program_synthesis_automated/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.youtube.com/watch?v=ehNGGYFO6ms', 'subreddit_subscribers': 11191, 'created_utc': 1617549267.0, 'num_crossposts': 6, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': '#50 Christian Szegedy - Formal Reasoning, Program Synthesis', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/ehNGGYFO6ms?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Machine Learning Street Talk', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/ehNGGYFO6ms/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/MachineLearningStreetTalk'}}, 'is_video': False}]",t3_mjy3jv,,,,,
,deeplearning,,t2_akengm24,False,,0,False,Passive voice in Egyptian Arabic dialect 🤩💫,[],r/deeplearning,False,6,,0,,False,t3_mkmvob,False,dark,0.17,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/qQ6fkBNwF8s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Learn Egyptian Arabic: Passive voice in Egyptian dialect', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/qQ6fkBNwF8s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/qQ6fkBNwF8s/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/qQ6fkBNwF8s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mkmvob', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1617664141.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/qQ6fkBNwF8s,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mkmvob,True,,Community-Of-Babel,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mkmvob/passive_voice_in_egyptian_arabic_dialect/,all_ads,False,https://youtu.be/qQ6fkBNwF8s,66146,1617635341.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Learn Egyptian Arabic: Passive voice in Egyptian dialect', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/qQ6fkBNwF8s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/qQ6fkBNwF8s/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}",False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Passive voice in Egyptian Arabic dialect 🤩💫', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mkh4x6', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 1, 'total_awards_received': 0, 'media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/qQ6fkBNwF8s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Learn Egyptian Arabic: Passive voice in Egyptian dialect', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/qQ6fkBNwF8s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/qQ6fkBNwF8s/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/qQ6fkBNwF8s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mkh4x6', 'height': 200}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1617645700.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtu.be', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://youtu.be/qQ6fkBNwF8s', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mkh4x6', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/mkh4x6/passive_voice_in_egyptian_arabic_dialect/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://youtu.be/qQ6fkBNwF8s', 'subreddit_subscribers': 0, 'created_utc': 1617616900.0, 'num_crossposts': 3, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Learn Egyptian Arabic: Passive voice in Egyptian dialect', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/qQ6fkBNwF8s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/qQ6fkBNwF8s/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}, 'is_video': False}]",t3_mkh4x6,,,,,
,deeplearning,,t2_108tfg,False,,0,False,3 Tips on getting a career in Machine Learning,[],r/deeplearning,False,6,,0,,False,t3_mk348h,False,dark,0.61,,public,4,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/kBu-F5MhzLE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Top 3 Tips for getting a career in Machine Learning', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/kBu-F5MhzLE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Melkey Dev', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/kBu-F5MhzLE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC1Zfv1Zrp1q5lKgBomzOyCA'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/kBu-F5MhzLE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mk348h', 'height': 200}",,False,4,,False,False,,False,,[],{},,False,,1617593663.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=kBu-F5MhzLE&amp;ab_channel=MelkeyDev,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mk348h,True,,Smoksyakov,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mk348h/3_tips_on_getting_a_career_in_machine_learning/,all_ads,False,https://www.youtube.com/watch?v=kBu-F5MhzLE&amp;ab_channel=MelkeyDev,66146,1617564863.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Top 3 Tips for getting a career in Machine Learning', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/kBu-F5MhzLE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Melkey Dev', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/kBu-F5MhzLE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UC1Zfv1Zrp1q5lKgBomzOyCA'}}",False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,EfficientNet v2: Smaller Models and Faster Training - paper explained!,[],r/deeplearning,False,6,,0,,False,t3_mjz9xi,False,dark,0.73,,public,5,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/CTsSrOKSPNo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'EfficientNetV2 - Smaller Models and Faster Training | Paper explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/CTsSrOKSPNo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/CTsSrOKSPNo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/CTsSrOKSPNo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mjz9xi', 'height': 200}",,False,5,,False,False,,False,,[],{},,False,,1617581758.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/CTsSrOKSPNo,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mjz9xi,True,,gordicaleksa,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mjz9xi/efficientnet_v2_smaller_models_and_faster/,all_ads,False,https://youtu.be/CTsSrOKSPNo,66146,1617552958.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'EfficientNetV2 - Smaller Models and Faster Training | Paper explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/CTsSrOKSPNo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/CTsSrOKSPNo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,,t2_9z9f4416,False,,0,False,black dog,[],r/deeplearning,False,6,,0,,False,t3_mk5cx1,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/Uh5Hp4sReqM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'black dog', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/Uh5Hp4sReqM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'pretty deep', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Uh5Hp4sReqM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCgRo1xJkdCmsrPaYJTWlv9g'}}",False,False,,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/Uh5Hp4sReqM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mk5cx1', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1617600643.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/Uh5Hp4sReqM,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mk5cx1,True,,prettydeepvideos,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mk5cx1/black_dog/,all_ads,False,https://youtu.be/Uh5Hp4sReqM,66146,1617571843.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'black dog', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/Uh5Hp4sReqM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'pretty deep', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Uh5Hp4sReqM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCgRo1xJkdCmsrPaYJTWlv9g'}}",False,,,,,,,
,deeplearning,,t2_5dfei77h,False,,0,False,Shit post regarding computer vision,[],r/deeplearning,False,6,,0,,False,t3_mjvg7l,False,dark,0.43,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/7N8Ht3hfsrg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Deep Learning Paradise  Introduction Video', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/7N8Ht3hfsrg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Deep Learning Paradise', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/7N8Ht3hfsrg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCO3JnTEkx7AhgJgLMH8Mh9Q'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/7N8Ht3hfsrg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mjvg7l', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1617568600.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=7N8Ht3hfsrg,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mjvg7l,True,,nagang,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mjvg7l/shit_post_regarding_computer_vision/,all_ads,False,https://www.youtube.com/watch?v=7N8Ht3hfsrg,66146,1617539800.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Deep Learning Paradise  Introduction Video', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/7N8Ht3hfsrg?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Deep Learning Paradise', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/7N8Ht3hfsrg/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCO3JnTEkx7AhgJgLMH8Mh9Q'}}",False,,,,,,,
,deeplearning,,t2_9z9f4416,False,,0,False,kashmir,[],r/deeplearning,False,6,,0,,False,t3_mjnd4v,False,dark,0.69,,public,6,0,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/5JzdTBU-yaY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'kashmir', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/5JzdTBU-yaY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'pretty deep', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/5JzdTBU-yaY/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCgRo1xJkdCmsrPaYJTWlv9g'}}",False,False,,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/5JzdTBU-yaY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mjnd4v', 'height': 200}",,False,6,,False,False,,False,,[],{},,False,,1617533174.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/5JzdTBU-yaY,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mjnd4v,True,,prettydeepvideos,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mjnd4v/kashmir/,all_ads,False,https://youtu.be/5JzdTBU-yaY,66146,1617504374.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'kashmir', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/5JzdTBU-yaY?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'pretty deep', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/5JzdTBU-yaY/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCgRo1xJkdCmsrPaYJTWlv9g'}}",False,,,,,,,
,deeplearning,,t2_tpult,False,,0,False,"Metrics for edge detection: ODS, OIS, etc?",[],r/deeplearning,False,6,,0,,False,t3_mjok7o,False,dark,1.0,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,False,,1617537623.0,text,6,,,text,self.computervision,False,,,,,/r/computervision/comments/mjojdu/metrics_for_edge_detection_ods_ois_etc/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mjok7o,True,,74throwaway,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mjok7o/metrics_for_edge_detection_ods_ois_etc/,all_ads,False,/r/computervision/comments/mjojdu/metrics_for_edge_detection_ods_ois_etc/,66146,1617508823.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'computervision', 'selftext': ""I'm looking for metrics to evaluate the results from an edge detector model I ran. I did some google searching and found that some metrics used are ODS and OIS. But I couldn't find anywhere how to calculate these and source code to calculate them if you have ground truth and predicted images. Can anyone help?"", 'author_fullname': 't2_tpult', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Metrics for edge detection: ODS, OIS, etc?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/computervision', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mjojdu', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help: Theory ', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1617537552.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.computervision', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking for metrics to evaluate the results from an edge detector model I ran. I did some google searching and found that some metrics used are ODS and OIS. But I couldn&amp;#39;t find anywhere how to calculate these and source code to calculate them if you have ground truth and predicted images. Can anyone help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '1bd4ce18-850c-11eb-8be8-0e5f6c846c6d', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2rfzn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#fdff85', 'id': 'mjojdu', 'is_robot_indexable': True, 'report_reasons': None, 'author': '74throwaway', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/computervision/comments/mjojdu/metrics_for_edge_detection_ods_ois_etc/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/computervision/comments/mjojdu/metrics_for_edge_detection_ods_ois_etc/', 'subreddit_subscribers': 48824, 'created_utc': 1617508752.0, 'num_crossposts': 3, 'media': None, 'is_video': False}]",t3_mjojdu,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,Will Transformers Replace CNNs in Computer Vision?,[],r/deeplearning,False,6,,0,,False,t3_mj9cn5,False,dark,0.88,,public,46,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QcCJJOLCeJQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Will Transformers Replace CNNs in Computer Vision? + NVIDIA GTC Giveaway', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QcCJJOLCeJQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/QcCJJOLCeJQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QcCJJOLCeJQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mj9cn5', 'height': 200}",,False,46,,False,False,,False,,[],{},,False,,1617488212.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/QcCJJOLCeJQ,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mj9cn5,True,,OnlyProggingForFun,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mj9cn5/will_transformers_replace_cnns_in_computer_vision/,all_ads,False,https://youtu.be/QcCJJOLCeJQ,66146,1617459412.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Will Transformers Replace CNNs in Computer Vision? + NVIDIA GTC Giveaway', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/QcCJJOLCeJQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/QcCJJOLCeJQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg'}}",False,,,,,,,
,deeplearning,"I’m at a very fortunate crossroad, one that I need help navigating. I’m pretty new to training models and I’ve come to realize that, the full grasp and expertise of deep learning isn’t going to happen overnight. In the mean time however I would like to know what to do with all my computational gpu power and how to best utilize, i have the capabilities to run massive data sets and possibilities are endless. Sadly the data set in my head seems to be the bottleneck as I don’t know how to properly and efficiently utilize this power until I’m ready to handle enterprise level models myself. Any input is helpful thanks!",t2_bbckrkis,False,,0,False,GPU computational power overload,[],r/deeplearning,False,6,,0,,False,t3_mjgztv,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617511834.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m at a very fortunate crossroad, one that I need help navigating. I’m pretty new to training models and I’ve come to realize that, the full grasp and expertise of deep learning isn’t going to happen overnight. In the mean time however I would like to know what to do with all my computational gpu power and how to best utilize, i have the capabilities to run massive data sets and possibilities are endless. Sadly the data set in my head seems to be the bottleneck as I don’t know how to properly and efficiently utilize this power until I’m ready to handle enterprise level models myself. Any input is helpful thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mjgztv,True,,invicta777,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/mjgztv/gpu_computational_power_overload/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mjgztv/gpu_computational_power_overload/,66146,1617483034.0,0,,False,,,,,,,
,deeplearning,"This article is a **comprehensive guide** to the backpropagation algorithm, the most widely used algorithm for training artificial neural networks. 

We’ll start by defining forward and backward passes in the process of training neural networks, and then we’ll focus on how backpropagation works in the backward pass. We’ll work on detailed mathematical calculations of the backpropagation algorithm. 

Also, we’ll discuss how to implement a backpropagation neural network in Python from scratch using NumPy, based on this [GitHub project](https://github.com/ahmedfgad/IntroDLPython). The project builds a generic backpropagation neural network that can work with any architecture.

[https://neptune.ai/blog/backpropagation-algorithm-in-neural-networks-guide](https://neptune.ai/blog/backpropagation-algorithm-in-neural-networks-guide)",t2_a8i2hluj,False,,0,False,A Comprehensive Guide to the Backpropagation Algorithm in Neural Networks,[],r/deeplearning,False,6,,0,,False,t3_miyrm3,False,dark,0.88,,public,27,1,{},,False,[],,False,False,,{},,False,27,,False,False,,False,,[],{'gid_1': 1},,True,,1617443085.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This article is a &lt;strong&gt;comprehensive guide&lt;/strong&gt; to the backpropagation algorithm, the most widely used algorithm for training artificial neural networks. &lt;/p&gt;

&lt;p&gt;We’ll start by defining forward and backward passes in the process of training neural networks, and then we’ll focus on how backpropagation works in the backward pass. We’ll work on detailed mathematical calculations of the backpropagation algorithm. &lt;/p&gt;

&lt;p&gt;Also, we’ll discuss how to implement a backpropagation neural network in Python from scratch using NumPy, based on this &lt;a href=""https://github.com/ahmedfgad/IntroDLPython""&gt;GitHub project&lt;/a&gt;. The project builds a generic backpropagation neural network that can work with any architecture.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://neptune.ai/blog/backpropagation-algorithm-in-neural-networks-guide""&gt;https://neptune.ai/blog/backpropagation-algorithm-in-neural-networks-guide&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,miyrm3,True,,ahmed26gad,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/miyrm3/a_comprehensive_guide_to_the_backpropagation/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/miyrm3/a_comprehensive_guide_to_the_backpropagation/,66146,1617414285.0,0,,False,,,,,,,
,deeplearning,,t2_3r02kqm0,False,,0,False,The Pianist AI: What it is and how it is done!,[],r/deeplearning,False,6,,0,,False,t3_mjfc6f,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1617506679.0,text,6,,,text,pianistai.com,False,,,,,https://pianistai.com/about/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mjfc6f,True,,amin_mlm,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mjfc6f/the_pianist_ai_what_it_is_and_how_it_is_done/,all_ads,False,https://pianistai.com/about/,66146,1617477879.0,0,,False,,,,,,,
,deeplearning,I don't know much about GANs. But can they be applied to augment data pertaining to object detection problem? Object detection data having multiple classes in one image. Is this possible? Are there any resources I should take a look at?,t2_3q4w2o4,False,,0,False,Augmenting object detection dataset using GANs,[],r/deeplearning,False,6,,0,,False,t3_mj2r9r,False,dark,0.75,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1617459028.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I don&amp;#39;t know much about GANs. But can they be applied to augment data pertaining to object detection problem? Object detection data having multiple classes in one image. Is this possible? Are there any resources I should take a look at?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mj2r9r,True,,hp2304,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mj2r9r/augmenting_object_detection_dataset_using_gans/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mj2r9r/augmenting_object_detection_dataset_using_gans/,66146,1617430228.0,0,,False,,,,,,,
,deeplearning,"This idea is so elegant, yet powerful:  
The authors use the recent CLIP model in a loss function to train a mapping network that takes text descriptions of image edits (e.g. ""a man with long hair"", ""Beyonce"", ""A woman without makeup"") and an image encoded in the latent space of a pretrained StyleGAN generator and predicts an offset vector that transforms the input image according to the text description of the edit.   


More details [here](https://t.me/casual_gan/18).   


https://preview.redd.it/pg961l0pesq61.png?width=1438&amp;format=png&amp;auto=webp&amp;s=02227552bbf20b7bf612299a9560eda4617ceb8a",t2_hhio3,False,,0,False,StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery (SOTA StyleGAN image editing) EXPLAINED,[],r/deeplearning,False,6,,0,,False,t3_minvz9,False,dark,0.95,,public,30,0,{},,False,[],,False,False,,{},,False,30,,False,False,,False,,[],{},,True,,1617409848.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This idea is so elegant, yet powerful:&lt;br/&gt;
The authors use the recent CLIP model in a loss function to train a mapping network that takes text descriptions of image edits (e.g. &amp;quot;a man with long hair&amp;quot;, &amp;quot;Beyonce&amp;quot;, &amp;quot;A woman without makeup&amp;quot;) and an image encoded in the latent space of a pretrained StyleGAN generator and predicts an offset vector that transforms the input image according to the text description of the edit.   &lt;/p&gt;

&lt;p&gt;More details &lt;a href=""https://t.me/casual_gan/18""&gt;here&lt;/a&gt;.   &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/pg961l0pesq61.png?width=1438&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=02227552bbf20b7bf612299a9560eda4617ceb8a""&gt;https://preview.redd.it/pg961l0pesq61.png?width=1438&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=02227552bbf20b7bf612299a9560eda4617ceb8a&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,minvz9,True,,KirillTheMunchKing,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/minvz9/styleclip_textdriven_manipulation_of_stylegan/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/minvz9/styleclip_textdriven_manipulation_of_stylegan/,66146,1617381048.0,0,,False,,,"{'pg961l0pesq61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 38, 'x': 108, 'u': 'https://preview.redd.it/pg961l0pesq61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a00874c84ea16904c5b3f4aeaf5b752a67b5e71f'}, {'y': 77, 'x': 216, 'u': 'https://preview.redd.it/pg961l0pesq61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=28645a44cee38c0e0b06c929d728d6a3777d0260'}, {'y': 115, 'x': 320, 'u': 'https://preview.redd.it/pg961l0pesq61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2090365ba5bab574e56c3355882d2ec5c6f18753'}, {'y': 230, 'x': 640, 'u': 'https://preview.redd.it/pg961l0pesq61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=512b8ec9caac193fe5f516473498cc23b02b13aa'}, {'y': 345, 'x': 960, 'u': 'https://preview.redd.it/pg961l0pesq61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8431ac2e4472c7132acf2651f367664ec386c757'}, {'y': 388, 'x': 1080, 'u': 'https://preview.redd.it/pg961l0pesq61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5d405fed14a893d19238b4cd44f4bf4b1e95cd89'}], 's': {'y': 517, 'x': 1438, 'u': 'https://preview.redd.it/pg961l0pesq61.png?width=1438&amp;format=png&amp;auto=webp&amp;s=02227552bbf20b7bf612299a9560eda4617ceb8a'}, 'id': 'pg961l0pesq61'}}",,,,
,deeplearning,,t2_17cr0z,False,,0,False,Worth watching it. Funny and impressive way to run a training experiment.,[],r/deeplearning,False,6,,0,,False,t3_miwagw,False,dark,0.81,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,False,,1617434390.0,text,6,,,text,tom7.org,False,,,,,http://tom7.org/lowercase/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,miwagw,True,,gammaSquared,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/miwagw/worth_watching_it_funny_and_impressive_way_to_run/,all_ads,False,http://tom7.org/lowercase/,66146,1617405590.0,0,,False,,,,,,,
,deeplearning,"In this course I will teach you 6 different live trading bots including:

· A Bitcoin Reddit Sentiment Analysis Trading Bot

· A Doge Reddit Sentiment Analysis Trading Bot with Technical Indicators

· A Bitcoin Twitter Sentiment Analysis Trading Bot using state of the art Natural Language Processing Algorithm (BERT) where we create our own dataset with Bullish/Bearish labels and use it live

· A Gold Twitter Sentiment Analysis Trading Bot where we web scrape CNN’s Fear &amp; Greed Index and implement it in live trading strategy

· A Tesla News Headline Sentiment Analysis Trading Bot

· A NIO News Headline Sentiment Analysis Trading Bot

Here is the link :): https://www.udemy.com/course/sentiment-trading-python/?couponCode=DCAABDC4D72BB41B15B3",t2_823gdb34,False,,0,False,Hello World!!! I built a Course on Udemy where I teach 6 live cutting-edge Sentiment Analysis Trading Algorithms used on Wall Street. All you need to know is Python!! (FREE UNTIL 4/5/2021),[],r/deeplearning,False,6,,0,,False,t3_mja8n8,False,dark,0.36,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617491060.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In this course I will teach you 6 different live trading bots including:&lt;/p&gt;

&lt;p&gt;· A Bitcoin Reddit Sentiment Analysis Trading Bot&lt;/p&gt;

&lt;p&gt;· A Doge Reddit Sentiment Analysis Trading Bot with Technical Indicators&lt;/p&gt;

&lt;p&gt;· A Bitcoin Twitter Sentiment Analysis Trading Bot using state of the art Natural Language Processing Algorithm (BERT) where we create our own dataset with Bullish/Bearish labels and use it live&lt;/p&gt;

&lt;p&gt;· A Gold Twitter Sentiment Analysis Trading Bot where we web scrape CNN’s Fear &amp;amp; Greed Index and implement it in live trading strategy&lt;/p&gt;

&lt;p&gt;· A Tesla News Headline Sentiment Analysis Trading Bot&lt;/p&gt;

&lt;p&gt;· A NIO News Headline Sentiment Analysis Trading Bot&lt;/p&gt;

&lt;p&gt;Here is the link :): &lt;a href=""https://www.udemy.com/course/sentiment-trading-python/?couponCode=DCAABDC4D72BB41B15B3""&gt;https://www.udemy.com/course/sentiment-trading-python/?couponCode=DCAABDC4D72BB41B15B3&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mja8n8,True,,samboylansajous,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mja8n8/hello_world_i_built_a_course_on_udemy_where_i/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mja8n8/hello_world_i_built_a_course_on_udemy_where_i/,66146,1617462260.0,0,,False,,,,,,,
,deeplearning,"I am trying to implement iterative pruning  algorithm (as described in the research papers in [\[1\]](https://arxiv.org/abs/1506.02626), [\[2\]](https://arxiv.org/abs/1803.03635))  which is: train a model, prune p% of smallest weights per layer,  re-train the pruned model and repeat. For experiment purposes, I  am  using LeNet-300-100 neural network on MNIST.

The code can be accessed [here](https://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/blob/master/LeNet_300_100-Iterative_Pruning.ipynb)

Within  the function “train\_with\_grad\_freezing(model, epoch)”, I am  using the  following lines of code for freezing the pruned weights by  making their  computed gradients equal to 0:

    for layer_name, param in model.named_parameters():
        if 'weight' in layer_name:
            tensor = param.data.cpu().numpy()
            grad_tensor = param.grad.data.cpu().numpy()
            grad_tensor = np.where(tensor == 0, 0, grad_tensor)
            param.grad.data = torch.from_numpy(grad_tensor).to(device)  

The first time I train the model, the code works fine after which I prune the layers by using the code:

    # Prune 15% of smallest magnitude weights in FC layers and 10% in output layer- pruned_d = prune_lenet(model = best_model, pruning_params_fc = 15, pruning_params_op = 10) 
    # Initialize and load pruned Python3 dict into a new model- pruned_model = LeNet300() pruned_model.load_state_dict(pruned_d)  

However, on re-training this pruned model, the training metric is stuck for these values:

&gt;training loss = 0.0285, training accuracy = 99.04%, val\_loss = 0.0910 &amp; val\_accuracy = 97.68%

What’s going wrong?",t2_2mmql89p,False,,0,False,Iterative Pruning: LeNet-300-100 - PyTorch,[],r/deeplearning,False,6,,0,,False,t3_miz41u,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617444391.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am trying to implement iterative pruning  algorithm (as described in the research papers in &lt;a href=""https://arxiv.org/abs/1506.02626""&gt;[1]&lt;/a&gt;, &lt;a href=""https://arxiv.org/abs/1803.03635""&gt;[2]&lt;/a&gt;)  which is: train a model, prune p% of smallest weights per layer,  re-train the pruned model and repeat. For experiment purposes, I  am  using LeNet-300-100 neural network on MNIST.&lt;/p&gt;

&lt;p&gt;The code can be accessed &lt;a href=""https://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/blob/master/LeNet_300_100-Iterative_Pruning.ipynb""&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Within  the function “train_with_grad_freezing(model, epoch)”, I am  using the  following lines of code for freezing the pruned weights by  making their  computed gradients equal to 0:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for layer_name, param in model.named_parameters():
    if &amp;#39;weight&amp;#39; in layer_name:
        tensor = param.data.cpu().numpy()
        grad_tensor = param.grad.data.cpu().numpy()
        grad_tensor = np.where(tensor == 0, 0, grad_tensor)
        param.grad.data = torch.from_numpy(grad_tensor).to(device)  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first time I train the model, the code works fine after which I prune the layers by using the code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Prune 15% of smallest magnitude weights in FC layers and 10% in output layer- pruned_d = prune_lenet(model = best_model, pruning_params_fc = 15, pruning_params_op = 10) 
# Initialize and load pruned Python3 dict into a new model- pruned_model = LeNet300() pruned_model.load_state_dict(pruned_d)  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, on re-training this pruned model, the training metric is stuck for these values:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;training loss = 0.0285, training accuracy = 99.04%, val_loss = 0.0910 &amp;amp; val_accuracy = 97.68%&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What’s going wrong?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,miz41u,True,,grid_world,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/miz41u/iterative_pruning_lenet300100_pytorch/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/miz41u/iterative_pruning_lenet300100_pytorch/,66146,1617415591.0,0,,False,,,,,,,
,deeplearning,"In this post we will go through one of the prominent works which took inspiration from [Non-Local Networks](https://arxiv.org/abs/1711.07971) and [Squeeze-and-Excitation Networks](https://blog.paperspace.com/channel-attention-squeeze-and-excitation-networks/) to model an attention mechanism that enables the network to capture long-range dependencies at a considerably cheap cost. This is known as the [Global Context Network](https://arxiv.org/pdf/1904.11492.pdf), which was accepted at ICCV Workshops in 2019. PyTorch code included.

Topics covered include:

* Abstract Overview
* Revisiting Non-Local Networks
* Revisiting Squeeze-and-Excitation Networks
* Global Context Networks
* PyTorch Code
* Results
* Shortcomings

Article link: [https://blog.paperspace.com/global-context-networks-gcnet/](https://blog.paperspace.com/global-context-networks-gcnet/)

Comments and discussion welcome!",t2_15en0l,False,,0,False,[Article] Global Context Networks (GCNet) Explained,[],r/deeplearning,False,6,,0,,False,t3_mim6k1,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617404670.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In this post we will go through one of the prominent works which took inspiration from &lt;a href=""https://arxiv.org/abs/1711.07971""&gt;Non-Local Networks&lt;/a&gt; and &lt;a href=""https://blog.paperspace.com/channel-attention-squeeze-and-excitation-networks/""&gt;Squeeze-and-Excitation Networks&lt;/a&gt; to model an attention mechanism that enables the network to capture long-range dependencies at a considerably cheap cost. This is known as the &lt;a href=""https://arxiv.org/pdf/1904.11492.pdf""&gt;Global Context Network&lt;/a&gt;, which was accepted at ICCV Workshops in 2019. PyTorch code included.&lt;/p&gt;

&lt;p&gt;Topics covered include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Abstract Overview&lt;/li&gt;
&lt;li&gt;Revisiting Non-Local Networks&lt;/li&gt;
&lt;li&gt;Revisiting Squeeze-and-Excitation Networks&lt;/li&gt;
&lt;li&gt;Global Context Networks&lt;/li&gt;
&lt;li&gt;PyTorch Code&lt;/li&gt;
&lt;li&gt;Results&lt;/li&gt;
&lt;li&gt;Shortcomings&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Article link: &lt;a href=""https://blog.paperspace.com/global-context-networks-gcnet/""&gt;https://blog.paperspace.com/global-context-networks-gcnet/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Comments and discussion welcome!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mim6k1,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mim6k1/article_global_context_networks_gcnet_explained/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mim6k1/article_global_context_networks_gcnet_explained/,66146,1617375870.0,0,,False,,,,,,,
,deeplearning,"Just like many of us, I'm quite tired of waiting for my 3080. I've ordered the card 5 minutes after its initial premiere and since tried to get it in 10 other shops.

As part of research at my uni (my engineering thesis), I am building YOLO (prob v1) from scratch. I know this requires a huge dataset and that training will take a lot of time, but I'm pretty sure I won't get my RTX anytime soon.. (hopefully summer, let's keep believing)  
So the question is:  
Is it possible to train such a huge model online or do I need to buy overprices used GPU for 800 $ like RTX 2070 because that's the price in Poland right now. If You suggest buying a GPU which card could suit me the best?",t2_5dpk4nle,False,,0,False,GPU for training own YOLO model,[],r/deeplearning,False,6,,0,,False,t3_mi463f,False,dark,0.86,,public,20,0,{},,False,[],,False,False,,{},,False,20,,False,False,,False,,[],{},,True,,1617337433.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Just like many of us, I&amp;#39;m quite tired of waiting for my 3080. I&amp;#39;ve ordered the card 5 minutes after its initial premiere and since tried to get it in 10 other shops.&lt;/p&gt;

&lt;p&gt;As part of research at my uni (my engineering thesis), I am building YOLO (prob v1) from scratch. I know this requires a huge dataset and that training will take a lot of time, but I&amp;#39;m pretty sure I won&amp;#39;t get my RTX anytime soon.. (hopefully summer, let&amp;#39;s keep believing)&lt;br/&gt;
So the question is:&lt;br/&gt;
Is it possible to train such a huge model online or do I need to buy overprices used GPU for 800 $ like RTX 2070 because that&amp;#39;s the price in Poland right now. If You suggest buying a GPU which card could suit me the best?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mi463f,True,,bindas13,,21,True,all_ads,False,[],False,,/r/deeplearning/comments/mi463f/gpu_for_training_own_yolo_model/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mi463f/gpu_for_training_own_yolo_model/,66146,1617308633.0,0,,False,,,,,,,
,deeplearning,,t2_1igruv2n,False,,0,False,An introduction and tutorial to TensorFlow Extended (TFX),[],r/deeplearning,False,6,,0,,False,t3_mi4m6w,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1617338753.0,text,6,,,text,adaltas.com,False,,,,,https://www.adaltas.com/en/2021/03/05/tfx-overview/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mi4m6w,True,,dworms,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mi4m6w/an_introduction_and_tutorial_to_tensorflow/,all_ads,False,https://www.adaltas.com/en/2021/03/05/tfx-overview/,66146,1617309953.0,0,,False,,,,,,,
,deeplearning,,t2_7b9jtb1c,False,,0,False,can someone explain that why do we have to array to load the data here?,[],r/deeplearning,False,6,,0,,False,t3_mhwlvb,False,dark,0.58,,public,6,0,{},,False,[],,True,False,,{},,False,6,,False,False,,False,,[],{},,False,,1617316427.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/sfsk8f3wokq61.png,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mhwlvb,True,,khokharnakshita,,24,True,all_ads,False,[],False,,/r/deeplearning/comments/mhwlvb/can_someone_explain_that_why_do_we_have_to_array/,all_ads,False,https://i.redd.it/sfsk8f3wokq61.png,66146,1617287627.0,0,,False,,,,,,,
,deeplearning,"I am in a dilemma. I don't know if you know it, but the latest drivers from Nvidia, break Linux systems so it's impossible to work. On the other hand, we have AMD which offers less efficient GPUs, but which have fairly reliable drivers. Like everyone else I use TensorFlow, which is eucominic, so I went on Nvidia, but AMD would be more ... reasonable, help !!!!",t2_ou2zv,False,,0,False,GPU and drivers,[],r/deeplearning,False,6,,0,,False,t3_mi87vo,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617349747.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am in a dilemma. I don&amp;#39;t know if you know it, but the latest drivers from Nvidia, break Linux systems so it&amp;#39;s impossible to work. On the other hand, we have AMD which offers less efficient GPUs, but which have fairly reliable drivers. Like everyone else I use TensorFlow, which is eucominic, so I went on Nvidia, but AMD would be more ... reasonable, help !!!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mi87vo,True,,darklinux1977,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mi87vo/gpu_and_drivers/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mi87vo/gpu_and_drivers/,66146,1617320947.0,0,,False,,,,,,,
,deeplearning,"I spent \~50 hours looking for the best resources on various GANs and Transformer models and organized them into a website [backprop.org](https://backprop.org).

Check it out! If people find this useful I'll add more pages on more topics. 

Also, if you know any great resources that I missed send it my way!",t2_8tp141ey,False,,0,False,Made website with best resources I could find on GANs and Transformers,[],r/deeplearning,False,6,,0,,False,t3_mheqz6,False,dark,0.97,,public,75,1,{},,False,[],,False,False,,{},,False,75,,False,False,,False,,[],{'gid_1': 1},,True,,1617250713.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I spent ~50 hours looking for the best resources on various GANs and Transformer models and organized them into a website &lt;a href=""https://backprop.org""&gt;backprop.org&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Check it out! If people find this useful I&amp;#39;ll add more pages on more topics. &lt;/p&gt;

&lt;p&gt;Also, if you know any great resources that I missed send it my way!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mheqz6,True,,backpropsite,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mheqz6/made_website_with_best_resources_i_could_find_on/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mheqz6/made_website_with_best_resources_i_could_find_on/,66146,1617221913.0,0,,False,,,,,,,
,deeplearning,"
working on digit recognise use CNN ( 38,38,64,64,128,128)and dropout (.2,.2,.5,.5)layers which give me 0.926 accuracy on test data So is there anyway to increase accuracy of model",t2_5vklt5m5,False,,0,False,How to increase accuracy on digital recognise dataset kaggle compitions,[],r/deeplearning,False,6,,0,,False,t3_mi2ubm,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617333731.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;working on digit recognise use CNN ( 38,38,64,64,128,128)and dropout (.2,.2,.5,.5)layers which give me 0.926 accuracy on test data So is there anyway to increase accuracy of model&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mi2ubm,True,,seeon321,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mi2ubm/how_to_increase_accuracy_on_digital_recognise/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mi2ubm/how_to_increase_accuracy_on_digital_recognise/,66146,1617304931.0,0,,False,,,,,,,
,deeplearning,,t2_a2fvpp34,False,,0,False,Sequence to Sequence Learning Animated,[],r/deeplearning,False,6,,0,,False,t3_mhqkv5,False,dark,0.86,,public,5,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/GTVgJhSlHEk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Sequence to Sequence Learning Animated (Inside Transformer Neural Networks and Attention Mechanisms)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/GTVgJhSlHEk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'learningcurve', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/GTVgJhSlHEk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/learningcurveai'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/GTVgJhSlHEk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mhqkv5', 'height': 200}",,False,5,,False,False,,False,,[],{},,False,,1617293190.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/GTVgJhSlHEk,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mhqkv5,True,,No-Guard-5438,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mhqkv5/sequence_to_sequence_learning_animated/,all_ads,False,https://youtu.be/GTVgJhSlHEk,66146,1617264390.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Sequence to Sequence Learning Animated (Inside Transformer Neural Networks and Attention Mechanisms)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/GTVgJhSlHEk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'learningcurve', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/GTVgJhSlHEk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/learningcurveai'}}",False,,,,,,,
,deeplearning,,t2_a4qdew5m,False,,0,False,Image Classification Using Model Builder (ML.NET Model Builder),[],r/deeplearning,False,6,,0,,False,t3_mhsrwe,False,dark,0.33,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Dg9O7PVMLYQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Image Classification Using Model Builder (ML.NET Model Builder)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Dg9O7PVMLYQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'OptiSol Solutions', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Dg9O7PVMLYQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/OptiSolSolutions'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Dg9O7PVMLYQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mhsrwe', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1617303393.0,text,6,,,text,youtube.com,False,,,,,https://youtube.com/watch?v=Dg9O7PVMLYQ&amp;feature=share,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mhsrwe,True,,softcompanyuk,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mhsrwe/image_classification_using_model_builder_mlnet/,all_ads,False,https://youtube.com/watch?v=Dg9O7PVMLYQ&amp;feature=share,66146,1617274593.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Image Classification Using Model Builder (ML.NET Model Builder)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Dg9O7PVMLYQ?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'OptiSol Solutions', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Dg9O7PVMLYQ/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/OptiSolSolutions'}}",False,,,,,,,
,deeplearning,"Hello
Im new here and i was looking forward to enroll in the nanodegree through FWD and NTL (two organisations that give these courses for free for CS students) but got rejected to both due to my age (which is 19)
Is there anyway i could download the new version of the nanodegree with pytorch and i will study it with my self?
I already finished the first part in the old version by myself but the next part will start using tenserflow 
Thx in advance

Edit: and if there no download for new version do i continue on the old version or should i go to coursera deep learning course?",t2_a825rk0z,False,,0,False,Udacity deep learning nanodegree free?,[],r/deeplearning,False,6,,0,,False,t3_mhoxpb,False,dark,0.76,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,1617257323.0,,[],{},,True,,1617285871.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello
Im new here and i was looking forward to enroll in the nanodegree through FWD and NTL (two organisations that give these courses for free for CS students) but got rejected to both due to my age (which is 19)
Is there anyway i could download the new version of the nanodegree with pytorch and i will study it with my self?
I already finished the first part in the old version by myself but the next part will start using tenserflow 
Thx in advance&lt;/p&gt;

&lt;p&gt;Edit: and if there no download for new version do i continue on the old version or should i go to coursera deep learning course?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mhoxpb,True,,NoFap_Panda,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mhoxpb/udacity_deep_learning_nanodegree_free/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mhoxpb/udacity_deep_learning_nanodegree_free/,66146,1617257071.0,0,,False,,,,,,,
,deeplearning,"I have a list of dictionaries (below is the sample)  which consist of 128 image vectors for each image, Now I want to save these data into Postgresql database, but I don't have any idea which method and datatype should use to save the vector as it is because I will find Euclidian distance from it for face recognition. 

I want to save this list into csv or json or npy format and then externally save it into the database, so please also suggest me which is the best format to convert in?

\[{ 'name': 'George\_HW\_Bush\_0005.jpg', 

  'img': array(\[-6.08353578e-02,  1.66202977e-01,  8.54108036e-02,  2.64507625e-02, -2.49952618e-02,  8.26701149e-02, -3.53199616e-02, -4.34518009e-02,          8.51533711e-02, -6.55662417e-02,  2.22901687e-01, -1.92691050e-02,         -3.02192807e-01, -2.82627549e-02, -9.89550427e-02,  1.01481207e-01,         -1.48302019e-01, -7.24662393e-02, -1.41541883e-01, -4.30632085e-02,         -1.79181602e-02,  7.14668408e-02, -3.18156220e-02, -1.12840414e-01,         -9.71992686e-02, -2.74635673e-01, -3.41563784e-02, -1.05296098e-01,          5.71775325e-02, -1.08009912e-01,  6.61401078e-02,  1.62646291e-04,         -2.22103953e-01, -1.95380449e-02, -1.67706627e-02,  1.98841095e-02,         -1.04590744e-01, -4.91602942e-02,  2.44830742e-01, -3.07598646e-04,         -1.22460142e-01,  5.40154874e-02,  1.07697263e-01,  2.19618991e-01,          2.12186426e-01, -7.63659030e-02, -4.21547107e-02, -4.53756154e-02,          1.02992378e-01, -2.73030281e-01,  6.86264187e-02,  1.82788327e-01,          1.83412746e-01,  2.17555761e-01,  7.20319897e-02, -1.13681927e-01,          5.40269949e-02,  1.64304838e-01, -1.61037013e-01,  7.31164068e-02,          5.13559654e-02, -1.04436658e-01, -1.39024807e-02,  8.65904540e-02,          8.64276886e-02,  6.22027554e-02, -1.94389019e-02, -1.93822086e-01,          1.99560717e-01, -1.59010977e-01, -3.11802272e-02,  8.16744193e-02,         -5.18603846e-02, -1.15916312e-01, -2.57695049e-01,  9.63293090e-02,          2.42554873e-01,  1.22541614e-01, -1.25135452e-01,  5.56182452e-02,         -4.80696559e-02, -1.15475528e-01, -8.14200903e-04,  1.32136038e-02,         -4.28808704e-02, -1.49314120e-01, -2.70449519e-02,  3.87667306e-02,          2.21050128e-01, -9.29581188e-03, -9.46529582e-03,  1.69327006e-01,          1.46268372e-04, -9.63619947e-02,  5.10829128e-02, -1.17124785e-02,         -8.15291181e-02, -6.01790026e-02, -1.11909479e-01,  2.53269309e-03,         -1.98859032e-02, -1.59346312e-01, -5.91453053e-02,  1.00001127e-01,         -1.87035248e-01,  1.49713486e-01, -9.77795757e-03, -5.53171374e-02,          3.81288752e-02, -5.98978512e-02, -3.40475552e-02,  6.95589632e-02,          2.09958583e-01, -2.06186399e-01,  3.47163618e-01,  9.52471495e-02,         -4.64627380e-03,  7.62443841e-02,  9.88056138e-02,  5.67689314e-02,          1.82110053e-02, -1.31150419e-02, -1.71786547e-01, -1.77120611e-01,         -1.88438110e-02, -1.68694910e-02, -2.67733559e-02,  1.85598787e-02\])},

{'name':--------------so on",t2_a8k0v7v0,False,,0,False,How to save n-dim array in a column in Postgressql?,[],r/deeplearning,False,6,,0,,False,t3_mhrpo7,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617298669.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a list of dictionaries (below is the sample)  which consist of 128 image vectors for each image, Now I want to save these data into Postgresql database, but I don&amp;#39;t have any idea which method and datatype should use to save the vector as it is because I will find Euclidian distance from it for face recognition. &lt;/p&gt;

&lt;p&gt;I want to save this list into csv or json or npy format and then externally save it into the database, so please also suggest me which is the best format to convert in?&lt;/p&gt;

&lt;p&gt;[{ &amp;#39;name&amp;#39;: &amp;#39;George_HW_Bush_0005.jpg&amp;#39;, &lt;/p&gt;

&lt;p&gt;&amp;#39;img&amp;#39;: array([-6.08353578e-02,  1.66202977e-01,  8.54108036e-02,  2.64507625e-02, -2.49952618e-02,  8.26701149e-02, -3.53199616e-02, -4.34518009e-02,          8.51533711e-02, -6.55662417e-02,  2.22901687e-01, -1.92691050e-02,         -3.02192807e-01, -2.82627549e-02, -9.89550427e-02,  1.01481207e-01,         -1.48302019e-01, -7.24662393e-02, -1.41541883e-01, -4.30632085e-02,         -1.79181602e-02,  7.14668408e-02, -3.18156220e-02, -1.12840414e-01,         -9.71992686e-02, -2.74635673e-01, -3.41563784e-02, -1.05296098e-01,          5.71775325e-02, -1.08009912e-01,  6.61401078e-02,  1.62646291e-04,         -2.22103953e-01, -1.95380449e-02, -1.67706627e-02,  1.98841095e-02,         -1.04590744e-01, -4.91602942e-02,  2.44830742e-01, -3.07598646e-04,         -1.22460142e-01,  5.40154874e-02,  1.07697263e-01,  2.19618991e-01,          2.12186426e-01, -7.63659030e-02, -4.21547107e-02, -4.53756154e-02,          1.02992378e-01, -2.73030281e-01,  6.86264187e-02,  1.82788327e-01,          1.83412746e-01,  2.17555761e-01,  7.20319897e-02, -1.13681927e-01,          5.40269949e-02,  1.64304838e-01, -1.61037013e-01,  7.31164068e-02,          5.13559654e-02, -1.04436658e-01, -1.39024807e-02,  8.65904540e-02,          8.64276886e-02,  6.22027554e-02, -1.94389019e-02, -1.93822086e-01,          1.99560717e-01, -1.59010977e-01, -3.11802272e-02,  8.16744193e-02,         -5.18603846e-02, -1.15916312e-01, -2.57695049e-01,  9.63293090e-02,          2.42554873e-01,  1.22541614e-01, -1.25135452e-01,  5.56182452e-02,         -4.80696559e-02, -1.15475528e-01, -8.14200903e-04,  1.32136038e-02,         -4.28808704e-02, -1.49314120e-01, -2.70449519e-02,  3.87667306e-02,          2.21050128e-01, -9.29581188e-03, -9.46529582e-03,  1.69327006e-01,          1.46268372e-04, -9.63619947e-02,  5.10829128e-02, -1.17124785e-02,         -8.15291181e-02, -6.01790026e-02, -1.11909479e-01,  2.53269309e-03,         -1.98859032e-02, -1.59346312e-01, -5.91453053e-02,  1.00001127e-01,         -1.87035248e-01,  1.49713486e-01, -9.77795757e-03, -5.53171374e-02,          3.81288752e-02, -5.98978512e-02, -3.40475552e-02,  6.95589632e-02,          2.09958583e-01, -2.06186399e-01,  3.47163618e-01,  9.52471495e-02,         -4.64627380e-03,  7.62443841e-02,  9.88056138e-02,  5.67689314e-02,          1.82110053e-02, -1.31150419e-02, -1.71786547e-01, -1.77120611e-01,         -1.88438110e-02, -1.68694910e-02, -2.67733559e-02,  1.85598787e-02])},&lt;/p&gt;

&lt;p&gt;{&amp;#39;name&amp;#39;:--------------so on&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mhrpo7,True,,Alan491,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mhrpo7/how_to_save_ndim_array_in_a_column_in_postgressql/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mhrpo7/how_to_save_ndim_array_in_a_column_in_postgressql/,66146,1617269869.0,0,,False,,,,,,,
,deeplearning,,t2_66dqvlke,False,,0,False,A survey on generative adversarial networks: fundamentals and recent advances - Link to free zoom lecture by the researcher in comments,[],r/deeplearning,False,6,,0,,False,t3_mhalhh,False,dark,0.89,,public,14,0,{},,False,[],,True,False,,{},,False,14,,False,False,,False,,[],{},,False,,1617238984.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/xj9o5tqmaeq61.jpg,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mhalhh,True,,dataskml,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mhalhh/a_survey_on_generative_adversarial_networks/,all_ads,False,https://i.redd.it/xj9o5tqmaeq61.jpg,66146,1617210184.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,Solve the Rubik's cube using AR and AI,[],r/deeplearning,False,6,,0,,False,t3_mhojhw,False,dark,0.57,,public,1,0,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/h3gBDr8pF84?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Solve the Rubik's cube using AR and AI"", 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/h3gBDr8pF84?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/h3gBDr8pF84/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/h3gBDr8pF84?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mhojhw', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1617284187.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/h3gBDr8pF84,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mhojhw,True,,cmillionaire9,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mhojhw/solve_the_rubiks_cube_using_ar_and_ai/,all_ads,False,https://youtu.be/h3gBDr8pF84,66146,1617255387.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': ""Solve the Rubik's cube using AR and AI"", 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/h3gBDr8pF84?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/h3gBDr8pF84/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,"Hello!  I'm building Quad GPU Deep Learning Rig Build: 3x3080 and 1x3090.  It will definitely require water cooling for the GPUs to even fit, and two PSUs since 1600W will not be enough.  


Does anyone have a recommendation for a case?",t2_4pp7pnh3,False,,0,False,Quad GPU Deep Learning Rig Build: 3x3080 and 1x3090 with ryzen 3990x (64 cores),[],r/deeplearning,False,6,,0,,False,t3_mhlg7s,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617272271.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello!  I&amp;#39;m building Quad GPU Deep Learning Rig Build: 3x3080 and 1x3090.  It will definitely require water cooling for the GPUs to even fit, and two PSUs since 1600W will not be enough.  &lt;/p&gt;

&lt;p&gt;Does anyone have a recommendation for a case?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mhlg7s,True,,egafni,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mhlg7s/quad_gpu_deep_learning_rig_build_3x3080_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mhlg7s/quad_gpu_deep_learning_rig_build_3x3080_and/,66146,1617243471.0,0,,False,,,,,,,
,deeplearning,"I'm trying to think of a way to use deep learning to automatically select frames that contain polyps from colonoscopy video material. However, I don't have a lot of experience yet with deep learning yet. I could make a classifier that determines for a single frame whether it contains an abnormality or not, but that's not quite what I want to do.

I looked at some papers about automatic thumbnail selection, but the algorithms described there wouldn't really work for this problem.

Could anyone think of a way to do this using neural networks? I would be very grateful for any suggestions.",t2_5a2gd5nw,False,,0,False,Deep learning for colonoscopy analysis,[],r/deeplearning,False,6,,0,,False,t3_mh2h4d,False,dark,0.85,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1617212262.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to think of a way to use deep learning to automatically select frames that contain polyps from colonoscopy video material. However, I don&amp;#39;t have a lot of experience yet with deep learning yet. I could make a classifier that determines for a single frame whether it contains an abnormality or not, but that&amp;#39;s not quite what I want to do.&lt;/p&gt;

&lt;p&gt;I looked at some papers about automatic thumbnail selection, but the algorithms described there wouldn&amp;#39;t really work for this problem.&lt;/p&gt;

&lt;p&gt;Could anyone think of a way to do this using neural networks? I would be very grateful for any suggestions.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mh2h4d,True,,LittleMisssMorbid,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/mh2h4d/deep_learning_for_colonoscopy_analysis/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mh2h4d/deep_learning_for_colonoscopy_analysis/,66146,1617183462.0,0,,False,,,,,,,
,deeplearning,"I'm looking for cases where AI has been used in sports training or competitions to improve athlete's performance. Many sports applications that I've come across are regarding the business behind sports, like ticket sales, merch sales, etc. I'm not interested in these. I'm more interested in the uses in the sport itself. Could anyone share some examples that you've come across?",t2_15yunp,False,,0,False,Any good examples of AI usage in sports?,[],r/deeplearning,False,6,,0,,False,t3_mh631y,False,dark,0.87,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1617226012.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking for cases where AI has been used in sports training or competitions to improve athlete&amp;#39;s performance. Many sports applications that I&amp;#39;ve come across are regarding the business behind sports, like ticket sales, merch sales, etc. I&amp;#39;m not interested in these. I&amp;#39;m more interested in the uses in the sport itself. Could anyone share some examples that you&amp;#39;ve come across?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mh631y,True,,timon_meerkat,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/mh631y/any_good_examples_of_ai_usage_in_sports/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mh631y/any_good_examples_of_ai_usage_in_sports/,66146,1617197212.0,0,,False,,,,,,,
,deeplearning,,t2_4xq9iceu,False,,0,False,Taking a walk after thinking deeply about CNNs,[],r/deeplearning,False,6,,0,,False,t3_mgfhgo,False,dark,0.94,,public,179,0,{},,False,[],,True,False,,{},,False,179,,False,False,,False,,[],{},,False,,1617138057.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/aypo6ppjy5q61.jpg,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mgfhgo,True,,Giacobako,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/mgfhgo/taking_a_walk_after_thinking_deeply_about_cnns/,all_ads,False,https://i.redd.it/aypo6ppjy5q61.jpg,66146,1617109257.0,3,,False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,How to ask people about their work in Syrian Arabic?😍,[],r/deeplearning,False,6,,0,,False,t3_mhg97i,False,dark,0.2,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1617255026.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/nukllwexlfq61.png,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mhg97i,True,,Community-Of-Babel,,0,False,all_ads,False,[],False,,/r/deeplearning/comments/mhg97i/how_to_ask_people_about_their_work_in_syrian/,all_ads,False,https://i.redd.it/nukllwexlfq61.png,66146,1617226226.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How to ask people about their work in Syrian Arabic?😍', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mhg7er', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1617254880.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/nukllwexlfq61.png', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mhg7er', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/mhg7er/how_to_ask_people_about_their_work_in_syrian/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://i.redd.it/nukllwexlfq61.png', 'subreddit_subscribers': 0, 'created_utc': 1617226080.0, 'num_crossposts': 5, 'media': None, 'is_video': False}]",t3_mhg7er,,,,,
,deeplearning,"Today we are sharing with you a traditional computer vision algorithm called Contour Detection. It can perform image foreground extraction, simple image segmentation, detection and recognition. It is interesting to note that there already exist real-life, problem-solving solutions based on Contour Detection. 

In this blog post, we are going to learn about contours and contour detection using OpenCV. Not only the theory, but we will also cover complete hands-on coding in both Python and C++ programming languages to have a first-hand experience of contour detection using OpenCV. This can be used to detect edges or outlines in any image at a very fast speed and high accuracy without requiring a significant amount of computational resources.  


[https://learnopencv.com/contour-detection-using-opencv-python-c/](https://learnopencv.com/contour-detection-using-opencv-python-c/)

https://preview.redd.it/d40h0ghbidq61.jpg?width=500&amp;format=pjpg&amp;auto=webp&amp;s=1bda2e572e6677110a583f9528a2e421cfb51157",t2_cvc9f,False,,0,False,Contour Detection using OpenCV (Python/C++),[],r/deeplearning,False,6,,0,,False,t3_mh78i3,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617229525.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Today we are sharing with you a traditional computer vision algorithm called Contour Detection. It can perform image foreground extraction, simple image segmentation, detection and recognition. It is interesting to note that there already exist real-life, problem-solving solutions based on Contour Detection. &lt;/p&gt;

&lt;p&gt;In this blog post, we are going to learn about contours and contour detection using OpenCV. Not only the theory, but we will also cover complete hands-on coding in both Python and C++ programming languages to have a first-hand experience of contour detection using OpenCV. This can be used to detect edges or outlines in any image at a very fast speed and high accuracy without requiring a significant amount of computational resources.  &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://learnopencv.com/contour-detection-using-opencv-python-c/""&gt;https://learnopencv.com/contour-detection-using-opencv-python-c/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/d40h0ghbidq61.jpg?width=500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=1bda2e572e6677110a583f9528a2e421cfb51157""&gt;https://preview.redd.it/d40h0ghbidq61.jpg?width=500&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=1bda2e572e6677110a583f9528a2e421cfb51157&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mh78i3,True,,spmallick,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mh78i3/contour_detection_using_opencv_pythonc/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mh78i3/contour_detection_using_opencv_pythonc/,66146,1617200725.0,0,,False,,,"{'d40h0ghbidq61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 86, 'x': 108, 'u': 'https://preview.redd.it/d40h0ghbidq61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=78a44719cd4e8aaa4c999e2c749d637157b3f682'}, {'y': 172, 'x': 216, 'u': 'https://preview.redd.it/d40h0ghbidq61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e6742855b5a1937c92a88ae95f2f07648b4184f8'}, {'y': 256, 'x': 320, 'u': 'https://preview.redd.it/d40h0ghbidq61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=91228128031efc5163c0d6073702b8d85a5f1b69'}], 's': {'y': 400, 'x': 500, 'u': 'https://preview.redd.it/d40h0ghbidq61.jpg?width=500&amp;format=pjpg&amp;auto=webp&amp;s=1bda2e572e6677110a583f9528a2e421cfb51157'}, 'id': 'd40h0ghbidq61'}}",,,,
,deeplearning,[https://youtu.be/5F5LlmO10AM](https://youtu.be/5F5LlmO10AM),t2_357rx0k0,False,,0,False,Advanced AutoML with Determined AI,[],r/deeplearning,False,6,,0,,False,t3_mhbp28,False,dark,0.25,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617242074.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://youtu.be/5F5LlmO10AM""&gt;https://youtu.be/5F5LlmO10AM&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mhbp28,True,,HenryAILabs,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mhbp28/advanced_automl_with_determined_ai/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mhbp28/advanced_automl_with_determined_ai/,66146,1617213274.0,0,,False,,,,,,,
,deeplearning,"I  am in process for publishing a paper in ""Deep Learning compression"" by  comparing a model's original size and performance vs. compressed size  and performance on some dataset. Majority of the research papers either  focus on CIFAR-10 and/or ImageNet.

ImageNet  becomes an infrastructure challenge since the dataset size is upward of  150 GB. The problem with CIFAR-10 is that you have a smaller dataset  (60K images) which doesn't scale well if your model size grows -&gt;  think ResNet-50 and bigger.

Therefore,  can you all suggest some other dataset which sits somewhere in between  and whose results will be accepted by journals, conferences, etc. (from  the academic point of view)?",t2_2mmql89p,False,,0,False,Dataset for research paper,[],r/deeplearning,False,6,,0,,False,t3_mh26n3,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617210950.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I  am in process for publishing a paper in &amp;quot;Deep Learning compression&amp;quot; by  comparing a model&amp;#39;s original size and performance vs. compressed size  and performance on some dataset. Majority of the research papers either  focus on CIFAR-10 and/or ImageNet.&lt;/p&gt;

&lt;p&gt;ImageNet  becomes an infrastructure challenge since the dataset size is upward of  150 GB. The problem with CIFAR-10 is that you have a smaller dataset  (60K images) which doesn&amp;#39;t scale well if your model size grows -&amp;gt;  think ResNet-50 and bigger.&lt;/p&gt;

&lt;p&gt;Therefore,  can you all suggest some other dataset which sits somewhere in between  and whose results will be accepted by journals, conferences, etc. (from  the academic point of view)?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mh26n3,True,,grid_world,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/mh26n3/dataset_for_research_paper/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mh26n3/dataset_for_research_paper/,66146,1617182150.0,0,,False,,,,,,,
,deeplearning,,t2_47jpmh5m,False,,0,False,45 Most Popular Computer Vision Applications by Industry,[],r/deeplearning,False,6,,0,,False,t3_mgwg9r,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1617187681.0,text,6,,,text,cnvrg.io,False,,,,,https://cnvrg.io/computer-vision-applications/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mgwg9r,True,,ItisAhmad,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mgwg9r/45_most_popular_computer_vision_applications_by/,all_ads,False,https://cnvrg.io/computer-vision-applications/,66146,1617158881.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': '', 'author_fullname': 't2_47jpmh5m', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '45 Most Popular Computer Vision Applications by Industry', 'link_flair_richtext': [{'e': 'text', 't': 'Discussion'}], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mgwfyy', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.75, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1617187652.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'cnvrg.io', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://cnvrg.io/computer-vision-applications/', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'bed45ad2-accf-11e9-adf9-0e84e198baba', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#007373', 'id': 'mgwfyy', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'ItisAhmad', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/mgwfyy/45_most_popular_computer_vision_applications_by/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://cnvrg.io/computer-vision-applications/', 'subreddit_subscribers': 232341, 'created_utc': 1617158852.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_mgwfyy,,,,,
,deeplearning,,t2_47jpmh5m,False,,0,False,How To Build Custom Loss Functions In Keras For Any Use Case,[],r/deeplearning,False,6,,0,,False,t3_mgwfbk,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1617187591.0,text,6,,,text,cnvrg.io,False,,,,,https://cnvrg.io/keras-custom-loss-functions/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mgwfbk,True,,ItisAhmad,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mgwfbk/how_to_build_custom_loss_functions_in_keras_for/,all_ads,False,https://cnvrg.io/keras-custom-loss-functions/,66146,1617158791.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': '', 'author_fullname': 't2_47jpmh5m', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How To Build Custom Loss Functions In Keras For Any Use Case', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mgwf1b', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1617187560.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'cnvrg.io', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://cnvrg.io/keras-custom-loss-functions/', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mgwf1b', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'ItisAhmad', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/mgwf1b/how_to_build_custom_loss_functions_in_keras_for/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://cnvrg.io/keras-custom-loss-functions/', 'subreddit_subscribers': 232341, 'created_utc': 1617158760.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_mgwf1b,,,,,
,deeplearning,,t2_1568ks,False,,0,False,Why AI can’t solve unknown problems,[],r/deeplearning,False,6,,0,,False,t3_mgmuxa,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1617158449.0,text,6,,,text,bdtechtalks.com,False,,,,,https://bdtechtalks.com/2021/03/29/ai-algorithms-representations-herbert-roitblat/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mgmuxa,True,,bendee983,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mgmuxa/why_ai_cant_solve_unknown_problems/,all_ads,False,https://bdtechtalks.com/2021/03/29/ai-algorithms-representations-herbert-roitblat/,66146,1617129649.0,0,,False,,,,,,,
,deeplearning,"A dataset is used to train an AI model. In the optimization process the model tries to understand why a piece should be rated better than the other. Therefore, a comprehensive dataset can be significantly helpful. However, as the size of the dataset increases, more time is required for all samples to be checked. This is why optimization is a time consuming process and results will get better when the optimization is done. 

In this project, up to now, only 11% of the available samples have been evaluated and in total 14% of the optimization process has been completed. As you can see, there is a long way to go. The process has been categorized. Out of 8 categories, 3 have been completed. You can see the latest release on The Pianist AI YouTube channel. The quality and harmony is low (very low) but the progress is promising.

Current level can be considered as a 7-year old kid playing with the piano keys and trying to understand which key generates what sound. Soon new samples from Category 4 will be released where it is anticipated that the quality and harmony has been improved.   

Thank you for all your support, hopefully the final result will be magnificent :).

Please subscribe to [The Pianist AI YouTube channel](https://www.youtube.com/c/ThePianistAI) for regular updates: 

Follow us on [Instagram](https://www.instagram.com/pianist_ai/) and [twitter](https://twitter.com/ai_pianist).

For more details you can check [The Pianist AI](https://pianistai.com/) website as well.",t2_3r02kqm0,False,,0,False,"The Pianist AI, an AI model that learns and generates piano pieces: Progress report",[],r/deeplearning,False,6,,0,,False,t3_mgb97z,False,dark,0.88,,public,13,0,{},,False,[],,False,False,,{},,False,13,,False,False,,False,,[],{},,True,,1617121805.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A dataset is used to train an AI model. In the optimization process the model tries to understand why a piece should be rated better than the other. Therefore, a comprehensive dataset can be significantly helpful. However, as the size of the dataset increases, more time is required for all samples to be checked. This is why optimization is a time consuming process and results will get better when the optimization is done. &lt;/p&gt;

&lt;p&gt;In this project, up to now, only 11% of the available samples have been evaluated and in total 14% of the optimization process has been completed. As you can see, there is a long way to go. The process has been categorized. Out of 8 categories, 3 have been completed. You can see the latest release on The Pianist AI YouTube channel. The quality and harmony is low (very low) but the progress is promising.&lt;/p&gt;

&lt;p&gt;Current level can be considered as a 7-year old kid playing with the piano keys and trying to understand which key generates what sound. Soon new samples from Category 4 will be released where it is anticipated that the quality and harmony has been improved.   &lt;/p&gt;

&lt;p&gt;Thank you for all your support, hopefully the final result will be magnificent :).&lt;/p&gt;

&lt;p&gt;Please subscribe to &lt;a href=""https://www.youtube.com/c/ThePianistAI""&gt;The Pianist AI YouTube channel&lt;/a&gt; for regular updates: &lt;/p&gt;

&lt;p&gt;Follow us on &lt;a href=""https://www.instagram.com/pianist_ai/""&gt;Instagram&lt;/a&gt; and &lt;a href=""https://twitter.com/ai_pianist""&gt;twitter&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For more details you can check &lt;a href=""https://pianistai.com/""&gt;The Pianist AI&lt;/a&gt; website as well.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mgb97z,True,,amin_mlm,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mgb97z/the_pianist_ai_an_ai_model_that_learns_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mgb97z/the_pianist_ai_an_ai_model_that_learns_and/,66146,1617093005.0,0,,False,,,,,,,
,deeplearning,"I am working on a project which involves multihead self attention with positional embedding and i am planning to use tensorflow's multihead attention function \[tfa.layers.MultiHeadAttention()\], and my question is does it already contain positional embedding or not ?",t2_3segrwii,False,,0,False,Positional embedding,[],r/deeplearning,False,6,,0,,False,t3_mgifwj,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1617146550.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am working on a project which involves multihead self attention with positional embedding and i am planning to use tensorflow&amp;#39;s multihead attention function [tfa.layers.MultiHeadAttention()], and my question is does it already contain positional embedding or not ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mgifwj,True,,blue_ark12,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mgifwj/positional_embedding/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mgifwj/positional_embedding/,66146,1617117750.0,0,,False,,,,,,,
,deeplearning,"I mostly see GAN image editing projects rely on Pix2Pix distillation to work in realtime, but the authors of ""Using latent space regression to analyze and leverage compositionality in GANS"" claim their encoder -&gt; generator setup works in realtime. I tried the demo from github, and it does work pretty fast for small edits, kinda strange that it hangs for larger edits. 

In case you are not familiar with the paper, and want to learn about it, I explained the main ideas in my  [telegram channel](https://t.me/casual_gan/17)",t2_hhio3,False,,0,False,GAN image editing in realtime with an encoder-generator,[],r/deeplearning,False,6,,0,,False,t3_mglmg7,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617155082.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I mostly see GAN image editing projects rely on Pix2Pix distillation to work in realtime, but the authors of &amp;quot;Using latent space regression to analyze and leverage compositionality in GANS&amp;quot; claim their encoder -&amp;gt; generator setup works in realtime. I tried the demo from github, and it does work pretty fast for small edits, kinda strange that it hangs for larger edits. &lt;/p&gt;

&lt;p&gt;In case you are not familiar with the paper, and want to learn about it, I explained the main ideas in my  &lt;a href=""https://t.me/casual_gan/17""&gt;telegram channel&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mglmg7,True,,KirillTheMunchKing,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mglmg7/gan_image_editing_in_realtime_with_an/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mglmg7/gan_image_editing_in_realtime_with_an/,66146,1617126282.0,0,,False,,,,,,,
,deeplearning,"I use keras tuner on digit recognise for optimize hyperparameter 
During running ii got warning 
'''
  5/756 [..............................] - ETA: 22s - loss: 2.3031 - accuracy: 0.0973WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0068s vs `on_train_batch_end` time: 0.0203s). Check your callbacks.
'''
Here it's [code](https://stackoverflow.com/questions/66818735/i-got-runtime-error-on-use-of-random-search-keras-tuner-for-optimization)",t2_5vklt5m5,False,,0,False,I got warning during keras-tuner.search(),[],r/deeplearning,False,6,,0,,False,t3_mglc5x,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617154285.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I use keras tuner on digit recognise for optimize hyperparameter 
During running ii got warning 
&amp;#39;&amp;#39;&amp;#39;
  5/756 [..............................] - ETA: 22s - loss: 2.3031 - accuracy: 0.0973WARNING:tensorflow:Callback method &lt;code&gt;on_train_batch_end&lt;/code&gt; is slow compared to the batch time (batch time: 0.0068s vs &lt;code&gt;on_train_batch_end&lt;/code&gt; time: 0.0203s). Check your callbacks.
&amp;#39;&amp;#39;&amp;#39;
Here it&amp;#39;s &lt;a href=""https://stackoverflow.com/questions/66818735/i-got-runtime-error-on-use-of-random-search-keras-tuner-for-optimization""&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mglc5x,True,,seeon321,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mglc5x/i_got_warning_during_kerastunersearch/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mglc5x/i_got_warning_during_kerastunersearch/,66146,1617125485.0,0,,False,,,,,,,
,deeplearning,,t2_74seeqo6,False,,0,False,Best Image Captioning Implementation,[],r/deeplearning,False,6,,0,,False,t3_mgku1i,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1617152948.0,text,6,,,text,github.com,False,,,,,https://github.com/saahiluppal/catr,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mgku1i,True,,spenceowen,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mgku1i/best_image_captioning_implementation/,all_ads,False,https://github.com/saahiluppal/catr,66146,1617124148.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'computervision', 'selftext': '', 'author_fullname': 't2_74seeqo6', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Best Image Captioning Implementation', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/computervision', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mgkste', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Showcase', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1617152857.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'github.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://github.com/saahiluppal/catr', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '548b6866-850c-11eb-98a7-0e2238bc8f5f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2rfzn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#fdaad0', 'id': 'mgkste', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'spenceowen', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/computervision/comments/mgkste/best_image_captioning_implementation/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://github.com/saahiluppal/catr', 'subreddit_subscribers': 48824, 'created_utc': 1617124057.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_mgkste,,,,,
,deeplearning,"Hi  everyone, I'm currently trying to find a way to apply Reinforcement Learning/Deep Learning to an inventory management project, more specifically it's for an Order  Management System.

The warehouse  in my system is small scale, it manages multiple storages and is  designed for e-commerce websites, the website receives an order and  sends status to the warehouse, the system will begin the stock checking  and order processing process, as well as checking if there's a need for  restocking. The supplier will restock directly to the storages in my  system

I came across this article for reinforcement learning for multi-echelon inventory system: [How to Improve your Supply Chain with Deep Reinforcement Learning | by Christian Hubbs | Towards Data Science](https://towardsdatascience.com/deep-reinforcement-learning-for-supply-chain-optimization-3e4d99ad4b58)  
But  I haven't found any for single echelon yet, is there any article or  resource for reinforcement learning for single echelon that I can  research more ? I want to tackle the problem of predicting the policy  for restocking",t2_yr1f7r3,False,,0,False,Is there a reinforcement/deep learning method to find stock policy for single echelon inventory system ?,[],r/deeplearning,False,6,,0,,False,t3_mgansz,False,dark,0.86,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1617119158.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi  everyone, I&amp;#39;m currently trying to find a way to apply Reinforcement Learning/Deep Learning to an inventory management project, more specifically it&amp;#39;s for an Order  Management System.&lt;/p&gt;

&lt;p&gt;The warehouse  in my system is small scale, it manages multiple storages and is  designed for e-commerce websites, the website receives an order and  sends status to the warehouse, the system will begin the stock checking  and order processing process, as well as checking if there&amp;#39;s a need for  restocking. The supplier will restock directly to the storages in my  system&lt;/p&gt;

&lt;p&gt;I came across this article for reinforcement learning for multi-echelon inventory system: &lt;a href=""https://towardsdatascience.com/deep-reinforcement-learning-for-supply-chain-optimization-3e4d99ad4b58""&gt;How to Improve your Supply Chain with Deep Reinforcement Learning | by Christian Hubbs | Towards Data Science&lt;/a&gt;&lt;br/&gt;
But  I haven&amp;#39;t found any for single echelon yet, is there any article or  resource for reinforcement learning for single echelon that I can  research more ? I want to tackle the problem of predicting the policy  for restocking&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mgansz,True,,catInOrbit001,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mgansz/is_there_a_reinforcementdeep_learning_method_to/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mgansz/is_there_a_reinforcementdeep_learning_method_to/,66146,1617090358.0,0,,False,,,,,,,
,deeplearning,"Apologies for another ""which hardware"" question, but I couldn't really find an answer to the question directly in previous posts. 

While beginning to learn ML/DL, I have been using a combination of Google Colab and workstations available at my university, so I haven't yet had to make choices about hardware.

My current laptop (no GPU) is getting old, so I am in the processing of choosing an upgrade. And because I will spend most of the summer travelling (plus I prefer the flexibility of a laptop anyway), a desktop workstation is really out of the question. 

Taking this into account, I think clearly the best option would be a paid cloud compute option once the limitations of Google Colab begin to prove too restrictive. The trouble is because I haven't been learning ML/DL using my own hardware, I don't really have a consideration of the different requirements for the interactive work you do while writing code and running quick small scale tests, and the multi-hour/day unattended computation while training models. 

If using cloud compute, the latter would obviously be off-loaded, but what are the hardware requirements for the former? Would you do all of your interactive work - writing code, small tests etc, on the cloud service as well? Or on the laptop?

If the latter, what would the hardware requirements for the laptop be? 

The one particular preference I have for laptops is a large screen, so I'm currently looking really at the new XPS 17, the Razer Blade Pro 17, and the LG Gram 17. 

Quick max stats for each: 

* XPS 17: GPU (RTX 2060 6GB with Max-Q), RAM (64GB), CPU (i9-10885H, 8 cores 5.3GHz)
* Razer Blade Pro 17: GPU (RTX 3080 16GB), RAM (64GB), CPU (i7-10875H, 8 cores, 5.1GHz)
* LG Gram 17: GPU (Intel UHD 620 only, go Nvidia card), RAM (16GB), CPU (i7-8565U, 4.6GHz)

So, my questions would be, even if using cloud compute for large training runs, is a proper GPU still necessary? And if so, is the performance gap between the RTX 3080 and RTX 2060 relevant?",t2_1kq6gtol,False,,0,False,"If using a laptop + cloud compute, to what extent does the choice of laptop GPU matter?",[],r/deeplearning,False,6,,0,,False,t3_mgjftl,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617149200.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Apologies for another &amp;quot;which hardware&amp;quot; question, but I couldn&amp;#39;t really find an answer to the question directly in previous posts. &lt;/p&gt;

&lt;p&gt;While beginning to learn ML/DL, I have been using a combination of Google Colab and workstations available at my university, so I haven&amp;#39;t yet had to make choices about hardware.&lt;/p&gt;

&lt;p&gt;My current laptop (no GPU) is getting old, so I am in the processing of choosing an upgrade. And because I will spend most of the summer travelling (plus I prefer the flexibility of a laptop anyway), a desktop workstation is really out of the question. &lt;/p&gt;

&lt;p&gt;Taking this into account, I think clearly the best option would be a paid cloud compute option once the limitations of Google Colab begin to prove too restrictive. The trouble is because I haven&amp;#39;t been learning ML/DL using my own hardware, I don&amp;#39;t really have a consideration of the different requirements for the interactive work you do while writing code and running quick small scale tests, and the multi-hour/day unattended computation while training models. &lt;/p&gt;

&lt;p&gt;If using cloud compute, the latter would obviously be off-loaded, but what are the hardware requirements for the former? Would you do all of your interactive work - writing code, small tests etc, on the cloud service as well? Or on the laptop?&lt;/p&gt;

&lt;p&gt;If the latter, what would the hardware requirements for the laptop be? &lt;/p&gt;

&lt;p&gt;The one particular preference I have for laptops is a large screen, so I&amp;#39;m currently looking really at the new XPS 17, the Razer Blade Pro 17, and the LG Gram 17. &lt;/p&gt;

&lt;p&gt;Quick max stats for each: &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;XPS 17: GPU (RTX 2060 6GB with Max-Q), RAM (64GB), CPU (i9-10885H, 8 cores 5.3GHz)&lt;/li&gt;
&lt;li&gt;Razer Blade Pro 17: GPU (RTX 3080 16GB), RAM (64GB), CPU (i7-10875H, 8 cores, 5.1GHz)&lt;/li&gt;
&lt;li&gt;LG Gram 17: GPU (Intel UHD 620 only, go Nvidia card), RAM (16GB), CPU (i7-8565U, 4.6GHz)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, my questions would be, even if using cloud compute for large training runs, is a proper GPU still necessary? And if so, is the performance gap between the RTX 3080 and RTX 2060 relevant?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mgjftl,True,,HenryWu001,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/mgjftl/if_using_a_laptop_cloud_compute_to_what_extent/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mgjftl/if_using_a_laptop_cloud_compute_to_what_extent/,66146,1617120400.0,0,,False,,,,,,,
,deeplearning,"What does your intuition/experience/expertise tell you? Would I be able to train a CNN to solve a binary classification problem described below and expect a high accuracy (let's say &gt;90%)?

**The problem:** Predicting whether an image contains one type of texture (class 0) or it contains several textures and clear borders among them (class 1).

**The data:** High resolution (5 centimeters / pixel) agricultural imagery obtained via remote sensing (drone imaging). So pictures depicting different crops, weeds, roads, soil, bushes, etc. I would feed the model square images of 256x256px (or 128x128px).

**Examples** **of images**: (""neg"" is class 0 and ""pos"" is class 1) [https://imgur.com/a/gnKbncA](https://imgur.com/a/gnKbncA)",t2_9hg5hon1,False,,0,False,Can i solve this problems using CNNs?,[],r/deeplearning,False,6,,0,,False,t3_mghvkj,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617144998.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What does your intuition/experience/expertise tell you? Would I be able to train a CNN to solve a binary classification problem described below and expect a high accuracy (let&amp;#39;s say &amp;gt;90%)?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The problem:&lt;/strong&gt; Predicting whether an image contains one type of texture (class 0) or it contains several textures and clear borders among them (class 1).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The data:&lt;/strong&gt; High resolution (5 centimeters / pixel) agricultural imagery obtained via remote sensing (drone imaging). So pictures depicting different crops, weeds, roads, soil, bushes, etc. I would feed the model square images of 256x256px (or 128x128px).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples&lt;/strong&gt; &lt;strong&gt;of images&lt;/strong&gt;: (&amp;quot;neg&amp;quot; is class 0 and &amp;quot;pos&amp;quot; is class 1) &lt;a href=""https://imgur.com/a/gnKbncA""&gt;https://imgur.com/a/gnKbncA&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mghvkj,True,,StandardDull3128,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mghvkj/can_i_solve_this_problems_using_cnns/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mghvkj/can_i_solve_this_problems_using_cnns/,66146,1617116198.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,A friendly approach to maths and coding in ML (2021-updated),[],r/deeplearning,False,6,,0,,False,t3_mgg6e6,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1617140144.0,text,6,,,text,github.com,False,,,,,https://github.com/louisfb01/start-machine-learning-in-2020,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mgg6e6,True,,OnlyProggingForFun,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mgg6e6/a_friendly_approach_to_maths_and_coding_in_ml/,all_ads,False,https://github.com/louisfb01/start-machine-learning-in-2020,66146,1617111344.0,0,,False,,,,,,,
,deeplearning,"I trained a VAE on a dataset containing 1k images. The VAE itself is convolutional, downsamples 256x256 rgb images four times before reconstruction and uses both relu and BatchNorm Layers as well as ResNet-like Skip Connection prior and after the bottleneck. Input is normalized to unit scale and no data augmentation takes place. The modal consists in total roughly of about 5e6 parameters and the visual inspection of the reconstructed images look decent enough. This is represented for both training and validation runs by the orange curve. No overfitting occurs as far as I can tell. However, if I use the entire dataset, i.e. \~ 35k training images and 5k validation images, the same model performs like shown by the green curve. Taking into account only the lower validation plot, I had said, this is overfitting, although it would have struck me as odd, that the same model that performed decently on the 1k images dataset now overfits on a much larger dataset. But also the training loss shows a clear inflection point around epoch 15.

https://preview.redd.it/1yh10yel95q61.png?width=846&amp;format=png&amp;auto=webp&amp;s=8db4867ff3c6e334d2bf91a5addd80f29b0f50f6

Can somebody tell me a likely source of error here? Is the models capacity not large enough to sufficiently capture the complexity of the data? I dont think so, since I am using a s[ota convolutional VAE used by OpenAI](https://github.com/openai/DALL-E/blob/master/dall_e/encoder.py) for a dataset comprising millions of images.

The context is, that I am trying to learn a discrete vocabulary of latent codes, i.e. have a discrete learnable embedding to sort of quantize the otherwise continuous latent outputs of the encoder that are then used to reconstruct the input image via the decoder [cf. this code snippet](https://github.com/karpathy/deep-vector-quantization/blob/main/dvq/model/quantize.py). So the idea is not to generate random sampled from noise but to learn an efficient notebook, i.e. bottleneck that captures the essentials of the data set. The decoder then outputs a prob distribution for every pixel over the 255 possible values 8 bit images can take o. The KL (assuming a uniform prior to encourage uniform use of all possible vocabulary entries) is currently weighted with 1.

Any help would be appreciated. Thank you in advance",t2_3p3qqcr1,False,,0,False,"this is not overfitting but something else, right?",[],r/deeplearning,False,6,,0,,False,t3_mgd1up,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617129670.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I trained a VAE on a dataset containing 1k images. The VAE itself is convolutional, downsamples 256x256 rgb images four times before reconstruction and uses both relu and BatchNorm Layers as well as ResNet-like Skip Connection prior and after the bottleneck. Input is normalized to unit scale and no data augmentation takes place. The modal consists in total roughly of about 5e6 parameters and the visual inspection of the reconstructed images look decent enough. This is represented for both training and validation runs by the orange curve. No overfitting occurs as far as I can tell. However, if I use the entire dataset, i.e. ~ 35k training images and 5k validation images, the same model performs like shown by the green curve. Taking into account only the lower validation plot, I had said, this is overfitting, although it would have struck me as odd, that the same model that performed decently on the 1k images dataset now overfits on a much larger dataset. But also the training loss shows a clear inflection point around epoch 15.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/1yh10yel95q61.png?width=846&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8db4867ff3c6e334d2bf91a5addd80f29b0f50f6""&gt;https://preview.redd.it/1yh10yel95q61.png?width=846&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8db4867ff3c6e334d2bf91a5addd80f29b0f50f6&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Can somebody tell me a likely source of error here? Is the models capacity not large enough to sufficiently capture the complexity of the data? I dont think so, since I am using a s&lt;a href=""https://github.com/openai/DALL-E/blob/master/dall_e/encoder.py""&gt;ota convolutional VAE used by OpenAI&lt;/a&gt; for a dataset comprising millions of images.&lt;/p&gt;

&lt;p&gt;The context is, that I am trying to learn a discrete vocabulary of latent codes, i.e. have a discrete learnable embedding to sort of quantize the otherwise continuous latent outputs of the encoder that are then used to reconstruct the input image via the decoder &lt;a href=""https://github.com/karpathy/deep-vector-quantization/blob/main/dvq/model/quantize.py""&gt;cf. this code snippet&lt;/a&gt;. So the idea is not to generate random sampled from noise but to learn an efficient notebook, i.e. bottleneck that captures the essentials of the data set. The decoder then outputs a prob distribution for every pixel over the 255 possible values 8 bit images can take o. The KL (assuming a uniform prior to encourage uniform use of all possible vocabulary entries) is currently weighted with 1.&lt;/p&gt;

&lt;p&gt;Any help would be appreciated. Thank you in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mgd1up,True,,Sewing31,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mgd1up/this_is_not_overfitting_but_something_else_right/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mgd1up/this_is_not_overfitting_but_something_else_right/,66146,1617100870.0,0,,False,,,"{'1yh10yel95q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 123, 'x': 108, 'u': 'https://preview.redd.it/1yh10yel95q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0552d187286445e50f116d2a1b53c9e830d8c2a6'}, {'y': 247, 'x': 216, 'u': 'https://preview.redd.it/1yh10yel95q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fafc90ed4cc93a371d4f3786a001e6227d81a24e'}, {'y': 366, 'x': 320, 'u': 'https://preview.redd.it/1yh10yel95q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ebf1ac4b45d74afa3d8758e707dd6374dd6e4bd'}, {'y': 732, 'x': 640, 'u': 'https://preview.redd.it/1yh10yel95q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b8093647317c7340ca5a4ffba9cdda7d3a172c2e'}], 's': {'y': 968, 'x': 846, 'u': 'https://preview.redd.it/1yh10yel95q61.png?width=846&amp;format=png&amp;auto=webp&amp;s=8db4867ff3c6e334d2bf91a5addd80f29b0f50f6'}, 'id': '1yh10yel95q61'}}",,,,
,deeplearning,,t2_1478qv,False,,0,False,[Noob Question] Is this the final testing accuracy for pytorch?,[],r/deeplearning,False,6,,0,,False,t3_mg99li,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1617112914.0,text,6,,,text,self.MLQuestions,False,,,,,/r/MLQuestions/comments/mg8z98/noob_question_is_this_the_final_testing_accuracy/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mg99li,True,,muiz1,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mg99li/noob_question_is_this_the_final_testing_accuracy/,all_ads,False,/r/MLQuestions/comments/mg8z98/noob_question_is_this_the_final_testing_accuracy/,66146,1617084114.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MLQuestions', 'selftext': '[deleted]', 'user_reports': [], 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[Noob Question] Is this the final testing accuracy for pytorch?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MLQuestions', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mg8z98', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': '', 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'thumbnail': '', 'edited': 1617085468.0, 'author_flair_css_class': None, 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1617111716.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': 'deleted', 'banned_by': None, 'domain': 'self.MLQuestions', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_30rel', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mg8z98', 'is_robot_indexable': False, 'stickied': False, 'author': '[deleted]', 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_flair_text_color': 'dark', 'permalink': '/r/MLQuestions/comments/mg8z98/noob_question_is_this_the_final_testing_accuracy/', 'parent_whitelist_status': 'all_ads', 'report_reasons': None, 'url': 'https://www.reddit.com/r/MLQuestions/comments/mg8z98/noob_question_is_this_the_final_testing_accuracy/', 'subreddit_subscribers': 32384, 'created_utc': 1617082916.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_mg8z98,,,,,
,deeplearning," Our research group (SWAT Lab., Polytechnique Montréal under supervision of Prof. Foutse Khomh) is conducting a survey on “Design Smells in Deep Learning Programs”. We have prepared an online survey that takes around 5-10 minutes to complete asking about relevance and severity of observed design issues in DL programs. 

We are looking for participants who have a strong background and experience in research/ development of Deep Learning programs (specially convolutional networks-CNNs). Please feel free to participate if you find yourself eligible. Moreover, you could kindly share this survey with colleagues/friends who you consider eligible to participate.

The results of this survey will be publicly accessible through arXiv.org in anonymized form. At no point in the survey will we ask you for your name, and we will not be logging your IP address to allow anonymity. If you would like to know more about this study, feel free to contact us with your questions.

Link: [https://forms.gle/Yedpq3Dx8tAoxYkL8](https://forms.gle/Yedpq3Dx8tAoxYkL8)

We really appreciate your time and support!

Best regards,

Amin Nikanjam (amin.nikanjam@polymtl.ca),

Foutse Khomh

SWAT Lab., Polytechnique Montréal, Montréal, Canada, [http://swat.polymtl.ca/](http://swat.polymtl.ca/)",t2_82tley41,False,,0,False,"A survey on ""Design Smells in Deep Learning Programs""",[],r/deeplearning,False,6,,0,,False,t3_mfqf4g,False,dark,0.94,,public,16,1,{},,False,[],,False,False,,{},,False,16,,False,False,,False,,[],{},,True,,1617055923.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Our research group (SWAT Lab., Polytechnique Montréal under supervision of Prof. Foutse Khomh) is conducting a survey on “Design Smells in Deep Learning Programs”. We have prepared an online survey that takes around 5-10 minutes to complete asking about relevance and severity of observed design issues in DL programs. &lt;/p&gt;

&lt;p&gt;We are looking for participants who have a strong background and experience in research/ development of Deep Learning programs (specially convolutional networks-CNNs). Please feel free to participate if you find yourself eligible. Moreover, you could kindly share this survey with colleagues/friends who you consider eligible to participate.&lt;/p&gt;

&lt;p&gt;The results of this survey will be publicly accessible through arXiv.org in anonymized form. At no point in the survey will we ask you for your name, and we will not be logging your IP address to allow anonymity. If you would like to know more about this study, feel free to contact us with your questions.&lt;/p&gt;

&lt;p&gt;Link: &lt;a href=""https://forms.gle/Yedpq3Dx8tAoxYkL8""&gt;https://forms.gle/Yedpq3Dx8tAoxYkL8&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We really appreciate your time and support!&lt;/p&gt;

&lt;p&gt;Best regards,&lt;/p&gt;

&lt;p&gt;Amin Nikanjam (&lt;a href=""mailto:amin.nikanjam@polymtl.ca""&gt;amin.nikanjam@polymtl.ca&lt;/a&gt;),&lt;/p&gt;

&lt;p&gt;Foutse Khomh&lt;/p&gt;

&lt;p&gt;SWAT Lab., Polytechnique Montréal, Montréal, Canada, &lt;a href=""http://swat.polymtl.ca/""&gt;http://swat.polymtl.ca/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mfqf4g,True,,aminnikanjam,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mfqf4g/a_survey_on_design_smells_in_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mfqf4g/a_survey_on_design_smells_in_deep_learning/,66146,1617027123.0,2,,False,,,,,,,
,deeplearning,"Hello (noob here)
I am trying to create a program that looks at a database of recipes and then begins to create its own recipes. I am not sure where to start. Any guidance would be greatly appreciated!",t2_340idtgr,False,,0,False,Recipe Generating Project Help (NOOB),[],r/deeplearning,False,6,,0,,False,t3_mg1dva,False,dark,1.0,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1617085906.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello (noob here)
I am trying to create a program that looks at a database of recipes and then begins to create its own recipes. I am not sure where to start. Any guidance would be greatly appreciated!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mg1dva,True,,shuacity,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mg1dva/recipe_generating_project_help_noob/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mg1dva/recipe_generating_project_help_noob/,66146,1617057106.0,0,,False,,,,,,,
,deeplearning,,t2_10fm9o,False,,0,False,[R] Swin Transformer: New SOTA backbone for Computer Vision🔥,[],r/deeplearning,False,6,,0,,False,t3_mfoefx,False,dark,0.83,,public,16,0,{},,False,[],,False,False,,{},,False,16,,False,False,,False,,[],{},,False,,1617049394.0,text,6,,,text,self.MachineLearning,False,,,,,/r/MachineLearning/comments/mfo8xo/r_swin_transformer_new_sota_backbone_for_computer/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mfoefx,True,,temakone,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mfoefx/r_swin_transformer_new_sota_backbone_for_computer/,all_ads,False,/r/MachineLearning/comments/mfo8xo/r_swin_transformer_new_sota_backbone_for_computer/,66146,1617020594.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'MachineLearning', 'selftext': '**Swin Transformer: New SOTA backbone for Computer Vision** 🔥*MS Research Asia*\n\n# 👉 What?\n\nNew vision Transformer architecture called Swin Transformer that can serve as a backbone in computer vision instead of CNNs.\n\n# ❓Why?\n\nThere are two main problems with the usage of Transformers for computer vision.\n\n1. Existing Transformer-based models have tokens of a fixed scale. However, in contrast to the word tokens, visual elements can be different in scale (e.g. objects of varying sizes on the scene)\n2. Regular self-attention requires quadratic of the image size number of operations, limiting applications in computer vision where high resolution is necessary (e.g., instance segmentation).\n\n# 🥊 The main ideas of the Swin Transformers:\n\n1. **Hierarchical feature maps** where at each level of hierarchy Self-attention is applied within local non-overlapping windows. The size of the windows is progressively increased with the network depth (inspired by CNNs). This enables building architectures similar to feature pyramid networks (FPN) or U-Net for dense pixel-level tasks.\n2. **Window-based Self-attention** reduces the computational overhead.\n\n# ⚙️ Overall Architecture consists of repeating the following blocks:\n\n\\- Split RGB image into non-overlapping patches (tokens).\n\n\\- Apply MLP to translate raw features into an arbitrary dimension.\n\n\\- Apply 2 consecutive Swin Transformer blocks with Window self-attention: **both blocks have the same window size, but the second block uses shifted by \\`patch\\_size/2\\` windows which allows information flow between non-overlapping windows**.\n\n\\- Downsampling layer: Reduce the number of tokens by merging neighboring patches in a 2x2 window, and double the feature depth.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/xtjhyflalyp61.png?width=1920&amp;format=png&amp;auto=webp&amp;s=b0f8539b4e1779ba8263281e4ff2974562858c0d\n\n&amp;#x200B;\n\nhttps://preview.redd.it/z95z4ycclyp61.png?width=1010&amp;format=png&amp;auto=webp&amp;s=0e27b6b8fb511da3be3b9647da4bacd2b8411dc3\n\n# 🦾 Results\n\n\\+ **Outperforms SOTA by a significant margin on COCO segmentation and detection tasks and ADE20K segmentation.**\n\n\\+ **Comparable accuracy to the EfficientNet** family on ImageNet-1K classification, while being faster.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/giw5nz4dlyp61.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=d8eb93e37dd44ee75e7476c584d41fb14d3b760a\n\n# 👌Conclusion\n\nWhile Transformers are super flexible, researchers start to **inject in Transformers inductive biases similar to those in CNNs**, e.g., local connectivity, feature hierarchies. And this seems to help tremendously!\n\n&amp;#x200B;\n\n📝 Paper [https://arxiv.org/abs/2103.14030](https://arxiv.org/abs/2103.14030)\n\n⚒ Code (promissed soon) [https://github.com/microsoft/Swin-Transformer](https://github.com/microsoft/Swin-Transformer)\n\n🌐 TL;DR blogpost [https://xzcodes.github.io/posts/paper-review-swin-transformer](https://xzcodes.github.io/posts/paper-review-swin-transformer)\n\n\\--\n\n👉  Join my Telegram channel [""Gradient Dude""](https://t.me/gradientdude) not to miss the latest posts like this [https://t.me/gradientdude](https://t.me/gradientdude)', 'author_fullname': 't2_10fm9o', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '[R] Swin Transformer: New SOTA backbone for Computer Vision🔥', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/MachineLearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': 'three', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'giw5nz4dlyp61': {'status': 'valid', 'e': 'Image', 'm': 'image/jpg', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/giw5nz4dlyp61.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c177fcee6e3a5778a87205ff4a8cb31a1f66462f'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/giw5nz4dlyp61.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e18ffd36113b8cd0e6227259f6b8a8e0b679b280'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/giw5nz4dlyp61.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9e2c1070caa9faf1d3eb5ef01dc16b8eb23a239b'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/giw5nz4dlyp61.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=11d5988d4bf13251ace88499324cbb4b6759b6c7'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/giw5nz4dlyp61.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b818aaa1a04b703a080916d2f8df090c0e53dc50'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/giw5nz4dlyp61.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=fd32aaa8d679a7d70871684ef5f9fde0a31302a4'}], 's': {'y': 1080, 'x': 1920, 'u': 'https://preview.redd.it/giw5nz4dlyp61.jpg?width=1920&amp;format=pjpg&amp;auto=webp&amp;s=d8eb93e37dd44ee75e7476c584d41fb14d3b760a'}, 'id': 'giw5nz4dlyp61'}, 'z95z4ycclyp61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 80, 'x': 108, 'u': 'https://preview.redd.it/z95z4ycclyp61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ec2f15315ef1674788f47d9f6865bdddfa0e76a2'}, {'y': 161, 'x': 216, 'u': 'https://preview.redd.it/z95z4ycclyp61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0ff0f27e66a620862262a0981e3f5d40e38e1590'}, {'y': 238, 'x': 320, 'u': 'https://preview.redd.it/z95z4ycclyp61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a8b4c1227958fc6ab10355bc3e2af97e42a97377'}, {'y': 477, 'x': 640, 'u': 'https://preview.redd.it/z95z4ycclyp61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a021ac67b4ba8398f543ee9375c2576edeb8e2e0'}, {'y': 715, 'x': 960, 'u': 'https://preview.redd.it/z95z4ycclyp61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=1c7ad880abb5300ffa50b8a7bd12904c4ef2aff1'}], 's': {'y': 753, 'x': 1010, 'u': 'https://preview.redd.it/z95z4ycclyp61.png?width=1010&amp;format=png&amp;auto=webp&amp;s=0e27b6b8fb511da3be3b9647da4bacd2b8411dc3'}, 'id': 'z95z4ycclyp61'}, 'xtjhyflalyp61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 60, 'x': 108, 'u': 'https://preview.redd.it/xtjhyflalyp61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a79d46ccc37acf384b047bee3f1723297b4112a8'}, {'y': 121, 'x': 216, 'u': 'https://preview.redd.it/xtjhyflalyp61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=41375f6660237ee6160b02a2078ab0db6da2cd19'}, {'y': 180, 'x': 320, 'u': 'https://preview.redd.it/xtjhyflalyp61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e7aa7af10d46795ed667a8552369a1d82ce11300'}, {'y': 360, 'x': 640, 'u': 'https://preview.redd.it/xtjhyflalyp61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4c6c5d22b0d672089c618e9dc4c22c87c11c9146'}, {'y': 540, 'x': 960, 'u': 'https://preview.redd.it/xtjhyflalyp61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bc745e9c0c55731ba5b3992ef3858308851683fa'}, {'y': 607, 'x': 1080, 'u': 'https://preview.redd.it/xtjhyflalyp61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=55229284d252c58aecbfeffd2723153bb1d53930'}], 's': {'y': 1080, 'x': 1920, 'u': 'https://preview.redd.it/xtjhyflalyp61.png?width=1920&amp;format=png&amp;auto=webp&amp;s=b0f8539b4e1779ba8263281e4ff2974562858c0d'}, 'id': 'xtjhyflalyp61'}}, 'name': 't3_mfo8xo', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.77, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 54, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Research', 'can_mod_post': False, 'score': 54, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': 1617062000.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1617048921.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.MachineLearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;strong&gt;Swin Transformer: New SOTA backbone for Computer Vision&lt;/strong&gt; 🔥&lt;em&gt;MS Research Asia&lt;/em&gt;&lt;/p&gt;\n\n&lt;h1&gt;👉 What?&lt;/h1&gt;\n\n&lt;p&gt;New vision Transformer architecture called Swin Transformer that can serve as a backbone in computer vision instead of CNNs.&lt;/p&gt;\n\n&lt;h1&gt;❓Why?&lt;/h1&gt;\n\n&lt;p&gt;There are two main problems with the usage of Transformers for computer vision.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Existing Transformer-based models have tokens of a fixed scale. However, in contrast to the word tokens, visual elements can be different in scale (e.g. objects of varying sizes on the scene)&lt;/li&gt;\n&lt;li&gt;Regular self-attention requires quadratic of the image size number of operations, limiting applications in computer vision where high resolution is necessary (e.g., instance segmentation).&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;🥊 The main ideas of the Swin Transformers:&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Hierarchical feature maps&lt;/strong&gt; where at each level of hierarchy Self-attention is applied within local non-overlapping windows. The size of the windows is progressively increased with the network depth (inspired by CNNs). This enables building architectures similar to feature pyramid networks (FPN) or U-Net for dense pixel-level tasks.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Window-based Self-attention&lt;/strong&gt; reduces the computational overhead.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;⚙️ Overall Architecture consists of repeating the following blocks:&lt;/h1&gt;\n\n&lt;p&gt;- Split RGB image into non-overlapping patches (tokens).&lt;/p&gt;\n\n&lt;p&gt;- Apply MLP to translate raw features into an arbitrary dimension.&lt;/p&gt;\n\n&lt;p&gt;- Apply 2 consecutive Swin Transformer blocks with Window self-attention: &lt;strong&gt;both blocks have the same window size, but the second block uses shifted by `patch_size/2` windows which allows information flow between non-overlapping windows&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;- Downsampling layer: Reduce the number of tokens by merging neighboring patches in a 2x2 window, and double the feature depth.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/xtjhyflalyp61.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b0f8539b4e1779ba8263281e4ff2974562858c0d""&gt;https://preview.redd.it/xtjhyflalyp61.png?width=1920&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b0f8539b4e1779ba8263281e4ff2974562858c0d&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/z95z4ycclyp61.png?width=1010&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0e27b6b8fb511da3be3b9647da4bacd2b8411dc3""&gt;https://preview.redd.it/z95z4ycclyp61.png?width=1010&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0e27b6b8fb511da3be3b9647da4bacd2b8411dc3&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;🦾 Results&lt;/h1&gt;\n\n&lt;p&gt;+ &lt;strong&gt;Outperforms SOTA by a significant margin on COCO segmentation and detection tasks and ADE20K segmentation.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;+ &lt;strong&gt;Comparable accuracy to the EfficientNet&lt;/strong&gt; family on ImageNet-1K classification, while being faster.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://preview.redd.it/giw5nz4dlyp61.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d8eb93e37dd44ee75e7476c584d41fb14d3b760a""&gt;https://preview.redd.it/giw5nz4dlyp61.jpg?width=1920&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=d8eb93e37dd44ee75e7476c584d41fb14d3b760a&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;👌Conclusion&lt;/h1&gt;\n\n&lt;p&gt;While Transformers are super flexible, researchers start to &lt;strong&gt;inject in Transformers inductive biases similar to those in CNNs&lt;/strong&gt;, e.g., local connectivity, feature hierarchies. And this seems to help tremendously!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;📝 Paper &lt;a href=""https://arxiv.org/abs/2103.14030""&gt;https://arxiv.org/abs/2103.14030&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;⚒ Code (promissed soon) &lt;a href=""https://github.com/microsoft/Swin-Transformer""&gt;https://github.com/microsoft/Swin-Transformer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;🌐 TL;DR blogpost &lt;a href=""https://xzcodes.github.io/posts/paper-review-swin-transformer""&gt;https://xzcodes.github.io/posts/paper-review-swin-transformer&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;--&lt;/p&gt;\n\n&lt;p&gt;👉  Join my Telegram channel &lt;a href=""https://t.me/gradientdude""&gt;&amp;quot;Gradient Dude&amp;quot;&lt;/a&gt; not to miss the latest posts like this &lt;a href=""https://t.me/gradientdude""&gt;https://t.me/gradientdude&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2r3gv', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mfo8xo', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'temakone', 'discussion_type': None, 'num_comments': 34, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/MachineLearning/comments/mfo8xo/r_swin_transformer_new_sota_backbone_for_computer/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/MachineLearning/comments/mfo8xo/r_swin_transformer_new_sota_backbone_for_computer/', 'subreddit_subscribers': 1931406, 'created_utc': 1617020121.0, 'num_crossposts': 2, 'media': None, 'is_video': False}]",t3_mfo8xo,,,,,
,deeplearning,[https://youtu.be/8tZZoX5ct0I](https://youtu.be/8tZZoX5ct0I),t2_ay68q22i,False,,0,False,"AI Weekly Update - March 29th, 2021 (#30)!",[],r/deeplearning,False,6,,0,,False,t3_mfuktx,False,dark,1.0,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1617067382.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://youtu.be/8tZZoX5ct0I""&gt;https://youtu.be/8tZZoX5ct0I&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mfuktx,True,,stoicpath30,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mfuktx/ai_weekly_update_march_29th_2021_30/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mfuktx/ai_weekly_update_march_29th_2021_30/,66146,1617038582.0,0,,False,,,,,,,
,deeplearning,"This tutorial covers how to use federated learning to train a Keras model. 

To keep user data private but still use it to train machine learning models, privacy-preserving machine learning has been on the rise. Federated learning is a client-server paradigm in which some clients train a global model with private user data, without sharing it to a centralized server.

The example discussed here has just 2 clients, where they work together to train a model that builds the XOR gate. You can easily use the project with other data as well, by just swapping out two arrays. 

The topics discussed include:

* Review of Federated Learning
* Preparing the Training Data
* Building the Keras Model
* Building a Population of Solutions
* Listening to Connections at the Server
* Server Reply to Client Request
* Client Behavior
* Conclusion

Tutorial link: [https://blog.paperspace.com/federated-learning-with-keras/](https://blog.paperspace.com/federated-learning-with-keras/)

Comments and questions welcome!",t2_15en0l,False,,0,False,[Tutorial] Federated Machine Learning With Keras,[],r/deeplearning,False,6,,0,,False,t3_mfrr51,False,dark,0.67,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1617059702.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This tutorial covers how to use federated learning to train a Keras model. &lt;/p&gt;

&lt;p&gt;To keep user data private but still use it to train machine learning models, privacy-preserving machine learning has been on the rise. Federated learning is a client-server paradigm in which some clients train a global model with private user data, without sharing it to a centralized server.&lt;/p&gt;

&lt;p&gt;The example discussed here has just 2 clients, where they work together to train a model that builds the XOR gate. You can easily use the project with other data as well, by just swapping out two arrays. &lt;/p&gt;

&lt;p&gt;The topics discussed include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Review of Federated Learning&lt;/li&gt;
&lt;li&gt;Preparing the Training Data&lt;/li&gt;
&lt;li&gt;Building the Keras Model&lt;/li&gt;
&lt;li&gt;Building a Population of Solutions&lt;/li&gt;
&lt;li&gt;Listening to Connections at the Server&lt;/li&gt;
&lt;li&gt;Server Reply to Client Request&lt;/li&gt;
&lt;li&gt;Client Behavior&lt;/li&gt;
&lt;li&gt;Conclusion&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tutorial link: &lt;a href=""https://blog.paperspace.com/federated-learning-with-keras/""&gt;https://blog.paperspace.com/federated-learning-with-keras/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Comments and questions welcome!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mfrr51,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mfrr51/tutorial_federated_machine_learning_with_keras/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mfrr51/tutorial_federated_machine_learning_with_keras/,66146,1617030902.0,1,,False,,,,,,,
,deeplearning,"Hi, Folks!

I want to ask about the packages and libraries you are using for deep learning. The desktop app we made (shameless promotion) - [Devbook](https://usedevbook.com/) is a really fast way to search documentation and Stack Overflow, with minimal context switching and no distractions. We want to focus on supporting the whole data science/ML stack - so far we added NumPy and PyTorch and we are working on adding Pandas, but we do not have that much data about what people really use and metrics like GitHub stars seem not that accurate to rely on.

Some folks mentioned that PySpark and PyArrow docs are bad - are there some other services that you think have bad documentation and you still have to work with them? Or are there any libraries or services that are just bad, but you still have to use them?

Thank you for any feedback, I will hang around in the comments.",t2_63of33cb,False,,0,False,What are the packages and libraries you are using the most? Are any of them a pain to use?,[],r/deeplearning,False,6,,0,,False,t3_mfwli4,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1617072778.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, Folks!&lt;/p&gt;

&lt;p&gt;I want to ask about the packages and libraries you are using for deep learning. The desktop app we made (shameless promotion) - &lt;a href=""https://usedevbook.com/""&gt;Devbook&lt;/a&gt; is a really fast way to search documentation and Stack Overflow, with minimal context switching and no distractions. We want to focus on supporting the whole data science/ML stack - so far we added NumPy and PyTorch and we are working on adding Pandas, but we do not have that much data about what people really use and metrics like GitHub stars seem not that accurate to rely on.&lt;/p&gt;

&lt;p&gt;Some folks mentioned that PySpark and PyArrow docs are bad - are there some other services that you think have bad documentation and you still have to work with them? Or are there any libraries or services that are just bad, but you still have to use them?&lt;/p&gt;

&lt;p&gt;Thank you for any feedback, I will hang around in the comments.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mfwli4,True,,ValentaTomas,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/mfwli4/what_are_the_packages_and_libraries_you_are_using/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mfwli4/what_are_the_packages_and_libraries_you_are_using/,66146,1617043978.0,0,,False,,,,,,,
,deeplearning,I want to compute the Inception score for a 3d model. As the IS defined on  **Inception**\-**v3**  which is a 2D network so how I can compute the IS for 3d Images?,t2_acrkzytr,False,,0,False,How to compute Inception score for 3d GAN,[],r/deeplearning,False,6,,0,,False,t3_mfoj9r,False,dark,0.87,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1617049852.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to compute the Inception score for a 3d model. As the IS defined on  &lt;strong&gt;Inception&lt;/strong&gt;-&lt;strong&gt;v3&lt;/strong&gt;  which is a 2D network so how I can compute the IS for 3d Images?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mfoj9r,True,,Bazangani,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mfoj9r/how_to_compute_inception_score_for_3d_gan/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mfoj9r/how_to_compute_inception_score_for_3d_gan/,66146,1617021052.0,0,,False,,,,,,,
,deeplearning,"so to begin with, this is a project I am helping my school with to gain experience.  I have taken plenty of [deeplearning.AI](https://deeplearning.AI) courses which helped me build this codes foundation. 

The data is from a chat bot which provides the chat text, ANGRY labels and HAPPY labels which were going to feed into the model.

&amp;#x200B;

https://preview.redd.it/ogws4rt0x0q61.png?width=1752&amp;format=png&amp;auto=webp&amp;s=d9dff151bf875ba1a84ca3cea07515d900efe122

Next up is the data preprocessing which includes splitting the data 80/20 for training and evaluation.

&amp;#x200B;

https://preview.redd.it/n8vs4re3x0q61.png?width=1464&amp;format=png&amp;auto=webp&amp;s=5d3385ef1d99158f5717406cebc5fdf860becc1c

The I preprocess the text by removing special characters, spaces, stop words, and tokenizing text like so:

&amp;#x200B;

https://preview.redd.it/04b6yeq4x0q61.png?width=1436&amp;format=png&amp;auto=webp&amp;s=7d8723b64a35e588d95ce6d853e3c885f78a2eae

Next up I build the vocab list like so:

&amp;#x200B;

https://preview.redd.it/rb36e8g7x0q61.png?width=1218&amp;format=png&amp;auto=webp&amp;s=3fc9c0bd2199a60f1c2862dec39f31a32c872231

Then create padded tensors for each sentence:

&amp;#x200B;

https://preview.redd.it/vpem1zt9x0q61.png?width=1310&amp;format=png&amp;auto=webp&amp;s=d941d9e101a777d7cae3e403099795a40d1a59a2

Afterwards create the data generator that we can apply to training and evaluation.

&amp;#x200B;

https://preview.redd.it/65wfgvobx0q61.png?width=1310&amp;format=png&amp;auto=webp&amp;s=f03a12cec2b7cc819aed1f77b4a4586821703fba

&amp;#x200B;

https://preview.redd.it/3wtiduycx0q61.png?width=1304&amp;format=png&amp;auto=webp&amp;s=be0fde9234e9260f0f2f6d7cd0a000e54369c0dd

&amp;#x200B;

https://preview.redd.it/ra0mijkex0q61.png?width=1404&amp;format=png&amp;auto=webp&amp;s=2bb5e17ce3fd97683967757b717a50b4501fcd3a

&amp;#x200B;

https://preview.redd.it/st97kz2hx0q61.png?width=1352&amp;format=png&amp;auto=webp&amp;s=426abbad82faab0ed99afb22fbfbff0d1507da94

&amp;#x200B;

https://preview.redd.it/infaivfix0q61.png?width=1746&amp;format=png&amp;auto=webp&amp;s=dfd8ca115b1316b0aa981b282ccbe09462fc2344

&amp;#x200B;

https://preview.redd.it/skth68flx0q61.png?width=1378&amp;format=png&amp;auto=webp&amp;s=24f57fa8431650fb7522f92620ed1eb30ddcae44

I then start to create the layers by forward propagation from one layer to the next neighing with a relu activation function

&amp;#x200B;

https://preview.redd.it/tqq2os2px0q61.png?width=1124&amp;format=png&amp;auto=webp&amp;s=5d5faa20885124147a87f41462ecc08abf78a1f5

Defining the Dense Layer:

&amp;#x200B;

https://preview.redd.it/xapdrklqx0q61.png?width=1336&amp;format=png&amp;auto=webp&amp;s=2f19de71e9838b2b222cbbcf6600dc429ddbc4a2

&amp;#x200B;

https://preview.redd.it/har0whisx0q61.png?width=1364&amp;format=png&amp;auto=webp&amp;s=afbd68945ee068b278ac5a929694509e10e97297

The next step we will define our model by using Trax and combining all our layers!

&amp;#x200B;

https://preview.redd.it/3of2n7stx0q61.png?width=1256&amp;format=png&amp;auto=webp&amp;s=8cdc60c3b866b0ec7d5da0d8631e317c6b0eb7c4

&amp;#x200B;

https://preview.redd.it/gq17v0uux0q61.png?width=1584&amp;format=png&amp;auto=webp&amp;s=16f05ee8bc29212e848ee4707083646f39d8e51c

I have created training and evaluation loops that will help us understand how our model is performing

&amp;#x200B;

https://preview.redd.it/17o28ebxx0q61.png?width=1118&amp;format=png&amp;auto=webp&amp;s=f555dd8b6b91f6d295ecf282696dd7ad466caf5d

**Next up we will check out the models accuracy, I know its pretty low but currently a learning student looking to improve and excited on some feedback to help improve this model.** 

&amp;#x200B;

https://preview.redd.it/lea5dqxzx0q61.png?width=1274&amp;format=png&amp;auto=webp&amp;s=76e57c31ac18b083ffc20609b693b4b850990c67

&amp;#x200B;

https://preview.redd.it/2xiopd61y0q61.png?width=1882&amp;format=png&amp;auto=webp&amp;s=ffd05102a1eb445bf47c95b2c361a39bb0977c09

As you can see this model is performing at 67%, The following is the code that I need help with. I am trying to print the observed sentence followed by the prediction. I have tried to do it but am not getting 2 output prediction for ANGRY and HAPPY labels. 

The purpose is to help understand if a customer is either angry or happy with the bot customer experience and also identify if interference is needed from an agent. 

&amp;#x200B;

https://preview.redd.it/l5qony34y0q61.png?width=1342&amp;format=png&amp;auto=webp&amp;s=1c12bf97133b9a31ef3691cf2fc9651a1f5e510b

Instead of getting 2 predicting labels this is what my output looks like. 

**I would greatly appreciate any help and welcome any ML mentors for this project**.

&amp;#x200B;

Thanks for looking everyone, and can't wait to hear from you all!",t2_9cq8fw1e,False,,0,False,"[P] Need Help with my neural network model using google Trax, I can't seem to figure out how to print the prediction outputs! (Please check out my code bellow)!",[],r/deeplearning,False,6,,0,,False,t3_mfyd2r,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617077501.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;so to begin with, this is a project I am helping my school with to gain experience.  I have taken plenty of &lt;a href=""https://deeplearning.AI""&gt;deeplearning.AI&lt;/a&gt; courses which helped me build this codes foundation. &lt;/p&gt;

&lt;p&gt;The data is from a chat bot which provides the chat text, ANGRY labels and HAPPY labels which were going to feed into the model.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ogws4rt0x0q61.png?width=1752&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d9dff151bf875ba1a84ca3cea07515d900efe122""&gt;https://preview.redd.it/ogws4rt0x0q61.png?width=1752&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d9dff151bf875ba1a84ca3cea07515d900efe122&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Next up is the data preprocessing which includes splitting the data 80/20 for training and evaluation.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/n8vs4re3x0q61.png?width=1464&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5d3385ef1d99158f5717406cebc5fdf860becc1c""&gt;https://preview.redd.it/n8vs4re3x0q61.png?width=1464&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5d3385ef1d99158f5717406cebc5fdf860becc1c&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The I preprocess the text by removing special characters, spaces, stop words, and tokenizing text like so:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/04b6yeq4x0q61.png?width=1436&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7d8723b64a35e588d95ce6d853e3c885f78a2eae""&gt;https://preview.redd.it/04b6yeq4x0q61.png?width=1436&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7d8723b64a35e588d95ce6d853e3c885f78a2eae&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Next up I build the vocab list like so:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/rb36e8g7x0q61.png?width=1218&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3fc9c0bd2199a60f1c2862dec39f31a32c872231""&gt;https://preview.redd.it/rb36e8g7x0q61.png?width=1218&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=3fc9c0bd2199a60f1c2862dec39f31a32c872231&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Then create padded tensors for each sentence:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/vpem1zt9x0q61.png?width=1310&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d941d9e101a777d7cae3e403099795a40d1a59a2""&gt;https://preview.redd.it/vpem1zt9x0q61.png?width=1310&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d941d9e101a777d7cae3e403099795a40d1a59a2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Afterwards create the data generator that we can apply to training and evaluation.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/65wfgvobx0q61.png?width=1310&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f03a12cec2b7cc819aed1f77b4a4586821703fba""&gt;https://preview.redd.it/65wfgvobx0q61.png?width=1310&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f03a12cec2b7cc819aed1f77b4a4586821703fba&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/3wtiduycx0q61.png?width=1304&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=be0fde9234e9260f0f2f6d7cd0a000e54369c0dd""&gt;https://preview.redd.it/3wtiduycx0q61.png?width=1304&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=be0fde9234e9260f0f2f6d7cd0a000e54369c0dd&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ra0mijkex0q61.png?width=1404&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2bb5e17ce3fd97683967757b717a50b4501fcd3a""&gt;https://preview.redd.it/ra0mijkex0q61.png?width=1404&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2bb5e17ce3fd97683967757b717a50b4501fcd3a&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/st97kz2hx0q61.png?width=1352&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=426abbad82faab0ed99afb22fbfbff0d1507da94""&gt;https://preview.redd.it/st97kz2hx0q61.png?width=1352&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=426abbad82faab0ed99afb22fbfbff0d1507da94&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/infaivfix0q61.png?width=1746&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dfd8ca115b1316b0aa981b282ccbe09462fc2344""&gt;https://preview.redd.it/infaivfix0q61.png?width=1746&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=dfd8ca115b1316b0aa981b282ccbe09462fc2344&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/skth68flx0q61.png?width=1378&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=24f57fa8431650fb7522f92620ed1eb30ddcae44""&gt;https://preview.redd.it/skth68flx0q61.png?width=1378&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=24f57fa8431650fb7522f92620ed1eb30ddcae44&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I then start to create the layers by forward propagation from one layer to the next neighing with a relu activation function&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/tqq2os2px0q61.png?width=1124&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5d5faa20885124147a87f41462ecc08abf78a1f5""&gt;https://preview.redd.it/tqq2os2px0q61.png?width=1124&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5d5faa20885124147a87f41462ecc08abf78a1f5&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Defining the Dense Layer:&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/xapdrklqx0q61.png?width=1336&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2f19de71e9838b2b222cbbcf6600dc429ddbc4a2""&gt;https://preview.redd.it/xapdrklqx0q61.png?width=1336&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2f19de71e9838b2b222cbbcf6600dc429ddbc4a2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/har0whisx0q61.png?width=1364&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=afbd68945ee068b278ac5a929694509e10e97297""&gt;https://preview.redd.it/har0whisx0q61.png?width=1364&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=afbd68945ee068b278ac5a929694509e10e97297&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The next step we will define our model by using Trax and combining all our layers!&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/3of2n7stx0q61.png?width=1256&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8cdc60c3b866b0ec7d5da0d8631e317c6b0eb7c4""&gt;https://preview.redd.it/3of2n7stx0q61.png?width=1256&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8cdc60c3b866b0ec7d5da0d8631e317c6b0eb7c4&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/gq17v0uux0q61.png?width=1584&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=16f05ee8bc29212e848ee4707083646f39d8e51c""&gt;https://preview.redd.it/gq17v0uux0q61.png?width=1584&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=16f05ee8bc29212e848ee4707083646f39d8e51c&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I have created training and evaluation loops that will help us understand how our model is performing&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/17o28ebxx0q61.png?width=1118&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f555dd8b6b91f6d295ecf282696dd7ad466caf5d""&gt;https://preview.redd.it/17o28ebxx0q61.png?width=1118&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f555dd8b6b91f6d295ecf282696dd7ad466caf5d&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Next up we will check out the models accuracy, I know its pretty low but currently a learning student looking to improve and excited on some feedback to help improve this model.&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/lea5dqxzx0q61.png?width=1274&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=76e57c31ac18b083ffc20609b693b4b850990c67""&gt;https://preview.redd.it/lea5dqxzx0q61.png?width=1274&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=76e57c31ac18b083ffc20609b693b4b850990c67&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/2xiopd61y0q61.png?width=1882&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ffd05102a1eb445bf47c95b2c361a39bb0977c09""&gt;https://preview.redd.it/2xiopd61y0q61.png?width=1882&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ffd05102a1eb445bf47c95b2c361a39bb0977c09&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As you can see this model is performing at 67%, The following is the code that I need help with. I am trying to print the observed sentence followed by the prediction. I have tried to do it but am not getting 2 output prediction for ANGRY and HAPPY labels. &lt;/p&gt;

&lt;p&gt;The purpose is to help understand if a customer is either angry or happy with the bot customer experience and also identify if interference is needed from an agent. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/l5qony34y0q61.png?width=1342&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c12bf97133b9a31ef3691cf2fc9651a1f5e510b""&gt;https://preview.redd.it/l5qony34y0q61.png?width=1342&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=1c12bf97133b9a31ef3691cf2fc9651a1f5e510b&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Instead of getting 2 predicting labels this is what my output looks like. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;I would greatly appreciate any help and welcome any ML mentors for this project&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks for looking everyone, and can&amp;#39;t wait to hear from you all!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mfyd2r,True,,memgamemotron,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mfyd2r/p_need_help_with_my_neural_network_model_using/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mfyd2r/p_need_help_with_my_neural_network_model_using/,66146,1617048701.0,0,,False,,,"{'17o28ebxx0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 132, 'x': 108, 'u': 'https://preview.redd.it/17o28ebxx0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f6d2a818f4f0f99bfb7029789354e0a8f225c99e'}, {'y': 265, 'x': 216, 'u': 'https://preview.redd.it/17o28ebxx0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=34ec826330db6b174e1f4df022b5c3597649e3e4'}, {'y': 393, 'x': 320, 'u': 'https://preview.redd.it/17o28ebxx0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f5b740b7bf37c1a1a88752dae043204d30791496'}, {'y': 787, 'x': 640, 'u': 'https://preview.redd.it/17o28ebxx0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=726a9ebf3a22451e09cc2a90730aa767fdf15301'}, {'y': 1181, 'x': 960, 'u': 'https://preview.redd.it/17o28ebxx0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ebc5a7dff08ad3daae6ff5d3b6c1bcf4fb52190a'}, {'y': 1329, 'x': 1080, 'u': 'https://preview.redd.it/17o28ebxx0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=96662c31e2206e63dac16be9bdccdbbaf3a2f0a9'}], 's': {'y': 1376, 'x': 1118, 'u': 'https://preview.redd.it/17o28ebxx0q61.png?width=1118&amp;format=png&amp;auto=webp&amp;s=f555dd8b6b91f6d295ecf282696dd7ad466caf5d'}, 'id': '17o28ebxx0q61'}, 'xapdrklqx0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 86, 'x': 108, 'u': 'https://preview.redd.it/xapdrklqx0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1240ba869b47c1b1341fbea21d424f15fddeb182'}, {'y': 172, 'x': 216, 'u': 'https://preview.redd.it/xapdrklqx0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6332697f67c77dce077088ce2b78b8ece1e53445'}, {'y': 256, 'x': 320, 'u': 'https://preview.redd.it/xapdrklqx0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=e6c7c573b05f43336c73be04109c29b2a14fedf6'}, {'y': 512, 'x': 640, 'u': 'https://preview.redd.it/xapdrklqx0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=31c225b4b6208af542c321d1f1c67de33d68ba60'}, {'y': 768, 'x': 960, 'u': 'https://preview.redd.it/xapdrklqx0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2dbd8c7ba28e4ac33cc930784d581899a218f6c8'}, {'y': 864, 'x': 1080, 'u': 'https://preview.redd.it/xapdrklqx0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5e1846e628bfc279b6dc0effd58c73ecf7665281'}], 's': {'y': 1070, 'x': 1336, 'u': 'https://preview.redd.it/xapdrklqx0q61.png?width=1336&amp;format=png&amp;auto=webp&amp;s=2f19de71e9838b2b222cbbcf6600dc429ddbc4a2'}, 'id': 'xapdrklqx0q61'}, 'skth68flx0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 114, 'x': 108, 'u': 'https://preview.redd.it/skth68flx0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=a8b8221fdf333e09202ceffa5f49a1a1962f1ec6'}, {'y': 229, 'x': 216, 'u': 'https://preview.redd.it/skth68flx0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=db189dc815383daf2d176cf459562b2416467a43'}, {'y': 339, 'x': 320, 'u': 'https://preview.redd.it/skth68flx0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c0343782772ca71be96c704250a993da6f2e213c'}, {'y': 679, 'x': 640, 'u': 'https://preview.redd.it/skth68flx0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=febff149fa7a8558588dd228ff01b927783410a8'}, {'y': 1018, 'x': 960, 'u': 'https://preview.redd.it/skth68flx0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4506c9bdc9cb6781b9528ff9d039230d15be2fc6'}, {'y': 1145, 'x': 1080, 'u': 'https://preview.redd.it/skth68flx0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=98ee3f4bf25ffb65366eae812d735e01f0d0489d'}], 's': {'y': 1462, 'x': 1378, 'u': 'https://preview.redd.it/skth68flx0q61.png?width=1378&amp;format=png&amp;auto=webp&amp;s=24f57fa8431650fb7522f92620ed1eb30ddcae44'}, 'id': 'skth68flx0q61'}, 'lea5dqxzx0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 106, 'x': 108, 'u': 'https://preview.redd.it/lea5dqxzx0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b3945fef4042a5cc1edc59aaf77b2c6894f0fb57'}, {'y': 212, 'x': 216, 'u': 'https://preview.redd.it/lea5dqxzx0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c88ba1708f19d5563eb787e32bf23bcb6c1d6253'}, {'y': 314, 'x': 320, 'u': 'https://preview.redd.it/lea5dqxzx0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=37833d76bd936fa6b103d112bba7748a09c1b2ec'}, {'y': 628, 'x': 640, 'u': 'https://preview.redd.it/lea5dqxzx0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b117554d284ec2e485a123b6641d91d6615cbee4'}, {'y': 943, 'x': 960, 'u': 'https://preview.redd.it/lea5dqxzx0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=888325af0bf6dedd1f207b29a7369ce82fd14554'}, {'y': 1061, 'x': 1080, 'u': 'https://preview.redd.it/lea5dqxzx0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b7d9ee0957a94d11656f78276312d69df2b06ec5'}], 's': {'y': 1252, 'x': 1274, 'u': 'https://preview.redd.it/lea5dqxzx0q61.png?width=1274&amp;format=png&amp;auto=webp&amp;s=76e57c31ac18b083ffc20609b693b4b850990c67'}, 'id': 'lea5dqxzx0q61'}, 'har0whisx0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 39, 'x': 108, 'u': 'https://preview.redd.it/har0whisx0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f954b4c1c821c7e480ae809c33d6041d620f938'}, {'y': 79, 'x': 216, 'u': 'https://preview.redd.it/har0whisx0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0cb46e40d501ccd0a19842eb46fc1594a6b2a436'}, {'y': 118, 'x': 320, 'u': 'https://preview.redd.it/har0whisx0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8587488b2570c931ac9c9acb5ecb27e4beb26659'}, {'y': 236, 'x': 640, 'u': 'https://preview.redd.it/har0whisx0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=26fc411ccbd202d0d1893989dbb7ff9318ce75c5'}, {'y': 354, 'x': 960, 'u': 'https://preview.redd.it/har0whisx0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=363edc06f6fee4bc72c72bb1cff6fdddbe2b755d'}, {'y': 399, 'x': 1080, 'u': 'https://preview.redd.it/har0whisx0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4c2e56ef819be8aa77ef290f8446a490d9b54c99'}], 's': {'y': 504, 'x': 1364, 'u': 'https://preview.redd.it/har0whisx0q61.png?width=1364&amp;format=png&amp;auto=webp&amp;s=afbd68945ee068b278ac5a929694509e10e97297'}, 'id': 'har0whisx0q61'}, '65wfgvobx0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 122, 'x': 108, 'u': 'https://preview.redd.it/65wfgvobx0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f16827a110da9044d8eed23dc98993e4b8b90147'}, {'y': 245, 'x': 216, 'u': 'https://preview.redd.it/65wfgvobx0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=632788afc5056bb66c4d9a2d478f69472eb6059f'}, {'y': 363, 'x': 320, 'u': 'https://preview.redd.it/65wfgvobx0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f79b09934ee6896898a1e7f12f1be8734ccb2d24'}, {'y': 727, 'x': 640, 'u': 'https://preview.redd.it/65wfgvobx0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7c72df9e603b015731dbb4b1df347ff3d3b06c23'}, {'y': 1091, 'x': 960, 'u': 'https://preview.redd.it/65wfgvobx0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c7ffb724904192cc0d946923d5b552964ea8fe56'}, {'y': 1228, 'x': 1080, 'u': 'https://preview.redd.it/65wfgvobx0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c920a90dc42874415675abcc9db9ba4d14aaacab'}], 's': {'y': 1490, 'x': 1310, 'u': 'https://preview.redd.it/65wfgvobx0q61.png?width=1310&amp;format=png&amp;auto=webp&amp;s=f03a12cec2b7cc819aed1f77b4a4586821703fba'}, 'id': '65wfgvobx0q61'}, '04b6yeq4x0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 108, 'x': 108, 'u': 'https://preview.redd.it/04b6yeq4x0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6b9a4e934da54a3edf1e3ea7673bd4bd19c502ef'}, {'y': 216, 'x': 216, 'u': 'https://preview.redd.it/04b6yeq4x0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=057ecae1dffc71e81ea9529e16d62505f366439e'}, {'y': 320, 'x': 320, 'u': 'https://preview.redd.it/04b6yeq4x0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=031ec19cda410e2698275ce390295dc2ef54ae24'}, {'y': 640, 'x': 640, 'u': 'https://preview.redd.it/04b6yeq4x0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7d3d2276fab2fa99885acc8f099b6da1a7999208'}, {'y': 960, 'x': 960, 'u': 'https://preview.redd.it/04b6yeq4x0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=901faba3c096b576fbda3b102a7d0a3db8444581'}, {'y': 1080, 'x': 1080, 'u': 'https://preview.redd.it/04b6yeq4x0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=856648976e29af6933b212bf9006340873da35b8'}], 's': {'y': 1436, 'x': 1436, 'u': 'https://preview.redd.it/04b6yeq4x0q61.png?width=1436&amp;format=png&amp;auto=webp&amp;s=7d8723b64a35e588d95ce6d853e3c885f78a2eae'}, 'id': '04b6yeq4x0q61'}, '3of2n7stx0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 111, 'x': 108, 'u': 'https://preview.redd.it/3of2n7stx0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ca7ac21520e99e8a7c138577356eb847ec8ac59e'}, {'y': 222, 'x': 216, 'u': 'https://preview.redd.it/3of2n7stx0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a5ada35ea8152edf46b6766cc0e95b4b24e4a0df'}, {'y': 329, 'x': 320, 'u': 'https://preview.redd.it/3of2n7stx0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=236b2cb80629193141534e46d41bcadc0a6722a0'}, {'y': 659, 'x': 640, 'u': 'https://preview.redd.it/3of2n7stx0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=b10d3e5b1de24e80746e5ce07044d9929c661dc0'}, {'y': 989, 'x': 960, 'u': 'https://preview.redd.it/3of2n7stx0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=42aba854f1c2e71048167cab1ca7e3c6b933f475'}, {'y': 1112, 'x': 1080, 'u': 'https://preview.redd.it/3of2n7stx0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1f9a239fbaa6b774a41afc5c658f6cceff7b199f'}], 's': {'y': 1294, 'x': 1256, 'u': 'https://preview.redd.it/3of2n7stx0q61.png?width=1256&amp;format=png&amp;auto=webp&amp;s=8cdc60c3b866b0ec7d5da0d8631e317c6b0eb7c4'}, 'id': '3of2n7stx0q61'}, 'gq17v0uux0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 98, 'x': 108, 'u': 'https://preview.redd.it/gq17v0uux0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2b03d27a3323cc197a1511596b1274e854ab078c'}, {'y': 196, 'x': 216, 'u': 'https://preview.redd.it/gq17v0uux0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=dbe620e196614103af8cb9ad4a67196c46cad147'}, {'y': 290, 'x': 320, 'u': 'https://preview.redd.it/gq17v0uux0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=7c136cf68a239b962076b11330dd08a45dd364a3'}, {'y': 581, 'x': 640, 'u': 'https://preview.redd.it/gq17v0uux0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e0fca6cacf4d028e01398d14e4fe44ea9001ce0'}, {'y': 871, 'x': 960, 'u': 'https://preview.redd.it/gq17v0uux0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=2cc6d6ac3208e72d455ac3dbec05262d36c6fa51'}, {'y': 980, 'x': 1080, 'u': 'https://preview.redd.it/gq17v0uux0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9df6bb35d2f75f8c0d6f4b212c59de94b7d6ed97'}], 's': {'y': 1438, 'x': 1584, 'u': 'https://preview.redd.it/gq17v0uux0q61.png?width=1584&amp;format=png&amp;auto=webp&amp;s=16f05ee8bc29212e848ee4707083646f39d8e51c'}, 'id': 'gq17v0uux0q61'}, 'n8vs4re3x0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 94, 'x': 108, 'u': 'https://preview.redd.it/n8vs4re3x0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d8347cf9d3cb76da269d679f82f0bb688aeb70bc'}, {'y': 188, 'x': 216, 'u': 'https://preview.redd.it/n8vs4re3x0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d6798a51e7d4023163af833d7a318cb49b826882'}, {'y': 279, 'x': 320, 'u': 'https://preview.redd.it/n8vs4re3x0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c138729e9572b5225cb8fa47d7be8ab8fb0aac51'}, {'y': 558, 'x': 640, 'u': 'https://preview.redd.it/n8vs4re3x0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f7a3fa5337935db7fcf3815af005944f329a5cb4'}, {'y': 838, 'x': 960, 'u': 'https://preview.redd.it/n8vs4re3x0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=4afb723ec75c41e4c07b3a1a88183c45bbb08285'}, {'y': 942, 'x': 1080, 'u': 'https://preview.redd.it/n8vs4re3x0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9581a60abfcbaecd116be3b8b880536caeb54fbb'}], 's': {'y': 1278, 'x': 1464, 'u': 'https://preview.redd.it/n8vs4re3x0q61.png?width=1464&amp;format=png&amp;auto=webp&amp;s=5d3385ef1d99158f5717406cebc5fdf860becc1c'}, 'id': 'n8vs4re3x0q61'}, '3wtiduycx0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 118, 'x': 108, 'u': 'https://preview.redd.it/3wtiduycx0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d9132c7ee765b18e1dc1857409ce58a83c4ee4ac'}, {'y': 237, 'x': 216, 'u': 'https://preview.redd.it/3wtiduycx0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bf1244d74b548c64b95cbebc9513f8e1b1d9ac36'}, {'y': 351, 'x': 320, 'u': 'https://preview.redd.it/3wtiduycx0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=19669727fb4a7f5df4bf2b5430ee7ae566137a37'}, {'y': 702, 'x': 640, 'u': 'https://preview.redd.it/3wtiduycx0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2da5bbc21344ec9bd787e6a064131c93e90ce513'}, {'y': 1054, 'x': 960, 'u': 'https://preview.redd.it/3wtiduycx0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=52fea93e0fcaf917eefea48b73199f73fa298261'}, {'y': 1186, 'x': 1080, 'u': 'https://preview.redd.it/3wtiduycx0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0ddcb09ddad001504995e20f48d321a52ac08cc7'}], 's': {'y': 1432, 'x': 1304, 'u': 'https://preview.redd.it/3wtiduycx0q61.png?width=1304&amp;format=png&amp;auto=webp&amp;s=be0fde9234e9260f0f2f6d7cd0a000e54369c0dd'}, 'id': '3wtiduycx0q61'}, 'tqq2os2px0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 120, 'x': 108, 'u': 'https://preview.redd.it/tqq2os2px0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e36adf6d0d36409a51c8b280ec623cb4c4e519fd'}, {'y': 241, 'x': 216, 'u': 'https://preview.redd.it/tqq2os2px0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0250240f8fc3ca330ba9f0d294dab1314a223297'}, {'y': 358, 'x': 320, 'u': 'https://preview.redd.it/tqq2os2px0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=77f810553ce74396683d240206cb76dce974baee'}, {'y': 716, 'x': 640, 'u': 'https://preview.redd.it/tqq2os2px0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a1d0204273a81c1ed7c0a49cc559e354e8f34117'}, {'y': 1074, 'x': 960, 'u': 'https://preview.redd.it/tqq2os2px0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fce21eaba40989fdc1d0d544bb2670c35695f44f'}, {'y': 1208, 'x': 1080, 'u': 'https://preview.redd.it/tqq2os2px0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e91e36033c5f36bd08fcaa6032af6934578bf1d3'}], 's': {'y': 1258, 'x': 1124, 'u': 'https://preview.redd.it/tqq2os2px0q61.png?width=1124&amp;format=png&amp;auto=webp&amp;s=5d5faa20885124147a87f41462ecc08abf78a1f5'}, 'id': 'tqq2os2px0q61'}, '2xiopd61y0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 32, 'x': 108, 'u': 'https://preview.redd.it/2xiopd61y0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=1f49e9c19b69a8fbdb8eb25ac7f22d8c914dc5f8'}, {'y': 64, 'x': 216, 'u': 'https://preview.redd.it/2xiopd61y0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c51eaa809753a604e2d544b0cc8445ae4e6d5d83'}, {'y': 95, 'x': 320, 'u': 'https://preview.redd.it/2xiopd61y0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=78dc6ee21e71e846242725b78776949a967a1794'}, {'y': 191, 'x': 640, 'u': 'https://preview.redd.it/2xiopd61y0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=03b8f67d931278f84c96277549a9c4c322e1d0f0'}, {'y': 286, 'x': 960, 'u': 'https://preview.redd.it/2xiopd61y0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=78477ebbaef7aeac84b372429e5a5bdcc1a8bb4c'}, {'y': 322, 'x': 1080, 'u': 'https://preview.redd.it/2xiopd61y0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7873287809a4e78a1926bcf31b7651cf0370a58f'}], 's': {'y': 562, 'x': 1882, 'u': 'https://preview.redd.it/2xiopd61y0q61.png?width=1882&amp;format=png&amp;auto=webp&amp;s=ffd05102a1eb445bf47c95b2c361a39bb0977c09'}, 'id': '2xiopd61y0q61'}, 'infaivfix0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 55, 'x': 108, 'u': 'https://preview.redd.it/infaivfix0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9850e5d229819f96445600354e7dfea807257051'}, {'y': 111, 'x': 216, 'u': 'https://preview.redd.it/infaivfix0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6cf1ae540a83634caaf7d597b1799794b7440a6c'}, {'y': 165, 'x': 320, 'u': 'https://preview.redd.it/infaivfix0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5910031e2c7207287a2c4eeb5d6a32edd509cf09'}, {'y': 330, 'x': 640, 'u': 'https://preview.redd.it/infaivfix0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a4b8d737854d31e203d0ce6768f754af9c75de6f'}, {'y': 495, 'x': 960, 'u': 'https://preview.redd.it/infaivfix0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=54f5d758cec3c916a5dcd2e238d092609600ad6d'}, {'y': 557, 'x': 1080, 'u': 'https://preview.redd.it/infaivfix0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8f34b1ff078a1174c9d0f0de0d5813cc567c7004'}], 's': {'y': 902, 'x': 1746, 'u': 'https://preview.redd.it/infaivfix0q61.png?width=1746&amp;format=png&amp;auto=webp&amp;s=dfd8ca115b1316b0aa981b282ccbe09462fc2344'}, 'id': 'infaivfix0q61'}, 'rb36e8g7x0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 90, 'x': 108, 'u': 'https://preview.redd.it/rb36e8g7x0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c91b51f6eb87d6b7dc1b1d8f60445382fd1a2252'}, {'y': 181, 'x': 216, 'u': 'https://preview.redd.it/rb36e8g7x0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b208f69261d05ac2f367019a9c1c257369a4e284'}, {'y': 268, 'x': 320, 'u': 'https://preview.redd.it/rb36e8g7x0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2843feb61619137f1a94b1b92d9e577d32e55ae6'}, {'y': 537, 'x': 640, 'u': 'https://preview.redd.it/rb36e8g7x0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=4372a81b4ff615391dce242eda1b22ac871173e9'}, {'y': 805, 'x': 960, 'u': 'https://preview.redd.it/rb36e8g7x0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=29111b12f9a9baeaa8b2375831dfd6e2655299ff'}, {'y': 906, 'x': 1080, 'u': 'https://preview.redd.it/rb36e8g7x0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8a4994523eb0cc56c4ba9bf25652269805599e12'}], 's': {'y': 1022, 'x': 1218, 'u': 'https://preview.redd.it/rb36e8g7x0q61.png?width=1218&amp;format=png&amp;auto=webp&amp;s=3fc9c0bd2199a60f1c2862dec39f31a32c872231'}, 'id': 'rb36e8g7x0q61'}, 'ra0mijkex0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 107, 'x': 108, 'u': 'https://preview.redd.it/ra0mijkex0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f06dd8ed3a315eab88eb0d90174d9085cef2662d'}, {'y': 214, 'x': 216, 'u': 'https://preview.redd.it/ra0mijkex0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=fe3d55863f45cdada66979709dc44076f83eace3'}, {'y': 318, 'x': 320, 'u': 'https://preview.redd.it/ra0mijkex0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8b799c92f4c829b37bd9796f2afecd9b2aa135d2'}, {'y': 636, 'x': 640, 'u': 'https://preview.redd.it/ra0mijkex0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ec76be80700de8bebc963accc291e28f467e8f4c'}, {'y': 954, 'x': 960, 'u': 'https://preview.redd.it/ra0mijkex0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d260f7a3565650cdbde8f851302003880f5b8f13'}, {'y': 1073, 'x': 1080, 'u': 'https://preview.redd.it/ra0mijkex0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c251f21262b734eb932396ce429ca67152507fec'}], 's': {'y': 1396, 'x': 1404, 'u': 'https://preview.redd.it/ra0mijkex0q61.png?width=1404&amp;format=png&amp;auto=webp&amp;s=2bb5e17ce3fd97683967757b717a50b4501fcd3a'}, 'id': 'ra0mijkex0q61'}, 'st97kz2hx0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 114, 'x': 108, 'u': 'https://preview.redd.it/st97kz2hx0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fe174c75d2faa7b689ecc07ec585fdb13771593b'}, {'y': 228, 'x': 216, 'u': 'https://preview.redd.it/st97kz2hx0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2331af07e98ff87d9a59c15ec5537d671ad2a3cd'}, {'y': 337, 'x': 320, 'u': 'https://preview.redd.it/st97kz2hx0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b20952ede2472e19fec3fc6ae4bc650634a8e6df'}, {'y': 675, 'x': 640, 'u': 'https://preview.redd.it/st97kz2hx0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=de91ae31f440f20e67ef354ae782cdd086db8472'}, {'y': 1013, 'x': 960, 'u': 'https://preview.redd.it/st97kz2hx0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ab7191a1c455cb58993d989c54a530af89212c87'}, {'y': 1140, 'x': 1080, 'u': 'https://preview.redd.it/st97kz2hx0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f1d064da847094cc650a4f83c9d4c498c957e038'}], 's': {'y': 1428, 'x': 1352, 'u': 'https://preview.redd.it/st97kz2hx0q61.png?width=1352&amp;format=png&amp;auto=webp&amp;s=426abbad82faab0ed99afb22fbfbff0d1507da94'}, 'id': 'st97kz2hx0q61'}, 'vpem1zt9x0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 122, 'x': 108, 'u': 'https://preview.redd.it/vpem1zt9x0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9c095506bc64e4090e994186160157d4ab0027c1'}, {'y': 245, 'x': 216, 'u': 'https://preview.redd.it/vpem1zt9x0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5707f63279f55eb55a253f283ce82d010e9d7b3a'}, {'y': 363, 'x': 320, 'u': 'https://preview.redd.it/vpem1zt9x0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=940b11f4dea50a8e0f18af850fdb05d48fbef3d6'}, {'y': 727, 'x': 640, 'u': 'https://preview.redd.it/vpem1zt9x0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=80241fded9f40536ff65a6ef4267a021b1f6ed78'}, {'y': 1091, 'x': 960, 'u': 'https://preview.redd.it/vpem1zt9x0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=5f387479a111b012cace830ee52ee7ba21cf23ba'}, {'y': 1228, 'x': 1080, 'u': 'https://preview.redd.it/vpem1zt9x0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c8f2f98518af603ba60d2af96a27b4fc1b44711f'}], 's': {'y': 1490, 'x': 1310, 'u': 'https://preview.redd.it/vpem1zt9x0q61.png?width=1310&amp;format=png&amp;auto=webp&amp;s=d941d9e101a777d7cae3e403099795a40d1a59a2'}, 'id': 'vpem1zt9x0q61'}, 'ogws4rt0x0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 82, 'x': 108, 'u': 'https://preview.redd.it/ogws4rt0x0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b230280ad852734a766400aeb85a36f2c0374f33'}, {'y': 165, 'x': 216, 'u': 'https://preview.redd.it/ogws4rt0x0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=93dc27b609bc3c51d85ca60f21128f0dcfd10ee0'}, {'y': 245, 'x': 320, 'u': 'https://preview.redd.it/ogws4rt0x0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0362b558afd5ed626ca33ec93b62b8bd8ff7dc23'}, {'y': 491, 'x': 640, 'u': 'https://preview.redd.it/ogws4rt0x0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e56609fcbe4ad2cfcdd3700cb2483e5217042f8'}, {'y': 737, 'x': 960, 'u': 'https://preview.redd.it/ogws4rt0x0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=43272b927c684999349ededb2a209776e5d2d481'}, {'y': 829, 'x': 1080, 'u': 'https://preview.redd.it/ogws4rt0x0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c868211f92052641822f75d37e8c558e7f5f47e5'}], 's': {'y': 1346, 'x': 1752, 'u': 'https://preview.redd.it/ogws4rt0x0q61.png?width=1752&amp;format=png&amp;auto=webp&amp;s=d9dff151bf875ba1a84ca3cea07515d900efe122'}, 'id': 'ogws4rt0x0q61'}, 'l5qony34y0q61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 92, 'x': 108, 'u': 'https://preview.redd.it/l5qony34y0q61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=237ef9c5d7d5eca25b2034913a10955c6c5391a7'}, {'y': 185, 'x': 216, 'u': 'https://preview.redd.it/l5qony34y0q61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=acb0cf8726ee1c10e294f8c6cb8f410a741a2b76'}, {'y': 274, 'x': 320, 'u': 'https://preview.redd.it/l5qony34y0q61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d9875d77bf34e0af0375c0fad1fe4326b49739fd'}, {'y': 548, 'x': 640, 'u': 'https://preview.redd.it/l5qony34y0q61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ccebe648a26dfc4e9d0fb12d61c1912e9eaa65e4'}, {'y': 822, 'x': 960, 'u': 'https://preview.redd.it/l5qony34y0q61.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=d12b94ccaa75b4f5e1813fbab34f1369aca582ef'}, {'y': 925, 'x': 1080, 'u': 'https://preview.redd.it/l5qony34y0q61.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b33eb56967cc1f0fc2f4767c12ba4dd011c93bb7'}], 's': {'y': 1150, 'x': 1342, 'u': 'https://preview.redd.it/l5qony34y0q61.png?width=1342&amp;format=png&amp;auto=webp&amp;s=1c12bf97133b9a31ef3691cf2fc9651a1f5e510b'}, 'id': 'l5qony34y0q61'}}",,,,
,deeplearning,,t2_365igvf9,False,,0,False,Checkout my latest blog on Transformers - Visual Guide,[],r/deeplearning,False,6,,0,,False,t3_mfwg7r,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1617072374.0,text,6,,,text,mlstuff.substack.com,False,,,,,https://mlstuff.substack.com/p/coming-soon?r=irzxz&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=reddit,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mfwg7r,True,,mayurat22,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mfwg7r/checkout_my_latest_blog_on_transformers_visual/,all_ads,False,https://mlstuff.substack.com/p/coming-soon?r=irzxz&amp;utm_campaign=post&amp;utm_medium=web&amp;utm_source=reddit,66146,1617043574.0,0,,False,,,,,,,
,deeplearning,What’s the best deep learning algorithm for image inpainting. If you know can you share the GitHub implementation,t2_6bg8t97l,False,,0,False,What’s the best deep learning algorithm for image inpainting,[],r/deeplearning,False,6,,0,,False,t3_mfruvg,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1617059992.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;What’s the best deep learning algorithm for image inpainting. If you know can you share the GitHub implementation&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mfruvg,True,,CulturalAfternoon306,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mfruvg/whats_the_best_deep_learning_algorithm_for_image/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mfruvg/whats_the_best_deep_learning_algorithm_for_image/,66146,1617031192.0,0,,False,,,,,,,
,deeplearning,,t2_kj0nv,False,,0,False,deep-daze: Simple command line tool for text to image generation using OpenAI's CLIP and Siren (Implicit neural representation network),[],r/deeplearning,False,6,,0,,False,t3_mfrt08,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1617059841.0,text,6,,,text,github.com,False,,,,,https://github.com/lucidrains/deep-daze,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mfrt08,True,,binaryfor,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mfrt08/deepdaze_simple_command_line_tool_for_text_to/,all_ads,False,https://github.com/lucidrains/deep-daze,66146,1617031041.0,0,,False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,Going to the gym,[],r/deeplearning,False,6,,0,,False,t3_mfplxt,False,dark,0.33,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/_jrLPv5CdNk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Learn Egyptian Arabic: Going to the Gym :)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/_jrLPv5CdNk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/_jrLPv5CdNk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/_jrLPv5CdNk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mfplxt', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1617053395.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/_jrLPv5CdNk,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mfplxt,True,,Community-Of-Babel,,0,False,all_ads,False,[],False,,/r/deeplearning/comments/mfplxt/going_to_the_gym/,all_ads,False,https://youtu.be/_jrLPv5CdNk,66146,1617024595.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Learn Egyptian Arabic: Going to the Gym :)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/_jrLPv5CdNk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/_jrLPv5CdNk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}",False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Going to the gym 🙂', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mfpkl3', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 1, 'total_awards_received': 0, 'media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/_jrLPv5CdNk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Learn Egyptian Arabic: Going to the Gym :)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/_jrLPv5CdNk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/_jrLPv5CdNk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/_jrLPv5CdNk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mfpkl3', 'height': 200}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1617053268.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtu.be', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://youtu.be/_jrLPv5CdNk', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mfpkl3', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/mfpkl3/going_to_the_gym/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://youtu.be/_jrLPv5CdNk', 'subreddit_subscribers': 0, 'created_utc': 1617024468.0, 'num_crossposts': 4, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Learn Egyptian Arabic: Going to the Gym :)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/_jrLPv5CdNk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Community of Babel Arabic', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/_jrLPv5CdNk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCYE6wh1he0q5HbXWIEVUbVw'}}, 'is_video': False}]",t3_mfpkl3,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,"MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model Paper explained!",[],r/deeplearning,False,6,,0,,False,t3_mf3x2r,False,dark,0.91,,public,27,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/mH7f7N7s79s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model | RL Paper explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/mH7f7N7s79s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/mH7f7N7s79s/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/mH7f7N7s79s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mf3x2r', 'height': 200}",,False,27,,False,False,,False,,[],{},,False,,1616976855.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/mH7f7N7s79s,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mf3x2r,True,,gordicaleksa,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mf3x2r/muzero_mastering_atari_go_chess_and_shogi_by/,all_ads,False,https://youtu.be/mH7f7N7s79s,66146,1616948055.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model | RL Paper explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/mH7f7N7s79s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/mH7f7N7s79s/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,"I’m wondering if there’s any computation of mathematics or conceptions that lets to do multiple-generators for generating different Classes at the same time ....? 
multiple-Generators adversarial Network for example ,,,,!!!",t2_a43srqxo,False,,0,False,let me suggest an idea may look interesting to you guys Multiple-Generators GANs,[],r/deeplearning,False,6,,0,,False,t3_mfigug,False,dark,0.43,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1617024372.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’m wondering if there’s any computation of mathematics or conceptions that lets to do multiple-generators for generating different Classes at the same time ....? 
multiple-Generators adversarial Network for example ,,,,!!!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mfigug,True,,Youness_Elbrag,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mfigug/let_me_suggest_an_idea_may_look_interesting_to/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mfigug/let_me_suggest_an_idea_may_look_interesting_to/,66146,1616995572.0,0,,False,,,,,,,
,deeplearning,"At the Lawrence Livermore National Laboratory (LLNL), scientists have developed a novel framework and an accompanying visualization tool that utilizes deep reinforcement learning for symbolic regression problems, outperforming baseline methods on benchmark problems.

Their paper was recently accepted as an oral presentation at the International Conference on Learning Representations (ICLR 2021). In their paper, the researchers describe applying deep reinforcement learning to discrete optimization. Discrete optimization focuses on problems that deal with discrete “building blocks” that must be combined in a particular order or configuration to optimize the desired property. They focused on a type of discrete optimization called symbolic regression. Symbolic regression finds short mathematical expressions that fit data gathered from an experiment. It aims to discover the underlying equations or dynamics of a physical process.

Summary: [https://www.marktechpost.com/2021/03/28/researchers-at-lawrence-livermore-national-laboratory-llnl-developed-a-novel-deep-learning-framework-for-symbolic-regression/](https://www.marktechpost.com/2021/03/28/researchers-at-lawrence-livermore-national-laboratory-llnl-developed-a-novel-deep-learning-framework-for-symbolic-regression/) 

Paper: [https://openreview.net/forum?id=m5Qsh0kBQG](https://openreview.net/forum?id=m5Qsh0kBQG)",t2_4wudjgid,False,,0,False,Researchers at Lawrence Livermore National Laboratory (LLNL) Developed a Novel Deep Learning Framework for Symbolic Regression,[],r/deeplearning,False,6,,0,,False,t3_mf79t9,False,dark,0.7,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1616986526.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;At the Lawrence Livermore National Laboratory (LLNL), scientists have developed a novel framework and an accompanying visualization tool that utilizes deep reinforcement learning for symbolic regression problems, outperforming baseline methods on benchmark problems.&lt;/p&gt;

&lt;p&gt;Their paper was recently accepted as an oral presentation at the International Conference on Learning Representations (ICLR 2021). In their paper, the researchers describe applying deep reinforcement learning to discrete optimization. Discrete optimization focuses on problems that deal with discrete “building blocks” that must be combined in a particular order or configuration to optimize the desired property. They focused on a type of discrete optimization called symbolic regression. Symbolic regression finds short mathematical expressions that fit data gathered from an experiment. It aims to discover the underlying equations or dynamics of a physical process.&lt;/p&gt;

&lt;p&gt;Summary: &lt;a href=""https://www.marktechpost.com/2021/03/28/researchers-at-lawrence-livermore-national-laboratory-llnl-developed-a-novel-deep-learning-framework-for-symbolic-regression/""&gt;https://www.marktechpost.com/2021/03/28/researchers-at-lawrence-livermore-national-laboratory-llnl-developed-a-novel-deep-learning-framework-for-symbolic-regression/&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;Paper: &lt;a href=""https://openreview.net/forum?id=m5Qsh0kBQG""&gt;https://openreview.net/forum?id=m5Qsh0kBQG&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mf79t9,True,,techsucker,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mf79t9/researchers_at_lawrence_livermore_national/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mf79t9/researchers_at_lawrence_livermore_national/,66146,1616957726.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,"Most of us are convinced that we can dissociate humans from machines, but is it really the case? This is what this study reveals using AI-made-up people on dating apps.",[],r/deeplearning,False,6,,0,,False,t3_mezd55,False,dark,0.72,,public,8,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IoRH5u13P-4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Would you swipe right on an AI\xa0profile?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IoRH5u13P-4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/IoRH5u13P-4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IoRH5u13P-4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/mezd55', 'height': 200}",,False,8,,False,False,,False,,[],{},,False,,1616958209.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/IoRH5u13P-4,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mezd55,True,,OnlyProggingForFun,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mezd55/most_of_us_are_convinced_that_we_can_dissociate/,all_ads,False,https://youtu.be/IoRH5u13P-4,66146,1616929409.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Would you swipe right on an AI\xa0profile?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/IoRH5u13P-4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/IoRH5u13P-4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,,,,,,,
,deeplearning,"I am planning on buying a laptop and I have two GPU options, viz. RTX 3070 Vs 3080.

How much of a difference is there from the point of view of Deep Learning training between these two?",t2_2mmql89p,False,,0,False,GPU comparison &amp; impact,[],r/deeplearning,False,6,,0,,False,t3_mesy4i,False,dark,0.99,,public,18,0,{},,False,[],,False,False,,{},,False,18,,False,False,,False,,[],{},,True,,1616928633.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am planning on buying a laptop and I have two GPU options, viz. RTX 3070 Vs 3080.&lt;/p&gt;

&lt;p&gt;How much of a difference is there from the point of view of Deep Learning training between these two?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mesy4i,True,,grid_world,,35,True,all_ads,False,[],False,,/r/deeplearning/comments/mesy4i/gpu_comparison_impact/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mesy4i/gpu_comparison_impact/,66146,1616899833.0,0,,False,,,,,,,
,deeplearning,,t2_wri36,False,,0,False,How to reference custom Python files when training a model with tensorflow_cloud in GCP?,[],r/deeplearning,False,6,,0,,False,t3_mf38uh,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,False,,1616974859.0,text,6,,,text,self.learnmachinelearning,False,,,,,/r/learnmachinelearning/comments/mf34qi/how_to_reference_custom_python_files_when/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mf38uh,True,,Vasilkosturski,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mf38uh/how_to_reference_custom_python_files_when/,all_ads,False,/r/learnmachinelearning/comments/mf34qi/how_to_reference_custom_python_files_when/,66146,1616946059.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': 'I\'m trying to train a Tensorflow model using in Google Cloud using tensorflow\\_cloud.\n\nSo I have the following code triggering the training:\n\n    import tensorflow_cloud as tfc\n    tfc.run(\n        requirements_txt=""requirements.txt"",\n        distribution_strategy=""auto"",\n        docker_image_bucket_name=&lt;bucket-name&gt;\n    ) \n\nI have a simple python file with some util functions let\'s say its\' name is `utils.py` \n\nSo, in the notebook I\'m importing this file like so:\n\n    from utils import *\n\nMy question is - **How do I reference this file when running the notebook in GCP?**\n\nAt the moment I get a `module not found` error indicating the `utils` file can\'t be found.\n\nI\'m trying to copy the file to my GCP bucket but it still says it can\'t find it.\n\nAny clues?', 'author_fullname': 't2_wri36', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How to reference custom Python files when training a model with tensorflow_cloud in GCP?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mf34qi', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1616974523.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnmachinelearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m trying to train a Tensorflow model using in Google Cloud using tensorflow_cloud.&lt;/p&gt;\n\n&lt;p&gt;So I have the following code triggering the training:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import tensorflow_cloud as tfc\ntfc.run(\n    requirements_txt=&amp;quot;requirements.txt&amp;quot;,\n    distribution_strategy=&amp;quot;auto&amp;quot;,\n    docker_image_bucket_name=&amp;lt;bucket-name&amp;gt;\n) \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I have a simple python file with some util functions let&amp;#39;s say its&amp;#39; name is &lt;code&gt;utils.py&lt;/code&gt; &lt;/p&gt;\n\n&lt;p&gt;So, in the notebook I&amp;#39;m importing this file like so:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from utils import *\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;My question is - &lt;strong&gt;How do I reference this file when running the notebook in GCP?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;At the moment I get a &lt;code&gt;module not found&lt;/code&gt; error indicating the &lt;code&gt;utils&lt;/code&gt; file can&amp;#39;t be found.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to copy the file to my GCP bucket but it still says it can&amp;#39;t find it.&lt;/p&gt;\n\n&lt;p&gt;Any clues?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mf34qi', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Vasilkosturski', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/mf34qi/how_to_reference_custom_python_files_when/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnmachinelearning/comments/mf34qi/how_to_reference_custom_python_files_when/', 'subreddit_subscribers': 232341, 'created_utc': 1616945723.0, 'num_crossposts': 4, 'media': None, 'is_video': False}]",t3_mf34qi,,,,,
,deeplearning,"Which dataset do you think is the right choice as a training dataset for the colorization of images using Deep Learning.

I am right now implementing Zhang et Al's paper on Colorization.

Paper:

[https://arxiv.org/pdf/1603.08511.pdf](https://arxiv.org/pdf/1603.08511.pdf)

My Code:

[https://github.com/saint1729/cs6140\_final\_project/tree/saint1729](https://github.com/saint1729/cs6140_final_project/tree/saint1729)",t2_3ftn1gw,False,,0,False,Dataset for Colorization [P],[],r/deeplearning,False,6,,0,,False,t3_mesqoy,False,dark,0.81,,public,3,1,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1616927882.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Which dataset do you think is the right choice as a training dataset for the colorization of images using Deep Learning.&lt;/p&gt;

&lt;p&gt;I am right now implementing Zhang et Al&amp;#39;s paper on Colorization.&lt;/p&gt;

&lt;p&gt;Paper:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://arxiv.org/pdf/1603.08511.pdf""&gt;https://arxiv.org/pdf/1603.08511.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My Code:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/saint1729/cs6140_final_project/tree/saint1729""&gt;https://github.com/saint1729/cs6140_final_project/tree/saint1729&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mesqoy,True,,saint1729,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/mesqoy/dataset_for_colorization_p/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mesqoy/dataset_for_colorization_p/,66146,1616899082.0,0,,False,,,,,,,
,deeplearning,,t2_409owhnf,False,,0,False,"In simple terms, please can someone please explain the difference between a rank and an axis ?",[],r/deeplearning,False,6,,0,,False,t3_mew879,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1616942636.0,text,6,,,text,self.deeplearning,False,,,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mew879,True,,destin95,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/mew879/in_simple_terms_please_can_someone_please_explain/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mew879/in_simple_terms_please_can_someone_please_explain/,66146,1616913836.0,0,,False,,,,,,,
,deeplearning,"Hi!

I'm still pretty new to DL and currently actively aiming to understand reinformcement learning as the most interesting thing to me. And I got a question which I still can't answer. I'm gulping a lot of educational materials about RL, I got acquainted with some of the methods, but still don't see a method which seems quite obvious to me. So, I'm wondering, is it an already used method (perhaps implicitly ""hidden"" in other methods that I didn't fully get), or the idea is really new?

Imagine we have an DNN for agent, which gives out an Action given the State. We then get a Reward (taking into account it's ""discounting"" nature or any other approach you use).

Then we have a separate network wich learns to approximate the Reward function, given the State and Action. Let's call it ""Reward network"". So, basically it is `F(S, A) -&gt; R`. This is generally a Q-function if I understand correctly.

So, the idea is quite simple, assuming our Reward Network is more or less trained already. At current `State`, agent network gives out probable `Action`. We then feed those `State` and `Action` into our ""Reward network"". But what we do next is calculate the gradient of R and ... calculate an ajusted `Action`-input to potentually increase the outcome. In other words, we calculate `dR/dA` and then adjust A in the direction of ascending (let it be `A'`). Absolutely the same as usual back-propagation, but we have no ""error"" and we don't adjust weights, but the input itself. After that, the agent performs this action `A'`, taking next reward which will then enrich the experience.

Is it an already known and used approach or somthing really new? Cause I still can't really find a explicit use of such method. Thanks.

P.S. Here we assume we are dealing with non-discrete action-space.",t2_pw626,False,,0,False,"Is ""back propagational"" action search a thing in RL?",[],r/deeplearning,False,6,,0,,False,t3_mea2zh,False,dark,0.8,,public,12,0,{},,False,[],,False,False,,{},,False,12,,False,False,,1616836050.0,,[],{},,True,,1616864165.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi!&lt;/p&gt;

&lt;p&gt;I&amp;#39;m still pretty new to DL and currently actively aiming to understand reinformcement learning as the most interesting thing to me. And I got a question which I still can&amp;#39;t answer. I&amp;#39;m gulping a lot of educational materials about RL, I got acquainted with some of the methods, but still don&amp;#39;t see a method which seems quite obvious to me. So, I&amp;#39;m wondering, is it an already used method (perhaps implicitly &amp;quot;hidden&amp;quot; in other methods that I didn&amp;#39;t fully get), or the idea is really new?&lt;/p&gt;

&lt;p&gt;Imagine we have an DNN for agent, which gives out an Action given the State. We then get a Reward (taking into account it&amp;#39;s &amp;quot;discounting&amp;quot; nature or any other approach you use).&lt;/p&gt;

&lt;p&gt;Then we have a separate network wich learns to approximate the Reward function, given the State and Action. Let&amp;#39;s call it &amp;quot;Reward network&amp;quot;. So, basically it is &lt;code&gt;F(S, A) -&amp;gt; R&lt;/code&gt;. This is generally a Q-function if I understand correctly.&lt;/p&gt;

&lt;p&gt;So, the idea is quite simple, assuming our Reward Network is more or less trained already. At current &lt;code&gt;State&lt;/code&gt;, agent network gives out probable &lt;code&gt;Action&lt;/code&gt;. We then feed those &lt;code&gt;State&lt;/code&gt; and &lt;code&gt;Action&lt;/code&gt; into our &amp;quot;Reward network&amp;quot;. But what we do next is calculate the gradient of R and ... calculate an ajusted &lt;code&gt;Action&lt;/code&gt;-input to potentually increase the outcome. In other words, we calculate &lt;code&gt;dR/dA&lt;/code&gt; and then adjust A in the direction of ascending (let it be &lt;code&gt;A&amp;#39;&lt;/code&gt;). Absolutely the same as usual back-propagation, but we have no &amp;quot;error&amp;quot; and we don&amp;#39;t adjust weights, but the input itself. After that, the agent performs this action &lt;code&gt;A&amp;#39;&lt;/code&gt;, taking next reward which will then enrich the experience.&lt;/p&gt;

&lt;p&gt;Is it an already known and used approach or somthing really new? Cause I still can&amp;#39;t really find a explicit use of such method. Thanks.&lt;/p&gt;

&lt;p&gt;P.S. Here we assume we are dealing with non-discrete action-space.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mea2zh,True,,Amegatron,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/mea2zh/is_back_propagational_action_search_a_thing_in_rl/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mea2zh/is_back_propagational_action_search_a_thing_in_rl/,66146,1616835365.0,0,,False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,Let's talk about cooking and cuisine in Standard Arabic 🤩,[],r/deeplearning,False,6,,0,,False,t3_mem5q8,False,dark,0.18,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1616906346.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/fwiewm28tmp61.png,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mem5q8,True,,Community-Of-Babel,,0,False,all_ads,False,[],False,,/r/deeplearning/comments/mem5q8/lets_talk_about_cooking_and_cuisine_in_standard/,all_ads,False,https://i.redd.it/fwiewm28tmp61.png,66146,1616877546.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': ""Let's talk about cooking and cuisine in Standard Arabic 🤩"", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_mem4dl', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.4, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1616906234.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/fwiewm28tmp61.png', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mem4dl', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/mem4dl/lets_talk_about_cooking_and_cuisine_in_standard/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://i.redd.it/fwiewm28tmp61.png', 'subreddit_subscribers': 0, 'created_utc': 1616877434.0, 'num_crossposts': 3, 'media': None, 'is_video': False}]",t3_mem4dl,,,,,
,deeplearning,"Hello y’all,

In the time distributed layers, say when we feed the model the sequence of frames, say 10/5, and each frames say when we consider 5, the labels(1,1,1,1,0), for a binary classification, then the sequence layers(if we use LSTM/GRU, majority votes the label? I mean like here we have got 1(as it has larger number)? I mean when we use this function -&gt; Timedistributed layer in Keras? If not how can I specify? 


Thanks.",t2_4juoyuxt,False,,0,False,Voting scheme for the labels,[],r/deeplearning,False,6,,0,,False,t3_me5koq,False,dark,0.71,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1616844125.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello y’all,&lt;/p&gt;

&lt;p&gt;In the time distributed layers, say when we feed the model the sequence of frames, say 10/5, and each frames say when we consider 5, the labels(1,1,1,1,0), for a binary classification, then the sequence layers(if we use LSTM/GRU, majority votes the label? I mean like here we have got 1(as it has larger number)? I mean when we use this function -&amp;gt; Timedistributed layer in Keras? If not how can I specify? &lt;/p&gt;

&lt;p&gt;Thanks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,me5koq,True,,bhatta90,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/me5koq/voting_scheme_for_the_labels/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/me5koq/voting_scheme_for_the_labels/,66146,1616815325.0,0,,False,,,,,,,
,deeplearning,"Hey!  


Recently, I have become somewhat frustrated at ML papers highlighting scores only stemming from a single run in result tables, and claiming that an approach is superior when it only outperforms others marginally. This is why I re-implemented, tested and packaged a statistical significance test proposed by Dror et al. (2019) that is specifically tailored towards neural networks. I also added information about statistical significance testing and how to apply the mentioned test in the most common scenarios faced by ML practitioners!

[https://github.com/Kaleidophon/deep-significance](https://github.com/Kaleidophon/deep-significance)

I'd be very happy to receive some feedback from the community here and improve this further and help move the field forward :-)",t2_entq9,False,,0,False,[Project] deep-significance: Easy and Better Significance Testing for Deep Neural Networks (link below),[],r/deeplearning,False,6,,0,,False,t3_mdq29j,False,dark,1.0,,public,32,0,{},,False,[],,False,False,,{},,False,32,,False,False,,False,,[],{},,True,,1616798271.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey!  &lt;/p&gt;

&lt;p&gt;Recently, I have become somewhat frustrated at ML papers highlighting scores only stemming from a single run in result tables, and claiming that an approach is superior when it only outperforms others marginally. This is why I re-implemented, tested and packaged a statistical significance test proposed by Dror et al. (2019) that is specifically tailored towards neural networks. I also added information about statistical significance testing and how to apply the mentioned test in the most common scenarios faced by ML practitioners!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://github.com/Kaleidophon/deep-significance""&gt;https://github.com/Kaleidophon/deep-significance&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I&amp;#39;d be very happy to receive some feedback from the community here and improve this further and help move the field forward :-)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mdq29j,True,,Kaleidophon,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mdq29j/project_deepsignificance_easy_and_better/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mdq29j/project_deepsignificance_easy_and_better/,66146,1616769471.0,0,,False,,,,,,,
,deeplearning,"I'm looking for good tutorials on DDP. I usually pride myself on being able to figure things out on my own pretty well, but I've been banging my head against the wall on this one. I've used DataParallel before (which is really easy to use), but I wanted to train on multiple nodes, so I'm trying to learn DDP. The documentation leaves a lot to be desired and every online tutorial I find conflicts with other ones and many seem outdated. Does anyone have suggestions? I have it working on a single node multi-gpu setup, but I run into issues when I try multi-node.",t2_73mzlywj,False,,0,False,Pytorch DistributedDataParallel (DDP) framework,[],r/deeplearning,False,6,,0,,False,t3_mdwu9u,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1616817003.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking for good tutorials on DDP. I usually pride myself on being able to figure things out on my own pretty well, but I&amp;#39;ve been banging my head against the wall on this one. I&amp;#39;ve used DataParallel before (which is really easy to use), but I wanted to train on multiple nodes, so I&amp;#39;m trying to learn DDP. The documentation leaves a lot to be desired and every online tutorial I find conflicts with other ones and many seem outdated. Does anyone have suggestions? I have it working on a single node multi-gpu setup, but I run into issues when I try multi-node.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mdwu9u,True,,space-buffalo,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mdwu9u/pytorch_distributeddataparallel_ddp_framework/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mdwu9u/pytorch_distributeddataparallel_ddp_framework/,66146,1616788203.0,0,,False,,,,,,,
,deeplearning,"I have seen that most of the deep-learning frameworks have the ability to do dilated pooling. Many frameworks have recently been updated to add the dilated property to the pooling op.

However, I have not been able to find a single mention of dilated pooling in any scholarly papers. I also have not been able to find any models that are using dilated pooling.

Happy for any discussion.  Would be absolutely excited if someone found a scholarly paper explaining a use case for a dilated pooling layer. I would also be excited if someone pointed me to a model that actually contained a dilated pooling layer.",t2_9wiq6,False,,0,False,Does anyone have a use case for dilated pooling operator used in a ML model?,[],r/deeplearning,False,6,,0,,False,t3_mdtn2r,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1616808141.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have seen that most of the deep-learning frameworks have the ability to do dilated pooling. Many frameworks have recently been updated to add the dilated property to the pooling op.&lt;/p&gt;

&lt;p&gt;However, I have not been able to find a single mention of dilated pooling in any scholarly papers. I also have not been able to find any models that are using dilated pooling.&lt;/p&gt;

&lt;p&gt;Happy for any discussion.  Would be absolutely excited if someone found a scholarly paper explaining a use case for a dilated pooling layer. I would also be excited if someone pointed me to a model that actually contained a dilated pooling layer.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mdtn2r,True,,gnash117,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/mdtn2r/does_anyone_have_a_use_case_for_dilated_pooling/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mdtn2r/does_anyone_have_a_use_case_for_dilated_pooling/,66146,1616779341.0,0,,False,,,,,,,
,deeplearning,"Have you guys seen the results from the pSp encoder?
 I found the paper extremely useful for my research on GAN inversion, and latent space projection for deep learning based image editing.  

If you want to know the main ideas of the paper ""Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation"" (pixel2style2pixel or pSp) by Richardson et al. head over my [telegram channel](https://t.me/casual_gan), where I break down the main ideas from popular GAN papers.   

In case you missed it, Pixel2Style2Pixel is nowadays used in many image editing apps because it has simple, yet effective ideas and it just works! Read 

more here: [https://t.me/casual\_gan/16](https://t.me/casual_gan/16)6)",t2_hhio3,False,,0,False,Encoding in Style (Pixel2Style2Pixel - pSp) explained,[],r/deeplearning,False,6,,0,,False,t3_mds9fc,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1616787832.0,,[],{},,True,,1616804376.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Have you guys seen the results from the pSp encoder?
 I found the paper extremely useful for my research on GAN inversion, and latent space projection for deep learning based image editing.  &lt;/p&gt;

&lt;p&gt;If you want to know the main ideas of the paper &amp;quot;Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation&amp;quot; (pixel2style2pixel or pSp) by Richardson et al. head over my &lt;a href=""https://t.me/casual_gan""&gt;telegram channel&lt;/a&gt;, where I break down the main ideas from popular GAN papers.   &lt;/p&gt;

&lt;p&gt;In case you missed it, Pixel2Style2Pixel is nowadays used in many image editing apps because it has simple, yet effective ideas and it just works! Read &lt;/p&gt;

&lt;p&gt;more here: &lt;a href=""https://t.me/casual_gan/16""&gt;https://t.me/casual_gan/16&lt;/a&gt;6)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mds9fc,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mds9fc/encoding_in_style_pixel2style2pixel_psp_explained/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mds9fc/encoding_in_style_pixel2style2pixel_psp_explained/,66146,1616775576.0,0,,False,,,,,,,
,deeplearning,"In this article, we will cover a new form of channel and spatial attention known as Triplet Attention (accepted at WACV 2021), with full Python (PyTorch) code included.

Topics covered include:

* Channel and Spatial Attention
* SENet
* CBAM
* Drawbacks to Current Attention Mechanisms
* Cross-Dimension Interaction
* Triplet Attention
* Full PyTorch Code
* Results on ImageNet, MS-COCO, and GradCAM
* Shortcomings

Article link: [https://blog.paperspace.com/triplet-attention-wacv-2021/](https://blog.paperspace.com/triplet-attention-wacv-2021/)

Comments and discussion welcome!",t2_15en0l,False,,0,False,[Article] Triplet Attention in Computer Vision Models Explained,[],r/deeplearning,False,6,,0,,False,t3_mdrqh7,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1616802953.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In this article, we will cover a new form of channel and spatial attention known as Triplet Attention (accepted at WACV 2021), with full Python (PyTorch) code included.&lt;/p&gt;

&lt;p&gt;Topics covered include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Channel and Spatial Attention&lt;/li&gt;
&lt;li&gt;SENet&lt;/li&gt;
&lt;li&gt;CBAM&lt;/li&gt;
&lt;li&gt;Drawbacks to Current Attention Mechanisms&lt;/li&gt;
&lt;li&gt;Cross-Dimension Interaction&lt;/li&gt;
&lt;li&gt;Triplet Attention&lt;/li&gt;
&lt;li&gt;Full PyTorch Code&lt;/li&gt;
&lt;li&gt;Results on ImageNet, MS-COCO, and GradCAM&lt;/li&gt;
&lt;li&gt;Shortcomings&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Article link: &lt;a href=""https://blog.paperspace.com/triplet-attention-wacv-2021/""&gt;https://blog.paperspace.com/triplet-attention-wacv-2021/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Comments and discussion welcome!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mdrqh7,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mdrqh7/article_triplet_attention_in_computer_vision/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mdrqh7/article_triplet_attention_in_computer_vision/,66146,1616774153.0,0,,False,,,,,,,
,deeplearning,"This new paper University of Edinburgh and University of Oxford looks shooting methods that applied tools from algebraic topology to extract information on the underlying structure of the solution space.

\[[5-Minute Paper Presentation](https://crossminds.ai/video/memory-clustering-using-persistent-homology-for-multimodality-and-discontinuity-sensitive-learning-of-optimal-control-warm-starts-605cfad44f676443d7bc0060/)\] \[[arXiv Paper](https://arxiv.org/abs/2010.01024)\]

**Abstract:** Shooting methods are an efficient approach to solving nonlinear optimal control problems. As they use local optimization, they exhibit favorable convergence when initialized with a good warm-start but may not converge at all if provided with a poor initial guess. Recent work has focused on providing an initial guess from a learned model trained on samples generated during an offline exploration of the problem space. However, in practice the solutions contain discontinuities introduced by system dynamics or the environment. Additionally, in many cases multiple equally suitable, i.e., multi-modal, solutions exist to solve a problem. Classic learning approaches smooth across the boundary of these discontinuities and thus generalize poorly. In this work, we apply tools from algebraic topology to extract information on the underlying structure of the solution space. In particular, we introduce a method based on persistent homology to automatically cluster the dataset of precomputed solutions to obtain different candidate initial guesses. We then train a Mixture-of-Experts within each cluster to predict state and control trajectories to warm-start the optimal control solver and provide a comparison with modality-agnostic learning. We demonstrate our method on a cart-pole toy problem and a quadrotor avoiding obstacles, and show that clustering samples based on inherent structure improves the warm-start quality.

&amp;#x200B;

[Example of the model](https://preview.redd.it/ns6333vw8ap61.png?width=923&amp;format=png&amp;auto=webp&amp;s=e5728e26bd2e8ab4e7988ab223d9c7fae68f5834)

**Authors:** Wolfgang Merkt, Vladimir Ivan, Traiko Dinev, Ioannis Havoutis, Sethu Vijayakumar (University of Edinburgh, University of Oxford)",t2_1uoh1xj8,False,,0,False,Memory Clustering using Persistent Homology for Multimodality- and Discontinuity-Sensitive Learning of Optimal Control Warm-starts,[],r/deeplearning,False,6,,0,,False,t3_mdekwv,False,dark,0.84,,public,12,0,{},,False,[],,False,False,,{},,False,12,,False,False,,False,,[],{},,True,,1616754234.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This new paper University of Edinburgh and University of Oxford looks shooting methods that applied tools from algebraic topology to extract information on the underlying structure of the solution space.&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://crossminds.ai/video/memory-clustering-using-persistent-homology-for-multimodality-and-discontinuity-sensitive-learning-of-optimal-control-warm-starts-605cfad44f676443d7bc0060/""&gt;5-Minute Paper Presentation&lt;/a&gt;] [&lt;a href=""https://arxiv.org/abs/2010.01024""&gt;arXiv Paper&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt; Shooting methods are an efficient approach to solving nonlinear optimal control problems. As they use local optimization, they exhibit favorable convergence when initialized with a good warm-start but may not converge at all if provided with a poor initial guess. Recent work has focused on providing an initial guess from a learned model trained on samples generated during an offline exploration of the problem space. However, in practice the solutions contain discontinuities introduced by system dynamics or the environment. Additionally, in many cases multiple equally suitable, i.e., multi-modal, solutions exist to solve a problem. Classic learning approaches smooth across the boundary of these discontinuities and thus generalize poorly. In this work, we apply tools from algebraic topology to extract information on the underlying structure of the solution space. In particular, we introduce a method based on persistent homology to automatically cluster the dataset of precomputed solutions to obtain different candidate initial guesses. We then train a Mixture-of-Experts within each cluster to predict state and control trajectories to warm-start the optimal control solver and provide a comparison with modality-agnostic learning. We demonstrate our method on a cart-pole toy problem and a quadrotor avoiding obstacles, and show that clustering samples based on inherent structure improves the warm-start quality.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/ns6333vw8ap61.png?width=923&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e5728e26bd2e8ab4e7988ab223d9c7fae68f5834""&gt;Example of the model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Wolfgang Merkt, Vladimir Ivan, Traiko Dinev, Ioannis Havoutis, Sethu Vijayakumar (University of Edinburgh, University of Oxford)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mdekwv,True,,m1900kang2,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mdekwv/memory_clustering_using_persistent_homology_for/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mdekwv/memory_clustering_using_persistent_homology_for/,66146,1616725434.0,0,,False,,,"{'ns6333vw8ap61': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 57, 'x': 108, 'u': 'https://preview.redd.it/ns6333vw8ap61.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b04362bc9d5a1ed93225c38b4a7de0bac0c62b78'}, {'y': 114, 'x': 216, 'u': 'https://preview.redd.it/ns6333vw8ap61.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9b69da4f91109cd47454bece1b13c9b80cccbe7c'}, {'y': 169, 'x': 320, 'u': 'https://preview.redd.it/ns6333vw8ap61.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8424f4d9b68f529b4f5a9c19f4ef44265b09e717'}, {'y': 339, 'x': 640, 'u': 'https://preview.redd.it/ns6333vw8ap61.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6c271a3ab5bcee0d31011a16276bf30f74fa173c'}], 's': {'y': 490, 'x': 923, 'u': 'https://preview.redd.it/ns6333vw8ap61.png?width=923&amp;format=png&amp;auto=webp&amp;s=e5728e26bd2e8ab4e7988ab223d9c7fae68f5834'}, 'id': 'ns6333vw8ap61'}}",,,,
,deeplearning,"   I got a question really bothered me for some time, and still cannot answer, I once heard (in an online course I was studying) that: we need convolution because if we tried to map each input of an image (pixel) to each neuron in a standard linear layer the number of parameters will grow massively, and also we don't know the image size in advance, Convolution doesn't need to know the input size, it will scan the whole input anyways.

   This second point is where my problem starts because in every model I saw so far the convolution is followed by linear layer/s, which need to know the number of inputs clearly, so the question is What is the reality do we need to put all of the inputs (images) in the same size? and how we could do so? or could any NN at all deal with inputs of different sizes?

One more thing I really want to know, how may I check for repeated questions in timely manner without checking tons of posts?",t2_2jafwe4f,False,,0,False,Size Interpretation,[],r/deeplearning,False,6,,0,,False,t3_mdph0o,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1616796556.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I got a question really bothered me for some time, and still cannot answer, I once heard (in an online course I was studying) that: we need convolution because if we tried to map each input of an image (pixel) to each neuron in a standard linear layer the number of parameters will grow massively, and also we don&amp;#39;t know the image size in advance, Convolution doesn&amp;#39;t need to know the input size, it will scan the whole input anyways.&lt;/p&gt;

&lt;p&gt;This second point is where my problem starts because in every model I saw so far the convolution is followed by linear layer/s, which need to know the number of inputs clearly, so the question is What is the reality do we need to put all of the inputs (images) in the same size? and how we could do so? or could any NN at all deal with inputs of different sizes?&lt;/p&gt;

&lt;p&gt;One more thing I really want to know, how may I check for repeated questions in timely manner without checking tons of posts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mdph0o,True,,hussein294,,10,True,all_ads,False,[],False,,/r/deeplearning/comments/mdph0o/size_interpretation/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mdph0o/size_interpretation/,66146,1616767756.0,0,,False,,,,,,,
,deeplearning,"Hello guys, I am considering buying a gaming laptop for Deep Learning stuff. At the moment HP Omen 15 and razer blade 15 are in my list. After buying I would like to replace Windows OS by Ubuntu 20.04. The concern for me is how would I be able to switch in between default and performance modes and control fan speeds offered by the manufacturers' software available only in Windows OS. Any lead here would be helpful. Thanks!",t2_a01j9y9x,False,,0,False,Ubuntu 20.04 in Gaming Laptop,[],r/deeplearning,False,6,,0,,False,t3_mdot3a,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1616794607.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello guys, I am considering buying a gaming laptop for Deep Learning stuff. At the moment HP Omen 15 and razer blade 15 are in my list. After buying I would like to replace Windows OS by Ubuntu 20.04. The concern for me is how would I be able to switch in between default and performance modes and control fan speeds offered by the manufacturers&amp;#39; software available only in Windows OS. Any lead here would be helpful. Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mdot3a,True,,Big_Carpenter_6236,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/mdot3a/ubuntu_2004_in_gaming_laptop/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mdot3a/ubuntu_2004_in_gaming_laptop/,66146,1616765807.0,0,,False,,,,,,,
,deeplearning,"I am a beginner in the field of Reinforcement Learning with only a couple of experience being in the field. Soon, I will be starting working on a project where we want to optimize the production of a chemical unit through a reinforcement learning approach. From the SME's, we already obtained a simulator code that can take some input and render us the output. A part of our output is our objective function that we want to maximize by tuning the input variables. From a reinforcement learning angle, the inputs will be the agent actions, while the state and reward can be obtained from the output. We are currently in the process of building a RL environment the major part of which is the simulator code described above.

We were talking to a RL expert and she mentioned that one of the thing that we have here conceptually wrong is that our environment will not have the Markov property in the sense that its really a 'one-step process' with the process not continuing from the previous state and there is no sort of continuity in state transitions. She is correct there. This made me think, how can we get around this then. Can we perhaps append some part of the current state to the next state etc. More importantly, I have seen RL applied to optimal control in other examples as well which are non-markovian ex. scheduling, tsp problems etc. What is the explanation in such cases? Does one simply assumes process to be markovian with unknown transition function?

Pardon me if my question appears too open ended but I am keen to seek some advice through this forum and would like to receive pointers helpful to think in right direction. Also, I think many others will find this question relevant too in the future.",t2_4sn8d9,False,,0,False,Reinforcement Learning for an environment that is non-markovian,[],r/deeplearning,False,6,,0,,False,t3_mdgm1t,False,dark,1.0,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1616761426.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am a beginner in the field of Reinforcement Learning with only a couple of experience being in the field. Soon, I will be starting working on a project where we want to optimize the production of a chemical unit through a reinforcement learning approach. From the SME&amp;#39;s, we already obtained a simulator code that can take some input and render us the output. A part of our output is our objective function that we want to maximize by tuning the input variables. From a reinforcement learning angle, the inputs will be the agent actions, while the state and reward can be obtained from the output. We are currently in the process of building a RL environment the major part of which is the simulator code described above.&lt;/p&gt;

&lt;p&gt;We were talking to a RL expert and she mentioned that one of the thing that we have here conceptually wrong is that our environment will not have the Markov property in the sense that its really a &amp;#39;one-step process&amp;#39; with the process not continuing from the previous state and there is no sort of continuity in state transitions. She is correct there. This made me think, how can we get around this then. Can we perhaps append some part of the current state to the next state etc. More importantly, I have seen RL applied to optimal control in other examples as well which are non-markovian ex. scheduling, tsp problems etc. What is the explanation in such cases? Does one simply assumes process to be markovian with unknown transition function?&lt;/p&gt;

&lt;p&gt;Pardon me if my question appears too open ended but I am keen to seek some advice through this forum and would like to receive pointers helpful to think in right direction. Also, I think many others will find this question relevant too in the future.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mdgm1t,True,,yourboyrabbit,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mdgm1t/reinforcement_learning_for_an_environment_that_is/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mdgm1t/reinforcement_learning_for_an_environment_that_is/,66146,1616732626.0,0,,False,,,,,,,
,deeplearning,,t2_79p1h62w,False,,0,False,Quantum brain: The hidden answers to the open questions in AI,[],r/deeplearning,False,6,,0,,False,t3_mdgsnj,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1616762148.0,text,6,,,text,artiba.org,False,,,,,https://www.artiba.org/blog/quantum-brain-the-hidden-answers-to-the-open-questions-in-ai,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mdgsnj,True,,Shradha_Singh,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mdgsnj/quantum_brain_the_hidden_answers_to_the_open/,all_ads,False,https://www.artiba.org/blog/quantum-brain-the-hidden-answers-to-the-open-questions-in-ai,66146,1616733348.0,0,,False,,,,,,,
,deeplearning,"Hi,

I recently went through the Attention is All You Need paper, as well as some blog posts on the original Transformer model described in the paper.

There were two things that I thought was unclear, specifically with respect to the Decoder stack.

1. During the decoding phase at position i = 1, (i.e. the first token of the output sequence the decoder is trying to predict), how is the decoder able to output anything useful when it doesn't have any input? Well technically, it does have the output sequence as input, they will all be masked to -Inf since decoder is not allowed to see positions greater or equal than the current phase position. Also, if you think about it on high level, it doesn't make sense to me that the decoder is calculating the attention values of the output token against each input tokens, when there *is no* output token.

&gt;We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i

2. Each encoder sub-layer outputs a \*list of vectors\* (one attention vector for each token), or you can also think of it has outputting a \*matrix\*. It is also highly emphasized that the decoder sub-layers are symmetric to the encoder sub-layers, so I'm guessing the output of each decoder sub-layer is also a matrix. Furthermore, the paper says each decoder sub-layer gets a residual connection, which strengthens my guess. Then how does the final layer, the linear and softmax layer, use the matrix to output a single vector (the softmax probabilities)? As an illustration to my point, let's say the decoder phase at position 6. The output of the decoder sub-layer would be five 512-dimension vectors representing the attention values. Or you can think of it as a 5 x 512 matrix. Then I'm not sure how any linear transformation can create a 1x37000 vector, where 37000 is the target vocabulary size.",t2_4xnu0yiq,False,,0,False,Novice questions on the Transformer architecture (focusing on the Decoder stack),[],r/deeplearning,False,6,,0,,False,t3_md3rtd,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,1616694934.0,,[],{},,True,,1616722561.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;/p&gt;

&lt;p&gt;I recently went through the Attention is All You Need paper, as well as some blog posts on the original Transformer model described in the paper.&lt;/p&gt;

&lt;p&gt;There were two things that I thought was unclear, specifically with respect to the Decoder stack.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;During the decoding phase at position i = 1, (i.e. the first token of the output sequence the decoder is trying to predict), how is the decoder able to output anything useful when it doesn&amp;#39;t have any input? Well technically, it does have the output sequence as input, they will all be masked to -Inf since decoder is not allowed to see positions greater or equal than the current phase position. Also, if you think about it on high level, it doesn&amp;#39;t make sense to me that the decoder is calculating the attention values of the output token against each input tokens, when there &lt;em&gt;is no&lt;/em&gt; output token.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
&lt;li&gt;Each encoder sub-layer outputs a *list of vectors* (one attention vector for each token), or you can also think of it has outputting a *matrix*. It is also highly emphasized that the decoder sub-layers are symmetric to the encoder sub-layers, so I&amp;#39;m guessing the output of each decoder sub-layer is also a matrix. Furthermore, the paper says each decoder sub-layer gets a residual connection, which strengthens my guess. Then how does the final layer, the linear and softmax layer, use the matrix to output a single vector (the softmax probabilities)? As an illustration to my point, let&amp;#39;s say the decoder phase at position 6. The output of the decoder sub-layer would be five 512-dimension vectors representing the attention values. Or you can think of it as a 5 x 512 matrix. Then I&amp;#39;m not sure how any linear transformation can create a 1x37000 vector, where 37000 is the target vocabulary size.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,md3rtd,True,,sir-codesalot,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/md3rtd/novice_questions_on_the_transformer_architecture/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/md3rtd/novice_questions_on_the_transformer_architecture/,66146,1616693761.0,0,,False,,,,,,,
,deeplearning,"Under the Cluster Configuration-&gt;Master Config, according to this [LINK](https://docs.determined.ai/0.12.3/reference/cluster-config.html) 
&gt; When training a model with multiple machines, the host network interface used by each machine MUST have the same interface name across machines.

What is the effect of having the same interface name on all of your machines?

And Did you managed to run agents on multiple different Co-Los? how did it go for you guys? 

what we are experiencing right now is, it takes more time if we do a distributed learning on 2 or more machines in different locations compared to just running one machine. In other words the job is done faster by only using one machine.",t2_65vj12re,False,,0,False,Question for those who already worked with Determined AI,[],r/deeplearning,False,6,,0,,False,t3_mcrlza,False,dark,0.94,,public,15,0,{},,False,[],,False,False,,{},,False,15,,False,False,,False,,[],{},,True,,1616681828.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Under the Cluster Configuration-&amp;gt;Master Config, according to this &lt;a href=""https://docs.determined.ai/0.12.3/reference/cluster-config.html""&gt;LINK&lt;/a&gt; &lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When training a model with multiple machines, the host network interface used by each machine MUST have the same interface name across machines.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What is the effect of having the same interface name on all of your machines?&lt;/p&gt;

&lt;p&gt;And Did you managed to run agents on multiple different Co-Los? how did it go for you guys? &lt;/p&gt;

&lt;p&gt;what we are experiencing right now is, it takes more time if we do a distributed learning on 2 or more machines in different locations compared to just running one machine. In other words the job is done faster by only using one machine.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mcrlza,True,,monk_hasu,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/mcrlza/question_for_those_who_already_worked_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mcrlza/question_for_those_who_already_worked_with/,66146,1616653028.0,0,,False,,,,,,,
,deeplearning,"Hey all, need people with a knowledge/interest of Deep learning/ Ai to fill out this survey. 

You are being invited to take part in a short online survey (5-10 minutes), conducted by 2nd-year psychology students at the University of Liverpool, exploring your perceptions of artificial intelligence in healthcare. If you are 18 or over and fluent in English, you are eligible to participate.

https://livpsych.eu.qualtrics.com/jfe/form/SV_eCCHeVzRvR78goC?fbclid=IwAR0efuUyzkOGURdWU6hZEU20icoQQ4iAiXiKBa27oi8U_Xta4z9RobR0HSw",t2_90w0ejl3,False,,0,False,Deep learning survey,[],r/deeplearning,False,6,,0,,False,t3_mcxzv9,False,dark,0.63,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1616707001.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey all, need people with a knowledge/interest of Deep learning/ Ai to fill out this survey. &lt;/p&gt;

&lt;p&gt;You are being invited to take part in a short online survey (5-10 minutes), conducted by 2nd-year psychology students at the University of Liverpool, exploring your perceptions of artificial intelligence in healthcare. If you are 18 or over and fluent in English, you are eligible to participate.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://livpsych.eu.qualtrics.com/jfe/form/SV_eCCHeVzRvR78goC?fbclid=IwAR0efuUyzkOGURdWU6hZEU20icoQQ4iAiXiKBa27oi8U_Xta4z9RobR0HSw""&gt;https://livpsych.eu.qualtrics.com/jfe/form/SV_eCCHeVzRvR78goC?fbclid=IwAR0efuUyzkOGURdWU6hZEU20icoQQ4iAiXiKBa27oi8U_Xta4z9RobR0HSw&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mcxzv9,True,,tylerm12341,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mcxzv9/deep_learning_survey/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mcxzv9/deep_learning_survey/,66146,1616678201.0,0,,False,,,,,,,
,deeplearning,Is information fusion essential for other visual linguistic problems except for VQA?,t2_6dydfryy,False,,0,False,Is information fusion essential for other visual linguistic problems except for VQA?,[],r/deeplearning,False,6,,0,,False,t3_mcu17w,False,dark,0.64,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1616692444.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is information fusion essential for other visual linguistic problems except for VQA?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mcu17w,True,,pppfly,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mcu17w/is_information_fusion_essential_for_other_visual/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mcu17w/is_information_fusion_essential_for_other_visual/,66146,1616663644.0,0,,False,,,,,,,
,deeplearning,"Hello community, I was wondering if DenseNet was robust to layer removal as ResNet ?

Can we compare concatenation with skipping connection in this case ?

&amp;#x200B;

I did some tests, and it seems that DenseNet performs poorly when deleting one the last blocks, compared to ResNet or MobileNet that use skip connections.

&amp;#x200B;

What do you think ?",t2_7l9ti89m,False,,0,False,[Question] Is DenseNet resilient to blocks deletion ?,[],r/deeplearning,False,6,,0,,False,t3_mcvkaw,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1616698739.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello community, I was wondering if DenseNet was robust to layer removal as ResNet ?&lt;/p&gt;

&lt;p&gt;Can we compare concatenation with skipping connection in this case ?&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I did some tests, and it seems that DenseNet performs poorly when deleting one the last blocks, compared to ResNet or MobileNet that use skip connections.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;What do you think ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mcvkaw,True,,rayanaay,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mcvkaw/question_is_densenet_resilient_to_blocks_deletion/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mcvkaw/question_is_densenet_resilient_to_blocks_deletion/,66146,1616669939.0,0,,False,,,,,,,
,deeplearning,"Transfer learning automates image annotation.

[The article](https://blog.superannotate.com/speed-up-labeling-process-using-transfer-learning) presents a tutorial on how transfer learning works and how it's applied towards accelerating the image labeling process without having to use coding!",t2_810pw8v7,False,,0,False,Speed up image labeling using transfer learning (no code required),[],r/deeplearning,False,6,,0,,False,t3_mcv2mj,False,dark,0.43,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1616696759.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Transfer learning automates image annotation.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://blog.superannotate.com/speed-up-labeling-process-using-transfer-learning""&gt;The article&lt;/a&gt; presents a tutorial on how transfer learning works and how it&amp;#39;s applied towards accelerating the image labeling process without having to use coding!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mcv2mj,True,,WeekendClassic,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mcv2mj/speed_up_image_labeling_using_transfer_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mcv2mj/speed_up_image_labeling_using_transfer_learning/,66146,1616667959.0,0,,False,,,,,,,
,deeplearning,,t2_44mbtmjy,False,,0,False,From MIT CSAIL researchers! Create novel images using GANs! (checkout where they create a new face using faces of 4 different people),[],r/deeplearning,False,6,,0,,False,t3_mcf3h3,False,dark,0.67,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,False,,1616644805.0,text,6,,,text,self.LatestInML,False,,,,,/r/LatestInML/comments/mcexhf/from_mit_csail_researchers_create_novel_images/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mcf3h3,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/mcf3h3/from_mit_csail_researchers_create_novel_images/,all_ads,False,/r/LatestInML/comments/mcexhf/from_mit_csail_researchers_create_novel_images/,66146,1616616005.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': "" [link to paper](https://www.catalyzex.com/paper/arxiv:2103.10426)\n\nhttps://reddit.com/link/mcexhf/video/41u49nmk61p61/player\n\n👇 Free extension to get code for ML papers (❤️' by Andrew Ng)  \nChrome: https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil  \nFirefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'From MIT CSAIL researchers! Create novel images using GANs! (checkout where they create a new face using faces of 4 different people)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'41u49nmk61p61': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/mcexhf/asset/41u49nmk61p61/DASHPlaylist.mpd?a=1626450702%2CYzJhOWFmYWIzMGUzY2VhMGU2MGZhYmU3ZDAwZTdiZDk5Mzg2NTljNDdhMGNmNTU1OTYyNTU3NzYxOWVhOGM0NQ%3D%3D&amp;v=1&amp;f=sd', 'x': 426, 'y': 213, 'hlsUrl': 'https://v.redd.it/link/mcexhf/asset/41u49nmk61p61/HLSPlaylist.m3u8?a=1626450702%2CMzM3NzJiYTY1OTc4ZDFiNzdmYjRhZmU0M2RlMGI3NGI1NTVjNTk2MWM2ZTRjMTY0YTY0ZDcyYmI5MDRiM2YyYQ%3D%3D&amp;v=1&amp;f=sd', 'id': '41u49nmk61p61', 'isGif': False}}, 'name': 't3_mcexhf', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.97, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 21, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 21, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1616644378.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2103.10426""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/mcexhf/video/41u49nmk61p61/player""&gt;https://reddit.com/link/mcexhf/video/41u49nmk61p61/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39; by Andrew Ng)&lt;br/&gt;\nChrome: &lt;a href=""https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;br/&gt;\nFirefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'mcexhf', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/mcexhf/from_mit_csail_researchers_create_novel_images/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/mcexhf/from_mit_csail_researchers_create_novel_images/', 'subreddit_subscribers': 7049, 'created_utc': 1616615578.0, 'num_crossposts': 11, 'media': None, 'is_video': False}]",t3_mcexhf,,,,,
,deeplearning,"[**Univ.AI**](http://univ.ai/) is an institution founded by **Harvard &amp; UCLA** professors of Artificial Intelligence and Machine Learning aiming to make state-of-the-art AI education available beyond the confines of the world’s top institutions.

We are inaugurating and launching [Geoffrey Hinton Fellowship (GHF)](https://www.univ.ai/ghf) for Artificial Intelligence and Machine Learning as a pre-eminent platform for recognising and rewarding the nation's top talent in AI, Machine Learning and Data Science. GHF inauguration will be graced by an enriching lecture on **part-whole hierarchies in neural networks by Prof. Geoffrey Hinton** himself.

We invite all the fellow Redditors for this rare &amp; exclusive opportunity to attend **Prof. Geoffrey Hinton’s lecture on 27th March 2021, 9 AM IST.** The lecture will be followed by a Q&amp;A session. **Watch Geoff Hinton’s last interview with** [**Andrew Ng here**](https://youtu.be/-eyhCTvrEtE)

**Seats are limited.**  [**Register**](https://www.univ.ai/events/geoffrey-hinton-live?ref=GHF-EXPERIMENTATION) for FREE on the GHF page to interact with Geoff Hinton LIVE.

**About Prof. Geoffrey Hinton**

Prof Geoffrey Hinton is known to many as the **Godfather of AI.** He introduced the famous backpropagation algorithm in his seminal 1986 paper and has made immense contributions to **deep learning**. He is the recipient of the prestigious **Turing Award** and currently splits his time as a professor of Computer Science at the University of Toronto and as the VP and Engineering Fellow at Google.

Best,

Team [Univ.AI](http://univ.ai/)",t2_4wi2vktr,False,,0,False,Geoffrey Hinton Fellowship for Artificial Intelligence | Godfather of AI Live,[],r/deeplearning,False,6,,0,,False,t3_mbzox6,False,dark,0.86,,public,34,0,{},,False,[],,False,False,,{},,False,34,,False,False,,False,,[],{},,True,,1616598372.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""http://univ.ai/""&gt;&lt;strong&gt;Univ.AI&lt;/strong&gt;&lt;/a&gt; is an institution founded by &lt;strong&gt;Harvard &amp;amp; UCLA&lt;/strong&gt; professors of Artificial Intelligence and Machine Learning aiming to make state-of-the-art AI education available beyond the confines of the world’s top institutions.&lt;/p&gt;

&lt;p&gt;We are inaugurating and launching &lt;a href=""https://www.univ.ai/ghf""&gt;Geoffrey Hinton Fellowship (GHF)&lt;/a&gt; for Artificial Intelligence and Machine Learning as a pre-eminent platform for recognising and rewarding the nation&amp;#39;s top talent in AI, Machine Learning and Data Science. GHF inauguration will be graced by an enriching lecture on &lt;strong&gt;part-whole hierarchies in neural networks by Prof. Geoffrey Hinton&lt;/strong&gt; himself.&lt;/p&gt;

&lt;p&gt;We invite all the fellow Redditors for this rare &amp;amp; exclusive opportunity to attend &lt;strong&gt;Prof. Geoffrey Hinton’s lecture on 27th March 2021, 9 AM IST.&lt;/strong&gt; The lecture will be followed by a Q&amp;amp;A session. &lt;strong&gt;Watch Geoff Hinton’s last interview with&lt;/strong&gt; &lt;a href=""https://youtu.be/-eyhCTvrEtE""&gt;&lt;strong&gt;Andrew Ng here&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Seats are limited.&lt;/strong&gt;  &lt;a href=""https://www.univ.ai/events/geoffrey-hinton-live?ref=GHF-EXPERIMENTATION""&gt;&lt;strong&gt;Register&lt;/strong&gt;&lt;/a&gt; for FREE on the GHF page to interact with Geoff Hinton LIVE.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;About Prof. Geoffrey Hinton&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Prof Geoffrey Hinton is known to many as the &lt;strong&gt;Godfather of AI.&lt;/strong&gt; He introduced the famous backpropagation algorithm in his seminal 1986 paper and has made immense contributions to &lt;strong&gt;deep learning&lt;/strong&gt;. He is the recipient of the prestigious &lt;strong&gt;Turing Award&lt;/strong&gt; and currently splits his time as a professor of Computer Science at the University of Toronto and as the VP and Engineering Fellow at Google.&lt;/p&gt;

&lt;p&gt;Best,&lt;/p&gt;

&lt;p&gt;Team &lt;a href=""http://univ.ai/""&gt;Univ.AI&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,mbzox6,True,,Hound301099,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/mbzox6/geoffrey_hinton_fellowship_for_artificial/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/mbzox6/geoffrey_hinton_fellowship_for_artificial/,66146,1616569572.0,0,,False,,,,,,,
,deeplearning,,t2_ap2kjhxj,False,,0,False,(Data Science Humour) I've found this to be really accurate. Making something from scratch and then moving on to libraries is the best way to learn.,[],r/deeplearning,False,6,,0,,False,t3_o0m0lk,False,dark,0.9,,public,153,0,{},,False,[],,True,False,,{},,False,153,,False,False,,False,,[],{},,False,,1623812858.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/adgnnwvx9h571.jpg,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0m0lk,True,,alan_turing8,,26,True,all_ads,False,[],False,,/r/deeplearning/comments/o0m0lk/data_science_humour_ive_found_this_to_be_really/,all_ads,False,https://i.redd.it/adgnnwvx9h571.jpg,66146,1623784058.0,0,,False,,,,,,,
,deeplearning,"A research team from Mila, McGill University, Université de Montréal, DeepMind and Microsoft proposes GFlowNet, a novel flow network-based generative method that can turn a given positive reward into a generative policy that samples with a probability proportional to the return. 

Here is a quick read: [Bengio Team Proposes Flow Network-Based Generative Models That Learn a Stochastic Policy From a Sequence of Actions.](https://syncedreview.com/2021/06/16/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-42/)

The implementations are available on the project [GitHub](https://github.com/bengioe/gflownet). The paper *Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation* is on [arXiv](https://arxiv.org/abs/2106.04399).",t2_2fv4yodo,False,,0,False,[R] Bengio Team Proposes Flow Network-Based Generative Models That Learn a Stochastic Policy From a Sequence of Actions,[],r/deeplearning,False,6,,0,,True,t3_o17stp,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623886845.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Mila, McGill University, Université de Montréal, DeepMind and Microsoft proposes GFlowNet, a novel flow network-based generative method that can turn a given positive reward into a generative policy that samples with a probability proportional to the return. &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/16/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-42/""&gt;Bengio Team Proposes Flow Network-Based Generative Models That Learn a Stochastic Policy From a Sequence of Actions.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The implementations are available on the project &lt;a href=""https://github.com/bengioe/gflownet""&gt;GitHub&lt;/a&gt;. The paper &lt;em&gt;Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2106.04399""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o17stp,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o17stp/r_bengio_team_proposes_flow_networkbased/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o17stp/r_bengio_team_proposes_flow_networkbased/,66146,1623858045.0,0,,False,,,,,,,
,deeplearning,,t2_hmbd5,False,,0,False,Tutorial for novice: How do we make the machine automatically classify crocodiles and snakes?,[],r/deeplearning,False,6,,0,,True,t3_o15nqp,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/EEZ_PrvqHXk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': '2. How do we make the machine automatically classify crocodiles and snakes?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/EEZ_PrvqHXk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Chier Hu', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/EEZ_PrvqHXk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ChierHu'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/EEZ_PrvqHXk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/o15nqp', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1623881060.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/EEZ_PrvqHXk,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o15nqp,True,,RossJD,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o15nqp/tutorial_for_novice_how_do_we_make_the_machine/,all_ads,False,https://youtu.be/EEZ_PrvqHXk,66146,1623852260.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': '2. How do we make the machine automatically classify crocodiles and snakes?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/EEZ_PrvqHXk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Chier Hu', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/EEZ_PrvqHXk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ChierHu'}}",False,,,,,,,
,deeplearning,"I have trained a posture analysis network to classify in a video of humans recorded in public places if there is a) shake-hand between two humans, b) Standing close together that their hands touch each other but not shake hand and c) No interaction at all. There are multiple labels to identify different parts of a human. The labels are done to train the network to spot hand-shaking in a large dataset of videos of humans recorded in public. As you can guess, this leads to an imbalanced dataset. To train, I sampled data such that 60% of my input contained handshaking images and the rest contained different images than hand-shaking. In this network, we are not looking at just labels but also the relative position of individual labels wrt to one another. We have an algorithm that can then classify them into the three classes.

&amp;#x200B;

I am stuck on how to evaluate the performance of this network. I have a large dataset and it is not labeled. So I have decided to pick 25 from class A) and B) and 50 from class (C) to create a small test dataset(with labels) to show the performance of the network. And to run the network on the large dataset without labels, but because classes A and B are quite rare events, I would be able to individually access the accuracy of the network prediction of True positive and false-positive cases.

&amp;#x200B;

Is this a sound way to evaluate ? Can anyone having experience or opinion share their input on this? How else can I evaluate this?",t2_c5febi8b,False,,0,False,Evaluating a convolutional neural network on an imbalanced (academic) dataset,[],r/deeplearning,False,6,,0,,False,t3_o14as5,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623877215.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have trained a posture analysis network to classify in a video of humans recorded in public places if there is a) shake-hand between two humans, b) Standing close together that their hands touch each other but not shake hand and c) No interaction at all. There are multiple labels to identify different parts of a human. The labels are done to train the network to spot hand-shaking in a large dataset of videos of humans recorded in public. As you can guess, this leads to an imbalanced dataset. To train, I sampled data such that 60% of my input contained handshaking images and the rest contained different images than hand-shaking. In this network, we are not looking at just labels but also the relative position of individual labels wrt to one another. We have an algorithm that can then classify them into the three classes.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am stuck on how to evaluate the performance of this network. I have a large dataset and it is not labeled. So I have decided to pick 25 from class A) and B) and 50 from class (C) to create a small test dataset(with labels) to show the performance of the network. And to run the network on the large dataset without labels, but because classes A and B are quite rare events, I would be able to individually access the accuracy of the network prediction of True positive and false-positive cases.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Is this a sound way to evaluate ? Can anyone having experience or opinion share their input on this? How else can I evaluate this?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o14as5,True,,popkept09,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o14as5/evaluating_a_convolutional_neural_network_on_an/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o14as5/evaluating_a_convolutional_neural_network_on_an/,66146,1623848415.0,0,,False,,,,,,,
,deeplearning,"Hello to everyone, I have a Dockerfile with my Neural Network and a Flask API to make calls.

Do you have a tutorial on deploying this Dockerfile on a google cloud machine with GPU, with the possibility to scale it depending on the number of requests (like it happens with Cloud Run).

I know the existence of GKE, I am just wondering if there's a tutorial that goes straight to the point.

Thanks",t2_b79ww8lt,False,,0,False,deploy on google cloud GPU,[],r/deeplearning,False,6,,0,,False,t3_o134ag,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623873346.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello to everyone, I have a Dockerfile with my Neural Network and a Flask API to make calls.&lt;/p&gt;

&lt;p&gt;Do you have a tutorial on deploying this Dockerfile on a google cloud machine with GPU, with the possibility to scale it depending on the number of requests (like it happens with Cloud Run).&lt;/p&gt;

&lt;p&gt;I know the existence of GKE, I am just wondering if there&amp;#39;s a tutorial that goes straight to the point.&lt;/p&gt;

&lt;p&gt;Thanks&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o134ag,True,,pemstr,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o134ag/deploy_on_google_cloud_gpu/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o134ag/deploy_on_google_cloud_gpu/,66146,1623844546.0,0,,False,,,,,,,
,deeplearning,"[Self Organizing Map](https://pythoncodingai.com/self-organizing-map/) (or Kohonen Map or SOM) is a order of [Artificial Neural](https://pythoncodingai.com/self-organizing-map/) net which is likewise heartened by consanguineous miniatures of neural complexes crystallize the 1970 ’s . It follows an unsupervised earnestness path and conditioned its net through a competitive clearness algorithm . SOM is harnessed for clustering and mapping (or measurement deduction) styles to conspire multidimensional data onto minor - dimensional which allows people to demote knotty matters for royal exposition . SOM has two layers, one is the Intake stratum and the distant one is the handiwork stratum .",t2_cr5c9b0q,False,,0,False,What is Self Organizing Map ? Meaning and Explained | Python Coding AI,[],r/deeplearning,False,6,,0,,False,t3_o10kj5,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623863294.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://pythoncodingai.com/self-organizing-map/""&gt;Self Organizing Map&lt;/a&gt; (or Kohonen Map or SOM) is a order of &lt;a href=""https://pythoncodingai.com/self-organizing-map/""&gt;Artificial Neural&lt;/a&gt; net which is likewise heartened by consanguineous miniatures of neural complexes crystallize the 1970 ’s . It follows an unsupervised earnestness path and conditioned its net through a competitive clearness algorithm . SOM is harnessed for clustering and mapping (or measurement deduction) styles to conspire multidimensional data onto minor - dimensional which allows people to demote knotty matters for royal exposition . SOM has two layers, one is the Intake stratum and the distant one is the handiwork stratum .&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o10kj5,True,,codingainp,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o10kj5/what_is_self_organizing_map_meaning_and_explained/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o10kj5/what_is_self_organizing_map_meaning_and_explained/,66146,1623834494.0,0,,False,,,,,,,
,deeplearning,,t2_c7lfuw9x,False,,0,False,Top 10 Deep Learning Algorithms One Should Know in 2021,[],r/deeplearning,False,6,,0,,False,t3_o102h2,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623861077.0,text,6,,,text,analyticsinsight.net,False,,,,,https://www.analyticsinsight.net/top-10-deep-learning-algorithms-one-should-know-in-2021/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o102h2,True,,Analyticsinsight01,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o102h2/top_10_deep_learning_algorithms_one_should_know/,all_ads,False,https://www.analyticsinsight.net/top-10-deep-learning-algorithms-one-should-know-in-2021/,66146,1623832277.0,0,,False,,,,,,,
,deeplearning,"Do you think about how Google Assistant or Apple’s Siri adhere to your guidelines? Do you see promotions for items you prior looked for on online business sites? What is Neural Network In the event that you have thought about how this all meets up, it is a result of . . . [Read more](https://pythoncodingai.com/what-is-neural-network/)",t2_cr5c9b0q,False,,0,False,"What is Neural Network: Overview, Applications, and Advantages 2021 | Python Coding AI",[],r/deeplearning,False,6,,0,,False,t3_o0zyee,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623860531.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Do you think about how Google Assistant or Apple’s Siri adhere to your guidelines? Do you see promotions for items you prior looked for on online business sites? What is Neural Network In the event that you have thought about how this all meets up, it is a result of . . . &lt;a href=""https://pythoncodingai.com/what-is-neural-network/""&gt;Read more&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0zyee,True,,codingainp,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0zyee/what_is_neural_network_overview_applications_and/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0zyee/what_is_neural_network_overview_applications_and/,66146,1623831731.0,0,,False,,,,,,,
,deeplearning,"TensorFlow is an open-source start to finish stage for making Machine Learning applications. It is an emblematic number related library that utilizations dataflow and differentiable programming to perform different undertakings zeroed in on preparing and surmising of profound neural organizations. It permits engineers to make AI applications utilizing different apparatuses, . . . [Read more](https://pythoncodingai.com/what-is-tensorflow-2021/)",t2_cr5c9b0q,False,,0,False,What is TensorFlow? 2021 | Python Coding AI,[],r/deeplearning,False,6,,0,,False,t3_o0zxrk,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623860444.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;TensorFlow is an open-source start to finish stage for making Machine Learning applications. It is an emblematic number related library that utilizations dataflow and differentiable programming to perform different undertakings zeroed in on preparing and surmising of profound neural organizations. It permits engineers to make AI applications utilizing different apparatuses, . . . &lt;a href=""https://pythoncodingai.com/what-is-tensorflow-2021/""&gt;Read more&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0zxrk,True,,codingainp,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/o0zxrk/what_is_tensorflow_2021_python_coding_ai/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0zxrk/what_is_tensorflow_2021_python_coding_ai/,66146,1623831644.0,0,,False,,,,,,,
,deeplearning,"We don’t make another dialect each time we talk – each human language has a constant arrangement of punctuation rules and an assortment of words that we depend on to decipher it. Long Short Term Memory Networks. As you read this article, you see each word dependent on your insight . . . [Read more](https://pythoncodingai.com/long-short-term-memory-networks/)",t2_cr5c9b0q,False,,0,False,Long Short Term Memory Networks,[],r/deeplearning,False,6,,0,,False,t3_o0za4t,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623857415.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;We don’t make another dialect each time we talk – each human language has a constant arrangement of punctuation rules and an assortment of words that we depend on to decipher it. Long Short Term Memory Networks. As you read this article, you see each word dependent on your insight . . . &lt;a href=""https://pythoncodingai.com/long-short-term-memory-networks/""&gt;Read more&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0za4t,True,,codingainp,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0za4t/long_short_term_memory_networks/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0za4t/long_short_term_memory_networks/,66146,1623828615.0,0,,False,,,,,,,
,deeplearning,,t2_auwgbh53,False,,0,False,Game search engine using Neural Networks - A demo built with 17k mobile strategy game dataset,[],r/deeplearning,False,6,,0,,False,t3_o0cjxa,False,dark,0.92,,public,27,2,{},,False,[],,True,False,,{},,False,27,,False,True,,False,,[],{},,False,,1623786769.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/aixbz2d14f571.gif,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 300, 'id': 'award_28e8196b-d4e9-45bc-b612-cd4c7d3ed4b3', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=16&amp;height=16&amp;auto=webp&amp;s=9d714b25ca25d05e3310bc60bc1714ddf7951331', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=32&amp;height=32&amp;auto=webp&amp;s=d584b15c8e17d61fa8ae319a91d351c8fe35b918', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=48&amp;height=48&amp;auto=webp&amp;s=d9fb2c025611a15e6bb4437734f92db99b93fd12', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=64&amp;height=64&amp;auto=webp&amp;s=744fb200d76bf21f6e023ba98d3b4189b34973e3', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/35d17tf5e5f61_oldrocketlike.png?width=128&amp;height=128&amp;auto=webp&amp;s=c180572afbc080622a8ac8441c3bc5214597d05a', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""When an upvote just isn't enough, smash the Rocket Like."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Rocket Like', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=16&amp;height=16&amp;auto=webp&amp;s=24fc4d912e595c3fed2ce0deef1c13f70df56056', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=32&amp;height=32&amp;auto=webp&amp;s=f9d869602e0d8b719186cc603864a42699e5c96e', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=48&amp;height=48&amp;auto=webp&amp;s=b223ac8fdd206b683b840c2782307c3f01b04fb7', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=64&amp;height=64&amp;auto=webp&amp;s=a0b840c6ecdee904012a6c53c40194733b72bca8', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png?width=128&amp;height=128&amp;auto=webp&amp;s=b2e2ca67e067f82ff9b4ea1fe1b39395ca622894', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/9fmmyy3c68361_RocketLikeSanta.png'}, {'giver_coin_reward': 0, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 80, 'id': 'award_8352bdff-3e03-4189-8a08-82501dd8f835', 'penny_donate': 0, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=16&amp;height=16&amp;auto=webp&amp;s=73a23bf7f08b633508dedf457f2704c522b94a04', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=32&amp;height=32&amp;auto=webp&amp;s=50f2f16e71d2929e3d7275060af3ad6b851dbfb1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=48&amp;height=48&amp;auto=webp&amp;s=ca487311563425e195699a4d7e4c57a98cbfde8b', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=64&amp;height=64&amp;auto=webp&amp;s=7b4eedcffb1c09a826e7837532c52979760f1d2b', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/ks45ij6w05f61_oldHugz.png?width=128&amp;height=128&amp;auto=webp&amp;s=e4d5ab237eb71a9f02bb3bf9ad5ee43741918d6c', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Everything is better with a good hug', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Hugz', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=16&amp;height=16&amp;auto=webp&amp;s=69997ace3ef4ffc099b81d774c2c8f1530602875', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=32&amp;height=32&amp;auto=webp&amp;s=e9519d1999ef9dce5c8a9f59369cb92f52d95319', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=48&amp;height=48&amp;auto=webp&amp;s=f076c6434fb2d2f9075991810fd845c40fa73fc6', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=64&amp;height=64&amp;auto=webp&amp;s=85527145e0c4b754306a30df29e584fd16187636', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png?width=128&amp;height=128&amp;auto=webp&amp;s=b8843cdf82c3b741d7af057c14076dcd2621e811', 'width': 128, 'height': 128}], 'icon_format': 'PNG', 'icon_height': 2048, 'penny_price': 0, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_q0gj4/fpm0r5ryq1361_PolarHugs.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0cjxa,True,,opensourcecolumbus,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/o0cjxa/game_search_engine_using_neural_networks_a_demo/,all_ads,False,https://i.redd.it/aixbz2d14f571.gif,66146,1623757969.0,0,,False,,,,,,,
,deeplearning,"Almost 80% of leading small-medium IT companies consider automation tools to be the key to their business success. 92% of AI startup companies think they should rely on AI to [improve their decision-making processes](https://techcrunch.com/2021/06/09/ai-startup-investment-is-on-pace-for-a-record-year/), and 79% of these respondents said they are [already doing so](https://techcrunch.com/2021/06/09/ai-startup-investment-is-on-pace-for-a-record-year/).

And more than that, today, you can fully automate marketing. We’ll tell you what you’ll get out of it and, most importantly, how to implement it — literally, the right steps and with the right tools.

What do you think of AI-powered marketing automation? I tried to put my thoughts in a [detailed guide](https://signum.ai/blog/marketing-automation-from-a-to-z/), and I sincerely want to hear your opinion.",t2_pur71,False,,0,False,Businesses are crazy about implementing AI to accelerate their marketing performance,[],r/deeplearning,False,6,,0,,False,t3_o116dy,False,dark,0.29,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623865891.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Almost 80% of leading small-medium IT companies consider automation tools to be the key to their business success. 92% of AI startup companies think they should rely on AI to &lt;a href=""https://techcrunch.com/2021/06/09/ai-startup-investment-is-on-pace-for-a-record-year/""&gt;improve their decision-making processes&lt;/a&gt;, and 79% of these respondents said they are &lt;a href=""https://techcrunch.com/2021/06/09/ai-startup-investment-is-on-pace-for-a-record-year/""&gt;already doing so&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;And more than that, today, you can fully automate marketing. We’ll tell you what you’ll get out of it and, most importantly, how to implement it — literally, the right steps and with the right tools.&lt;/p&gt;

&lt;p&gt;What do you think of AI-powered marketing automation? I tried to put my thoughts in a &lt;a href=""https://signum.ai/blog/marketing-automation-from-a-to-z/""&gt;detailed guide&lt;/a&gt;, and I sincerely want to hear your opinion.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o116dy,True,,kotik007,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o116dy/businesses_are_crazy_about_implementing_ai_to/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o116dy/businesses_are_crazy_about_implementing_ai_to/,66146,1623837091.0,0,,False,,,,,,,
,deeplearning,"Not that surprising - XGBoost still rocks when the underlying data is in a tabular form.

Original article here: [https://arxiv.org/pdf/2106.03253.pdf](https://arxiv.org/pdf/2106.03253.pdf)

More hard-to-find, independent stuff related to AI &amp; Data Science [here](https://thereshape.co/?utm_source=reddit).",t2_4gl6xq75,False,,0,False,Tabular Data: Deep Learning is Not All You Need,[],r/deeplearning,False,6,,0,,False,t3_o0l92k,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623810852.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Not that surprising - XGBoost still rocks when the underlying data is in a tabular form.&lt;/p&gt;

&lt;p&gt;Original article here: &lt;a href=""https://arxiv.org/pdf/2106.03253.pdf""&gt;https://arxiv.org/pdf/2106.03253.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;More hard-to-find, independent stuff related to AI &amp;amp; Data Science &lt;a href=""https://thereshape.co/?utm_source=reddit""&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0l92k,True,,rshpkamil,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0l92k/tabular_data_deep_learning_is_not_all_you_need/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0l92k/tabular_data_deep_learning_is_not_all_you_need/,66146,1623782052.0,0,,False,,,,,,,
,deeplearning,"65% of respondents don't know what their models are doing... Only 20% monitor them for fairness and ethics.

Original article here: [https://www.fico.com/blogs/its-2021-do-you-know-what-your-ai-doing](https://www.fico.com/blogs/its-2021-do-you-know-what-your-ai-doing)

More hard-to-find, independent stuff related to AI &amp; Data Science [here](https://thereshape.co/?utm_source=reddit).",t2_4gl6xq75,False,,0,False,It’s 2021. Do You Know What Your AI Is Doing?,[],r/deeplearning,False,6,,0,,False,t3_o0izhm,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623804946.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;65% of respondents don&amp;#39;t know what their models are doing... Only 20% monitor them for fairness and ethics.&lt;/p&gt;

&lt;p&gt;Original article here: &lt;a href=""https://www.fico.com/blogs/its-2021-do-you-know-what-your-ai-doing""&gt;https://www.fico.com/blogs/its-2021-do-you-know-what-your-ai-doing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;More hard-to-find, independent stuff related to AI &amp;amp; Data Science &lt;a href=""https://thereshape.co/?utm_source=reddit""&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0izhm,True,,rshpkamil,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/o0izhm/its_2021_do_you_know_what_your_ai_is_doing/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0izhm/its_2021_do_you_know_what_your_ai_is_doing/,66146,1623776146.0,0,,False,,,,,,,
,deeplearning,,t2_hkv9s,False,,0,False,Detecting Hallucinated Content in Conditional Neural Sequence Generation (NLP Paper Walkthrough),[],r/deeplearning,False,6,,0,,False,t3_o0dr7e,False,dark,0.75,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fD2g9s1Isi4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Detecting Hallucinated Content in Conditional Neural Sequence Generation (NLP Paper Walkthrough)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fD2g9s1Isi4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/fD2g9s1Isi4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fD2g9s1Isi4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/o0dr7e', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1623790706.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/fD2g9s1Isi4,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0dr7e,True,,prakhar21,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0dr7e/detecting_hallucinated_content_in_conditional/,all_ads,False,https://youtu.be/fD2g9s1Isi4,66146,1623761906.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Detecting Hallucinated Content in Conditional Neural Sequence Generation (NLP Paper Walkthrough)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/fD2g9s1Isi4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'TechViz - The Data Science Guy', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/fD2g9s1Isi4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TechVizTheDataScienceGuy'}}",False,,,,,,,
,deeplearning,"In other words, I just want to use a part of my model as an encoder somewhere else. Is there any format constraint that I must obey or is it even possible? I am assuming I have to use local model save because the two project are not related. Any help or advice would be much appreciated. thanks in advance",t2_5xf5u3ie,False,,0,False,I want to use a part of my keras model in another project,[],r/deeplearning,False,6,,0,,False,t3_o0hxhe,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623802139.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In other words, I just want to use a part of my model as an encoder somewhere else. Is there any format constraint that I must obey or is it even possible? I am assuming I have to use local model save because the two project are not related. Any help or advice would be much appreciated. thanks in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0hxhe,True,,mortuish,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0hxhe/i_want_to_use_a_part_of_my_keras_model_in_another/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0hxhe/i_want_to_use_a_part_of_my_keras_model_in_another/,66146,1623773339.0,0,,False,,,,,,,
,deeplearning,"A research team from DeepMind and Google Brain proposes Launchpad, a programming model that simplifies the process of defining and launching instances of distributed computation.   

Here is a quick read: [Google's Launchpad Programming Framework Simplifies the Distributed Computation Learning Process.](https://syncedreview.com/2021/06/15/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-41/)

The paper *Launchpad: A Programming Model for Distributed Machine Learning Research* is on [arXiv](https://arxiv.org/abs/2106.04516).",t2_2fv4yodo,False,,0,False,[R] Google's Launchpad Programming Framework Simplifies the Distributed Computation Learning Process,[],r/deeplearning,False,6,,0,,False,t3_o0hf7c,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623800789.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from DeepMind and Google Brain proposes Launchpad, a programming model that simplifies the process of defining and launching instances of distributed computation.   &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/15/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-41/""&gt;Google&amp;#39;s Launchpad Programming Framework Simplifies the Distributed Computation Learning Process.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Launchpad: A Programming Model for Distributed Machine Learning Research&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2106.04516""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0hf7c,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0hf7c/r_googles_launchpad_programming_framework/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0hf7c/r_googles_launchpad_programming_framework/,66146,1623771989.0,0,,False,,,,,,,
,deeplearning,"model.fit is too rigid to this one's tastes so he runs a tensorflow train op, but the layers have been declared using keras. The declaration includes regularizers and they don't seem to be run automatically, he has looked at keras code on github a bit but hasn't found at which point they are called. Maybe anybody knows how to do it? Probably not but why not ask =)",t2_bukbhrzs,False,,0,False,"question, how to make keras layers run regularizers without model.fit",[],r/deeplearning,False,6,,0,,False,t3_o09lt0,False,dark,0.83,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1623775323.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;model.fit is too rigid to this one&amp;#39;s tastes so he runs a tensorflow train op, but the layers have been declared using keras. The declaration includes regularizers and they don&amp;#39;t seem to be run automatically, he has looked at keras code on github a bit but hasn&amp;#39;t found at which point they are called. Maybe anybody knows how to do it? Probably not but why not ask =)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o09lt0,True,,ne-skwai,,5,False,all_ads,False,[],False,,/r/deeplearning/comments/o09lt0/question_how_to_make_keras_layers_run/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o09lt0/question_how_to_make_keras_layers_run/,66146,1623746523.0,0,,False,,,,,,,
,deeplearning,"Can GAN learn to increase the resolution of image ? For reference, suppose a MNIST - handwritten digits dataset (28 x 28) is fed into just an encoder and have been turned into low resolution image (around 15 x 15 maybe ). Can a GAN now be trained with the low resolution image as input and original ""high-res"" MNIST image as output so that it can recreate the high-res image for encoder generated low resolution test data ?? Help a Deep-Learning Newbie.",t2_55tkmq8g,False,,0,False,Is it possible to have different input and output sizes in GAN ?,[],r/deeplearning,False,6,,0,,False,t3_o09fx1,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623774564.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can GAN learn to increase the resolution of image ? For reference, suppose a MNIST - handwritten digits dataset (28 x 28) is fed into just an encoder and have been turned into low resolution image (around 15 x 15 maybe ). Can a GAN now be trained with the low resolution image as input and original &amp;quot;high-res&amp;quot; MNIST image as output so that it can recreate the high-res image for encoder generated low resolution test data ?? Help a Deep-Learning Newbie.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o09fx1,True,,BakedTiger,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/o09fx1/is_it_possible_to_have_different_input_and_output/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o09fx1/is_it_possible_to_have_different_input_and_output/,66146,1623745764.0,0,,False,,,,,,,
,deeplearning,I'm looking for topics on which I can read multiple research papers and write a survey paper on. Any suggestions,t2_5id0e0q7,False,,0,False,Topics on which I can read research papers?,[],r/deeplearning,False,6,,0,,False,t3_o0assy,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623780421.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;m looking for topics on which I can read multiple research papers and write a survey paper on. Any suggestions&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0assy,True,,rshells,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/o0assy/topics_on_which_i_can_read_research_papers/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0assy/topics_on_which_i_can_read_research_papers/,66146,1623751621.0,0,,False,,,,,,,
,deeplearning,,t2_cccdvf8f,False,,0,False,Speech AI – how to improve call center sales performance,[],r/deeplearning,False,6,,0,,False,t3_o0d4e5,False,dark,0.62,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1623788664.0,text,6,,,text,addepto.com,False,,,,,https://addepto.com/how-to-improve-call-center-sales-performance-with-ai-in-speech/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0d4e5,True,,AddeptoAnalytics,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0d4e5/speech_ai_how_to_improve_call_center_sales/,all_ads,False,https://addepto.com/how-to-improve-call-center-sales-performance-with-ai-in-speech/,66146,1623759864.0,0,,False,,,,,,,
,deeplearning,"Hey fellow deep learners,

I'd love to ask you for some feedback on our NLG project, as we have just released our documentation to our AI copywriter API!

Now we are inviting developers to test out the current platform. Feedback from you is gold for us as we are trying to better understand where we can generate value in your daily needs! And please do share it with people which would enjoy our work!

**How we got started?**

We are two NLG Enthusiasts in Berlin who wanted to take away the complexity till somebody could leverage some of the newest GPT models. Hence, we built an infrastructure to get your AI copywriter ready in a matter of minutes!

What started as a GUI to validate that individuals and businesses show interest in natural language generation is now also just one API request away.

Please ask me any question in the chat below or on twitter via dom\_does.

Links for accessing HemingwAI API.

Documentation: [https://textcortex.com/documentation/api](https://textcortex.com/documentation/api)

Github: [https://github.com/textcortex/hemingwai](https://github.com/textcortex/hemingwai)

Discuss within our [Slack community](https://join.slack.com/t/textcortexaicommunity/shared_invite/zt-rmaw7j10-Lz9vf86aF5I_fYZAS7JafQ)",t2_p8q7k,False,,0,False,"HemingwAI, the API writing text with you is looking for feedback",[],r/deeplearning,False,6,,0,,False,t3_o0byh1,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1623760949.0,,[],{},,True,,1623784705.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey fellow deep learners,&lt;/p&gt;

&lt;p&gt;I&amp;#39;d love to ask you for some feedback on our NLG project, as we have just released our documentation to our AI copywriter API!&lt;/p&gt;

&lt;p&gt;Now we are inviting developers to test out the current platform. Feedback from you is gold for us as we are trying to better understand where we can generate value in your daily needs! And please do share it with people which would enjoy our work!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How we got started?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We are two NLG Enthusiasts in Berlin who wanted to take away the complexity till somebody could leverage some of the newest GPT models. Hence, we built an infrastructure to get your AI copywriter ready in a matter of minutes!&lt;/p&gt;

&lt;p&gt;What started as a GUI to validate that individuals and businesses show interest in natural language generation is now also just one API request away.&lt;/p&gt;

&lt;p&gt;Please ask me any question in the chat below or on twitter via dom_does.&lt;/p&gt;

&lt;p&gt;Links for accessing HemingwAI API.&lt;/p&gt;

&lt;p&gt;Documentation: &lt;a href=""https://textcortex.com/documentation/api""&gt;https://textcortex.com/documentation/api&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Github: &lt;a href=""https://github.com/textcortex/hemingwai""&gt;https://github.com/textcortex/hemingwai&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Discuss within our &lt;a href=""https://join.slack.com/t/textcortexaicommunity/shared_invite/zt-rmaw7j10-Lz9vf86aF5I_fYZAS7JafQ""&gt;Slack community&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o0byh1,True,,kotanasu,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o0byh1/hemingwai_the_api_writing_text_with_you_is/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o0byh1/hemingwai_the_api_writing_text_with_you_is/,66146,1623755905.0,0,,False,,,,,,,
,deeplearning,"That's a good field of application.

I've asked in Bitcoin subreddit but they said it'd be guaranteed to fail because of external factors..",t2_93zr2qdu,False,,0,False,Any research about crypto price prediction with deep learning?,[],r/deeplearning,False,6,,0,,False,t3_o09b7o,False,dark,0.38,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623773972.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;That&amp;#39;s a good field of application.&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve asked in Bitcoin subreddit but they said it&amp;#39;d be guaranteed to fail because of external factors..&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o09b7o,True,,depaul9,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/o09b7o/any_research_about_crypto_price_prediction_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/o09b7o/any_research_about_crypto_price_prediction_with/,66146,1623745172.0,0,,False,,,,,,,
,deeplearning,"Hello Everyone. 

I am really scratching my head to get this topic inside my brain, It's obvious that even stackoverflow and google can't give me something satisfactory on this.
So I could use your help guys. 

I know about NN, CNN, RNN , LSTM, HMM and other heavy terms used in deep learning, but still can't connect how exactly this works (Phonemes Alignment).

It will be so helpful if you could provide me something on this. 
Thanks in advance.",t2_5mworz81,False,,0,False,Phonemes Alignment is Automatic Speech Recognition (ASR)?,[],r/deeplearning,False,6,,0,,False,t3_nzr1ae,False,dark,0.94,,public,13,0,{},,False,[],,False,False,,{},,False,13,,False,False,,False,,[],{},,True,,1623717776.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello Everyone. &lt;/p&gt;

&lt;p&gt;I am really scratching my head to get this topic inside my brain, It&amp;#39;s obvious that even stackoverflow and google can&amp;#39;t give me something satisfactory on this.
So I could use your help guys. &lt;/p&gt;

&lt;p&gt;I know about NN, CNN, RNN , LSTM, HMM and other heavy terms used in deep learning, but still can&amp;#39;t connect how exactly this works (Phonemes Alignment).&lt;/p&gt;

&lt;p&gt;It will be so helpful if you could provide me something on this. 
Thanks in advance.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzr1ae,True,,bugboy404,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nzr1ae/phonemes_alignment_is_automatic_speech/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzr1ae/phonemes_alignment_is_automatic_speech/,66146,1623688976.0,0,,False,,,,,,,
,deeplearning,"Hi everyone,

I am entering my last quarter of school and am planning on doing a Capstone project related to neural networks. I have taken an introductory course and learned about perceptrons, backprop, gradient descent, etc. The course ended right when we started talking about deep learning, unsupervised learning, and convolutions neural networks. I would like to do a project related to deep unsupervised learning and building a neural network from scratch in order to solve a certain meaningful problem. One thing that has always interested me is neural networks playing and learning video games but I would love to get some more ideas. Please link or comment some good ideas and/or any great resources regarding unsupervised learning and deep neural networks.",t2_beo5jpj9,False,,0,False,Capstone Project Ideas,[],r/deeplearning,False,6,,0,,False,t3_nzyntv,False,dark,0.73,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1623737998.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I am entering my last quarter of school and am planning on doing a Capstone project related to neural networks. I have taken an introductory course and learned about perceptrons, backprop, gradient descent, etc. The course ended right when we started talking about deep learning, unsupervised learning, and convolutions neural networks. I would like to do a project related to deep unsupervised learning and building a neural network from scratch in order to solve a certain meaningful problem. One thing that has always interested me is neural networks playing and learning video games but I would love to get some more ideas. Please link or comment some good ideas and/or any great resources regarding unsupervised learning and deep neural networks.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzyntv,True,,I_love_Jesus_1,,7,True,all_ads,False,[],False,,/r/deeplearning/comments/nzyntv/capstone_project_ideas/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzyntv/capstone_project_ideas/,66146,1623709198.0,0,,False,,,,,,,
,deeplearning,,t2_44mbtmjy,False,,0,False,State of the art in Face Swapping! (Thank you TenCent),[],r/deeplearning,False,6,,0,,False,t3_nzyaxp,False,dark,0.63,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1623737006.0,text,6,,,text,self.LatestInML,False,,,,,/r/LatestInML/comments/nzxqyj/state_of_the_art_in_face_swapping_thank_you/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzyaxp,True,,MLtinkerer,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nzyaxp/state_of_the_art_in_face_swapping_thank_you/,all_ads,False,/r/LatestInML/comments/nzxqyj/state_of_the_art_in_face_swapping_thank_you/,66146,1623708206.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'LatestInML', 'selftext': ""[link to paper](https://www.catalyzex.com/paper/arxiv:2106.06340)\n\nhttps://reddit.com/link/nzxqyj/video/q6cp5pf0wa571/player\n\n👇 Free extension to get code for ML papers (❤️'d by Andrew Ng) Chrome: https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil\n\nFirefox: https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex"", 'author_fullname': 't2_44mbtmjy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'State of the art in Face Swapping! (Thank you TenCent)', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/LatestInML', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'q6cp5pf0wa571': {'status': 'valid', 'e': 'RedditVideo', 'dashUrl': 'https://v.redd.it/link/nzxqyj/asset/q6cp5pf0wa571/DASHPlaylist.mpd?a=1626450726%2CYWQzMzA2NGRkM2ViZjZhMmU5YTk2NDQ1NDUxMjNhYTEwZGFmMzRlYzhkZDVhMTQ4ZTBlYWYwZGRiNDAwMTEwZg%3D%3D&amp;v=1&amp;f=sd', 'x': 638, 'y': 360, 'hlsUrl': 'https://v.redd.it/link/nzxqyj/asset/q6cp5pf0wa571/HLSPlaylist.m3u8?a=1626450726%2CYTNkZDA2YTE0NDYxZTk0MmQ1NGZlMjdmNGI2ZmYxZDY5NzdlNjgxMDZhZGJhYjgwNmRjZTNlOGY1YzI3ODM0Mw%3D%3D&amp;v=1&amp;f=sd', 'id': 'q6cp5pf0wa571', 'isGif': False}}, 'name': 't3_nzxqyj', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.71, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 7, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1623735496.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.LatestInML', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://www.catalyzex.com/paper/arxiv:2106.06340""&gt;link to paper&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://reddit.com/link/nzxqyj/video/q6cp5pf0wa571/player""&gt;https://reddit.com/link/nzxqyj/video/q6cp5pf0wa571/player&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;👇 Free extension to get code for ML papers (❤️&amp;#39;d by Andrew Ng) Chrome: &lt;a href=""https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil""&gt;https://chrome.google.com/webstore/detail/aiml-papers-with-code-eve/aikkeehnlfpamidigaffhfmgbkdeheil&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Firefox: &lt;a href=""https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex""&gt;https://addons.mozilla.org/en-US/firefox/addon/code-finder-catalyzex&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2c0xdn', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nzxqyj', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'MLtinkerer', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/LatestInML/comments/nzxqyj/state_of_the_art_in_face_swapping_thank_you/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/LatestInML/comments/nzxqyj/state_of_the_art_in_face_swapping_thank_you/', 'subreddit_subscribers': 7049, 'created_utc': 1623706696.0, 'num_crossposts': 6, 'media': None, 'is_video': False}]",t3_nzxqyj,,,,,
,deeplearning,"I can't really tell if the OpenCV LBPH facial recognition algorithm is based on deep learning and neural networks. From what I've found I don't think it is, but if someone more knowledgeable could confirm I would rly appreciate it 🙏",t2_4c0ol738,False,,0,False,Is the OpenCV LBPH algorithm based on deep learning?,[],r/deeplearning,False,6,,0,,False,t3_nzxq00,False,dark,0.83,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1623735421.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I can&amp;#39;t really tell if the OpenCV LBPH facial recognition algorithm is based on deep learning and neural networks. From what I&amp;#39;ve found I don&amp;#39;t think it is, but if someone more knowledgeable could confirm I would rly appreciate it 🙏&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzxq00,True,,fluffsnake_,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nzxq00/is_the_opencv_lbph_algorithm_based_on_deep/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzxq00/is_the_opencv_lbph_algorithm_based_on_deep/,66146,1623706621.0,0,,False,,,,,,,
,deeplearning,"Deep learning is one area of technology where ambitiousness has no barriers. According to a recent announcement by [The Beijing Academy of Artificial Intelligence (BAAI)](https://www.baai.ac.cn/), in China, yet another milestone has been achieved in the field with its “Wu Dao” AI system. The [GPT 3](https://www.marktechpost.com/2020/08/02/gpt-3-a-new-breakthrough-in-language-generator/) brought in new interest for all the AI researchers, the super scale pre training models. By this approach and making use of 175 billion parameters, it managed to achieve exceptional performance results across the natural language processing tasks (NLP). However, the lacking component is its inability to have any form of cognitive abilities or common sense. Therefore, despite the size, even these models cannot indulge in tasks such as open dialogues, visual reasoning, and so on. With Wu Dao, the researchers plan to address this issue. This is China’s first attempt at a home-grown super-scale intelligent model system. 

Article: [https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/](https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/?_ga=2.13897584.636390090.1623335762-488125022.1618729090)

Reference: [https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/](https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/)",t2_2wsvqwhg,False,,0,False,"This Chinese Super Scale Intelligence Model, ‘Wu Dao 2.0’, Claims To Be Trained Using 1.75 Trillion Parameters, Surpassing All Prior Models to Achieve a New Breakthrough in Deep Learning",[],r/deeplearning,False,6,,0,,False,t3_nzgkj3,False,dark,0.91,,public,36,0,{},,False,[],,False,False,,{},,False,36,,False,False,,False,,[],{},,True,,1623681273.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Deep learning is one area of technology where ambitiousness has no barriers. According to a recent announcement by &lt;a href=""https://www.baai.ac.cn/""&gt;The Beijing Academy of Artificial Intelligence (BAAI)&lt;/a&gt;, in China, yet another milestone has been achieved in the field with its “Wu Dao” AI system. The &lt;a href=""https://www.marktechpost.com/2020/08/02/gpt-3-a-new-breakthrough-in-language-generator/""&gt;GPT 3&lt;/a&gt; brought in new interest for all the AI researchers, the super scale pre training models. By this approach and making use of 175 billion parameters, it managed to achieve exceptional performance results across the natural language processing tasks (NLP). However, the lacking component is its inability to have any form of cognitive abilities or common sense. Therefore, despite the size, even these models cannot indulge in tasks such as open dialogues, visual reasoning, and so on. With Wu Dao, the researchers plan to address this issue. This is China’s first attempt at a home-grown super-scale intelligent model system. &lt;/p&gt;

&lt;p&gt;Article: &lt;a href=""https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/?_ga=2.13897584.636390090.1623335762-488125022.1618729090""&gt;https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Reference: &lt;a href=""https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/""&gt;https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzgkj3,True,,ai-lover,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/nzgkj3/this_chinese_super_scale_intelligence_model_wu/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzgkj3/this_chinese_super_scale_intelligence_model_wu/,66146,1623652473.0,0,,False,,,,,,,
,deeplearning,,t2_5hxzzmvk,False,,0,False,"[JOB POST] PhD in Fusion of quantitative multi modal imaging and parametric mapping of lung structure and function and applications to COPD, asthma and long term effects of COVID-19 disease",[],r/deeplearning,False,6,,0,,False,t3_o01mdt,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623747077.0,text,6,,,text,sano.science,False,,,,,https://sano.science/job-offers/fusion-of-quantitative-multi-modal-imaging-and-parametric-mapping-of-lung-structure-and-function-and-applications-to-copd-asthma-and-long-term-effects-of-covid-19-disease/?fbclid=IwAR0BRFXbCFCOvn9FycWR24C_oQGkRQ1_c3BayCITnubdqUMPqHmdq8uuqdk,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,o01mdt,True,,alecrimi,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/o01mdt/job_post_phd_in_fusion_of_quantitative_multi/,all_ads,False,https://sano.science/job-offers/fusion-of-quantitative-multi-modal-imaging-and-parametric-mapping-of-lung-structure-and-function-and-applications-to-copd-asthma-and-long-term-effects-of-covid-19-disease/?fbclid=IwAR0BRFXbCFCOvn9FycWR24C_oQGkRQ1_c3BayCITnubdqUMPqHmdq8uuqdk,66146,1623718277.0,0,,False,,,,,,,
,deeplearning,"Im using Ubuntu 21.04 and I have a dedicated Radeon AMD  gpu .I was just searching about it and I think my new gpu is usless :( I just bought it for Deep Learning purposes , I just tried to install Rocm but unfortunately it wont install since its not supported by Ubuntu 21.04 I don’t know what to do 
Help please to overcome this problem",t2_50ckme9a,False,,0,False,HELP: AMD Radeon and tensorflow,[],r/deeplearning,False,6,,0,,False,t3_nzxums,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623735783.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Im using Ubuntu 21.04 and I have a dedicated Radeon AMD  gpu .I was just searching about it and I think my new gpu is usless :( I just bought it for Deep Learning purposes , I just tried to install Rocm but unfortunately it wont install since its not supported by Ubuntu 21.04 I don’t know what to do 
Help please to overcome this problem&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzxums,True,,rayudy,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nzxums/help_amd_radeon_and_tensorflow/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzxums/help_amd_radeon_and_tensorflow/,66146,1623706983.0,0,,False,,,,,,,
,deeplearning,"I’ve been searching forever on deep learning benchmarks of the i7 11700k. I’m not sure whether to get it or the Ryzen 7 5800X. Will I actually use the AVX-512 technology, I presume it’ll still be far from a GPU in performance? Currently leaning to the AMD for less heat and less power consumption. Thoughts?",t2_7eip8,False,,0,False,Getting an Intel CPU for the AVX-512?,[],r/deeplearning,False,6,,0,,False,t3_nzxf5q,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623734604.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I’ve been searching forever on deep learning benchmarks of the i7 11700k. I’m not sure whether to get it or the Ryzen 7 5800X. Will I actually use the AVX-512 technology, I presume it’ll still be far from a GPU in performance? Currently leaning to the AMD for less heat and less power consumption. Thoughts?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzxf5q,True,,jakkes12,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nzxf5q/getting_an_intel_cpu_for_the_avx512/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzxf5q/getting_an_intel_cpu_for_the_avx512/,66146,1623705804.0,0,,False,,,,,,,
,deeplearning,I'd like to know if there's any research paper reading group I can join. Thank you,t2_5id0e0q7,False,,0,False,Research Paper reading group?,[],r/deeplearning,False,6,,0,,False,t3_nzhwf6,False,dark,0.77,,public,9,0,{},,False,[],,False,False,,{},,False,9,,False,False,,False,,[],{},,True,,1623687309.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I&amp;#39;d like to know if there&amp;#39;s any research paper reading group I can join. Thank you&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzhwf6,True,,rshells,,5,True,all_ads,False,[],False,,/r/deeplearning/comments/nzhwf6/research_paper_reading_group/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzhwf6/research_paper_reading_group/,66146,1623658509.0,0,,False,,,,,,,
,deeplearning,,t2_2op3d34c,False,,0,False,"Advanced AI eBooks Bundle by Morgan Claypool, 15 books",[],r/deeplearning,False,6,,0,,False,t3_nzv5g0,False,dark,0.58,,public,2,1,{},,False,[],,False,False,,{},,False,2,,False,True,,False,,[],{},,False,,1623728656.0,text,6,,,text,medium.com,False,,,,,https://medium.com/@Humble_Bundle/advanced-ai-ebooks-bundle-by-morgan-claypool-47510754139f?58712581,,False,True,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzv5g0,True,,reps_up,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nzv5g0/advanced_ai_ebooks_bundle_by_morgan_claypool_15/,all_ads,False,https://medium.com/@Humble_Bundle/advanced-ai-ebooks-bundle-by-morgan-claypool-47510754139f?58712581,66146,1623699856.0,1,,False,,,,,,,
,deeplearning,"So Im currently working on my thesis , and I have read many publications on that , most of them are focusing on the GPU while in my case (im using spyder with anaconda installed in ubuntu) is consuming 90% of my CPU is there any way to make my algorithm run with the GPU rather than CPU 
Im a but lost guys",t2_50ckme9a,False,,0,False,What resources does Deep Learning consumes?,[],r/deeplearning,False,6,,0,,False,t3_nzuxju,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623728067.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;So Im currently working on my thesis , and I have read many publications on that , most of them are focusing on the GPU while in my case (im using spyder with anaconda installed in ubuntu) is consuming 90% of my CPU is there any way to make my algorithm run with the GPU rather than CPU 
Im a but lost guys&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzuxju,True,,rayudy,,10,True,all_ads,False,[],False,,/r/deeplearning/comments/nzuxju/what_resources_does_deep_learning_consumes/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzuxju/what_resources_does_deep_learning_consumes/,66146,1623699267.0,0,,False,,,,,,,
,deeplearning,"I want to create a reinforcement learning environment, designed for wind tunnel simulations, where for each iteration a deep convolutional model could receive the 3D vector/scalar fields from the past simulation and output a better shape that maximizes the reward function (e.g. minimize drag, maximize lift, etc.).

 The observation and action space for the neural network is the same, the inputs of the model will be 3D arrays representing velocity field, pressure field, etc. and the output will be a 3D array (created using Conv3DTranspose) with values \[0, 1\] which represents the mesh. I'm thinking that the architecture of the model could be something similar to an auto-encoder. My plan is to use the algorithm of Marching Cubes in order to create the mesh from those points and openFoam for the CFD simulations. 

The goal will be to have multiple trained models specialized in optimizing a particular reward function, like minimizing drag or maximizing lift, for any object/shape given as input. What are your thoughts on this? Do you think it makes sense?

PS: I recently discover Growing Neural Cellular Automata that could be a better fit for this type of iterative process.",t2_1n4w9qid,False,,0,False,CFD Reinforcement Learning for Topology optimization in wind tunnel,[],r/deeplearning,False,6,,0,,False,t3_nzizby,False,dark,1.0,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1623692129.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I want to create a reinforcement learning environment, designed for wind tunnel simulations, where for each iteration a deep convolutional model could receive the 3D vector/scalar fields from the past simulation and output a better shape that maximizes the reward function (e.g. minimize drag, maximize lift, etc.).&lt;/p&gt;

&lt;p&gt;The observation and action space for the neural network is the same, the inputs of the model will be 3D arrays representing velocity field, pressure field, etc. and the output will be a 3D array (created using Conv3DTranspose) with values [0, 1] which represents the mesh. I&amp;#39;m thinking that the architecture of the model could be something similar to an auto-encoder. My plan is to use the algorithm of Marching Cubes in order to create the mesh from those points and openFoam for the CFD simulations. &lt;/p&gt;

&lt;p&gt;The goal will be to have multiple trained models specialized in optimizing a particular reward function, like minimizing drag or maximizing lift, for any object/shape given as input. What are your thoughts on this? Do you think it makes sense?&lt;/p&gt;

&lt;p&gt;PS: I recently discover Growing Neural Cellular Automata that could be a better fit for this type of iterative process.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzizby,True,,cTatu,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nzizby/cfd_reinforcement_learning_for_topology/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzizby/cfd_reinforcement_learning_for_topology/,66146,1623663329.0,2,,False,,,,,,,
,deeplearning,"Hi, I'm looking for an algorithm or model that removes the sky from an input image. Specifically, I'm trying to acquire a mask of the sky, so I can filter the sky pixels out of my model's prediction. The scenery I'm working with is through the front view of a car like a dashcam during morning.

Does anyone know a model or algorithm that I can use to perform this task in a computationally inexpensive way?",t2_tvxmr,False,,0,False,Sky removal model or algorithm?,[],r/deeplearning,False,6,,0,,False,t3_nzsz16,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623722908.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I&amp;#39;m looking for an algorithm or model that removes the sky from an input image. Specifically, I&amp;#39;m trying to acquire a mask of the sky, so I can filter the sky pixels out of my model&amp;#39;s prediction. The scenery I&amp;#39;m working with is through the front view of a car like a dashcam during morning.&lt;/p&gt;

&lt;p&gt;Does anyone know a model or algorithm that I can use to perform this task in a computationally inexpensive way?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzsz16,True,,AbdrahmanDiab,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/nzsz16/sky_removal_model_or_algorithm/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzsz16/sky_removal_model_or_algorithm/,66146,1623694108.0,0,,False,,,,,,,
,deeplearning,,t2_30jgxa2x,False,,0,False,How to Do Face Detection and Tagging in Video With Deep Learning,[],r/deeplearning,False,6,,0,,False,t3_nzrgi1,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623718879.0,text,6,,,text,education-ecosystem.com,False,,,,,https://www.education-ecosystem.com/sebagam/R8QqW-face-recognition-and-grouping-using-deep-learning/Ba1K9-outline-faces/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzrgi1,True,,NaturalWildFishOil,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nzrgi1/how_to_do_face_detection_and_tagging_in_video/,all_ads,False,https://www.education-ecosystem.com/sebagam/R8QqW-face-recognition-and-grouping-using-deep-learning/Ba1K9-outline-faces/,66146,1623690079.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'EducationEcosystem1', 'selftext': '', 'author_fullname': 't2_9vz6ic5r', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How to Do Face Detection and Tagging in Video With Deep Learning', 'link_flair_richtext': [{'e': 'text', 't': 'Artificial Intelligence'}], 'subreddit_name_prefixed': 'r/EducationEcosystem1', 'hidden': False, 'pwls': None, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nzmkof', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'restricted', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Artificial Intelligence', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1623705430.0, 'link_flair_type': 'richtext', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'education-ecosystem.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.education-ecosystem.com/sebagam/R8QqW-face-recognition-and-grouping-using-deep-learning/Ba1K9-outline-faces/', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '7bde20ac-a465-11eb-b9e0-0e44616a98ed', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_4av7i3', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#5a74cc', 'id': 'nzmkof', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Makeyourpuppyproud', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/EducationEcosystem1/comments/nzmkof/how_to_do_face_detection_and_tagging_in_video/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://www.education-ecosystem.com/sebagam/R8QqW-face-recognition-and-grouping-using-deep-learning/Ba1K9-outline-faces/', 'subreddit_subscribers': 82, 'created_utc': 1623676630.0, 'num_crossposts': 4, 'media': None, 'is_video': False}]",t3_nzmkof,,,,,
,deeplearning,"How are models trained on new set of data post production deployment ?

Suppose your Deep learning model was trained on 1 million labelled images. After 1year of deployment into production, your team has gathered  100,000 more labelled images. How will the training process look like? Will it be:

 1. Training on top of the existing weights using just the new images? (Similar to Transfer learning)

2. Training the whole 1.1 million datasets from scratch ?",t2_5c8umwtu,False,,0,False,Training of models post Production deployment,[],r/deeplearning,False,6,,0,,False,t3_nzhm31,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1623686045.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;How are models trained on new set of data post production deployment ?&lt;/p&gt;

&lt;p&gt;Suppose your Deep learning model was trained on 1 million labelled images. After 1year of deployment into production, your team has gathered  100,000 more labelled images. How will the training process look like? Will it be:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Training on top of the existing weights using just the new images? (Similar to Transfer learning)&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Training the whole 1.1 million datasets from scratch ?&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzhm31,True,,7pointsome1,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nzhm31/training_of_models_post_production_deployment/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzhm31/training_of_models_post_production_deployment/,66146,1623657245.0,0,,False,,,,,,,
,deeplearning,"A Google Research team proposes MergeDistill, a framework for merging pretrained teacher LMs from multiple monolingual/multilingual LMs into a single multilingual task-agnostic student LM to leverage the capabilities of the powerful language-specific LMs while still being multilingual and enabling positive language transfer.  

Here is a quick read: [Google Researchers Merge Pretrained Teacher LMs Into a Single Multilingual Student LM Via Knowledge Distillation.](https://syncedreview.com/2021/06/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-40/)

The paper *MergeDistill: Merging Pre-trained Language Models using Distillation* is on [arXiv](https://arxiv.org/pdf/2106.02834).",t2_2fv4yodo,False,,0,False,[R] Google Researchers Merge Pretrained Teacher LMs Into a Single Multilingual Student LM Via Knowledge Distillation,[],r/deeplearning,False,6,,0,,False,t3_nzohha,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623710925.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A Google Research team proposes MergeDistill, a framework for merging pretrained teacher LMs from multiple monolingual/multilingual LMs into a single multilingual task-agnostic student LM to leverage the capabilities of the powerful language-specific LMs while still being multilingual and enabling positive language transfer.  &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-40/""&gt;Google Researchers Merge Pretrained Teacher LMs Into a Single Multilingual Student LM Via Knowledge Distillation.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;MergeDistill: Merging Pre-trained Language Models using Distillation&lt;/em&gt; is on &lt;a href=""https://arxiv.org/pdf/2106.02834""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzohha,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nzohha/r_google_researchers_merge_pretrained_teacher_lms/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzohha/r_google_researchers_merge_pretrained_teacher_lms/,66146,1623682125.0,0,,False,,,,,,,
,deeplearning,"I heard someone saying that tensorflow and keras is much faster then pytorch in terms of production inference. If i wish to deoply some trained model to production then should i code in keras?

As of my research pytorch is faster.",t2_3f4tbfwj,False,,0,False,Keras/tf is much faster then pytorch in production inference.,[],r/deeplearning,False,6,,0,,False,t3_nzjjy0,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623694505.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I heard someone saying that tensorflow and keras is much faster then pytorch in terms of production inference. If i wish to deoply some trained model to production then should i code in keras?&lt;/p&gt;

&lt;p&gt;As of my research pytorch is faster.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nzjjy0,True,,ashishgupta2598,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nzjjy0/kerastf_is_much_faster_then_pytorch_in_production/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nzjjy0/kerastf_is_much_faster_then_pytorch_in_production/,66146,1623665705.0,0,,False,,,,,,,
,deeplearning,"It seems like defining the model is just random coding, except for making the shapes match so you won't have an exception.    
I'm at a point in my project where I'm just adding and removing different blocks (Conv block, sigmoid, PReLU) to the model and hoping for the best.

How does anyone know which block to use in a net?

Here is [my project](https://github.com/unimonkiez/final_engineering_project) and the [task](https://arxiv.org/pdf/2006.05712.pdf) I'm trying to implement, don't need to enter though as this post is more about seeking advice than help (but is welcomed).",t2_sgea0,False,,0,False,Frustrated with deep-learning development,[],r/deeplearning,False,6,,0,,False,t3_nyzrfh,False,dark,0.83,,public,24,0,{},,False,[],,False,False,,{},,False,24,,False,False,,False,,[],{},,True,,1623629655.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It seems like defining the model is just random coding, except for making the shapes match so you won&amp;#39;t have an exception.&lt;br/&gt;
I&amp;#39;m at a point in my project where I&amp;#39;m just adding and removing different blocks (Conv block, sigmoid, PReLU) to the model and hoping for the best.&lt;/p&gt;

&lt;p&gt;How does anyone know which block to use in a net?&lt;/p&gt;

&lt;p&gt;Here is &lt;a href=""https://github.com/unimonkiez/final_engineering_project""&gt;my project&lt;/a&gt; and the &lt;a href=""https://arxiv.org/pdf/2006.05712.pdf""&gt;task&lt;/a&gt; I&amp;#39;m trying to implement, don&amp;#39;t need to enter though as this post is more about seeking advice than help (but is welcomed).&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyzrfh,True,,unimonkiez,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/nyzrfh/frustrated_with_deeplearning_development/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nyzrfh/frustrated_with_deeplearning_development/,66146,1623600855.0,0,,False,,,,,,,
,deeplearning,,t2_159buvym,False,,0,False,Can anyone please guide me to a video based Automatic speech recognition (ASR) course ?,[],r/deeplearning,False,6,,0,,False,t3_nyw2z2,False,dark,0.86,,public,14,0,{},,False,[],,False,False,,{},,False,14,,False,False,,False,,[],{},,True,,1623618892.0,text,6,,,text,self.deeplearning,False,,,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyw2z2,True,,rakshith291,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nyw2z2/can_anyone_please_guide_me_to_a_video_based/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nyw2z2/can_anyone_please_guide_me_to_a_video_based/,66146,1623590092.0,0,,False,,,,,,,
,deeplearning,"At the beginning of training the model clearly will predict the wrong number of object bboxes in the image, which leads to have the predicted bboxes size different than the target bboxes size. 

So how does it still be able compute loss between these, when the dim is unmatched?",t2_abbcm4w8,False,,0,False,Mask RCNN loss,[],r/deeplearning,False,6,,0,,False,t3_nz7hfp,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623651357.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;At the beginning of training the model clearly will predict the wrong number of object bboxes in the image, which leads to have the predicted bboxes size different than the target bboxes size. &lt;/p&gt;

&lt;p&gt;So how does it still be able compute loss between these, when the dim is unmatched?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nz7hfp,True,,I_am_not_doing_this,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nz7hfp/mask_rcnn_loss/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nz7hfp/mask_rcnn_loss/,66146,1623622557.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,AI will fake your handwriting using just a single word,[],r/deeplearning,False,6,,0,,False,t3_nyed8t,False,dark,0.93,,public,66,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Hc5_M7ziy-Q?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI will fake your handwriting using just a single word', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Hc5_M7ziy-Q?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Hc5_M7ziy-Q/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Hc5_M7ziy-Q?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nyed8t', 'height': 200}",,False,66,,False,False,,False,,[],{},,False,,1623554911.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/Hc5_M7ziy-Q,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyed8t,True,,cmillionaire9,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nyed8t/ai_will_fake_your_handwriting_using_just_a_single/,all_ads,False,https://youtu.be/Hc5_M7ziy-Q,66146,1623526111.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI will fake your handwriting using just a single word', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Hc5_M7ziy-Q?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Hc5_M7ziy-Q/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,"Does anyone knows of a program/app to draw pretty neural network architectures? Not the actual code, just an schematic of the NN.",t2_cdlnd,False,,0,False,App or website to draw NNs?,[],r/deeplearning,False,6,,0,,False,t3_nyzzq9,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623630289.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Does anyone knows of a program/app to draw pretty neural network architectures? Not the actual code, just an schematic of the NN.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyzzq9,True,,donpepep,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nyzzq9/app_or_website_to_draw_nns/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nyzzq9/app_or_website_to_draw_nns/,66146,1623601489.0,0,,False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,Text Style Brush by Facebook AI - amazing single-shot text style transfer results (deepfakes just got ++),[],r/deeplearning,False,6,,0,,False,t3_nyxb8f,False,dark,0.6,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/OC0oe1EzQxo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Text Style Brush - Transfer of text aesthetics from a single example | Paper Explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/OC0oe1EzQxo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/OC0oe1EzQxo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/OC0oe1EzQxo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nyxb8f', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1623622766.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/OC0oe1EzQxo,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyxb8f,True,,gordicaleksa,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nyxb8f/text_style_brush_by_facebook_ai_amazing/,all_ads,False,https://youtu.be/OC0oe1EzQxo,66146,1623593966.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Text Style Brush - Transfer of text aesthetics from a single example | Paper Explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/OC0oe1EzQxo?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/OC0oe1EzQxo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,Hi there! Let us know your nationality and practice your Arabic with us!,[],r/deeplearning,False,6,,0,,False,t3_nz4qji,False,dark,0.22,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623643656.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/e1iy1bw2a3571.jpg,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nz4qji,True,,Community-Of-Babel,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nz4qji/hi_there_let_us_know_your_nationality_and/,all_ads,False,https://i.redd.it/e1iy1bw2a3571.jpg,66146,1623614856.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Hi there! Let us know your nationality and practice your Arabic with us!', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nz4mb6', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1623643343.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/e1iy1bw2a3571.jpg', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nz4mb6', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/nz4mb6/hi_there_let_us_know_your_nationality_and/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://i.redd.it/e1iy1bw2a3571.jpg', 'subreddit_subscribers': 0, 'created_utc': 1623614543.0, 'num_crossposts': 6, 'media': None, 'is_video': False}]",t3_nz4mb6,,,,,
,deeplearning,,t2_b35fb5yn,False,,0,False,"Learn Machine Learning, Data Science and Deep Learning with Python",[],r/deeplearning,False,6,,0,,False,t3_nywnw2,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623620745.0,text,6,,,text,medium.com,False,,,,,https://medium.com/@devexpert/20-best-machine-learning-courses-online-4a7863c4326a,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nywnw2,True,,hngkng21,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nywnw2/learn_machine_learning_data_science_and_deep/,all_ads,False,https://medium.com/@devexpert/20-best-machine-learning-courses-online-4a7863c4326a,66146,1623591945.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,Real-time Writing with fingers on Web Camera Screen,[],r/deeplearning,False,6,,0,,False,t3_nyev2d,False,dark,0.93,,public,13,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Qv82F4qe0CE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Real-time Writing with fingers on Web Camera Screen', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Qv82F4qe0CE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Qv82F4qe0CE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Qv82F4qe0CE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nyev2d', 'height': 200}",,False,13,,False,False,,False,,[],{},,False,,1623556293.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/Qv82F4qe0CE,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyev2d,True,,cmillionaire9,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nyev2d/realtime_writing_with_fingers_on_web_camera_screen/,all_ads,False,https://youtu.be/Qv82F4qe0CE,66146,1623527493.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Real-time Writing with fingers on Web Camera Screen', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Qv82F4qe0CE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Qv82F4qe0CE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,Can I learn deep learning without machine learning?,t2_7f6u7n1z,False,,0,False,Confused,[],r/deeplearning,False,6,,0,,False,t3_nz1vhk,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623635544.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can I learn deep learning without machine learning?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nz1vhk,True,,satvs,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/nz1vhk/confused/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nz1vhk/confused/,66146,1623606744.0,0,,False,,,,,,,
,deeplearning,"Hello everyone,

Is there the source code and pre-trained models of Google Switch Transformers available for download?",t2_sm171,False,,0,False,Google Switch Transformers available?,[],r/deeplearning,False,6,,0,,False,t3_nys0ui,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623602216.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;

&lt;p&gt;Is there the source code and pre-trained models of Google Switch Transformers available for download?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nys0ui,True,,notooth1,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nys0ui/google_switch_transformers_available/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nys0ui/google_switch_transformers_available/,66146,1623573416.0,0,,False,,,,,,,
,deeplearning,,t2_c14wpji,False,,0,False,Barbershop: Try Different Hairstyles and Hair Colors from Pictures (GANs+),[],r/deeplearning,False,6,,0,,False,t3_ny99f3,False,dark,0.82,,public,11,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HtqYMvBVJD8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Barbershop: Try Different Hairstyles and Hair Colors from Pictures (GANs)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HtqYMvBVJD8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/HtqYMvBVJD8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HtqYMvBVJD8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ny99f3', 'height': 200}",,False,11,,False,False,,False,,[],{},,False,,1623540508.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/HtqYMvBVJD8,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny99f3,True,,OnlyProggingForFun,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/ny99f3/barbershop_try_different_hairstyles_and_hair/,all_ads,False,https://youtu.be/HtqYMvBVJD8,66146,1623511708.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Barbershop: Try Different Hairstyles and Hair Colors from Pictures (GANs)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/HtqYMvBVJD8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': ""What's AI"", 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/HtqYMvBVJD8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/WhatsAI'}}",False,,,,,,,
,deeplearning,,t2_bgz5v,False,,0,False,"Audiovisual Project ""Incomplete"" (2021) made with GANs, Segmentation, &amp; 3D Animation",[],r/deeplearning,False,6,,0,,False,t3_nyjy94,False,dark,0.76,,public,2,0,"{'content': '&lt;iframe class=""embedly-embed"" src=""https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fplayer.vimeo.com%2Fvideo%2F537999129%3Fapp_id%3D122963&amp;dntp=1&amp;display_name=Vimeo&amp;url=https%3A%2F%2Fvimeo.com%2F537999129&amp;image=http%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1147179301_1280&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=vimeo"" width=""600"" height=""338"" scrolling=""no"" title=""Vimeo embed"" frameborder=""0"" allow=""autoplay; fullscreen"" allowfullscreen=""true""&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'height': 338}",,False,[],"{'type': 'vimeo.com', 'oembed': {'provider_url': 'https://vimeo.com/', 'description': 'The year is 2021. The future has already happened. Composed of a single take, ""Incomplete"" invites us to traverse an endless choreography of bodies in perpetual free-fall and updating images that reflect a world in constant change.', 'title': 'Incomplete (2021)', 'type': 'video', 'author_name': 'Dalena Tran', 'height': 338, 'width': 600, 'html': '&lt;iframe class=""embedly-embed"" src=""https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fplayer.vimeo.com%2Fvideo%2F537999129%3Fapp_id%3D122963&amp;dntp=1&amp;display_name=Vimeo&amp;url=https%3A%2F%2Fvimeo.com%2F537999129&amp;image=http%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1147179301_1280&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=vimeo"" width=""600"" height=""338"" scrolling=""no"" title=""Vimeo embed"" frameborder=""0"" allow=""autoplay; fullscreen"" allowfullscreen=""true""&gt;&lt;/iframe&gt;', 'thumbnail_width': 1280, 'version': '1.0', 'provider_name': 'Vimeo', 'thumbnail_url': 'https://i.embed.ly/1/image?url=http%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1147179301_1280&amp;key=b1e305db91cf4aa5a86b732cc9fffceb', 'thumbnail_height': 720, 'author_url': 'https://vimeo.com/dalenatran'}}",False,False,,"{'content': '&lt;iframe class=""embedly-embed"" src=""https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fplayer.vimeo.com%2Fvideo%2F537999129%3Fapp_id%3D122963&amp;dntp=1&amp;display_name=Vimeo&amp;url=https%3A%2F%2Fvimeo.com%2F537999129&amp;image=http%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1147179301_1280&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=vimeo"" width=""600"" height=""338"" scrolling=""no"" title=""Vimeo embed"" frameborder=""0"" allow=""autoplay; fullscreen"" allowfullscreen=""true""&gt;&lt;/iframe&gt;', 'width': 600, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nyjy94', 'height': 338}",,False,2,,False,False,,False,,[],{},,False,,1623570534.0,text,6,,,text,vimeo.com,False,,,,,https://vimeo.com/537999129,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyjy94,True,,dalenatran,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nyjy94/audiovisual_project_incomplete_2021_made_with/,all_ads,False,https://vimeo.com/537999129,66146,1623541734.0,0,"{'type': 'vimeo.com', 'oembed': {'provider_url': 'https://vimeo.com/', 'description': 'The year is 2021. The future has already happened. Composed of a single take, ""Incomplete"" invites us to traverse an endless choreography of bodies in perpetual free-fall and updating images that reflect a world in constant change.', 'title': 'Incomplete (2021)', 'type': 'video', 'author_name': 'Dalena Tran', 'height': 338, 'width': 600, 'html': '&lt;iframe class=""embedly-embed"" src=""https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fplayer.vimeo.com%2Fvideo%2F537999129%3Fapp_id%3D122963&amp;dntp=1&amp;display_name=Vimeo&amp;url=https%3A%2F%2Fvimeo.com%2F537999129&amp;image=http%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1147179301_1280&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=text%2Fhtml&amp;schema=vimeo"" width=""600"" height=""338"" scrolling=""no"" title=""Vimeo embed"" frameborder=""0"" allow=""autoplay; fullscreen"" allowfullscreen=""true""&gt;&lt;/iframe&gt;', 'thumbnail_width': 1280, 'version': '1.0', 'provider_name': 'Vimeo', 'thumbnail_url': 'https://i.embed.ly/1/image?url=http%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F1147179301_1280&amp;key=b1e305db91cf4aa5a86b732cc9fffceb', 'thumbnail_height': 720, 'author_url': 'https://vimeo.com/dalenatran'}}",False,,,,,,,
,deeplearning,,t2_83s7wqlw,False,,0,False,I'm trying to recreate this CNN in order to predict bounding boxes coordinates (I'm not doing any object classification...just bounding boxes). I can't seem to understand well the numbers on the rectangles (layers). Can someone enlighten me on how to translate this image to tensorflow/py. Thankieees,[],r/deeplearning,False,6,,0,,False,t3_ny3qjy,False,dark,0.86,,public,21,0,{},,False,[],,True,False,,{},,False,21,,False,False,,False,,[],{},,False,,1623522449.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/u9lfco036t471.png,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny3qjy,True,,Moroccanmuslim,,6,True,all_ads,False,[],False,,/r/deeplearning/comments/ny3qjy/im_trying_to_recreate_this_cnn_in_order_to/,all_ads,False,https://i.redd.it/u9lfco036t471.png,66146,1623493649.0,0,,False,,,,,,,
,deeplearning,"Generative models have become synonymous with convolutions and more recently with self-attention, yet we (yes, I am the second author of this paper, yay 🙌) ask the question: are convolutions REALLY necessary to generate state-of-the-art quality images? Perhaps surprisingly a simple multilayer perceptron (MLP) with a couple of clever tricks does just as good (if not better) as specialized convolutional architectures (StyleGAN-2) on 256x256 resolution.

Check out the [full paper digest](https://t.me/casual_gan/51) (reading time \~5 minutes) to learn about the architecture of our MLP-based generator, the two types of positional encoding used to increase the fidelity of generated images, and how CIPS can be used to generate seamless cyclical panoramas without ever training on full panoramic images.

Meanwhile, check out the paper summary poster by [Casual GAN Papers](https://t.me/casual_gan)!

[CIPS: Conditionally Independent Pixel Synthesis](https://preview.redd.it/zmprpyqtzt471.png?width=680&amp;format=png&amp;auto=webp&amp;s=8a86c73bb7a5d535fb18f16d0b155b4765d00f36)

\[[Full Explanation Post](https://t.me/casual_gan/51)\] \[[Arxiv](https://arxiv.org/abs/2011.13775)\] \[[Project page](https://github.com/saic-mdal/CIPS)\]

More recent popular computer vision paper breakdowns:

&gt;[DALL-E](https://t.me/casual_gan/48)  
[VQGAN](https://t.me/casual_gan/46)  
[Decision Transformer](https://t.me/casual_gan/50)",t2_hhio3,False,,0,False,Image Generators with Conditionally-Independent Pixel Synthesis (CIPS) by Anokhin et al.,[],r/deeplearning,False,6,,0,,False,t3_ny60md,False,dark,0.84,,public,8,0,{},,False,[],,False,False,,{},,False,8,,False,False,,False,,[],{},,True,,1623530962.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Generative models have become synonymous with convolutions and more recently with self-attention, yet we (yes, I am the second author of this paper, yay 🙌) ask the question: are convolutions REALLY necessary to generate state-of-the-art quality images? Perhaps surprisingly a simple multilayer perceptron (MLP) with a couple of clever tricks does just as good (if not better) as specialized convolutional architectures (StyleGAN-2) on 256x256 resolution.&lt;/p&gt;

&lt;p&gt;Check out the &lt;a href=""https://t.me/casual_gan/51""&gt;full paper digest&lt;/a&gt; (reading time ~5 minutes) to learn about the architecture of our MLP-based generator, the two types of positional encoding used to increase the fidelity of generated images, and how CIPS can be used to generate seamless cyclical panoramas without ever training on full panoramic images.&lt;/p&gt;

&lt;p&gt;Meanwhile, check out the paper summary poster by &lt;a href=""https://t.me/casual_gan""&gt;Casual GAN Papers&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/zmprpyqtzt471.png?width=680&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8a86c73bb7a5d535fb18f16d0b155b4765d00f36""&gt;CIPS: Conditionally Independent Pixel Synthesis&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/51""&gt;Full Explanation Post&lt;/a&gt;] [&lt;a href=""https://arxiv.org/abs/2011.13775""&gt;Arxiv&lt;/a&gt;] [&lt;a href=""https://github.com/saic-mdal/CIPS""&gt;Project page&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;More recent popular computer vision paper breakdowns:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=""https://t.me/casual_gan/48""&gt;DALL-E&lt;/a&gt;&lt;br/&gt;
&lt;a href=""https://t.me/casual_gan/46""&gt;VQGAN&lt;/a&gt;&lt;br/&gt;
&lt;a href=""https://t.me/casual_gan/50""&gt;Decision Transformer&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny60md,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ny60md/image_generators_with_conditionallyindependent/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ny60md/image_generators_with_conditionallyindependent/,66146,1623502162.0,0,,False,,,"{'zmprpyqtzt471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 203, 'x': 108, 'u': 'https://preview.redd.it/zmprpyqtzt471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=49197c138222ca877021bd04c281025723d09014'}, {'y': 406, 'x': 216, 'u': 'https://preview.redd.it/zmprpyqtzt471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8e825bac5feab62b3bef2cb8186236d210de8431'}, {'y': 602, 'x': 320, 'u': 'https://preview.redd.it/zmprpyqtzt471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=435de8508de4ff56d38a4107b65c478a6dcefbac'}, {'y': 1204, 'x': 640, 'u': 'https://preview.redd.it/zmprpyqtzt471.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=33e209b32154e372d20230226d62890936943285'}], 's': {'y': 1280, 'x': 680, 'u': 'https://preview.redd.it/zmprpyqtzt471.png?width=680&amp;format=png&amp;auto=webp&amp;s=8a86c73bb7a5d535fb18f16d0b155b4765d00f36'}, 'id': 'zmprpyqtzt471'}}",,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,State of the art in Video Object Segmentation,[],r/deeplearning,False,6,,0,,False,t3_nyhpp4,False,dark,0.5,,public,0,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FVzZubDj3AA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'State of the art in Video Object Segmentation', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FVzZubDj3AA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/FVzZubDj3AA/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FVzZubDj3AA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nyhpp4', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1623563823.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=FVzZubDj3AA,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyhpp4,True,,cmillionaire9,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nyhpp4/state_of_the_art_in_video_object_segmentation/,all_ads,False,https://www.youtube.com/watch?v=FVzZubDj3AA,66146,1623535023.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'State of the art in Video Object Segmentation', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/FVzZubDj3AA?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/FVzZubDj3AA/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,"My training with SAEHD isn’t starting when selecting Nvidia T500 (it does work with CPU, but only does about 30 iterations every 15min)

I have received this error message: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize

I saw another solution on github to this was to add the following code:

“OK, I was able to execute my CNN. I'm using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:

from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

I’m unsure exactly where to input this, as putting it in the notebook.py file located in the tensorboard folder hasn’t yielded any success

I have a HP Zbook, Inter Core i7, 32Gb RAM, Nvidia t500 graphics card.

Forever grateful if anyone can point me in the right direction. Thanks in advance",t2_2f5xu7mz,False,,0,False,DFL - SAEHD training not starting,[],r/deeplearning,False,6,,0,,False,t3_nyh5fx,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623562281.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;My training with SAEHD isn’t starting when selecting Nvidia T500 (it does work with CPU, but only does about 30 iterations every 15min)&lt;/p&gt;

&lt;p&gt;I have received this error message: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize&lt;/p&gt;

&lt;p&gt;I saw another solution on github to this was to add the following code:&lt;/p&gt;

&lt;p&gt;“OK, I was able to execute my CNN. I&amp;#39;m using tensorflow tf-nightly-gpu-2.0-preview, and running on a ipython notebook. I had to add this to my notebook:&lt;/p&gt;

&lt;p&gt;from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession&lt;/p&gt;

&lt;p&gt;config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)&lt;/p&gt;

&lt;p&gt;I’m unsure exactly where to input this, as putting it in the notebook.py file located in the tensorboard folder hasn’t yielded any success&lt;/p&gt;

&lt;p&gt;I have a HP Zbook, Inter Core i7, 32Gb RAM, Nvidia t500 graphics card.&lt;/p&gt;

&lt;p&gt;Forever grateful if anyone can point me in the right direction. Thanks in advance&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nyh5fx,True,,Kirchart007,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nyh5fx/dfl_saehd_training_not_starting/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nyh5fx/dfl_saehd_training_not_starting/,66146,1623533481.0,0,,False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,"Chip Placement with Deep RL paper explained! (recently published in Nature, used to develop Google's TPU v5)",[],r/deeplearning,False,6,,0,,False,t3_ny86od,False,dark,0.67,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Z3XtWuuTHz4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Chip Placement with Deep Reinforcement Learning | Paper Explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Z3XtWuuTHz4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Z3XtWuuTHz4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Z3XtWuuTHz4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ny86od', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1623537479.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/Z3XtWuuTHz4,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny86od,True,,gordicaleksa,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ny86od/chip_placement_with_deep_rl_paper_explained/,all_ads,False,https://youtu.be/Z3XtWuuTHz4,66146,1623508679.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Chip Placement with Deep Reinforcement Learning | Paper Explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Z3XtWuuTHz4?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Z3XtWuuTHz4/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,,t2_hmbd5,False,,0,False,Tutorial for novice: How does the machine recognize numbers and black-and-white images?,[],r/deeplearning,False,6,,0,,False,t3_ny1g4t,False,dark,0.72,,public,8,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/kiua6bTqy0Y?start=773&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How does the machine recognize numbers and black-and-white images?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/kiua6bTqy0Y?start=773&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Chier Hu', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/kiua6bTqy0Y/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ChierHu'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/kiua6bTqy0Y?start=773&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/ny1g4t', 'height': 200}",,False,8,,False,False,,False,,[],{},,False,,1623512855.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/kiua6bTqy0Y?t=773,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny1g4t,True,,RossJD,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/ny1g4t/tutorial_for_novice_how_does_the_machine/,all_ads,False,https://youtu.be/kiua6bTqy0Y?t=773,66146,1623484055.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How does the machine recognize numbers and black-and-white images?', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/kiua6bTqy0Y?start=773&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Chier Hu', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/kiua6bTqy0Y/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ChierHu'}}",False,,,,,,,
,deeplearning,"&amp;#x200B;

https://preview.redd.it/b0b8fzoxau471.png?width=1121&amp;format=png&amp;auto=webp&amp;s=4d94b1ed901dcc33720d1b0455a3cd4fe1738a61",t2_3f66wv8f,False,,0,False,Pytorch Implementation Translating Real Images to cartoon images using PIX2PIX - Image-to-Image Translation with Conditional Adversarial Networks Code : https://lnkd.in/etv3Kws paper : https://lnkd.in/exdgeBB,[],r/deeplearning,False,6,,0,,False,t3_ny77uw,False,dark,0.71,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1623534706.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/b0b8fzoxau471.png?width=1121&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4d94b1ed901dcc33720d1b0455a3cd4fe1738a61""&gt;https://preview.redd.it/b0b8fzoxau471.png?width=1121&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4d94b1ed901dcc33720d1b0455a3cd4fe1738a61&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny77uw,True,,rohitkuk,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/ny77uw/pytorch_implementation_translating_real_images_to/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ny77uw/pytorch_implementation_translating_real_images_to/,66146,1623505906.0,3,,False,,,"{'b0b8fzoxau471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 107, 'x': 108, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7379800dd42804c0d14c3c0e5a68151e228dbbcb'}, {'y': 215, 'x': 216, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=40410fcb901321c77cb836e8df5cb3bc97ef9827'}, {'y': 318, 'x': 320, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d1adb964573d7d925cb322f4c40ae476251c4008'}, {'y': 637, 'x': 640, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8bf9501bcd036cf3236e4088a11ec1466bae1df5'}, {'y': 956, 'x': 960, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=012cc053ee761df7cd89af526eb5c6f164bb3591'}, {'y': 1076, 'x': 1080, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b9f15d63770af01885bcb4124890629ee6bf70d4'}], 's': {'y': 1117, 'x': 1121, 'u': 'https://preview.redd.it/b0b8fzoxau471.png?width=1121&amp;format=png&amp;auto=webp&amp;s=4d94b1ed901dcc33720d1b0455a3cd4fe1738a61'}, 'id': 'b0b8fzoxau471'}}",,,,
,deeplearning,"Using tensor flow and 30,000 samples from celebA dataset i trained a DCGan to produce 128x128x3 images of faces. Check out the github and images produced.  [GitHub](https://github.com/giovannidmilana/Deep_conv_gen_gan)

https://preview.redd.it/x4vmrhk6ev471.png?width=432&amp;format=png&amp;auto=webp&amp;s=923e01f1fdc4f43564ca9bcd43c51025b49313d8",t2_2elywrfx,False,,0,False,Deep convolutional generative Adversarial neural net to produce images of faces,[],r/deeplearning,False,6,,0,,False,t3_nybxtg,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623548094.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Using tensor flow and 30,000 samples from celebA dataset i trained a DCGan to produce 128x128x3 images of faces. Check out the github and images produced.  &lt;a href=""https://github.com/giovannidmilana/Deep_conv_gen_gan""&gt;GitHub&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/x4vmrhk6ev471.png?width=432&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=923e01f1fdc4f43564ca9bcd43c51025b49313d8""&gt;https://preview.redd.it/x4vmrhk6ev471.png?width=432&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=923e01f1fdc4f43564ca9bcd43c51025b49313d8&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nybxtg,True,,Extra-most-best,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nybxtg/deep_convolutional_generative_adversarial_neural/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nybxtg/deep_convolutional_generative_adversarial_neural/,66146,1623519294.0,1,,False,,,"{'x4vmrhk6ev471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 72, 'x': 108, 'u': 'https://preview.redd.it/x4vmrhk6ev471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=46aa40b046e321d93f7dc16c47c940adfe22fb9b'}, {'y': 144, 'x': 216, 'u': 'https://preview.redd.it/x4vmrhk6ev471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ed5e7cf1e769ca1850f99664ac02fac88b692ae5'}, {'y': 213, 'x': 320, 'u': 'https://preview.redd.it/x4vmrhk6ev471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f0d0043489aae4f22452e92d9fc0186770ac817e'}], 's': {'y': 288, 'x': 432, 'u': 'https://preview.redd.it/x4vmrhk6ev471.png?width=432&amp;format=png&amp;auto=webp&amp;s=923e01f1fdc4f43564ca9bcd43c51025b49313d8'}, 'id': 'x4vmrhk6ev471'}}",,,,
,deeplearning,"Recently, I have been studying NLP transformer based language models like GPT-2, T5. From the research papers, I came to know that just changing the input format gives required task-specific output. But a lot of articles show fine-tuning them. I am really amused how models with 1.5 billion parameters can be fine-tuned. Can someone explain how is it possible? What is happening during fine-tuning?",t2_4ezy6j81,False,,0,False,"Fine-tuning GPT-2, T5",[],r/deeplearning,False,6,,0,,False,t3_nxz5se,False,dark,0.78,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1623503370.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Recently, I have been studying NLP transformer based language models like GPT-2, T5. From the research papers, I came to know that just changing the input format gives required task-specific output. But a lot of articles show fine-tuning them. I am really amused how models with 1.5 billion parameters can be fine-tuned. Can someone explain how is it possible? What is happening during fine-tuning?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxz5se,True,,Sunee_,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nxz5se/finetuning_gpt2_t5/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxz5se/finetuning_gpt2_t5/,66146,1623474570.0,0,,False,,,,,,,
,deeplearning,"A research team from McGill University, Université de Montréal, DeepMind and Mila presents an end-to-end, model-based deep reinforcement learning (RL) agent that dynamically attends to relevant parts of its environments to facilitate out-of-distribution (OOD) and systematic generalization.

Here is a quick read: [Yoshua Bengio Team Designs Consciousness-Inspired Planning Agent for Model-Based RL.](https://syncedreview.com/2021/06/11/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-39/)

The paper *A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning* is on [arXiv](https://arxiv.org/abs/2106.02097).",t2_2fv4yodo,False,,0,False,[R] Yoshua Bengio Team Designs Consciousness-Inspired Planning Agent for Model-Based RL,[],r/deeplearning,False,6,,0,,False,t3_nxikzm,False,dark,0.95,,public,37,0,{},,False,[],,False,False,,{},,False,37,,False,False,,False,,[],{},,True,,1623453910.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from McGill University, Université de Montréal, DeepMind and Mila presents an end-to-end, model-based deep reinforcement learning (RL) agent that dynamically attends to relevant parts of its environments to facilitate out-of-distribution (OOD) and systematic generalization.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/11/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-39/""&gt;Yoshua Bengio Team Designs Consciousness-Inspired Planning Agent for Model-Based RL.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2106.02097""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxikzm,True,,Yuqing7,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nxikzm/r_yoshua_bengio_team_designs/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxikzm/r_yoshua_bengio_team_designs/,66146,1623425110.0,0,,False,,,,,,,
,deeplearning,"Hello folks,

I have a Asus G15 with a RTX 3080 mobile and I tried to install and use my GPU for training my NN with tensorflow.

I used [this video](https://www.youtube.com/watch?v=hHWkvEcDBO0&amp;t=2s) as a set-up guide but it did not work.

Tensorflow says it can't find a certain dll-file.

Just to make sure that it can be done: Does anyone know of someone with a RTX 3080 mobile who got the GPU acceleration working?",t2_gdgf6,False,,0,False,CUDA with RTX3080 mobile,[],r/deeplearning,False,6,,0,,False,t3_ny3zwx,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623523531.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello folks,&lt;/p&gt;

&lt;p&gt;I have a Asus G15 with a RTX 3080 mobile and I tried to install and use my GPU for training my NN with tensorflow.&lt;/p&gt;

&lt;p&gt;I used &lt;a href=""https://www.youtube.com/watch?v=hHWkvEcDBO0&amp;amp;t=2s""&gt;this video&lt;/a&gt; as a set-up guide but it did not work.&lt;/p&gt;

&lt;p&gt;Tensorflow says it can&amp;#39;t find a certain dll-file.&lt;/p&gt;

&lt;p&gt;Just to make sure that it can be done: Does anyone know of someone with a RTX 3080 mobile who got the GPU acceleration working?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,ny3zwx,True,,TheHupfdole,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/ny3zwx/cuda_with_rtx3080_mobile/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/ny3zwx/cuda_with_rtx3080_mobile/,66146,1623494731.0,0,,False,,,,,,,
,deeplearning,"Many deep learning models created using TensorFlow require high processing capabilities to perform inference. Fortunately, there is a lite version of TensorFlow called TensorFlow Lite (TFLite for short) which allows these models to run on devices with limited capabilities. Inference is performed in less than a second.

This tutorial will go through how to prepare Raspberry Pi (RPi) to run a TFLite model for classifying images. After that, the TFLite version of the MobileNet model will be downloaded and used for making predictions on-device.

Tutorial video link: [https://youtu.be/FdfxizUUQJI](https://youtu.be/FdfxizUUQJI)

Run the code on a free GPU: [https://console.paperspace.com/ml-showcase/notebook/rljtgo7aadmiq7q?file=Raspberry%20Pi%20TF%20Lite%20Models.ipynb](https://console.paperspace.com/ml-showcase/notebook/rljtgo7aadmiq7q?file=Raspberry%20Pi%20TF%20Lite%20Models.ipynb)",t2_15en0l,False,,0,False,[Video] Running TensorFlow Lite Models on Raspberry Pi,[],r/deeplearning,False,6,,0,,False,t3_nxq771,False,dark,0.7,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1623474250.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Many deep learning models created using TensorFlow require high processing capabilities to perform inference. Fortunately, there is a lite version of TensorFlow called TensorFlow Lite (TFLite for short) which allows these models to run on devices with limited capabilities. Inference is performed in less than a second.&lt;/p&gt;

&lt;p&gt;This tutorial will go through how to prepare Raspberry Pi (RPi) to run a TFLite model for classifying images. After that, the TFLite version of the MobileNet model will be downloaded and used for making predictions on-device.&lt;/p&gt;

&lt;p&gt;Tutorial video link: &lt;a href=""https://youtu.be/FdfxizUUQJI""&gt;https://youtu.be/FdfxizUUQJI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Run the code on a free GPU: &lt;a href=""https://console.paperspace.com/ml-showcase/notebook/rljtgo7aadmiq7q?file=Raspberry%20Pi%20TF%20Lite%20Models.ipynb""&gt;https://console.paperspace.com/ml-showcase/notebook/rljtgo7aadmiq7q?file=Raspberry%20Pi%20TF%20Lite%20Models.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxq771,True,,hellopaperspace,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nxq771/video_running_tensorflow_lite_models_on_raspberry/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxq771/video_running_tensorflow_lite_models_on_raspberry/,66146,1623445450.0,0,,False,,,,,,,
,deeplearning,"Transformers are everywhere, so why not add them to reinforcement learning (RL) as well? Yeah, that's right, the researchers at UC Berkeley just did that. They approach RL as a sequence modeling problem and use an autoregressive transformer to predict the next optimal action given the previous states, actions, and rewards so that it maximizes some reward function. Perhaps surprisingly, this simple Decision Transformer approach achieves state-of-the-art performance on Atari, OpenAI Gym, Key-to-Door tasks.

Check out the [full paper digest](https://t.me/casual_gan/50) to learn about how offline RL can be turned into a sequence modeling problem, represent simulation trajectories for the Transformer to learn from, and, most importantly, apply Transformers to ace offline RL tasks!

Meanwhile, check out this paper poster presented by [Casual GAN Papers](https://t.me/casual_gan):

[Decision Transformer](https://preview.redd.it/yfuy5n7x0n471.png?width=759&amp;format=png&amp;auto=webp&amp;s=faffb3478b73a3f694de28733306421b84b94a24)

\[[Full Explanation Post](https://t.me/casual_gan/50)\] \[[Arxiv](https://arxiv.org/pdf/2106.01345.pdf)\] \[[Project page](https://github.com/kzl/decision-transformer)\]

More recent popular computer vision paper breakdowns:

&gt;[DALL-E](https://t.me/casual_gan/48)  
[VQGAN](https://t.me/casual_gan/46)  
[DINO](https://t.me/casual_gan/40)",t2_hhio3,False,,0,False,Paper explained - Decision Transformer: Reinforcement Learning via Sequence Modeling (DecisionTransformer) by Lili Chen et al.,[],r/deeplearning,False,6,,0,,False,t3_nxfvgo,False,dark,0.76,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,1623463680.0,,[],{},,True,,1623446558.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Transformers are everywhere, so why not add them to reinforcement learning (RL) as well? Yeah, that&amp;#39;s right, the researchers at UC Berkeley just did that. They approach RL as a sequence modeling problem and use an autoregressive transformer to predict the next optimal action given the previous states, actions, and rewards so that it maximizes some reward function. Perhaps surprisingly, this simple Decision Transformer approach achieves state-of-the-art performance on Atari, OpenAI Gym, Key-to-Door tasks.&lt;/p&gt;

&lt;p&gt;Check out the &lt;a href=""https://t.me/casual_gan/50""&gt;full paper digest&lt;/a&gt; to learn about how offline RL can be turned into a sequence modeling problem, represent simulation trajectories for the Transformer to learn from, and, most importantly, apply Transformers to ace offline RL tasks!&lt;/p&gt;

&lt;p&gt;Meanwhile, check out this paper poster presented by &lt;a href=""https://t.me/casual_gan""&gt;Casual GAN Papers&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/yfuy5n7x0n471.png?width=759&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=faffb3478b73a3f694de28733306421b84b94a24""&gt;Decision Transformer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/50""&gt;Full Explanation Post&lt;/a&gt;] [&lt;a href=""https://arxiv.org/pdf/2106.01345.pdf""&gt;Arxiv&lt;/a&gt;] [&lt;a href=""https://github.com/kzl/decision-transformer""&gt;Project page&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;More recent popular computer vision paper breakdowns:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=""https://t.me/casual_gan/48""&gt;DALL-E&lt;/a&gt;&lt;br/&gt;
&lt;a href=""https://t.me/casual_gan/46""&gt;VQGAN&lt;/a&gt;&lt;br/&gt;
&lt;a href=""https://t.me/casual_gan/40""&gt;DINO&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxfvgo,True,,KirillTheMunchKing,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nxfvgo/paper_explained_decision_transformer/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxfvgo/paper_explained_decision_transformer/,66146,1623417758.0,0,,False,,,"{'yfuy5n7x0n471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 182, 'x': 108, 'u': 'https://preview.redd.it/yfuy5n7x0n471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=22ad6d1ff315884f546d89b700e29b9c94119f9e'}, {'y': 364, 'x': 216, 'u': 'https://preview.redd.it/yfuy5n7x0n471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=67d9a26f88a2f7cc6f8feadc358e5c14d3332686'}, {'y': 539, 'x': 320, 'u': 'https://preview.redd.it/yfuy5n7x0n471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=78168e3f4a71b62ebc99a4f7ec885fbe2cccbf21'}, {'y': 1079, 'x': 640, 'u': 'https://preview.redd.it/yfuy5n7x0n471.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=60680f5558f3ca8321faf1566e902903c734a489'}], 's': {'y': 1280, 'x': 759, 'u': 'https://preview.redd.it/yfuy5n7x0n471.png?width=759&amp;format=png&amp;auto=webp&amp;s=faffb3478b73a3f694de28733306421b84b94a24'}, 'id': 'yfuy5n7x0n471'}}",,,,
,deeplearning,Looking for action recognition references that perform post processing to detect start and end time for actions?,t2_bwsrpjo6,False,,0,False,Action recognition papers references,[],r/deeplearning,False,6,,0,,False,t3_nxgu9w,False,dark,0.8,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1623449311.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Looking for action recognition references that perform post processing to detect start and end time for actions?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxgu9w,True,,AbjectDrink3276,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nxgu9w/action_recognition_papers_references/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxgu9w/action_recognition_papers_references/,66146,1623420511.0,0,,False,,,,,,,
,deeplearning,"Hi everyone,

I've heard about deep learning and I find the concept really interesting, but i dont have any idea about how to do it or how it works in detail so do you know what are the prerequisite to learn this science and where i could learn it. My final objective (maybe is it too big?) is to create a bot that could learn from the cryptocurrencies market and be able to make ""predictions"" do you think it could be realisable at my scale? 

&amp;#x200B;

Thank you for reading !",t2_ad6d4twn,False,,0,False,How can I learn deeplearning?,[],r/deeplearning,False,6,,0,,False,t3_nxshw7,False,dark,0.6,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623480758.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve heard about deep learning and I find the concept really interesting, but i dont have any idea about how to do it or how it works in detail so do you know what are the prerequisite to learn this science and where i could learn it. My final objective (maybe is it too big?) is to create a bot that could learn from the cryptocurrencies market and be able to make &amp;quot;predictions&amp;quot; do you think it could be realisable at my scale? &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thank you for reading !&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxshw7,True,,Idunnos0rry,,3,True,all_ads,False,[],False,,/r/deeplearning/comments/nxshw7/how_can_i_learn_deeplearning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxshw7/how_can_i_learn_deeplearning/,66146,1623451958.0,0,,False,,,,,,,
,deeplearning,,t2_ibqd1,False,,0,False,Facebook's Grand AI Challenge,[],r/deeplearning,False,6,,0,,False,t3_nx9i7x,False,dark,0.7,,public,13,0,{},,False,[],,False,False,,{},,False,13,,False,False,,False,,[],{},,False,,1623422935.0,text,6,,,text,aicrowd.com,False,,,,,https://www.aicrowd.com/challenges/neurips-2021-the-nethack-challenge?utm_source=reddit&amp;utm_medium=programming&amp;utm_campaign=nethack,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx9i7x,True,,EscapedLaughter,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nx9i7x/facebooks_grand_ai_challenge/,all_ads,False,https://www.aicrowd.com/challenges/neurips-2021-the-nethack-challenge?utm_source=reddit&amp;utm_medium=programming&amp;utm_campaign=nethack,66146,1623394135.0,0,,False,,,,,,,
,deeplearning,,t2_2htwi6,False,,0,False,MusicBERT: Symbolic Music Understanding with Large-Scale Pre-Training,[],r/deeplearning,False,6,,0,,False,t3_nx9xkp,False,dark,0.85,,public,9,0,{},,False,[],,False,False,,{},,False,9,,False,False,,False,,[],{},,False,,1623424709.0,text,6,,,text,arxiv.org,False,,,,,https://arxiv.org/pdf/2106.05630.pdf,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx9xkp,True,,tobyoup,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nx9xkp/musicbert_symbolic_music_understanding_with/,all_ads,False,https://arxiv.org/pdf/2106.05630.pdf,66146,1623395909.0,0,,False,,,,,,,
,deeplearning,"It’ an elegant way to perform matrix or vector manipulation.  
I  find it’s extremely useful if I have to perform matrix multiplication  of matrices which is of higher dimension, it gives a great flexibility  to sum and multiply among certain axis.  
Ex : if you have to multiply  matrix A of shape (1,200,2,32) &amp; matrix B of shape (2,32,32) and  results in a matrix C of shape (1,200,32).  
This can be implemented as follows:  
np.einsum(‘abcd,cde-&gt;abe’,A,B)  
That’s it ! 

&amp;#x200B;

[https://rakshithv.medium.com/einsum-equation-bb5f6292a98c](https://rakshithv.medium.com/einsum-equation-bb5f6292a98c)",t2_159buvym,False,,0,False,"What is ""Einsum"" equation ?",[],r/deeplearning,False,6,,0,,False,t3_nxlp27,False,dark,0.27,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623461976.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;It’ an elegant way to perform matrix or vector manipulation.&lt;br/&gt;
I  find it’s extremely useful if I have to perform matrix multiplication  of matrices which is of higher dimension, it gives a great flexibility  to sum and multiply among certain axis.&lt;br/&gt;
Ex : if you have to multiply  matrix A of shape (1,200,2,32) &amp;amp; matrix B of shape (2,32,32) and  results in a matrix C of shape (1,200,32).&lt;br/&gt;
This can be implemented as follows:&lt;br/&gt;
np.einsum(‘abcd,cde-&amp;gt;abe’,A,B)&lt;br/&gt;
That’s it ! &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://rakshithv.medium.com/einsum-equation-bb5f6292a98c""&gt;https://rakshithv.medium.com/einsum-equation-bb5f6292a98c&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxlp27,True,,rakshith291,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nxlp27/what_is_einsum_equation/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nxlp27/what_is_einsum_equation/,66146,1623433176.0,0,,False,,,,,,,
,deeplearning,,t2_159buvym,False,,0,False,"What is ""Einsum"" equation ?",[],r/deeplearning,False,6,,0,,False,t3_nxlm94,False,dark,0.17,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623461769.0,text,6,,,text,rakshithv.medium.com,False,,,,,https://rakshithv.medium.com/einsum-equation-bb5f6292a98c,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxlm94,True,,rakshith291,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nxlm94/what_is_einsum_equation/,all_ads,False,https://rakshithv.medium.com/einsum-equation-bb5f6292a98c,66146,1623432969.0,0,,False,,,,,,,
,deeplearning,"An IEEE team provides a comprehensive overview of the bottom-up and top-down design approaches toward neuromorphic intelligence, highlighting the different levels of granularity present in existing silicon implementations and assessing the benefits of the different circuit design styles in neural processing systems. 

Here is a quick read: [IEEE Publishes Comprehensive Survey of Bottom-Up and Top-Down Neural Processing System Design.](https://syncedreview.com/2021/06/10/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-38/)

The paper *Bottom-Up and Top-Down Neural Processing Systems Design: Neuromorphic Intelligence as the Convergence of Natural and Artificial Intelligence* is on [arXiv](https://arxiv.org/abs/2106.01288).",t2_2fv4yodo,False,,0,False,[R] IEEE Publishes Comprehensive Survey of Bottom-Up and Top-Down Neural Processing System Design,[],r/deeplearning,False,6,,0,,False,t3_nwqnxp,False,dark,0.94,,public,25,0,{},,False,[],,False,False,,{},,False,25,,False,False,,False,,[],{},,True,,1623368296.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;An IEEE team provides a comprehensive overview of the bottom-up and top-down design approaches toward neuromorphic intelligence, highlighting the different levels of granularity present in existing silicon implementations and assessing the benefits of the different circuit design styles in neural processing systems. &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/10/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-38/""&gt;IEEE Publishes Comprehensive Survey of Bottom-Up and Top-Down Neural Processing System Design.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Bottom-Up and Top-Down Neural Processing Systems Design: Neuromorphic Intelligence as the Convergence of Natural and Artificial Intelligence&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2106.01288""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwqnxp,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nwqnxp/r_ieee_publishes_comprehensive_survey_of_bottomup/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nwqnxp/r_ieee_publishes_comprehensive_survey_of_bottomup/,66146,1623339496.0,0,,False,,,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,AI Sign Language Translator,[],r/deeplearning,False,6,,0,,False,t3_nxas4p,False,dark,0.57,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/cTwKP796PPw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI Sign Language Translator', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/cTwKP796PPw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/cTwKP796PPw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/cTwKP796PPw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nxas4p', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1623428207.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/cTwKP796PPw,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nxas4p,True,,cmillionaire9,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nxas4p/ai_sign_language_translator/,all_ads,False,https://youtu.be/cTwKP796PPw,66146,1623399407.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'AI Sign Language Translator', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/cTwKP796PPw?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/cTwKP796PPw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning,"I have the following problem statement in which I only need to predict whether a given image is an apple or not. For training only 8 images are provided with the following details:

1. apple\_1 image - 2400x1889 PNG
2. apple\_2 image - 641x618 PNG
3. apple\_3 image - 1000x1001 PNG
4. apple\_4 image - 500x500 PNG		contains a sticker on top of fruit
5. apple\_5 image - 2400x1889 PNG
6. apple\_6 image - 1000x1000 PNG
7. apple\_7 image - 253x199 JPG
8. apple\_8 image - 253x199 JPG

&amp;#x200B;

I am thinking about using Transfer learning: either VGG or ResNet-18/34/50. Maybe ResNet is an overkill for this problem statement? How do I deal with such varying image sizes and of different file extensions (PNG, JPG)?

Any online code tutorial will be helpful.

Thanks!",t2_2mmql89p,False,,0,False,CNN - Apple Classification,[],r/deeplearning,False,6,,0,,False,t3_nx882t,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623417937.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have the following problem statement in which I only need to predict whether a given image is an apple or not. For training only 8 images are provided with the following details:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;apple_1 image - 2400x1889 PNG&lt;/li&gt;
&lt;li&gt;apple_2 image - 641x618 PNG&lt;/li&gt;
&lt;li&gt;apple_3 image - 1000x1001 PNG&lt;/li&gt;
&lt;li&gt;apple_4 image - 500x500 PNG     contains a sticker on top of fruit&lt;/li&gt;
&lt;li&gt;apple_5 image - 2400x1889 PNG&lt;/li&gt;
&lt;li&gt;apple_6 image - 1000x1000 PNG&lt;/li&gt;
&lt;li&gt;apple_7 image - 253x199 JPG&lt;/li&gt;
&lt;li&gt;apple_8 image - 253x199 JPG&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am thinking about using Transfer learning: either VGG or ResNet-18/34/50. Maybe ResNet is an overkill for this problem statement? How do I deal with such varying image sizes and of different file extensions (PNG, JPG)?&lt;/p&gt;

&lt;p&gt;Any online code tutorial will be helpful.&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx882t,True,,grid_world,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/nx882t/cnn_apple_classification/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nx882t/cnn_apple_classification/,66146,1623389137.0,0,,False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,Non-Parametric Transformers | Paper explained!,[],r/deeplearning,False,6,,0,,False,t3_nwk1zy,False,dark,0.93,,public,27,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6ekOVosCQN8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Non-Parametric Transformers | Paper explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6ekOVosCQN8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6ekOVosCQN8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6ekOVosCQN8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nwk1zy', 'height': 200}",,False,27,,False,False,,False,,[],{},,False,,1623348904.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/6ekOVosCQN8,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwk1zy,True,,gordicaleksa,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nwk1zy/nonparametric_transformers_paper_explained/,all_ads,False,https://youtu.be/6ekOVosCQN8,66146,1623320104.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Non-Parametric Transformers | Paper explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6ekOVosCQN8?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6ekOVosCQN8/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,Can someone suggest me some good course /platform to learn NLP with hands-on experience such as chatboat and all ?,t2_4839qzd1,False,,0,False,Suggestions for NLP tutorials,[],r/deeplearning,False,6,,0,,False,t3_nx6l0k,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623412142.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Can someone suggest me some good course /platform to learn NLP with hands-on experience such as chatboat and all ?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx6l0k,True,,Vivek_Murali,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nx6l0k/suggestions_for_nlp_tutorials/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nx6l0k/suggestions_for_nlp_tutorials/,66146,1623383342.0,0,,False,,,,,,,
,deeplearning,Hello wonderful people. First a little background about me. I am currently in my second year of MTech Signal Processing. I specifically chose this brach because of its wide ranging applications in AI and deep learning. So I want a little help from you guys on what sort of research area I can chose so that my dissertation stands out a little from the crowd and which can actually help me in landing a job. I am also thinking of publishing a paper that would add to the project I want to work on. I am very inclined towards deep learning applications in medical field as well as in field the sound processing if that makes sense. Any sort of help would be appreciated.,t2_22fn1krt,False,,0,False,Some help regarding my upcoming dissertation next semester,[],r/deeplearning,False,6,,0,,False,t3_nx5vyl,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623409799.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hello wonderful people. First a little background about me. I am currently in my second year of MTech Signal Processing. I specifically chose this brach because of its wide ranging applications in AI and deep learning. So I want a little help from you guys on what sort of research area I can chose so that my dissertation stands out a little from the crowd and which can actually help me in landing a job. I am also thinking of publishing a paper that would add to the project I want to work on. I am very inclined towards deep learning applications in medical field as well as in field the sound processing if that makes sense. Any sort of help would be appreciated.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx5vyl,True,,AltruisticEmphasis,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nx5vyl/some_help_regarding_my_upcoming_dissertation_next/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nx5vyl/some_help_regarding_my_upcoming_dissertation_next/,66146,1623380999.0,2,,False,,,,,,,
,deeplearning,"Guys, I am college student in last semester and would like to prepare myself for the work after graduating. I would appreciate if you guy can share tools/libs or your experience working in the field. (which area? Which tool? Which sector? Firm? Research? Etc. )

P/s If here is the wrong place for the question, mods please remove it.",t2_aajz5dw6,False,,0,False,Tools you are using...,[],r/deeplearning,False,6,,0,,False,t3_nx0n1s,False,dark,0.38,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623393542.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Guys, I am college student in last semester and would like to prepare myself for the work after graduating. I would appreciate if you guy can share tools/libs or your experience working in the field. (which area? Which tool? Which sector? Firm? Research? Etc. )&lt;/p&gt;

&lt;p&gt;P/s If here is the wrong place for the question, mods please remove it.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx0n1s,True,,PlutoMother,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nx0n1s/tools_you_are_using/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nx0n1s/tools_you_are_using/,66146,1623364742.0,0,,False,,,,,,,
,deeplearning,"Hi everyone, I am 36 yrs old. My major is computer science.  I am desperatley  in a need for a job to have a roof and a loaf. 

Recently I have applied for many jobs, I got 1000 plus rejections. What I see in the job market nowadays is video and image processing jobs. 
I set this goal: I want them to look for me in a year or less. I want them to ask for my service,  not me looking for companies  anymore.   
I want your help , guide me , order me, tell me what to do to become an expert in video processing. I promise, I will follow your steps and post my results here after months.

Edit: language mistakes",t2_zj4u90g,False,,0,False,Just give your orders !,[],r/deeplearning,False,6,,0,,False,t3_nwosn8,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623363592.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi everyone, I am 36 yrs old. My major is computer science.  I am desperatley  in a need for a job to have a roof and a loaf. &lt;/p&gt;

&lt;p&gt;Recently I have applied for many jobs, I got 1000 plus rejections. What I see in the job market nowadays is video and image processing jobs. 
I set this goal: I want them to look for me in a year or less. I want them to ask for my service,  not me looking for companies  anymore.&lt;br/&gt;
I want your help , guide me , order me, tell me what to do to become an expert in video processing. I promise, I will follow your steps and post my results here after months.&lt;/p&gt;

&lt;p&gt;Edit: language mistakes&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwosn8,True,,Beginner4ever,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/nwosn8/just_give_your_orders/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nwosn8/just_give_your_orders/,66146,1623334792.0,0,,False,,,,,,,
,deeplearning," Hi! I would like to cluster news articles with their similarity, I want to create and classifier with respect to their clusters.

I have 4 million of news articles text data and it's completely unsupervised, Now I am stuck on which is the best technique that I should use and how do I validate that the cluster perfect and having similarity. 

Thanks for any input!",t2_a8k0v7v0,False,,0,False,Best clustering approach on unsupervised news articles?,[],r/deeplearning,False,6,,0,,False,t3_nwhfgv,False,dark,0.73,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,True,,1623337780.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi! I would like to cluster news articles with their similarity, I want to create and classifier with respect to their clusters.&lt;/p&gt;

&lt;p&gt;I have 4 million of news articles text data and it&amp;#39;s completely unsupervised, Now I am stuck on which is the best technique that I should use and how do I validate that the cluster perfect and having similarity. &lt;/p&gt;

&lt;p&gt;Thanks for any input!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwhfgv,True,,Alan491,,8,True,all_ads,False,[],False,,/r/deeplearning/comments/nwhfgv/best_clustering_approach_on_unsupervised_news/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nwhfgv/best_clustering_approach_on_unsupervised_news/,66146,1623308980.0,0,,False,,,,,,,
,deeplearning,"Hi guys, i'm data science student and i'm traying to build a mask r cnn model for 13 classes for instances segmentation task .

My datasets have the following distribution:

train set:

* n images =  1296

&amp;#8203;

    # class:n_annotations
    CLASS_WEIGHTS = {1:1559, 2:835, 3:1112, 4:1205,
                 5:997, 6:31, 7:120, 8:37,
                 9:48, 10:28, 11:37, 12:1992, 13:1907}

val set:

* n images = 154

&amp;#8203;

    # class:n_annotations
    CLASS_WEIGHTS = {1:130, 2:79, 3:93, 4:152,
                     5:144, 6:2, 7:18, 8:0,
                     9:0, 10:0, 11:1, 12:235, 13:241}

I tried this:

    class CustomConfig(Config):
        """"""Configuration for training on the custom  dataset.
        Derives from the base Config class and overrides some values.
        """"""
        # Give the configuration a recognizable name
        NAME = ""object""
    
        # We use a GPU with 12GB memory, which can fit two images.
        # Adjust down if you use a smaller GPU.
        IMAGES_PER_GPU = 2
    
        # Number of classes (including background)
        NUM_CLASSES = 1 + 13
        # Number of training steps per epoch
        STEPS_PER_EPOCH = 120
        VALIDATION_STEPS = 30
    
        # Skip detections with &lt; 85% confidence
        DETECTION_MIN_CONFIDENCE = 0.5
        BACKBONE_STRIDES = [8,16,32,64,128]
        DETECTION_NMS_THRESHOLD=0.1
    
    ####################################################################
    
    
    augmentation = iaa.Sequential([
        iaa.Fliplr(0.8), # only horizontal flip here
        iaa.Flipud(0.8), # only vertical flip here
    ])
    
    ####################################################################
    
    CLASS_WEIGHTS = {1:1559, 2:835, 3:1112, 4:1205,
                     5:997, 6:31, 7:120, 8:37,
                     9:48, 10:28, 11:37, 12:1992, 13:1907}
    
    def compute_class_weights(CLASS_WEIGHTS=CLASS_WEIGHTS):
    
      mean = np.array(list(CLASS_WEIGHTS.values())).mean() # sum_class_occurence / nb_classes
      max_weight = np.array(list(CLASS_WEIGHTS.values())).max()
      CLASS_WEIGHTS.update((x, float(max_weight/(y))) for x, y in CLASS_WEIGHTS.items())
      CLASS_WEIGHTS=dict(sorted(CLASS_WEIGHTS.items()))
    
      return CLASS_WEIGHTS
    
    class_weights = compute_class_weights(CLASS_WEIGHTS)
    
    ########################################################################
    print(""Training mask r cnn"")
    model.train(dataset_train, dataset_val,
                learning_rate=0.0001*2,
                class_weight= class_weights,
                epochs=2,          # i tried diffferent number of epochs (2-20-30-50)
                augmentation= augmentation,
                layers='heads', custom_callbacks=[tensorboard])
    
    history = model.keras_model.history.history	

* Loss: values between range (0.6-1.8, based on number of epochs)
*  val\_loss : values between range (0.4 - 1)

both values are however fluctuating. 

I WANT fix this because i get this error : NO ISTANCES TO DISPLAY.  With only the 2 largest classes, it works very well.

&amp;#x200B;

Thanks for the attention.",t2_3zwz9769,False,,0,False,Fix Class imbalance in Mask r cnn,[],r/deeplearning,False,6,,0,,False,t3_nwt13h,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623374231.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi guys, i&amp;#39;m data science student and i&amp;#39;m traying to build a mask r cnn model for 13 classes for instances segmentation task .&lt;/p&gt;

&lt;p&gt;My datasets have the following distribution:&lt;/p&gt;

&lt;p&gt;train set:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;n images =  1296&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#8203;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# class:n_annotations
CLASS_WEIGHTS = {1:1559, 2:835, 3:1112, 4:1205,
             5:997, 6:31, 7:120, 8:37,
             9:48, 10:28, 11:37, 12:1992, 13:1907}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;val set:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;n images = 154&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;#8203;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# class:n_annotations
CLASS_WEIGHTS = {1:130, 2:79, 3:93, 4:152,
                 5:144, 6:2, 7:18, 8:0,
                 9:0, 10:0, 11:1, 12:235, 13:241}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I tried this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class CustomConfig(Config):
    &amp;quot;&amp;quot;&amp;quot;Configuration for training on the custom  dataset.
    Derives from the base Config class and overrides some values.
    &amp;quot;&amp;quot;&amp;quot;
    # Give the configuration a recognizable name
    NAME = &amp;quot;object&amp;quot;

    # We use a GPU with 12GB memory, which can fit two images.
    # Adjust down if you use a smaller GPU.
    IMAGES_PER_GPU = 2

    # Number of classes (including background)
    NUM_CLASSES = 1 + 13
    # Number of training steps per epoch
    STEPS_PER_EPOCH = 120
    VALIDATION_STEPS = 30

    # Skip detections with &amp;lt; 85% confidence
    DETECTION_MIN_CONFIDENCE = 0.5
    BACKBONE_STRIDES = [8,16,32,64,128]
    DETECTION_NMS_THRESHOLD=0.1

####################################################################


augmentation = iaa.Sequential([
    iaa.Fliplr(0.8), # only horizontal flip here
    iaa.Flipud(0.8), # only vertical flip here
])

####################################################################

CLASS_WEIGHTS = {1:1559, 2:835, 3:1112, 4:1205,
                 5:997, 6:31, 7:120, 8:37,
                 9:48, 10:28, 11:37, 12:1992, 13:1907}

def compute_class_weights(CLASS_WEIGHTS=CLASS_WEIGHTS):

  mean = np.array(list(CLASS_WEIGHTS.values())).mean() # sum_class_occurence / nb_classes
  max_weight = np.array(list(CLASS_WEIGHTS.values())).max()
  CLASS_WEIGHTS.update((x, float(max_weight/(y))) for x, y in CLASS_WEIGHTS.items())
  CLASS_WEIGHTS=dict(sorted(CLASS_WEIGHTS.items()))

  return CLASS_WEIGHTS

class_weights = compute_class_weights(CLASS_WEIGHTS)

########################################################################
print(&amp;quot;Training mask r cnn&amp;quot;)
model.train(dataset_train, dataset_val,
            learning_rate=0.0001*2,
            class_weight= class_weights,
            epochs=2,          # i tried diffferent number of epochs (2-20-30-50)
            augmentation= augmentation,
            layers=&amp;#39;heads&amp;#39;, custom_callbacks=[tensorboard])

history = model.keras_model.history.history 
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Loss: values between range (0.6-1.8, based on number of epochs)&lt;/li&gt;
&lt;li&gt; val_loss : values between range (0.4 - 1)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;both values are however fluctuating. &lt;/p&gt;

&lt;p&gt;I WANT fix this because i get this error : NO ISTANCES TO DISPLAY.  With only the 2 largest classes, it works very well.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks for the attention.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwt13h,True,,Dario_Della,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nwt13h/fix_class_imbalance_in_mask_r_cnn/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nwt13h/fix_class_imbalance_in_mask_r_cnn/,66146,1623345431.0,0,,False,,,,,,,
,deeplearning,"Hi, I used a neural network on Keras to approximate a concave one dimensional function , I would like to find the argmax and the max of my neural network, what would be the easiest way to solve this ? Should I implement something myself or does Keras already have some buil in function for that ?

Thanks!",t2_64rkugj2,False,,0,False,maximize a neural network,[],r/deeplearning,False,6,,0,,False,t3_nx0wb4,False,dark,0.2,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623394275.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I used a neural network on Keras to approximate a concave one dimensional function , I would like to find the argmax and the max of my neural network, what would be the easiest way to solve this ? Should I implement something myself or does Keras already have some buil in function for that ?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nx0wb4,True,,draleo183013,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nx0wb4/maximize_a_neural_network/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nx0wb4/maximize_a_neural_network/,66146,1623365475.0,0,,False,,,,,,,
,deeplearning,,t2_154ll80i,False,,0,False,The 10 Emerging Deep Learning Trends To Watch in The Near Future,[],r/deeplearning,False,6,,0,,False,t3_nwru4j,False,dark,0.43,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623371253.0,text,6,,,text,ubuntupit.com,False,,,,,https://www.ubuntupit.com/emerging-deep-learning-trends/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwru4j,True,,UbuntuPIT,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nwru4j/the_10_emerging_deep_learning_trends_to_watch_in/,all_ads,False,https://www.ubuntupit.com/emerging-deep-learning-trends/,66146,1623342453.0,0,,False,,,,,,,
,deeplearning,,t2_5v1ni8yq,False,,0,False,"Using deep learning to decipher the regulatory code of gene expression, a review",[],r/deeplearning,False,6,,0,,False,t3_nwkop6,False,dark,0.62,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,False,,1623351352.0,text,6,,,text,frontiersin.org,False,,,,,https://www.frontiersin.org/articles/10.3389/fmolb.2021.673363,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwkop6,True,,janimezzz,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nwkop6/using_deep_learning_to_decipher_the_regulatory/,all_ads,False,https://www.frontiersin.org/articles/10.3389/fmolb.2021.673363,66146,1623322552.0,0,,False,,,,,,,
,deeplearning,,t2_akengm24,False,,0,False,😂😂😂,[],r/deeplearning,False,6,,0,,False,t3_nwtous,False,dark,0.23,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623375888.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/utv9m9h06h471.png,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nwtous,True,,Community-Of-Babel,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nwtous/_/,all_ads,False,https://i.redd.it/utv9m9h06h471.png,66146,1623347088.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'u_Community-Of-Babel', 'selftext': '', 'author_fullname': 't2_akengm24', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '😂😂😂', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'u/Community-Of-Babel', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nwtl5k', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'user', 'ups': 9, 'total_awards_received': 0, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 9, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1623375625.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': 'qa', 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/utv9m9h06h471.png', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_40oteb', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': 'nwtl5k', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Community-Of-Babel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/u_Community-Of-Babel/comments/nwtl5k/_/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://i.redd.it/utv9m9h06h471.png', 'subreddit_subscribers': 0, 'created_utc': 1623346825.0, 'num_crossposts': 7, 'media': None, 'is_video': False}]",t3_nwtl5k,,,,,
,deeplearning,"Programming is way more fun when you learn/work with someone. Help each other, ask questions, brainstorm, etc. There is just so much benefit to joining a community when you are in this field, especially when you cannot find the question you are looking for on stack overflow! 😉  
This is the same thing with AI, and it is why a little less than a year ago, I created a discord server where anyone learning or working in the field could come and share their projects, learn together, work together, and much more. As a result, the community is now close to 13'000 members, which is unbelievable! So glad to see it growing and see everyone so active.  


Join us if you are in the field of AI!  
[https://discord.gg/learnaitogether](https://discord.gg/learnaitogether)",t2_c14wpji,False,,0,False,"Are you currently learning or working with AI? Well, 12'000+ of us are, too! So join our Discord servers, ask questions, find teammates, share your projects, help others, and much more!",[],r/deeplearning,False,6,,0,,False,t3_nvt9fs,False,dark,0.8,,public,36,1,{},,False,[],,False,False,,{},,False,36,,False,False,,False,,[],{},,True,,1623266002.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Programming is way more fun when you learn/work with someone. Help each other, ask questions, brainstorm, etc. There is just so much benefit to joining a community when you are in this field, especially when you cannot find the question you are looking for on stack overflow! 😉&lt;br/&gt;
This is the same thing with AI, and it is why a little less than a year ago, I created a discord server where anyone learning or working in the field could come and share their projects, learn together, work together, and much more. As a result, the community is now close to 13&amp;#39;000 members, which is unbelievable! So glad to see it growing and see everyone so active.  &lt;/p&gt;

&lt;p&gt;Join us if you are in the field of AI!&lt;br/&gt;
&lt;a href=""https://discord.gg/learnaitogether""&gt;https://discord.gg/learnaitogether&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 150, 'id': 'award_f44611f1-b89e-46dc-97fe-892280b13b82', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'Thank you stranger. Shows the award.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Helpful', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=16&amp;height=16&amp;auto=webp&amp;s=a5662dfbdb402bf67866c050aa76c31c147c2f45', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=32&amp;height=32&amp;auto=webp&amp;s=a6882eb3f380e8e88009789f4d0072e17b8c59f1', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=48&amp;height=48&amp;auto=webp&amp;s=e50064b090879e8a0b55e433f6ee61d5cb5fbe1d', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=64&amp;height=64&amp;auto=webp&amp;s=8e5bb2e76683cb6b161830bcdd9642049d6adc11', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png?width=128&amp;height=128&amp;auto=webp&amp;s=eda4a9246f95f42ee6940cc0ec65306fd20de878', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/klvxk1wggfd41_Helpful.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvt9fs,True,,OnlyProggingForFun,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvt9fs/are_you_currently_learning_or_working_with_ai/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvt9fs/are_you_currently_learning_or_working_with_ai/,66146,1623237202.0,0,,False,,,,,,,
,deeplearning,"A research team from UC Berkeley, Facebook AI Research and Google Brain abstracts Reinforcement Learning (RL) as a sequence modelling problem. Their proposed Decision Transformer simply outputs optimal actions by leveraging a causally masked transformer, yet matches or exceeds state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.

Here is a quick read: [Pieter Abbeel Team’s Decision Transformer Abstracts RL as Sequence Modelling.](https://syncedreview.com/2021/06/09/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-37/)

The paper *Decision Transformer: Reinforcement Learning via Sequence Modeling* is on [arXiv](https://arxiv.org/abs/2106.01345).",t2_2fv4yodo,False,,0,False,[R] Pieter Abbeel Team’s Decision Transformer Abstracts RL as Sequence Modelling,[],r/deeplearning,False,6,,0,,False,t3_nvxwi7,False,dark,0.74,,public,7,0,{},,False,[],,False,False,,{},,False,7,,False,False,,False,,[],{},,True,,1623279460.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from UC Berkeley, Facebook AI Research and Google Brain abstracts Reinforcement Learning (RL) as a sequence modelling problem. Their proposed Decision Transformer simply outputs optimal actions by leveraging a causally masked transformer, yet matches or exceeds state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/09/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-37/""&gt;Pieter Abbeel Team’s Decision Transformer Abstracts RL as Sequence Modelling.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Decision Transformer: Reinforcement Learning via Sequence Modeling&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2106.01345""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvxwi7,True,,Yuqing7,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nvxwi7/r_pieter_abbeel_teams_decision_transformer/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvxwi7/r_pieter_abbeel_teams_decision_transformer/,66146,1623250660.0,0,,False,,,,,,,
,deeplearning,EDIT: CURSOR'S MOVEMENT. I am sorry guy's I thought I typed this.smh,t2_34qgdyb6,False,,0,False,Can NN be trained to predict the attention of the user based on its movement?,[],r/deeplearning,False,6,,0,,False,t3_nw2qxo,False,dark,0.61,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,1623299340.0,,[],{},,True,,1623292096.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;EDIT: CURSOR&amp;#39;S MOVEMENT. I am sorry guy&amp;#39;s I thought I typed this.smh&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nw2qxo,True,,yaakarsh1011,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nw2qxo/can_nn_be_trained_to_predict_the_attention_of_the/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nw2qxo/can_nn_be_trained_to_predict_the_attention_of_the/,66146,1623263296.0,0,,False,,,,,,,
,deeplearning,"I am working on identifying product placements in Youtube Videos and currently, I am looking at kids' toys being endorsed. When I was collecting training data for the toys, I noticed that most of the product images have just the object in the image and nothing else. There is no other pictorial significance other than the object in the image. 

For example, this is one of the training images: 
[Training Image](https://drive.google.com/file/d/1Jc04W5-Y1HLAbyoH8x-06Zg9dZf8inY4/view?usp=sharing)

And this is one of the images, that I'll be testing my object detector on after training my model:
[Inference Image](https://drive.google.com/file/d/1mHDerDcCd5UPykUB-DXjgrxhFl7slIvM/view?usp=sharing)

I just wanted to know how will this affect the performance of the model. I'll be annotating these images and use Few-Shot Learning for this task but I never encountered this situation where the training sample had images that contained only the object and nothing else. Also, since the image itself contains the object, fit to the image dimensions, and has nothing else in the image, should I actually annotate these images or is there any other approach that I can adopt that would help me train this kind of images faster? (on top of my mind, resize all the images to one size and since all the objects are fit to image dimensions, automate the process of drawing bounding boxes at coordinates close to the borders of the image)",t2_2y8jn07i,False,,0,False,"How well will an objector work if in the training images, there is no other spatial information other than the object itself?",[],r/deeplearning,False,6,,0,,False,t3_nw744v,False,dark,0.67,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623303613.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I am working on identifying product placements in Youtube Videos and currently, I am looking at kids&amp;#39; toys being endorsed. When I was collecting training data for the toys, I noticed that most of the product images have just the object in the image and nothing else. There is no other pictorial significance other than the object in the image. &lt;/p&gt;

&lt;p&gt;For example, this is one of the training images: 
&lt;a href=""https://drive.google.com/file/d/1Jc04W5-Y1HLAbyoH8x-06Zg9dZf8inY4/view?usp=sharing""&gt;Training Image&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And this is one of the images, that I&amp;#39;ll be testing my object detector on after training my model:
&lt;a href=""https://drive.google.com/file/d/1mHDerDcCd5UPykUB-DXjgrxhFl7slIvM/view?usp=sharing""&gt;Inference Image&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I just wanted to know how will this affect the performance of the model. I&amp;#39;ll be annotating these images and use Few-Shot Learning for this task but I never encountered this situation where the training sample had images that contained only the object and nothing else. Also, since the image itself contains the object, fit to the image dimensions, and has nothing else in the image, should I actually annotate these images or is there any other approach that I can adopt that would help me train this kind of images faster? (on top of my mind, resize all the images to one size and since all the objects are fit to image dimensions, automate the process of drawing bounding boxes at coordinates close to the borders of the image)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nw744v,True,,pranay-ar,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nw744v/how_well_will_an_objector_work_if_in_the_training/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nw744v/how_well_will_an_objector_work_if_in_the_training/,66146,1623274813.0,0,,False,,,,,,,
,deeplearning,,t2_clegqv8z,False,,0,False,GAN trained on instagram models,[],r/deeplearning,False,6,,0,,False,t3_nv6mzi,False,dark,0.93,,public,159,1,{},,False,[],"{'reddit_video': {'bitrate_kbps': 1200, 'fallback_url': 'https://v.redd.it/50i9nxgv72471/DASH_480.mp4?source=fallback', 'height': 480, 'width': 480, 'scrubber_media_url': 'https://v.redd.it/50i9nxgv72471/DASH_96.mp4', 'dash_url': 'https://v.redd.it/50i9nxgv72471/DASHPlaylist.mpd?a=1626450752%2CMzExZTM2MTQ4MDM2ZjMwZDMyN2ZkZTEyZDhmY2Q4MzBmOTQxOTlkOWMzZmQyODcxMzAyMWVkZGFhOTczZmM2Mw%3D%3D&amp;v=1&amp;f=sd', 'duration': 19, 'hls_url': 'https://v.redd.it/50i9nxgv72471/HLSPlaylist.m3u8?a=1626450752%2CYWUzNTk5OWRhMmYzZGQ0MjBhYzk1ZDkzMDQzMTE4YTA4Mjg2NWFhNGQwNjAyYmIwZTJhYmRlNTdjNWNlMzUzZQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,159,,False,False,,False,,[],{},,False,,1623195240.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/50i9nxgv72471,,False,False,False,False,False,"[{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 125, 'id': 'award_5f123e3d-4f48-42f4-9c11-e98b566d5897', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_width': 2048, 'static_icon_width': 2048, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': 'When you come across a feel-good thing.', 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 2048, 'name': 'Wholesome', 'resized_static_icons': [{'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=16&amp;height=16&amp;auto=webp&amp;s=92932f465d58e4c16b12b6eac4ca07d27e3d11c0', 'width': 16, 'height': 16}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=32&amp;height=32&amp;auto=webp&amp;s=d11484a208d68a318bf9d4fcf371171a1cb6a7ef', 'width': 32, 'height': 32}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=48&amp;height=48&amp;auto=webp&amp;s=febdf28b6f39f7da7eb1365325b85e0bb49a9f63', 'width': 48, 'height': 48}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=64&amp;height=64&amp;auto=webp&amp;s=b4406a2d88bf86fa3dc8a45aacf7e0c7bdccc4fb', 'width': 64, 'height': 64}, {'url': 'https://preview.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png?width=128&amp;height=128&amp;auto=webp&amp;s=19555b13e3e196b62eeb9160d1ac1d1b372dcb0b', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 2048, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://i.redd.it/award_images/t5_22cerq/5izbv4fn0md41_Wholesome.png'}]",[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv6mzi,True,,ThisModelDoesNotExis,,42,True,all_ads,False,[],False,,/r/deeplearning/comments/nv6mzi/gan_trained_on_instagram_models/,all_ads,False,https://v.redd.it/50i9nxgv72471,66146,1623166440.0,0,"{'reddit_video': {'bitrate_kbps': 1200, 'fallback_url': 'https://v.redd.it/50i9nxgv72471/DASH_480.mp4?source=fallback', 'height': 480, 'width': 480, 'scrubber_media_url': 'https://v.redd.it/50i9nxgv72471/DASH_96.mp4', 'dash_url': 'https://v.redd.it/50i9nxgv72471/DASHPlaylist.mpd?a=1626450752%2CMzExZTM2MTQ4MDM2ZjMwZDMyN2ZkZTEyZDhmY2Q4MzBmOTQxOTlkOWMzZmQyODcxMzAyMWVkZGFhOTczZmM2Mw%3D%3D&amp;v=1&amp;f=sd', 'duration': 19, 'hls_url': 'https://v.redd.it/50i9nxgv72471/HLSPlaylist.m3u8?a=1626450752%2CYWUzNTk5OWRhMmYzZGQ0MjBhYzk1ZDkzMDQzMTE4YTA4Mjg2NWFhNGQwNjAyYmIwZTJhYmRlNTdjNWNlMzUzZQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,https://youtu.be/z9mDGLKKqo0,t2_357rx0k0,False,,0,False,"AI Weekly Update - June 9th, 2021",[],r/deeplearning,False,6,,0,,False,t3_nw12t4,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623287763.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://youtu.be/z9mDGLKKqo0""&gt;https://youtu.be/z9mDGLKKqo0&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nw12t4,True,,HenryAILabs,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nw12t4/ai_weekly_update_june_9th_2021/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nw12t4/ai_weekly_update_june_9th_2021/,66146,1623258963.0,0,,False,,,,,,,
,deeplearning,"This is the autoencoder I am building.

https://preview.redd.it/gdu3p9hrv9471.png?width=739&amp;format=png&amp;auto=webp&amp;s=e1b914f6433b2a3bbd962bb265a18278efa89f1d",t2_39dnc90e,False,,0,False,Does anyone know why my val_loss is nan?,[],r/deeplearning,False,6,,0,,False,t3_nw0y6t,False,dark,0.57,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623287434.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;This is the autoencoder I am building.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/gdu3p9hrv9471.png?width=739&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e1b914f6433b2a3bbd962bb265a18278efa89f1d""&gt;https://preview.redd.it/gdu3p9hrv9471.png?width=739&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=e1b914f6433b2a3bbd962bb265a18278efa89f1d&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nw0y6t,True,,HVACCalculations,,11,True,all_ads,False,[],False,,/r/deeplearning/comments/nw0y6t/does_anyone_know_why_my_val_loss_is_nan/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nw0y6t/does_anyone_know_why_my_val_loss_is_nan/,66146,1623258634.0,0,,False,,,"{'gdu3p9hrv9471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 123, 'x': 108, 'u': 'https://preview.redd.it/gdu3p9hrv9471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6dd0ffa8d94472e4f7ef2113b06e6a806672cdcd'}, {'y': 246, 'x': 216, 'u': 'https://preview.redd.it/gdu3p9hrv9471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2d5c3e68890b087d38aa9573e7954897d67893f6'}, {'y': 365, 'x': 320, 'u': 'https://preview.redd.it/gdu3p9hrv9471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=d93e2d3fcd2b52dfb7d236701a98e16b61ef337d'}, {'y': 731, 'x': 640, 'u': 'https://preview.redd.it/gdu3p9hrv9471.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2d05bdeacfc20c989359ebe916ee4fc73d2210f4'}], 's': {'y': 845, 'x': 739, 'u': 'https://preview.redd.it/gdu3p9hrv9471.png?width=739&amp;format=png&amp;auto=webp&amp;s=e1b914f6433b2a3bbd962bb265a18278efa89f1d'}, 'id': 'gdu3p9hrv9471'}}",,,,
,deeplearning,,t2_3r02kqm0,False,,0,False,"Pianist AI&gt; Level 4, Try 10 &gt; Getting better day by day :)!",[],r/deeplearning,False,6,,0,,False,t3_nvvjd1,False,dark,0.56,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/POVyCBcPj2s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Level 4: Try 10', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/POVyCBcPj2s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '[ The Pianist AI ]', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/POVyCBcPj2s/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ThePianistAI'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/POVyCBcPj2s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nvvjd1', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1623272896.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/POVyCBcPj2s,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvvjd1,True,,amin_mlm,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nvvjd1/pianist_ai_level_4_try_10_getting_better_day_by/,all_ads,False,https://youtu.be/POVyCBcPj2s,66146,1623244096.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Level 4: Try 10', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/POVyCBcPj2s?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': '[ The Pianist AI ]', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/POVyCBcPj2s/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ThePianistAI'}}",False,,,,,,,
,deeplearning,"Hi, I'm trying to construct a model that takes in the first two/three input values from the user and based on those values, decides the best 4th independent variable to ask the user to optimize the time needed to bucket the user into one of the 5-6 different buckets (supervised clusters). The initial approaches that I was considering were bidirectional LSTM/RNN's.. but after reading up on these two, I'm now thinking there may be more suitable/clever approaches to tackles this. Thank you, deep learning gods of Reddit xx",t2_4okx2lwr,False,,0,False,Dynamic model that predicts the best next input variable to ask based on the first two/three inputs,[],r/deeplearning,False,6,,0,,False,t3_nvza2w,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623283154.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi, I&amp;#39;m trying to construct a model that takes in the first two/three input values from the user and based on those values, decides the best 4th independent variable to ask the user to optimize the time needed to bucket the user into one of the 5-6 different buckets (supervised clusters). The initial approaches that I was considering were bidirectional LSTM/RNN&amp;#39;s.. but after reading up on these two, I&amp;#39;m now thinking there may be more suitable/clever approaches to tackles this. Thank you, deep learning gods of Reddit xx&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvza2w,True,,lalopark,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvza2w/dynamic_model_that_predicts_the_best_next_input/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvza2w/dynamic_model_that_predicts_the_best_next_input/,66146,1623254354.0,0,,False,,,,,,,
,deeplearning,"I came across Thinc library because I am a spacy user.

&amp;#x200B;

I am very confused about how Thinc implement the back-propagation. Did someone get into that?",t2_a1citpn9,False,,0,False,Thinc library for deep learning.,[],r/deeplearning,False,6,,0,,False,t3_nvuxf0,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623271107.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I came across Thinc library because I am a spacy user.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I am very confused about how Thinc implement the back-propagation. Did someone get into that?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvuxf0,True,,MMOigres,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nvuxf0/thinc_library_for_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvuxf0/thinc_library_for_deep_learning/,66146,1623242307.0,0,,False,,,,,,,
,deeplearning,"I have a custom dataset with annotations in .json format. HI was watching various tutorials for custom tfod, and all were using .XML files as annotations. Is there anyway to use .json fornat as it is? 
P.S I'm a newbie in this field .",t2_7oqb9etn,False,,0,False,Custom TFOD,[],r/deeplearning,False,6,,0,,False,t3_nvs5ki,False,dark,1.0,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623261846.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have a custom dataset with annotations in .json format. HI was watching various tutorials for custom tfod, and all were using .XML files as annotations. Is there anyway to use .json fornat as it is? 
P.S I&amp;#39;m a newbie in this field .&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvs5ki,True,,Lonely_Soul97,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvs5ki/custom_tfod/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvs5ki/custom_tfod/,66146,1623233046.0,0,,False,,,,,,,
,deeplearning,"In the field of AI, the adaptability of imaginary numbers is sometimes overlooked. When contrasted to their real-valued equivalents, the added domain information contained in these numbers can enable substantially richer representations.
I'm here to announce the release of the first of two reports featured on Weights and Biases, which delves deep into the math underpinning complex variable optimization and includes a regressive example in Tensorflow to demonstrate its utility. You can find it here: 

https://wandb.ai/darshandeshpande/complex-optimization/reports/The-Reality-Behind-the-Optimization-of-Imaginary-Variables--Vmlldzo2OTk3MDM

The goal of this series is to encourage ML researchers and practitioners to indulge in complex numbers and representations in their research. Any feedback or suggestions are most welcome :)",t2_5yyol1fn,False,,0,False,A Mathematical Guide to Complex Variable Optimization,[],r/deeplearning,False,6,,0,,False,t3_nvmhfl,False,dark,0.67,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623239257.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;In the field of AI, the adaptability of imaginary numbers is sometimes overlooked. When contrasted to their real-valued equivalents, the added domain information contained in these numbers can enable substantially richer representations.
I&amp;#39;m here to announce the release of the first of two reports featured on Weights and Biases, which delves deep into the math underpinning complex variable optimization and includes a regressive example in Tensorflow to demonstrate its utility. You can find it here: &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://wandb.ai/darshandeshpande/complex-optimization/reports/The-Reality-Behind-the-Optimization-of-Imaginary-Variables--Vmlldzo2OTk3MDM""&gt;https://wandb.ai/darshandeshpande/complex-optimization/reports/The-Reality-Behind-the-Optimization-of-Imaginary-Variables--Vmlldzo2OTk3MDM&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The goal of this series is to encourage ML researchers and practitioners to indulge in complex numbers and representations in their research. Any feedback or suggestions are most welcome :)&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvmhfl,True,,Megixist,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvmhfl/a_mathematical_guide_to_complex_variable/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvmhfl/a_mathematical_guide_to_complex_variable/,66146,1623210457.0,0,,False,,,,,,,
,deeplearning,,t2_1568ks,False,,0,False,DeepMind scientists: Reinforcement learning is enough for general AI,[],r/deeplearning,False,6,,0,,False,t3_nv1kbv,False,dark,0.78,,public,17,0,{},,False,[],,False,False,,{},,False,17,,False,False,,False,,[],{},,False,,1623179485.0,text,6,,,text,bdtechtalks.com,False,,,,,https://bdtechtalks.com/2021/06/07/deepmind-artificial-intelligence-reward-maximization/,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv1kbv,True,,bendee983,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nv1kbv/deepmind_scientists_reinforcement_learning_is/,all_ads,False,https://bdtechtalks.com/2021/06/07/deepmind-artificial-intelligence-reward-maximization/,66146,1623150685.0,0,,False,,,,,,,
,deeplearning,,t2_ebf9d,False,,0,False,"A model that detects filler words and shouts them back at you would be quite useful, be wary of false positives with like/so/etc.",[],r/deeplearning,False,6,,0,,False,t3_nvg372,False,dark,0.75,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6bvPECCshIo?start=57&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Community S1 E10 Public Speaking', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6bvPECCshIo?start=57&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'SmokeAndMirrorsBaby', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6bvPECCshIo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/SmokeAndMirrorsBaby'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6bvPECCshIo?start=57&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nvg372', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1623219140.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/6bvPECCshIo?t=57,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvg372,True,,JoelMahon,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvg372/a_model_that_detects_filler_words_and_shouts_them/,all_ads,False,https://youtu.be/6bvPECCshIo?t=57,66146,1623190340.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Community S1 E10 Public Speaking', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/6bvPECCshIo?start=57&amp;feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'SmokeAndMirrorsBaby', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6bvPECCshIo/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/user/SmokeAndMirrorsBaby'}}",False,,,,,,,
,deeplearning,,t2_11pdrgca,False,,0,False,Character animation layering using AI is here! [https://youtu.be/SkJNxLYNwN0],[],r/deeplearning,False,6,,0,,False,t3_nurkp4,False,dark,0.98,,public,73,0,{},,False,[],"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/z6jxfr71px371/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/z6jxfr71px371/DASH_96.mp4', 'dash_url': 'https://v.redd.it/z6jxfr71px371/DASHPlaylist.mpd?a=1626450774%2CNTRmN2M2ODQ2NGUzNjFkMmE0YWRkMGFhMWRlZWJmNzBiOTVjOGEzMDhjNWI1ZTk1YTI3ODNkMDY4NjQ1MWYzZQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 30, 'hls_url': 'https://v.redd.it/z6jxfr71px371/HLSPlaylist.m3u8?a=1626450774%2CMmQ1OTMyOWJkOWUyNjZmOWU4ZDBlYjQxZWRjNmViMTc4NTJlNzQwNjhmYWJhNzQyZDllOGQ0ZmQ0ZmEwYjY2YQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,False,,{},,False,73,,False,False,,False,,[],{},,False,,1623139951.0,text,6,,,text,v.redd.it,False,,,,,https://v.redd.it/z6jxfr71px371,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nurkp4,True,,-BlackSquirrel-,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nurkp4/character_animation_layering_using_ai_is_here/,all_ads,False,https://v.redd.it/z6jxfr71px371,66146,1623111151.0,0,"{'reddit_video': {'bitrate_kbps': 4800, 'fallback_url': 'https://v.redd.it/z6jxfr71px371/DASH_1080.mp4?source=fallback', 'height': 1080, 'width': 1920, 'scrubber_media_url': 'https://v.redd.it/z6jxfr71px371/DASH_96.mp4', 'dash_url': 'https://v.redd.it/z6jxfr71px371/DASHPlaylist.mpd?a=1626450774%2CNTRmN2M2ODQ2NGUzNjFkMmE0YWRkMGFhMWRlZWJmNzBiOTVjOGEzMDhjNWI1ZTk1YTI3ODNkMDY4NjQ1MWYzZQ%3D%3D&amp;v=1&amp;f=sd', 'duration': 30, 'hls_url': 'https://v.redd.it/z6jxfr71px371/HLSPlaylist.m3u8?a=1626450774%2CMmQ1OTMyOWJkOWUyNjZmOWU4ZDBlYjQxZWRjNmViMTc4NTJlNzQwNjhmYWJhNzQyZDllOGQ0ZmQ0ZmEwYjY2YQ%3D%3D&amp;v=1&amp;f=sd', 'is_gif': False, 'transcoding_status': 'completed'}}",True,,,,,,,
,deeplearning,"Wouldn't it be amazing if you could simply type a text prompt describing the image in as much or as little detail as you want and a bunch of images fitting the description was generated on the fly? Well, thanks to the good folks at OpenAI it is possible! Introducing their DALL-E model that uses a discrete visual codebook obtained by training a discrete VAE, and a transformer to model the joint probability of text prompts and their corresponding images. And if that was not cool enough, they also make it possible to use an input image alongside a special text prompt as an additional condition to perform zero-shot image-to-image translation.

To learn how the authors managed to create an effective discrete visual codebook for text-to-image tasks, and how they cleverly applied an autoregressive transformer to generate high-resolution images from a combination of text and image tokens check out [the full explanation post](https://t.me/casual_gan/48)!

Meanwhile, check out some really awesome samples from the paper:

[DALL-E samples](https://preview.redd.it/dh0e2nbp34471.png?width=1280&amp;format=png&amp;auto=webp&amp;s=9d1d32fe1a81ee339d0bdbc4a26617087ed3395d)

\[[Full Explanation Post](https://t.me/casual_gan/48)\] \[[Arxiv](https://arxiv.org/abs/2102.12092)\] \[[Project page](https://github.com/openai/DALL-E)\]

More recent popular computer vision paper explanations:

&gt;\[[CoModGAN](https://t.me/casual_gan/43)\]\[[VQGAN](https://t.me/casual_gan/46)\]\[[DINO](https://t.me/casual_gan/40)\]",t2_hhio3,False,,0,False,Paper explаined - DALL-E: Zero-Shot Text-to-Image Generation,[],r/deeplearning,False,6,,0,,False,t3_nvfena,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623217463.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Wouldn&amp;#39;t it be amazing if you could simply type a text prompt describing the image in as much or as little detail as you want and a bunch of images fitting the description was generated on the fly? Well, thanks to the good folks at OpenAI it is possible! Introducing their DALL-E model that uses a discrete visual codebook obtained by training a discrete VAE, and a transformer to model the joint probability of text prompts and their corresponding images. And if that was not cool enough, they also make it possible to use an input image alongside a special text prompt as an additional condition to perform zero-shot image-to-image translation.&lt;/p&gt;

&lt;p&gt;To learn how the authors managed to create an effective discrete visual codebook for text-to-image tasks, and how they cleverly applied an autoregressive transformer to generate high-resolution images from a combination of text and image tokens check out &lt;a href=""https://t.me/casual_gan/48""&gt;the full explanation post&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;Meanwhile, check out some really awesome samples from the paper:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/dh0e2nbp34471.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9d1d32fe1a81ee339d0bdbc4a26617087ed3395d""&gt;DALL-E samples&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/48""&gt;Full Explanation Post&lt;/a&gt;] [&lt;a href=""https://arxiv.org/abs/2102.12092""&gt;Arxiv&lt;/a&gt;] [&lt;a href=""https://github.com/openai/DALL-E""&gt;Project page&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;More recent popular computer vision paper explanations:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;[&lt;a href=""https://t.me/casual_gan/43""&gt;CoModGAN&lt;/a&gt;][&lt;a href=""https://t.me/casual_gan/46""&gt;VQGAN&lt;/a&gt;][&lt;a href=""https://t.me/casual_gan/40""&gt;DINO&lt;/a&gt;]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvfena,True,,KirillTheMunchKing,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvfena/paper_explаined_dalle_zeroshot_texttoimage/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nvfena/paper_explаined_dalle_zeroshot_texttoimage/,66146,1623188663.0,0,,False,,,"{'dh0e2nbp34471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 81, 'x': 108, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=cc75eb55a32072273025d8e1b9974efa29eff591'}, {'y': 163, 'x': 216, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7cbf2f53f5fcfe0953b4b0339b6da8d416d53acb'}, {'y': 241, 'x': 320, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=abdb78b624eff549a8729e22aa7ab82df848f021'}, {'y': 483, 'x': 640, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=57a365d57e133f104f4d5f01d5f83b110455b569'}, {'y': 724, 'x': 960, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=19e08fd8162a0f897c7c0d2410ec8014aa53f3d2'}, {'y': 815, 'x': 1080, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f11ce3ddf29a95d0d0dc48e052736333af2cc8de'}], 's': {'y': 966, 'x': 1280, 'u': 'https://preview.redd.it/dh0e2nbp34471.png?width=1280&amp;format=png&amp;auto=webp&amp;s=9d1d32fe1a81ee339d0bdbc4a26617087ed3395d'}, 'id': 'dh0e2nbp34471'}}",,,,
,deeplearning,,t2_87yl1fq2,False,,0,False,Some Maths Resources to Help You in Your ML Journey,[],r/deeplearning,False,6,,0,,False,t3_nvfe26,False,dark,0.33,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623217417.0,text,6,,,text,self.learnmachinelearning,False,,,,,/r/learnmachinelearning/comments/nun6qb/some_maths_resources_to_help_you_in_your_ml/,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvfe26,True,,axetobe_ML,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvfe26/some_maths_resources_to_help_you_in_your_ml/,all_ads,False,/r/learnmachinelearning/comments/nun6qb/some_maths_resources_to_help_you_in_your_ml/,66146,1623188617.0,0,,False,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': 'I have been looking for content to improve my maths skills for ML. I have also noticed when scrolling a few threads many people did not find content that explains maths in an intuitive manner. Leading to a lack of belief in learning ML. But this does not have to be.\n\nI’m with you, odd-looking characters and Greek letters don’t look welcoming. But they are some good teachers online that can demystify that experience.\n\nSome of those materials are below:\n\n3blue1brown [Calculus](https://youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr) and [Linear Algebra](https://youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) series\n\nI remember watching both of these series a while. And I will be watching them again. The narrator explores the topic without getting bogged down in the details. Feels like your discovering the maths with the original people who made calculus. In the linear algebra series, he does such a great job visualising vector space. You can see the various operations done to vectors and matrices in picture form.\n\n[3blue1brown Deep Learning series](https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n\nTaking the concepts from the previous series and applying them to deep learning.\n\n[Khan Academy](https://khanacademy.org/)\n\nI’m sure you know about Sal Kahn by now. As you watched a couple of his videos. His video intuitively explains various topics. Also, show you the various hand by hand actions you need to take to do various calculations. Like matrix multiplication and calculating derivatives.\n\n[Mathematics for Machine Learning book](https://mml-book.github.io/)\n\nI tend to use this book as a reference guide if it’s a concept I want to check out. This book goes through the most important subjects relevant to machine learning and goes in-depth.\n\n[Mathematics for Machine Learning - Multivariate Calculus – Imperial College London](https://www.youtube.com/watch?v=QpwTEsO51tU)\n\nA multi-hour series explaining how calculus is used in deep learning. The material comes at the subject with a high-level view. But goes into sufficient enough detail to help you learn a lot.\n\n[Understand Calculus in 35 Minutes - The Organic Chemistry Tutor](https://www.youtube.com/watch?v=WsQQvHm4lSw)\n\nA general overview of the subject. So you can be familiar with the concepts for deep learning later on.\n\nNOTE: you won’t learn all of calculus in 30 minutes. But the video will help you get accustomed to the main ideas of the subject.\n\n&amp;#x200B;\n\nNow, these are resources that I have not used or have used very lightly but gotten good recommendations from various people.\n\nSo check them out:\n\n[Computational Linear Algebra](https://www.fast.ai/2017/07/17/num-lin-alg/):\n\nThis course talks about the linear algebra used in real computation. Not just Linear algebra done by hand.\n\n[Deep Learning book by Ian Goodfellow and Yoshua Bengio and Aaron Courville](https://www.deeplearningbook.org/)\n\nFrom their website:\n\n&gt;The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular.\n\nI have not thoroughly read all of the book. But I have used the notation page to understand maths symbols in various deep learning work.\n\n[An Introduction to Statistical Learning](https://www.statlearning.com/)\n\nA few people in this subreddit and the main subreddit have recommended this book. But I have never read it.\n\nInteresting book series which explains the maths used in high-performance code. Starting from the ground up.\n\n[Deep Learning for Programmers](https://aiprobook.com/numerical-linear-algebra-for-programmers/)\n\n[Numerical Linear Algebra for Programmers](https://aiprobook.com/deep-learning-for-programmers/)\n\n\\-\n\n*If you found this article interesting,* [*then check out my mailing list.*](https://www.tobiolabode.com/subscribe) *Where I write more stuff like this*', 'author_fullname': 't2_87yl1fq2', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Some Maths Resources to Help You in Your ML Journey', 'link_flair_richtext': [{'e': 'text', 't': 'Tutorial'}], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nun6qb', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.93, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 68, 'total_awards_received': 1, 'media_embed': {}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Tutorial', 'can_mod_post': False, 'score': 68, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': 1623187067.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {'gid_1': 1}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1623127747.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.learnmachinelearning', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have been looking for content to improve my maths skills for ML. I have also noticed when scrolling a few threads many people did not find content that explains maths in an intuitive manner. Leading to a lack of belief in learning ML. But this does not have to be.&lt;/p&gt;\n\n&lt;p&gt;I’m with you, odd-looking characters and Greek letters don’t look welcoming. But they are some good teachers online that can demystify that experience.&lt;/p&gt;\n\n&lt;p&gt;Some of those materials are below:&lt;/p&gt;\n\n&lt;p&gt;3blue1brown &lt;a href=""https://youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr""&gt;Calculus&lt;/a&gt; and &lt;a href=""https://youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab""&gt;Linear Algebra&lt;/a&gt; series&lt;/p&gt;\n\n&lt;p&gt;I remember watching both of these series a while. And I will be watching them again. The narrator explores the topic without getting bogged down in the details. Feels like your discovering the maths with the original people who made calculus. In the linear algebra series, he does such a great job visualising vector space. You can see the various operations done to vectors and matrices in picture form.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi""&gt;3blue1brown Deep Learning series&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Taking the concepts from the previous series and applying them to deep learning.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://khanacademy.org/""&gt;Khan Academy&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I’m sure you know about Sal Kahn by now. As you watched a couple of his videos. His video intuitively explains various topics. Also, show you the various hand by hand actions you need to take to do various calculations. Like matrix multiplication and calculating derivatives.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://mml-book.github.io/""&gt;Mathematics for Machine Learning book&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I tend to use this book as a reference guide if it’s a concept I want to check out. This book goes through the most important subjects relevant to machine learning and goes in-depth.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=QpwTEsO51tU""&gt;Mathematics for Machine Learning - Multivariate Calculus – Imperial College London&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A multi-hour series explaining how calculus is used in deep learning. The material comes at the subject with a high-level view. But goes into sufficient enough detail to help you learn a lot.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://www.youtube.com/watch?v=WsQQvHm4lSw""&gt;Understand Calculus in 35 Minutes - The Organic Chemistry Tutor&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A general overview of the subject. So you can be familiar with the concepts for deep learning later on.&lt;/p&gt;\n\n&lt;p&gt;NOTE: you won’t learn all of calculus in 30 minutes. But the video will help you get accustomed to the main ideas of the subject.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now, these are resources that I have not used or have used very lightly but gotten good recommendations from various people.&lt;/p&gt;\n\n&lt;p&gt;So check them out:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://www.fast.ai/2017/07/17/num-lin-alg/""&gt;Computational Linear Algebra&lt;/a&gt;:&lt;/p&gt;\n\n&lt;p&gt;This course talks about the linear algebra used in real computation. Not just Linear algebra done by hand.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://www.deeplearningbook.org/""&gt;Deep Learning book by Ian Goodfellow and Yoshua Bengio and Aaron Courville&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;From their website:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I have not thoroughly read all of the book. But I have used the notation page to understand maths symbols in various deep learning work.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://www.statlearning.com/""&gt;An Introduction to Statistical Learning&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A few people in this subreddit and the main subreddit have recommended this book. But I have never read it.&lt;/p&gt;\n\n&lt;p&gt;Interesting book series which explains the maths used in high-performance code. Starting from the ground up.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://aiprobook.com/numerical-linear-algebra-for-programmers/""&gt;Deep Learning for Programmers&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=""https://aiprobook.com/deep-learning-for-programmers/""&gt;Numerical Linear Algebra for Programmers&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;-&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;If you found this article interesting,&lt;/em&gt; &lt;a href=""https://www.tobiolabode.com/subscribe""&gt;&lt;em&gt;then check out my mailing list.&lt;/em&gt;&lt;/a&gt; &lt;em&gt;Where I write more stuff like this&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [{'giver_coin_reward': None, 'subreddit_id': None, 'is_new': False, 'days_of_drip_extension': 0, 'coin_price': 100, 'id': 'gid_1', 'penny_donate': None, 'award_sub_type': 'GLOBAL', 'coin_reward': 0, 'icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png', 'days_of_premium': 0, 'tiers_by_required_awardings': None, 'resized_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_width': 512, 'static_icon_width': 512, 'start_date': None, 'is_enabled': True, 'awardings_required_to_grant_benefits': None, 'description': ""Shows the Silver Award... and that's it."", 'end_date': None, 'subreddit_coin_reward': 0, 'count': 1, 'static_icon_height': 512, 'name': 'Silver', 'resized_static_icons': [{'url': 'https://www.redditstatic.com/gold/awards/icon/silver_16.png', 'width': 16, 'height': 16}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_32.png', 'width': 32, 'height': 32}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_48.png', 'width': 48, 'height': 48}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_64.png', 'width': 64, 'height': 64}, {'url': 'https://www.redditstatic.com/gold/awards/icon/silver_128.png', 'width': 128, 'height': 128}], 'icon_format': None, 'icon_height': 512, 'penny_price': None, 'award_type': 'global', 'static_icon_url': 'https://www.redditstatic.com/gold/awards/icon/silver_512.png'}], 'awarders': [], 'media_only': False, 'link_flair_template_id': '8aeee882-d289-11ea-b4f0-0ed750cbd99b', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#dadada', 'id': 'nun6qb', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'axetobe_ML', 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/nun6qb/some_maths_resources_to_help_you_in_your_ml/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/learnmachinelearning/comments/nun6qb/some_maths_resources_to_help_you_in_your_ml/', 'subreddit_subscribers': 232341, 'created_utc': 1623098947.0, 'num_crossposts': 1, 'media': None, 'is_video': False}]",t3_nun6qb,,,,,
,deeplearning,,t2_19qv49zm,False,,0,False,A Theoretical and Practical Guide to Probabilistic Graphical Models with Tensorflow,[],r/deeplearning,False,6,,0,,False,t3_nv8rxp,False,dark,0.75,,public,2,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Directed Graphical Models | Intro | Implementation in TensorFlow Probability | [english]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Machine Learning &amp; Simulation', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yBc01ZeaFxw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCh0P7KwJhuQ4vrzc3IRuw4Q'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nv8rxp', 'height': 200}",,False,2,,False,False,,False,,[],{},,False,,1623200166.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=yBc01ZeaFxw&amp;list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv8rxp,True,,OB_two,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nv8rxp/a_theoretical_and_practical_guide_to/,all_ads,False,https://www.youtube.com/watch?v=yBc01ZeaFxw&amp;list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ,66146,1623171366.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Directed Graphical Models | Intro | Implementation in TensorFlow Probability | [english]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Machine Learning &amp; Simulation', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yBc01ZeaFxw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCh0P7KwJhuQ4vrzc3IRuw4Q'}}",False,"[{'approved_at_utc': None, 'subreddit': 'learnmachinelearning', 'selftext': '', 'author_fullname': 't2_19qv49zm', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'A Theoretical and Practical Guide to Probabilistic Graphical Models with Tensorflow', 'link_flair_richtext': [{'e': 'text', 't': 'Tutorial'}], 'subreddit_name_prefixed': 'r/learnmachinelearning', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_nv8kzp', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 0.86, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 17, 'total_awards_received': 0, 'media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Directed Graphical Models | Intro | Implementation in TensorFlow Probability | [english]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Machine Learning &amp; Simulation', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yBc01ZeaFxw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCh0P7KwJhuQ4vrzc3IRuw4Q'}}, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nv8kzp', 'height': 200}, 'link_flair_text': 'Tutorial', 'can_mod_post': False, 'score': 17, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': '', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1623199656.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'youtube.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.youtube.com/watch?v=yBc01ZeaFxw&amp;list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '8aeee882-d289-11ea-b4f0-0ed750cbd99b', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_3cqa1', 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#dadada', 'id': 'nv8kzp', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'OB_two', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/learnmachinelearning/comments/nv8kzp/a_theoretical_and_practical_guide_to/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.youtube.com/watch?v=yBc01ZeaFxw&amp;list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ', 'subreddit_subscribers': 232341, 'created_utc': 1623170856.0, 'num_crossposts': 4, 'media': {'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Directed Graphical Models | Intro | Implementation in TensorFlow Probability | [english]', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yBc01ZeaFxw?list=PLISXH-iEM4JlFsAp7trKCWyxeO3M70QyJ"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Machine Learning &amp; Simulation', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yBc01ZeaFxw/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/channel/UCh0P7KwJhuQ4vrzc3IRuw4Q'}}, 'is_video': False}]",t3_nv8kzp,,,,,
,deeplearning,,t2_2crnmmt9,False,,0,False,Differentiable Self-organizing Systems,[],r/deeplearning,False,6,,0,,False,t3_nvaz4a,False,dark,1.0,,public,1,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Pn2QL_5LmJE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Differentiable Self-organizing Systems', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Pn2QL_5LmJE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Pn2QL_5LmJE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Pn2QL_5LmJE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nvaz4a', 'height': 200}",,False,1,,False,False,,False,,[],{},,False,,1623206039.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/Pn2QL_5LmJE,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nvaz4a,True,,cmillionaire9,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nvaz4a/differentiable_selforganizing_systems/,all_ads,False,https://youtu.be/Pn2QL_5LmJE,66146,1623177239.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Differentiable Self-organizing Systems', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/Pn2QL_5LmJE?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Vecanoi', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/Pn2QL_5LmJE/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/Vecanoi'}}",False,,,,,,,
,deeplearning," Is it possible to create a program that automatically finds similarities between disciplines in different fields?  For example, is it possible to have a machine learning or deep learning program that finds the laws of biology with a structure and number of variables similar to the equation of force such as f=ma in physics?",t2_68sl7hms,False,,0,False,Is it possible to write code that automatically retrieves insights by finding homogeneity between different disciplines?(This is a fairly abstract question),[],r/deeplearning,False,6,,0,,False,t3_nuyujx,False,dark,1.0,,public,6,0,{},,False,[],,False,False,,{},,False,6,,False,False,,False,,[],{},,True,,1623165271.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Is it possible to create a program that automatically finds similarities between disciplines in different fields?  For example, is it possible to have a machine learning or deep learning program that finds the laws of biology with a structure and number of variables similar to the equation of force such as f=ma in physics?&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuyujx,True,,Plus-Ad1156,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nuyujx/is_it_possible_to_write_code_that_automatically/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nuyujx/is_it_possible_to_write_code_that_automatically/,66146,1623136471.0,0,,False,,,,,,,
,deeplearning,,t2_39dnc90e,False,,0,False,Can anyone help me figure out what im doing wrong with my input? I keep getting an error. I am new to coding and D.L. This is part of a autoencoder model i got off Keras. I am using sensor data not images.,[],r/deeplearning,False,6,,0,,False,t3_nv75zc,False,dark,0.5,,public,0,0,{},,False,[],,True,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623196194.0,text,6,,,text,i.redd.it,False,,,,,https://i.redd.it/3xuo1o6na2471.png,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv75zc,True,,HVACCalculations,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nv75zc/can_anyone_help_me_figure_out_what_im_doing_wrong/,all_ads,False,https://i.redd.it/3xuo1o6na2471.png,66146,1623167394.0,0,,False,,,,,,,
,deeplearning,"\#This is the code I am using

input = layers.Input(shape=(sensor.shape\[1\]))

&amp;#x200B;

\# Encoder

x = layers.Conv2D(64, (3, 3), activation=""relu"", padding=""same"")(input)

x = layers.MaxPooling2D((2, 2), padding=""same"")(x)

x = layers.Conv2D(32, (3, 3), activation=""relu"", padding=""same"")(x)

x = layers.MaxPooling2D((2, 2), padding=""same"")(x)

&amp;#x200B;

\# Decoder

x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=""relu"", padding=""same"")(x)

x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation=""relu"", padding=""same"")(x)

x = layers.Conv2D(128, (3, 3), activation=""sigmoid"", padding=""same"")(x)

&amp;#x200B;

\# Autoencoder

autoencoder = Model(input, x)

autoencoder.compile(optimizer=""adam"", loss=""binary\_crossentropy"")

autoencoder.summary()

&amp;#x200B;

\#This is the error message

 **---------------------------------------------------------------------------** 

**ValueError**                                Traceback (most recent call last)

 **&lt;ipython-input-17-bdd3a2559477&gt;** in &lt;module&gt;       

2       

3 **# Encoder**

 **----&gt; 4** x **=** layers**.**Conv2D**(64,** **(3,** **3),** activation**=""relu"",** padding**=""same"")(**input**)**      

 5 x **=** layers**.**MaxPooling2D**((2,** **2),** padding**=""same"")(**x**)**       

6 x **=** layers**.**Conv2D**(32,** **(3,** **3),** activation**=""relu"",** padding**=""same"")(**x**)** **\~\\anaconda3\\envs\\Mytfenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base\_layer.py** in \_\_call\_\_**(self, \*args, \*\*kwargs)**    

 923 **# &gt;&gt; model = tf.keras.Model(inputs, outputs)**   

  924 **if** \_in\_functional\_construction\_mode**(**self**,** inputs**,** args**,** kwargs**,** input\_list**):**

 **--&gt; 925       return self.\_functional\_construction\_call(inputs, args, kwargs,**    

 926                                                 input\_list)    

 927 **\~\\anaconda3\\envs\\Mytfenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base\_layer.py** in \_functional\_construction\_call**(self, inputs, args, kwargs, input\_list)**    

1090 **# TODO(reedwm): We should assert input compatibility after the inputs**    

1091 **# are casted, not before.** **-&gt; 1092** input\_spec**.**assert\_input\_compatibility**(**self**.**input\_spec**,** inputs**,** self**.**name**)**    

1093       graph **=** backend**.**get\_graph**()**  

  1094 **# Use \`self.\_name\_scope()\` to avoid auto-incrementing the name.** **\~\\anaconda3\\envs\\Mytfenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input\_spec.py** in assert\_input\_compatibility**(input\_spec, inputs, layer\_name)**   

  189       ndim **=** x**.**shape**.**ndims     190 **if** ndim **is** **not** **None** **and** ndim **&lt;** spec**.**min\_ndim**:**

 **--&gt; 191         raise ValueError('Input ' + str(input\_index) + ' of layer ' +**     

192                          layer\_name **+** **' is incompatible with the layer: '**     

193 **': expected min\_ndim='** **+** str**(**spec**.**min\_ndim**)** **+** 

**ValueError**: Input 0 of layer conv2d\_3 is incompatible with the layer: : expected min\_ndim=4, found ndim=2. Full shape received: \[None, 8\]   
 ",t2_39dnc90e,False,,0,False,Can anyone help me figure out my why im getting this error? I found a autoencoder model off of keras and im trying to input some sensor data to train the model. Please let me know if you need any additional information (Sorry for the noob question),[],r/deeplearning,False,6,,0,,False,t3_nv74mw,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,1623167623.0,,[],{},,True,,1623196130.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;#This is the code I am using&lt;/p&gt;

&lt;p&gt;input = layers.Input(shape=(sensor.shape[1]))&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;# Encoder&lt;/p&gt;

&lt;p&gt;x = layers.Conv2D(64, (3, 3), activation=&amp;quot;relu&amp;quot;, padding=&amp;quot;same&amp;quot;)(input)&lt;/p&gt;

&lt;p&gt;x = layers.MaxPooling2D((2, 2), padding=&amp;quot;same&amp;quot;)(x)&lt;/p&gt;

&lt;p&gt;x = layers.Conv2D(32, (3, 3), activation=&amp;quot;relu&amp;quot;, padding=&amp;quot;same&amp;quot;)(x)&lt;/p&gt;

&lt;p&gt;x = layers.MaxPooling2D((2, 2), padding=&amp;quot;same&amp;quot;)(x)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;# Decoder&lt;/p&gt;

&lt;p&gt;x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=&amp;quot;relu&amp;quot;, padding=&amp;quot;same&amp;quot;)(x)&lt;/p&gt;

&lt;p&gt;x = layers.Conv2DTranspose(64, (3, 3), strides=2, activation=&amp;quot;relu&amp;quot;, padding=&amp;quot;same&amp;quot;)(x)&lt;/p&gt;

&lt;p&gt;x = layers.Conv2D(128, (3, 3), activation=&amp;quot;sigmoid&amp;quot;, padding=&amp;quot;same&amp;quot;)(x)&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;# Autoencoder&lt;/p&gt;

&lt;p&gt;autoencoder = Model(input, x)&lt;/p&gt;

&lt;p&gt;autoencoder.compile(optimizer=&amp;quot;adam&amp;quot;, loss=&amp;quot;binary_crossentropy&amp;quot;)&lt;/p&gt;

&lt;p&gt;autoencoder.summary()&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;#This is the error message&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;---------------------------------------------------------------------------&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ValueError&lt;/strong&gt;                                Traceback (most recent call last)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&amp;lt;ipython-input-17-bdd3a2559477&amp;gt;&lt;/strong&gt; in &amp;lt;module&amp;gt;       &lt;/p&gt;

&lt;p&gt;2       &lt;/p&gt;

&lt;p&gt;3 &lt;strong&gt;# Encoder&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;----&amp;gt; 4&lt;/strong&gt; x &lt;strong&gt;=&lt;/strong&gt; layers&lt;strong&gt;.&lt;/strong&gt;Conv2D&lt;strong&gt;(64,&lt;/strong&gt; &lt;strong&gt;(3,&lt;/strong&gt; &lt;strong&gt;3),&lt;/strong&gt; activation&lt;strong&gt;=&amp;quot;relu&amp;quot;,&lt;/strong&gt; padding&lt;strong&gt;=&amp;quot;same&amp;quot;)(&lt;/strong&gt;input&lt;strong&gt;)&lt;/strong&gt;      &lt;/p&gt;

&lt;p&gt;5 x &lt;strong&gt;=&lt;/strong&gt; layers&lt;strong&gt;.&lt;/strong&gt;MaxPooling2D&lt;strong&gt;((2,&lt;/strong&gt; &lt;strong&gt;2),&lt;/strong&gt; padding&lt;strong&gt;=&amp;quot;same&amp;quot;)(&lt;/strong&gt;x&lt;strong&gt;)&lt;/strong&gt;       &lt;/p&gt;

&lt;p&gt;6 x &lt;strong&gt;=&lt;/strong&gt; layers&lt;strong&gt;.&lt;/strong&gt;Conv2D&lt;strong&gt;(32,&lt;/strong&gt; &lt;strong&gt;(3,&lt;/strong&gt; &lt;strong&gt;3),&lt;/strong&gt; activation&lt;strong&gt;=&amp;quot;relu&amp;quot;,&lt;/strong&gt; padding&lt;strong&gt;=&amp;quot;same&amp;quot;)(&lt;/strong&gt;x&lt;strong&gt;)&lt;/strong&gt; &lt;strong&gt;~\anaconda3\envs\Mytfenv\lib\site-packages\tensorflow\python\keras\engine\base_layer.py&lt;/strong&gt; in __call__&lt;strong&gt;(self, *args, **kwargs)&lt;/strong&gt;    &lt;/p&gt;

&lt;p&gt;923 &lt;strong&gt;# &amp;gt;&amp;gt; model = tf.keras.Model(inputs, outputs)&lt;/strong&gt;   &lt;/p&gt;

&lt;p&gt;924 &lt;strong&gt;if&lt;/strong&gt; _in_functional_construction_mode&lt;strong&gt;(&lt;/strong&gt;self&lt;strong&gt;,&lt;/strong&gt; inputs&lt;strong&gt;,&lt;/strong&gt; args&lt;strong&gt;,&lt;/strong&gt; kwargs&lt;strong&gt;,&lt;/strong&gt; input_list&lt;strong&gt;):&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;--&amp;gt; 925       return self._functional_construction_call(inputs, args, kwargs,&lt;/strong&gt;    &lt;/p&gt;

&lt;p&gt;926                                                 input_list)    &lt;/p&gt;

&lt;p&gt;927 &lt;strong&gt;~\anaconda3\envs\Mytfenv\lib\site-packages\tensorflow\python\keras\engine\base_layer.py&lt;/strong&gt; in _functional_construction_call&lt;strong&gt;(self, inputs, args, kwargs, input_list)&lt;/strong&gt;    &lt;/p&gt;

&lt;p&gt;1090 &lt;strong&gt;# TODO(reedwm): We should assert input compatibility after the inputs&lt;/strong&gt;    &lt;/p&gt;

&lt;p&gt;1091 &lt;strong&gt;# are casted, not before.&lt;/strong&gt; &lt;strong&gt;-&amp;gt; 1092&lt;/strong&gt; input_spec&lt;strong&gt;.&lt;/strong&gt;assert_input_compatibility&lt;strong&gt;(&lt;/strong&gt;self&lt;strong&gt;.&lt;/strong&gt;input_spec&lt;strong&gt;,&lt;/strong&gt; inputs&lt;strong&gt;,&lt;/strong&gt; self&lt;strong&gt;.&lt;/strong&gt;name&lt;strong&gt;)&lt;/strong&gt;    &lt;/p&gt;

&lt;p&gt;1093       graph &lt;strong&gt;=&lt;/strong&gt; backend&lt;strong&gt;.&lt;/strong&gt;get_graph&lt;strong&gt;()&lt;/strong&gt;  &lt;/p&gt;

&lt;p&gt;1094 &lt;strong&gt;# Use `self._name_scope()` to avoid auto-incrementing the name.&lt;/strong&gt; &lt;strong&gt;~\anaconda3\envs\Mytfenv\lib\site-packages\tensorflow\python\keras\engine\input_spec.py&lt;/strong&gt; in assert_input_compatibility&lt;strong&gt;(input_spec, inputs, layer_name)&lt;/strong&gt;   &lt;/p&gt;

&lt;p&gt;189       ndim &lt;strong&gt;=&lt;/strong&gt; x&lt;strong&gt;.&lt;/strong&gt;shape&lt;strong&gt;.&lt;/strong&gt;ndims     190 &lt;strong&gt;if&lt;/strong&gt; ndim &lt;strong&gt;is&lt;/strong&gt; &lt;strong&gt;not&lt;/strong&gt; &lt;strong&gt;None&lt;/strong&gt; &lt;strong&gt;and&lt;/strong&gt; ndim &lt;strong&gt;&amp;lt;&lt;/strong&gt; spec&lt;strong&gt;.&lt;/strong&gt;min_ndim&lt;strong&gt;:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;--&amp;gt; 191         raise ValueError(&amp;#39;Input &amp;#39; + str(input_index) + &amp;#39; of layer &amp;#39; +&lt;/strong&gt;     &lt;/p&gt;

&lt;p&gt;192                          layer_name &lt;strong&gt;+&lt;/strong&gt; &lt;strong&gt;&amp;#39; is incompatible with the layer: &amp;#39;&lt;/strong&gt;     &lt;/p&gt;

&lt;p&gt;193 &lt;strong&gt;&amp;#39;: expected min_ndim=&amp;#39;&lt;/strong&gt; &lt;strong&gt;+&lt;/strong&gt; str&lt;strong&gt;(&lt;/strong&gt;spec&lt;strong&gt;.&lt;/strong&gt;min_ndim&lt;strong&gt;)&lt;/strong&gt; &lt;strong&gt;+&lt;/strong&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ValueError&lt;/strong&gt;: Input 0 of layer conv2d_3 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [None, 8]   &lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv74mw,True,,HVACCalculations,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nv74mw/can_anyone_help_me_figure_out_my_why_im_getting/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nv74mw/can_anyone_help_me_figure_out_my_why_im_getting/,66146,1623167330.0,0,,False,,,"{'xs3cu31kc2471': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 93, 'x': 108, 'u': 'https://preview.redd.it/xs3cu31kc2471.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fe5f4155e2816d1fc70da835b811edc36feb607d'}, {'y': 186, 'x': 216, 'u': 'https://preview.redd.it/xs3cu31kc2471.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cfc7efbc0cdf7ad2f1d2ddee23aadf12190ecf6e'}, {'y': 276, 'x': 320, 'u': 'https://preview.redd.it/xs3cu31kc2471.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=b111a4eae079a20cd0aa76badcc82c686c1ae651'}, {'y': 553, 'x': 640, 'u': 'https://preview.redd.it/xs3cu31kc2471.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8a4c63759774e485fd7a2b50a5e10141389e52e6'}], 's': {'y': 786, 'x': 909, 'u': 'https://preview.redd.it/xs3cu31kc2471.png?width=909&amp;format=png&amp;auto=webp&amp;s=208e54940a1e5efa2052fb0f38e036dfaca3f0f2'}, 'id': 'xs3cu31kc2471'}}",,,,
,deeplearning,"A research team from Google Brain conducts a comprehensive empirical study on more than fifty choices in a generic adversarial imitation learning framework and explores their impacts on large-scale (&gt;500k trained agents) continuous-control tasks to provide practical insights and recommendations for designing novel and effective AIL algorithms.

Here is a quick read: [What Matters in Adversarial Imitation Learning? Google Brain Study Reveals Valuable Insights.](https://syncedreview.com/2021/06/08/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-36/)

The paper *What Matters for Adversarial Imitation Learning?* is on [arXiv](https://arxiv.org/abs/2106.00672).",t2_2fv4yodo,False,,0,False,[R] What Matters in Adversarial Imitation Learning? Google Brain Study Reveals Valuable Insights,[],r/deeplearning,False,6,,0,,False,t3_nv5lqm,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623192085.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Google Brain conducts a comprehensive empirical study on more than fifty choices in a generic adversarial imitation learning framework and explores their impacts on large-scale (&amp;gt;500k trained agents) continuous-control tasks to provide practical insights and recommendations for designing novel and effective AIL algorithms.&lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/08/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-36/""&gt;What Matters in Adversarial Imitation Learning? Google Brain Study Reveals Valuable Insights.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;What Matters for Adversarial Imitation Learning?&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2106.00672""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv5lqm,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nv5lqm/r_what_matters_in_adversarial_imitation_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nv5lqm/r_what_matters_in_adversarial_imitation_learning/,66146,1623163285.0,0,,False,,,,,,,
,deeplearning,"Hey Guys! I recently am inspired by the paper mixup on network classification, and decided to write a PyTorch implementation of the mixup on image classification. Feel free to check it out:

[https://taying-cheng.medium.com/enhancing-neural-networks-with-mixup-in-pytorch-5129d261bc4a](https://taying-cheng.medium.com/enhancing-neural-networks-with-mixup-in-pytorch-5129d261bc4a)",t2_jn2eq6v,False,,0,False,Mixup - Enhancing Image Classification Results of Networks in PyTorch,[],r/deeplearning,False,6,,0,,False,t3_nuzkzj,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623168301.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hey Guys! I recently am inspired by the paper mixup on network classification, and decided to write a PyTorch implementation of the mixup on image classification. Feel free to check it out:&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://taying-cheng.medium.com/enhancing-neural-networks-with-mixup-in-pytorch-5129d261bc4a""&gt;https://taying-cheng.medium.com/enhancing-neural-networks-with-mixup-in-pytorch-5129d261bc4a&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuzkzj,True,,tt12343,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nuzkzj/mixup_enhancing_image_classification_results_of/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nuzkzj/mixup_enhancing_image_classification_results_of/,66146,1623139501.0,0,,False,,,,,,,
,deeplearning,,t2_r68sd3,False,,0,False,Data Structures in Python,[],r/deeplearning,False,6,,0,,False,t3_nv3co8,False,dark,0.4,,public,0,0,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/6TJERSlqQIk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Data Structures in Python #5', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/6TJERSlqQIk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Amine M. Boulouma', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6TJERSlqQIk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/AmineMBoulouma'}}",False,False,,"{'content': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/6TJERSlqQIk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 267, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nv3co8', 'height': 200}",,False,0,,False,False,,False,,[],{},,False,,1623185599.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/6TJERSlqQIk,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nv3co8,True,,flambok,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nv3co8/data_structures_in_python/,all_ads,False,https://youtu.be/6TJERSlqQIk,66146,1623156799.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Data Structures in Python #5', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 267, 'html': '&lt;iframe width=""267"" height=""200"" src=""https://www.youtube.com/embed/6TJERSlqQIk?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Amine M. Boulouma', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/6TJERSlqQIk/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/AmineMBoulouma'}}",False,,,,,,,
,deeplearning,,t2_c74s9tl6,False,,0,False,How Convolutional Neural Networks Work (CNNs Explained &amp; Visualized),[],r/deeplearning,False,6,,0,,False,t3_nuhkfv,False,dark,0.73,,public,12,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pj9-rr1wDhM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How Convolutional Neural Networks Work (CNNs Explained &amp; Visualized)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pj9-rr1wDhM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Futurology — An Optimistic Future', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/pj9-rr1wDhM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/FuturologyTV'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pj9-rr1wDhM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nuhkfv', 'height': 200}",,False,12,,False,False,,False,,[],{},,False,,1623114071.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=pj9-rr1wDhM,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuhkfv,True,,SpaghettiFagetti,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nuhkfv/how_convolutional_neural_networks_work_cnns/,all_ads,False,https://www.youtube.com/watch?v=pj9-rr1wDhM,66146,1623085271.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'How Convolutional Neural Networks Work (CNNs Explained &amp; Visualized)', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/pj9-rr1wDhM?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Futurology — An Optimistic Future', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/pj9-rr1wDhM/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/FuturologyTV'}}",False,,,,,,,
,deeplearning,,t2_5ovlhke5,False,,0,False,When Vision Transformers Outperform ResNets without Pretraining! (Paper Explained),[],r/deeplearning,False,6,,0,,False,t3_nu92k1,False,dark,0.95,,public,40,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oDtcobGQ7xU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'When Vision Transformers Outperform ResNets without Pretraining | Paper Explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oDtcobGQ7xU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/oDtcobGQ7xU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oDtcobGQ7xU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nu92k1', 'height': 200}",,False,40,,False,False,,False,,[],{},,False,,1623090382.0,text,6,,,text,youtu.be,False,,,,,https://youtu.be/oDtcobGQ7xU,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nu92k1,True,,gordicaleksa,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nu92k1/when_vision_transformers_outperform_resnets/,all_ads,False,https://youtu.be/oDtcobGQ7xU,66146,1623061582.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'When Vision Transformers Outperform ResNets without Pretraining | Paper Explained', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/oDtcobGQ7xU?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'The AI Epiphany', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/oDtcobGQ7xU/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/TheAIEpiphany'}}",False,,,,,,,
,deeplearning,"Are there any issues that come about with this? How does one test the network properly? I have a few separate programs that function semi-properly but my advisor has some doubts, as do I, so I'd like some assistance if possible. I simply want to train the network to give me an output value that is an estimate of the function of the input values. One input node, one output node, and as many or as few hidden layers/nodes as is necessary. So, if I input .4, the output the neural network should give me should be pretty close to .8. 

For the program Ill focus on, my network seems to get a very acceptably low MSE (1e-4 or 1e-5) when I train it, but there are a few caveats:

1) The network has 250 inputs. It takes the whole input as one batch and then backpropagates it all, and then updates the weights accordingly. It then uses the same input values again during the next iteration. I can change it to 2500 and 25000 inputs as well, and it still seems to train properly. Should I not train over the same inputs over and over again? My other program isn't like this, but I think this one works better. Im training over a fairly large set of input values.

2) My input data is between the range of .1 and 1. These are the values of the 250 inputs I mentioned in the above point. Is this bad? Is it good? What should my input ""range"" be? Are there any range of values that there are examples of that ""wouldn't be good"" in this case?

3) This point is just a series of related questions. How should I test my neural network? Should I just send random values through the network once it is finished and see if it outputs what I need it to, or is that not good? Does my input data being between .1 and 1 mean that I can't really input values too much larger than 1, or too much less than .1? Should my input data be *completely* random and be *any* real valued number? Or should there be bounds?

Thanks!",t2_i5dbu,False,,0,False,Deep Learning Regression Neural Network utilizing MATLAB (without using the toolbox),[],r/deeplearning,False,6,,0,,False,t3_nuul19,False,dark,0.6,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,1623125204.0,,[],{},,True,,1623149544.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Are there any issues that come about with this? How does one test the network properly? I have a few separate programs that function semi-properly but my advisor has some doubts, as do I, so I&amp;#39;d like some assistance if possible. I simply want to train the network to give me an output value that is an estimate of the function of the input values. One input node, one output node, and as many or as few hidden layers/nodes as is necessary. So, if I input .4, the output the neural network should give me should be pretty close to .8. &lt;/p&gt;

&lt;p&gt;For the program Ill focus on, my network seems to get a very acceptably low MSE (1e-4 or 1e-5) when I train it, but there are a few caveats:&lt;/p&gt;

&lt;p&gt;1) The network has 250 inputs. It takes the whole input as one batch and then backpropagates it all, and then updates the weights accordingly. It then uses the same input values again during the next iteration. I can change it to 2500 and 25000 inputs as well, and it still seems to train properly. Should I not train over the same inputs over and over again? My other program isn&amp;#39;t like this, but I think this one works better. Im training over a fairly large set of input values.&lt;/p&gt;

&lt;p&gt;2) My input data is between the range of .1 and 1. These are the values of the 250 inputs I mentioned in the above point. Is this bad? Is it good? What should my input &amp;quot;range&amp;quot; be? Are there any range of values that there are examples of that &amp;quot;wouldn&amp;#39;t be good&amp;quot; in this case?&lt;/p&gt;

&lt;p&gt;3) This point is just a series of related questions. How should I test my neural network? Should I just send random values through the network once it is finished and see if it outputs what I need it to, or is that not good? Does my input data being between .1 and 1 mean that I can&amp;#39;t really input values too much larger than 1, or too much less than .1? Should my input data be &lt;em&gt;completely&lt;/em&gt; random and be &lt;em&gt;any&lt;/em&gt; real valued number? Or should there be bounds?&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuul19,True,,Kanep96,,9,True,all_ads,False,[],False,,/r/deeplearning/comments/nuul19/deep_learning_regression_neural_network_utilizing/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nuul19/deep_learning_regression_neural_network_utilizing/,66146,1623120744.0,0,,False,,,,,,,
,deeplearning," The performance of deep neural networks (DNNs) relies heavily on their structures, and designing a good structure (aka architecture) tends to require extensive effort from human experts. The idea of an automatic structure-learning algorithm that can achieve performance on par with the best human-designed structures is thus increasingly appealing to machine learning researchers. 

[https://medium.com/syncedreview/microsoft-oneflow-leverage-the-efficient-coding-principle-to-design-unsupervised-dnn-9d2d258bdc3c](https://medium.com/syncedreview/microsoft-oneflow-leverage-the-efficient-coding-principle-to-design-unsupervised-dnn-9d2d258bdc3c)

&amp;#x200B;

https://preview.redd.it/2jqq3p4h5y371.png?width=790&amp;format=png&amp;auto=webp&amp;s=b78f0a397b65d7f473cf1dcc79153624468f8004",t2_c3oqcv1s,False,,0,False,Microsoft &amp; OneFlow Leverage the Efficient Coding Principle to Design Unsupervised DNN Structure-Learning That Outperforms Human-Designed Structures,[],r/deeplearning,False,6,,0,,False,t3_nutayl,False,dark,0.66,,public,1,0,{},,False,[],,False,False,,{},,False,1,,False,False,,False,,[],{},,True,,1623145411.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;The performance of deep neural networks (DNNs) relies heavily on their structures, and designing a good structure (aka architecture) tends to require extensive effort from human experts. The idea of an automatic structure-learning algorithm that can achieve performance on par with the best human-designed structures is thus increasingly appealing to machine learning researchers. &lt;/p&gt;

&lt;p&gt;&lt;a href=""https://medium.com/syncedreview/microsoft-oneflow-leverage-the-efficient-coding-principle-to-design-unsupervised-dnn-9d2d258bdc3c""&gt;https://medium.com/syncedreview/microsoft-oneflow-leverage-the-efficient-coding-principle-to-design-unsupervised-dnn-9d2d258bdc3c&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://preview.redd.it/2jqq3p4h5y371.png?width=790&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b78f0a397b65d7f473cf1dcc79153624468f8004""&gt;https://preview.redd.it/2jqq3p4h5y371.png?width=790&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b78f0a397b65d7f473cf1dcc79153624468f8004&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nutayl,True,,xuchanghua,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nutayl/microsoft_oneflow_leverage_the_efficient_coding/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nutayl/microsoft_oneflow_leverage_the_efficient_coding/,66146,1623116611.0,0,,False,,,"{'2jqq3p4h5y371': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 43, 'x': 108, 'u': 'https://preview.redd.it/2jqq3p4h5y371.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ee299299aa1d047c1a20e5e3c7e82fc6f1965ff9'}, {'y': 87, 'x': 216, 'u': 'https://preview.redd.it/2jqq3p4h5y371.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0a1a42a275b2c19aba4b1b8626693a9b784320b3'}, {'y': 129, 'x': 320, 'u': 'https://preview.redd.it/2jqq3p4h5y371.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=04d0a70bebaad34e0bb2c372709a493cb27cf843'}, {'y': 259, 'x': 640, 'u': 'https://preview.redd.it/2jqq3p4h5y371.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce6d24cf4ffb0ad4ce74c0efc541395126461abb'}], 's': {'y': 320, 'x': 790, 'u': 'https://preview.redd.it/2jqq3p4h5y371.png?width=790&amp;format=png&amp;auto=webp&amp;s=b78f0a397b65d7f473cf1dcc79153624468f8004'}, 'id': '2jqq3p4h5y371'}}",,,,
,deeplearning,"Hi all, I've been waiting since the beginning of this year for the availability of the RTX 3090 for building my research workstation and now I've just given up and I am currently looking for something else.  


I've found some refurbished ""HP Z840 Workstation"" with a Nvidia Quadro P6000 (or M6000) with 24gb. I plan to put another one to have 48gb. I need mostly Memory (Contrastive Learning needs bigger batch sizes) instead of speed - so they kind of look to fit well. However, I have not found any official benchmark and some very old forum like [this](https://www.kaggle.com/general/11332) speak badly about Quadros.   


So, what do you guys think? Any experience with Quadros for DL out there? Thx !!",t2_q9paa,False,,0,False,Quadro M6000 for Deep Learning?,[],r/deeplearning,False,6,,0,,False,t3_nugkzi,False,dark,0.72,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1623111664.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi all, I&amp;#39;ve been waiting since the beginning of this year for the availability of the RTX 3090 for building my research workstation and now I&amp;#39;ve just given up and I am currently looking for something else.  &lt;/p&gt;

&lt;p&gt;I&amp;#39;ve found some refurbished &amp;quot;HP Z840 Workstation&amp;quot; with a Nvidia Quadro P6000 (or M6000) with 24gb. I plan to put another one to have 48gb. I need mostly Memory (Contrastive Learning needs bigger batch sizes) instead of speed - so they kind of look to fit well. However, I have not found any official benchmark and some very old forum like &lt;a href=""https://www.kaggle.com/general/11332""&gt;this&lt;/a&gt; speak badly about Quadros.   &lt;/p&gt;

&lt;p&gt;So, what do you guys think? Any experience with Quadros for DL out there? Thx !!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nugkzi,True,,mortadelass,,2,True,all_ads,False,[],False,,/r/deeplearning/comments/nugkzi/quadro_m6000_for_deep_learning/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nugkzi/quadro_m6000_for_deep_learning/,66146,1623082864.0,0,,False,,,,,,,
,deeplearning,,t2_50i7d,False,,0,False,Lucy says hi: real time visualization of the changes in the parameters of neural networks,[],r/deeplearning,False,6,,0,,False,t3_nucccs,False,dark,0.87,,public,6,0,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yB-quDmIR2w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'height': 200}",,False,[],"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Lucy | real time deep learning visualization | neural network parameters visualization in real time', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yB-quDmIR2w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Javier ideami', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yB-quDmIR2w/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ideami'}}",False,False,,"{'content': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yB-quDmIR2w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'width': 356, 'scrolling': False, 'media_domain_url': 'https://www.redditmedia.com/mediaembed/nucccs', 'height': 200}",,False,6,,False,False,,False,,[],{},,False,,1623100721.0,text,6,,,text,youtube.com,False,,,,,https://www.youtube.com/watch?v=yB-quDmIR2w,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nucccs,True,,javismiles,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nucccs/lucy_says_hi_real_time_visualization_of_the/,all_ads,False,https://www.youtube.com/watch?v=yB-quDmIR2w,66146,1623071921.0,0,"{'type': 'youtube.com', 'oembed': {'provider_url': 'https://www.youtube.com/', 'version': '1.0', 'title': 'Lucy | real time deep learning visualization | neural network parameters visualization in real time', 'type': 'video', 'thumbnail_width': 480, 'height': 200, 'width': 356, 'html': '&lt;iframe width=""356"" height=""200"" src=""https://www.youtube.com/embed/yB-quDmIR2w?feature=oembed&amp;enablejsapi=1"" frameborder=""0"" allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"" allowfullscreen&gt;&lt;/iframe&gt;', 'author_name': 'Javier ideami', 'provider_name': 'YouTube', 'thumbnail_url': 'https://i.ytimg.com/vi/yB-quDmIR2w/hqdefault.jpg', 'thumbnail_height': 360, 'author_url': 'https://www.youtube.com/c/ideami'}}",False,,,,,,,
,deeplearning,"[https://nn.labml.ai/transformers/gmlp/index.html](https://nn.labml.ai/transformers/gmlp/index.html)

gMLP uses Multilayer Perceptrons (MLP) with gating instead of attention. It does pretty well compared to BERT on NLP and achieves same accuracy as ViT in vision tasks.

* [Github](https://github.com/labmlai/annotated_deep_learning_paper_implementations/tree/master/labml_nn/transformers/gmlp)
* [Paper](https://arxiv.org/abs/2105.08050)",t2_1jyhaoq,False,,0,False,Pay Attention to MLPs - Annotated PyTorch implementation,[],r/deeplearning,False,6,,0,,False,t3_nud3xn,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1623102864.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;&lt;a href=""https://nn.labml.ai/transformers/gmlp/index.html""&gt;https://nn.labml.ai/transformers/gmlp/index.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;gMLP uses Multilayer Perceptrons (MLP) with gating instead of attention. It does pretty well compared to BERT on NLP and achieves same accuracy as ViT in vision tasks.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=""https://github.com/labmlai/annotated_deep_learning_paper_implementations/tree/master/labml_nn/transformers/gmlp""&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=""https://arxiv.org/abs/2105.08050""&gt;Paper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nud3xn,True,,mlvpj,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nud3xn/pay_attention_to_mlps_annotated_pytorch/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nud3xn/pay_attention_to_mlps_annotated_pytorch/,66146,1623074064.0,0,,False,,,,,,,
,deeplearning,"A research team from Google Research combines the benefits of implicit differentiation and autodiff and proposes a unified, efficient and modular approach for implicit differentiation of optimization problems. 

Here is a quick read: [Google Proposes Efficient and Modular Implicit Differentiation for Optimization Problems.](https://syncedreview.com/2021/06/07/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-35/)

The paper *Efficient and Modular Implicit Differentiation* is on [arXiv](https://arxiv.org/abs/2105.15183).",t2_2fv4yodo,False,,0,False,[R] Google Proposes Efficient and Modular Implicit Differentiation for Optimization Problems,[],r/deeplearning,False,6,,0,,False,t3_nufqin,False,dark,0.75,,public,2,0,{},,False,[],,False,False,,{},,False,2,,False,False,,False,,[],{},,True,,1623109618.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;A research team from Google Research combines the benefits of implicit differentiation and autodiff and proposes a unified, efficient and modular approach for implicit differentiation of optimization problems. &lt;/p&gt;

&lt;p&gt;Here is a quick read: &lt;a href=""https://syncedreview.com/2021/06/07/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-35/""&gt;Google Proposes Efficient and Modular Implicit Differentiation for Optimization Problems.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The paper &lt;em&gt;Efficient and Modular Implicit Differentiation&lt;/em&gt; is on &lt;a href=""https://arxiv.org/abs/2105.15183""&gt;arXiv&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nufqin,True,,Yuqing7,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nufqin/r_google_proposes_efficient_and_modular_implicit/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nufqin/r_google_proposes_efficient_and_modular_implicit/,66146,1623080818.0,0,,False,,,,,,,
,deeplearning,"Hi,   
I am working as a Senior Machine Learning Engineer with 3 years of experience in DL. Being self-taught in ML, I want to give back to the community and make ML more accessible for everyone, especially the more recent topics as there are already a plethora of resources covering just the basics.  
Here is a small tutorial on Fine Tuning BERT and using it for text classification using TensorFlow 2  
[https://www.kaggle.com/au1206/fine-tuning-bert-text-classification](https://www.kaggle.com/au1206/fine-tuning-bert-text-classification)  


I will also often post annotated papers, where I will try to annotate a recent paper and try to make it more readable for a better understanding for the people just starting out. You can find some at  
[https://au1206.github.io/](https://au1206.github.io/) and will now consciously try to make it easier to understand.",t2_qxkg2,False,,0,False,Fine-Tune BERT for Text Classification with TensorFlow Tutorial,[],r/deeplearning,False,6,,0,,False,t3_nuc3j1,False,dark,0.8,,public,3,0,{},,False,[],,False,False,,{},,False,3,,False,False,,False,,[],{},,True,,1623100015.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;Hi,&lt;br/&gt;
I am working as a Senior Machine Learning Engineer with 3 years of experience in DL. Being self-taught in ML, I want to give back to the community and make ML more accessible for everyone, especially the more recent topics as there are already a plethora of resources covering just the basics.&lt;br/&gt;
Here is a small tutorial on Fine Tuning BERT and using it for text classification using TensorFlow 2&lt;br/&gt;
&lt;a href=""https://www.kaggle.com/au1206/fine-tuning-bert-text-classification""&gt;https://www.kaggle.com/au1206/fine-tuning-bert-text-classification&lt;/a&gt;  &lt;/p&gt;

&lt;p&gt;I will also often post annotated papers, where I will try to annotate a recent paper and try to make it more readable for a better understanding for the people just starting out. You can find some at&lt;br/&gt;
&lt;a href=""https://au1206.github.io/""&gt;https://au1206.github.io/&lt;/a&gt; and will now consciously try to make it easier to understand.&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuc3j1,True,,au1206,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nuc3j1/finetune_bert_for_text_classification_with/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nuc3j1/finetune_bert_for_text_classification_with/,66146,1623071215.0,0,,False,,,,,,,
,deeplearning,,t2_6l105jav,False,,0,False,2021 Python for Data Science &amp; Machine Learning from A-Z - free course from udemy,[],r/deeplearning,False,6,,0,,False,t3_nuhazo,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,False,,1623113424.0,text,6,,,text,myfreeonlinecourses.com,False,,,,,https://www.myfreeonlinecourses.com/2021/04/100-off-2021-python-for-data-science.html,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuhazo,True,,Ordinary_Craft,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nuhazo/2021_python_for_data_science_machine_learning/,all_ads,False,https://www.myfreeonlinecourses.com/2021/04/100-off-2021-python-for-data-science.html,66146,1623084624.0,0,,False,,,,,,,
,deeplearning,"I have done countless research, but i am a first timer in Artificial Intelligence.  


My final implementation needs to be with openCV and c++

Noob question regarding the above statement:  
If i train a model that requires Tensorflow, keras, etc, like CNN, after training it, can i implement it using openCV only?  


If anyone has any recommendations on what i should use for this goal, i would really appreciate it!",t2_6y5y4bqx,False,,0,False,"Help, I am trying to detect and count some insect species in a glue trap! What should my aproach be?",[],r/deeplearning,False,6,,0,,False,t3_nu7ynb,False,dark,0.71,,public,4,0,{},,False,[],,False,False,,{},,False,4,,False,False,,False,,[],{},,True,,1623085698.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I have done countless research, but i am a first timer in Artificial Intelligence.  &lt;/p&gt;

&lt;p&gt;My final implementation needs to be with openCV and c++&lt;/p&gt;

&lt;p&gt;Noob question regarding the above statement:&lt;br/&gt;
If i train a model that requires Tensorflow, keras, etc, like CNN, after training it, can i implement it using openCV only?  &lt;/p&gt;

&lt;p&gt;If anyone has any recommendations on what i should use for this goal, i would really appreciate it!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,False,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nu7ynb,True,,Tyrian_Callows,,4,True,all_ads,False,[],False,,/r/deeplearning/comments/nu7ynb/help_i_am_trying_to_detect_and_count_some_insect/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nu7ynb/help_i_am_trying_to_detect_and_count_some_insect/,66146,1623056898.0,0,,False,,,,,,,
,deeplearning,"NFNets - A network that achieves state-of-the-art performance without Batch Norm.

A few baks back DeepMind published a very interesting [paper](https://arxiv.org/abs/2102.06171) in which they claimed to beat the EfficientNet-B7 which was SOTA on ImageNet.

They introduced a family of nets i.e. NfNets which tried to reproduce the batch norm benefits without using it.

Here is the blog which discussed it so that we can explore the topic in this thread.

https://highontechs.com/deep-learning/nfnets-networks-without-batch-norm/",t2_730sjlh9,False,,0,False,NFNets - A network that achieves state-of-the-art performance without Batch Norm.,[],r/deeplearning,False,6,,0,,False,t3_nu6ewu,False,dark,0.73,,public,5,0,{},,False,[],,False,False,,{},,False,5,,False,False,,False,,[],{},,True,,1623078714.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;NFNets - A network that achieves state-of-the-art performance without Batch Norm.&lt;/p&gt;

&lt;p&gt;A few baks back DeepMind published a very interesting &lt;a href=""https://arxiv.org/abs/2102.06171""&gt;paper&lt;/a&gt; in which they claimed to beat the EfficientNet-B7 which was SOTA on ImageNet.&lt;/p&gt;

&lt;p&gt;They introduced a family of nets i.e. NfNets which tried to reproduce the batch norm benefits without using it.&lt;/p&gt;

&lt;p&gt;Here is the blog which discussed it so that we can explore the topic in this thread.&lt;/p&gt;

&lt;p&gt;&lt;a href=""https://highontechs.com/deep-learning/nfnets-networks-without-batch-norm/""&gt;https://highontechs.com/deep-learning/nfnets-networks-without-batch-norm/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nu6ewu,True,,Vivekvpawar,,0,True,all_ads,False,[],False,,/r/deeplearning/comments/nu6ewu/nfnets_a_network_that_achieves_stateoftheart/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nu6ewu/nfnets_a_network_that_achieves_stateoftheart/,66146,1623049914.0,0,,False,,,,,,,
,deeplearning,,t2_6zmd7l7y,False,,0,False,Do you guys have any idea on completing Andrew Ng’s deep learning course with companion books?,[],r/deeplearning,False,6,,0,,False,t3_nufd4t,False,dark,0.4,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623108677.0,text,3,,,text,self.deeplearning,False,,,,,,,False,True,False,False,True,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nufd4t,True,,Super_AI_1086,,2,True,promo_adult_nsfw,False,[],False,,/r/deeplearning/comments/nufd4t/do_you_guys_have_any_idea_on_completing_andrew/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nufd4t/do_you_guys_have_any_idea_on_completing_andrew/,66146,1623079877.0,0,,False,,,,,,,
,deeplearning,"I searched the subreddit for this, but I think I am not using the right terms. 

&amp;#x200B;

I want to take a bunch of my art and have it morph into each other. I dont want to use Art Breeder, I want an app/program on my computer that will do it.

&amp;#x200B;

Can anyone point me in the right direction? 

&amp;#x200B;

Example: [https://www.youtube.com/watch?v=xp1MLeLbFvE](https://www.youtube.com/watch?v=xp1MLeLbFvE)

&amp;#x200B;

Thanks!",t2_5bihi,False,,0,False,Deep Learning generated art.,[],r/deeplearning,False,6,,0,,False,t3_nuex9z,False,dark,0.5,,public,0,0,{},,False,[],,False,False,,{},,False,0,,False,False,,False,,[],{},,True,,1623107581.0,text,6,,,text,self.deeplearning,False,"&lt;!-- SC_OFF --&gt;&lt;div class=""md""&gt;&lt;p&gt;I searched the subreddit for this, but I think I am not using the right terms. &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;I want to take a bunch of my art and have it morph into each other. I dont want to use Art Breeder, I want an app/program on my computer that will do it.&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Can anyone point me in the right direction? &lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Example: &lt;a href=""https://www.youtube.com/watch?v=xp1MLeLbFvE""&gt;https://www.youtube.com/watch?v=xp1MLeLbFvE&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&amp;#x200B;&lt;/p&gt;

&lt;p&gt;Thanks!&lt;/p&gt;
&lt;/div&gt;&lt;!-- SC_ON --&gt;",,,,,,False,True,False,False,False,[],[],False,False,False,False,,[],False,,,,t5_2t5eh,,,,nuex9z,True,,murrray,,1,True,all_ads,False,[],False,,/r/deeplearning/comments/nuex9z/deep_learning_generated_art/,all_ads,False,https://www.reddit.com/r/deeplearning/comments/nuex9z/deep_learning_generated_art/,66146,1623078781.0,0,,False,,,,,,,
