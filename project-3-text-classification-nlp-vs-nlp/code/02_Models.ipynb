{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6053c83e",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "The objective of this project is a binary classification task of distinguishing between posts about Language Technology and posts about Neuro Linguistic Programming.\n",
    "\n",
    "In this notebook, models with different features and hyperpameters will be evaluated, both on the dataset on Language Tech and Neuro Linguistic Programming (df), and also how well it generalises to the tangential datasets of Deep Learning and Hypnosis (dldf).\n",
    "\n",
    "Logistic Regression, Naive Bayes, K Nearest Neighbors, Random Forest, Support Vector Machine and XGBoost classifiers will be tried out, each with both the Count Vectorizer and Tfidf Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3b247df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score as ROC, roc_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7acf6c4",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf060f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean/nl_lt_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42b8878",
   "metadata": {},
   "outputs": [],
   "source": [
    "dldf = pd.read_csv('../data/clean/hy_dl_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3bd392",
   "metadata": {},
   "source": [
    "Define target and content to be featurised into predictors for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6c407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['content']\n",
    "y = df['LT']\n",
    "X_dl = dldf['content']\n",
    "y_dl = dldf['DL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b0f2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823aeff",
   "metadata": {},
   "source": [
    "## Utils\n",
    "\n",
    "More complicated functions are consolidated in this section to allow for a better flow of the analysis in subesequent sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6488b1a",
   "metadata": {},
   "source": [
    "#### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf38599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sqb(text):\n",
    "    \"\"\"\n",
    "    Removes square brackets\n",
    "    and text between them from a string of text.\n",
    "    Allows for larger window within a url-like pattern.\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\[.{1,20}\\]|\\[.{1,20}\\..{1,8}/.{0,50}\\]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd90f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_urls(text):\n",
    "    \"\"\"\n",
    "    Breaks down urls in text\n",
    "    into constituent information.\n",
    "    \"\"\"\n",
    "    return re.sub(r'/|-|_|http:|https:|html|en|www|google|facebook|reddit|\\.com|\\.co|\\.net|\\.info|\\.org|\\.us|\\.uk|\\.eu|\\.ru|\\.de|\\.fr|\\.au|\\.cn|\\.in|\\.jp|\\.ca|\\.tk|\\.ly|\\.io', ' ',\n",
    "                  text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67099f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    pstem = PorterStemmer()\n",
    "    return ' '.join([pstem.stem(w) for w in text.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c02effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not removing 'nlp', 'linguist', programming' as they are commonly used terms in both sets\n",
    "stpwrds = stopwords.words('english') + ['language', 'technology',\n",
    "                                              'natural', 'processing',\n",
    "                                              'neuro', 'neurolinguist', 'neurolinguistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "852db3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stpwrds = stpwrds):\n",
    "    return ' '.join([w for w in text.split(' ') if w not in stpwrds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ab313c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(raw_text):\n",
    "    processed = re.sub(r'\\n|\\t', ' ', raw_text)\n",
    "    processed = melt_urls(clean_sqb(processed))\n",
    "    processed = re.sub(r'\\d+', '', processed)\n",
    "    processed = processed.lower()\n",
    "    processed = remove_stopwords(processed)\n",
    "    return stem(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4bfe05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_no_stem(raw_text):\n",
    "    processed = re.sub(r'\\n|\\t', ' ', raw_text)\n",
    "    processed = melt_urls(clean_sqb(processed))\n",
    "    processed = re.sub(r'\\d+', '', processed)\n",
    "    processed = processed.lower()\n",
    "    processed = remove_stopwords(processed)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75724c40",
   "metadata": {},
   "source": [
    "#### Results Generating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "457956b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Model No.', 'Classifier', 'Vectorizer', 'Hyperparams', \n",
    "                                'Train Accuracy', 'Test Accuracy', 'Test F1',\n",
    "                                'Related Topic Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0d04e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_results(model, model_no, df=results, comment='', hyp={}):\n",
    "    result = {'Comments': comment}\n",
    "    result['Model No.'] = model_no\n",
    "    result['Classifier'] = type(model[-1]).__name__\n",
    "    result['Vectorizer'] = type(model[0]).__name__\n",
    "    result['Hyperparams'] = hyp\n",
    "    result['Train Accuracy'] = model.score(X_train, y_train)\n",
    "    result['Test Accuracy'] = model.score(X_test, y_test)\n",
    "    result['Test F1'] = f1_score(y_test, model.predict(X_test))\n",
    "    result['Related Topic Accuracy'] = model.score(X_dl, y_dl)\n",
    "    df = df.append(result, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf78f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_scores(model, reverse=True):\n",
    "    \"\"\"\n",
    "    Returns dictionary of features and \n",
    "    their respective model weight/scores.\n",
    "    If reverse is set to True, \n",
    "    features will be ranked by weight/score \n",
    "    in descending order (highest first).\n",
    "    \"\"\"\n",
    "    model_type = type(model[-1]).__name__\n",
    "    \n",
    "    if 'NB' in model_type:\n",
    "        prob_difference = np.exp(model[1].feature_log_prob_[1]) - np.exp(model[1].feature_log_prob_[0])\n",
    "        return dict(sorted(zip(model[0].vocabulary_, prob_difference), \n",
    "                           reverse=reverse, key=lambda x:np.abs(x[1])))\n",
    "        \n",
    "    elif 'Logistic' in model_type:\n",
    "        return dict(sorted(zip(model[0].vocabulary_, np.exp(model[1].coef_[0])), \n",
    "                           reverse=reverse, key=lambda x:x[1]))\n",
    "        \n",
    "    elif 'SV' in model_type:\n",
    "        return dict(sorted(zip(model[0].vocabulary_, model[1].coef_.toarray()[0]), \n",
    "                    reverse=reverse, key=lambda x:np.abs(x[1])))\n",
    "        \n",
    "    elif 'XG' in model_type or 'Forest' in model_type:\n",
    "        return dict(sorted(zip(model_12[0].vocabulary_, model_12[1].feature_importances_), \n",
    "                    reverse=True, key=lambda x:x[1]))\n",
    "    else:\n",
    "        return 'Model type not supported by this fn.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "003847e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(model, X, y, title=None):\n",
    "    if not title:\n",
    "        model_name = type(model[-1]).__name__\n",
    "        plt.title(f'ROC Curve for {model_name}') \n",
    "    else:\n",
    "        plt.title(title) \n",
    "    y_score = model.predict_proba(X)[:,1]\n",
    "    roc_score = round(ROC(y, y_score),2)\n",
    "    base_fpr, base_tpr, _ = roc_curve(y, np.zeros(len(y)))\n",
    "    model_fpr, model_tpr, _ = roc_curve(y, y_score)   \n",
    "    plt.plot(base_fpr, base_tpr, linestyle='--', label='Baseline')\n",
    "    plt.plot(model_fpr, model_tpr, marker='.', label='Model')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.text(0.6, 0.2, f'ROC Score: {roc_score}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c82e611",
   "metadata": {},
   "source": [
    "## Model Training and Scoring\n",
    "\n",
    "In this section, Logistic Regression, Multinomial Naive Bayes, K Nearest Neighbors, Random Forest, Support Vector Machine and XGBoost classifier (six model types) will each be tried out with two different word vectorizers (Count Vectorizer and Tfidf Vectorizer). \n",
    "\n",
    "For each model and vectorizer pair, a grid search of selected hyperparameters will be done. The best performing models for each grid search will be compared and analysed in the following section. Their results will be written to a dataframe, as initiated as the `results` variable above, to facilitate evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a8ab20",
   "metadata": {},
   "source": [
    "**Note when rerunning this notebook**: After each model's grid search is done, the best hyperparameters found from the grid search are subsequently passed as arguments into a new model. These hyperparameters are passed manually instead of calling the best estimator attribute from the grid search so that when this notebook is rerun, the grid search steps, which take a lot of time and computation, can be commented out and skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f870e6e",
   "metadata": {},
   "source": [
    "### Count Vectorizer with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b64acef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1 = Pipeline([('cvec', CountVectorizer()),\n",
    "#                ('lr', LogisticRegression())])\n",
    "\n",
    "# m1_params = {\n",
    "#     'cvec__preprocessor': [preproc, preproc_no_stem],\n",
    "#     'cvec__ngram_range': [(1,2), (2,3), (1,4)],\n",
    "#     'cvec__min_df': [2, 4],\n",
    "#     'cvec__max_df': [0.9, 0.95],\n",
    "#     'lr__C': [0.01, 0.1, 1]\n",
    "# }\n",
    "\n",
    "# m1_grid = GridSearchCV(m1, m1_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "519fad07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# m1_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f43f047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "244e42d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b6ff66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Pipeline([('cvec', CountVectorizer(\n",
    "    preprocessor = preproc,\n",
    "    ngram_range = (1,2),\n",
    "    min_df = 4,\n",
    "    max_df=0.9)),\n",
    "               ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7659fb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.9, min_df=4, ngram_range=(1, 2),\n",
       "                                 preprocessor=<function preproc at 0x7fc2debe03a0>)),\n",
       "                ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "609ac6bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992282958199357"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fe58ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9305912596401028"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e1ead7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9283819628647214"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a441bc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8478622987229317"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e765c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = update_results(model_1, 1, results, hyp=m1_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ad27d",
   "metadata": {},
   "source": [
    "If grid search is not run, pass in `hyp=str(model_1)` instead to write the model hyperparms to the results table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a426aa",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ada1a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2 = Pipeline([('tvec', TfidfVectorizer()),\n",
    "#                ('lr', LogisticRegression())])\n",
    "\n",
    "# m2_params = {\n",
    "#     'tvec__preprocessor': [preproc, preproc_no_stem],\n",
    "#     'tvec__ngram_range': [(1,2), (2,3), (1,4)],\n",
    "#     'tvec__min_df': [2, 4],\n",
    "#     'tvec__max_df': [0.9, 0.95],\n",
    "#     'lr__C': [0.01, 0.1, 1]\n",
    "# }\n",
    "\n",
    "# m2_grid = GridSearchCV(m2, m2_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2aba005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1266200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93e34ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16810386",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Pipeline([('tvec', TfidfVectorizer(\n",
    "    preprocessor = preproc_no_stem,\n",
    "    ngram_range = (1,2),\n",
    "    min_df = 4,\n",
    "    max_df=0.9)),\n",
    "               ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc324ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tvec',\n",
       "                 TfidfVectorizer(max_df=0.9, min_df=4, ngram_range=(1, 2),\n",
       "                                 preprocessor=<function preproc_no_stem at 0x7fc2debe0700>)),\n",
       "                ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7da7b4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9826366559485531"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c02df5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460154241645244"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42519e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462915601023019"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a53d6421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9172681843420322"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d19b71c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = update_results(model_2, 2, results, hyp=m2_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6eba8e",
   "metadata": {},
   "source": [
    "### Count Vectorizer with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fc91464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m3 = Pipeline([('cvec', CountVectorizer()),\n",
    "#                ('nb', MultinomialNB())])\n",
    "\n",
    "# m3_params = {\n",
    "#     'cvec__preprocessor': [preproc, preproc_no_stem],\n",
    "#     'cvec__ngram_range': [(1,2), (2,3), (1,4)],\n",
    "#     'cvec__min_df': [2, 4],\n",
    "#     'cvec__max_df': [0.9, 0.95],\n",
    "#     'nb__fit_prior': [True, False]\n",
    "# }\n",
    "\n",
    "# m3_grid = GridSearchCV(m3, m3_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4751d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m3_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09fae8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m3_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2371befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m3_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5abb2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Pipeline([('cvec', CountVectorizer(\n",
    "    preprocessor = preproc,\n",
    "    ngram_range = (1,2),\n",
    "    min_df = 2,\n",
    "    max_df=0.9)),\n",
    "               ('nb', MultinomialNB(fit_prior=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "901759f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.9, min_df=2, ngram_range=(1, 2),\n",
       "                                 preprocessor=<function preproc at 0x7fc2debe03a0>)),\n",
       "                ('nb', MultinomialNB(fit_prior=False))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3843201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762057877813505"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5c00c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460154241645244"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d16043f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9460154241645244"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_3.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e790028e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9283731260410882"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "175ddf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = update_results(model_3, 3, results, hyp=m3_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b5d64",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49e03015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m4 = Pipeline([('tvec', TfidfVectorizer()),\n",
    "#                ('nb', MultinomialNB())])\n",
    "\n",
    "# m4_params = {\n",
    "#     'tvec__preprocessor': [preproc, preproc_no_stem],\n",
    "#     'tvec__ngram_range': [(1,2), (2,3), (1,4)],\n",
    "#     'tvec__min_df': [2, 4],\n",
    "#     'tvec__max_df': [0.9, 0.95],\n",
    "#     'nb__fit_prior': [True, False]\n",
    "# }\n",
    "\n",
    "# m4_grid = GridSearchCV(m4, m4_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6889868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m4_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b64abc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m4_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a474fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m4_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64656b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = Pipeline([('tvec', TfidfVectorizer(\n",
    "    preprocessor = preproc,\n",
    "    ngram_range = (1,2),\n",
    "    min_df = 2,\n",
    "    max_df=0.9)),\n",
    "               ('nb', MultinomialNB(fit_prior=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae686a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tvec',\n",
       "                 TfidfVectorizer(max_df=0.9, min_df=2, ngram_range=(1, 2),\n",
       "                                 preprocessor=<function preproc at 0x7fc2debe03a0>)),\n",
       "                ('nb', MultinomialNB(fit_prior=False))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8d40c83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9845659163987138"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a95fb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9511568123393316"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02b60aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9533169533169533"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_4.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc63a519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9383675735702388"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "989aa7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = update_results(model_4, 4, results, hyp=m4_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aadd4f1",
   "metadata": {},
   "source": [
    "### Count Vectorizer with KNN\n",
    "Will not use scaling as word counts are on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b12fd267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m5 = Pipeline([('cvec', CountVectorizer()),\n",
    "#                ('knn', KNeighborsClassifier())])\n",
    "\n",
    "# m5_params = {\n",
    "#     'cvec__preprocessor': [preproc, preproc_no_stem],\n",
    "#     'cvec__ngram_range': [(1,2), (2,3), (1,4)],\n",
    "#     'cvec__min_df': [2, 4],\n",
    "#     'cvec__max_df': [0.9, 0.95],\n",
    "#     'knn__n_neighbors': [3, 5],\n",
    "#     'knn__p': [1, 2]\n",
    "# }\n",
    "\n",
    "# m5_grid = GridSearchCV(m5, m5_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "381c373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m5_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f57c59bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m5_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6705b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m5_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5fb3818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = Pipeline([('cvec', CountVectorizer(\n",
    "    preprocessor = preproc,\n",
    "    ngram_range = (1,2),\n",
    "    min_df = 4,\n",
    "    max_df=0.9)),\n",
    "               ('knn', KNeighborsClassifier(n_neighbors=3, p=2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "58c8ce41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.9, min_df=4, ngram_range=(1, 2),\n",
       "                                 preprocessor=<function preproc at 0x7fc2debe03a0>)),\n",
       "                ('knn', KNeighborsClassifier(n_neighbors=3))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a762b0c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8231511254019293"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ab38c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7275064267352185"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "248b3348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6513157894736842"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_5.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c20ca815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6296501943364797"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f53b6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = update_results(model_5, 5, results, hyp=m5_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f40b9",
   "metadata": {},
   "source": [
    "Reconfirm that scaling does not help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3db6ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_5s = Pipeline([('cvec', CountVectorizer(\n",
    "#                         preprocessor = preproc,\n",
    "#                         ngram_range = (1,2),\n",
    "#                         min_df = 4,\n",
    "#                         max_df=0.9)),\n",
    "#                      ('ss', StandardScaler(with_mean=False)),\n",
    "#                      ('knn', KNeighborsClassifier(n_neighbors=3, p=2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6eaac097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_5s.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6be113fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_5s.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df3c1bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_5s.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "12ad50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_5s.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6702f57e",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "80c3ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m6 = Pipeline([('tvec', TfidfVectorizer()),\n",
    "#                ('knn', KNeighborsClassifier())])\n",
    "\n",
    "# m6_params = {\n",
    "#     'tvec__preprocessor': [preproc, preproc_no_stem],\n",
    "#     'tvec__ngram_range': [(1,2), (2,3), (1,4)],\n",
    "#     'tvec__min_df': [2, 4],\n",
    "#     'tvec__max_df': [0.9, 0.95],\n",
    "#     'knn__n_neighbors': [3, 5, 8],\n",
    "#     'knn__p': [1, 2]\n",
    "# }\n",
    "\n",
    "# m6_grid = GridSearchCV(m6, m6_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e1c09205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m6_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2171ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m6_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7538d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m6_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cf825d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = Pipeline([('tvec', TfidfVectorizer(\n",
    "    preprocessor = preproc_no_stem,\n",
    "    ngram_range = (2,3),\n",
    "    min_df = 4,\n",
    "    max_df=0.9)),\n",
    "               ('knn', KNeighborsClassifier(n_neighbors=3, p=2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cea84a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tvec',\n",
       "                 TfidfVectorizer(max_df=0.9, min_df=4, ngram_range=(2, 3),\n",
       "                                 preprocessor=<function preproc_no_stem at 0x7fc2debe0700>)),\n",
       "                ('knn', KNeighborsClassifier(n_neighbors=3))])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d396ac67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9009646302250803"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "865af1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7043701799485861"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ec31919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6504559270516717"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_6.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "48a95968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6357579122709606"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "92dbe7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = update_results(model_6, 6, results, hyp=m6_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a0b8c1",
   "metadata": {},
   "source": [
    "### Count Vectorizer with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "abe90808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m7 = Pipeline([\n",
    "#     ('cvec', CountVectorizer()),\n",
    "#     ('rf', RandomForestClassifier())])\n",
    "\n",
    "# m7_params = {\n",
    "#     'cvec__preprocessor': [preproc, preproc_no_stem],\n",
    "#     'cvec__ngram_range': [(1,2), (2,3), (1,4)],\n",
    "#     'cvec__min_df': [2, 4],\n",
    "#     'cvec__max_df': [0.9, 0.95],\n",
    "#     'rf__max_depth': [None, 5, 10, 20],\n",
    "#     'rf__bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# m7_grid = GridSearchCV(m7, m7_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d94a7d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m7_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dadc28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m7_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f9767625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m7_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ea8ade1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = Pipeline([('cvec', CountVectorizer(\n",
    "    preprocessor = preproc,\n",
    "    ngram_range = (1,2),\n",
    "    min_df = 2,\n",
    "    max_df=0.9)),\n",
    "               ('rf', RandomForestClassifier(max_depth=None, bootstrap=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b23dcbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.9, min_df=2, ngram_range=(1, 2),\n",
       "                                 preprocessor=<function preproc at 0x7fc2debe03a0>)),\n",
       "                ('rf', RandomForestClassifier(bootstrap=False))])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "556a4507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cfb744d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9357326478149101"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8a4ffdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9367088607594938"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_7.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "77349094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8445308162132149"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "929b0bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = update_results(model_7, 7, results, hyp=m7_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943cd877",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ada52ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m8 = Pipeline([\n",
    "#     ('tvec', TfidfVectorizer()),\n",
    "#     ('rf', RandomForestClassifier())])\n",
    "\n",
    "# m8_params = {\n",
    "#     'tvec__preprocessor': [preproc, preproc_no_stem],\n",
    "#     'tvec__ngram_range': [(1,2), (2,3), (1,4)],\n",
    "#     'tvec__min_df': [2, 4],\n",
    "#     'tvec__max_df': [0.9, 0.95],\n",
    "#     'rf__max_depth': [None, 5, 10, 20],\n",
    "#     'rf__bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# m8_grid = GridSearchCV(m8, m8_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "43de555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m8_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e8c94353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m8_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f836d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m8_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "68fc97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8 = Pipeline([('tvec', TfidfVectorizer(\n",
    "    preprocessor = preproc_no_stem,\n",
    "    ngram_range = (1,2),\n",
    "    min_df = 2,\n",
    "    max_df=0.95)),\n",
    "               ('rf', RandomForestClassifier(max_depth=None, bootstrap=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4f055593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tvec',\n",
       "                 TfidfVectorizer(max_df=0.95, min_df=2, ngram_range=(1, 2),\n",
       "                                 preprocessor=<function preproc_no_stem at 0x7fc2debe0700>)),\n",
       "                ('rf', RandomForestClassifier(bootstrap=False))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "18403273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6ca31599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9434447300771208"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4de5deb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9447236180904522"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_8.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1f88a2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8517490283176014"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b6f26945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = update_results(model_8, 8, results, hyp=m8_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acc9b6c",
   "metadata": {},
   "source": [
    "### Count Vectorizer with Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "705bf163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m9 = Pipeline([\n",
    "#     ('cvec', CountVectorizer()),\n",
    "#     ('sv', SVC())])\n",
    "\n",
    "# m9_params = {\n",
    "#     'cvec__preprocessor': [preproc, preproc_no_stem],\n",
    "#     'cvec__ngram_range': [(1,2), (2,3), (1,4)],\n",
    "#     'cvec__min_df': [2, 4],\n",
    "#     'cvec__max_df': [0.9, 0.95],\n",
    "#     'sv__C': [0.1, 1, 10, 100],\n",
    "#     'sv__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#     'sv__degree': [3, 5]\n",
    "# }\n",
    "\n",
    "# m9_grid = GridSearchCV(m9, m9_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "365e155c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# m9_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b6ecd8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m9_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "11984bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m9_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b52f36ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_9 = Pipeline([('cvec', CountVectorizer(\n",
    "    preprocessor = preproc,\n",
    "    ngram_range = (1,2),\n",
    "    min_df = 2,\n",
    "    max_df=0.9)),\n",
    "               ('sv', SVC(kernel='linear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e6921f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.9, min_df=2, ngram_range=(1, 2),\n",
       "                                 preprocessor=<function preproc at 0x7fc2debe03a0>)),\n",
       "                ('sv', SVC(kernel='linear'))])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "69c61707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993569131832798"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "26b3d56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8997429305912596"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f2f48ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_9.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "97352c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8051082731815657"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4f009868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = update_results(model_9, 9, results, hyp=m9_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3db5a3",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer with Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6245282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m10 = Pipeline([\n",
    "#     ('tvec', TfidfVectorizer()),\n",
    "#     ('sv', SVC())])\n",
    "\n",
    "# m10_params = {\n",
    "#     'tvec__preprocessor': [preproc, preproc_no_stem],\n",
    "#     'tvec__ngram_range': [(1,2), (2,3), (1,4)],\n",
    "#     'tvec__min_df': [2, 4],\n",
    "#     'tvec__max_df': [0.9, 0.95],\n",
    "#     'sv__C': [0.1, 1, 10, 100],\n",
    "#     'sv__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#     'sv__degree': [3, 5]\n",
    "# }\n",
    "\n",
    "# m10_grid = GridSearchCV(m10, m10_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8682a160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# m10_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fa0f8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m10_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d65f9434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m10_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7da5f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10 = Pipeline([('tvec', TfidfVectorizer(\n",
    "    preprocessor = preproc_no_stem,\n",
    "    ngram_range = (1,2),\n",
    "    min_df = 2,\n",
    "    max_df=0.9)),\n",
    "               ('sv', SVC(kernel='linear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "19fb282d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tvec',\n",
       "                 TfidfVectorizer(max_df=0.9, min_df=2, ngram_range=(1, 2),\n",
       "                                 preprocessor=<function preproc_no_stem at 0x7fc2debe0700>)),\n",
       "                ('sv', SVC(kernel='linear'))])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "634077e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9948553054662379"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cb7a593e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9383033419023136"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b1f9c6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9387755102040817"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_10.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fc73987c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9128262076624097"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c7b8be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = update_results(model_10, 10, results, hyp=m10_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d4819b",
   "metadata": {},
   "source": [
    "### Count Vectorizer with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bdfa5178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m11 = Pipeline([\n",
    "#     ('cvec', CountVectorizer()),\n",
    "#     ('xgc', xgb.XGBClassifier())])\n",
    "\n",
    "# m11_params = {\n",
    "#     'cvec__preprocessor': [preproc, preproc_no_stem],\n",
    "#     'cvec__ngram_range': [(1,2), (2,3), (1,4)],\n",
    "#     'cvec__min_df': [2, 4],\n",
    "#     'cvec__max_df': [0.9, 0.95],\n",
    "#     'xgc__n_estimators': [10, 100, 200],\n",
    "#     'xgc__max_depth': [2, 5, 10]\n",
    "# }\n",
    "\n",
    "# m11_grid = GridSearchCV(m11, m11_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "20929ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# m11_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "005c9e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# m11_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "36c3423c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# m11_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "543cae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11 = Pipeline([('cvec', CountVectorizer(\n",
    "    preprocessor = preproc_no_stem,\n",
    "    ngram_range = (1,2),\n",
    "    min_df = 2 ,\n",
    "    max_df=0.9)),\n",
    "               ('xgc', xgb.XGBClassifier(max_depth=5, n_estimators=100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cbb8e017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neilyap/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:34:04] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.9, min_df=2, ngram_range=(1, 2),\n",
       "                                 preprocessor=<function preproc_no_stem at 0x7fc2debe0700>)),\n",
       "                ('xgc',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=5, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_11.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2e05ae92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9704180064308682"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_11.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d746e3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9357326478149101"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_11.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a3bdd6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9347258485639688"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_11.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "249ff83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8445308162132149"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_11.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3d3b4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = update_results(model_11, 11, results, hyp=m11_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e4012",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ca71c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m12 = Pipeline([\n",
    "#     ('tvec', TfidfVectorizer()),\n",
    "#     ('xgc', xgb.XGBClassifier())])\n",
    "\n",
    "# m12_params = {\n",
    "#     'tvec__preprocessor': [preproc, preproc_no_stem],\n",
    "#     'tvec__ngram_range': [(1,2), (2,3), (1,4)],\n",
    "#     'tvec__min_df': [2, 4],\n",
    "#     'tvec__max_df': [0.9, 0.95],\n",
    "#     'xgc__n_estimators': [10, 100, 200],\n",
    "#     'xgc__max_depth': [2, 5, 10]\n",
    "# }\n",
    "\n",
    "# m12_grid = GridSearchCV(m12, m12_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e9590b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# m12_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "61d4510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m12_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dc004dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m12_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c0ea5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_12 = Pipeline([('tvec', TfidfVectorizer(\n",
    "    preprocessor = preproc,\n",
    "    ngram_range = (1,4),\n",
    "    min_df = 4,\n",
    "    max_df=0.9)),\n",
    "               ('xgc', xgb.XGBClassifier(max_depth=2, n_estimators=200))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c83e12a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neilyap/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:34:09] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tvec',\n",
       "                 TfidfVectorizer(max_df=0.9, min_df=4, ngram_range=(1, 4),\n",
       "                                 preprocessor=<function preproc at 0x7fc2debe03a0>)),\n",
       "                ('xgc',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=2, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=200,\n",
       "                               n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_12.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fe3d2fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9717041800643087"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_12.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bd1078cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9357326478149101"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_12.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ef57cb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9343832020997376"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, model_12.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6a9e90a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8389783453636869"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_12.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5d42ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = update_results(model_12, 12, results, hyp=m12_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "81a6bf6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24d1bfa",
   "metadata": {},
   "source": [
    "## Model Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bafc76f",
   "metadata": {},
   "source": [
    "### Benchmarks\n",
    "\n",
    "Here is a reminder of the benchmark accuracy for both the test set and the related topic (deep learning vs hypnosis) set. Both sets have quite evenly distributed positive and negative examples, and the benchmark accuracy, which is that in which the majority class is predicted all the time, is about 52% for both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eeb169ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.51671\n",
       "0    0.48329\n",
       "Name: LT, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "05ff13fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.521932\n",
       "0    0.478068\n",
       "Name: DL, dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dl.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09836ab7",
   "metadata": {},
   "source": [
    "### Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8a436573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(results.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd03168",
   "metadata": {},
   "source": [
    "|   Model No. | Classifier             | Vectorizer      | Hyperparams                                                                                                                                                                                    |   Train Accuracy |   Test Accuracy |   Test F1 |   Related Topic Accuracy | Comments   |\n",
    "|------------:|:-----------------------|:----------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------:|----------------:|----------:|-------------------------:|:-----------|\n",
    "|           1 | LogisticRegression     | CountVectorizer | {'cvec__max_df': 0.9, 'cvec__min_df': 4, 'cvec__ngram_range': (1, 2), 'cvec__preprocessor': <function preproc at 0x7ffd44dba8b0>, 'lr__C': 1}                                                  |         0.992283 |        0.930591 |  0.928382 |                 0.847862 |            |\n",
    "|           2 | LogisticRegression     | TfidfVectorizer | {'lr__C': 1, 'tvec__max_df': 0.9, 'tvec__min_df': 4, 'tvec__ngram_range': (1, 2), 'tvec__preprocessor': <function preproc_no_stem at 0x7ffd408b11f0>}                                          |         0.982637 |        0.946015 |  0.946292 |                 0.917268 |            |\n",
    "|           3 | MultinomialNB          | CountVectorizer | {'cvec__max_df': 0.9, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__preprocessor': <function preproc at 0x7ffd44dba8b0>, 'nb__fit_prior': False}                                      |         0.976206 |        0.946015 |  0.946015 |                 0.928373 |            |\n",
    "|           4 | MultinomialNB          | TfidfVectorizer | {'nb__fit_prior': False, 'tvec__max_df': 0.9, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 2), 'tvec__preprocessor': <function preproc at 0x7ffd44dba8b0>}                                      |         0.984566 |        0.951157 |  0.953317 |                 0.938368 |            |\n",
    "|           5 | KNeighborsClassifier   | CountVectorizer | {'cvec__max_df': 0.9, 'cvec__min_df': 4, 'cvec__ngram_range': (1, 2), 'cvec__preprocessor': <function preproc at 0x7ffd44dba8b0>, 'knn__n_neighbors': 3, 'knn__p': 2}                          |         0.823151 |        0.727506 |  0.651316 |                 0.62965  |            |\n",
    "|           6 | KNeighborsClassifier   | TfidfVectorizer | {'knn__n_neighbors': 3, 'knn__p': 2, 'tvec__max_df': 0.9, 'tvec__min_df': 4, 'tvec__ngram_range': (2, 3), 'tvec__preprocessor': <function preproc_no_stem at 0x7ffd408b11f0>}                  |         0.900965 |        0.70437  |  0.650456 |                 0.635758 |            |\n",
    "|           7 | RandomForestClassifier | CountVectorizer | {'cvec__max_df': 0.9, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__preprocessor': <function preproc at 0x7ffd44dba8b0>, 'rf__bootstrap': False, 'rf__max_depth': None}               |         1        |        0.928021 |  0.930348 |                 0.850083 |            |\n",
    "|           8 | RandomForestClassifier | TfidfVectorizer | {'rf__bootstrap': False, 'rf__max_depth': None, 'tvec__max_df': 0.95, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 2), 'tvec__preprocessor': <function preproc_no_stem at 0x7ffd408b11f0>}      |         1        |        0.943445 |  0.944444 |                 0.855081 |            |\n",
    "|           9 | SVC                    | CountVectorizer | {'cvec__max_df': 0.9, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__preprocessor': <function preproc at 0x7ffd44dba8b0>, 'sv__C': 1, 'sv__degree': 3, 'sv__kernel': 'linear'}         |         0.999357 |        0.899743 |  0.896    |                 0.805108 |            |\n",
    "|          10 | SVC                    | TfidfVectorizer | {'sv__C': 1, 'sv__degree': 3, 'sv__kernel': 'linear', 'tvec__max_df': 0.9, 'tvec__min_df': 2, 'tvec__ngram_range': (1, 2), 'tvec__preprocessor': <function preproc_no_stem at 0x7ffd408b11f0>} |         0.994855 |        0.938303 |  0.938776 |                 0.912826 |            |\n",
    "|          11 | XGBClassifier          | CountVectorizer | {'cvec__max_df': 0.9, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 2), 'cvec__preprocessor': <function preproc_no_stem at 0x7ffd408b11f0>, 'xgc__max_depth': 5, 'xgc__n_estimators': 100}       |         0.970418 |        0.935733 |  0.934726 |                 0.844531 |            |\n",
    "|          12 | XGBClassifier          | TfidfVectorizer | {'tvec__max_df': 0.9, 'tvec__min_df': 4, 'tvec__ngram_range': (1, 4), 'tvec__preprocessor': <function preproc at 0x7ffd44dba8b0>, 'xgc__max_depth': 2, 'xgc__n_estimators': 200}               |         0.971704 |        0.935733 |  0.934383 |                 0.838978 |            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e662b",
   "metadata": {},
   "source": [
    "**Model Performance**\n",
    "\n",
    "The above table summarises how the models performed. All models outperformed benchmark accuracy for both the test set and related topics set.\n",
    "\n",
    "The Multinomial Naive Bayes (MNB) model with Tfidf Vectorizer (model_4) has the best test accuracy and F1 score, and best accuracy on predicting related topics. This is followed closely by the MNB model with Count Vectorizer (model_3) and Logistic Regression model with Tfidf Vectorizer (model_2).\n",
    "\n",
    "The worst performing models on all the metrics in the table are the K Nearest Neighbors models (model_5 and model_6).\n",
    "\n",
    "\n",
    "**Tfidf vs Count**\n",
    "\n",
    "In general, for each model type, the Tfidf Vectorizer version outperformed the Count Vectorizer version on test accuracy and related topic accuracy. \n",
    "\n",
    "This is likely due to Tfidf being able to better generalise to a variety of unseen posts by accounting for feature prominence in texts of different content length, as the term frequency is relevant to the document length. With just a count vectorizer, there could be words that are mentioned in passing that form just a small part of what the post's meaning is about, but that feature gets an equivalent weight to a separate shorter post where the word/phrase forms the crux of the post.\n",
    "\n",
    "Tfidf also focuses on more prominent word features by penalising the relative importance of words/phrases that appear too commonly throughout the corpus. In contrast, with just a count vectorizer, words that occur frequently in many documents throughout the corpus may be mistakenly learned to be important features, drowning out rarer and possible more significant words that are better signals to characterist a post.\n",
    "\n",
    "\n",
    "**KNN**\n",
    "\n",
    "The KNN models perform the worst. This is likely due to how KNN models do not do well on data with many features or that have outliers. It is likely that there are many small posts with combination of relatively rare words, forming what is akin to outliers, causing the neighbors to struggle to accurately vote on to classify.\n",
    "\n",
    "**Random Forests and XGBoost**\n",
    "\n",
    "The random forests and XGBoost perform very well on the train and test accuracy, but suffer a >10% dip on related topic accuracy, signifying these models are quite overfit to the word features of the original corpus and do not generalise well to adjacent topics that may use slightly different vocabulary. XGBoost is known to work well when there are a lot more samples than there are features, which is not the case here.\n",
    "\n",
    "**Best Performing Models**\n",
    "\n",
    "Apart from the naive bayes models, the logistic regression and support vector machine models perform very well. Support vector machines are known to do relatively well on data with a lot of features, such as in this text classification task. This is likely due to its ability to focus on the data points that lie closest to the decision boundary, being less sensitive to the noise of somany features. However, the logistic regression model with tfidf (model 2) still slightly outperformed the better support vector model. Thhe logistic regression model would also be favoured due to its better interpretability of coefficients. Although we can interpret the coefficients of support vector machines with linear kernels (as so happens the grid search chose in this case), in general, support vector machines are harder to interpret than logistic regression models.\n",
    "\n",
    "The naive bayes models clearly outperformed the rest, and will be the models of choice moving forward as on top of empirically good scores, as models, they are relatively easy to interpret and efficiently fit to the data.\n",
    "\n",
    "Models 2 (Logistic Regression with Tfidf), 3 and 4 (Naive Bayes) will be shortlisted for deeper analysis moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b0c4bb",
   "metadata": {},
   "source": [
    "### Deeper Comparison of Best Models\n",
    "\n",
    "The selected best models (models 2,3, and 4) of Logistic Regression with Tfidf Vectorizer and both the Naive Bayes models have very close performing accuracy scores on train, test and related topics data. They will be further evaluated with more metrics, namely the ROC AUC, and taking a deeper look at the other metrics in the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2389fc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(model_2, X_dl, y_dl,\n",
    "               title='ROC Curve for Tfidf LogReg on Related Topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "681d1844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(model_3, X_dl, y_dl,\n",
    "               title='ROC Curve for CV Naive Bayes on Related Topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "55fafd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(model_4, X_dl, y_dl,\n",
    "               title='ROC Curve for Tfidf Naive Bayes on Related Topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f01bdc",
   "metadata": {},
   "source": [
    "The Tfidf Naive Bayes Model (model 4) has a higher score than the Count Vectorizer Naive Bayes Model (model 3) and the Tfidf Logistic Regression Model (model 2), but all three models have extremely close scores. The best score was 0.99. These scores are evaluated on the related topic data. This shows that the model can generalise to unseen data of adjacent topics, and that the model is capable of distinguishing between these classes effectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7a80ef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92       861\n",
      "           1       0.95      0.89      0.92       940\n",
      "\n",
      "    accuracy                           0.92      1801\n",
      "   macro avg       0.92      0.92      0.92      1801\n",
      "weighted avg       0.92      0.92      0.92      1801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dl, model_2.predict(X_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bbcbb0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       861\n",
      "           1       0.99      0.87      0.93       940\n",
      "\n",
      "    accuracy                           0.93      1801\n",
      "   macro avg       0.93      0.93      0.93      1801\n",
      "weighted avg       0.94      0.93      0.93      1801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dl, model_3.predict(X_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d9a9a80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       861\n",
      "           1       0.94      0.94      0.94       940\n",
      "\n",
      "    accuracy                           0.94      1801\n",
      "   macro avg       0.94      0.94      0.94      1801\n",
      "weighted avg       0.94      0.94      0.94      1801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dl, model_4.predict(X_dl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9732bd2d",
   "metadata": {},
   "source": [
    "Taking a closer look at the detailed classification reports of models 2-4 show us that they differ in their ability to comprehensively or precisely capture the positive and negative classes.\n",
    "\n",
    "For instance, model 3 has the best precision with the positive class and best recall with the negative class, but does the worst of the 3 for recall on the positive class. This means that it performed the worst in capturing all the positive examples (deep learning) in the related topic set.\n",
    "\n",
    "In general, although model 4 does not outperform the other models on individual precision and recall metrics for both the negative and positive label, it has the best f1-scores overall because its performance on all the metrics are overall more balanced and consistently high across the different metrics and classes. As for this task, since it is both important to identify content actually about natural language processing/deep learning and also to filter out content about neuro linguistic programming, a model with a more consistent performance on both classes' fronts is more desirable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0595681",
   "metadata": {},
   "source": [
    "### Interpreting Feature Selection of Best Models\n",
    "\n",
    "To better understand the good performance of the NB models (model_3, model_4) and the Logistic Regression Tfidf model (model_2), the feature importances of these models will be analysed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "498ed173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tal state': 22.46706652994162,\n",
       " 'taught': 18.45078747923615,\n",
       " 'import': 10.129880475050593,\n",
       " 'cy': 8.86558547954498,\n",
       " 'bash': 8.391252487438773,\n",
       " 'model question': 7.5192377755537105,\n",
       " 'dont': 6.736122335869252,\n",
       " 'ori': 6.237244524744945,\n",
       " 'pay att': 5.892106774249803,\n",
       " 'managed': 5.667968761458337,\n",
       " 'appreciate it': 5.4971979862144424,\n",
       " 'movem': 5.493191364763877,\n",
       " 'description': 4.72232167362157,\n",
       " 'giv': 4.60183455187465,\n",
       " 'associate': 4.524835173098711,\n",
       " 'would helpful': 4.288056318279742,\n",
       " 'techniques used': 4.278357579154733,\n",
       " 'anyone': 3.9954095082718837,\n",
       " 'gpus': 3.9338860748161366,\n",
       " 'anything': 3.7605122723320403,\n",
       " 'hold': 3.6863199300234735,\n",
       " 'help out': 3.5479203163674766,\n",
       " 'hang': 3.218506696942786,\n",
       " 'while': 3.21137638307645,\n",
       " 'pip install': 3.165893760503456,\n",
       " 'conflict': 3.141370800770972,\n",
       " 'says': 3.124476505209685,\n",
       " 'find answer': 3.09835350621622,\n",
       " 'summit': 2.948528821058937,\n",
       " 'sound': 2.892054492420774,\n",
       " 'perfect': 2.8850707826476745,\n",
       " 'hurt': 2.874371218792244,\n",
       " 'wanna': 2.839393969031551,\n",
       " 'attempts': 2.7998111340810525,\n",
       " 'practitioner': 2.7834876770949015,\n",
       " 'differ tly': 2.7049500979667753,\n",
       " 'calling': 2.6888889967682488,\n",
       " 'mean': 2.6697838532102183,\n",
       " 'negative': 2.6613117353981175,\n",
       " 'ge': 2.650987486040166,\n",
       " 'aclweb anthology': 2.644036313535808,\n",
       " 'evaluate': 2.622954003096648,\n",
       " 'bug': 2.5956136476064566,\n",
       " 'like help': 2.571932370179807,\n",
       " 'medium': 2.5600603835443883,\n",
       " 'tonality': 2.4977319866236103,\n",
       " 'coaching': 2.4471286617120067,\n",
       " 'cross lingual': 2.439121859083451,\n",
       " 'good stuff': 2.4311893883407727,\n",
       " 'correct': 2.4271776368440134,\n",
       " 'james': 2.3998807513370837,\n",
       " 'much appreciated': 2.3997541850549866,\n",
       " 've tried': 2.3940246103433007,\n",
       " 'constraints': 2.3892159736973,\n",
       " 'punctuation': 2.3831354953616315,\n",
       " 'clusters': 2.353535543422715,\n",
       " 'widely used': 2.3292875555763217,\n",
       " 'white': 2.289628070673778,\n",
       " 'tok ize': 2.2870318133191256,\n",
       " 'hello everyone': 2.280972694584179,\n",
       " 'shift': 2.2729600559216783,\n",
       " 'helps': 2.267564382465445,\n",
       " 'category': 2.2447830563878233,\n",
       " 'attributes': 2.2366927967266275,\n",
       " 'support': 2.2357856283742152,\n",
       " 'synthesis': 2.2117685444930704,\n",
       " 'metaphors': 2.211717525666906,\n",
       " 'clip': 2.211291671193084,\n",
       " 'fbclid': 2.20660717932088,\n",
       " 'commercial': 2.202526300245375,\n",
       " 'area life': 2.196645720048963,\n",
       " 'pretrained model': 2.180008377798371,\n",
       " 'edu': 2.177609001566485,\n",
       " 'fr ch': 2.170355976158936,\n",
       " 'heard': 2.1630797721343615,\n",
       " 'comparison': 2.1418913616133306,\n",
       " 'want do': 2.1169721202409106,\n",
       " 'pressure': 2.116737783921838,\n",
       " 'place': 2.112155049004725,\n",
       " 'involved': 2.111718957134374,\n",
       " 'text similarity': 2.1023560903122065,\n",
       " 'standard': 2.0974304412948017,\n",
       " 'fee': 2.0825929348814833,\n",
       " 'derr': 2.0766149618055376,\n",
       " 'question is': 2.0718307719923574,\n",
       " 'integration': 2.029019010263029,\n",
       " 'dilemma': 2.0224600230054874,\n",
       " 'numerous': 2.011733666188318,\n",
       " 'auto webp': 2.011211543010487,\n",
       " 'hidd': 2.0097444186424966,\n",
       " 'relief': 2.0022279620300023,\n",
       " 'patterns': 1.9979237791765674,\n",
       " 'anyways': 1.9970250960899636,\n",
       " 'possible use': 1.994898681741113,\n",
       " 'what': 1.9924902411957308,\n",
       " 'nlp trying': 1.9877216135766096,\n",
       " 'propose': 1.986648930721394,\n",
       " 'andrew': 1.9861287133647296,\n",
       " 'here': 1.970604054205588,\n",
       " 'words': 1.9672075898723937,\n",
       " 'ter': 1.964915365839955,\n",
       " 'share': 1.964915365839955,\n",
       " 'interest': 1.9600621866566927,\n",
       " 'wonderful': 1.9590016861995412,\n",
       " 'tfidf': 1.9408673036805775,\n",
       " 'serious': 1.9353657420992736,\n",
       " 'aspects': 1.932951301192436,\n",
       " 'solely': 1.9261734813560658,\n",
       " 'ac': 1.9236156378484217,\n",
       " 'developm': 1.9013265777382655,\n",
       " 'my': 1.894652197218905,\n",
       " 'languages': 1.886134867869127,\n",
       " 'third': 1.8848216263334976,\n",
       " 'allows': 1.8577165659536214,\n",
       " 'clean': 1.8439918539517728,\n",
       " 'ces using': 1.8432978651690937,\n",
       " 'she': 1.8337014052216645,\n",
       " 'transformer models': 1.8318565885236135,\n",
       " 'advice': 1.8281307948198158,\n",
       " 'leadership': 1.815749651851292,\n",
       " 'how': 1.8138256741296352,\n",
       " 'study nlp': 1.813464496142139,\n",
       " 'table': 1.812290497559467,\n",
       " 'goals': 1.8081561285069105,\n",
       " 'users': 1.8052608522440987,\n",
       " 'compare': 1.802771352388763,\n",
       " 'nlp thanks': 1.7960484657401787,\n",
       " 'nlp projects': 1.7921353968014362,\n",
       " 'rec': 1.7833376871664202,\n",
       " 'processing': 1.780608422799455,\n",
       " 'nlp metaprograms': 1.779191507265921,\n",
       " 'they ve': 1.7758984822870443,\n",
       " 'word segm': 1.7712743610070818,\n",
       " 'community': 1.764930680825655,\n",
       " 'custom': 1.760970921669568,\n",
       " 'needs': 1.7590564463654705,\n",
       " 'topics': 1.7579661352015363,\n",
       " 'female': 1.754766230367783,\n",
       " 'street': 1.7523577886174946,\n",
       " 'marktechpost researchers': 1.7519739649226675,\n",
       " 'resource': 1.750695274272912,\n",
       " 'phrasing': 1.7498143358145446,\n",
       " 'faculty': 1.7462665922513543,\n",
       " 'pres ted': 1.7432214776349655,\n",
       " 'tagging': 1.7426308578389555,\n",
       " 'clear': 1.7419562075378656,\n",
       " 'books': 1.7394245642798096,\n",
       " 'others': 1.7381910608065227,\n",
       " 'looked': 1.7380686560455036,\n",
       " 'docs notebooks': 1.7336818544383674,\n",
       " 'transcripts': 1.7329852138107062,\n",
       " 'followed': 1.7306539856824183,\n",
       " 'thanks': 1.7294955984303002,\n",
       " 'speed': 1.726511322668819,\n",
       " 'amp utm': 1.7217331388977382,\n",
       " 'like it': 1.7214390434592477,\n",
       " 'line': 1.7107551264463516,\n",
       " 'perception': 1.708884582841046,\n",
       " 'useful': 1.7063803130148254,\n",
       " 'presupposition': 1.7052567800426792,\n",
       " 'org': 1.7030229327277286,\n",
       " 'marketing': 1.7027814582485565,\n",
       " 'please': 1.700787668553791,\n",
       " 'cleaning': 1.6989273194158674,\n",
       " 'functions': 1.6973413228639567,\n",
       " 'got': 1.6964220941669486,\n",
       " 'doubt': 1.6948260750915658,\n",
       " 'relationship': 1.6885008801438162,\n",
       " 'assume': 1.6853471726164224,\n",
       " 'door': 1.6808911109234748,\n",
       " 'pypi pip': 1.6807150089041307,\n",
       " 'looking nlp': 1.677766601388045,\n",
       " 'online': 1.6772598397827423,\n",
       " 'europe': 1.6745547440406388,\n",
       " 'tool': 1.6729826984035068,\n",
       " 'see': 1.6708726056264325,\n",
       " 'wall': 1.6703353501071394,\n",
       " 'masked': 1.6651578333508812,\n",
       " 'research project': 1.6599962912526356,\n",
       " 'destructive': 1.659703344084033,\n",
       " 'previously': 1.6557184044205988,\n",
       " 'black': 1.6539448667503054,\n",
       " 'something would': 1.6514225150141304,\n",
       " 'bag words': 1.6490283805201147,\n",
       " 'bell': 1.6444373652974023,\n",
       " 'wonder': 1.6444027184628616,\n",
       " 'psychology': 1.6410124502055177,\n",
       " 'tutorial': 1.6389805404987958,\n",
       " 'finishing': 1.6345331352955628,\n",
       " 'common': 1.6341396765956533,\n",
       " 'par ts': 1.6334567157393287,\n",
       " 'it thanks': 1.632456367240716,\n",
       " 'belong': 1.6321941630365158,\n",
       " 'based text': 1.6308892572345481,\n",
       " 'calculate': 1.6265943603877773,\n",
       " 'humans': 1.6256631212051567,\n",
       " 'question eration': 1.6148687030499784,\n",
       " 'solutions': 1.6127767031959186,\n",
       " 'come': 1.6116179551884138,\n",
       " 'fri ds': 1.6095287420817566,\n",
       " 'format': 1.6085600583905972,\n",
       " 'guys': 1.6057630097499016,\n",
       " 'make': 1.6039730023738696,\n",
       " 'bear': 1.601213828221336,\n",
       " 'german': 1.6010182251850997,\n",
       " 'focus': 1.5991950694274961,\n",
       " 'doz': 1.5988872487763135,\n",
       " 'direct': 1.5982946555707511,\n",
       " 'welcome': 1.5978681974415156,\n",
       " 'experi ces': 1.5972333085043668,\n",
       " 'gpt': 1.5966717497442466,\n",
       " 'trying get': 1.5939479525629527,\n",
       " 'express': 1.5908068980867935,\n",
       " 'us': 1.590569333603416,\n",
       " 'summer': 1.5887462075399705,\n",
       " 'contain': 1.5866557563398545,\n",
       " 'test data': 1.58656390225079,\n",
       " 'request': 1.5817580916403748,\n",
       " 'cant': 1.5803268448778929,\n",
       " 'opportunity': 1.5799953962000224,\n",
       " 'crypto': 1.5798669871851987,\n",
       " 'such': 1.5797459549803243,\n",
       " 'martin': 1.575137904468451,\n",
       " 'annotated': 1.5743582683995108,\n",
       " 'now': 1.5738490793180617,\n",
       " 'tim classification': 1.5725519858673178,\n",
       " 'meet': 1.5716716527936754,\n",
       " 'epochs': 1.570926208972448,\n",
       " 'pdf pdf': 1.5706133297153884,\n",
       " 'done': 1.5682155235175685,\n",
       " 'time': 1.5641755185846253,\n",
       " 'core': 1.5578640545650448,\n",
       " 'besides': 1.5570448783102202,\n",
       " 'lives': 1.556966494771909,\n",
       " 'favorite': 1.5527657204033278,\n",
       " 'recognize': 1.5520028355618387,\n",
       " 'features': 1.5470659975347474,\n",
       " 'correctly': 1.5467519428705592,\n",
       " 'michael': 1.5455825736021358,\n",
       " 'might': 1.5437370928148986,\n",
       " 'later': 1.5425143670855217,\n",
       " 'modern': 1.5423221803605967,\n",
       " 'lesson': 1.5402411000511604,\n",
       " 'picture': 1.5401992330382144,\n",
       " 'pdf': 1.5395844527032077,\n",
       " 'suggestions': 1.5385566463141687,\n",
       " 'floor': 1.537784177806564,\n",
       " 'high': 1.5377744612746087,\n",
       " 'json': 1.534483943812964,\n",
       " 'comfortable': 1.5291566923684659,\n",
       " 'level': 1.5269397110722953,\n",
       " 'contact': 1.5232827962543245,\n",
       " 'want work': 1.5220371328788265,\n",
       " 'compute': 1.5215873002339286,\n",
       " 'flow': 1.5212714216061318,\n",
       " 'scratch': 1.518071212986203,\n",
       " 'post amp': 1.517180759998394,\n",
       " 'movie': 1.5155536151306164,\n",
       " 'huggingface models': 1.5147832522735447,\n",
       " 'want use': 1.5143638990339159,\n",
       " 'eye': 1.5135374392628516,\n",
       " 'bug caused': 1.5126357353783544,\n",
       " 'goal': 1.5119608164081064,\n",
       " 'question': 1.5109500524114712,\n",
       " 'leader': 1.5108834915083003,\n",
       " 'criteria': 1.5102757919514962,\n",
       " 'using transformers': 1.5091222197247736,\n",
       " 'presid': 1.5086912617871318,\n",
       " 'least': 1.5067540568327518,\n",
       " 'achieving': 1.5048804144613688,\n",
       " 'random': 1.5028276259532605,\n",
       " 'behavior': 1.5027993721775603,\n",
       " 'careful': 1.5024912453281096,\n",
       " 'github research': 1.5022105558559569,\n",
       " 'said': 1.500460428794441,\n",
       " 'normalization': 1.4997954617386555,\n",
       " 'tech': 1.4985270520185578,\n",
       " 'showcase': 1.4979112237602572,\n",
       " 'american': 1.4973776019808633,\n",
       " 'ce positive': 1.4972685454306232,\n",
       " 'possible': 1.4966180303479173,\n",
       " 'lemma': 1.49658349257309,\n",
       " 'manner': 1.494642796294676,\n",
       " 'workshop': 1.4920732137777708,\n",
       " 'germany': 1.49124347291333,\n",
       " 'consist': 1.4905077326360778,\n",
       " 'pyspark conda': 1.4890870962489335,\n",
       " 'tl': 1.4867946483754029,\n",
       " 'mindfulness': 1.4864909772493955,\n",
       " 'tools': 1.4863292478854755,\n",
       " 'metric': 1.4838027683838648,\n",
       " 'fasttext': 1.4822515342818776,\n",
       " 'think': 1.4822301504950552,\n",
       " 'respectively': 1.4821779614182848,\n",
       " 'cnn': 1.4799676897299354,\n",
       " 'kinesthetic': 1.4783224950658385,\n",
       " 'facebook': 1.4771386968292322,\n",
       " 'incorrectly': 1.4771386968292322,\n",
       " 'tiny': 1.4759375550146507,\n",
       " 'foreign': 1.4756784350015721,\n",
       " 'bad': 1.4743686279252104,\n",
       " 'date': 1.4725367482541005,\n",
       " 'models amp': 1.470872615901512,\n",
       " 'transfer': 1.4705323195850861,\n",
       " 'instagram': 1.468008943329007,\n",
       " 'th get': 1.465784233642236,\n",
       " 'deep learning': 1.465058756487061,\n",
       " 'built': 1.464085971547295,\n",
       " 'word embeddings': 1.4639096400817164,\n",
       " 'naive': 1.4609371473526325,\n",
       " 'form': 1.4579033521176366,\n",
       " 'london': 1.45726689550363,\n",
       " 'programming languages': 1.4542892047097384,\n",
       " 'efits': 1.4542735446700994,\n",
       " 'industry': 1.4530556464034914,\n",
       " 'vironm': 1.4526054286252943,\n",
       " 'hope': 1.4520724828782015,\n",
       " 'pretraining': 1.451423579155574,\n",
       " 'approaches': 1.4478205996086984,\n",
       " 'studying': 1.4471485735361054,\n",
       " 'practice': 1.445174444263059,\n",
       " 'minimal': 1.4448134050109234,\n",
       " 'ways': 1.4445194366850362,\n",
       " 'humanities': 1.444273457581082,\n",
       " 'leads': 1.4433820416499599,\n",
       " 'casual': 1.4419138632473183,\n",
       " 'title says': 1.4413426558225737,\n",
       " 'resistance': 1.4393180573504252,\n",
       " 'main': 1.4389356555768835,\n",
       " 'reads': 1.4371475687575384,\n",
       " 'milton': 1.4365968983206399,\n",
       " 'psychotherapy': 1.4360629432312864,\n",
       " 'side': 1.4359333221155361,\n",
       " 'governm': 1.4347061434929314,\n",
       " 'toward': 1.4347061434929314,\n",
       " 'anyone good': 1.4321175474866699,\n",
       " 'augm': 1.431210698023314,\n",
       " 'methods used': 1.4312020307327797,\n",
       " 'really want': 1.4288063210026678,\n",
       " 'completely': 1.4276733882052737,\n",
       " 'segm': 1.427329631970763,\n",
       " 'trained models': 1.4262169504465738,\n",
       " 'ext ded': 1.4217210957214255,\n",
       " 'therapy': 1.4211616471156556,\n",
       " 'improved': 1.4210370996539001,\n",
       " 'desired': 1.4198465202633437,\n",
       " 'come mind': 1.4191079260562762,\n",
       " 'nlp technique': 1.4186969862361916,\n",
       " 'doable': 1.4181450590362574,\n",
       " 'source amp': 1.416933632519657,\n",
       " 'fixed': 1.4164541206202514,\n",
       " 'before': 1.4163042009369282,\n",
       " 'really': 1.415401452011986,\n",
       " 'discovered': 1.4150066305220996,\n",
       " 'imdb': 1.4145798940703904,\n",
       " 'preferably': 1.4124201339953446,\n",
       " 'alexa': 1.4109796396145935,\n",
       " 'failure': 1.409622278981799,\n",
       " 'implem tation': 1.4082013369948188,\n",
       " 'assistant': 1.4078935437709579,\n",
       " 'fast': 1.4076759290791216,\n",
       " 'but': 1.406818773476195,\n",
       " 'made': 1.4066900848381436,\n",
       " 'classifying': 1.4057786561700847,\n",
       " 'sets': 1.4056432302533366,\n",
       " 'semantic': 1.4040332796599286,\n",
       " 'artificial intellig': 1.4015036727205934,\n",
       " 'course nlp': 1.3995073706430667,\n",
       " 'fixed bug': 1.3991683638605048,\n",
       " 'tal': 1.3984494327073795,\n",
       " 'models use': 1.3975089703877615,\n",
       " 'translation': 1.3973289406641807,\n",
       " 'offered': 1.3973035730288175,\n",
       " 'entity': 1.3970119862369785,\n",
       " 'based models': 1.3969973735465995,\n",
       " 'acuity': 1.396482499061689,\n",
       " 'totally': 1.3954212358132039,\n",
       " 'logical': 1.3939006180306515,\n",
       " 'thank you': 1.392623084266618,\n",
       " 'another': 1.3909617535160126,\n",
       " 'paragraph': 1.388651317816344,\n",
       " 'japanese': 1.3884252812716482,\n",
       " 'be hero': 1.3880723586130852,\n",
       " 'time nlp': 1.3842756397227645,\n",
       " 'greatly appreciated': 1.3835655330213712,\n",
       " 'forgive': 1.3835583678674872,\n",
       " 'within': 1.38327856745624,\n",
       " 'mirror': 1.381160849306489,\n",
       " 'hance': 1.379214399649483,\n",
       " 'something could': 1.3787721204941223,\n",
       " 'gains': 1.3776055998782284,\n",
       " 'korean': 1.377228661010716,\n",
       " 'growth': 1.3767996530565692,\n",
       " 'kindly': 1.3763661327864303,\n",
       " 'filter': 1.3755991974434867,\n",
       " 'get': 1.3755542137136731,\n",
       " 'decade': 1.375140902047581,\n",
       " 'significantly': 1.3741550276722694,\n",
       " 'excited announce': 1.3721805361006516,\n",
       " 'utilize': 1.3685711020240092,\n",
       " 'ergy': 1.368539663238488,\n",
       " 'apis': 1.3685014052545044,\n",
       " 'hugging': 1.3674645258342246,\n",
       " 'nlp nlu': 1.3670157603460216,\n",
       " 'onto': 1.3669508281359546,\n",
       " 'ges': 1.3669365215148253,\n",
       " 'xb thanks': 1.3661076934278251,\n",
       " 'would much': 1.3655490066361187,\n",
       " 'nlp applications': 1.365167028379379,\n",
       " 'mind': 1.3633377812533107,\n",
       " 'reverse': 1.3633246047042777,\n",
       " 'things': 1.3632909415728727,\n",
       " 'known': 1.3630916368161146,\n",
       " 'errors': 1.3628857958430145,\n",
       " 'total': 1.3626488511258017,\n",
       " 'likely': 1.3613941922643098,\n",
       " 'interaction': 1.360964785887848,\n",
       " 'tions': 1.360927656038886,\n",
       " 'techniques nlp': 1.3588950548661045,\n",
       " 'please help': 1.3578953773977458,\n",
       " 'released': 1.3574569606333178,\n",
       " 'id tifying': 1.3571783514349143,\n",
       " 'messages': 1.3567972400403154,\n",
       " 'ms': 1.356503459479801,\n",
       " 'cosine': 1.3562170324723963,\n",
       " 'thinks': 1.3546680999659486,\n",
       " 'research': 1.3525073870313793,\n",
       " 'someone knows': 1.3510513181742425,\n",
       " 'chall ge': 1.3505515165592046,\n",
       " 'bert pre': 1.3503722864624677,\n",
       " 'der': 1.3502090444738208,\n",
       " 'reading book': 1.3497085211115158,\n",
       " 'mood': 1.3490395123010968,\n",
       " 'tal health': 1.348960291621201,\n",
       " 'pytorch': 1.348776624195694,\n",
       " 've done': 1.3477298632764607,\n",
       " 'classification problem': 1.3475060873439753,\n",
       " 'code github': 1.3469587910829446,\n",
       " 'structures': 1.3468572260701233,\n",
       " 'classification using': 1.345911238288124,\n",
       " 'you ll': 1.3454262813209252,\n",
       " 'solution': 1.3453224715511127,\n",
       " 'supported': 1.344716322068365,\n",
       " 'sive': 1.344647352606474,\n",
       " 'exact': 1.3444231499204278,\n",
       " 'anyone would': 1.3428427137933452,\n",
       " 'requires': 1.3419935056733334,\n",
       " 'model wh': 1.3419199820549037,\n",
       " 'source code': 1.3418594813722757,\n",
       " 'reasons': 1.3418394486838428,\n",
       " 'images': 1.340269607062685,\n",
       " 'interpret': 1.3399149126559213,\n",
       " 'pictures': 1.3385333301839932,\n",
       " 'like that': 1.3382286492154734,\n",
       " 'tim analysis': 1.3378916779975587,\n",
       " 'tree': 1.336894985219978,\n",
       " 'trauma': 1.3367734516085492,\n",
       " 'presuppositions': 1.3364864845056652,\n",
       " 'att ding': 1.33597669849549,\n",
       " 'forward': 1.3353752922786126,\n",
       " 'virus day': 1.3352566606935925,\n",
       " 'mode': 1.3341674921744815,\n",
       " 'next week': 1.3341390886062765,\n",
       " 'undergraduate': 1.3330222561831702,\n",
       " 'exercise': 1.3327603962836954,\n",
       " 'marktechpost': 1.3322355101953136,\n",
       " 'happy': 1.331373591818291,\n",
       " 'mirroring amp': 1.3304603201425607,\n",
       " 'dear': 1.3300933915687956,\n",
       " 'extraction': 1.3293617921537242,\n",
       " 'male': 1.3291236840813097,\n",
       " 'relevant': 1.3284160969348882,\n",
       " 'differ ces': 1.3260392932490386,\n",
       " 'seminars': 1.3253255287121966,\n",
       " 'number': 1.3251778049437628,\n",
       " 'amazing': 1.322712751585676,\n",
       " 'conv': 1.3221181104475472,\n",
       " 'let know': 1.3221125313757025,\n",
       " 'hopefully': 1.3216760682112558,\n",
       " 'blog post': 1.321656953975388,\n",
       " 'chunk': 1.320569393094596,\n",
       " 'walkthrough': 1.320171936846726,\n",
       " 'johnsnowlabs nlu': 1.3199244022243934,\n",
       " 'guided': 1.3197998159071174,\n",
       " 'mess': 1.319737263990773,\n",
       " 'heart': 1.3193800526916486,\n",
       " 'measures': 1.3192669029099944,\n",
       " 'honestly': 1.3187559715509294,\n",
       " 'politics': 1.316781798305346,\n",
       " 'squad': 1.3155795455919004,\n",
       " 'why': 1.3148460161696929,\n",
       " 'native': 1.314749814145444,\n",
       " 'efit': 1.3140336209878367,\n",
       " 'friday': 1.3129815032807648,\n",
       " 'front': 1.3128911324745063,\n",
       " 'anchor': 1.3126056295053259,\n",
       " 'andreas': 1.3123513754845393,\n",
       " 'conclusion': 1.3123311279423315,\n",
       " 'implem': 1.3121884910582642,\n",
       " 'purposes': 1.3121059057387245,\n",
       " 'second': 1.3115556655760108,\n",
       " 'pros': 1.310365999596309,\n",
       " 'amount': 1.3100030388643478,\n",
       " 'familiar': 1.307987295019869,\n",
       " 'source': 1.3076769702615882,\n",
       " 'learning rate': 1.307529848396392,\n",
       " 'lot time': 1.3074435802669118,\n",
       " 'life coaches': 1.307404059325934,\n",
       " 'ess': 1.307108581092851,\n",
       " 'sure use': 1.3069217904522195,\n",
       " 'etc': 1.304718373326381,\n",
       " 'pretrained': 1.3046309080168,\n",
       " 'expertise': 1.3045094674835789,\n",
       " 'sure': 1.3044786403192343,\n",
       " 'publicly available': 1.3044471248239362,\n",
       " 'linear algebra': 1.3015120523455432,\n",
       " 'classes': 1.3013489663267943,\n",
       " 'less': 1.3009000726990514,\n",
       " 'search': 1.3000623631057362,\n",
       " 'teams': 1.2987849999749455,\n",
       " 'categorize': 1.298554462175944,\n",
       " 'opposed': 1.2979652395054777,\n",
       " 'hard': 1.2969219884064367,\n",
       " 'no': 1.296526549210881,\n",
       " 'keyword': 1.2961858998288,\n",
       " 'english nlp': 1.2952935680489188,\n",
       " 'me': 1.2937232263366196,\n",
       " 'these': 1.2936368569135177,\n",
       " 'avoid': 1.2924303736516032,\n",
       " 'tübing': 1.2920094375613174,\n",
       " 'guy': 1.2914225600498725,\n",
       " 'bart large': 1.2913311478381502,\n",
       " 'wise': 1.2910062037835313,\n",
       " 'learning': 1.2908936200889445,\n",
       " 'act': 1.2905035337458592,\n",
       " 'graduated': 1.289958586288395,\n",
       " 'four': 1.289767509474493,\n",
       " 'therapists': 1.289767509474493,\n",
       " 'matter': 1.289767509474493,\n",
       " 'trying understand': 1.2896497748318252,\n",
       " 'tim classifier': 1.2895663806664883,\n",
       " 'install nlu': 1.2895663806664883,\n",
       " 'wish': 1.2895101387959844,\n",
       " 'learning nlp': 1.2892857808504958,\n",
       " 'ignorance': 1.2884505452144508,\n",
       " 'organization': 1.2883821225134355,\n",
       " 'intermediate': 1.2868592532261451,\n",
       " 'guide': 1.286815471415061,\n",
       " 'non': 1.2865173983711633,\n",
       " 'like learn': 1.285836836961016,\n",
       " 'tific': 1.2857358918111124,\n",
       " 'sc ario': 1.2852869472465471,\n",
       " 'matching': 1.2852082552845177,\n",
       " 'mostly': 1.2851719309819425,\n",
       " 'solving': 1.284075788735572,\n",
       " 'installation bash': 1.2836329811091005,\n",
       " 'graphs': 1.2824626687640264,\n",
       " 'equal': 1.282245140425768,\n",
       " 'hope find': 1.2820341251815828,\n",
       " 'occurr': 1.2819161069419198,\n",
       " 'real world': 1.2816651530735366,\n",
       " 'believe': 1.2805262154339032,\n",
       " 'webp amp': 1.2805262154339032,\n",
       " 'gott': 1.2805262154339032,\n",
       " 'repres tation': 1.280518586007635,\n",
       " 'installed': 1.2799665674976506,\n",
       " 'workflow': 1.2798415837350858,\n",
       " 'notebooks nlu': 1.2798415837350858,\n",
       " 'this': 1.2792299833355252,\n",
       " 'nlp would': 1.279094726339206,\n",
       " 'nlu videos': 1.278544737733702,\n",
       " 'accurate': 1.2779727285490559,\n",
       " 'communication': 1.2773579481166215,\n",
       " 'claims': 1.2771636086676588,\n",
       " 'purpose': 1.2765030668111614,\n",
       " 'layer': 1.276402836355079,\n",
       " 'hesitate': 1.2760082099837853,\n",
       " 'smoking': 1.2759440449192505,\n",
       " 'services': 1.2738013958810601,\n",
       " 'want': 1.273768088306224,\n",
       " 'forums': 1.2734373362589524,\n",
       " 'extract': 1.2731505181571339,\n",
       " 'company': 1.2726803775016031,\n",
       " 'parser': 1.2726440860926742,\n",
       " 'nlp trainers': 1.2720747377446515,\n",
       " 'schools': 1.2712406585238705,\n",
       " 'exam': 1.2709384868574929,\n",
       " 'dep': 1.2707443085987837,\n",
       " 'use model': 1.2697830971334143,\n",
       " 'treat': 1.2696879166354886,\n",
       " 'retrieval': 1.2695181800246664,\n",
       " 'skilled': 1.2694521695185998,\n",
       " 'udemy': 1.2691487692486938,\n",
       " 'neural networks': 1.2689475240978239,\n",
       " 'software': 1.2687016836663272,\n",
       " 'pot': 1.2686361194473212,\n",
       " 'average': 1.268102895810476,\n",
       " 'medication': 1.2676998487457025,\n",
       " 'using word': 1.2672897431736694,\n",
       " 'johnsnowlabs docs': 1.2669902918366585,\n",
       " 'opportunities': 1.2657562589129383,\n",
       " 'experim ts': 1.2651019775901342,\n",
       " 'true': 1.264552960682536,\n",
       " 'affect': 1.2641302525631115,\n",
       " 'real time': 1.2638243462023364,\n",
       " 'talk': 1.2634243591528178,\n",
       " 'straightforward': 1.26237415217692,\n",
       " 'posts': 1.2620293151603639,\n",
       " 'def': 1.2610602013290295,\n",
       " 'models nlu': 1.2610167126929348,\n",
       " 'universal': 1.2605201408795697,\n",
       " 'customer': 1.2603522629984725,\n",
       " 'proof': 1.2603428982882061,\n",
       " 'keynote': 1.2598570158221791,\n",
       " 'val': 1.2594180334724994,\n",
       " 'united': 1.259342522916228,\n",
       " 'something similar': 1.2593129823321343,\n",
       " 'showed': 1.2591409596944139,\n",
       " 'becoming': 1.2587390779986944,\n",
       " 'stupid': 1.2567776008586569,\n",
       " 'analysis andrew': 1.2559826494682518,\n",
       " 'all nlu': 1.2531353971319459,\n",
       " 'augm tation': 1.2518607794104297,\n",
       " 'million': 1.2516060684438428,\n",
       " 'johnsnowlabs': 1.2512202087951727,\n",
       " 'amp': 1.2510089734696146,\n",
       " 'sota': 1.2508310677763756,\n",
       " 'knowing': 1.2502711414754957,\n",
       " 'part speech': 1.2501225901352089,\n",
       " 'eral': 1.2499328412081139,\n",
       " 'basic': 1.2485707364151726,\n",
       " 'corresponding': 1.2485558769381215,\n",
       " 'notebook': 1.2485106186761112,\n",
       " 'tagger': 1.2484578485321096,\n",
       " 'we re': 1.2484561835527994,\n",
       " 'brief': 1.2483613664296183,\n",
       " 'summarize text': 1.2478428886637283,\n",
       " 'biobert': 1.2477435785190838,\n",
       " 'affirmations': 1.2475963078704055,\n",
       " 'actual': 1.2473237531150758,\n",
       " 'hi curr': 1.2458188449066836,\n",
       " 'floating': 1.2456558621287734,\n",
       " 'admin': 1.2454723199214663,\n",
       " 'basically': 1.24500627177507,\n",
       " 'lasting': 1.2449143667128275,\n",
       " 'applied': 1.2445133736218321,\n",
       " 'pythons': 1.244264486755496,\n",
       " 'hey everyone': 1.2441030055061184,\n",
       " 'stop': 1.2436848245719487,\n",
       " 'naacl': 1.2436848245719487,\n",
       " 'incredibly': 1.2434960274762596,\n",
       " 'coaches': 1.2434605619404422,\n",
       " 'self': 1.2434469600638192,\n",
       " 'similarity': 1.2433190709785529,\n",
       " 'using python': 1.243312707226593,\n",
       " 'mind amp': 1.2432313869750895,\n",
       " 'good things': 1.2431734642433199,\n",
       " 'textual': 1.2406956900253698,\n",
       " 'scre': 1.2405816961267582,\n",
       " 'int tion': 1.2403775906567363,\n",
       " 'bert model': 1.2400583614129126,\n",
       " 'half': 1.2399689120230803,\n",
       " 'domain': 1.2390713832598153,\n",
       " 'wh get': 1.2390397737443053,\n",
       " 'side project': 1.2386841483454811,\n",
       " 'game': 1.2383304784896754,\n",
       " 'physical': 1.2372001806366169,\n",
       " 'nlp community': 1.2368665137709105,\n",
       " 'knowledge graph': 1.2367602274373064,\n",
       " 'networking': 1.2363445861018207,\n",
       " 'fix': 1.2362399067148448,\n",
       " 'chatbots': 1.2359515136608847,\n",
       " 'extremely': 1.2358236013289294,\n",
       " 'podcasts': 1.2355964221561133,\n",
       " 'extract keywords': 1.2350470232948132,\n",
       " 'tly got': 1.2346569817036697,\n",
       " 'ess tial': 1.23443805214408,\n",
       " 'model would': 1.2344198409540654,\n",
       " 'repres tations': 1.2341006601883189,\n",
       " 'combination': 1.2339714975084917,\n",
       " 'using bert': 1.2335670439438446,\n",
       " 'publications': 1.2329259016191076,\n",
       " 'twitter': 1.232828432208874,\n",
       " 'tirely': 1.2322685848225503,\n",
       " 'sion': 1.2322601601193621,\n",
       " 'life coach': 1.232259859416885,\n",
       " 'grinder': 1.2320367375279277,\n",
       " 'and': 1.2310826870589415,\n",
       " 'take account': 1.2309943543200823,\n",
       " 'train model': 1.2303283245508385,\n",
       " 'ask question': 1.2302329430709462,\n",
       " 'wellbeing': 1.229905583250927,\n",
       " 'analyzing': 1.2294395966766098,\n",
       " 'early': 1.2289321501903856,\n",
       " 'parts': 1.2288811193408546,\n",
       " 'change way': 1.2285080044734082,\n",
       " 'behaviors': 1.2284520608184346,\n",
       " 'alongside': 1.2283702219841284,\n",
       " 'responsible': 1.2268609556839967,\n",
       " 'real': 1.2266532795645517,\n",
       " 'decision': 1.2262306548710875,\n",
       " 'received': 1.2251604323814667,\n",
       " 'hav': 1.224808176537914,\n",
       " 'sophisticated': 1.224494204166538,\n",
       " 'could': 1.224285284684717,\n",
       " 'submodalities': 1.2233819957525252,\n",
       " 'sleep': 1.2231802935922371,\n",
       " 'nlp think': 1.2231015623121255,\n",
       " 'social': 1.222565070618057,\n",
       " 'call': 1.2225315712654707,\n",
       " 'brown': 1.2223074253659847,\n",
       " 'clearly': 1.2218849322460972,\n",
       " 'positive': 1.2217089987014715,\n",
       " 'sample': 1.2216087972455822,\n",
       " 'file': 1.221382132899679,\n",
       " 'mastery': 1.2211695390929438,\n",
       " 'uk': 1.2210970626336728,\n",
       " 'nlu johnsnowlabs': 1.2210667156691601,\n",
       " 'training': 1.2209147122412354,\n",
       " 'wordvec': 1.220859976848211,\n",
       " 'answer': 1.2205480245037945,\n",
       " 'feasible': 1.2203449503724777,\n",
       " 'taking': 1.220286556624636,\n",
       " 'training set': 1.219950583209839,\n",
       " 'want make': 1.2198468805649625,\n",
       " 'redd': 1.218474667907772,\n",
       " 'checking': 1.2184312086977331,\n",
       " 'ml dl': 1.2181303642060395,\n",
       " 'quick': 1.2176566498587933,\n",
       " 'everything': 1.217172775555754,\n",
       " 'richard bandler': 1.2170029333094063,\n",
       " 'cues': 1.216467475861894,\n",
       " 'cv': 1.2163138529520072,\n",
       " 'skype': 1.2162462013439146,\n",
       " 'nlu pyspark': 1.2153019023866158,\n",
       " 'please let': 1.2151897893865815,\n",
       " 'release notes': 1.2150983719479158,\n",
       " 'mouth': 1.2149323804860404,\n",
       " 'roles': 1.21465275751723,\n",
       " 'unfortunately': 1.2144911233695639,\n",
       " 'work well': 1.214359487662859,\n",
       " 'model thinking': 1.2142882786596771,\n",
       " 'tional': 1.2139940892822045,\n",
       " 'that': 1.2135853948817634,\n",
       " 'body': 1.2135853948817634,\n",
       " 'could someone': 1.2135519399090395,\n",
       " 'xb thank': 1.2133859783335164,\n",
       " 'ones': 1.2133140311418589,\n",
       " 'rather': 1.2132238080827924,\n",
       " 'days': 1.2132027242276333,\n",
       " 'causes': 1.21274810863679,\n",
       " 'accuracy': 1.2127373895958293,\n",
       " 'structure': 1.2127300959492355,\n",
       " 'feel free': 1.2125234775817093,\n",
       " 'guidance': 1.2124938091050068,\n",
       " 'conc': 1.212192376990965,\n",
       " 'bash pypi': 1.212178120644801,\n",
       " 'grown': 1.2115411431395624,\n",
       " 'info': 1.2111059198013783,\n",
       " 'variations': 1.2107487302436772,\n",
       " 'treated': 1.210264366473928,\n",
       " 'long take': 1.2101661048466161,\n",
       " 'abstractive': 1.2101636205980117,\n",
       " 'definitely': 1.2100811146940327,\n",
       " 'about': 1.2099950868301184,\n",
       " 'members': 1.2094377509727319,\n",
       " 'many people': 1.209316030272091,\n",
       " 'group': 1.2088421084160226,\n",
       " 'normal': 1.208713056386305,\n",
       " 'tly using': 1.2080828348729287,\n",
       " 'worth': 1.2074643207153308,\n",
       " 'ce amp': 1.206586720595354,\n",
       " 'therefore': 1.2058307792090062,\n",
       " 'looking': 1.2053777653986468,\n",
       " 'tists': 1.2053279622750408,\n",
       " 'passed': 1.204864142527323,\n",
       " 'thousands': 1.204689576854192,\n",
       " 'nlu release': 1.2043557770542392,\n",
       " 'programs': 1.2043243998344426,\n",
       " 'inclined': 1.204249608774157,\n",
       " 'api': 1.2038712204033617,\n",
       " 'meta model': 1.2035727064007748,\n",
       " 'recomm dation': 1.2031738633543736,\n",
       " 'mistake': 1.2029287587473407,\n",
       " 'family': 1.2026800785107763,\n",
       " 'confusion': 1.2024930903598958,\n",
       " 'pre trained': 1.2024341270002485,\n",
       " 'collected': 1.2023201995763542,\n",
       " 'steps': 1.201793258624941,\n",
       " 'process': 1.201132159273426,\n",
       " 'test set': 1.200866971337756,\n",
       " 'acceptable': 1.200832080647063,\n",
       " 'paragraphs': 1.2005376127802627,\n",
       " 'pipelines': 1.2000612815486165,\n",
       " 'heavily': 1.1998868641419558,\n",
       " 'detailed': 1.1997895321432162,\n",
       " 'defining': 1.1995583427158953,\n",
       " 'ask': 1.1994479610903803,\n",
       " 'compreh sive': 1.1990289838464727,\n",
       " 'drugs': 1.1990172074001462,\n",
       " 'upcoming': 1.1989650815695336,\n",
       " 'detected': 1.1983340181601925,\n",
       " 'train': 1.198168508940513,\n",
       " 'putting': 1.197688981521137,\n",
       " 'amp nlp': 1.1974864009413781,\n",
       " 'your': 1.1972919424103616,\n",
       " 'could point': 1.1969598232131295,\n",
       " 'nlu nlp': 1.1967251121557276,\n",
       " 'mix': 1.1965728477601334,\n",
       " 'metaprograms episode': 1.1964428781718417,\n",
       " 'jobs': 1.1964356712981283,\n",
       " 'transition': 1.196336855193997,\n",
       " 'gth': 1.1961855391080476,\n",
       " 'mixing': 1.1959026617263355,\n",
       " 'set': 1.1953742725856846,\n",
       " 'isn': 1.195370134901389,\n",
       " 'robbins': 1.1944947768399978,\n",
       " 'text example': 1.1944187216259492,\n",
       " 'loaded': 1.194341486818531,\n",
       " 'one thing': 1.1938865914214762,\n",
       " 'trying extract': 1.193691846044222,\n",
       " 'apple': 1.1932242364920533,\n",
       " 'external': 1.191693964267008,\n",
       " 'hypnosis nlp': 1.1916349987845911,\n",
       " 'automated': 1.1916229209793243,\n",
       " 'black white': 1.1914417791028276,\n",
       " 'monday': 1.1910506358551993,\n",
       " 'xlnet': 1.1909079089016188,\n",
       " 'pointing': 1.1908246845175103,\n",
       " 'drug': 1.1906482928356332,\n",
       " 'wouldn': 1.1904418811367137,\n",
       " 'ables': 1.1902647534277055,\n",
       " 'motivation': 1.1894843736407652,\n",
       " 'unique': 1.189445384265288,\n",
       " 'structured': 1.1893825129120361,\n",
       " 'usage': 1.189216422122864,\n",
       " 'create new': 1.1891658290465454,\n",
       " 'ce spark': 1.18870623983432,\n",
       " 'experi ce': 1.1887058870317795,\n",
       " 'translating': 1.1886290145668184,\n",
       " 'unsure': 1.1885803719080992,\n",
       " 'project': 1.1885684600679276,\n",
       " 'compon ts': 1.1877957675444835,\n",
       " 'decoding': 1.1876585109208693,\n",
       " 'move towards': 1.1872086990243105,\n",
       " 'like get': 1.1869126233497032,\n",
       " 'needed': 1.1866250801424312,\n",
       " 'material': 1.1862384510991295,\n",
       " 'colab': 1.186048466152357,\n",
       " 'showing': 1.1855433271652491,\n",
       " 'ize': 1.1848471100746643,\n",
       " 'nlp research': 1.183937732382849,\n",
       " 'knows': 1.18377822971794,\n",
       " 'nlp tasks': 1.1837198618519387,\n",
       " 'input': 1.1836965935526231,\n",
       " 'shows': 1.1836255328373861,\n",
       " 'rarely': 1.1836159961102457,\n",
       " 'tried using': 1.1835300899413808,\n",
       " 'steve andreas': 1.183031269157213,\n",
       " 'related nlp': 1.1827865383645177,\n",
       " 'question giv': 1.1827818211853407,\n",
       " 'upon': 1.1826377133855452,\n",
       " 'decode': 1.182484437593539,\n",
       " 'wont': 1.1822891157936533,\n",
       " 'problem is': 1.1819393371738334,\n",
       " 'speakers': 1.181837504816957,\n",
       " 'section': 1.181684564816612,\n",
       " 'bart': 1.1815585884741093,\n",
       " 'preview redd': 1.1811573571122198,\n",
       " 'suggestion': 1.1805418339358684,\n",
       " 'lifestyle': 1.1804007060154509,\n",
       " 'soon': 1.1802890029328739,\n",
       " 'click': 1.180010680772049,\n",
       " 'data augm': 1.1799694764769302,\n",
       " 'fully': 1.179585480117108,\n",
       " 'influ cing': 1.1789240820454527,\n",
       " 'subconscious': 1.1787468724795114,\n",
       " 'classifiers': 1.178683892838181,\n",
       " 'id tify': 1.1784711594009738,\n",
       " 'strongly': 1.178126641574462,\n",
       " 'nlp': 1.1780340970723338,\n",
       " 'python': 1.1778036995507257,\n",
       " 'cases': 1.1775354106243918,\n",
       " 'stuck': 1.1774042968504081,\n",
       " 'whether': 1.1773247130550943,\n",
       " 'initially': 1.1773088755016887,\n",
       " 'evaluating': 1.1771827264287065,\n",
       " 'decisions': 1.177164981527988,\n",
       " 'across': 1.1769566039437365,\n",
       " 'gage': 1.1769224030527483,\n",
       " 'final': 1.1769074832920474,\n",
       " 'kept': 1.1769049492215378,\n",
       " 'pursuing': 1.1765097701521268,\n",
       " 'necessarily': 1.1762243721373393,\n",
       " 'msc': 1.1762195052761213,\n",
       " 'fits': 1.1762189019315785,\n",
       " 'pay': 1.1759164062610397,\n",
       " 'anyone ideas': 1.1756045233620758,\n",
       " 'addition': 1.1755679902037497,\n",
       " 'assuming': 1.1749531250595362,\n",
       " 'system': 1.1746678957454066,\n",
       " 'modelling': 1.1746016156331252,\n",
       " 'subset': 1.1745179547416005,\n",
       " 've also': 1.173844596918026,\n",
       " 'floating around': 1.1737164555314032,\n",
       " 'behaviour': 1.1736057420270014,\n",
       " 'load': 1.173587042090273,\n",
       " 'it possible': 1.173380130726291,\n",
       " 'welcome thanks': 1.1729325054241362,\n",
       " 'google ai': 1.172455022374316,\n",
       " 'developing': 1.1723086251380355,\n",
       " 'balance': 1.171507941722131,\n",
       " 'project need': 1.1711976067363263,\n",
       " 'll': 1.1710932699692347,\n",
       " 'pretty good': 1.1708548441447424,\n",
       " 'sort': 1.1706980595465508,\n",
       " 'extractor': 1.170663577139933,\n",
       " 'expected': 1.1706370848682184,\n",
       " 'performing': 1.1706249497990837,\n",
       " 'chatbot': 1.1704523521937515,\n",
       " 'ds': 1.1702535379394676,\n",
       " 'variable': 1.1695602578125173,\n",
       " 'closed': 1.16952472628354,\n",
       " 'march': 1.1690095849438744,\n",
       " 'towardsdatasci ce': 1.168727327806121,\n",
       " 'recognition': 1.168714579750974,\n",
       " 'doctor': 1.1686423264584704,\n",
       " 'dealing': 1.1683001382779243,\n",
       " 'in': 1.1682307330828032,\n",
       " 'mediums': 1.1680925341531134,\n",
       " 'on': 1.167865989613726,\n",
       " 'cannot': 1.1676266954502235,\n",
       " 'despite': 1.1674010404703115,\n",
       " 'sory': 1.16699608045192,\n",
       " 'computer vision': 1.1669805212582294,\n",
       " 'volume': 1.1664934840612733,\n",
       " 'wrote': 1.165815646030032,\n",
       " 'free': 1.1657938559766934,\n",
       " 'ting': 1.165220605483544,\n",
       " 'automatically': 1.1651083447855277,\n",
       " 'connecting': 1.1650361655388282,\n",
       " 'betwe words': 1.1645383288435043,\n",
       " 'life': 1.164198214529829,\n",
       " 'designed': 1.1640795379749613,\n",
       " 'setup': 1.1639112832867269,\n",
       " 'script': 1.1638136794762504,\n",
       " 'hey all': 1.163635936862019,\n",
       " 'part': 1.1633655742461706,\n",
       " 'multilingual': 1.1628868901953822,\n",
       " 'start': 1.1627394496900536,\n",
       " 'thanks lot': 1.1624277064188977,\n",
       " 'amounts': 1.1622295907954543,\n",
       " 'eye accessing': 1.1620178778918875,\n",
       " 'modules': 1.1617677728526423,\n",
       " 'slightly': 1.1612280600871059,\n",
       " 'researchers': 1.1611658716759934,\n",
       " 'php': 1.1609424688189447,\n",
       " 'hey': 1.160845056194942,\n",
       " 'both': 1.1607636552234741,\n",
       " 'kinda': 1.1605912189469623,\n",
       " 'requests': 1.1605349114160177,\n",
       " 'pdfs': 1.1602879460395141,\n",
       " 'processes': 1.1601183114428049,\n",
       " 'did': 1.1601065752673718,\n",
       " 'remove': 1.1600255654302036,\n",
       " 'differ': 1.159560996970491,\n",
       " 'fire': 1.1594178235080912,\n",
       " 'hour': 1.1590757177718294,\n",
       " 'betwe': 1.1590230678604736,\n",
       " 'pick': 1.1590230678604736,\n",
       " 'decide': 1.1584130484350879,\n",
       " 'gre': 1.1582116947365164,\n",
       " 'characters': 1.1578117255595386,\n",
       " 'luck': 1.1577466608129807,\n",
       " 'high quality': 1.1576914310871416,\n",
       " 'datasets': 1.1571787667265712,\n",
       " 'you': 1.1570404704179589,\n",
       " 'times': 1.1567529756739063,\n",
       " 'master nlp': 1.1565253408546305,\n",
       " 'paid': 1.1563114432997894,\n",
       " 'dl': 1.1561198650824493,\n",
       " 'many': 1.156045746003095,\n",
       " 'period': 1.1557382483622902,\n",
       " 'far': 1.1557037243854782,\n",
       " 'want see': 1.1552276299000221,\n",
       " 'method': 1.155084139160961,\n",
       " 'library github': 1.154627782759968,\n",
       " 'workers': 1.1545468746220873,\n",
       " 'link': 1.1542952184201103,\n",
       " 'at': 1.1540788600202412,\n",
       " 'world': 1.1539519153252147,\n",
       " 'beyond': 1.1537153008696701,\n",
       " 'face': 1.1530221765246595,\n",
       " 'covers': 1.1530221765246595,\n",
       " 'years': 1.1530042478984839,\n",
       " 'metaprograms': 1.1528965193002063,\n",
       " 'shift strategy': 1.1528675766794232,\n",
       " 'competitive': 1.1528675766794232,\n",
       " 'electra': 1.1527786598869862,\n",
       " 'freely': 1.1525834316962043,\n",
       " ...}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_scores(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c78fee7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'control tabl': 0.006853401491387033,\n",
       " 'laughs': 0.006610959722940027,\n",
       " 'answer someth': -0.005497307517016702,\n",
       " 'research team': 0.005284062892327886,\n",
       " 'without code': 0.004746889136103169,\n",
       " 'word repr': 0.004576384582668077,\n",
       " 'running': 0.004565497265219893,\n",
       " 'actual go': 0.004518448404978532,\n",
       " 'chat': 0.004308095134070148,\n",
       " 'rpc': 0.0031680271442457103,\n",
       " 'tok order': 0.003084816741211172,\n",
       " 'becaus': 0.0030381564270721183,\n",
       " 'john snow': -0.002778409641669203,\n",
       " 'along': -0.0026800352385332443,\n",
       " 'that happ': 0.002612773954388339,\n",
       " 'know tool': -0.002606932385214412,\n",
       " 'like this': -0.002539467463670824,\n",
       " 'formul': -0.0025361634840372843,\n",
       " 'alignm': 0.002485234513828589,\n",
       " 'project onto': 0.0024850496051249714,\n",
       " 'qualif': 0.002451211312362031,\n",
       " 'max gth': 0.0024344931278513834,\n",
       " 'rare': -0.0024020187597383193,\n",
       " 'python': 0.0023889984520192482,\n",
       " 'schedul': 0.002369750704551806,\n",
       " 'sever': -0.002337083401151523,\n",
       " 'kera': -0.0023339723568052053,\n",
       " 'domain abl': 0.0023230903904127524,\n",
       " 'use search': 0.0022041069906873446,\n",
       " 'ize ce': -0.0020884222195397427,\n",
       " 'study': 0.0020524616386173853,\n",
       " 'nlp technique': 0.0020485735020664524,\n",
       " 'sort information': -0.001978967563668379,\n",
       " 'there post': 0.0019653630990319145,\n",
       " 'hu': 0.0019466995084818674,\n",
       " 'want do': -0.0019293918159980926,\n",
       " 'similar task': -0.0018753437748594804,\n",
       " 'fuell': 0.0017962197947188282,\n",
       " 'hot labels': -0.0017870769214392251,\n",
       " 'bn': -0.001748969972606649,\n",
       " 'somebody': 0.0016698486679938616,\n",
       " 'person project': -0.0016332932280426473,\n",
       " 'littl experi': -0.0016103529548393601,\n",
       " 'factual': 0.001609385602875392,\n",
       " 'two': 0.0015687517666138895,\n",
       " 'class classif': -0.0015668036850466239,\n",
       " 'first train': 0.0014894321756581518,\n",
       " 'managem': 0.0014802919779064137,\n",
       " 'this look': 0.001476015295253175,\n",
       " 'know start': -0.0014618186471157188,\n",
       " 'accuraci marktechpost': 0.0014441304351132372,\n",
       " 'romant relationship': -0.0014309064899954815,\n",
       " 'quit interest': 0.00142935498111412,\n",
       " 'olfactori anchor': 0.0014171064145439307,\n",
       " 'hypnot': -0.0013988286945683223,\n",
       " 'metaphor analysi': 0.0013826946669750668,\n",
       " 'focus ev': -0.0013708319709793172,\n",
       " 'll also': -0.0013622759301449732,\n",
       " 'abl help': -0.0013564450630825081,\n",
       " 'improvem ts': -0.0013440008856972323,\n",
       " 'me': 0.0013412837385089512,\n",
       " 'commun nlp': -0.0013358360664930597,\n",
       " 'polit comm': 0.0013296193288561543,\n",
       " 'shreyansh github': -0.0013294210425132016,\n",
       " 'year now': 0.0013257338678330879,\n",
       " 'use cosin': 0.001289569649512044,\n",
       " 'convert text': 0.0012833475608194063,\n",
       " 'attach': -0.001268569431292425,\n",
       " 'beach': -0.0012493216838249826,\n",
       " 'differ dataset': 0.0012236615879055498,\n",
       " 'parameters': 0.0012184122022326105,\n",
       " 'class': -0.0011871088234822003,\n",
       " 'minutes': -0.0011766100521363228,\n",
       " 'meta': 0.0011715589528063367,\n",
       " 'practition course': -0.0011556125094445693,\n",
       " 'want put': 0.0011513385023191952,\n",
       " 'adopt': 0.0011400626387687049,\n",
       " 'iclr': -0.0011243091306941569,\n",
       " 'model name': -0.001119062420549085,\n",
       " 'theori behind': -0.0011056428646162406,\n",
       " 'follow code': 0.0010885414850590196,\n",
       " 'opt': 0.0010759043723865226,\n",
       " 'tradit': 0.001054129737490155,\n",
       " 'got interest': 0.0010414926248176592,\n",
       " 'beam': 0.0010379930343690327,\n",
       " 'shorter': -0.0010333251300856212,\n",
       " 'use topic': -0.0010282686796999028,\n",
       " 'laughter': 0.00101271880902404,\n",
       " 'jordan': -0.0010049398603943092,\n",
       " 'large': 0.0010000816963515434,\n",
       " 'bad habit': -0.0009969679764773574,\n",
       " 'experim ts': -0.0009905502769696336,\n",
       " 'redir': 0.0009891943789033597,\n",
       " 'range': -0.0009849150207222551,\n",
       " 'use model': 0.0009818066519038016,\n",
       " 'nlp certif': -0.0009800541811516227,\n",
       " 'old male': -0.0009773316829076108,\n",
       " 'financ': -0.0009627518397235799,\n",
       " 'basically creat': 0.0009600320170074336,\n",
       " 'journal get': 0.0009592549248028211,\n",
       " 'apolog': -0.0009586654168296949,\n",
       " 'revers gineer': -0.0009551631508532021,\n",
       " 'know talk': -0.0009501147270510834,\n",
       " 'jamesppesch facebook': 0.0009277586107651895,\n",
       " 'distort': -0.0009228950956666912,\n",
       " 'say someth': -0.0009147302764625203,\n",
       " 'quick': 0.0009094835663174478,\n",
       " 'imo': -0.0009077284200374029,\n",
       " 'peopl': 0.0009073452249908281,\n",
       " 'requir first': -0.0009013160715854104,\n",
       " 'gda dataset': 0.0008880974775233872,\n",
       " 'process': 0.000878959955299516,\n",
       " 'idf method': -0.0008742920510161037,\n",
       " 'improv it': 0.0008725476068475227,\n",
       " 'draft': -0.000849794917875725,\n",
       " 'topic interest': -0.0008451296891201783,\n",
       " 'wh comput': 0.0008437711155260385,\n",
       " 'learn nlp': 0.0008410486172820265,\n",
       " 'raw data': 0.0008357992316090878,\n",
       " 'power new': -0.000834630917774301,\n",
       " 'slp': 0.0008315225489558487,\n",
       " 'els describ': 0.0008284115046095293,\n",
       " 'im': -0.000827243190774743,\n",
       " 'pl': 0.00082627316328291,\n",
       " 'imageri': 0.0008231621189365907,\n",
       " 'compromis': 0.0008175241871613462,\n",
       " 'stori share': -0.0008107179415513142,\n",
       " 'empath': -0.0008107179415513142,\n",
       " 'nlp mind': 0.000810525006264094,\n",
       " 'almost': 0.000810525006264094,\n",
       " 'santa': -0.0008091610816142216,\n",
       " 'person get': 0.0008079981188351681,\n",
       " 'help thank': 0.0008031372792645364,\n",
       " 'synset': -0.0008019689654297498,\n",
       " 'acknowledg': 0.0007996376888159104,\n",
       " 'product': -0.0007926358323907926,\n",
       " 'assumpt': -0.0007875820575329411,\n",
       " 'appreci peopl': 0.0007852507809191009,\n",
       " 'bart larg': 0.0007743634634709173,\n",
       " 'campaign fcc': 0.0007743634634709173,\n",
       " 'betw languag': 0.0007726136682466045,\n",
       " 'exampl sequ': 0.0007722251221442979,\n",
       " 'german train': -0.0007613351291682485,\n",
       " 'except': 0.0007599765555741081,\n",
       " 'subconsci mind': -0.0007570584465150093,\n",
       " 'tf': -0.0007475323781888314,\n",
       " 'repository': -0.0007409217433938869,\n",
       " 'one better': -0.0007370336068429546,\n",
       " 'png': 0.0007356750332488148,\n",
       " 'asset': -0.0007278960846190835,\n",
       " 'ant': 0.0007247877158006304,\n",
       " 'whether may': 0.0007247877158006304,\n",
       " 'well number': -0.0007228396342333649,\n",
       " 'section': 0.0007220652175566185,\n",
       " 'certif': 0.0007220652175566185,\n",
       " 'always': 0.0007220652175566185,\n",
       " 'korean languag': -0.0007205083576195255,\n",
       " 'new articl': -0.0007166202210685934,\n",
       " 'refr ce': -0.0007164246102535065,\n",
       " 'much differ': 0.0007129276953327475,\n",
       " 'understand': 0.0007111779001084343,\n",
       " 'lot': 0.0007094281048841215,\n",
       " 'well ough': 0.0006991276198811962,\n",
       " 'docum level': 0.0006985407874359382,\n",
       " 'evalu it': -0.0006930957909479134,\n",
       " 'use wordvec': -0.0006913459957236003,\n",
       " 'shift strategi': 0.0006841538795391288,\n",
       " 'guid nlp': -0.0006804586782754168,\n",
       " 'share prescript': -0.0006695713608272331,\n",
       " 'like tri': -0.0006682101117052259,\n",
       " 'record': -0.0006678215656029203,\n",
       " 'flu english': -0.0006660717703786071,\n",
       " 'descript paper': -0.0006658761595635201,\n",
       " 'softwar': -0.0006654876134612146,\n",
       " 'analys': -0.0006629607260322874,\n",
       " 'link blog': -0.0006625721799299809,\n",
       " 'use': 0.0006602409033161417,\n",
       " 'good far': 0.0006588796541941354,\n",
       " 'custom dataset': -0.0006520734085841041,\n",
       " 'xb final': 0.0006476037906436451,\n",
       " 'would possibl': 0.0006462425415216392,\n",
       " 'sophist': 0.0006388548145220805,\n",
       " 'regret': -0.0006372979545849878,\n",
       " 'experim ting': 0.0006371050192977681,\n",
       " 'read one': 0.0006353552240734551,\n",
       " 'use small': 0.000633605428849142,\n",
       " 'wonder peopl': 0.000633605428849142,\n",
       " 'trepr': 0.000633605428849142,\n",
       " 'learn new': -0.0006225225005858722,\n",
       " 'happy': 0.0006209683161766458,\n",
       " 'secondari': 0.0006209683161766458,\n",
       " 'xlnet': 0.0006170801796257131,\n",
       " 'models bert': -0.0006110510262202951,\n",
       " 'hello': 0.0006083312035041492,\n",
       " 'ces exampl': -0.0006067743435670565,\n",
       " 'first th': -0.0006023020500987316,\n",
       " 'nlp secret': -0.0005989980704651915,\n",
       " 'cool': 0.0005974438860559655,\n",
       " 'deploy model': 0.0005956940908316527,\n",
       " 'erat system': -0.0005954984800165664,\n",
       " 'link read': 0.0005951126094421251,\n",
       " 'kinesthet': 0.0005914174081784136,\n",
       " 'realli practic': -0.0005914120571226811,\n",
       " 'real life': 0.0005875292716274809,\n",
       " 'take quick': 0.0005848067733834689,\n",
       " 'episode': 0.0005846138380962486,\n",
       " 'comput linguistics': -0.0005846111625683823,\n",
       " 'friday': 0.0005836411350765486,\n",
       " 'gut': 0.0005830569781591557,\n",
       " 'get results': 0.0005830569781591557,\n",
       " 'nlp dataset': 0.0005797529985256167,\n",
       " 'data comput': 0.0005791688416082237,\n",
       " 'tr ds': -0.0005748894834271185,\n",
       " 'freeli avail': -0.0005737238451201984,\n",
       " 'descriptions': -0.0005717784390807997,\n",
       " 'read first': -0.0005667246642229475,\n",
       " 'rainbow': 0.0005630321384871011,\n",
       " 'gre': 0.0005630321384871011,\n",
       " 'each': 0.0005630321384871011,\n",
       " 'mani time': -0.0005544760976527567,\n",
       " 'outlook': -0.000551949210223831,\n",
       " 'one idea': -0.000551949210223831,\n",
       " 'due covid': 0.0005468954353659789,\n",
       " 'af': -0.0005449500293265799,\n",
       " 'pleas help': 0.0005439800018347459,\n",
       " 'studi comput': -0.0005408662819605607,\n",
       " 'classif problem': -0.0005400891897559476,\n",
       " 'activ': 0.0005356195718154888,\n",
       " 'transformations': 0.0005325085274691697,\n",
       " 'online': 0.0005325085274691697,\n",
       " 'applications': 0.0005325085274691697,\n",
       " 'commands': 0.0005325085274691697,\n",
       " 'machinelearn': 0.0005325085274691697,\n",
       " 'fear height': 0.0005325085274691697,\n",
       " 'tion provid': -0.0005284247801031508,\n",
       " 'book suggest': -0.0005284247801031508,\n",
       " 'reach': 0.0005251208004696116,\n",
       " 'sh bash': -0.0005235639405325187,\n",
       " 'coupl day': 0.0005233710052452986,\n",
       " 'model use': -0.000523175394430212,\n",
       " 'aforem': 0.0005198714147966727,\n",
       " 'tag word': -0.0005179260087572741,\n",
       " 'interest machin': -0.0005140378722063412,\n",
       " 'sim lda': -0.0005126766230843355,\n",
       " 'technic': -0.000512481012269249,\n",
       " 'abl get': 0.0005107338925728021,\n",
       " 'epoch': 0.0005107338925728021,\n",
       " 'stemming': 0.0005089840973484894,\n",
       " 'look into': -0.0005087884865334027,\n",
       " 'trade': 0.0005072343021241761,\n",
       " 'op domain': -0.0005070386913090903,\n",
       " 'transform blob': 0.0005050959607975572,\n",
       " 'yelp reviews': -0.0005049003499824706,\n",
       " 'sites': -0.0005049003499824706,\n",
       " 'situations': -0.0005035391008604645,\n",
       " 'survey': 0.0005015963703489314,\n",
       " 'gpt': -0.0004996509643095321,\n",
       " 'model appli': 0.0004977082337979987,\n",
       " 'ext ding': 0.0004963469846759924,\n",
       " 'becom reality': 0.0004945971894516798,\n",
       " 'byte': 0.0004924588481250601,\n",
       " 'embed': -0.000492263237309974,\n",
       " 'project nlp': 0.0004903205067984408,\n",
       " 'anxiety th': 0.0004877936193695149,\n",
       " 'lab': 0.0004837098720034958,\n",
       " 'legitim': 0.0004829327797988829,\n",
       " 'luck': 0.00048196007677918287,\n",
       " 'tri tim': -0.00048137591986178996,\n",
       " 'float': -0.00048137591986178996,\n",
       " 'po tagger': -0.00048137591986178996,\n",
       " 'train ai': -0.0004800146707397842,\n",
       " 'thought share': 0.0004769063019213313,\n",
       " 'continue': -0.00047690362639346497,\n",
       " 'abd': -0.00047456967425175923,\n",
       " 'hypnosi nlp': 0.00047107275933099945,\n",
       " 'degre': 0.0004706842132286927,\n",
       " 'group togeth': 0.0004693229641066865,\n",
       " 'chang model': 0.0004693229641066865,\n",
       " 'txtai': -0.00046873880718929334,\n",
       " 'github': -0.00046776610416959373,\n",
       " 'traumat ev': -0.00046698901196498083,\n",
       " 'might help': -0.00046504360592558146,\n",
       " 'categori': -0.00046387796761866175,\n",
       " 'th fine': 0.0004634920970442212,\n",
       " 'though': 0.00046329648622913506,\n",
       " 'want coach': 0.0004601854418828155,\n",
       " 'occup': -0.0004599898310677291,\n",
       " 'mean pool': 0.00045941370073393625,\n",
       " 'math': 0.0004588268682886752,\n",
       " 'microsoft marian': 0.00045804710055619645,\n",
       " 'mark': -0.0004578514897411096,\n",
       " 'heard nlp': -0.0004578514897411096,\n",
       " 'two amp': 0.00045668585143418994,\n",
       " 'cross post': -0.0004564902406191038,\n",
       " 'duti': -0.0004543518992924843,\n",
       " 'https': -0.0004543518992924843,\n",
       " 'start get': 0.00045279771488325763,\n",
       " 'grone': -0.0004491025136195457,\n",
       " 'hear someon': 0.000448521032230019,\n",
       " 'nlp practitioner': 0.0004457985339860062,\n",
       " 'labor': 0.00044404873876169315,\n",
       " 'prefer': 0.00044404873876169315,\n",
       " 'noob': -0.0004421033327222946,\n",
       " 'board': -0.0004417147866199877,\n",
       " 'apis': 0.00044016060221076117,\n",
       " 'relation tempor': 0.00043957912082123393,\n",
       " 'liner intro': 0.00043491121653782224,\n",
       " 'syndrome': -0.00043471560572273587,\n",
       " 'vak': -0.00043432705962042945,\n",
       " 'second question': 0.00043316142131350963,\n",
       " 'new behavior': -0.00043296581049842326,\n",
       " 'use inform': 0.00043141162608919674,\n",
       " 'machin learning': -0.0004308274691718037,\n",
       " 'linkedin': -0.0004308274691718037,\n",
       " 'classif use': -0.0004308274691718037,\n",
       " 'ipynb nlu': -0.0004294662200497981,\n",
       " 'way go': 0.0004292732847625772,\n",
       " 'lot money': 0.0004257736943139515,\n",
       " 'nlp ask': 0.0004257736943139515,\n",
       " 'biomed nlp': -0.0004226599744397671,\n",
       " 'without give': 0.00042052430864101284,\n",
       " 'like me': -0.0004203286978259269,\n",
       " 'exist model': 0.0004201357625387065,\n",
       " 'trick mind': 0.00041897012423178595,\n",
       " 'hyperparamet': 0.00041877451341669995,\n",
       " 'may': 0.00041877451341669995,\n",
       " 'run model': 0.00041877451341669995,\n",
       " 'packag': 0.00041877451341669995,\n",
       " 'js': 0.00041877451341669995,\n",
       " 'stopword removal': -0.00041585640435760137,\n",
       " 'use ml': -0.00041332951692867525,\n",
       " 'gestur erat': -0.0004129409708263686,\n",
       " 'contact us': -0.00041196826780666917,\n",
       " 'wordvec model': 0.0004113867864171419,\n",
       " 'tutorial': -0.00041080262949974914,\n",
       " 'regards': -0.00041080262949974914,\n",
       " 'mimic': -0.0004090528342754363,\n",
       " 'stream': 0.0004078871959685164,\n",
       " 'anyon list': 0.0004078871959685164,\n",
       " 'leader': 0.00040749864986620995,\n",
       " 'another': 0.0004061374007442037,\n",
       " 'hello all': 0.00040399905941758407,\n",
       " 'compani work': 0.0004036105133152772,\n",
       " 'helps': -0.0004030236808700183,\n",
       " 'test sets': -0.00040205365337818487,\n",
       " 'would great': 0.00040186071809096503,\n",
       " 'nlp applic': 0.00040186071809096503,\n",
       " 'high': 0.0003987496737446455,\n",
       " 'data custom': -0.0003981655168272525,\n",
       " 'automat extract': 0.0003952500832960196,\n",
       " 'states': 0.0003952500832960196,\n",
       " 'teach nlp': 0.0003952500832960196,\n",
       " 'els make': 0.00039350028807170687,\n",
       " 'data text': 0.00039350028807170687,\n",
       " 'test eval': -0.00039330467725662104,\n",
       " 'and learn': 0.00039311174196940044,\n",
       " 'book subject': -0.0003929161311543138,\n",
       " 'spare time': -0.0003929161311543138,\n",
       " 'charact': 0.00039097340064278097,\n",
       " 'book att': -0.00038727819937906893,\n",
       " 'll see': -0.00038727819937906893,\n",
       " 'msc': 0.0003849469227652292,\n",
       " 'short': -0.00038377860893044316,\n",
       " 'hav ing': 0.00038261297062352334,\n",
       " 'companies': 0.0003808631753992106,\n",
       " 'someon tere': 0.0003808631753992106,\n",
       " 'embedding': 0.0003808631753992106,\n",
       " 'transact': 0.0003808631753992106,\n",
       " 'success would': 0.0003808631753992106,\n",
       " 'pressure': -0.0003802790184818172,\n",
       " 'question follow': 0.0003783362879702845,\n",
       " 'way stori': -0.000377945066340112,\n",
       " 'convinc': 0.0003769750388482782,\n",
       " 'spark': -0.00037677942803319184,\n",
       " 'ingl': 0.00037658649274597167,\n",
       " 'paraphrases': 0.0003752252436239653,\n",
       " 'from': 0.0003748366975216586,\n",
       " 'multi docum': -0.0003746410867065723,\n",
       " 'lot work': -0.0003746410867065723,\n",
       " 'higher level': 0.0003744481514193519,\n",
       " 'measur': 0.00037347544839965216,\n",
       " 'developm psychotherapi': 0.00037347544839965216,\n",
       " 'necessari': -0.00037114149625794654,\n",
       " 'leadership': -0.000370168793238247,\n",
       " 'googl': 0.00036997585795102656,\n",
       " 'know python': 0.00036997585795102656,\n",
       " 'despit': 0.00036997585795102656,\n",
       " 'pattern amp': 0.00036997585795102656,\n",
       " 'discov nlp': -0.0003697802471359405,\n",
       " 'tor': -0.0003697802471359405,\n",
       " 'associ': -0.00036939170103363343,\n",
       " 'modifi': -0.00036939170103363343,\n",
       " 'erat dataset': -0.00036939170103363343,\n",
       " 'wh nlp': -0.00036939170103363343,\n",
       " 'nlp understand': 0.0003684216735418001,\n",
       " 'hi work': 0.0003682260627267139,\n",
       " 'change': 0.0003682260627267139,\n",
       " 'mt': 0.0003682260627267139,\n",
       " 'charact act': 0.0003682260627267139,\n",
       " 'embed word': 0.0003682260627267139,\n",
       " 'take action': 0.0003682260627267139,\n",
       " 'let us': -0.00036666920278962127,\n",
       " 'nlp sub': -0.0003645308614630021,\n",
       " 'la': -0.0003637537692583887,\n",
       " 'respectively': -0.0003637537692583887,\n",
       " 'api': -0.0003637537692583887,\n",
       " 'grammar': -0.0003637537692583887,\n",
       " 'news tim': -0.0003637537692583887,\n",
       " 'yield': -0.0003637537692583887,\n",
       " 'master stud': -0.0003637537692583887,\n",
       " 'medication': -0.0003637537692583887,\n",
       " 'what best': -0.0003620039740340758,\n",
       " 'brain mind': 0.00036083833572715576,\n",
       " 'th back': 0.00036083833572715576,\n",
       " 'grasp': 0.00036083833572715576,\n",
       " 'ev wh': -0.0003606427249120695,\n",
       " 'hebrew': 0.00035869999440053644,\n",
       " 'recognit asr': -0.0003585043835854499,\n",
       " 'networks': 0.0003555889500542175,\n",
       " 'best way': 0.0003555889500542175,\n",
       " 'if': 0.0003555889500542175,\n",
       " 'approaches would': 0.0003555889500542175,\n",
       " 'peopl post': 0.0003555889500542175,\n",
       " 'nueva app': 0.0003552004039519104,\n",
       " 'look exampl': -0.00035325499791251163,\n",
       " 'bring': 0.00035170081350328496,\n",
       " 'techniqu appli': -0.00034839415834187967,\n",
       " 'probabl need': -0.00034800561223957314,\n",
       " 'discuss': 0.0003447016326060335,\n",
       " 'embed bert': 0.0003447016326060335,\n",
       " 'banner': 0.000344313086503727,\n",
       " 'by': -0.0003441174756886402,\n",
       " 'larg text': 0.0003429518373817209,\n",
       " 'conversations': 0.0003429518373817209,\n",
       " 'volum': 0.0003429518373817209,\n",
       " 'easi nlu': -0.00034275622656663454,\n",
       " 'anyon read': 0.00034256329127941383,\n",
       " 'decis': -0.00034236768046432757,\n",
       " 'person growth': -0.0003402293391377084,\n",
       " 'ce docum': -0.0003402293391377084,\n",
       " 'travel': -0.0003402293391377084,\n",
       " 'nlp tri': -0.0003402293391377084,\n",
       " 'val': -0.0003402293391377084,\n",
       " 'constitu': -0.0003402293391377084,\n",
       " 'light this': 0.0003390637008307884,\n",
       " 'via video': -0.0003388680900157019,\n",
       " 'implem tation': -0.00033847954391339553,\n",
       " 'program look': 0.00033731390560647555,\n",
       " 'deploy': 0.00033731390560647555,\n",
       " 'embed wordvec': -0.00033692268397630346,\n",
       " 'thing alreadi': -0.00033672974868908265,\n",
       " 'cosin similarity': -0.0003353684995670766,\n",
       " 'regist': -0.0003353684995670766,\n",
       " 'tailm': -0.0003349799534647696,\n",
       " 'work on': 0.0003347870181775492,\n",
       " 'know common': 0.00033381431515785,\n",
       " 'extract ner': -0.00033323015824045666,\n",
       " 'applic curr': -0.00033186890911845074,\n",
       " 'link': 0.0003303147247092242,\n",
       " 'anyon share': 0.0003303147247092242,\n",
       " 'someon provid': 0.0003303147247092242,\n",
       " 'cc': 0.0003303147247092242,\n",
       " 'sinc sub': 0.0003303147247092242,\n",
       " 'summari paper': 0.0003303147247092242,\n",
       " 'admiss': 0.0003303147247092242,\n",
       " 'everyon alway': 0.0003303147247092242,\n",
       " 'method find': -0.0003275922264652118,\n",
       " 'money': -0.0003275922264652118,\n",
       " 'may ev': -0.0003266195234455122,\n",
       " 'suggest like': -0.00032623097734320555,\n",
       " 'statisticsglob': -0.0003252582743235058,\n",
       " 'work fine': -0.000324092636016586,\n",
       " 'probably': -0.000324092636016586,\n",
       " 'him': -0.00032272871136671314,\n",
       " 'look success': -0.000322342840792273,\n",
       " 'chang': 0.00032117720248535326,\n",
       " 'phobia': -0.00032059304556796,\n",
       " 'receiv': 0.00031962301807612697,\n",
       " 'nlp think': 0.0003194274072610406,\n",
       " 'tv': 0.0003194274072610406,\n",
       " 'older': 0.0003190388611587334,\n",
       " 'resourc use': -0.0003188432503436472,\n",
       " 'guy know': 0.00031767761203672755,\n",
       " 'high perform': 0.00031767761203672755,\n",
       " 'colleg london': 0.00031767761203672755,\n",
       " 'find english': 0.00031767761203672755,\n",
       " 'in': -0.000316704909017028,\n",
       " 'hug': -0.000316704909017028,\n",
       " 'random': -0.000316704909017028,\n",
       " 'learn faster': -0.000316704909017028,\n",
       " 'summar dataset': -0.000316704909017028,\n",
       " 'find differ': -0.000316704909017028,\n",
       " 'tri figur': 0.00031553927071010796,\n",
       " 'instanc': 0.00031028988503716963,\n",
       " 'wh get': -0.00030970572811977635,\n",
       " 'ressourc nlu': 0.00030854008981285686,\n",
       " 'start': 0.0003050404993642308,\n",
       " 'classroom': 0.0003050404993642308,\n",
       " 'resolve': 0.0003050404993642308,\n",
       " 'check website': -0.0003040677963445314,\n",
       " 'known': -0.0003040677963445314,\n",
       " 'like arabic': -0.0003040677963445314,\n",
       " 'anxieti': -0.0003034836394271385,\n",
       " 'seem offer': -0.0003034836394271385,\n",
       " 'larg univers': -0.00030270654722252535,\n",
       " 'true one': -0.00030231800112021865,\n",
       " 'internship': 0.0003011523628132984,\n",
       " 'sort thing': 0.0003007638167109919,\n",
       " 'best method': -0.00030056820589590577,\n",
       " 'family': 0.0002994025675889857,\n",
       " 'new you': -0.00029881841067159277,\n",
       " 'help achiev': 0.0002959029771403603,\n",
       " 'make list': 0.0002959029771403603,\n",
       " 'consciou': -0.00029570736632527337,\n",
       " 'erat transform': 0.00029551443103805337,\n",
       " 'classif nlp': 0.00029415318191604724,\n",
       " 'wing': 0.00029415318191604724,\n",
       " 'dep cie': -0.00029318047889634747,\n",
       " 'label data': -0.00029318047889634747,\n",
       " 'dollar': -0.00029318047889634747,\n",
       " 'piec': -0.00029318047889634747,\n",
       " 'wrap': -0.00029318047889634747,\n",
       " 'citi': -0.00029318047889634747,\n",
       " 'intermedi level': -0.00029318047889634747,\n",
       " 'ev extract': 0.0002924033866917344,\n",
       " 'book nlp': 0.0002924033866917344,\n",
       " 'done simpli': 0.0002924033866917344,\n",
       " 'out think': 0.0002924033866917344,\n",
       " 'prone': 0.0002924033866917344,\n",
       " 'model nlpcloud': 0.0002924033866917344,\n",
       " 'transcript': -0.00029181922977434107,\n",
       " 'qualiti nlp': -0.00029143068367203486,\n",
       " 'main reason': -0.00029143068367203486,\n",
       " 'ce result': 0.0002902650453651148,\n",
       " 'around it': 0.0002902650453651148,\n",
       " 'tli use': 0.0002898764992628084,\n",
       " 'surana': -0.00028968088844772213,\n",
       " 'better idea': 0.00028851525014080215,\n",
       " 'product fastapi': 0.00028676545491648943,\n",
       " 'support coach': -0.00028618129799909615,\n",
       " 'chines word': 0.00028598836271187577,\n",
       " 'betw tities': -0.0002836517350423048,\n",
       " 'use semant': 0.0002832658644678636,\n",
       " 'meta program': 0.0002832658644678636,\n",
       " 'help nlp': -0.0002813204584284642,\n",
       " 'text spanish': 0.0002811275231412438,\n",
       " 'affili': -0.0002809319123261573,\n",
       " 'ce betw': -0.00028054336622385085,\n",
       " 'nlp anchoring': -0.00028054336622385085,\n",
       " 'eleutherai': 0.00027996188483432366,\n",
       " 'advic welcome': 0.00027976627401923767,\n",
       " 'model train': 0.00027976627401923767,\n",
       " 'example call': 0.00027976627401923767,\n",
       " 'at': 0.00027976627401923767,\n",
       " 'reaction': 0.00027976627401923767,\n",
       " 'emerg': 0.00027976627401923767,\n",
       " 'worker': 0.00027976627401923767,\n",
       " 'uninhibit': -0.00027957066320415146,\n",
       " 'missed': -0.0002791821171018447,\n",
       " 'age': -0.00027879357099953823,\n",
       " 'understand it': 0.00027762793269261803,\n",
       " 'scalabl': -0.0002752939805509125,\n",
       " 'advis': 0.0002721856117324598,\n",
       " 'nlu support': 0.0002706287517953669,\n",
       " 'spaci model': 0.0002702402056930601,\n",
       " 'this would': -0.00026965604877566716,\n",
       " 'rec tli': -0.00026965604877566716,\n",
       " 'hope help': -0.00026965604877566716,\n",
       " 'monday': -0.00026965604877566716,\n",
       " 'god': -0.00026965604877566716,\n",
       " 'ts want': -0.00026965604877566716,\n",
       " 'check articl': -0.00026965604877566716,\n",
       " 'topic modelling': -0.00026965604877566716,\n",
       " 'tutor': -0.00026965604877566716,\n",
       " 'immediately': -0.00026965604877566716,\n",
       " 'featur dataset': -0.00026965604877566716,\n",
       " 'dataset yake': -0.00026965604877566716,\n",
       " 'conditions': -0.00026965604877566716,\n",
       " 'classify': -0.00026965604877566716,\n",
       " 'checklist': 0.0002688789565710541,\n",
       " 'realli want': -0.00026790625355135433,\n",
       " 'valuabl': -0.00026790625355135433,\n",
       " 'cloth': -0.00026790625355135433,\n",
       " 'balanc betw': 0.00026712916134674115,\n",
       " 'influ': 0.00026712916134674115,\n",
       " 'reinforc': 0.00026712916134674115,\n",
       " 'abl run': 0.00026712916134674115,\n",
       " 'off also': 0.00026712916134674115,\n",
       " 'govern': 0.0002667406152444344,\n",
       " 'deep medit': -0.0002665450044293478,\n",
       " 'tree': -0.0002661564583270417,\n",
       " 'excit releas': -0.0002661564583270417,\n",
       " 'use pytorch': -0.0002647952092050356,\n",
       " 'understand nlp': -0.0002644066631027289,\n",
       " 'put': 0.0002628524786935023,\n",
       " 'rc': -0.0002616841648587165,\n",
       " 'approach best': -0.000260907072654103,\n",
       " 'good paper': 0.00025974143434718324,\n",
       " 'encod decod': -0.0002595458235320971,\n",
       " 'ce stud': -0.00025954314800423093,\n",
       " 'statem': 0.00025896434214257,\n",
       " 'point view': 0.0002579916391228702,\n",
       " 'want give': -0.00025701893610317054,\n",
       " 'realis': -0.00025701893610317054,\n",
       " 'treebank': -0.0002556576869811644,\n",
       " 'high accuraci': -0.0002552691408788577,\n",
       " 'train it': -0.0002552691408788577,\n",
       " 'bottom': 0.00025449204867424464,\n",
       " 'cross': 0.00025449204867424464,\n",
       " 'tuning': 0.00025449204867424464,\n",
       " 'ide': 0.00025449204867424464,\n",
       " 'multi label': 0.00025449204867424464,\n",
       " 'belong': 0.00025449204867424464,\n",
       " 'concept could': 0.00025449204867424464,\n",
       " 'know keyword': 0.00025449204867424464,\n",
       " 'th decid': 0.0002541035025719376,\n",
       " 'like go': -0.00025371228094176574,\n",
       " 'aforem tion': -0.00025332373483945834,\n",
       " 'tool nlp': -0.00025215809653253895,\n",
       " 'much say': -0.00025176955043023226,\n",
       " 'addict': -0.00025001975520591926,\n",
       " 'string match': -0.0002480743491665204,\n",
       " 'principl': -0.0002465201647572935,\n",
       " 'etc': -0.000246131618654987,\n",
       " 'explained': -0.000246131618654987,\n",
       " 'want like': -0.000246131618654987,\n",
       " 'anyon point': -0.000246131618654987,\n",
       " 'find quit': -0.000246131618654987,\n",
       " 'react': 0.0002453545264503738,\n",
       " 'frog': 0.0002453545264503738,\n",
       " 'speech tag': 0.0002453545264503738,\n",
       " 'gtx': -0.000244381823430674,\n",
       " 'boundari': -0.000244381823430674,\n",
       " 'market coach': -0.000244381823430674,\n",
       " 'keytotext': -0.000244381823430674,\n",
       " 'zt': -0.000244381823430674,\n",
       " 'unsupervis': 0.00024360473122606082,\n",
       " 'via': 0.00024360473122606082,\n",
       " 'would expect': 0.00024360473122606082,\n",
       " 'nlp coaching': 0.00024360473122606082,\n",
       " 'way develop': -0.00024302057430866745,\n",
       " 'input like': -0.00024263202820636116,\n",
       " 'emot': 0.0002418549360017479,\n",
       " 'tag': 0.0002418549360017479,\n",
       " 'php': 0.0002418549360017479,\n",
       " 'dump': 0.0002418549360017479,\n",
       " 'afterward': 0.0002418549360017479,\n",
       " 'necessarili': 0.0002418549360017479,\n",
       " 'fcc abd': 0.0002418549360017479,\n",
       " 'nlp time': 0.0002418549360017479,\n",
       " 'medic titi': 0.0002418549360017479,\n",
       " 'need take': 0.0002418549360017479,\n",
       " 'paper link': 0.0002418549360017479,\n",
       " 'python not': 0.0002410778437971345,\n",
       " 'program language': -0.00023913243775773563,\n",
       " 'lost': -0.00023913243775773563,\n",
       " 'webp amp': 0.00023796679945081592,\n",
       " 'lifecycl': -0.0002367984856160298,\n",
       " 'model work': 0.00023505136591958295,\n",
       " 'approach find': 0.00023407866289988324,\n",
       " 'need littl': -0.00023349450598249041,\n",
       " 'someth quit': 0.00023271741377787705,\n",
       " 'remot': -0.00023213325686048423,\n",
       " 'purpos': -0.0002317447107581774,\n",
       " 'pretrained model': -0.0002317447107581774,\n",
       " 'also note': -0.0002317447107581774,\n",
       " 'nlp order': -0.0002307720077384778,\n",
       " 'packag seem': 0.00023057907245125725,\n",
       " 'winner': 0.00023019052634895072,\n",
       " 'classifi train': -0.00022999491553386456,\n",
       " 'extract writt': 0.00022921782332925128,\n",
       " 'marian': 0.00022921782332925128,\n",
       " 'matching': 0.00022921782332925128,\n",
       " 'bcbc ac': 0.00022921782332925128,\n",
       " 'guidelin': 0.00022921782332925128,\n",
       " 'here want': 0.00022921782332925128,\n",
       " 'coeffici': 0.00022921782332925128,\n",
       " 'mission': 0.00022921782332925128,\n",
       " 'visualization': 0.00022921782332925128,\n",
       " 'nlp exist': 0.00022921782332925128,\n",
       " 'sinc th': 0.00022921782332925128,\n",
       " 'featur new': 0.00022883195275481198,\n",
       " 'requirem': -0.00022863366641185832,\n",
       " 'dumb': 0.00022844073112463805,\n",
       " 'regular': -0.00022824512030955184,\n",
       " 'chill': -0.00022824512030955184,\n",
       " 'back': -0.00022766096339215855,\n",
       " 'who': -0.00022649532508523898,\n",
       " 'person respons': -0.00022649532508523898,\n",
       " 'go back': -0.00022493846514814596,\n",
       " 'bypass': -0.00022474552986092628,\n",
       " 'ce start': -0.0002237728268412268,\n",
       " 'model would': 0.00022319134545169944,\n",
       " 'make corpu': 0.00022319134545169944,\n",
       " 'could summar': -0.00022299573463661326,\n",
       " 'question erat': -0.00022260718853430646,\n",
       " 'compon ts': -0.00022260718853430646,\n",
       " 'nlp mirror': -0.00022260718853430646,\n",
       " 'vocabulari tok': -0.00022260718853430646,\n",
       " 'thorough understand': -0.00022260718853430646,\n",
       " 'summaries': -0.00022260718853430646,\n",
       " 'model give': -0.00022260718853430646,\n",
       " 'pseudosci': -0.00022260718853430646,\n",
       " 'use help': -0.00022260718853430646,\n",
       " 'coupl': 0.00022183009632969342,\n",
       " 'crash fix': -0.000221634485514607,\n",
       " 'effect': -0.00022085739330999384,\n",
       " 'doz': -0.00022085739330999384,\n",
       " 'sat': -0.00022085739330999384,\n",
       " 'day seminar': 0.00022008030110538053,\n",
       " 'ab github': 0.00022008030110538053,\n",
       " 'avail free': 0.000219691755003074,\n",
       " 'second': -0.00021910759808568085,\n",
       " 'ux': -0.00021910759808568085,\n",
       " 'gali': 0.00021833050588106756,\n",
       " 'predict task': -0.00021774634896367458,\n",
       " 'non': 0.0002165807106567548,\n",
       " 'descript': 0.0002165807106567548,\n",
       " 'udemi': 0.0002165807106567548,\n",
       " 'udemy': 0.0002165807106567548,\n",
       " 'anchor': 0.0002165807106567548,\n",
       " 'phd program': 0.0002165807106567548,\n",
       " 'like these': 0.0002165807106567548,\n",
       " 'circl': 0.0002165807106567548,\n",
       " 'ideas thanks': 0.0002165807106567548,\n",
       " 'process much': 0.0002165807106567548,\n",
       " 'np': 0.0002165807106567548,\n",
       " 'sum': 0.0002165807106567548,\n",
       " 'master program': 0.0002165807106567548,\n",
       " 'github post': 0.0002165807106567548,\n",
       " 'messy': 0.0002165807106567548,\n",
       " 'second one': 0.0002165807106567548,\n",
       " 'domain knowledg': 0.0002165807106567548,\n",
       " 'tok thu': -0.00021638509984166899,\n",
       " 'nlp expert': -0.00021599655373936158,\n",
       " 'spare': -0.0002146353046173562,\n",
       " 'okay use': -0.0002146353046173562,\n",
       " 'reason': -0.00021210841718842969,\n",
       " 'former': -0.00021210841718842969,\n",
       " 'tabl': -0.00021210841718842969,\n",
       " 'slow': 0.00021191548190120955,\n",
       " 'bert transform': -0.0002119128063733433,\n",
       " 'manipul peopl': 0.00021133400051168193,\n",
       " 'rec tly': 0.00021094277888150962,\n",
       " 'tm': 0.00021094277888150962,\n",
       " 'well amp': 0.00021094277888150962,\n",
       " 'scale': -0.00021035862196411664,\n",
       " 'use pre': -0.00021035862196411664,\n",
       " 'allow past': -0.00021035862196411664,\n",
       " 'vs': -0.0002099700758618099,\n",
       " 'personally think': -0.0002099700758618099,\n",
       " 'angeles': -0.0002099700758618099,\n",
       " 'bind': -0.0002099700758618099,\n",
       " 'hood': -0.0002099700758618099,\n",
       " 'ue': -0.0002099700758618099,\n",
       " 'are not': -0.00020977446504672327,\n",
       " 'japanese korean': 0.00020919298365719668,\n",
       " 'nlp recomm': 0.00020919298365719668,\n",
       " 'technolog': 0.00020744318843288401,\n",
       " 'war': 0.00020744318843288401,\n",
       " 'overwhelm': 0.00020666609622827046,\n",
       " 'complet new': 0.00020666609622827046,\n",
       " 'welcomed': 0.00020569339320857094,\n",
       " 'one day': 0.00020569339320857094,\n",
       " 'suggestions': -0.0002047206901888713,\n",
       " 'leg': -0.0002047206901888713,\n",
       " 'memori': 0.0002039435979842584,\n",
       " 'member': 0.0002039435979842584,\n",
       " 'said': 0.0002039435979842584,\n",
       " 'trump': 0.0002039435979842584,\n",
       " 'archiv': 0.0002039435979842584,\n",
       " 'hello guys': 0.0002039435979842584,\n",
       " 'part speech': 0.0002039435979842584,\n",
       " 'snow': 0.0002039435979842584,\n",
       " 'df': 0.0002039435979842584,\n",
       " 'hindi': 0.0002039435979842584,\n",
       " 'norm': 0.0002039435979842584,\n",
       " 'applic text': 0.0002039435979842584,\n",
       " 'lower': 0.0002039435979842584,\n",
       " 'rudim': 0.0002039435979842584,\n",
       " 'inher': 0.0002039435979842584,\n",
       " 'auditory': 0.0002039435979842584,\n",
       " 'this wh': 0.0002039435979842584,\n",
       " 'new multilingu': 0.0002039435979842584,\n",
       " 'bodies': 0.0002039435979842584,\n",
       " 'sklearn': 0.0002039435979842584,\n",
       " 'feel safe': 0.0002039435979842584,\n",
       " 'villag': 0.0002039435979842584,\n",
       " 'entiti class': 0.0002039435979842584,\n",
       " 'class ner': 0.0002039435979842584,\n",
       " 'smoke cigarette': 0.000203166505779645,\n",
       " 'ev know': -0.00020316383025177902,\n",
       " 'combin nlp': -0.00020297089496455856,\n",
       " 'familiar python': -0.00020297089496455856,\n",
       " 'summarize': -0.00020297089496455856,\n",
       " 'ergi': -0.00020297089496455856,\n",
       " 'tell': 0.00020180525665763896,\n",
       " 'gpu ml': 0.00020180525665763896,\n",
       " 'similar word': -0.00020122109974024603,\n",
       " 'fears': 0.000200055461433326,\n",
       " 'work directli': -0.000199471304515933,\n",
       " 'new nlp': -0.00019908275841362642,\n",
       " 'immers': -0.00019908275841362642,\n",
       " 'balanc': -0.00019908275841362642,\n",
       " 'doubt': -0.00019908275841362642,\n",
       " 'situation thank': -0.00019908275841362642,\n",
       " 'model wordvec': -0.00019908275841362642,\n",
       " 'nlu nlu': -0.00019908275841362642,\n",
       " 'ce ce': -0.00019908275841362642,\n",
       " 'limitations': -0.00019908275841362642,\n",
       " 'train time': -0.00019908275841362642,\n",
       " 'model normal': -0.00019908275841362642,\n",
       " 'chang belief': -0.00019908275841362642,\n",
       " 'seldom': -0.00019908275841362642,\n",
       " 'drama': -0.00019908275841362642,\n",
       " 'nlp thanks': -0.00019908275841362642,\n",
       " 'word embedding': -0.00019908275841362642,\n",
       " 'good resource': -0.00019908275841362642,\n",
       " 'ridicul': -0.00019908275841362642,\n",
       " 'access gpt': -0.00019908275841362642,\n",
       " 'behavior expert': -0.00019908275841362642,\n",
       " 'width amp': 0.00019830566620901321,\n",
       " 'pip instal': 0.00019791712010670652,\n",
       " 'pleasant': 0.00019791712010670652,\n",
       " 'cigarette': 0.00019791712010670652,\n",
       " 'make model': -0.00019772150929162004,\n",
       " 'basically': -0.00019772150929162004,\n",
       " 'po neg': -0.00019733296318931332,\n",
       " 'criteria': -0.00019733296318931332,\n",
       " 'nlp ml': -0.00019733296318931332,\n",
       " 'som': -0.00019733296318931332,\n",
       " 'hope get': 0.00019655587098470017,\n",
       " 'gramform': 0.00019655587098470017,\n",
       " 'wave': 0.00019655587098470017,\n",
       " 'treat': -0.000195971714067307,\n",
       " 'nlu pipelin': -0.000195971714067307,\n",
       " 'etc kind': -0.0001955831679650007,\n",
       " 'wether': -0.0001955831679650007,\n",
       " 'syntact': -0.0001955831679650007,\n",
       " 'sci tific': 0.00019480607576038728,\n",
       " 'dataframe': 0.00019480607576038728,\n",
       " 'embeddings github': 0.00019480607576038728,\n",
       " 'european': -0.0001946104649453009,\n",
       " 'made': 0.000194028983555774,\n",
       " 'founder': -0.00019383337274068763,\n",
       " 'divid': -0.00019383337274068763,\n",
       " 'work person': 0.00019305628053607445,\n",
       " 'toni robbin': -0.00019208357751637469,\n",
       " 'merg': -0.00019208357751637469,\n",
       " 'job prospect': -0.00019208357751637469,\n",
       " 'stud ts': 0.00019130648531176148,\n",
       " 'corona': 0.00019130648531176148,\n",
       " 'attitud': 0.00019130648531176148,\n",
       " 'awak': 0.00019130648531176148,\n",
       " 'tional': 0.00019130648531176148,\n",
       " 'built': 0.00019130648531176148,\n",
       " 'wonder whether': 0.00019130648531176148,\n",
       " 'app nlp': 0.00019130648531176148,\n",
       " 'joke': 0.00019130648531176148,\n",
       " 'upper': 0.00019130648531176148,\n",
       " 'live in': 0.00019130648531176148,\n",
       " 'presupposit nlp': 0.00019130648531176148,\n",
       " 'model daili': 0.00019130648531176148,\n",
       " 'fcc': 0.00019130648531176148,\n",
       " 'uncas': 0.00019130648531176148,\n",
       " 'minute': 0.00019130648531176148,\n",
       " 'model releas': 0.00019130648531176148,\n",
       " 'white': 0.00019130648531176148,\n",
       " 'make next': 0.00019130648531176148,\n",
       " 'released': 0.00019130648531176148,\n",
       " 'sport': 0.00019130648531176148,\n",
       " 'ig': 0.00019130648531176148,\n",
       " 'bathroom': 0.00019130648531176148,\n",
       " 'claus': 0.00019130648531176148,\n",
       " 'erat paragraph': 0.00019130648531176148,\n",
       " 'discoveri': 0.00019130648531176148,\n",
       " 'thoughts would': 0.00019130648531176148,\n",
       " 'metaphors': -0.00019072232839436855,\n",
       " 'her': -0.0001903337822920621,\n",
       " 'anatomi': -0.0001903337822920621,\n",
       " 'slack': -0.0001903337822920621,\n",
       " 'relat word': -0.00018974962537466917,\n",
       " 'one label': 0.00018916814398514228,\n",
       " 'finetun sst': 0.0001887795978828355,\n",
       " 'would good': 0.0001887795978828355,\n",
       " 'basi': -0.00018858398706774943,\n",
       " 'hear thought': -0.00018683419184343638,\n",
       " 'sound': -0.00018683419184343638,\n",
       " 'model support': -0.00018683419184343638,\n",
       " 'later': -0.00018644564574112985,\n",
       " 'psycholog': -0.00018644564574112985,\n",
       " 'dont': -0.00018644564574112985,\n",
       " 'ess tially': -0.00018644564574112985,\n",
       " 'corpu th': -0.00018644564574112985,\n",
       " 'outdat': -0.00018644564574112985,\n",
       " 'ration think': -0.00018644564574112985,\n",
       " 'also come': -0.00018644564574112985,\n",
       " 'job': -0.00018586148882373697,\n",
       " 'tire sequ': 0.00018566855353651648,\n",
       " 'structur text': 0.00018566855353651648,\n",
       " 'entiti relat': 0.00018566855353651648,\n",
       " 'abc nlp': 0.00018528000743420973,\n",
       " 'discard': -0.00018469585051681672,\n",
       " 'submit': -0.00018469585051681672,\n",
       " 'separ': -0.00018469585051681672,\n",
       " 'driv': -0.00018469585051681672,\n",
       " 'get accuraci': -0.00018469585051681672,\n",
       " 'ce find': -0.00018469585051681672,\n",
       " 'surpris': -0.0001829460552925041,\n",
       " 'sure': 0.00018216896308789065,\n",
       " 'black white': 0.00018216896308789065,\n",
       " 'need get': -0.00018197335227280407,\n",
       " 'clean': -0.000181196260068191,\n",
       " 'because': 0.00018041916786357807,\n",
       " 'system alreadi': 0.00018041916786357807,\n",
       " 'model': -0.00017944646484387803,\n",
       " 'started': -0.00017944646484387803,\n",
       " 'countri': -0.00017944646484387803,\n",
       " 'pretrain': 0.00017866937263926515,\n",
       " 'seminars': 0.00017866937263926515,\n",
       " 'forms': 0.00017866937263926515,\n",
       " 'way make': 0.00017866937263926515,\n",
       " 'gt lt': 0.00017866937263926515,\n",
       " 'social': 0.00017866937263926515,\n",
       " 'seminar': 0.00017866937263926515,\n",
       " 'tok ize': 0.00017866937263926515,\n",
       " 'giv context': 0.00017866937263926515,\n",
       " 'level tok': 0.00017866937263926515,\n",
       " 'tok df': 0.00017866937263926515,\n",
       " 'ev need': 0.00017866937263926515,\n",
       " 'lists': 0.00017866937263926515,\n",
       " 'temporarily': 0.00017866937263926515,\n",
       " 'proof': 0.00017866937263926515,\n",
       " 'anyon ever': 0.00017866937263926515,\n",
       " 'post hi': 0.00017866937263926515,\n",
       " 'embed sure': 0.00017866937263926515,\n",
       " 'searches': 0.00017866937263926515,\n",
       " 'skill need': 0.00017866937263926515,\n",
       " 'dataset larg': 0.00017866937263926515,\n",
       " 'believe': 0.00017866937263926515,\n",
       " 'angri surpris': 0.00017866937263926515,\n",
       " 'languag use': 0.00017866937263926515,\n",
       " 'nlp guru': 0.00017866937263926515,\n",
       " 'download': 0.0001782808265369586,\n",
       " 'translation summarization': 0.0001782808265369586,\n",
       " 'ambit': 0.0001782808265369586,\n",
       " 'didn know': 0.0001782808265369586,\n",
       " 'sev': 0.00017789228043465144,\n",
       " 'want abl': -0.0001776966696195656,\n",
       " 'nlp curr': -0.0001776966696195656,\n",
       " 'five': -0.0001776966696195656,\n",
       " 'load zh': -0.00017711251270217205,\n",
       " 'embeddings': 0.00017672664212773227,\n",
       " 'model tri': -0.0001763354204975593,\n",
       " 'however': -0.00017555832829294603,\n",
       " 'or': -0.00017555832829294603,\n",
       " 'indic': -0.00017555832829294603,\n",
       " 'low resourc': -0.00017555832829294603,\n",
       " 'plug': -0.00017555832829294603,\n",
       " 'ejacul': -0.00017555832829294603,\n",
       " 'cannot': -0.00017555832829294603,\n",
       " 'experi ces': -0.00017555832829294603,\n",
       " 'chick': -0.00017555832829294603,\n",
       " 'fish': -0.00017555832829294603,\n",
       " 'one time': -0.00017555832829294603,\n",
       " 'perform variou': -0.00017555832829294603,\n",
       " 'level rapport': -0.00017555832829294603,\n",
       " 'caring': -0.00017555832829294603,\n",
       " 'it wh': -0.00017555832829294603,\n",
       " 'value': -0.00017555832829294603,\n",
       " 'back mind': -0.00017555832829294603,\n",
       " 'someon help': -0.00017555832829294603,\n",
       " 'di tangl': -0.00017555832829294603,\n",
       " 'folks talk': -0.00017555832829294603,\n",
       " 'learn grow': -0.00017555832829294603,\n",
       " 'like nlp': -0.00017555832829294603,\n",
       " 'problem vs': -0.00017555832829294603,\n",
       " 'answer model': -0.00017555832829294603,\n",
       " 'costs': -0.00017555832829294603,\n",
       " 'similar kind': -0.00017555832829294603,\n",
       " 'load bh': -0.00017555832829294603,\n",
       " 'demo nlp': -0.00017555832829294603,\n",
       " 'learning': 0.00017478123608833285,\n",
       " 'fine': -0.00017380853306863328,\n",
       " 'clustering': -0.00017380853306863328,\n",
       " 'one ce': -0.00017380853306863328,\n",
       " 'emoji': -0.00017380853306863328,\n",
       " 'time thank': -0.00017380853306863328,\n",
       " 'learn data': -0.00017380853306863328,\n",
       " 'welcom back': 0.00017225434865940695,\n",
       " 'similar use': -0.00017205873784432017,\n",
       " 'calcul': -0.00017205873784432017,\n",
       " 'consum': 0.00017128164563970692,\n",
       " 'code ce': -0.00017069748872231412,\n",
       " 'pypi project': -0.00017030894262000748,\n",
       " 'one': 0.0001695318504153942,\n",
       " 'would greatli': 0.0001695318504153942,\n",
       " 'thought patterns': 0.0001695318504153942,\n",
       " 'def': 0.0001695318504153942,\n",
       " 'path': 0.0001695318504153942,\n",
       " ...}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_scores(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9f429335",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer someth': -0.002492068301433774,\n",
       " 'control tabl': 0.0014276859260246733,\n",
       " 'without code': 0.001374452876770179,\n",
       " 'alignm': 0.0011376001703257582,\n",
       " 'actual go': 0.0010580084035463487,\n",
       " 'schedul': 0.0009578191339627622,\n",
       " 'qualif': 0.0008708457249824087,\n",
       " 'along': -0.0008439014306213211,\n",
       " 'max gth': 0.000759603186856061,\n",
       " 'project onto': 0.0007162955961191045,\n",
       " 'becaus': 0.0007087648149156139,\n",
       " 'domain abl': 0.0007084125144091826,\n",
       " 'tok order': 0.0007068473096124685,\n",
       " 'fuell': 0.0006916166373863361,\n",
       " 'chat': 0.0006911521992583047,\n",
       " 'record': -0.0006709298220158653,\n",
       " 'sort information': -0.0006602871093293443,\n",
       " 'rare': -0.0006305031654683865,\n",
       " 'want do': -0.00062093299841378,\n",
       " 'python': 0.0006093027398819546,\n",
       " 'littl experi': -0.0006064875487128446,\n",
       " 'convert text': 0.0006064854900355395,\n",
       " 'two': 0.0005970679052184572,\n",
       " 'nlp technique': 0.0005966295517289448,\n",
       " 'book suggest': -0.000592831280872775,\n",
       " 'factual': 0.0005898575335488433,\n",
       " 'sever': -0.000580426716483763,\n",
       " 'hypnot': -0.0005701565929471901,\n",
       " 'po tagger': -0.0005647959591755135,\n",
       " 'there post': 0.0005604283508029463,\n",
       " 'heard nlp': -0.0005600480385986954,\n",
       " 'like this': -0.0005483150185294933,\n",
       " 'shorter': -0.0005461428920437496,\n",
       " 'use search': 0.0005418858324453614,\n",
       " 'similar task': -0.0005382070504446388,\n",
       " 'beam': 0.000523521999713041,\n",
       " 'want coach': 0.0005217886832477274,\n",
       " 'adopt': 0.0005213952853593605,\n",
       " 'nlp secret': -0.0005199373453521159,\n",
       " 'financ': -0.000516836366953595,\n",
       " 'differ dataset': 0.0004903797044830903,\n",
       " 'that happ': 0.00047516191347676524,\n",
       " 'polit comm': 0.00047347770730395036,\n",
       " 'john snow': -0.0004402843790311249,\n",
       " 'this look': 0.0004371751888764088,\n",
       " 'year now': 0.00043542217755479035,\n",
       " 'attach': -0.00043141814232171017,\n",
       " 'kera': -0.000430584683403423,\n",
       " 'requir first': -0.0004285717793957169,\n",
       " 'mean pool': 0.00042070570116114407,\n",
       " 'float': -0.0004196613072742028,\n",
       " 'class': -0.000416004043185704,\n",
       " 'help thank': 0.00041284685323359757,\n",
       " 'imageri': 0.00039034977684597797,\n",
       " 'subconsci mind': -0.00038949316843215064,\n",
       " 'empath': -0.000384405571016408,\n",
       " 'linkedin': -0.0003745841827030449,\n",
       " 'parameters': 0.0003739041492841751,\n",
       " 'pl': 0.00037012445620486446,\n",
       " 'exampl sequ': 0.0003668769402518251,\n",
       " 'know start': -0.00036659981452667094,\n",
       " 'betw languag': 0.00036454688980540567,\n",
       " 'romant relationship': -0.0003629239927110313,\n",
       " 'focus ev': -0.00035945577121300704,\n",
       " 'necessari': -0.0003520340896091791,\n",
       " 'js': 0.0003477953523857391,\n",
       " 'know tool': -0.0003465902384506042,\n",
       " 'quit interest': 0.0003465463013189353,\n",
       " 'learn new': -0.0003440756269929815,\n",
       " 'traumat ev': -0.0003422447642644838,\n",
       " 'running': 0.00034051756436961574,\n",
       " 'rpc': 0.0003391963841029802,\n",
       " 'redir': 0.0003390387364435854,\n",
       " 'acknowledg': 0.000338929364110558,\n",
       " 'follow code': 0.0003384844748257022,\n",
       " 'use model': 0.00033733156611517233,\n",
       " 'board': -0.0003349993596908785,\n",
       " 'process': 0.0003345614270912885,\n",
       " 'gda dataset': 0.0003318754472598906,\n",
       " 'im': -0.0003269501390888467,\n",
       " 'abl get': 0.0003260065930773522,\n",
       " 'use': 0.0003237442057902437,\n",
       " 'wh comput': 0.0003230190965536749,\n",
       " 'jamesppesch facebook': 0.00032175355334011275,\n",
       " 'opt': 0.0003190033055549536,\n",
       " 'mark': -0.00031815993348604393,\n",
       " 'journal get': 0.00031733139737791233,\n",
       " 'asset': -0.00031681882358258057,\n",
       " 'study': 0.00031681229811424203,\n",
       " 'happy': 0.00031657213228450214,\n",
       " 'regards': -0.00031508989472930156,\n",
       " 'stori share': -0.0003146960116881867,\n",
       " 'respectively': -0.0003072380783010766,\n",
       " 'topic interest': -0.00030479679000635105,\n",
       " 'hello': 0.00030269377537066734,\n",
       " 'compromis': 0.0003025151272776222,\n",
       " 'll see': -0.0002968292773203983,\n",
       " 'outlook': -0.0002958978394273765,\n",
       " 'olfactori anchor': 0.0002938901234013922,\n",
       " 'data comput': 0.00029259910610074136,\n",
       " 'yelp reviews': -0.00029191487551295564,\n",
       " 'minutes': -0.0002871843897181596,\n",
       " 'episode': 0.00028681629383019375,\n",
       " 'in': -0.0002867950973923756,\n",
       " 'manipul peopl': 0.0002853223355606197,\n",
       " 'share prescript': -0.00028362200438501414,\n",
       " 'tr ds': -0.0002831837961382856,\n",
       " 'nlp tri': -0.00028234973819658523,\n",
       " 'power new': -0.00028067263926079847,\n",
       " 'bart larg': 0.00027993875543739415,\n",
       " 'if': 0.00027674522003764046,\n",
       " 'summar dataset': -0.0002759721098200698,\n",
       " 'stemming': 0.00027347172768147916,\n",
       " 'guidelin': 0.00027325852457059103,\n",
       " 'managem': 0.0002726458554232242,\n",
       " 'evalu it': -0.0002723282574078965,\n",
       " 'la': -0.00027187312347187005,\n",
       " 'thought share': 0.00027094194901079055,\n",
       " 'slp': 0.000269969976026551,\n",
       " 'nlp understand': 0.0002685640440278054,\n",
       " 'label data': -0.00026852031893488573,\n",
       " 'jordan': -0.000268251690999965,\n",
       " 'person get': 0.0002673100745263629,\n",
       " 'except': 0.00026684633747200764,\n",
       " 'byte': 0.0002649532074604797,\n",
       " 'learn nlp': 0.0002636260366323769,\n",
       " 'understand': 0.00026315974361309293,\n",
       " 'new articl': -0.00026288394573371627,\n",
       " 'sophist': 0.0002626147547350584,\n",
       " 'one idea': -0.0002621072533695724,\n",
       " 'ant': 0.0002588768945150599,\n",
       " 'png': 0.0002568226926190487,\n",
       " 'experim ting': 0.00025589982828477326,\n",
       " 'comput linguistics': -0.0002544979265262533,\n",
       " 'microsoft marian': 0.00025418575817814015,\n",
       " 'peopl': 0.0002527753180014624,\n",
       " 'hu': 0.00025264420981545554,\n",
       " 'gali': 0.00025120741005140644,\n",
       " 'metaphor analysi': 0.00025059768271449434,\n",
       " 'hear someon': 0.0002495886726954843,\n",
       " 'tri tim': -0.0002493178077258543,\n",
       " 'rainbow': 0.00024924837732044787,\n",
       " 'searches': 0.00024848130459415355,\n",
       " 'always': 0.0002478161124842531,\n",
       " 'error': 0.00024780783546678414,\n",
       " 'nlp practitioner': 0.00024774163460922275,\n",
       " 'tradit': 0.0002472862006134906,\n",
       " 'sites': -0.0002469325376077202,\n",
       " 'degre': 0.00024626378498529935,\n",
       " 'dollar': -0.0002457514817981323,\n",
       " 'piec': -0.0002457514817981323,\n",
       " 'wrap': -0.0002457514817981323,\n",
       " 'shreyansh github': -0.0002449894216047325,\n",
       " 'idf method': -0.0002446844703751962,\n",
       " 'beach': -0.00024338520423226694,\n",
       " 'raw data': 0.00024217506224470412,\n",
       " 'range': -0.00024112229662279737,\n",
       " 'chinese japanese': -0.0002409734764100991,\n",
       " 'real life': 0.0002404515986518835,\n",
       " 'principl': -0.00024017935201138806,\n",
       " 'first train': 0.00023957361637383655,\n",
       " 'korean languag': -0.00023799172322643204,\n",
       " 'els describ': 0.00023780581626256059,\n",
       " 'studi comput': -0.00023697529887280416,\n",
       " 'link read': 0.0002359188241700232,\n",
       " 'receiv': 0.000235897097320105,\n",
       " 'ce betw': -0.000234738663410435,\n",
       " 'nlp dataset': 0.00023390978520525224,\n",
       " 'pleas help': 0.00023382009104069964,\n",
       " 'online': 0.00023302109578751096,\n",
       " 'way go': 0.00023177980198716184,\n",
       " 'work on': 0.00023072771254367135,\n",
       " 'find quit': -0.00023058793689134218,\n",
       " 'quick': 0.0002280870095552973,\n",
       " 'featur new': 0.00022745539581517176,\n",
       " 'would possibl': 0.00022679772508842769,\n",
       " 'xlnet': 0.00022664774675128495,\n",
       " 'nlp applic': 0.0002260934196126817,\n",
       " 'trepr': 0.00022503625283880213,\n",
       " 'anxiety th': 0.000223302537485022,\n",
       " 'epoch': 0.00022245625585406135,\n",
       " 'class classif': -0.0002205173759539702,\n",
       " 'someon help': -0.00022023129222170767,\n",
       " 'automat extract': 0.00021903292473902315,\n",
       " 'master stud': -0.0002174086550487976,\n",
       " 'higher level': 0.00021710843922475342,\n",
       " 'chick': -0.00021700283987817164,\n",
       " 'like tri': -0.0002165955213496635,\n",
       " 'kinesthet': 0.0002155335424260479,\n",
       " 'high accuraci': -0.00021462763757095494,\n",
       " 'word repr': 0.00021458693857993722,\n",
       " 'webp amp': 0.00021367031627368447,\n",
       " 'mt': 0.00021219984482188868,\n",
       " 'leadership': -0.00021184426927321214,\n",
       " 'relation tempor': 0.00021171819296748542,\n",
       " 'chines word': 0.00021168654031152978,\n",
       " 'ext ding': 0.00020933144194831238,\n",
       " 'embed word': 0.00020906897767359957,\n",
       " 'read one': 0.00020825232169097765,\n",
       " 'embed bert': 0.00020811367853096991,\n",
       " 'tailm': -0.00020801465826599967,\n",
       " 'secondari': 0.00020783139001578349,\n",
       " 'though': 0.0002068541399093271,\n",
       " 'hot labels': -0.0002065961538786311,\n",
       " 'lab': 0.0002062536248041549,\n",
       " 'fear height': 0.00020582796375431044,\n",
       " 'th fine': 0.00020514917007809956,\n",
       " 'whether may': 0.00020476712825596746,\n",
       " 'meta': 0.00020441009397341166,\n",
       " 'deploy model': 0.0002031573826205636,\n",
       " 'fears': 0.00020239780147322556,\n",
       " 'python not': 0.00019830034626764446,\n",
       " 'practition course': -0.0001981207568996328,\n",
       " 'exist model': 0.00019761049011299226,\n",
       " 'monday': -0.0001974043574474027,\n",
       " 'make list': 0.00019495712347382665,\n",
       " 'hebrew': 0.00019415802830473791,\n",
       " 'pattern amp': 0.00019408962983776147,\n",
       " 'colleg london': 0.00019295717289780103,\n",
       " 'criteria': -0.00019163126146430078,\n",
       " 'activ': 0.00019154799237907423,\n",
       " 'nlu support': 0.00019144317284157335,\n",
       " 'legitim': 0.00019088389215668824,\n",
       " 'model appli': 0.00019053394299216312,\n",
       " 'flu english': -0.00018973446197267745,\n",
       " 'money': -0.00018851985133213066,\n",
       " 'input like': -0.00018789689061409767,\n",
       " 'formul': -0.00018786729178918633,\n",
       " 'revers gineer': 0.00018678102296460712,\n",
       " 'reach': 0.00018628283674214442,\n",
       " 'find differ': -0.00018606303200997026,\n",
       " 'intermedi level': -0.00018602882638691653,\n",
       " 'gre': 0.00018579750301380956,\n",
       " 'trick mind': 0.00018579021560422034,\n",
       " 'use ml': -0.00018504815907716406,\n",
       " 'data text': 0.0001834242174652829,\n",
       " 'smoke cigarette': 0.00018255793844842346,\n",
       " 'paraphrases': 0.00018210711242062886,\n",
       " 'friday': 0.0001803243148913538,\n",
       " 'like cluster': -0.00017979487308848673,\n",
       " 'nlp thanks': -0.00017901792391766843,\n",
       " 'becom reality': 0.00017850728797815936,\n",
       " 'gestur erat': -0.0001783405485611174,\n",
       " 'campaign fcc': 0.00017733083071006263,\n",
       " 'topic modelling': -0.00017654503135117262,\n",
       " 'model train': 0.00017641021733350306,\n",
       " 'want put': 0.00017583134815435297,\n",
       " 'vak': -0.00017569794811952017,\n",
       " 'would great': 0.0001753414258751481,\n",
       " 'discov nlp': -0.0001749396149502146,\n",
       " 'bind': -0.00017434570074030146,\n",
       " 'duti': -0.00017428772968971422,\n",
       " 'prov wrong': 0.00017367107418222742,\n",
       " 'math': 0.00017222807917551892,\n",
       " 'yield': -0.00017207248685933844,\n",
       " 'nlp ask': 0.00017174173657653088,\n",
       " 'volum': 0.00017162805736884912,\n",
       " 'decis': -0.0001715602382349249,\n",
       " 'lot': 0.00017139095232405953,\n",
       " 'nlp coaching': 0.0001707426072137968,\n",
       " 'states': 0.0001702439931064837,\n",
       " 'grasp': 0.00016978588664353365,\n",
       " 'older': 0.00016971741055637682,\n",
       " 'commun nlp': -0.00016965124884776633,\n",
       " 'from': 0.0001691022029427411,\n",
       " 'deploy': 0.00016907920785040522,\n",
       " 'draft': -0.00016905057758433536,\n",
       " 'associ': -0.00016868489506129253,\n",
       " 'tional': 0.00016859036276086148,\n",
       " 'multi label': 0.00016753102569623193,\n",
       " 'msc': 0.000166427478401887,\n",
       " 'chang model': 0.00016465396546725065,\n",
       " 'certain way': 0.00016429061777981695,\n",
       " 'statem': 0.00016282522364736404,\n",
       " 'and learn': 0.0001624681376935974,\n",
       " 'charact': 0.00016112796098501634,\n",
       " 'model name': -0.0001605650116969229,\n",
       " 'txtai': -0.00016006644961454822,\n",
       " 'may': 0.0001597604313124515,\n",
       " 'wors': -0.00015975399539306864,\n",
       " 'crash': -0.00015909640895658475,\n",
       " 'indic': -0.00015902853174128658,\n",
       " 'manually': 0.0001585804934396364,\n",
       " 'tutorial': -0.00015825956064141324,\n",
       " 'made': 0.00015769924772287116,\n",
       " 'well ough': 0.0001576052602088766,\n",
       " 'transact': 0.00015737180352072967,\n",
       " 'measur': 0.00015733397724454316,\n",
       " 'person growth': -0.00015687155459359774,\n",
       " 'cont be': 0.00015618484242324024,\n",
       " 'download': 0.00015611277320641098,\n",
       " 'metamodel': 0.00015606106998682296,\n",
       " 'success would': 0.00015554645264216356,\n",
       " 'deriv': 0.00015544366516593574,\n",
       " 'af': -0.00015467882423392354,\n",
       " 'nlp certif': -0.00015458923997604685,\n",
       " 'ize ce': -0.00015389527815045788,\n",
       " 'chang belief': -0.00015377113944334812,\n",
       " 'compani work': 0.0001536858619855623,\n",
       " 'random': -0.00015339968664328452,\n",
       " 'hello all': 0.0001525265748061019,\n",
       " 'classif nlp': 0.00015251197191113228,\n",
       " 'medication': -0.00015190945880458456,\n",
       " 'nlp recomm': 0.00015093708208119107,\n",
       " 'teach nlp': 0.00015057785332656137,\n",
       " 'visualization': 0.00015053822194522235,\n",
       " 'link blog': -0.00015049040222903895,\n",
       " 'nlp curr': -0.00015036384350332888,\n",
       " 'laughs': 0.00015006635343511675,\n",
       " 'know talk': -0.0001500227510044848,\n",
       " 'lost': -0.00014943678641770913,\n",
       " 'personally think': -0.0001493243534938729,\n",
       " 'use cosin': 0.00014883779838930798,\n",
       " 'erat system': -0.00014844836584279703,\n",
       " 'abl help': -0.00014825006127094955,\n",
       " 'technolog': 0.0001479551667779491,\n",
       " 'someon provid': 0.0001473668925187551,\n",
       " 'admiss': 0.0001473668925187551,\n",
       " 'use topic': -0.00014666523301711188,\n",
       " 'news tim': -0.00014609494127510402,\n",
       " 'much differ': 0.00014591430347309024,\n",
       " 'second question': 0.00014555147300558615,\n",
       " 'level rapport': -0.00014554907053961123,\n",
       " 'packag seem': 0.0001455363391531725,\n",
       " 'nlp think': 0.00014476343749392955,\n",
       " 'nvidia': -0.0001447271014311213,\n",
       " 'helps': 0.00014422571447482332,\n",
       " 'attitud': 0.00014398698077274522,\n",
       " 'recognit asr': -0.0001438611873720216,\n",
       " 'guid nlp': -0.00014383234605049223,\n",
       " 'unsupervis': 0.00014366857808833193,\n",
       " 'custom dataset': -0.00014277728224442325,\n",
       " 'look forward': 0.00014264652646241,\n",
       " 'discuss': 0.0001425437172962881,\n",
       " 'https': -0.00014221301547767,\n",
       " 'iclr': -0.00014214818544567003,\n",
       " 'realli practic': 0.00014182355972709737,\n",
       " 'embeddings': 0.00014165887559686624,\n",
       " 'achiev peak': 0.00014137153667997,\n",
       " 'founder': -0.00014113316981047812,\n",
       " 'wether': -0.00014093779011473465,\n",
       " 'synset': -0.00014087492459806107,\n",
       " 'slow': 0.00014071548871727745,\n",
       " 'also come': -0.00014065998911422226,\n",
       " 'bring': 0.0001405152948390797,\n",
       " 'sort thing': 0.00014051431591448826,\n",
       " 'nlp school': -0.00014029987991398437,\n",
       " 'model work': 0.00014027525271529336,\n",
       " 'brain mind': 0.00013946255734592983,\n",
       " 'classif problem': -0.00013931981640655377,\n",
       " 'ig': 0.00013926443605672353,\n",
       " 'contemporari': 0.00013912917970730783,\n",
       " 'train ai': -0.00013869826787903973,\n",
       " 'interest machin': -0.00013860067197342033,\n",
       " 'another': 0.0001367967699775694,\n",
       " 'dumb': 0.00013657594503485194,\n",
       " 'prefer': 0.000136485362935025,\n",
       " 'coupl day': 0.00013641194630564075,\n",
       " 'latest nlu': -0.00013624919864397894,\n",
       " 'messag': -0.00013620890603170552,\n",
       " 'categori': -0.00013613848270476524,\n",
       " 'spaci model': 0.0001359112109821758,\n",
       " 'ipynb nlu': -0.0001358129699290419,\n",
       " 'sev': 0.00013555607966486566,\n",
       " 'access gpt': -0.00013548279236091015,\n",
       " 'anyon read': 0.00013543245556277983,\n",
       " 'question follow': 0.00013537230319808231,\n",
       " 'someon tere': 0.0001350940726952922,\n",
       " 'speech tag': 0.00013468726420370322,\n",
       " 'anyon share': 0.00013462721996181817,\n",
       " 'ridicul': -0.00013427856950342176,\n",
       " 'high': 0.00013413130834247444,\n",
       " 'german train': -0.00013403478700882941,\n",
       " 'ev extract': 0.00013400755359409727,\n",
       " 'static': 0.0001334685570021326,\n",
       " 'model nlpcloud': 0.00013344726565931174,\n",
       " 'could summar': -0.00013328813402094773,\n",
       " 'stopword removal': -0.00013290224958424656,\n",
       " 'program look': 0.00013286122687970915,\n",
       " 'stream': 0.00013260850773482534,\n",
       " 'purpos': -0.0001323257025526964,\n",
       " 'dep cie': -0.0001321210258555497,\n",
       " 'need take': 0.00013153859249916198,\n",
       " 'techniqu either': -0.00013138843014563016,\n",
       " 'leader': 0.00013133963829407887,\n",
       " 'say someth': -0.000131178065890252,\n",
       " 'norm': 0.00013111933229702634,\n",
       " 'new behavior': -0.0001308793846639441,\n",
       " 'nature': -0.0001308390648711054,\n",
       " 'erat transform': 0.0001305408397475777,\n",
       " 'anatomi': -0.00013047909901060041,\n",
       " 'anchor': 0.00013041989479742398,\n",
       " 'tell me': 0.00013014504840015392,\n",
       " 'read first': -0.00012971048591417487,\n",
       " 'classif use': -0.00012968346606154706,\n",
       " 'link': 0.00012956914757880674,\n",
       " 'repository': -0.0001294636714895904,\n",
       " 'travel': -0.0001292936490696233,\n",
       " 'gpt': -0.00012909148504383248,\n",
       " 'extract ner': -0.0001287335478293338,\n",
       " 'fine': -0.0001287043735180858,\n",
       " 'know keyword': 0.00012842001531191986,\n",
       " 'load zh': -0.0001284087031396409,\n",
       " 'check articl': -0.00012840334699070643,\n",
       " 'sure': 0.00012828610316338498,\n",
       " 'banner': 0.00012821918744040594,\n",
       " 'model would': 0.0001281408280337239,\n",
       " 'also note': -0.000128086353395295,\n",
       " 'each': 0.0001280514303934268,\n",
       " 'come play': -0.00012799384188544015,\n",
       " 'section': 0.00012775185608329164,\n",
       " 'op domain': -0.0001271974770320674,\n",
       " 'grone': -0.00012709609933550726,\n",
       " 'react': 0.0001268004531581559,\n",
       " 'techniqu help': -0.0001263969488809817,\n",
       " 'via video': -0.00012620818887558064,\n",
       " 'users': 0.00012613136579929778,\n",
       " 'enhanc': -0.00012600451336820616,\n",
       " 'ts want': -0.00012571296158762478,\n",
       " 'coupl': 0.0001253596068769845,\n",
       " 'aforem': 0.0001251185739170516,\n",
       " 'learn faster': -0.0001249558941284369,\n",
       " 'notebook nlu': -0.0001248895100349497,\n",
       " 'body': -0.00012455939660647121,\n",
       " 'use semant': 0.00012451046910873643,\n",
       " 'float around': -0.00012422193280060788,\n",
       " 'sinc th': 0.00012420182814315334,\n",
       " 'abc nlp': 0.00012403671682338025,\n",
       " 'machin learning': -0.00012394518424774942,\n",
       " 'convinc': 0.00012382302577044295,\n",
       " 'thing alreadi': -0.00012343674465899125,\n",
       " 'without give': 0.0001230968315438333,\n",
       " 'outdat': -0.00012284916808454576,\n",
       " 'tag word': -0.00012253690790416756,\n",
       " 'best method': -0.0001219376545661235,\n",
       " 'nlpers': -0.00012161994532466676,\n",
       " 'continue': -0.00012152482987232691,\n",
       " 'playful': -0.00012131811356876703,\n",
       " 'wing': 0.0001211895152574206,\n",
       " 'book att': -0.00012117526287719392,\n",
       " 'improvem ts': -0.00012080997313762803,\n",
       " 'meta program': 0.00012077574442294841,\n",
       " 'tli use': 0.00012073869984769597,\n",
       " 'think name': 0.0001206347123708622,\n",
       " 'check website': -0.00012018416606023963,\n",
       " 'wanna': -0.00012006410641754027,\n",
       " 'help us': -0.00011996919755084535,\n",
       " 'him': 0.00011936392745540142,\n",
       " 'ce docum': -0.00011914585529358045,\n",
       " 'scale': -0.00011897748024318347,\n",
       " 'larg text': 0.00011894546929435649,\n",
       " 'support coach': -0.0001187311670374903,\n",
       " 'feelings': 0.00011864368920839268,\n",
       " 'xb final': 0.00011838263237970092,\n",
       " 'str gth': -0.00011837095974165569,\n",
       " 'pred': -0.00011837095974165569,\n",
       " 'wh get': -0.00011800980216341864,\n",
       " 'nlp might': -0.00011757807393725621,\n",
       " 'big one': -0.00011757807393725621,\n",
       " 'som': -0.00011753906198740252,\n",
       " 'deal': 0.00011747488314029712,\n",
       " 'look into': -0.00011685084641547979,\n",
       " 'noob': -0.00011666490607732528,\n",
       " 'behavior expert': -0.00011648037319459306,\n",
       " 'due covid': 0.00011634431375859558,\n",
       " 'high perform': 0.00011629982012839368,\n",
       " 'freeli avail': -0.00011617721754830505,\n",
       " 'data custom': -0.00011617222232042543,\n",
       " 'blog': 0.00011615453145038325,\n",
       " 'age': -0.000115984597649134,\n",
       " 'psycholog time': -0.00011573695774548697,\n",
       " 'verb': -0.00011573695774548697,\n",
       " 'descript': 0.00011540455405849775,\n",
       " 'caring': -0.0001152901372264761,\n",
       " 'it wh': -0.0001152901372264761,\n",
       " 'short': -0.00011523171753904932,\n",
       " 'rudim': 0.00011511410613440699,\n",
       " 'you': -0.00011510617310587609,\n",
       " 'second one': 0.00011499043542077833,\n",
       " 'similar kind': -0.00011498249128434108,\n",
       " 'audio transcript': 0.00011473216211503362,\n",
       " 'models bert': -0.00011454452562461703,\n",
       " 'comparison betw': -0.00011452685711032783,\n",
       " 'mission': 0.0001140588323951702,\n",
       " 'messy': 0.00011382423876680743,\n",
       " 'nest': 0.00011368795565979114,\n",
       " 'worker': 0.00011350778129585681,\n",
       " 'anyon list': 0.00011338957470260618,\n",
       " 'paper summari': 0.00011335986130878159,\n",
       " 'resolve': 0.00011326533480183785,\n",
       " 'ote': -0.00011296760401352442,\n",
       " 'docum level': 0.000112210750042406,\n",
       " 'sim lda': -0.00011212160046233859,\n",
       " 'train time': -0.00011205813978302552,\n",
       " 'second': -0.00011198027271877998,\n",
       " 'hear thought': -0.00011197237402974097,\n",
       " 'fuzzi match': -0.00011195244652571215,\n",
       " 'one': 0.00011187394912412586,\n",
       " 'god': -0.00011158214780813652,\n",
       " 'udemy': 0.00011132747384692872,\n",
       " 'white': 0.0001111041603491578,\n",
       " 'book nlp': 0.00011109040380114773,\n",
       " 'speech tagger': -0.00011098347931054825,\n",
       " 'stop work': -0.00011075052443757249,\n",
       " 'sh': -0.00011072652024487432,\n",
       " 'recogn': 0.00011057158276756346,\n",
       " 'implem tation': -0.00011050749537152535,\n",
       " 'didn know': 0.00011028312846225208,\n",
       " 'book subject': -0.00011016232120274609,\n",
       " 'situation thank': -0.00011003460118776977,\n",
       " 'avail free': 0.00010991369248484144,\n",
       " 'qualiti nlp': -0.00010974258442461339,\n",
       " 'ev know': -0.00010947314352957637,\n",
       " 'accuraci marktechpost': 0.00010933433470553257,\n",
       " 'sinc sub': 0.00010930748182701788,\n",
       " 'japanese korean': 0.00010896784477938021,\n",
       " 'use op': -0.00010877590624438219,\n",
       " 'heal': -0.00010856789732399517,\n",
       " 'check grammar': -0.00010851901795827005,\n",
       " 'model use': -0.00010817074250000025,\n",
       " 'th go': 0.00010780699688731787,\n",
       " 'train it': -0.00010758322851009198,\n",
       " 'problem problem': -0.00010756462648333435,\n",
       " 'mind awar': 0.00010750745712765183,\n",
       " 'ce stud': 0.00010740749296840856,\n",
       " 'softwar model': -0.00010721012904707053,\n",
       " 'dead': -0.00010678146018479726,\n",
       " 'talk nlp': -0.00010655242102167018,\n",
       " 'applic curr': -0.0001064676879215433,\n",
       " 'theori behind': 0.00010634240658526832,\n",
       " 'tv': 0.00010629674802458181,\n",
       " 'project nlp': 0.00010603796168427072,\n",
       " 'di tangl': -0.00010601160382820078,\n",
       " 'motivation': -0.0001059324547820071,\n",
       " 'explained': -0.00010548536767104863,\n",
       " 'would expect': 0.000105173956884762,\n",
       " 'way get': 0.00010510849786277386,\n",
       " 'wrote articl': -0.00010500196678790905,\n",
       " 'put': 0.00010489873101163718,\n",
       " 'hood': -0.00010476830500120883,\n",
       " 'dont': -0.00010474511490550056,\n",
       " 'instanc': 0.0001047226157704292,\n",
       " 'unlabel': -0.0001044903530850189,\n",
       " 'research team': 0.00010427217930372159,\n",
       " 'nlp pattern': 0.00010424915767279165,\n",
       " 'influ': 0.00010403926659980205,\n",
       " 'keep go': 0.00010372889835749002,\n",
       " 'this wh': 0.00010359470779279159,\n",
       " 'see improv': -0.00010280790503679321,\n",
       " 'live in': 0.00010260849236632863,\n",
       " 'learn grow': -0.00010257316400026672,\n",
       " 'sequ ce': -0.00010256763854795634,\n",
       " 'cool': 0.00010207739960865745,\n",
       " 'angri surpris': 0.00010206736333849897,\n",
       " 'one better': -0.00010169270061161645,\n",
       " 'string match': 0.000101691792558905,\n",
       " 'ambit': 0.00010165177934730497,\n",
       " 'memories': -0.00010138765669779248,\n",
       " 'here want': 0.00010132320883336098,\n",
       " 'two years': -0.00010120141926005661,\n",
       " 'make feel': 0.0001010597408585173,\n",
       " 'etc': -0.00010104921541827404,\n",
       " 'one label': 0.00010097345284590377,\n",
       " 'el': 0.00010078717681701388,\n",
       " 'someth came': 0.0001007311745522923,\n",
       " 'companies': 0.00010045071828972135,\n",
       " 'demo nlp': -0.00010042646001226841,\n",
       " 'entiti relat': 0.00010041489082839672,\n",
       " 'back mind': -0.00010028329916864326,\n",
       " 'level docum': 0.00010008266676697877,\n",
       " 'discoveri': 9.999328656787215e-05,\n",
       " 'classifi train': -9.989796019297065e-05,\n",
       " 'likewise': -9.984915030094085e-05,\n",
       " 'night': -9.979190182607227e-05,\n",
       " 'embed vector': -9.9459801906189e-05,\n",
       " 'concat ate': -9.9459801906189e-05,\n",
       " 'alway interest': -9.9459801906189e-05,\n",
       " 'vision': -9.915645332021092e-05,\n",
       " 'backwards': -9.915645332021092e-05,\n",
       " 'tinker': -9.915645332021092e-05,\n",
       " 'ter said': 9.914577476984329e-05,\n",
       " 'hello guys': 9.908475385967603e-05,\n",
       " 'constitu cy': -9.903947961997293e-05,\n",
       " 'nlp exist': 9.898487676068189e-05,\n",
       " 'product': -9.891160863419136e-05,\n",
       " 'need read': 9.882425893940872e-05,\n",
       " 'better idea': 9.846265565923939e-05,\n",
       " 'by': -9.821605915603755e-05,\n",
       " 'dousli': 9.80331879226472e-05,\n",
       " 'learning': 9.780204213249405e-05,\n",
       " 'text messag': 9.765561063397761e-05,\n",
       " 'explan': -9.761762125726121e-05,\n",
       " 'tag': 9.734677657340248e-05,\n",
       " 'finetun sst': 9.727254753966273e-05,\n",
       " 'slack join': -9.723778772149469e-05,\n",
       " 'bad habit': -9.717356673875351e-05,\n",
       " 'critic': 9.713801274150152e-05,\n",
       " 'common se': 9.713801274150152e-05,\n",
       " 'github shreyansh': -9.705881616336366e-05,\n",
       " 'processing': 9.700850965273588e-05,\n",
       " 'unabl': 9.677493567425988e-05,\n",
       " 'trade': 9.660641616024115e-05,\n",
       " 'anyon point': -9.660014115896672e-05,\n",
       " 'googl': 9.657684359376566e-05,\n",
       " 'pleas consid': -9.65232440137447e-05,\n",
       " 'med': -9.651813732285952e-05,\n",
       " 'dataset can': -9.651813732285952e-05,\n",
       " 'univers uk': 9.628635978152374e-05,\n",
       " 'efici': 9.623395696673598e-05,\n",
       " 'found': -9.614358205576116e-05,\n",
       " 'augm': -9.606929931949809e-05,\n",
       " 'bite': -9.606929931949809e-05,\n",
       " 'tool nlp': -9.605280061918962e-05,\n",
       " 'well number': -9.600663572835699e-05,\n",
       " 'outputs': 9.59494210018361e-05,\n",
       " 'get accuraci': -9.59150033228385e-05,\n",
       " 'stemm classifi': 9.585385754937121e-05,\n",
       " 'op': -9.577446187074167e-05,\n",
       " 'limitations': -9.563749971606107e-05,\n",
       " 'word embedding': -9.563749971606107e-05,\n",
       " 'good resource': -9.563749971606107e-05,\n",
       " 'conquer': 9.559518405083921e-05,\n",
       " 'machin read': -9.543848418949266e-05,\n",
       " 'nlp time': 9.52897405352379e-05,\n",
       " 'know there': -9.504592137136875e-05,\n",
       " 'also much': -9.504592137136875e-05,\n",
       " 'hundr': -9.491968549465768e-05,\n",
       " 'dissert': 9.486624579539853e-05,\n",
       " 'load bh': -9.481266986966714e-05,\n",
       " 'apis': 9.457997901809298e-05,\n",
       " 'calculu': 9.457131641129801e-05,\n",
       " 'constitu': -9.443910373748123e-05,\n",
       " 'get nlp': 9.442777940588205e-05,\n",
       " 'search paper': -9.442182797712523e-05,\n",
       " 'hmm': -9.426588029289867e-05,\n",
       " 'probabl need': -9.425888220511246e-05,\n",
       " 'know common': 9.42561320386881e-05,\n",
       " 'imag processing': -9.420566058076274e-05,\n",
       " 'make next': 9.403825404532062e-05,\n",
       " 'look success': -9.396854115705139e-05,\n",
       " 'sci tific': 9.385626478522644e-05,\n",
       " 'talk about': -9.385597553280998e-05,\n",
       " 'sport': 9.368530758947286e-05,\n",
       " 'naturallanguage': 9.357244215075696e-05,\n",
       " 'crawl': 9.354213823687885e-05,\n",
       " 'would good': 9.339572587197174e-05,\n",
       " 'start make': -9.333772647959377e-05,\n",
       " 'main reason': -9.332259520358873e-05,\n",
       " 'chang world': -9.327045138705528e-05,\n",
       " 'hire': 9.302395431415875e-05,\n",
       " 'summari': 9.294396977752703e-05,\n",
       " 'matter minutes': -9.292178066986058e-05,\n",
       " 'approach find': 9.2886041227408e-05,\n",
       " 'mani time': -9.269423674306606e-05,\n",
       " 'thorough understand': -9.261647082386368e-05,\n",
       " 'wh ask': 9.246369791265406e-05,\n",
       " 'cc': 9.240449129768293e-05,\n",
       " 'imo': -9.229731187527384e-05,\n",
       " 'war': 9.226774844031152e-05,\n",
       " 'two amp': 9.225621563724613e-05,\n",
       " 'train ner': 9.22342136090996e-05,\n",
       " 'luck': 9.213900774199366e-05,\n",
       " 'false': -9.202650553471084e-05,\n",
       " 'piss': 9.196561013559434e-05,\n",
       " 'tune': -9.181873296607288e-05,\n",
       " 'model fastapi': -9.176849408204857e-05,\n",
       " 'destruct': 9.169687694343345e-05,\n",
       " 'theirs': -9.168111897483731e-05,\n",
       " 'help trigger': 9.150164281784834e-05,\n",
       " 'like move': -9.149274415766648e-05,\n",
       " 'apolog': 9.146395515973013e-05,\n",
       " 'developm psychotherapi': 9.142965128779715e-05,\n",
       " 'syndrome': -9.135040320221182e-05,\n",
       " 'lean toward': -9.108644710088373e-05,\n",
       " 'answer model': -9.103796317180569e-05,\n",
       " 'know python': 9.088090814943521e-05,\n",
       " 'embeddings github': 9.086945314327529e-05,\n",
       " 'order find': -9.083153221626068e-05,\n",
       " 'help out': -9.083153221626068e-05,\n",
       " 'noob question': -9.079948938214713e-05,\n",
       " 'num': -9.077491534521188e-05,\n",
       " 'rust': -9.071002483142037e-05,\n",
       " 'low resourc': -9.046199062092642e-05,\n",
       " 'someth quit': 9.023999489064684e-05,\n",
       " 'earli': 9.014022771237939e-05,\n",
       " 'nlp question': -9.006278441989044e-05,\n",
       " 'make corpu': 9.004258248267462e-05,\n",
       " 'internship': 8.998812681026839e-05,\n",
       " 'balanc betw': 8.977875297117946e-05,\n",
       " 'flew cuckoo': 8.972526998184778e-05,\n",
       " 'think would': -8.971365694613603e-05,\n",
       " 'algorithm': -8.967061961516693e-05,\n",
       " 'approxim': -8.967061961516693e-05,\n",
       " 'light this': -8.964798125363216e-05,\n",
       " 'prone': 8.945418773681152e-05,\n",
       " 'topic convers': -8.938111214885778e-05,\n",
       " 'eleutherai': 8.927120966200985e-05,\n",
       " 'api tool': 8.922182658777729e-05,\n",
       " 'excit releas': -8.917524215687806e-05,\n",
       " 'bert': -8.916666616243935e-05,\n",
       " 'closer': -8.913970525342116e-05,\n",
       " 'ce result': 8.912013122172076e-05,\n",
       " 'cross post': -8.906376800160522e-05,\n",
       " 'ts last': -8.902625129182662e-05,\n",
       " 'path': 8.900109506539074e-05,\n",
       " 'master program': 8.859375151651022e-05,\n",
       " 'expert tutor': -8.827649723737609e-05,\n",
       " 'distanc result': 8.821368793209434e-05,\n",
       " 'provid insight': 8.820097056462024e-05,\n",
       " 'similar word': -8.81692272426468e-05,\n",
       " 'github post': 8.794696872666563e-05,\n",
       " 'anybodi recomm': -8.771790304242533e-05,\n",
       " 'crash fix': -8.768989357235473e-05,\n",
       " 'preview redd': 8.754189335103955e-05,\n",
       " 'refr ce': -8.750106774239939e-05,\n",
       " 'word model': -8.747324129352151e-05,\n",
       " 'late': -8.741335779379603e-05,\n",
       " 'task could': -8.738913690841717e-05,\n",
       " 'model normal': -8.730646165504169e-05,\n",
       " 'tutori cover': -8.728848333106553e-05,\n",
       " 'would greatli': 8.727255067784873e-05,\n",
       " 'scratch': -8.721176777836461e-05,\n",
       " 'seminar': 8.699931797821612e-05,\n",
       " 'nlp trainer': -8.694918869877957e-05,\n",
       " 'transform import': -8.681333385400259e-05,\n",
       " 'base uncased': -8.681333385400259e-05,\n",
       " 'annotator': -8.681333385400259e-05,\n",
       " 'corpu get': 8.654348866114393e-05,\n",
       " 'izat': -8.652799727249921e-05,\n",
       " 'concept could': 8.647528249260274e-05,\n",
       " 'spare time': -8.645725972061816e-05,\n",
       " 'nlp feel': -8.622334634707135e-05,\n",
       " 'paper github': -8.622334634707135e-05,\n",
       " 'bypass': -8.604817478707828e-05,\n",
       " 'nlp gineer': 8.604018718873387e-05,\n",
       " 'zh': -8.598750347645675e-05,\n",
       " 'shown': -8.595228598584786e-05,\n",
       " 'th chang': 8.594134421997931e-05,\n",
       " 'nlu library': 8.586548307517588e-05,\n",
       " 'dive': 8.586059173108619e-05,\n",
       " 'someon know': 8.572405204923514e-05,\n",
       " 'ressourc nlu': 8.54903592926664e-05,\n",
       " 'wolf': -8.544166977886785e-05,\n",
       " 'symbol repr': -8.537126568186051e-05,\n",
       " 'import spaci': -8.53055219443531e-05,\n",
       " 'explain well': 8.528580924475429e-05,\n",
       " 'regret': -8.526615705471707e-05,\n",
       " 'author topic': -8.526537384507525e-05,\n",
       " 'test eval': -8.495707497683077e-05,\n",
       " 'tell': 8.49388302216322e-05,\n",
       " 'arbitrari': -8.48567265689208e-05,\n",
       " 'nlp sub': -8.48152386404838e-05,\n",
       " 'lot work': -8.46447437757538e-05,\n",
       " 'want like': -8.461676521569152e-05,\n",
       " 'build trust': 8.460705923442564e-05,\n",
       " 'quit like': -8.458062592513175e-05,\n",
       " 'kinesthetic': -8.442487781034762e-05,\n",
       " 'gage': -8.43470658229676e-05,\n",
       " 'tell stori': 8.406595067085221e-05,\n",
       " 'regul': -8.400516930977733e-05,\n",
       " 'guy help': -8.399887420159821e-05,\n",
       " 'day seminar': 8.38715904098849e-05,\n",
       " 'nlu nlu': -8.386528285223114e-05,\n",
       " 'sessions': -8.373365022566599e-05,\n",
       " 'right use': 8.33843012999112e-05,\n",
       " 'japanes': -8.331707863015511e-05,\n",
       " 'like nlp': -8.325289883301935e-05,\n",
       " 'off also': 8.311596049349383e-05,\n",
       " 'titi get': 8.305894227417758e-05,\n",
       " 'mani sub': -8.292243735402708e-05,\n",
       " 'topic problem': -8.291472461786022e-05,\n",
       " 'plug': -8.280249066041666e-05,\n",
       " 'know dataset': -8.264209209840765e-05,\n",
       " 'modul': -8.26271735103962e-05,\n",
       " 'app nlp': 8.235054239622331e-05,\n",
       " 'attack': -8.219007949827604e-05,\n",
       " 'phobia': -8.214042316357336e-05,\n",
       " 'list name': -8.212764769687796e-05,\n",
       " 'wh nlp': -8.210037404541872e-05,\n",
       " 'cigarette': 8.206744001935075e-05,\n",
       " 'way make': 8.190964661921259e-05,\n",
       " 'ran': -8.190512615118283e-05,\n",
       " 'thing like': 8.177208542341781e-05,\n",
       " 'european': -8.175523239188889e-05,\n",
       " 'follow error': 8.166430719023566e-05,\n",
       " 'anyon ever': 8.160860326355103e-05,\n",
       " 'jamespesch support': 8.16061575844824e-05,\n",
       " 'hi work': 8.158677667918936e-05,\n",
       " 'group work': 8.148523258529763e-05,\n",
       " 'costs': -8.145509223717813e-05,\n",
       " 'would ce': 8.10178754583804e-05,\n",
       " 'upvot': 8.082394985209208e-05,\n",
       " 'use regex': 8.082394985209208e-05,\n",
       " 'start': 8.065707346892236e-05,\n",
       " 'classroom': 8.065707346892236e-05,\n",
       " 'much nlp': -8.058394162954374e-05,\n",
       " 'nlp know': -8.058394162954374e-05,\n",
       " 'ab github': 8.052629005573351e-05,\n",
       " 'detrim': 8.052555793358377e-05,\n",
       " 'phd program': 8.030966389636462e-05,\n",
       " 'next level': -8.019308957309836e-05,\n",
       " 'example could': 8.012325035016733e-05,\n",
       " 'answer questions': -8.009020415456335e-05,\n",
       " 'much appreciated': 8.0083058623722e-05,\n",
       " 'easi nlu': -7.986627783099502e-05,\n",
       " 'image': 7.975802381050953e-05,\n",
       " 'tion score': 7.974505206646707e-05,\n",
       " 'share experi': 7.973672686027632e-05,\n",
       " 'would hear': -7.97058491427952e-05,\n",
       " 'like find': 7.955867717792067e-05,\n",
       " 'honest': -7.950117517755272e-05,\n",
       " 'time wh': 7.945504397300847e-05,\n",
       " 'much luck': 7.935757453130277e-05,\n",
       " 'thus': 7.931942928419946e-05,\n",
       " 'email mailto': -7.930473403349993e-05,\n",
       " 'stop neg': -7.923113901952365e-05,\n",
       " 'betw tities': 7.920113023706233e-05,\n",
       " 'understand model': -7.916897858967366e-05,\n",
       " 'unless': -7.912132277116638e-05,\n",
       " 'allow past': -7.904428434833436e-05,\n",
       " 'black white': 7.90156709612975e-05,\n",
       " 'date latest': 7.898550235176143e-05,\n",
       " 'softwar': -7.882801786236103e-05,\n",
       " 'multi docum': -7.881578089311678e-05,\n",
       " 'evid ce': -7.873350253987871e-05,\n",
       " 'help nlp': -7.871038847027012e-05,\n",
       " 'emot': 7.870462803382926e-05,\n",
       " 'true one': -7.857345531852986e-05,\n",
       " 'time sp': 7.843899113438033e-05,\n",
       " 'meticul': -7.836566289871742e-05,\n",
       " 'linguist studi': -7.831776670795998e-05,\n",
       " 'let know': -7.828258500501483e-05,\n",
       " 'use help': -7.827168600974192e-05,\n",
       " 'hope get': 7.810214233148639e-05,\n",
       " 'stake': 7.793606298094626e-05,\n",
       " 'ce one': -7.791186265391822e-05,\n",
       " 'syntact': -7.788282535341182e-05,\n",
       " 'would abl': 7.780610120241833e-05,\n",
       " 'villag': 7.776780163652844e-05,\n",
       " 'problem vs': -7.758878635616252e-05,\n",
       " 'jamespesch categori': 7.752264294612056e-05,\n",
       " 'however': -7.752071699532547e-05,\n",
       " 'anger': 7.750363823894641e-05,\n",
       " 'analys': -7.74759788717775e-05,\n",
       " 'person project': -7.7357712273617e-05,\n",
       " 'affirmations': 7.72673447297116e-05,\n",
       " 'someth want': -7.719088619827778e-05,\n",
       " 'balanc': -7.709445548905423e-05,\n",
       " 'scalabl': -7.705508176827745e-05,\n",
       " 'hav ing': 7.700197227419932e-05,\n",
       " 'would need': -7.691727255769868e-05,\n",
       " 'easily': -7.691727255769868e-05,\n",
       " 'networks': 7.68669467930378e-05,\n",
       " 'layers': -7.666599767184757e-05,\n",
       " 'accur': -7.657532779988056e-05,\n",
       " 'was': -7.657532779988056e-05,\n",
       " 'answer google': -7.657532779988056e-05,\n",
       " 'tutorial github': -7.657532779988056e-05,\n",
       " 'variou languag': -7.657532779988056e-05,\n",
       " 'guy give': -7.657532779988056e-05,\n",
       " 'landscap': -7.657532779988056e-05,\n",
       " 'augm tation': -7.657532779988056e-05,\n",
       " 'streamlin': 7.643777303454005e-05,\n",
       " 'load use': 7.643008513874099e-05,\n",
       " 'suggest would': 7.633071537067838e-05,\n",
       " 'ce stop': 7.626861633824584e-05,\n",
       " 'sim topic': 7.621471893082827e-05,\n",
       " 'liner intro': 7.609988955331614e-05,\n",
       " 'feed': -7.60731456358548e-05,\n",
       " 'hoc': -7.602764128453635e-05,\n",
       " 'rant': -7.596468132024835e-05,\n",
       " 'tion provid': -7.594525900231117e-05,\n",
       " 'say them': 7.593390007101672e-05,\n",
       " 'would highli': -7.591771963786186e-05,\n",
       " 'thought patterns': 7.584051696994688e-05,\n",
       " 'ud': -7.574257250576115e-05,\n",
       " 'tweak': -7.565222881009221e-05,\n",
       " 'mum': -7.564451487838828e-05,\n",
       " 'description twitter': 7.564269643593689e-05,\n",
       " 'thank advance': -7.562417138575093e-05,\n",
       " 'dataset dataset': -7.561114621437221e-05,\n",
       " 'nlp guru': 7.544013271818995e-05,\n",
       " 'social': 7.541923147322036e-05,\n",
       " 'pip instal': 7.53651312111413e-05,\n",
       " 'make': -7.532529410795219e-05,\n",
       " 'neural text': 7.522756543047423e-05,\n",
       " 'that possible': 7.520804341597126e-05,\n",
       " 'hypnot suggest': -7.512611689985754e-05,\n",
       " 'medit': 7.51072479904038e-05,\n",
       " 'text spanish': 7.504224177761921e-05,\n",
       " 'systems': 7.498555092219633e-05,\n",
       " 'nlp ressourc': -7.49835243649401e-05,\n",
       " 'ideas thanks': 7.497372081366748e-05,\n",
       " 'lines': -7.491922839837777e-05,\n",
       " 'hello community': -7.486288117308399e-05,\n",
       " 'ml dl': 7.484614920597508e-05,\n",
       " 'data could': -7.483130169837803e-05,\n",
       " 'izer model': 7.480803419561419e-05,\n",
       " 'prompt': 7.47862940012102e-05,\n",
       " 'famou': -7.478536683273256e-05,\n",
       " 'machinelearning': 7.47184734746473e-05,\n",
       " 'around it': 7.469925551241183e-05,\n",
       " 'anyth could': -7.457218900390849e-05,\n",
       " 'ce way': 7.456678978106898e-05,\n",
       " 'hug': -7.449324625899282e-05,\n",
       " 'much say': -7.439024886947613e-05,\n",
       " 'translat marian': 7.438239100113837e-05,\n",
       " 'posts': -7.434957793162796e-05,\n",
       " 'kid': -7.434916142281839e-05,\n",
       " 'theme': 7.43140475955255e-05,\n",
       " 'scraper': -7.42388727416946e-05,\n",
       " 'embedding': 7.413338538844849e-05,\n",
       " 'me thank': 7.41325733889248e-05,\n",
       " 'incid': -7.404773128229372e-05,\n",
       " 'speaker need': -7.404618364090863e-05,\n",
       " 'learn would': -7.39243893358973e-05,\n",
       " 'fortun': -7.391070145051362e-05,\n",
       " 'newslett': -7.391070145051362e-05,\n",
       " 'idea that': -7.383283979088372e-05,\n",
       " 'run full': -7.383283979088372e-05,\n",
       " 'googl ai': -7.3767070897512e-05,\n",
       " 'last': -7.360932666892786e-05,\n",
       " 'lists': 7.353651447336904e-05,\n",
       " 'this new': -7.346039806575059e-05,\n",
       " 'wise': 7.335378979939186e-05,\n",
       " 'assessm': -7.333327636925413e-05,\n",
       " 'nlp british': 7.330568877287155e-05,\n",
       " 'exampl name': 7.329160668875799e-05,\n",
       " 'new video': -7.329109387366962e-05,\n",
       " 'make model': -7.325221587718554e-05,\n",
       " 'situations': -7.300280623510555e-05,\n",
       " 'taught me': -7.293299155790333e-05,\n",
       " 'invest': -7.28065120181354e-05,\n",
       " 'blow': -7.28065120181354e-05,\n",
       " 'person respons': -7.263568016712207e-05,\n",
       " 'use simpl': -7.24816853156821e-05,\n",
       " 'erat dataset': -7.240296989175551e-05,\n",
       " 'first one': -7.237660948201816e-05,\n",
       " 'overwhelm': 7.236484197430926e-05,\n",
       " 'work too': -7.220276047953588e-05,\n",
       " 'elem tari': 7.215741494242766e-05,\n",
       " 'medic titi': 7.215235623025932e-05,\n",
       " 'eastern': -7.213298830437194e-05,\n",
       " 'wide use': -7.212989963267684e-05,\n",
       " 'use po': -7.203510301040711e-05,\n",
       " 'hello new': -7.201586639434869e-05,\n",
       " 'already': 7.197163025857587e-05,\n",
       " 'model wordvec': -7.196898918882777e-05,\n",
       " 'languag nlu': -7.18652315100483e-05,\n",
       " 'hindi': 7.180764608833353e-05,\n",
       " 'realiti thoma': -7.178477400237508e-05,\n",
       " 'grinder': -7.174679800140575e-05,\n",
       " 'know paper': 7.159718630020395e-05,\n",
       " 'version': -7.155069874050253e-05,\n",
       " 'sorflow': 7.152970554484995e-05,\n",
       " 'summar': 7.151057837521942e-05,\n",
       " 'word corpu': -7.140689956601731e-05,\n",
       " 'give best': 7.133704717389534e-05,\n",
       " 'let say': 7.132931011156206e-05,\n",
       " 'method find': -7.130630048750171e-05,\n",
       " 'perform metric': 7.122367777344176e-05,\n",
       " 'small corpu': -7.121675373656346e-05,\n",
       " 'one know': -7.115556873506018e-05,\n",
       " 'dataset larg': 7.114974808091192e-05,\n",
       " 'stud ts': 7.113004855768254e-05,\n",
       " 'model give': -7.10643349347418e-05,\n",
       " 'tation techniqu': -7.097700758188271e-05,\n",
       " 'doubt': -7.092494590429211e-05,\n",
       " 'new multilingu': 7.081456344549874e-05,\n",
       " 'th back': 7.080940805522204e-05,\n",
       " 'article marktechpost': -7.078270098445942e-05,\n",
       " 'height': -7.075994373614378e-05,\n",
       " 'corpu docum': -7.06988519865929e-05,\n",
       " 'presupposit nlp': 7.062772295009126e-05,\n",
       " 'tell get': -7.05835196034592e-05,\n",
       " 'fcc': 7.056261368404255e-05,\n",
       " 'reproduc': 7.054539253377752e-05,\n",
       " 'result': -7.04723137017048e-05,\n",
       " 'sigmoid': -7.043772888621116e-05,\n",
       " 'descript paper': -7.038728027835889e-05,\n",
       " 'tire sequ': 7.037214787335901e-05,\n",
       " 'bot ds': 7.037207222352907e-05,\n",
       " 'research univers': -7.034613710356355e-05,\n",
       " 'proof': 7.029912163715213e-05,\n",
       " 'toni robbin': -7.029358036103588e-05,\n",
       " 'wave': 7.028628487065205e-05,\n",
       " 'new nlp': -7.014315880440473e-05,\n",
       " 'ergy': 7.009034047942021e-05,\n",
       " 'tape': -6.99297810016219e-05,\n",
       " 'semant nlp': -6.99297810016219e-05,\n",
       " 'nlpcloud nlpcloud': 6.99210943469377e-05,\n",
       " 'rec tly': 6.98786461683553e-05,\n",
       " 'extract relev': 6.986128954250835e-05,\n",
       " 'let call': 6.981693374228867e-05,\n",
       " 'filter': -6.972281582980517e-05,\n",
       " 'project would': 6.971149168847785e-05,\n",
       " 'wrong sub': 6.965137291860295e-05,\n",
       " 'addition': -6.964678059207767e-05,\n",
       " 'specifi': 6.962344099721248e-05,\n",
       " 'project think': -6.958204951667648e-05,\n",
       " ...}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_scores(model_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3859e79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Who regulates NLP in the UK?   \\n\\nI have cause for concern regarding the toxic side of the self-development industry, its marketing towards children, families with sick children, and children with mental health problems. It’s application for ‘self-development’ that is being targeted towards children, as well as its use to treat medical conditions in children by those with no medical training or education; and alarmingly its encroachment into the school and classroom environments for both.\\n\\nMy hope is that this email will start a conversation with those who are best equipped to have it, so that the right action can be taken to ensure the welfare of all children.\\n\\nThere are a lot of people in this world selling snake oil, “cure all’s”, one in particular is N.L.P. \\n\\nN.L.P. is part of the self-development industry which is estimated to be worth globally $15 billion with nearly 6% average yearly gains. To put it lightly, people are making serious money from self-development. The selling of books, seminars online programmes, podcasts, blogs, live speaking events, and coaching are some of the mediums used.\\n\\nThis is potentially problematic because, put simply, people are more profitable to the self-development industry if they are unhappy and discontent, than they would be if they are happy and fulfilled.\\n\\nIn order to successfully market any self-development product, a sense of self dissatisfaction needs to be created in the prospective market or customer. In order to pull them in this is achieved by projecting a feeling of inadequacy. In turn, each piece of self-development material consumed, be it a video, book, seminar, webinar, or 1 on 1 session with a life coach, will give the consumer a sense of wellbeing, a small high. This high is caused by a surge in dopamine levels that rise in the brain.\\n\\nThis is incredibly dangerous because it can create an addictive cycle of behaviour. \\n\\nSelf-development will make you feel good. There's no doubt about it. There's a feeling of satisfaction that anyone will have after finishing a self-development book, or after attending a seminar or coaching session, because these products are designed to give you a sense of motivation and accomplishment, especially in a group context where group social biases can make people vulnerable to the perceived inadequacies and insecurities upon which they are marketed to resolve. But that feeling of accomplishing something isn’t real because you haven’t actually accomplished anything other than consume a product that is designed to make you feel as though you have. Furthermore, that feeling of motivation, that bubble may burst due to external forces outside a person’s control, leading them to feel personally responsible for not having the success that was marketed to them, because they didn’t put in ‘enough hard work and commitment’ that you were told they needed to put in while their brain was flooded with dopamine. (Imagine this if you are suffering from depression, I’ll come to that later) Due to an increased sense of inadequacy this leaves people needing more and so the cycle of the consumption of more self-development material begins again.\\n\\nThe reason anything becomes addictive is not because of the thing itself. The reason someone becomes addicted to cocaine is not cocaine; it's what the cocaine does to the brain. It’s the rush of dopamine caused by cocaine that gets a user hooked. It’s the rush of dopamine that causes addiction. N.L.P. and other self-development products can cause pathological behaviour cycles by creating a dependency on the feeling of wellbeing triggered by dopamine. It does so by using social context and behaviour to turn people into a consumer of its products by playing inadequacy against success to create a false sense accomplishment and motivation that facilitates a dopamine rush, the high. N.L.P and other forms of self-development stimulate the same neurological and psychological mechanisms as cocaine.\\n\\nIn order to become an N.L.P. life coach or self-development guru I would suggest that you would have fallen foul to this kind of predatory marketing and in turn, in some way become addicted to its products and ideas. \\n\\nThere are many N.L.P. organisations. I will focus solely on the ones I have seen that are aimed towards children that I believe to be toxic.\\n\\nMany N.L.P. organisations and self-development gurus market the idea to potential prospective N.L.P. practitioners of being your own boss (are you sick of the 9 to 5?), financial freedom (do you want less stress?), success (do you need people to think highly of you?), all whilst helping children. You can do this after attending a course lasting only 4 days. Some even with one of those days spent on teaching someone how to set up a children’s therapy practice, and how to market their particular brand of N.L.P. as a franchise. Shockingly but not unsurprisingly there are optional add-ons, so after attending and successfully passing your short course, you can pass on your new N.L.P. skills to parents, and teachers.\\n\\nSome of these N.L.P. and self-development practitioners take the opportunity to present themselves as a guru with promotional video testimonials from their ‘licenced practitioners’ praising them for their support and helping them achieve success, and finish as all new wave internet gurus do with “make the commitment”, “hard work”, “earn money” and “success”, with the offering of monthly private webinars and closed forums of N.L.P. and self-development content and not failing to subtly mention the financial commitment to your new guru to ensure your skills are up to date so you can acquire your next annual franchise licence for your successful N.L.P. business in what, on the face of it, appears in some instances to be a pyramid scheme.\\n\\nSome of these N.L.P. and self-development organisations seem to blur the distinction between a medical licence and a franchise licence and sell the idea of helping children with medical conditions to potential practitioners who may then go on to think that because they are a ‘licenced N.L.P. practitioner’ and may already be a registered child minder, and have a clean police check; they can treat the symptoms of a number of medical conditions that could have their roots in all kinds of serious conditions that these practitioners would lack the competencies to diagnose.\\n\\nOne video testimonial I have seen, the new practitioner states they felt dissatisfied with the corporate world, so signed up to become a child therapist, and so applied to attend and after a 4 day course was a child therapist. \\n\\nIn short you can quit your job at McDonald’s on Monday and by Friday be under the illusion that you are a ‘fully registered and licenced’ child therapist.\\n\\nI struggle to reconcile the notion that it is possible to become a professional child therapist, regardless of whether or not you then operate in schools, but especially if you do, after completing a course lasting less than a week. I further struggle to believe that you can tell people that you are a licenced child therapist after completing one of these courses. I struggle more to believe that people who don’t have a degree in psychology or any medical qualification who are not doctors or professors are allowed to teach people to become a child therapist and give them the illusion that can work with children and in schools. \\n\\nIt is my belief that this appears to actually be happening.\\n\\nSchools, while having checks in place may fall short, because their child mentors and class support workers have a clean police check and are registered child minders and when they say they are a ‘licenced practitioner’, do schools realise this isn’t from a recognised medical training scheme and in actual fact issued by someone selling ’self-development’ franchises on the internet in an unregulated industry that the scientific community has dismissed due to its numerous factual errors and its lack of empirical evidence for effectiveness and recognises as pseudoscience. \\n\\nWhen it comes to diagnosing medical conditions, a medically trained professional, a Doctor, will, after many years of study, approach any patient with a degree of scepticism, and after rigorous investigation and the process of elimination rule out what things are definitely not, in order to find out what things may be, before narrowing down a diagnosis and then deciding on the correct course of treatment for a given condition. N.L.P. practitioners after a 3 or 4 day course won’t be able to do this, and would, with an unscientific mind, approach a patient with any given condition with flow chart diagnostics. They will look for certain symptoms that they could potentially treat with N.L.P. Once confirmation bias has falsely validated a condition, they would then apply their N.L.P. techniques to treat what they believe can be treated with N.L.P. \\n\\nShould they have accurately diagnosed a condition, blind luck will be interpreted as success.\\n\\nAnxiety, O.C.D., A.D.H.D., Anger, Depression, , could all have social triggers, but are also symptomatic of other very serious conditions that N.L.P. practitioners would not be able to recognise with flow chart diagnostics let alone effectively diagnose or realise they should even be aware of after attending a 4 day seminar. As such, this could cause significant problems further down the line for a child with autoimmune disease, or perhaps a genetic condition like hemochromatosis, McLeod Neuroacanthocytosis Syndrome, Cushing's Syndrome (the list can go on) or in the worst case some types of Cancer. \\n\\nThe symptoms of conditions these practitioners are treating could also be early onset schizophrenia. Schizophrenia causes all sorts of social and psychological symptoms because it is fundamentally a language disorder that in part robs the patient of the capacity to distinguish between their internal thoughts and the real world through something called ‘concrete language’. If you apply some one size fits all thinking techniques to a person (a child in this instance) suffering from this form of psychosis, the damage that could be done is catastrophic and potentially puts people, (children), in serious danger.\\n\\nAs a more frightening example, Depression (in its truest most destructive sense) is a genetic neurochemical disorder, that is as biological as diabetes, which through the impact of life experience influences, or perhaps just any way robs people at a biological level of the ability to experience joy. (Consider here what I mentioned above - that sense of personal responsibility for failure) Combine all this with people’s inability to distinguish the difference between being depressed and having depression due to semantic similarities and the social stigmatisms that further impact the psyche of someone who is already withdrawn and you have a cocktail for disaster. You can’t just sit them down and go through some thinking or social behavioural techniques and expect it to improve. This is because Depression, a neurochemical disorder, is in most cases a serotonin deficiency. This is analogous to sitting a diabetic down and telling them to snap out of it and hoping that in so doing their pancreas starts producing insulin. \\n\\nDepression is treated with professional therapy in conjunction with prescribed S.S.R.I. medication to trigger the production of serotonin in the brain. N.L.P. and other self-development products release dopamine. Neurochemically speaking this is comparable to treating depression with a cocaine habit. Children will report that they will feel better. Neither these practitioners, children, nor parents would be aware that they are actually not better and have in actual fact substituted a lack of self-worth, with a short term high, just like a ‘fix’. The damage that could be done here could result in suicide. This is because a patient with depression is at their most vulnerable from suicide when they are going through what appears to be a recovery; when everyone around them thinks they are doing well; after a period of psychomotor retardation, as they now have energy to take action on their self-destructiveness and self-harming thoughts.\\n\\nI would suggest, the positive results that these organisations are reporting for treating Depression (as well as a number of other conditions) are in actual fact the result of a fallacy of composition biased by false validation because N.L.P. makes people ‘feel good’. In some cases children, sick children, who are potentially becoming hooked on the dopamine rush from consuming self-development products from an unregulated industry that has found its way into the classroom. I would further suggest that these statistics are in actual fact an alarm bell that should be seen as the number of children, potentially sick children, who are becoming self-development product addicts.\\n\\nWhile the above may be extreme worst case scenarios, of which there could be more. Where more unnoticed damage could be done is in the realm of personality disorders and pathological behaviour.\\n\\nBrain chemistry plays a huge role in personality disorders. ‘Messenger chemicals’ such as the previously mentioned serotonin are used in the brain to transmit signals between brain cells. Altered levels of serotonin have been linked to depression, aggression and difficulty controlling destructive urges. All of which some N.L.P. organisations wrongly target with their N.L.P. therapy which triggers dopamine.\\n\\nIn addition to this, if a person is overly sensitive to negative emotions and is neurotic, N.L.P. practitioners conditioning a child to avoid circumstances that may trigger negative feelings or reconditioning their thinking about these circumstances with repetitive self-affirmations reinforced with dopamine, could lead the child to develop a pathological narcissistic personality disorder simply because practitioner, parent, teacher or child wouldn’t be able to determine the difference between an angry child feeling better due to dopamine, and creating pathological behaviour models that will become malignant over time.\\n\\nAre parents made fully aware that their child’s mentor, classroom assistant or even therapist; are offering or passively using potentially addictive pseudoscience from an unregulated industry for personal development? Furthermore do they realise in some cases offering this as a treatment for what they don’t realise is more often than not symptoms of autoimmune diseases or genetic disorder that require proper medical treatment? While these practitioners may have passed a police background check, and who are ‘fully licenced’, do the parents realise that these practitioners in actual fact have no medical training or education? Do parents realise they in fact only have a franchise licence from an unregulated industry issued after a 4 day course by a person; who in one instance that I have seen, who also has no formal medical training or education and holds only a certification in nursery nursing?\\n\\nN.L.P. used by a psychiatrist with an advanced degree and understanding of psychology I am sure presents no problem what so ever. In fact there are numerous success stories about it positively changing people’s lives all of which are highly commendable but in these instances N.L.P. was applied by a trained any qualified psychotherapist.\\n\\nN.L.P. in the wrong hands, like someone with no medical background having completed only a 3 or 4 day course is in my opinion reckless and incredibly dangerous. It is then being used to treat children’s medical conditions by people who are not qualified to know what they are doing. As well as being used in the application of self-development by exposing children to a potentially addictive cycle of consumption, that in the short term may make a child feel good, but in the long term may have catastrophic consequences.\\n\\nThe self-development industry could be seen as a community of individuals and entrepreneurs looking to better themselves. These life coaches could be seen as providing value by trying to make people’s lives better. I am sure some of them are. So where’s the harm? This is naive thinking when you're dealing with an unregulated industry that is worth billions that relies upon creating a sense of vulnerability and inadequacy to snare its practitioners that can then potentially be projected onto others to make a profit on potentially addictive products especially when they are marketed to children with medical conditions. In seems to me to be a pyramid scheme glued together by projecting social inadequacy onto the next person, so they can return a sense of affirmation.\\n\\nIt is my belief that there are people in The U.K. and quite likely elsewhere probably globally who have no medical qualifications, using potentially addictive N.L.P. techniques on children in schools. They have no education in psychology, they are not psychiatrists, and some have no medical qualifications. Some have only done a course only a few days long. Some of these people are treating psychological problems in children in schools.\\n\\nI want to be clear, I am making no accusation of abuse against any individual, or organisation. There is no conspiracy, there is no malice. It is only my opinion that this is something that could potentially be harmful to children being committed naively by those who probably have the best of intentions, who are ignorant in their actions. This in my opinion has been allowed to take place due to an institutional failure that has let the potentially toxic side of an unregulated industry slip through the net and find its way into the classroom.\\n\\nPlease approach this with due diligence and care, children are involved, practitioners may have children, who could be exposed to backlash from sensationalist reactions. \\n\\nThe self-development industry is unregulated, and that needs to change. Step one, get it out of the classroom.  \\n\\n\\nShould N.L.P. be regulated?\\n\\n[View Poll](https://www.reddit.com/poll/j9t5az)\",\n",
       " 'HOW TO CURE FEAR &amp; PHOBIAS | NLP | REMOVE FEAR | CURE PHOBIA  *\\\\*\\\\*SOURCE CREDIT: THIS TECHNIQUE IS MY OWN SPECIFIC METHOD, but it is BASED OFF OF THE TECHNIQUE ON PAGE 195 OF DERREN BROWN’S TRICKS OF THE MIND.\\\\*\\\\*\\\\**\\n\\nVIDEO TUTORIAL LINK AT BOTTOM\\n\\nhttps://preview.redd.it/n66gaf6r9es01.jpg?width=640&amp;format=pjpg&amp;auto=webp&amp;s=edae7e0307b2607c6d0121e6e8ceaa3c0521f35f\\n\\n**INTRODUCTION**\\n\\n\\n&gt;**“I can’t breathe,”**  \\n&gt;  \\n&gt;**“it makes me shiver uncontrollably,”**  \\n&gt;  \\n&gt;**“I can’t sleep,”**  \\n&gt;  \\n&gt;**“I break out into sweats.”**\\n\\nDoes any of that sound familiar? Do you have a FEAR or PHOBIA that you would like to be FREE from Now? This MIND SHIFT STRATEGYTM has worked for so many! We have seen instant and total elimination of\\n\\n* FEAR OF HEIGHTS\\n* CLAUSTROPHOBIA\\n* AGORAPHOBIA\\n* HYPOCHONDRIA\\n* FEAR OF PUBLIC SPEAKING\\n* FEAR OF FAILURE\\n* &amp; PTSD\\n\\nin my own practice and I am confident that that this simple but powerful technique will work for you NOW. Quickly, before we begin, if you have a fear of visualizing, imagination, cinemas, or movie theatres, please stop reading now and contact me directly for a different method.\\nNow, before we get started, I need you to take a moment or two and imagine an activity which you are able to do very well. It could be anything, as long as you know for sure that you are excellent at it. Can you Bake a lasagna, are you an athlete, a host, a caretaker, a friend?\\nTHINK now and really picture that activity which you know you are absolutely great at achieving. Now, the feeling you have when you picture yourself doing that action well, that feeling that you feel NOW is the mentality of a winner and the exact mental state that you must really be able to generate before we move on to the first step of this FAST \\\\+ EASY MIND SHIFT STRATEGYTM. So, if you have been intentional and if you feel bold, continue.\\n\\n**BODY**\\n\\n\\nNow, as you read these words, and now that you know that you have established a safe and clear mental state that makes you feel empowered and ready to engage with this successful solution to this little issue we can begin. First, imagine yourself entering your favorite movie theater. If you do not have a favorite, it doesn’t really matter, but you must feel safe, secure, and the imagery of the theater must be vivid and real to you. As you smell the buttery popcorn wafting through the air, you may stop by the concession stand and grab a beverage or candy selection before entering the actual auditorium where we will pick our favorite seat. Did you make a selection? What did you get?\\n\\nhttps://preview.redd.it/d5hpwrlx9es01.jpg?width=1024&amp;format=pjpg&amp;auto=webp&amp;s=511deb877f01f7289ba1ff78a0644c0d59e966cf\\n\\n\\nJolly ranchers, skittles, snickers, twizzlers, or traditional popcorn, get whatever you like.\\n\\n\\nOk, great! As you find the perfect seat in the theater, you will now notice that there is a room at the back of the theater where the projector for the film is, that room is also for you; when ready, you will control when the movie will begin. The control room is entirely run by you, when you are ready to begin, however, it is important that you only visit the control room IF you need to see yourself watching the memory for any reason, but otherwise you will relax, get comfortable and control this video of your memory from your seat.\\n\\n\\nAs you look around the empty and yet cozy theater, pick your favorite seat and settle down and relax. As you now begin to notice the lights in the theater dim, you will begin to see a movie play out on the screen in front of you. You’ll have to squint a bit because the image is extremely small on the screen in front of you; as you adjust your eyes, you will begin to be amused as you see that the fuzzy, black and white picture is a movie of your memory. The small film is a picture featuring you as the HERO, but it is also of the FEAR or PHOBIA that we are about to eliminate. This is the event that occurred that started this series of emotions. Good. Now focus. The events on the screen will play at normal speed but there will be a few important differences; instead of the feelings we would normally feel, we are now going to layer a comical audio file over the top of the film. There will be no elaborate or scary sounds in this movie, other than humorous ones; be sure to use a laugh track from a sit com or your favorite funny theme song; I use THE OFFICE &amp; It’s Always Sunny in Philadelphia and play this over and over again to drown out the sounds of the original memory.\\n\\n\\n***Note: Occasionally, as some people have engaged with this image, they have felt overwhelmed by the thought of watching this memory play out; focus and relax, we have a solution for this as well! As you breathe steadily and peacefully, you can take a moment and drift back to the control room where you can watch yourself bravely facing the film of your fear. As you face your fear, now is a good time to encourage yourself and tell yourself how proud you are of yourself for facing this issue.*** \\n\\nhttps://preview.redd.it/ln0vf9m0aes01.jpg?width=710&amp;format=pjpg&amp;auto=webp&amp;s=6603b7719514cfa32596e2516d6e40cd8123c4ba\\n\\n\\nNow, as the film ends, it is time to take our power back from this memory. As we process how much better we already feel, the movie is over and the reel hums as it comes to an end. As this happens, we are going to stop the movie of our memories on the last frame.Now, look at your face on the screen and step into that body, you will now run that movie in reverse at 2XX the original speed as vividly and colorfully as you possibly can until you arrive back at the start. Fast, QUICKLY, RUN IT ALL THE WAY BACK!\\nGOOD!\\n\\n\\n**CONCLUSION**\\nNow, as you look into the eyes of the new you, the you that has conquered that mental image that you had, how do you feel? Do you now feel freedom, joy, and peace? GREAT!! That means that you have completed this technique and you can live a life of confidence and victory over a minor issue that used to hold you back in some capacity. Congratulations on your Future and please share this content with someone that you want to enable to Be their own HERO just like you were able to do.\\nIF YOU ENGAGE BETTER WITH A VISUAL EXAMPLE, I HAVE UPLOADED THIS TECHNIQUE TO YOUTUBE AND WILLPROVIDE THE LINK HERE: \\n\\n[HOW TO CURE FEAR &amp; PHOBIAS | NLP | REMOVE FEAR | CURE PHOBIA](https://youtu.be/lnPX1HcVWd4) ',\n",
       " 'HOW TO GAIN TRUST using Cold-Reading &amp; Barnum Statements in 4 EASY STEPS https://preview.redd.it/5x6fflir2tr01.jpg?width=828&amp;format=pjpg&amp;auto=webp&amp;s=104deb34859c0c9986fca8f38e742ceb6a58a2f7\\n\\n**DISCLAIMER:** ***\\\\*\\\\*These techniques and methods are extremely POWERFUL and INFLUENTIAL, always assess and take priority in ensuring that the emotional and mental state of the person you are influencing is healthy. However, if you choose to use these methods solely for personal gain people will begin to distance themselves from you; don\\'t be an idiot and use this power to help others and empower your own life simultaneously to optimize these HACKS!***\\n\\n## INTRODUCTION\\n\\nPreachers use it, Psychics live by it, &amp; Mediums can\\'t influence a single soul without it. What non\\\\-magic, magical formula am I sharing?!\\n\\nhttps://preview.redd.it/e0yu5mlq2tr01.jpg?width=640&amp;format=pjpg&amp;auto=webp&amp;s=ba1166b09fa1e43dffc712e6db7e59b34424611a\\n\\n&gt;*How to GAIN Trust using \"Cold\\\\-Reading\" and \"Barnum Statements\"*\\n\\nEveryone uses ***Barnum Statements*** from time to time, but only the greatest communicators and salesmen learn the Psychology behind Human Behavior and the Language that determines the way we FEEL toward others.\\n\\nBarnum Statement:\\n\\n&gt;*“Deep down you know your own self worth, however you find that often you are far too critical of yourself and this limits your confidence in many areas.”*\\n\\n\\xa0See, how that sentence seems like it is specifically and uniquely designed for ***you?!***\\n\\n## It wasn’t. 😉\\n\\n\\xa0Imagine walking into all your future meetings, dates, or emergency scenarios equipped with a secret that would make you the most\\n\\n## \\xa0·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Trusted\\n\\n## ·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Influential\\n\\n## ·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Confident\\n\\n## ·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0&amp; Persuasive\\n\\nperson in the room.\\n\\n\\xa0As you begin to see yourself walking into situations with incredible power and control, this unique gift will endow you with inexplicable favor and success, which area of improvement in your life is the most significant?\\n\\n\\xa0Which situation matters most and which one will change the most in your life once you learn and implement these 4 methods into ALL future social interactions?\\n\\n\\xa0NOW, you can excitedly and with great focus, as you realize and notice the exact scenario you will apply this to for massive growth and optimization, continue.\\n\\n## \\xa0MIND SHIFT STRATEGY (MSS)™ 4 STEPS to use Cold-Reading to Gain Trust\\n\\n## \\xa01.\\xa0\\xa0\\xa0\\xa0Make Statement Personal\\xa0\\n\\nSTEP 1: USE “You” &amp; Exact Words provided by your audience\\n\\nThis seems to be common sense, however, most people have no idea how to do this naturally and powerfully, so pay attention closely.\\n\\nLet me ask you a question. How often do you pay attention to the manner in which others introduce themselves? Has anyone ever made you feel incredible about yourself by remembering your\\n\\n### ·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Sign: Libra, Scorpio, etc. . .\\n\\n### ·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Name: If they say “Christopher,” Don’t say, “Chris.”\\n\\n### ·\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0or detail: Wife’s name, Pet, vehicle, clothing, etc. . .\\n\\nDid this person seem like it was difficult for them or as if they were searching for a way to connect or manipulate you, or did their compliments and admiration of you and your talent flow uninhibited from their soul? Focus. Others are incredible. You can see their wonderful and impressive qualities. Say it, casually, and intentionally. Make sure you are heard, and then begin phrasing opinions using “YOU” statements ie\\n\\n\\xa0“You often find. . .” or “You, like most, probably. . .”\\n\\n## \\xa02.\\xa0\\xa0\\xa0\\xa0\\xa0Use Sincere Language\\n\\n\\xa0STEP 2: UTILIZE Sincere Language\\n\\nUse words like ***“Feelings,” “Deep down,” “on the inside,” “Honestly,” “Personal”***\\n\\nExamine your audience closely, \\\\(this works best when you begin working with a single, captive and voluntary audience.\\n\\nAs you focus now, on sitting across from another human, imagine trying to comprehend not what the other person is thinking but what they are feeling. When we teach mirroring techniques, we teach our practitioners to try to feel what others feel by mirroring their body language markers.\\n\\n&gt;***Posture*** *– If they are leaned back and appear relaxed, so do you; likewise, if seated forward and more engaged in anticipation, mirror this posture*  \\n&gt;  \\n&gt;***Eye Contact*** *– Some people love it, some hate it, mirror whatever they prefer*  \\n&gt;  \\n&gt;***Limbs*** *– If they are crossing their arms, have hands in pockets, legs crossed, or fidgeting, mirror a similar mannerism as casually and naturally as possible.*  \\n&gt;  \\n&gt;***Words*** *– I can not stress this enough; use their words, EXACTLY. If they say they need to relieve “Anxiety,” then you use that exact and sincere word. If they state that they are looking for an affordable solution, then you find and deliver the most “AFFORDABLE,” solution you have, etc.*\\n\\n## 3.\\xa0\\xa0\\xa0\\xa0\\xa0STEP 3: USE Vague &amp; Ambiguous Language\\n\\n\\xa0\\xa0\\xa0\\xa0\\xa0STEP 3: Use words like “Rarely, Sometimes, Occassionally, Often, etc.”\\n\\nMost people are totally ok with words like Most, Often, Rarely, Usually, because although they appear to be leaning toward one end of a behavioral spectrum, there is still plenty of room in these words for cognitive relativism. Most of us can find ourselves agreeing with someone who is opinionated but leaves much space in the conversation to be themselves entirely incorrect about their opinion, that is why these words have a tendency to be useful in building emotional rapport.\\n\\nThere are certain words which do NOT allow for this cognitive space and distances others from our perspective or words:\\n\\n&gt;***NEVER USE “NEVER;” ALWAYS STAY AWAY FROM USING “ALWAYS”***\\n\\n\\\\(unless the audience volunteers “Never or Always,” just don’t.\\n\\n## \\xa04.\\xa0\\xa0\\xa0\\xa0\\xa0Step 4 Create an Out: Offer a double bind option\\n\\nSTEP 4: Offer The Linguistic Double Bind\\n\\nMany expert and human behavior specialists develop subtle and savvy strategies to get the result they want in conversation by offering an out in the way of a double bind.\\n\\n## \\xa0For Parents: \"You’ve been very well behaved today, would you like to go to bed at 8:00 or 8:30pm?”\\n\\n## For Sales: “As someone who is obviously, honest and transparent, like myself, would you rather disclose the budget you are working with, or would you just like to move forward to the pricing options we are currently offering?”\\n\\n## For Cold-Reading &amp; Barnum Statements: “I can tell you are someone who is smart and that causes you have a tendency to hide details from others, however, once you establish trust, you’ll find that you are quite open to sharing your deepest thoughts.”\\n\\n## \\xa0CONCLUSION\\n\\nAs you now begin to use these 4 FAST \\\\+ EASY Steps to increase your own influence, pay it forward and tell others about your ability to optimize your success and future relationships &amp; share this article with as many people as you can.\\n\\n\\xa0Visualize the impact you will have on your social circle and the ways you will be able to help those around you by making them feel incredible about themselves and take special note of the ways this will change the level of influence you begin to experience in your day to day life.\\n\\n\\xa0Thank you so much for reading, and if the above article was not quite good enough, please checkout my 5:00 min YouTube Video where I share the 4 steps quickly!\\n\\n[GAIN TRUST IN 4 STEPS](https://youtu.be/7npBe4DLRiI)\\n\\nEnjoy and don\\'t forget to Be Your Own HERO!!\\n\\nJames Pesch welcomes you back! James is a Human Behavioral Specialist skilled in Linguistics, NLP, Mentalism, &amp; Psychology creating content so YOU WILL \"Be your own HERO.\" \\\\-James Pesch KEYNOTE | BUSINESS COACH | CORPORATE TRAINER | SALES TRAINER | HUMAN PERSUASION EXPERT | LINGUIST The PATREON PAGE..............................► https://www.patreon.com/jamespesch The Website..............................► https://www.jamespesch.com Twitter......................► https://twitter.com/jppdiddy Facebook.................► https://www.facebook.com/mindninjaJP LinkedIn....................► http://www.linkedin.com/jamespesch Your support means everything!',\n",
       " 'Creating Characters to combat motivation issues **Summary**  \\nI\\'ve developed a method for my own use that utilizes acting, to help with motivation and procrastination. Characters are created and developed that have certain aspects that you need in your life. Such as a character may be extremely work-driven and loves tackling monotonous work tasks. Or perhaps they are extremely studious and love absorbing themselves into a college textbook. You then, essentially, act or pretend to be the character. When done right, and with practice, you are willing your mind to treat a situation differently.  \\n\\nIt may sound simple and silly, but there\\'s quite a bit that goes on behind the scenes with getting this to work, and uses some basics of NLP behind how it works.\\n_____\\n\\n**Background**  \\nThe inspiration behind all of this stemmed from a podcast I listened to at complete random, of Sir Patrick Stewart in a casual interview. During the interview he explained that for his live plays, in which he\\'d often perform the same show multiple times a day, he used a technique to keep it fresh each time. This is far far far from verbatim since this was a while ago that I listened to it, but he basically explained that he used a trigger to \\'become\\' his characters.  \\nFor one show, entering onto the stage through a doorway, when he touched the door handle he would become his character fully--and that character was fresh. So even if he immediately performed a second show, the character he assumed was a fresh version of that character who had not yet experienced everything that happened in the previous show. This made everything that happened in the show new and exciting for him.  \\nHe explained that it allowed him to not get drained from the shows, and kept it from feeling monotonous and like he was just on repeat over and over again.  \\n\\nAs I was listening, I immediately was fascinated. I began to think of how this could be used in many other formats. How it could help *me*.   \\n\\nI suffer from severe motivation issues and depression from the results of my lack of motivation. (Yeah, feedback loop) The logic was pretty sound for what Sir Patrick Stewart was doing, especially after I discovered NLP (Which was a few months after I began developing this), and how the brain could be manipulated into experiencing things.  \\n\\nThis can also be used to improve yourself as a whole, or certain aspects about yourself. Such as confidence or sense of adventure. While you\\'re using this as a trick to start off with--sort of \\'fake it till you make it\\', it goes deeper in that over time you\\'re instilling good habits regarding the aspect of your life. So even though you\\'re just pretending now, they eventually become a part of you (Should you want, anyways)  \\n\\nI began creating a method that used Sir Patrick\\'s own play acting method, which has developed significantly over time.  \\n\\nBasically, you create a character or multiple characters that you will act as/pretend to be that character for whatever duration you need. I know it sounds silly and too simple to be true, but despite how simple it sounds, it can be remarkably effective. You\\'ll be not only developing your ability to do this over time with practice, but also developing your characters over time so that they are more believable, relatable, and easier to get in character for.  \\n\\nIf you\\'re interested in this, or giving it a try, I thought I\\'d share what I\\'ve created. I don\\'t know if something like this already exists or not, it\\'s just something I came up with over time. Hopefully someone will find it useful!  \\n_____\\n\\n**Starting off/How-to**   \\n^WARNING: ^*Please ^do ^not ^attempt ^this ^if ^you ^have ^schizophrenia. ^Please ^consult ^whatever ^professional ^you ^talk ^to ^about ^potential ^ramifications ^this ^may ^have ^with ^your ^schizophrenia.*  \\n^^WARNING ^^2: ^^*These ^^characters ^^may ^^potentially ^^become ^^Tulpas. ^^If ^^this ^^happens, ^^please ^^begin ^^treating ^^them ^^as ^^tulpa ^^instead ^^of ^^fake ^^imaginary ^^characters ^^used ^^solely ^^for ^^your ^^embetterment. ^^If ^^you ^^don\\'t ^^want ^^these ^^to ^^potentially ^^become ^^tulpas, ^^please ^^set ^^out ^^with ^^the ^^intention ^^that ^^these ^^characters ^^will ^^not ^^become ^^tulpas.*   \\n  \\nWhat do you want to improve? Make a list of what your goals are. I\\'m going to detail all of my own examples for reference, in all of this.  \\n\\nMy goals that I wrote out:  \\nMotivation for work, chores, and to keep myself in good health.  \\nHigher sexual libido.  \\nHigher affection.  \\nConfidence.  \\nStudious.  \\nCurious about everything--engaged in learning.  \\nEngaged in discovering my faith/beliefs.  \\nAble to ignore tiredness/get second wind  \\nStop snacking throughout the day.  \\nHealthier meal choices.  \\n\\nThat\\'s quite a few goals... Depending on how many goals you have, you may want to create multiple characters. Honestly, it\\'s just harder to have a single character take on 6+ significant traits. It\\'s more effort on your part to keep all of those traits in check when you\\'re using the characters. So please consider making multiple characters.  \\n\\nI have three. Corie, Elle, and Elspeth.  \\n\\nYou\\'ll be developing these characters over time, so start off simple. Just the names and what traits they embody, and perhaps a few general personality traits to make them more \\'human\\'. It doesn\\'t matter what gender they are, just make whatever characters you want. All three of mine are female, not really for any good reason. You\\'re basically creating characters like you would for a novel/short story.\\n\\nCorie: Motivation for work, chores, and to keep myself/herself in good health.  \\n\\t-No nonsense, extremely caring, motherly in a somewhat strict way. Cares more about \\'my\\' wellbeing far more than the other two.  \\nElle: Studious, Curious - Engaged in learning, Engaged in faith/beliefs discovery.  \\n\\t-High energy, whimsical, outgoing.  \\nElspeth: Higher Sexual Libido, Higher affection  \\n\\t-Pretty laid back, sexually adventurous, loves attention romantically/sexually (Doesn\\'t really care about normal social attention, and in that way is rather introverted.)  \\nTraits shared by all three: Confidence, Second Wind, No Snacking, Healthier Meal Choices.  \\n\\nWhy some of the traits are shared by all three:    \\nConfidence - they each have confidence in their own way. Corie is business confidence--no nonsense, doesn\\'t really care what anyone thinks. Elle is a free spirit and, again, doesn\\'t really care what anyone things and doesn\\'t care if people judge her. Elspeth believes she\\'s attractive and hot shit, so there\\'s no being ashamed of her body or appearance, but she couldn\\'t be a public speaker like Corie...unless drunk.  \\nSecond Wind - They\\'re each their own \\'entity\\'. When they\\'re being used, they\\'re using their own minds, not my tired/bored one. So switching alone gives a second wind.\\nNo Snacking and Healthier Meal Choices - They all eat purely for sustenance. Elspeth loves herself some wine or beer, but that\\'s about it.  \\n_____\\n\\n**Using your Characters**  \\nSome of the terms I\\'ll be using for when you\\'re \\'acting\\' or \\'pretending\\' to be your characters will be Assuming, and Imposing. They\\'re better terms imo for this technique than either acting or pretending.   \\n\\nIt\\'s good practice to try using one of your characters at least once a day, so you\\'re practicing. It takes some getting used to, so the more practice the better.  \\n\\nGetting started, I suggest you use a trigger. It can be a word, phrase, or my personal favorite: a physical gesture. Decide on a trigger for each of your characters. My trigger for Corie is to, on my left hand, put my middle and ring finger together with my thumb at their tips. Then slide my thumb down the two fingers, and back up to the tips.  \\n(It\\'s possible to do this without any trigger at all, but I suggest doing it with a trigger. It\\'ll create a much more stable and reliable foundation for you)  \\n\\n\"But where am \\'I\\', in all this?\" When you\\'re characters are imposing you, \\'you\\' may be either just somewhere in the back of your brain, observing, relaxing, or just kind of in \\'off\\' mode. Or if you have an imaginary place/landscape (sometimes called a wonderland or mind palace), you may be off in that location doing whatever. It\\'s really up to you. If you have more than one character, you may be off chilling with them somewhere.\\n\\nTo develop your trigger, you\\'ll need to put it to use numerous times. Use your trigger, and then immediately after, pretend that you are your character. Believe it. You are your character. Feel their emotions, feel their drives to do what they were intended for. If they were meant to be highly motivated for work, feel their need to get started working.  \\n\\n_____\\n\\n**Development**  \\nDon\\'t just do the trigger, feel the character, and then let that be that. USE your character each time you activate the trigger and assume your character. You\\'re establishing your ability to be that character too, and to maintain it. Doesn\\'t need to be long, especially if you don\\'t really need them right then and there. But just do it to get a good feel for them.  \\n\\nTHINK like them. They are their own person. Their own thoughts, feelings, opinions that may vary from your own. When your characters are imposing you, go all out. Think as they might think. This will also further develop them, making them more solid in your mind and easier to use. They\\'re like your own little brain babies. (Okay maybe not, that sounds weird)     \\n\\nYes, you\\'ll feel silly starting out. Doesn\\'t matter! Do it anyways! No one will know anyhow.     \\n\\nTo give an example, when I first became able to use Corie for a couple hours at a time, I spent the time as Corie, having a conversation in her head with Elle, Elspeth, and \\'me\\' all at the same time. Let your characters talk to \\'you\\', when they\\'re in control. This will help develop them.  \\n\\nEven when I don\\'t need to use any of them, I\\'ll sometimes have conversations with one or all three while I\\'m browsing reddit or playing games. It\\'s kind of like having an imaginary friend in your headspace. (This is also how these may eventually become tulpa over time.) It\\'s great entertainment, at the very least. Other people also *can\\'t* hear inside your head to know how crazy you sound having conversations with made-up characters.  \\n\\nEventually, if you really start using your characters and doing everything, such as talking to them, fully behaving as them when they\\'re \\'imposing\\' you, they will develop over time. Their personalities may become much more diverse, like an actual person. More complex. This is great! It means that they\\'re growing for you, becoming more lifelike and relatable. You\\'ll become more accustomed to them, their thoughts, emotions, feelings, and it\\'ll be so much easier to assume them.  \\n\\nNow all three of my characters are way more developed than the original outline of them I listed above. They\\'re intricate and complex characters that are easy for me to assume when I need them, because I\\'m now so familiar with them. At this point, they each have their own appearances too so that when I\\'m \\'talking\\' to them, I can imagine what they look like. Corie is the most developed, since I need to focus most of my time on work at this point in time in my life, but Elle and Elspeth will be getting more attention once I\\'m in a better work place (Which is improving because of Corie!)  \\n\\n\\nI\\'m happy to answer any and all questions. :) And please let me know if you try this out!',\n",
       " \"Conditional Text Generation (About Me) I'm looking for resources/code which will allow me to generate text (Introduction/About Me) based on defined text inputs like Name, Place,  Occupation, etc.   \\n\\n\\nI was able to find a good relatable paper but there is no available code for [ToTTo: A Controlled Table-To-Text Generation Dataset](https://paperswithcode.com/paper/totto-a-controlled-table-to-text-generation) . If anyone have done something in generation or have some idea then it will be helpful.  \\nthanks in advance.\",\n",
       " '[Best Practices] on how to organize deep learning projects In this article you’ll see how to structure work on deep learning projects — from the inception to deployment, and everything in between. You will learn:\\n\\n- About the lifecycle of the project.\\n- Importance of defining an objective or goal of the project.\\n- Collecting data based on the requirements of the project.\\n- Model training and results exploration including:\\n    - Establishing baselines for better results.\\n    -Adopting techniques and approaches from the existing open-source state-of-the-art models research papers and code repositories.\\n    - Experiment tracking and management management \\n- Model refinement techniques to avoid underfitting and overfitting like:\\n    - Controlling hyperparameters\\n    - Regularisation\\n    - Pruning\\n- Testing and evaluating your project before deployment.\\n- Model deployment\\n- Project maintenance\\n\\n[Structuring deep learning projects](https://neptune.ai/blog/how-to-organize-deep-learning-projects-best-practices?utm_source=reddit&amp;utm_medium=post&amp;utm_campaign=blog-how-to-organize-deep-learning-projects-best-practices&amp;utm_content=languagetechnology)',\n",
       " 'Google AI Introduces ToTTo: A Controlled Table-to-Text Generation Dataset Using Novel Annotation Process **The rising field of natural-language generation**\\n\\nResearch in natural language generation (NLG), a subset of artificial intelligence, is rising. [NLG](https://en.wikipedia.org/wiki/Natural-language_generation) is a software process that changes structured data into natural language. Not to be confused with natural language processing (NLP), NLG synthesizes and writes new content, whereas NLP reads and derives analytic insights from content ([Gartner](https://www.gartner.com/en/documents/3388326)).\\xa0\\xa0\\n\\n* Natural language generation (NLG) creates (or generates) text. It is when computers write language, turning structured data into text.\\n* Natural language processing (NLP) reads (or processes) text. It is when computers read language and derive insights.\\n\\nRead Full Summary: [https://www.marktechpost.com/2021/01/18/google-ai-introduces-totto-a-controlled-table-to-text-generation-dataset-using-novel-annotation-process/](https://www.marktechpost.com/2021/01/18/google-ai-introduces-totto-a-controlled-table-to-text-generation-dataset-using-novel-annotation-process/)\\n\\nPaper:\\xa0[https://arxiv.org/abs/2004.14373](https://arxiv.org/abs/2004.14373)\\n\\nGitHub:\\xa0[https://github.com/google-research-datasets/totto](https://github.com/google-research-datasets/totto)']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in df['content'] if 'control' in t.lower() and 'tabl' in t.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2866b0d",
   "metadata": {},
   "source": [
    "The 'contrl tabl' feature in the naive bayes coefficients seems to come from Google AI's ToTTo: A Controlled Table-to-Text Generation Dataset. While this makes sense as a feature that can characterises the natural language processing topic, it is weird that it features so heavily against the other features as this feature is not going to always appear in language technology content as it is a very particular example of a subtopic.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb14fe7",
   "metadata": {},
   "source": [
    "The top weighted coefficients for the logistic regression model and the naive models are quite different. Although this is not surprising due to a huge amount of features, it is also worrying that there are no strong insights as to obvious features that distinguish the two classes. \n",
    "\n",
    "In terms of interpretability, this is a strong drawback, and there are no obvious insights into important terms that can effectively distinguish the topics. On the other hand, perhaps it is precisely that the models' strengths in classifying effectively comes from the **combination of many features** that is not easily visible when one simply looks at the top coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3b73e",
   "metadata": {},
   "source": [
    "## Analyse Wrongly Classified Posts\n",
    "\n",
    "In this section, the best model's (model 4) features will be analysed to see if trimming any misleading features can improve performance.\n",
    "\n",
    "The features with the highest cumulative tfidf scores in the misclassified examples of the model relative to the scores of all the examples will be examined. The assumption being that these features are likely to be the features that misleads the model.\n",
    "\n",
    "There will be some discussion of these features. And some of these top features will be removed to see if doing so can improve model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c9bc9b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incorrect_samples(model, predictors=X_test.values, targets=y_test.values):\n",
    "    \"\"\"\n",
    "    Returns a new dataframe of all the texts where actual != predicted.\n",
    "    \"\"\"\n",
    "    incorrect_df = pd.DataFrame(predictors, columns=['text'])\n",
    "    incorrect_df['actual'] = targets\n",
    "    incorrect_df['predicted'] = model.predict(predictors)\n",
    "    \n",
    "    incorrect_df['og_index'] = incorrect_df.index\n",
    "    \n",
    "    \n",
    "    incorrect = incorrect_df[incorrect_df['actual'] != incorrect_df['predicted']]\n",
    "    incorrect = incorrect.reset_index(drop='True')\n",
    "    return incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cff97c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_misclassed_features(model, predictors=X_test.values, targets=y_test.values, reverse=True):\n",
    "    \"\"\"\n",
    "    Returns text features of misclassified examples\n",
    "    if they are present in the model, ranked by their \n",
    "    cumulative feature scores in the misclassified data\n",
    "    as a proportion of the cumulative feature scores in\n",
    "    the total data.\n",
    "    \"\"\"\n",
    "    incorrect_predictions = get_incorrect_samples(model, predictors, targets)\n",
    "    incorrect_predictions_text = incorrect_predictions['text']\n",
    "    ic_model_term_matrix = model[0].transform(incorrect_predictions_text)\n",
    "    total_model_term_matrix = model[0].transform(predictors)\n",
    "    ic_model_t_m_summed = ic_model_term_matrix.sum(axis=0)\n",
    "    total_model_t_m_summed = total_model_term_matrix.sum(axis=0)\n",
    "    \n",
    "    ic_model_t_m_summed.resize(ic_model_t_m_summed.shape[1],)\n",
    "    total_model_t_m_summed.resize(total_model_t_m_summed.shape[1],)\n",
    "    # add 1 to scores to prevent zero division errors\n",
    "    total_model_scores = np.add(total_model_t_m_summed, (np.ones(total_model_t_m_summed.shape),))\n",
    "    \n",
    "    summed_score_proportions = ic_model_t_m_summed / total_model_scores\n",
    "    summed_score_proportions.resize(summed_score_proportions.shape[1],)\n",
    "    return dict(sorted(zip(model[0].vocabulary_, summed_score_proportions),key=lambda x:x[1], reverse=reverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f65fd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_miscl_features = get_frequent_misclassed_features(model_4, X_dl.values, y_dl.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5e558632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ha': 0.44093458909729927,\n",
       " 'start make': 0.4327824831429995,\n",
       " 'ce model': 0.3879057122412223,\n",
       " 'best knowledge': 0.3852385989563146,\n",
       " 'intrus': 0.3779704559424049,\n",
       " 'properly': 0.3774851805205872,\n",
       " 'around lot': 0.3747293397298133,\n",
       " 'reg': 0.3549978483626867,\n",
       " 'work best': 0.34982869538374556,\n",
       " 'hidd': 0.3479670611650218,\n",
       " 'rpc': 0.34764653286088265,\n",
       " 'th turi': 0.3441566853825062,\n",
       " 'member ev': 0.3304330263182701,\n",
       " 'erget': 0.3301048942270919,\n",
       " 'nxivm': 0.32728754616191275,\n",
       " 'like these': 0.3267024979804952,\n",
       " 'categor': 0.31466877564411677,\n",
       " 'model rec': 0.31416920844148755,\n",
       " 'form': 0.30648638660359845,\n",
       " 'everyth': 0.28346265577088225,\n",
       " 'dollar': 0.2832784906229598,\n",
       " 'taught': 0.28298440821272053,\n",
       " 'child': 0.2775761142206541,\n",
       " 'immedi': 0.27018088015681213,\n",
       " 'intermedi': 0.26729370271928116,\n",
       " 'ce ce': 0.26427446678934446,\n",
       " 'seldom': 0.26427446678934446,\n",
       " 'drama': 0.26427446678934446,\n",
       " 'model success': 0.2606268349340258,\n",
       " 'much info': 0.2585523842946256,\n",
       " 'deviat': 0.2581893078135993,\n",
       " 'doubt': 0.2567919572843618,\n",
       " 'filter': 0.2555663906135661,\n",
       " 'iter': 0.2554216894866888,\n",
       " 'ner aspect': 0.2552676176148717,\n",
       " 'market coach': 0.2543809418633321,\n",
       " 'keytotext': 0.2543809418633321,\n",
       " 'this would': 0.25179537048410155,\n",
       " 'rec tli': 0.25179537048410155,\n",
       " 'hope help': 0.25179537048410155,\n",
       " 'featur dataset': 0.25179537048410155,\n",
       " 'dataset yake': 0.25179537048410155,\n",
       " 'classify': 0.25179537048410155,\n",
       " 'boundari': 0.2512216054173542,\n",
       " 'doc notebooks': 0.24761516679178805,\n",
       " 'good task': 0.24681846397601115,\n",
       " 'mistak': 0.24654325214554101,\n",
       " 'download': 0.24606673934845194,\n",
       " 'latest nlu': 0.2444020180684113,\n",
       " 'lost': 0.2436263075560318,\n",
       " 'realli want': 0.24223773553580435,\n",
       " 'low resourc': 0.24116484403165003,\n",
       " 'extract ce': 0.24035570381051405,\n",
       " 'data however': 0.24010794227341103,\n",
       " 'educ nlp': 0.23940292328763554,\n",
       " 'word vector': 0.23616023222484828,\n",
       " 'fetch': 0.23448162643265197,\n",
       " 'would say': 0.23343849588016474,\n",
       " 'po ner': 0.23334845766348303,\n",
       " 'famou': 0.23166698489355728,\n",
       " 'jordan belfort': 0.23125324900221148,\n",
       " 'cope': 0.23120977685502314,\n",
       " 'need littl': 0.23097734240105336,\n",
       " 'damon cart': 0.2309739192193396,\n",
       " 'make se': 0.23023846342795076,\n",
       " 'quantiz': 0.22948812987324912,\n",
       " 'assignm ts': 0.2288599043871429,\n",
       " 'chinese japanese': 0.22876915188898572,\n",
       " 'ive': 0.22760504636404735,\n",
       " 'conditions': 0.22602550587318423,\n",
       " 'may missed': 0.22394599148642225,\n",
       " 'packag': 0.22203613685208973,\n",
       " 'specif use': 0.22180559565008837,\n",
       " 'ding day': 0.21986284493334002,\n",
       " 'locat': 0.21972919564393723,\n",
       " 'founder': 0.2177112660623712,\n",
       " 'now ev': 0.21726039323466512,\n",
       " 'googl ai': 0.21365123597547447,\n",
       " 'jsl wip': 0.21218135570558672,\n",
       " 'social situat': 0.21200217501106175,\n",
       " 'freelanc': 0.2093690847325317,\n",
       " 'basically': 0.20833559702377694,\n",
       " 'virtual': 0.2081374618417395,\n",
       " 'pre process': 0.20800863782884313,\n",
       " 'peopl say': 0.20800863782884313,\n",
       " 'nlp group': 0.20800863782884313,\n",
       " 'mask model': 0.20790415272278848,\n",
       " 'mani peopl': 0.20655576023184455,\n",
       " 'task so': 0.20655576023184455,\n",
       " 'survey': 0.20459126759353136,\n",
       " 'train model': 0.20439721045713213,\n",
       " 'audio book': 0.20268079484235826,\n",
       " 'dog': 0.20038768391896886,\n",
       " 'models hi': 0.1980878138619385,\n",
       " 'fire': 0.19678216635357476,\n",
       " 'int classifi': 0.19545677825170946,\n",
       " 'preview': 0.1944621510254112,\n",
       " 'necessari': 0.19414351869025173,\n",
       " 'unbalanced': 0.19364278924037184,\n",
       " 'work realli': 0.1918082025449222,\n",
       " 'th back': 0.19145700733787316,\n",
       " 'look someon': 0.18958415924618294,\n",
       " 'simpl question': 0.18935293823734076,\n",
       " 'situations': 0.189304993457335,\n",
       " 'tok izat': 0.18836998142900926,\n",
       " 'lt gt': 0.1876443435222301,\n",
       " 'new habits': 0.18660906552627624,\n",
       " 'paper investig': 0.18637900625461815,\n",
       " 'impressive': 0.186148211438176,\n",
       " 'like play': 0.18587140311074296,\n",
       " 'alway': 0.18506830893409817,\n",
       " 'words': 0.18399554462343345,\n",
       " 'semesters': 0.18340266887085072,\n",
       " 'amp coach': 0.1829997122014326,\n",
       " 'cluster method': 0.18275989222546143,\n",
       " 'nlp decid': 0.18243336668323032,\n",
       " 'compani': 0.18196486272244747,\n",
       " 'can': 0.1817382962153886,\n",
       " 'extract name': 0.17969971977873703,\n",
       " 'chang': 0.17959174415183457,\n",
       " 'se new': 0.17880224610345669,\n",
       " 'demo nlp': 0.1785467096070163,\n",
       " 'word example': 0.17838329888139257,\n",
       " 'responses': 0.17763794272975839,\n",
       " 'reply would': 0.1762202493947001,\n",
       " 'second': 0.1757356887317057,\n",
       " 'much': 0.17572655978120597,\n",
       " 'interest processing': 0.17532721050967112,\n",
       " 'everybody': 0.175127364885294,\n",
       " 'directori': 0.17503414552238147,\n",
       " 'performance': 0.17439336114671702,\n",
       " 'pdf github': 0.17399235548388942,\n",
       " 'lite': 0.17368633244109696,\n",
       " 'hi like': 0.17312284782115947,\n",
       " 'nlp commun': 0.17220606743047032,\n",
       " 'would helpful': 0.1701946740476484,\n",
       " 'world largest': 0.16983226740630472,\n",
       " 'silly': 0.16939895660376209,\n",
       " 'multi docum': 0.1692848644054955,\n",
       " 'vari': 0.1691979696763524,\n",
       " 'build rapport': 0.168911030031303,\n",
       " 'narr': 0.16869253399246192,\n",
       " 'hand': 0.16861923679614904,\n",
       " 'new habit': 0.16858769393616502,\n",
       " 'research paper': 0.16670217988622604,\n",
       " 'spatial': 0.16670217988622604,\n",
       " 'total number': 0.16666099585231983,\n",
       " 'model nlu': 0.1663800338940091,\n",
       " 'heard': 0.16623352371071418,\n",
       " 'thus': 0.16601341429351185,\n",
       " 'xb coupl': 0.16573574717569353,\n",
       " 'nlp work': 0.16569569028442319,\n",
       " 'comfort work': 0.1655247607471955,\n",
       " 'frog': 0.16515219369069783,\n",
       " 'ce code': 0.16467252577374106,\n",
       " 'missed thanks': 0.16465262708538775,\n",
       " 'quit time': 0.16381188411818695,\n",
       " 'certain way': 0.16307061625767136,\n",
       " 'laugh': 0.1624920328337831,\n",
       " 'do': 0.16170513478228432,\n",
       " 'day nlp': 0.16104217814334687,\n",
       " 'train ai': 0.16065214792148294,\n",
       " 'unsupervis way': 0.16049253510453776,\n",
       " 'eat': 0.16029820853004048,\n",
       " 'earli draft': 0.15883987722106488,\n",
       " 'billi': 0.15883987722106488,\n",
       " 'creat nlp': 0.1579797939355923,\n",
       " 'think social': 0.15746434329216488,\n",
       " 'models new': 0.1567668536003528,\n",
       " 'coach decept': 0.1563733782137444,\n",
       " 'convert': 0.15623835549261203,\n",
       " 'pictur': 0.1561902496379533,\n",
       " 'whether one': 0.15598092092916027,\n",
       " 'rememb': 0.15551066757262308,\n",
       " 'output hi': 0.1550989452478245,\n",
       " 'activ think': 0.1542164532720477,\n",
       " 'ce way': 0.15368152449087255,\n",
       " 'easy': 0.15336164504436092,\n",
       " 'abus': 0.1528906999604558,\n",
       " 'ai model': 0.1526420395711378,\n",
       " 'load use': 0.152320702079698,\n",
       " 'look use': 0.15216785939661595,\n",
       " 'creat author': 0.15196559731089876,\n",
       " 'think need': 0.1510642052188333,\n",
       " 'like this': 0.15081637384893115,\n",
       " 'fine that': 0.15071101631985892,\n",
       " 'nlp natur': 0.1483809765932151,\n",
       " 'trigger anchor': 0.1474991040549128,\n",
       " 'get accuraci': 0.14611329642469967,\n",
       " 'brown': 0.1460743703513636,\n",
       " 'hour': 0.14570098597885048,\n",
       " 'output level': 0.14562176030087978,\n",
       " 'story': 0.1455148982538673,\n",
       " 'crawl data': 0.1454406601882741,\n",
       " 'spark support': 0.14532993596315133,\n",
       " 'read book': 0.1450452970550693,\n",
       " 'lutctgm kuuazcyfkhugi': 0.14457427982626936,\n",
       " 'think way': 0.14337892362459623,\n",
       " 'dqdnicyikg amp': 0.1427889091684141,\n",
       " 'ration think': 0.1413978773714651,\n",
       " 'float valu': 0.1411640384091572,\n",
       " 'tempor ev': 0.14009797044684819,\n",
       " 'steel': 0.1396394662092079,\n",
       " 'similar task': 0.13962007153293238,\n",
       " 'best done': 0.13949044969054825,\n",
       " 'desir': 0.1393575062837055,\n",
       " 'pip pip': 0.1393501221443195,\n",
       " 'rather': 0.1389625852171483,\n",
       " 'would expect': 0.13856215192082041,\n",
       " 'draft': 0.1384365719933301,\n",
       " 'take nlp': 0.13832354446000397,\n",
       " 'best paper': 0.13807772020840137,\n",
       " 'dive': 0.1380516892773624,\n",
       " 'easier use': 0.13764948557678222,\n",
       " 'ad': 0.1374295637335503,\n",
       " 'pleasant': 0.13715409110620155,\n",
       " 'specifi': 0.13646596734296487,\n",
       " 'corpora one': 0.13609976846052044,\n",
       " 'embeddings github': 0.13592015823418074,\n",
       " 'first step': 0.13513666866247998,\n",
       " 'trainer hr': 0.13424282000048313,\n",
       " 'ce wh': 0.13383212679454093,\n",
       " 'summarize': 0.13360428925600312,\n",
       " 'becam': 0.13263349052199513,\n",
       " 'chang model': 0.132547670734282,\n",
       " 'this sub': 0.13238898544092395,\n",
       " 'blogpost nlu': 0.13228897372642065,\n",
       " 'also come': 0.13222241940445767,\n",
       " 'field': 0.13195291721689487,\n",
       " 'use myself': 0.13195291721689487,\n",
       " 'talism': 0.1318769830676401,\n",
       " 'realli good': 0.13164935965429136,\n",
       " 'is hand': 0.13163527888623439,\n",
       " 'amp ev': 0.13123765956457822,\n",
       " 'program give': 0.13123210384818118,\n",
       " 'nlp idea': 0.131185057530548,\n",
       " 'reading': 0.13071633584898684,\n",
       " 'ner ner': 0.13046728203799884,\n",
       " 'know keyword': 0.12989041974931007,\n",
       " 'epoch': 0.12974725627090694,\n",
       " 'curiou': 0.12891903895236304,\n",
       " 'languages answer': 0.12840737700372126,\n",
       " 'reduction': 0.12821863254307783,\n",
       " 'next level': 0.12762336677421637,\n",
       " 'paper note': 0.127562703245805,\n",
       " 'hypnot pattern': 0.1275229204711082,\n",
       " 'parsing': 0.12707102207744658,\n",
       " 'language': 0.12696674802993507,\n",
       " 'state model': 0.1263368843064881,\n",
       " 'entiti recognition': 0.12594199683071022,\n",
       " 'code real': 0.12586612895696786,\n",
       " 'api tool': 0.12575953612211696,\n",
       " 'autoregress pretrain': 0.1257008119541284,\n",
       " 'th found': 0.12535593584500335,\n",
       " 'docum level': 0.1252020528447961,\n",
       " 'smooth': 0.12511477885877575,\n",
       " 'remark': 0.12495758459292643,\n",
       " 'hope get': 0.12470558275284611,\n",
       " 'stud': 0.12435888491472888,\n",
       " 'supportive': 0.12366303427153336,\n",
       " 'congru ce': 0.12336995916694186,\n",
       " 'grammar correct': 0.12326209028878085,\n",
       " 'queri': 0.12324748787354868,\n",
       " 'butter': 0.12291412083881172,\n",
       " 'program better': 0.1228752875448851,\n",
       " 'mani nlp': 0.12233201778349417,\n",
       " 'instruct': 0.12200616411662622,\n",
       " 'prematur ejacul': 0.12153117557776438,\n",
       " 'check github': 0.12141511137463544,\n",
       " 'resolut titi': 0.12063151836296879,\n",
       " 'take around': 0.12021127487985045,\n",
       " 'watch hbo': 0.12003805828983824,\n",
       " 'states': 0.11989170687447788,\n",
       " 'person bot': 0.11982313042960772,\n",
       " 'som': 0.11963574963070349,\n",
       " 'ts sub': 0.11948709748366647,\n",
       " 'gt translat': 0.1194865573503335,\n",
       " 'fairli': 0.11913775992304915,\n",
       " 'call wh': 0.119113017106261,\n",
       " 'bipolar': 0.11909889343241155,\n",
       " 'exampl name': 0.11903790982997325,\n",
       " 'media text': 0.11884296967190461,\n",
       " 'nlp linguist': 0.1186212311608424,\n",
       " 'nlp practitioners': 0.11858759724545904,\n",
       " 'without code': 0.11817446044671427,\n",
       " 'want give': 0.11784293870472477,\n",
       " 'intuit': 0.1177487521128346,\n",
       " 'comm tari': 0.1176272897236358,\n",
       " 'swish pattern': 0.11757989291936786,\n",
       " 'ce applic': 0.11753181352224235,\n",
       " 'hear experi': 0.11670058248636718,\n",
       " 'despit': 0.11656897592181784,\n",
       " 'meta': 0.11615732954827117,\n",
       " 'gtc nvkasmith': 0.11614428878083524,\n",
       " 'back forth': 0.11607662132391444,\n",
       " 'would great': 0.11589490097454187,\n",
       " 'github shreyansh': 0.11582928174305754,\n",
       " 'multipl time': 0.1157317528933921,\n",
       " 'much say': 0.11530480810064206,\n",
       " 'org': 0.11529895026882969,\n",
       " 'anyon awar': 0.11488695532385956,\n",
       " 'doc nlp': 0.11462097038345505,\n",
       " 'not': 0.11448280047171618,\n",
       " 'sort': 0.11448280047171618,\n",
       " 'tific': 0.11448280047171618,\n",
       " 'neptune': 0.11448280047171618,\n",
       " 'hint': 0.11443026805843491,\n",
       " 'stopword removal': 0.11409719862780654,\n",
       " 'processes': 0.11402115772661754,\n",
       " 'metamodel': 0.1137561291421178,\n",
       " 'lambda': 0.11363907399704988,\n",
       " 'find use': 0.11343958257925274,\n",
       " 'like univers': 0.11343199568270167,\n",
       " 'focus ev': 0.11255642270996477,\n",
       " 'wh get': 0.11196751862941003,\n",
       " 'member group': 0.11193266903466109,\n",
       " 'some': 0.1117490815862509,\n",
       " 'duti': 0.11137705795236094,\n",
       " 'learning': 0.11135892158341698,\n",
       " 'advis': 0.11117410640589022,\n",
       " 'understand it': 0.11073134713925213,\n",
       " 'category': 0.11036196364512006,\n",
       " 'load zh': 0.11016809537853109,\n",
       " 'know mani': 0.11004378341187647,\n",
       " 'morn': 0.10975635804462539,\n",
       " 'tech compani': 0.10967738297419789,\n",
       " 'all wonder': 0.10964145007418817,\n",
       " 'limited': 0.10962581303920069,\n",
       " 'question hello': 0.10953075420614018,\n",
       " 'usage': 0.10940979581274585,\n",
       " 'increases': 0.10933205640875927,\n",
       " 'keyword like': 0.10893436629320784,\n",
       " 'pretti similar': 0.10863481266383707,\n",
       " 'th tri': 0.10859732411005346,\n",
       " 'uncomfort': 0.10857631307020334,\n",
       " 'step refram': 0.10849657139213296,\n",
       " 'tri use': 0.10827727216798351,\n",
       " 'think would': 0.10801856329835993,\n",
       " 'evolv': 0.10798642356322513,\n",
       " 'fear height': 0.10784014726023512,\n",
       " 'apach': 0.10776111623358114,\n",
       " 'wh ask': 0.10703253361354154,\n",
       " 'now like': 0.10652467132586306,\n",
       " 'manipul peopl': 0.10634831052391784,\n",
       " 'apr der': 0.10629991707723653,\n",
       " 'trillion parameters': 0.10623007514216512,\n",
       " 'interviews': 0.10581534346962013,\n",
       " 'suppos': 0.1057516061506972,\n",
       " 'glove imdb': 0.1057516061506972,\n",
       " 'impact': 0.10544373752029625,\n",
       " 'pleas go': 0.10542628139292096,\n",
       " 'pattern use': 0.10496534480083279,\n",
       " 'process simplifi': 0.10490137866469097,\n",
       " 'data custom': 0.10476379536678233,\n",
       " 'ab': 0.10468501338717294,\n",
       " 'im look': 0.10432534258231874,\n",
       " 'failure': 0.10359985716261139,\n",
       " 'ough data': 0.10350039212529973,\n",
       " 'discord': 0.10347992554001148,\n",
       " 'realli practic': 0.10344532320564123,\n",
       " 'want know': 0.10343170588974036,\n",
       " 'seem offer': 0.10338899083622634,\n",
       " 'internship': 0.10332233795688144,\n",
       " 'coffe': 0.10330391978350288,\n",
       " 'see need': 0.10318292310807392,\n",
       " 'tially': 0.10277368336002785,\n",
       " 'question better': 0.10271092301573836,\n",
       " 'hav ing': 0.10258232298966802,\n",
       " 'notebook nlu': 0.10247651645369812,\n",
       " 'sorting': 0.10185432900609749,\n",
       " 'normalization': 0.10184441009868389,\n",
       " 'test eval': 0.10093859663071135,\n",
       " 'hidd keep': 0.10088767703213498,\n",
       " 'nlp se': 0.10078519372757039,\n",
       " 'records': 0.10038149606585703,\n",
       " 'gtx': 0.10027216541182389,\n",
       " 'mind awar': 0.10011481092848315,\n",
       " 'ev learn': 0.09976053052179346,\n",
       " 'first train': 0.09967933357864,\n",
       " 'answer someth': 0.09959327680937408,\n",
       " 'terms': 0.09958175221928245,\n",
       " 'immers': 0.09941582469465703,\n",
       " 'concept nlp': 0.09885234343717333,\n",
       " 'perhap': 0.09881381261101516,\n",
       " 'could provid': 0.09865773588972693,\n",
       " 'finish master': 0.09829484731530584,\n",
       " 'tal block': 0.09822284405592943,\n",
       " 'later': 0.09811343987926084,\n",
       " 'tri mani': 0.09726961463934031,\n",
       " 'folder': 0.09703159449465416,\n",
       " 'money': 0.09666718194827764,\n",
       " 'summar task': 0.09660261400603384,\n",
       " 'simplif': 0.09648186392709225,\n",
       " 'think possibl': 0.09636675119531118,\n",
       " 'paragraph': 0.09613191669363375,\n",
       " 'ts nlp': 0.09589365719496197,\n",
       " 'use sorflow': 0.09553368160172315,\n",
       " 'nlp dataset': 0.09550137190223647,\n",
       " 'nose': 0.09539255462100493,\n",
       " 'laptop': 0.09512066907271029,\n",
       " 'tm': 0.09491939204596575,\n",
       " 'id tify': 0.09480257137254003,\n",
       " 'ce success': 0.09468748223540831,\n",
       " 'someon know': 0.09423188361003544,\n",
       " 'free gpu': 0.09386189595024758,\n",
       " 'none': 0.09382083809217535,\n",
       " 'jamespesch amp': 0.09352744590155096,\n",
       " 'learn hello': 0.0930678621802735,\n",
       " 'improvem ts': 0.0930343637874209,\n",
       " 'aforem tion': 0.09302069562620993,\n",
       " 'work emot': 0.09283779044834109,\n",
       " 'here what': 0.09266519440650156,\n",
       " 'id tical': 0.09240193275446926,\n",
       " 'sigmoid': 0.09238468451592412,\n",
       " 'talks': 0.0922147854779709,\n",
       " 'nlu nlp': 0.09218243362929068,\n",
       " 'learn python': 0.09218243362929068,\n",
       " 'interest in': 0.09218243362929068,\n",
       " 'new data': 0.09213578811495571,\n",
       " 'alive': 0.09205232624620449,\n",
       " 'took': 0.09190038495988849,\n",
       " 'seqseq': 0.09187010088880847,\n",
       " 'tire dataset': 0.09138379861703753,\n",
       " 'activ': 0.09115372141874029,\n",
       " 'issu rec': 0.09036430895222693,\n",
       " 'teaching': 0.09035548435025752,\n",
       " 'like me': 0.0902488304266927,\n",
       " 'origin nlp': 0.09022050124700368,\n",
       " 'fasttext': 0.09012919473057888,\n",
       " 'ideal like': 0.09003672394407344,\n",
       " 'cool': 0.08996535714181916,\n",
       " 'need': 0.08992490923380507,\n",
       " 'pleas help': 0.08991600958648022,\n",
       " 'korean languag': 0.08969549438069327,\n",
       " 'hug': 0.08962851984574721,\n",
       " 'module': 0.08950506813708968,\n",
       " 'way go': 0.08943607872635687,\n",
       " 'vocabulari': 0.08916219654448464,\n",
       " 'ring finger': 0.08911570599002164,\n",
       " 'stuck': 0.08906311039252168,\n",
       " 'spare': 0.08859064822916525,\n",
       " 'nlp understand': 0.08846034642969074,\n",
       " 'audio text': 0.08825714968961526,\n",
       " 'sql': 0.08823654143397354,\n",
       " 'arxiv ab': 0.08804505710226522,\n",
       " 'pd': 0.08799143703395806,\n",
       " 'motiv': 0.08785545545179435,\n",
       " 'sophist': 0.08784677132832722,\n",
       " 'person project': 0.08781924586863879,\n",
       " 'style transfer': 0.08742316076403459,\n",
       " 'task name': 0.08722237884325504,\n",
       " 'girlfri': 0.08711957104030874,\n",
       " 'afraid': 0.08682702658591573,\n",
       " 'tag part': 0.08678396820871949,\n",
       " 'chines word': 0.08678300796746458,\n",
       " 'know paper': 0.08635321949439026,\n",
       " 'subconsci mind': 0.08608130523761218,\n",
       " 'ext ding': 0.08597146417521616,\n",
       " 'nvkasmith': 0.08571405256260112,\n",
       " 'rephras': 0.0856705685209601,\n",
       " 'car': 0.08563845192958769,\n",
       " 'tion video': 0.08534136373154133,\n",
       " 'studying': 0.08513906992702973,\n",
       " 'familiar python': 0.08469737524654308,\n",
       " 'encod': 0.08453357950459521,\n",
       " 'theori behind': 0.08428866547921417,\n",
       " 'basi': 0.08403533031808025,\n",
       " 'label text': 0.08403161228080586,\n",
       " 'healthier': 0.08380057925311601,\n",
       " 'pl': 0.08359352897013853,\n",
       " 'algorithm use': 0.08294429359995228,\n",
       " 'per week': 0.08293480504944245,\n",
       " 'limitations': 0.08244403878656127,\n",
       " 'learned': 0.08240067433325987,\n",
       " 'bad': 0.08235910044696576,\n",
       " 'littl experi': 0.08226802815685819,\n",
       " 'short term': 0.08210450079158597,\n",
       " 'rebuild spellchecker': 0.08172126487485173,\n",
       " 'sever': 0.08161907398660254,\n",
       " 'sometim convers': 0.08154228385062383,\n",
       " 'peopl life': 0.08151369264842172,\n",
       " 'however ev': 0.08129391398368062,\n",
       " 'flu english': 0.08125052171952248,\n",
       " 'pyspark': 0.08119427303464294,\n",
       " 'guilt': 0.08096953902853922,\n",
       " 'comput vision': 0.0809396000771632,\n",
       " 'multi lingual': 0.08086201109290557,\n",
       " 'redir': 0.08077395209970516,\n",
       " 'example could': 0.08057624052931855,\n",
       " 'two years': 0.08056563477220322,\n",
       " 'medit': 0.08023104009230028,\n",
       " 'date latest': 0.08020621834629793,\n",
       " 'way around': 0.07978173901332096,\n",
       " 'understand nlp': 0.07978153371347554,\n",
       " 'what opinion': 0.07957669212262457,\n",
       " 'presupposit nlp': 0.07949035671121958,\n",
       " 'hear thought': 0.07877932188851679,\n",
       " 'way get': 0.07875029356467259,\n",
       " 'use pre': 0.07874904248369845,\n",
       " 'ces exampl': 0.07866270471986803,\n",
       " 'older': 0.07864901083253409,\n",
       " 'model chmark': 0.07834740928363124,\n",
       " 'business': 0.07834051642525157,\n",
       " 'mani mani': 0.07822201685824934,\n",
       " 'inc': 0.07819465900388896,\n",
       " 'docs nlpcloud': 0.078129885615289,\n",
       " 'tion need': 0.07795491973656694,\n",
       " 'pleas bear': 0.07789516615547136,\n",
       " 'imagin': 0.07786184748888601,\n",
       " 'anyon read': 0.07774915229952217,\n",
       " 'grasp': 0.07743920289953382,\n",
       " 'link': 0.07741980626318155,\n",
       " 'bert tok': 0.07732471242997188,\n",
       " 'real life': 0.07724019869200194,\n",
       " 'resourc state': 0.07716228447595738,\n",
       " 'peopl think': 0.07714317348483721,\n",
       " 'nlp hypnosi': 0.07701056678264359,\n",
       " 'exist solut': 0.07693144157623631,\n",
       " 'video ad': 0.07685564033173475,\n",
       " 'while': 0.07683900774977728,\n",
       " 'report variou': 0.0765295735312134,\n",
       " 'stage': 0.07574956278063055,\n",
       " 'im curr': 0.07540959238806093,\n",
       " 'text corpus': 0.07513864349570774,\n",
       " 'principl': 0.07510701981510726,\n",
       " 'driv': 0.07485353681979952,\n",
       " 'east': 0.07479887504605885,\n",
       " 'hawk': 0.07476322843971739,\n",
       " 'whether may': 0.07467320991270336,\n",
       " 'need improv': 0.07463554912874029,\n",
       " 'entiti relat': 0.07454626001054004,\n",
       " 'put': 0.07443636340368788,\n",
       " 'relat stuff': 0.07423506796597545,\n",
       " 'apolog': 0.0742292817528311,\n",
       " 'predict type': 0.07407275340099624,\n",
       " 'data set': 0.07390416942659055,\n",
       " 'comma': 0.07378645417691068,\n",
       " 'don': 0.0735755624224529,\n",
       " 'already': 0.07323965871663479,\n",
       " 'share inform': 0.07295365394786033,\n",
       " 'prov wrong': 0.07292146053157461,\n",
       " 'groov': 0.07272087360661203,\n",
       " 'expert tutor': 0.0727119605661831,\n",
       " 'max features': 0.07270247967119428,\n",
       " 'graduat stud': 0.07247185144258804,\n",
       " 'didn know': 0.07246262347722954,\n",
       " 'cosin similarity': 0.07240374931351463,\n",
       " 'extract relev': 0.07239021879729178,\n",
       " 'said someth': 0.07227836785702334,\n",
       " 'improv results': 0.07223587640883448,\n",
       " 'layers': 0.07215804015520048,\n",
       " 'cold read': 0.07202384810378744,\n",
       " 'uc berkeley': 0.07200366017612803,\n",
       " 'classif python': 0.07199467700064446,\n",
       " 'af': 0.07162191029948611,\n",
       " 'similar ce': 0.07153594445495448,\n",
       " 'https patreon': 0.07136376647663066,\n",
       " 'similarity': 0.07131158758836585,\n",
       " 'devic': 0.0712392588738121,\n",
       " 'preserv': 0.07123681897150336,\n",
       " 'everyon interest': 0.07116416766428846,\n",
       " 'curiou anyon': 0.07102732971270372,\n",
       " 'head': 0.07100951858293456,\n",
       " 'react': 0.07100607716171035,\n",
       " 'academi': 0.07077710260877533,\n",
       " 'huggingfac': 0.07061555373646893,\n",
       " 'tell stori': 0.0704921307595715,\n",
       " 'upgrad': 0.07016803555857329,\n",
       " 'new english': 0.06997835001645938,\n",
       " 'success would': 0.06990917789360981,\n",
       " 'post comm': 0.06979236069622613,\n",
       " 'use topic': 0.06949119517799159,\n",
       " 'dumb': 0.0694251736600331,\n",
       " 'sh bash': 0.06940527453464938,\n",
       " 'tativ': 0.06938537436548538,\n",
       " 'll take': 0.06936134236273288,\n",
       " 'though': 0.06932241353539657,\n",
       " 'purpos': 0.06915214302328844,\n",
       " 'dream': 0.06913584610581798,\n",
       " 'degre': 0.06891897182502661,\n",
       " 'mean pool': 0.06866567230971646,\n",
       " 'relation tempor': 0.06856628656559227,\n",
       " 'look nlp': 0.06853385781511823,\n",
       " 'analyst': 0.06815776974217395,\n",
       " 'earli': 0.06813119079195445,\n",
       " 'flatt': 0.06802138789684067,\n",
       " 'word frequ': 0.06788091108841422,\n",
       " 'argum': 0.06772286200400304,\n",
       " 'se it': 0.06769325490396516,\n",
       " 'panic attack': 0.06768254204808861,\n",
       " 'real experi': 0.06751287950009632,\n",
       " 'taking': 0.06744415224433097,\n",
       " 'bcbc': 0.0674187938381308,\n",
       " 'reactions': 0.06692898281282703,\n",
       " 'machin learning': 0.06691227793216944,\n",
       " 'look into': 0.06688870664908837,\n",
       " 'people': 0.06672738247093678,\n",
       " 'improv it': 0.06659930920938849,\n",
       " 'think take': 0.06653674924217062,\n",
       " 'support coach': 0.06634095910161811,\n",
       " 'pretrain bert': 0.06599196839006936,\n",
       " 'int': 0.06575144600048173,\n",
       " 'item': 0.06568252368328156,\n",
       " 'life chang': 0.06563624070906433,\n",
       " 'xb anyon': 0.06532080424462618,\n",
       " 'base assignm': 0.06509487625429054,\n",
       " 'abc nlp': 0.06501354631176302,\n",
       " 'ling': 0.06489103811683512,\n",
       " 'road': 0.06486185561254337,\n",
       " 'patrick': 0.06473572935038166,\n",
       " 'ny': 0.06470878672855045,\n",
       " 'positive negative': 0.06465145857915691,\n",
       " 'smoke cigarette': 0.06461485922842343,\n",
       " 'fail': 0.06436475412291046,\n",
       " 'suggestions': 0.0642273996575166,\n",
       " 'came across': 0.06365516649826794,\n",
       " 'nlu base': 0.06361111877728946,\n",
       " 'wip clinical': 0.0635163107552473,\n",
       " 'mad': 0.06338289042533674,\n",
       " 'ce stop': 0.06335893723140361,\n",
       " 'regret': 0.06335066180342902,\n",
       " 'ce start': 0.06291163495553406,\n",
       " 'erat paragraph': 0.06283642820912001,\n",
       " 'softwar': 0.06273799825559821,\n",
       " 'paraphrases': 0.06268215509393145,\n",
       " 'look great': 0.06265237207618923,\n",
       " 'am': 0.06265237207618923,\n",
       " 'davidshephard': 0.06261815392795986,\n",
       " 'ga github': 0.06251556499346274,\n",
       " 'learning thank': 0.06244691007545304,\n",
       " 'tutori cover': 0.062055073889703966,\n",
       " 'read nlp': 0.061988605362372995,\n",
       " 'lutctgm': 0.0619213304335843,\n",
       " 'cs nlp': 0.06182546553897156,\n",
       " 'trait': 0.06157671664303854,\n",
       " 'work full': 0.06131283724691709,\n",
       " 'ize ce': 0.06123491167310339,\n",
       " 'se someon': 0.060902397295360185,\n",
       " 'lab spark': 0.06060711456707262,\n",
       " 'let go': 0.060513423789982035,\n",
       " 'thank advance': 0.060453912625793874,\n",
       " 'decision': 0.06044298482704566,\n",
       " 'calcul': 0.06041833931813532,\n",
       " 'technic': 0.060321515744817956,\n",
       " 'matrix use': 0.06031712516757627,\n",
       " 'truli': 0.06030912771892974,\n",
       " 'categori': 0.06029397845303656,\n",
       " 'probably': 0.060261381481054914,\n",
       " 'restaur': 0.06015169510155524,\n",
       " 'use dynam': 0.06014375810466081,\n",
       " 'advance': 0.06009879899108474,\n",
       " 'vector classifi': 0.06000732235462921,\n",
       " 'sub programming': 0.059977939569949436,\n",
       " 'dataset give': 0.059920926576859684,\n",
       " 'perform nlp': 0.059879979554436615,\n",
       " 'time feel': 0.05984800652841684,\n",
       " 'rank': 0.059600187432335625,\n",
       " 'creat tal': 0.05954673376680919,\n",
       " 'embed like': 0.05950423288046741,\n",
       " 'gain': 0.05924762493684784,\n",
       " 'we': 0.05921828923560549,\n",
       " 'cool thing': 0.05905190686221417,\n",
       " 'jail': 0.059038309768835597,\n",
       " 'fixes': 0.05896636174945454,\n",
       " 'inform would': 0.05881373018485268,\n",
       " 'says': 0.05876327688566158,\n",
       " 'episode': 0.05871302080406689,\n",
       " 'ge': 0.05845724059953964,\n",
       " 'health': 0.05837280889210878,\n",
       " 'vp': 0.05825608225156397,\n",
       " 'initi embed': 0.058201891949263146,\n",
       " 'human engin': 0.058132339967239786,\n",
       " 'recogn': 0.05770111644928993,\n",
       " 'anxiety th': 0.05767605635093756,\n",
       " 'oc': 0.05744639247508735,\n",
       " 'rare': 0.057444319252328374,\n",
       " 'notebook tutori': 0.057372356712923046,\n",
       " 'code ce': 0.0573685283066142,\n",
       " 'merg': 0.05728834778821056,\n",
       " 'gpt model': 0.05687351100677895,\n",
       " 'th pass': 0.05663853344922608,\n",
       " 'kinesthet': 0.056518183246290044,\n",
       " 'alreadi look': 0.05650747597631998,\n",
       " 'csv': 0.05648157029384596,\n",
       " 'basic want': 0.0563979871179429,\n",
       " 'ce achiev': 0.05619601039368305,\n",
       " 'nlp nlu': 0.05600841697793086,\n",
       " 'anyth els': 0.05594780261659566,\n",
       " 'bad habit': 0.055838730145149916,\n",
       " 'custom dataset': 0.055745928858176974,\n",
       " 'edit clarification': 0.05570685457133366,\n",
       " 'poison': 0.05548911428280959,\n",
       " 'nlp order': 0.055487352599130124,\n",
       " 'freeli avail': 0.05537326561515889,\n",
       " 'are not': 0.0552925325121454,\n",
       " 'think it': 0.05516985338307085,\n",
       " 'convinc': 0.055158889406383894,\n",
       " 'project onto': 0.05501908545151433,\n",
       " 'use abbrevi': 0.0550058807687414,\n",
       " 'ce run': 0.05490632314949593,\n",
       " 'need model': 0.054883661913159104,\n",
       " 'train it': 0.054823823199470136,\n",
       " 'grinder approach': 0.054652984553712106,\n",
       " 'ep': 0.05454605246139023,\n",
       " 'bypass': 0.05433445404039214,\n",
       " 'me like': 0.05429474475188923,\n",
       " 'wh tri': 0.054199605959799654,\n",
       " 'python not': 0.05411376220603684,\n",
       " 'first book': 0.054058138494711014,\n",
       " 'day usual': 0.05366889020413413,\n",
       " 'factual': 0.05358115400680362,\n",
       " 'imo': 0.05357663092622173,\n",
       " 'warn': 0.05354018159572215,\n",
       " 'know anyth': 0.05347042219273041,\n",
       " 'distort': 0.05339516181075683,\n",
       " 'directly': 0.05321442595569309,\n",
       " 'better result': 0.053047562023711886,\n",
       " 'bring': 0.05272995914016413,\n",
       " 'math': 0.05272389391827478,\n",
       " 'also interest': 0.05269643068728065,\n",
       " 'absorb': 0.0525769764324309,\n",
       " 'sev': 0.05247702504606407,\n",
       " 'mirror matching': 0.05239255752490443,\n",
       " 'ev know': 0.05222676095974294,\n",
       " 'outputs': 0.05216416042475885,\n",
       " 'interest machin': 0.05213762787787392,\n",
       " 'whatev': 0.05196314532792816,\n",
       " 'elem tari': 0.05193919007202345,\n",
       " 'tion above': 0.051937983581027004,\n",
       " 'result': 0.05187481086044553,\n",
       " 'deep medit': 0.05172682215025443,\n",
       " 'romal': 0.051726569002209295,\n",
       " 'again': 0.051714530947392,\n",
       " 'everyon know': 0.05166342500009974,\n",
       " 'nlpers': 0.05165825501226812,\n",
       " 'slow': 0.05163890686075152,\n",
       " 'sale person': 0.05161232346386612,\n",
       " 'spacy load': 0.05154253984009767,\n",
       " 'hot labels': 0.051458128043378515,\n",
       " 'person amp': 0.05132314072073913,\n",
       " 'nlp certif': 0.0512050014867822,\n",
       " 'efici': 0.05102824419554436,\n",
       " 'ote': 0.05094284493820386,\n",
       " 'submit': 0.05057333825829423,\n",
       " 'nlp problem': 0.05056631431852583,\n",
       " 'made': 0.05053674968293538,\n",
       " 'viru pandem': 0.05032625502173602,\n",
       " 'stanford nlp': 0.05032310828803963,\n",
       " 'pretrained model': 0.05029588224677326,\n",
       " 'cont': 0.05020840032205367,\n",
       " 'ngo': 0.05020149323823824,\n",
       " 'annot paper': 0.05013894455225016,\n",
       " 'th fine': 0.04994675448310172,\n",
       " 'mind take': 0.04979922286781541,\n",
       " 'max gth': 0.04979053392164768,\n",
       " 'classif use': 0.049701089205264136,\n",
       " 'scores': 0.0496677471089072,\n",
       " 'may occur': 0.04947983494328462,\n",
       " 'nlp nlp': 0.04946921294945792,\n",
       " 'winner': 0.049386614047692706,\n",
       " 'lat': 0.04935670790549386,\n",
       " 'artifici': 0.04934680792102077,\n",
       " 'titi get': 0.049152530950144366,\n",
       " 'know python': 0.049079239656451064,\n",
       " 'reading paper': 0.04892867481456013,\n",
       " 'tire sequ': 0.048906349688361536,\n",
       " 'load bn': 0.04882006269013351,\n",
       " 'time work': 0.04878659024040947,\n",
       " 'question pleas': 0.048506396102565644,\n",
       " 'error': 0.048493052526909206,\n",
       " 'iclr': 0.04830118468805545,\n",
       " 'specif label': 0.048281687882523336,\n",
       " 'want abl': 0.0480999640167245,\n",
       " 'adult': 0.04806994539175286,\n",
       " 'model tri': 0.04805308653496762,\n",
       " 'would good': 0.04803813894528084,\n",
       " 'german train': 0.047945803637147476,\n",
       " 'yelp reviews': 0.047869937247634484,\n",
       " 'gestur erat': 0.04778573178281311,\n",
       " 'hanc': 0.047734591159945085,\n",
       " 'unifi': 0.04770590632882376,\n",
       " 'vironm': 0.04769728433006818,\n",
       " 'regist': 0.04767161412540973,\n",
       " 'polit comm': 0.04749778784787237,\n",
       " 'struggl find': 0.04739704912555715,\n",
       " 'fellow': 0.04733310174226492,\n",
       " 'brand': 0.04724116854958009,\n",
       " 'there good': 0.0471948426846683,\n",
       " 'make model': 0.047178414321392415,\n",
       " 'wake': 0.047129900779185344,\n",
       " 'crossminds': 0.047125675440649675,\n",
       " 'ev wh': 0.04711504842107406,\n",
       " 'audiobook': 0.04703724866000368,\n",
       " 'lic': 0.047003945051625744,\n",
       " 'jamesppesch video': 0.046963094992319834,\n",
       " 'set label': 0.046763148189618055,\n",
       " 'summary': 0.04675700406407479,\n",
       " 'way stori': 0.04671702247088434,\n",
       " 'pandem': 0.04664244293756989,\n",
       " 'differ short': 0.04659045001687353,\n",
       " 'ce stud': 0.04657973659843724,\n",
       " 'syndrome': 0.0464907250451852,\n",
       " 'experim ts': 0.04638625489131552,\n",
       " 'thought could': 0.04635352660587422,\n",
       " 'anyon list': 0.046332417652573565,\n",
       " 'code import': 0.04625541725439414,\n",
       " 'second question': 0.04603070166219583,\n",
       " 'link blog': 0.04598356743659859,\n",
       " 'job': 0.045874122262270785,\n",
       " 'sort thing': 0.045823081712864096,\n",
       " 'contact us': 0.04580271930523661,\n",
       " 'kera': 0.04572369805293942,\n",
       " 'false': 0.04566620522794872,\n",
       " 'model atmodel': 0.04564731587815394,\n",
       " 'complex': 0.04549119072758792,\n",
       " 'pypi project': 0.04547539546795667,\n",
       " 'nlp look': 0.04541447510205829,\n",
       " 'link read': 0.04506214199940153,\n",
       " 'arabic farsi': 0.044944748857179195,\n",
       " 'models bert': 0.0449382699696103,\n",
       " 'use ml': 0.044912960486020025,\n",
       " 'mani ml': 0.04485407109224875,\n",
       " 'urg': 0.044811245704810584,\n",
       " 'so that': 0.04466941618349706,\n",
       " 'almost everi': 0.04464997514135503,\n",
       " 'biomed nlp': 0.04461102018510177,\n",
       " 'transform blob': 0.04449164742327503,\n",
       " 'weeks': 0.04428802117270151,\n",
       " 'one use': 0.04403719151375268,\n",
       " 'for exampl': 0.04391915301798257,\n",
       " 'sort information': 0.043843716339302244,\n",
       " 'war': 0.04369588471732009,\n",
       " 'solv': 0.043676781733879184,\n",
       " 'techniqu appli': 0.04359989242436252,\n",
       " 'ty': 0.04351559454322594,\n",
       " 'words look': 0.0434502515222233,\n",
       " 'travel': 0.04331564404889191,\n",
       " 'final year': 0.04323988668784375,\n",
       " 'exists': 0.043222558386019905,\n",
       " 'leverag': 0.043222123250656976,\n",
       " 'practition course': 0.042977612806543095,\n",
       " 'know tool': 0.04296502928596338,\n",
       " 'jamespesch author': 0.042936847437202594,\n",
       " 'way develop': 0.04291429015342421,\n",
       " 'affect people': 0.04284717322649345,\n",
       " 'that happ': 0.04279027404843038,\n",
       " 'work person': 0.04271124970563283,\n",
       " 'follow code': 0.0425989168730284,\n",
       " 'forth': 0.04253816103030828,\n",
       " 'good bad': 0.04253470876686838,\n",
       " 'like they': 0.04252648313702421,\n",
       " 'classif problem': 0.04231139736144337,\n",
       " 'hello all': 0.04226266264229645,\n",
       " 'bert pretrain': 0.04225874761142653,\n",
       " 'sales': 0.04225299078632225,\n",
       " 'boring': 0.04215079916100014,\n",
       " 'hu': 0.042139511592728746,\n",
       " 'nueva app': 0.04213622045608517,\n",
       " 'news headlin': 0.0420772807055653,\n",
       " 'peopl': 0.04206245057662208,\n",
       " 'welcom back': 0.0414896148597469,\n",
       " 'jordan': 0.04145852940385601,\n",
       " 'audio file': 0.041391831157778475,\n",
       " 'hardwork': 0.04138967828256133,\n",
       " 'multilingu models': 0.04136559854898065,\n",
       " 'alreadi develop': 0.041336793040433015,\n",
       " 'python': 0.041259175894877244,\n",
       " 'high accuraci': 0.04110555083762667,\n",
       " 'ce result': 0.04099606099464518,\n",
       " 'tree': 0.040942677915924285,\n",
       " 'playlist': 0.04088874085418266,\n",
       " 'distilbert base': 0.04088158430960367,\n",
       " 'reproduc': 0.0407554555154856,\n",
       " 'featur new': 0.04035885412264328,\n",
       " 'anyon insight': 0.040289257716827384,\n",
       " 'chrome': 0.040269069522593244,\n",
       " 'model base': 0.04010044869938944,\n",
       " 'rudim': 0.039803320128165925,\n",
       " 'xb final': 0.03974214398970983,\n",
       " 'way blog': 0.03970071776189234,\n",
       " 'nlp curr': 0.03969995859710594,\n",
       " 'two': 0.0394787065601818,\n",
       " 'ce usual': 0.039443701283946454,\n",
       " 'bert transform': 0.03941745665217666,\n",
       " 'trick mind': 0.039411074559370284,\n",
       " 'grone': 0.03936282472923893,\n",
       " 'get control': 0.03935986589338297,\n",
       " 'class classif': 0.03928343048850969,\n",
       " 'findings': 0.03914542625876611,\n",
       " 'consciou': 0.03901298151435407,\n",
       " 'remot': 0.0389956756751017,\n",
       " 'help trigger': 0.038988795438268595,\n",
       " 'tune': 0.03880619934785975,\n",
       " 'therefor use': 0.03878921136138234,\n",
       " 'year now': 0.03877184913813505,\n",
       " 'tübing': 0.038673986741035754,\n",
       " 'excit share': 0.038624195561308985,\n",
       " 'practic better': 0.03856777157742932,\n",
       " 'tv': 0.03855079691373014,\n",
       " 'chill': 0.03845479410810868,\n",
       " 'thought experim': 0.03842918591915981,\n",
       " 'svm': 0.03840995414827776,\n",
       " 'meta program': 0.03812702139355104,\n",
       " 'elem': 0.038122051305047595,\n",
       " 'another': 0.0380920545556677,\n",
       " 'refr ce': 0.038035443023335704,\n",
       " 'aggreg': 0.03798677355867496,\n",
       " 'metaphors': 0.037822645244648664,\n",
       " 'treat': 0.03781702841627728,\n",
       " 'gramform': 0.037814639876249896,\n",
       " 'around it': 0.03780331166861812,\n",
       " 'superficially': 0.03775585151296229,\n",
       " 'nlp tok': 0.03774746163164811,\n",
       " 'translation summarization': 0.03764820788494773,\n",
       " 'conquer': 0.03761012932910215,\n",
       " 'transfer': 0.0375986230273564,\n",
       " 'larg univers': 0.0375410089975133,\n",
       " 'well number': 0.037418143972101796,\n",
       " 'like good': 0.037294720543125236,\n",
       " 'school project': 0.03724547376270427,\n",
       " 'tri creat': 0.03707572783510996,\n",
       " 'descriptions': 0.03688941456681978,\n",
       " 'manually': 0.03682539558010637,\n",
       " 'might help': 0.036703002189828665,\n",
       " 'abl help': 0.03670071933036717,\n",
       " 'product': 0.03667801084117687,\n",
       " 'es': 0.036608064137714114,\n",
       " 'wh comput': 0.03659423055710126,\n",
       " 'wave': 0.03654681255297105,\n",
       " 'helps': 0.03646382806311722,\n",
       " 'sound': 0.036390061365743014,\n",
       " 'nlu ressourc': 0.036387729664514014,\n",
       " 'drain': 0.036099500643327266,\n",
       " 'essay': 0.036015443963961453,\n",
       " 'go back': 0.035997092449281745,\n",
       " 'formul': 0.03589220111655764,\n",
       " 'know common': 0.03582211584298101,\n",
       " 'normally': 0.035793814015231934,\n",
       " 'similar match': 0.035744877200583045,\n",
       " 'leader': 0.03572056497301651,\n",
       " 'meat': 0.03568261572905218,\n",
       " 'ambit': 0.03566718489419031,\n",
       " 'interpret thing': 0.03566157974111817,\n",
       " 'thu': 0.035626708995826775,\n",
       " 'it amp': 0.035482433206345323,\n",
       " 'schedul': 0.03547422258050209,\n",
       " 'project nlp': 0.0353442903739051,\n",
       " 'it also': 0.03490665915332224,\n",
       " 'tool nlp': 0.03488584695571514,\n",
       " 'concept could': 0.03483741114748756,\n",
       " 'cont be': 0.03482446150036278,\n",
       " 'ner hello': 0.034422544456682025,\n",
       " 'revers gineer': 0.034353516527932886,\n",
       " 'requir first': 0.03435331237648399,\n",
       " 'chat': 0.0342435675123346,\n",
       " 'shreyansh github': 0.0342419746465187,\n",
       " 'topic interest': 0.03423988250813226,\n",
       " 'isn': 0.033979045811055604,\n",
       " 'dynamic': 0.03395522434275054,\n",
       " 'll also': 0.033856793102904154,\n",
       " 'nlp practitioner': 0.03356514570738735,\n",
       " 'analys': 0.033555656409927886,\n",
       " 'family': 0.03352230286027968,\n",
       " 'higher level': 0.0335105782687996,\n",
       " 'question': 0.03343948772363117,\n",
       " 'code exampl': 0.03334577160182022,\n",
       " 'recomm book': 0.033267912252168214,\n",
       " 'model make': 0.033163651083793176,\n",
       " 'somewhat': 0.03308853224826883,\n",
       " 'pressure': 0.03279980933646927,\n",
       " 'raw data': 0.03274894206327529,\n",
       " 'ergi': 0.03269161892198788,\n",
       " 'santa': 0.03256559872547129,\n",
       " 'decis': 0.03245686038012118,\n",
       " 'mani time': 0.03241280304225115,\n",
       " 'ant': 0.0322776968120484,\n",
       " 'divid': 0.03209922785406106,\n",
       " 'erat dataset': 0.03209068444532705,\n",
       " 'could also': 0.03208452788917902,\n",
       " 'appli deep': 0.031905962594919124,\n",
       " 'nlp part': 0.03160357765428201,\n",
       " 'nlp techniqu': 0.031597870521127114,\n",
       " 'day night': 0.031497420858206275,\n",
       " 'automat extract': 0.03146958718300353,\n",
       " 'right use': 0.0312980895264222,\n",
       " 'load bh': 0.031225228813204522,\n",
       " 'rearrang': 0.031099409185572986,\n",
       " 'pip instal': 0.031036925205452034,\n",
       " 'associ': 0.030867280737993066,\n",
       " 'paper implem': 0.030861870133249675,\n",
       " 'detrim': 0.030807923953376577,\n",
       " 'anxieti': 0.03071929384146224,\n",
       " 'ye': 0.030685798571269386,\n",
       " 'ce eral': 0.03061308091753561,\n",
       " 'continue': 0.030469872088654298,\n",
       " 'model explain': 0.030437381489637632,\n",
       " 'betw tities': 0.03039941813807467,\n",
       " 'things': 0.030356185554729777,\n",
       " 'tell': 0.030281673958040295,\n",
       " 'test sets': 0.02999221191220237,\n",
       " ...}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_miscl_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d775faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_miscl_features_20 = list(m4_miscl_features.keys())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "59eb5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_rm_features(raw_text, features_to_remove=m4_miscl_features_20):\n",
    "    processed = re.sub(r'\\n|\\t', ' ', raw_text)\n",
    "    processed = melt_urls(clean_sqb(processed))\n",
    "    processed = re.sub(r'\\d+', '', processed)\n",
    "    processed = processed.lower()\n",
    "    processed = remove_stopwords(processed)\n",
    "    processed = stem(processed) \n",
    "    for ft in features_to_remove:\n",
    "        processed = processed.replace(ft, ' ')\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2ce7e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_rm = Pipeline(steps=[('tvec',\n",
    "                 TfidfVectorizer(max_df=0.9, min_df=2, ngram_range=(1, 2),\n",
    "                                 preprocessor=preproc_rm_features)),\n",
    "                ('nb', MultinomialNB(fit_prior=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ed31c8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tvec',\n",
       "                 TfidfVectorizer(max_df=0.9, min_df=2, ngram_range=(1, 2),\n",
       "                                 preprocessor=<function preproc_rm_features at 0x7fc2cc71f280>)),\n",
       "                ('nb', MultinomialNB(fit_prior=False))])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_rm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "38e9712a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9858520900321543"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_rm.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f5f67b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9485861182519281"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_rm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fe69e450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9389228206551916"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_rm.score(X_dl, y_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9e05e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to original model performance\n",
    "# results.iloc[3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8775f",
   "metadata": {},
   "source": [
    "Removing the top 20 highest tfidf scoring features of the misclassified data from the model seems to slightly improve the train accuracy and related topic accuracy at the expense of the test accuracy. There does not seem to be significant benefit from the added complexity of calculating the top features in the misclassified data and filtering them out from the models after."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a81aa",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e71b4e",
   "metadata": {},
   "source": [
    "1. The best model for prediction is multinomial naive bayes classifier with tifidf vectorizer, and it has proven to generalise well to distinguishing adjacent topics too. This shows promise that the classifier has the potential to learn from a wider range of natural language processing topics to be able to classify beyond the limited language technology reddit subset of vocabulary it has trained on.\n",
    "\n",
    "\n",
    "2. Separating neuro-linguistic programming content from natural language processing content appears to be a very achievable task, however, the highest weighted features of the best models are slightly worrying in that they do not seem to be words that very obviously distinguish the two classes. (might not be a bad thing, that is why we have ML). More work can definitely be done to improve the model to be ready for a wider range of natural language processing topics. Moving forward, it would be helpful scrape a larger variety of training data that covers a wider range of vocabulary for both topics. \n",
    "\n",
    "\n",
    "3. Although the intuition is that the two topics can be separated by a few obvious terms, the model performance and coefficients indicate that better prediction comes from learning from a wider variety of features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
